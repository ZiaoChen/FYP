Title,Abstract,Keywords
Global Contrast Based Salient Region Detection,"Automatic estimation of salient object regions across images, without any prior assumption or knowledge of the contents of the corresponding scenes, enhances many computer vision and computer graphics applications. We introduce a regional contrast based salient object detection algorithm, which simultaneously evaluates global contrast differences and spatial weighted coherence scores. The proposed algorithm is simple, efficient, naturally multi-scale, and produces full-resolution, high-quality saliency maps. These saliency maps are further used to initialize a novel iterative version of GrabCut, namely SaliencyCut, for high quality unsupervised salient object segmentation. We extensively evaluated our algorithm using traditional salient object detection datasets, as well as a more challenging Internet image dataset. Our experimental results demonstrate that our algorithm consistently outperforms 15 existing salient object detection and segmentation methods, yielding higher precision and better recall rates. We also show that our algorithm can be used to efficiently extract salient object masks from Internet images, enabling effective sketch-based image retrieval (SBIR) via simple shape comparisons. Despite such noisy internet images, where the saliency regions are ambiguous, our saliency guided image retrieval achieves a superior retrieval rate compared with state-of-the-art SBIR methods, and additionally provides important target object region information.","Image color analysis,
Image segmentation,
Histograms,
Smoothing methods,
Visualization,
Quantization (signal),
Object detection"
Incremental Support Vector Learning for Ordinal Regression,"Support vector ordinal regression (SVOR) is a popular method to tackle ordinal regression problems. However, until now there were no effective algorithms proposed to address incremental SVOR learning due to the complicated formulations of SVOR. Recently, an interesting accurate on-line algorithm was proposed for training ν-support vector classification (ν-SVC), which can handle a quadratic formulation with a pair of equality constraints. In this paper, we first present a modified SVOR formulation based on a sum-of-margins strategy. The formulation has multiple constraints, and each constraint includes a mixture of an equality and an inequality. Then, we extend the accurate on-line ν-SVC algorithm to the modified formulation, and propose an effective incremental SVOR algorithm. The algorithm can handle a quadratic formulation with multiple constraints, where each constraint is constituted of an equality and an inequality. More importantly, it tackles the conflicts between the equality and inequality constraints. We also provide the finite convergence analysis for the algorithm. Numerical experiments on the several benchmark and real-world data sets show that the incremental algorithm can converge to the optimal solution in a finite number of steps, and is faster than the existing batch and incremental SVOR algorithms. Meanwhile, the modified formulation has better accuracy than the existing incremental SVOR algorithm, and is as accurate as the sum-of-margins based formulation of Shashua and Levin.","Support vector machines,
Training,
Algorithm design and analysis,
Vectors,
Training data,
Educational institutions,
Convergence"
Segmentation-Based Image Copy-Move Forgery Detection Scheme,"In this paper, we propose a scheme to detect the copy-move forgery in an image, mainly by extracting the keypoints for comparison. The main difference to the traditional methods is that the proposed scheme first segments the test image into semantically independent patches prior to keypoint extraction. As a result, the copy-move regions can be detected by matching between these patches. The matching process consists of two stages. In the first stage, we find the suspicious pairs of patches that may contain copy-move forgery regions, and we roughly estimate an affine transform matrix. In the second stage, an Expectation-Maximization-based algorithm is designed to refine the estimated matrix and to confirm the existence of copy-move forgery. Experimental results prove the good performance of the proposed scheme via comparing it with the state-of-the-art schemes on the public databases.",
Wireless Power Transfer for Electric Vehicle Applications,"Wireless power transfer (WPT) using magnetic resonance is the technology which could set human free from the annoying wires. In fact, the WPT adopts the same basic theory which has already been developed for at least 30 years with the term inductive power transfer. WPT technology is developing rapidly in recent years. At kilowatts power level, the transfer distance increases from several millimeters to several hundred millimeters with a grid to load efficiency above 90%. The advances make the WPT very attractive to the electric vehicle (EV) charging applications in both stationary and dynamic charging scenarios. This paper reviewed the technologies in the WPT area applicable to EV wireless charging. By introducing WPT in EVs, the obstacles of charging time, range, and cost can be easily mitigated. Battery technology is no longer relevant in the mass market penetration of EVs. It is hoped that researchers could be encouraged by the state-of-the-art achievements, and push forward the further development of WPT as well as the expansion of EV.","Coils,
Couplers,
Batteries,
Wireless communication,
Couplings,
Power electronics,
Ferrites"
Deep visual-semantic alignments for generating image descriptions,"We present a model that generates natural language descriptions of images and their regions. Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data. Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions significantly outperform retrieval baselines on both full images and on a new dataset of region-level annotations.","recurrent neural nets,
image retrieval,
image segmentation,
learning (artificial intelligence),
natural language processing"
Object Tracking Benchmark,"Object tracking has been one of the most important and active research areas in the field of computer vision. A large number of tracking algorithms have been proposed in recent years with demonstrated success. However, the set of sequences used for evaluation is often not sufficient or is sometimes biased for certain types of algorithms. Many datasets do not have common ground-truth object positions or extents, and this makes comparisons among the reported quantitative results difficult. In addition, the initial conditions or parameters of the evaluated tracking algorithms are not the same, and thus, the quantitative results reported in literature are incomparable or sometimes contradictory. To address these issues, we carry out an extensive evaluation of the state-of-the-art online object-tracking algorithms with various evaluation criteria to understand how these methods perform within the same framework. In this work, we first construct a large dataset with ground-truth object positions and extents for tracking and introduce the sequence attributes for the performance analysis. Second, we integrate most of the publicly available trackers into one code library with uniform input and output formats to facilitate large-scale performance evaluation. Third, we extensively evaluate the performance of 31 algorithms on 100 sequences with different initialization settings. By analyzing the quantitative results, we identify effective approaches for robust tracking and provide potential future research directions in this field.","Target tracking,
Object tracking,
Algorithm design and analysis,
Performance evaluation,
Robustness,
Histograms"
Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,"Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224
×
224) input image. This requirement is “artificial” and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, “spatial pyramid pooling”, to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102
×
faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.","Training,
Feature extraction,
Accuracy,
Convolutional codes,
Agriculture,
Testing,
Vectors"
Efficient Motion and Disparity Estimation Optimization for Low Complexity Multiview Video Coding,"The use of variable block-size motion estimation (ME), disparity estimation (DE), and multiple reference frames selection aims to improve the coding efficiency of multiview video coding (MVC), however, this is at the cost of high computational complexity of these advanced coding techniques, which are not suitable for real-time video broadcasting applications. In this paper, we propose an efficient ME and DE algorithm for reducing the computational complexity of MVC. Firstly, according to the characteristics of the coded block pattern and rate distortion (RD) cost, an early DIRECT mode decision algorithm is proposed. Then, based on the characteristics of the initial search point in the ME/DE process and the observation that the best point is center-biased, an early ME/DE termination strategy is proposed. If the ME/DE early termination is not satisfied, the ME/DE search window will be reduced by applying the optimal theory. At last, two block matching search strategies are proposed to predict the best point for the ME/DE. Experimental results show that the proposed algorithm can achieve 50.05% to 77.61%, 64.83% on average encoding time saving. Meanwhile, the RD performance degradation is negligible. Especially, the proposed algorithm can be applied to not only the odd views but also the even views.",
The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS),"In this paper we report the set-up and results of the Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized in conjunction with the MICCAI 2012 and 2013 conferences. Twenty state-of-the-art tumor segmentation algorithms were applied to a set of 65 multi-contrast MR scans of low- and high-grade glioma patients - manually annotated by up to four raters - and to 65 comparable scans generated using tumor image simulation software. Quantitative evaluations revealed considerable disagreement between the human raters in segmenting various tumor sub-regions (Dice scores in the range 74%-85%), illustrating the difficulty of this task. We found that different algorithms worked best for different sub-regions (reaching performance comparable to human inter-rater variability), but that no single algorithm ranked in the top for all sub-regions simultaneously. Fusing several good algorithms using a hierarchical majority vote yielded segmentations that consistently ranked above all individual algorithms, indicating remaining opportunities for further methodological improvements. The BRATS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource.","Image segmentation,
Educational institutions,
Benchmark testing,
Biomedical imaging,
Lesions"
Salient Object Detection: A Benchmark,"We extensively compare, qualitatively and quantitatively, 41 state-of-the-art models (29 salient object detection, 10 fixation prediction, 1 objectness, and 1 baseline) over seven challenging data sets for the purpose of benchmarking salient object detection and segmentation methods. From the results obtained so far, our evaluation shows a consistent rapid progress over the last few years in terms of both accuracy and running time. The top contenders in this benchmark significantly outperform the models identified as the best in the previous benchmark conducted three years ago. We find that the models designed specifically for salient object detection generally work better than models in closely related areas, which in turn provides a precise definition and suggests an appropriate treatment of this problem that distinguishes it from other problems. In particular, we analyze the influences of center bias and scene complexity in model performance, which, along with the hard cases for the state-of-the-art models, provide useful hints toward constructing more challenging large-scale data sets and better saliency models. Finally, we propose probable solutions for tackling several open problems, such as evaluation scores and data set bias, which also suggest future research directions in the rapidly growing field of salient object detection.","Benchmark testing,
Object detection,
Predictive models,
Solid modeling,
Computational modeling,
Visualization,
Proposals"
A Survey on Software-Defined Networking,"Emerging mega-trends (e.g., mobile, social, cloud, and big data) in information and communication technologies (ICT) are commanding new challenges to future Internet, for which ubiquitous accessibility, high bandwidth, and dynamic management are crucial. However, traditional approaches based on manual configuration of proprietary devices are cumbersome and error-prone, and they cannot fully utilize the capability of physical network infrastructure. Recently, software-defined networking (SDN) has been touted as one of the most promising solutions for future Internet. SDN is characterized by its two distinguished features, including decoupling the control plane from the data plane and providing programmability for network application development. As a result, SDN is positioned to provide more efficient configuration, better performance, and higher flexibility to accommodate innovative network designs. This paper surveys latest developments in this active research area of SDN. We first present a generally accepted definition for SDN with the aforementioned two characteristic features and potential benefits of SDN. We then dwell on its three-layer architecture, including an infrastructure layer, a control layer, and an application layer, and substantiate each layer with existing research efforts and its related research areas. We follow that with an overview of the de facto SDN implementation (i.e., OpenFlow). Finally, we conclude this survey paper with some suggested open research challenges.","Optical switches,
Routing,
Software,
Computer architecture,
Complexity theory"
Multi-View Intact Space Learning,"It is practical to assume that an individual view is unlikely to be sufficient for effective multi-view learning. Therefore, integration of multi-view information is both valuable and necessary. In this paper, we propose the Multi-view Intact Space Learning (MISL) algorithm, which integrates the encoded complementary information in multiple views to discover a latent intact representation of the data. Even though each view on its own is insufficient, we show theoretically that by combing multiple views we can obtain abundant information for latent intact space learning. Employing the Cauchy loss (a technique used in statistical learning) as the error measurement strengthens robustness to outliers. We propose a new definition of multi-view stability and then derive the generalization error bound based on multi-view stability and Rademacher complexity, and show that the complementarity between multiple views is beneficial for the stability and generalization. MISL is efficiently optimized using a novel Iteratively Reweight Residuals (IRR) technique, whose convergence is theoretically analyzed. Experiments on synthetic data and real-world datasets demonstrate that MISL is an effective and promising algorithm for practical applications.","Statistical learning,
Stability analysis,
Measurement uncertainty,
Loss measurement,
Learning systems,
Algorithm design and analysis,
Complexity theory"
Phase-Change Memory Optimization for Green Cloud with Genetic Algorithm,"Green cloud is an emerging new technology in the computing world in which memory is a critical component. Phase-change memory (PCM) is one of the most promising alternative techniques to the dynamic random access memory (DRAM) that faces the scalability wall. Recent research has been focusing on the multi-level cell (MLC) of PCM. By precisely arranging multiple levels of resistance inside a PCM cell, more than one bit of data can be stored in one single PCM cell. However, the MLC PCM suffers from the degradation of performance compared to the single-level cell(SLC) PCM, due to the longer memory access time. In this paper, we present a genetic-based optimization algorithm for chip multiprocessor (CMP) equipped with PCM memory in green clouds. The proposed genetic-based algorithm not only schedules and assigns tasks to cores in the CMP system, but also provides a PCM MLC configuration that balances the PCM memory performance as well as the efficiency. The experimental results show that our genetic-based algorithm can significantly reduce the maximum memory usage by 76.8 percent comparing with the uniform SLC configuration, and improve the efficiency of memory usage by 127 percent comparing with the uniform 4 bits/cell MLC configuration. Moreover, the performance of the system is also improved by 24.5 percent comparing with the uniform 4 bits/cell MLC configuration in terms of total execution time.",
Person re-identification by Local Maximal Occurrence representation and metric learning,"Person re-identification is an important technique towards automatic search of a person's presence in a surveillance video. Two fundamental problems are critical for person re-identification, feature representation and metric learning. An effective feature representation should be robust to illumination and viewpoint changes, and a discriminant metric should be learned to match various person images. In this paper, we propose an effective feature representation called Local Maximal Occurrence (LOMO), and a subspace and metric learning method called Cross-view Quadratic Discriminant Analysis (XQDA). The LOMO feature analyzes the horizontal occurrence of local features, and maximizes the occurrence to make a stable representation against viewpoint changes. Besides, to handle illumination variations, we apply the Retinex transform and a scale invariant texture operator. To learn a discriminant metric, we propose to learn a discriminant low dimensional subspace by cross-view quadratic discriminant analysis, and simultaneously, a QDA metric is learned on the derived subspace. We also present a practical computation method for XQDA, as well as its regularization. Experiments on four challenging person re-identification databases, VIPeR, QMUL GRID, CUHK Campus, and CUHK03, show that the proposed method improves the state-of-the-art rank-1 identification rates by 2.2%, 4.88%, 28.91%, and 31.55% on the four databases, respectively.","Measurement,
Image color analysis,
Databases,
Feature extraction,
Robustness,
Cameras,
Histograms"
Interference-Based Topology Control Algorithm for Delay-Constrained Mobile Ad Hoc Networks,"As the foundation of routing, topology control should minimize the interference among nodes, and increase the network capacity. With the development of mobile ad hoc networks (MANETs), there is a growing requirement of quality of service (QoS) in terms of delay. In order to meet the delay requirement, it is important to consider topology control in delay constrained environment, which is contradictory to the objective of minimizing interference. In this paper, we focus on the delay-constrained topology control problem, and take into account delay and interference jointly. We propose a cross-layer distributed algorithm called interference-based topology control algorithm for delay-constrained (ITCD) MANETs with considering both the interference constraint and the delay constraint, which is different from the previous work. The transmission delay, contention delay and the queuing delay are taken into account in the proposed algorithm. Moreover, the impact of node mobility on the interference-based topology control algorithm is investigated and the unstable links are removed from the topology. The simulation results show that ITCD can reduce the delay and improve the performance effectively in delay-constrained mobile ad hoc networks.","Delays,
Topology,
Network topology,
Quality of service,
Mobile computing,
Interference,
Routing"
A Survey of Sparse Representation: Algorithms and Applications,"Sparse representation has attracted much attention from researchers in fields of signal processing, image processing, computer vision, and pattern recognition. Sparse representation also has a good reputation in both theoretical research and practical applications. Many different algorithms have been proposed for sparse representation. The main purpose of this paper is to provide a comprehensive study and an updated review on sparse representation and to supply guidance for researchers. The taxonomy of sparse representation methods can be studied from various viewpoints. For example, in terms of different norm minimizations used in sparsity constraints, the methods can be roughly categorized into five groups: 1) sparse representation with l0-norm minimization; 2) sparse representation with lp-norm (0 <; p <; 1) minimization; 3) sparse representation with l1-norm minimization; 4) sparse representation with l2,1-norm minimization; and 5) sparse representation with l2-norm minimization. In this paper, a comprehensive overview of sparse representation is provided. The available sparse representation algorithms can also be empirically categorized into four groups: 1) greedy strategy approximation; 2) constrained optimization; 3) proximity algorithm-based optimization; and 4) homotopy algorithm-based sparse representation. The rationales of different algorithms in each category are analyzed and a wide range of sparse representation applications are summarized, which could sufficiently reveal the potential nature of the sparse representation theory. In particular, an experimentally comparative study of these sparse representation algorithms was presented.",
"Full duplex techniques for 5G networks: self-interference cancellation, protocol design, and relay selection","The wireless research community aspires to conceive full duplex operation by supporting concurrent transmission and reception in a single time/frequency channel for the sake of improving the attainable spectral efficiency by a factor of two as compared to the family of conventional half duplex wireless systems. The main challenge encountered in implementing FD wireless devices is that of finding techniques for mitigating the performance degradation imposed by self-interference. In this article, we investigate the potential FD techniques, including passive suppression, active analog cancellation, and active digital cancellation, and highlight their pros and cons. Furthermore, the troubles of FD medium access control protocol design are discussed for addressing the problems such as the resultant end-to-end delay and network congestion. Additionally, an opportunistic decode-and-forward- based relay selection scheme is analyzed in underlay cognitive networks communicating over independent and identically distributed Rayleigh and Nakagami-m fading channels in the context of FD relaying. We demonstrate that the outage probability of multi-relay cooperative communication links can be substantially reduced. Finally, we discuss the challenges imposed by the aforementioned techniques and a range of critical issues associated with practical FD implementations. It is shown that numerous open challenges, such as efficient SI suppression, high-performance FD MAC-layer protocol design, low power consumption, and hybrid FD/HD designs, have to be tackled before successfully implementing FD-based systems.","Wireless communication,
Receiving antennas,
Transmitting antennas,
Relays,
Full duplex communication,
Throughput,
MIMO"
"EDAL: An Energy-Efficient, Delay-Aware, and Lifetime-Balancing Data Collection Protocol for Heterogeneous Wireless Sensor Networks","Our work in this paper stems from our insight that recent research efforts on open vehicle routing (OVR) problems, an active area in operations research, are based on similar assumptions and constraints compared to sensor networks. Therefore, it may be feasible that we could adapt these techniques in such a way that they will provide valuable solutions to certain tricky problems in the wireless sensor network (WSN) domain. To demonstrate that this approach is feasible, we develop one data collection protocol called EDAL, which stands for Energy-efficient Delay-aware Lifetime-balancing data collection. The algorithm design of EDAL leverages one result from OVR to prove that the problem formulation is inherently NP-hard. Therefore, we proposed both a centralized heuristic to reduce its computational overhead and a distributed heuristic to make the algorithm scalable for large-scale network operations. We also develop EDAL to be closely integrated with compressive sensing, an emerging technique that promises considerable reduction in total traffic cost for collecting sensor readings under loose delay bounds. Finally, we systematically evaluate EDAL to compare its performance to related protocols in both simulations and a hardware testbed.","Vehicles,
Delays,
Heuristic algorithms,
Wireless sensor networks,
Routing,
Data collection,
Protocols"
PCANet: A Simple Deep Learning Baseline for Image Classification?,"In this paper, we propose a very simple deep learning network for image classification that is based on very basic data processing components: 1) cascaded principal component analysis (PCA); 2) binary hashing; and 3) blockwise histograms. In the proposed architecture, the PCA is employed to learn multistage filter banks. This is followed by simple binary hashing and block histograms for indexing and pooling. This architecture is thus called the PCA network (PCANet) and can be extremely easily and efficiently designed and learned. For comparison and to provide a better understanding, we also introduce and study two simple variations of PCANet: 1) RandNet and 2) LDANet. They share the same topology as PCANet, but their cascaded filters are either randomly selected or learned from linear discriminant analysis. We have extensively tested these basic networks on many benchmark visual data sets for different tasks, including Labeled Faces in the Wild (LFW) for face verification; the MultiPIE, Extended Yale B, AR, Facial Recognition Technology (FERET) data sets for face recognition; and MNIST for hand-written digit recognition. Surprisingly, for all tasks, such a seemingly naive PCANet model is on par with the state-of-the-art features either prefixed, highly hand-crafted, or carefully learned [by deep neural networks (DNNs)]. Even more surprisingly, the model sets new records for many classification tasks on the Extended Yale B, AR, and FERET data sets and on MNIST variations. Additional experiments on other public data sets also demonstrate the potential of PCANet to serve as a simple but highly competitive baseline for texture classification and object recognition.","Principal component analysis,
Histograms,
Face,
Feature extraction,
Machine learning,
Training,
Face recognition"
Fronthaul-constrained cloud radio access networks: insights and challenges,"As a promising paradigm for fifth generation wireless communication systems, cloud radio access networks (C-RANs) have been shown to reduce both capital and operating expenditures, as well as to provide high spectral efficiency (SE) and energy efficiency (EE). The fronthaul in such networks, defined as the transmission link between the baseband unit and the remote radio head, requires a high capacity, but is often constrained. This article comprehensively surveys recent advances in fronthaul-constrained CRANs, including system architectures and key techniques. Particularly, major issues relating to the impact of the constrained fronthaul on SE/EE and quality of service for users, including compression and quantization, large-scale coordinated processing and clustering, and resource allocation optimization, are discussed together with corresponding potential solutions. Open issues in terms of software-defined networking, network function virtualization, and partial centralization are also identified.","Quantization (signal),
Wireless communication,
Radio access networks,
Computer architecture,
Noise measurement,
Baseband"
Supervised Discrete Hashing,"Recently, learning based hashing techniques have attracted broad research interests because they can support efficient storage and retrieval for high-dimensional data such as images, videos, documents, etc. However, a major difficulty of learning to hash lies in handling the discrete constraints imposed on the pursued hash codes, which typically makes hash optimizations very challenging (NP-hard in general). In this work, we propose a new supervised hashing framework, where the learning objective is to generate the optimal binary hash codes for linear classification. By introducing an auxiliary variable, we reformulate the objective such that it can be solved substantially efficiently by employing a regularization algorithm. One of the key steps in this algorithm is to solve a regularization sub-problem associated with the NP-hard binary optimization. We show that the sub-problem admits an analytical solution via cyclic coordinate descent. As such, a high-quality discrete solution can eventually be obtained in an efficient computing manner, therefore enabling to tackle massive datasets. We evaluate the proposed approach, dubbed Supervised Discrete Hashing (SDH), on four large image datasets and demonstrate its superiority to the state-of-the-art hashing methods in large-scale image retrieval.","Binary codes,
Optimization,
Synchronous digital hierarchy,
Kernel,
Fasteners,
Training data,
Joints"
An Efficient Approach to Nondominated Sorting for Evolutionary Multiobjective Optimization,"Evolutionary algorithms have been shown to be powerful for solving multiobjective optimization problems, in which nondominated sorting is a widely adopted technique in selection. This technique, however, can be computationally expensive, especially when the number of individuals in the population becomes large. This is mainly because in most existing nondominated sorting algorithms, a solution needs to be compared with all other solutions before it can be assigned to a front. In this paper we propose a novel, computationally efficient approach to nondominated sorting, termed efficient nondominated sort (ENS). In ENS, a solution to be assigned to a front needs to be compared only with those that have already been assigned to a front, thereby avoiding many unnecessary dominance comparisons. Based on this new approach, two nondominated sorting algorithms have been suggested. Both theoretical analysis and empirical results show that the ENS-based sorting algorithms are computationally more efficient than the state-of-the-art nondominated sorting methods.","Sorting,
Sociology,
Statistics,
Time complexity,
Optimization,
Algorithm design and analysis"
An Evolutionary Many-Objective Optimization Algorithm Based on Dominance and Decomposition,"Achieving balance between convergence and diversity is a key issue in evolutionary multiobjective optimization. Most existing methodologies, which have demonstrated their niche on various practical problems involving two and three objectives, face significant challenges in many-objective optimization. This paper suggests a unified paradigm, which combines dominance- and decomposition-based approaches, for many-objective optimization. Our major purpose is to exploit the merits of both dominance- and decomposition-based approaches to balance the convergence and diversity of the evolutionary process. The performance of our proposed method is validated and compared with four state-of-the-art algorithms on a number of unconstrained benchmark problems with up to 15 objectives. Empirical results fully demonstrate the superiority of our proposed method on all considered test instances. In addition, we extend this method to solve constrained problems having a large number of objectives. Compared to two other recently proposed constrained optimizers, our proposed method shows highly competitive performance on all the constrained optimization problems.",
Robust Structured Subspace Learning for Data Representation,"To uncover an appropriate latent subspace for data representation, in this paper we propose a novel Robust Structured Subspace Learning (RSSL) algorithm by integrating image understanding and feature learning into a joint learning framework. The learned subspace is adopted as an intermediate space to reduce the semantic gap between the low-level visual features and the high-level semantics. To guarantee the subspace to be compact and discriminative, the intrinsic geometric structure of data, and the local and global structural consistencies over labels are exploited simultaneously in the proposed algorithm. Besides, we adopt the `2;1-norm for the formulations of loss function and regularization respectively to make our algorithm robust to the outliers and noise. An efficient algorithm is designed to solve the proposed optimization problem. It is noted that the proposed framework is a general one which can leverage several well-known algorithms as special cases and elucidate their intrinsic relationships. To validate the effectiveness of the proposed method, extensive experiments are conducted on diversity datasets for different image understanding tasks, i.e., image tagging, clustering, and classification, and the more encouraging results are achieved compared with some state-of-the-art approaches.","Semantics,
Robustness,
Algorithm design and analysis,
Optimization,
Noise,
Vectors,
Visualization"
Global Neural Dynamic Surface Tracking Control of Strict-Feedback Systems With Application to Hypersonic Flight Vehicle,"This paper studies both indirect and direct global neural control of strict-feedback systems in the presence of unknown dynamics, using the dynamic surface control (DSC) technique in a novel manner. A new switching mechanism is designed to combine an adaptive neural controller in the neural approximation domain, together with the robust controller that pulls the transient states back into the neural approximation domain from the outside. In comparison with the conventional control techniques, which could only achieve semiglobally uniformly ultimately bounded stability, the proposed control scheme guarantees all the signals in the closed-loop system are globally uniformly ultimately bounded, such that the conventional constraints on initial conditions of the neural control system can be relaxed. The simulation studies of hypersonic flight vehicle (HFV) are performed to demonstrate the effectiveness of the proposed global neural DSC design.","Artificial neural networks,
Vehicle dynamics,
Aerodynamics,
Approximation methods,
Switches,
Stability analysis"
Using Free Energy Principle For Blind Image Quality Assessment,"In this paper we propose a new no-reference (NR) image quality assessment (IQA) metric using the recently revealed free-energy-based brain theory and classical human visual system (HVS)-inspired features. The features used can be divided into three groups. The first involves the features inspired by the free energy principle and the structural degradation model. Furthermore, the free energy theory also reveals that the HVS always tries to infer the meaningful part from the visual stimuli. In terms of this finding, we first predict an image that the HVS perceives from a distorted image based on the free energy theory, then the second group of features is composed of some HVS-inspired features (such as structural information and gradient magnitude) computed using the distorted and predicted images. The third group of features quantifies the possible losses of “naturalness” in the distorted image by fitting the generalized Gaussian distribution to mean subtracted contrast normalized coefficients. After feature extraction, our algorithm utilizes the support vector machine based regression module to derive the overall quality score. Experiments on LIVE, TID2008, CSIQ, IVC, and Toyama databases confirm the effectiveness of our introduced NR IQA metric compared to the state-of-the-art.","Brain modeling,
Computational modeling,
Measurement,
Degradation,
Feature extraction,
Predictive models,
Visualization"
CDC: Compressive Data Collection for Wireless Sensor Networks,"Data collection is a crucial operation in wireless sensor networks. The design of data collection schemes is challenging due to the limited energy supply and the hot spot problem. Leveraging empirical observations that sensory data possess strong spatiotemporal compressibility, this paper proposes a novel compressive data collection scheme for wireless sensor networks. We adopt a power-law decaying data model verified by real data sets and then propose a random projection-based estimation algorithm for this data model. Our scheme requires fewer compressed measurements, thus greatly reduces the energy consumption. It allows simple routing strategy without much computation and control overheads, which leads to strong robustness in practical applications. Analytically, we prove that it achieves the optimal estimation error bound. Evaluations on real data sets (from the GreenOrbs, IntelLab and NBDC-CTD projects) show that compared with existing approaches, this new scheme prolongs the network lifetime by 1.5X to 2X for estimation error 5-20 percent.","Data collection,
Wireless sensor networks,
Routing,
Compressed sensing,
Estimation,
Data models,
Vectors"
A Study on Relationship Between Generalization Abilities and Fuzziness of Base Classifiers in Ensemble Learning,"We investigate essential relationships between generalization capabilities and fuzziness of fuzzy classifiers (viz., the classifiers whose outputs are vectors of membership grades of a pattern to the individual classes). The study makes a claim and offers sound evidence behind the observation that higher fuzziness of a fuzzy classifier may imply better generalization aspects of the classifier, especially for classification data exhibiting complex boundaries. This observation is not intuitive with a commonly accepted position in “traditional” pattern recognition. The relationship that obeys the conditional maximum entropy principle is experimentally confirmed. Furthermore, the relationship can be explained by the fact that samples located close to classification boundaries are more difficult to be correctly classified than the samples positioned far from the boundaries. This relationship is expected to provide some guidelines as to the improvement of generalization aspects of fuzzy classifiers.","Training,
Support vector machine classification,
Uncertainty,
Pragmatics,
Entropy,
Indexes"
Aggregate Flexibility of Thermostatically Controlled Loads,"It is widely accepted that thermostatically controlled loads (TCLs) can be used to provide regulation reserve to the grid. We first argue that the aggregate flexibility offered by a collection of TCLs can be succinctly modeled as a stochastic battery with dissipation. We next characterize the power limits and energy capacity of this battery model in terms of TCL parameters and random exogenous variables such as ambient temperature and user-specified set-points. We then describe a direct load control architecture for regulation service provision. Here, we use a priority-stack-based control framework to select which TCLs to control at any time. The control objective is for the aggregate power deviation from baseline to track an automatic generation control signal supplied by the system operator. Simulation studies suggest the practical promise of our methods.","Batteries,
Aggregates,
Load modeling,
Sociology,
Statistics,
Mathematical model,
Frequency control"
Text Detection and Recognition in Imagery: A Survey,"This paper analyzes, compares, and contrasts technical challenges, methods, and the performance of text detection and recognition research in color imagery. It summarizes the fundamental problems and enumerates factors that should be considered when addressing these problems. Existing techniques are categorized as either stepwise or integrated and sub-problems are highlighted including text localization, verification, segmentation and recognition. Special issues associated with the enhancement of degraded text and the processing of video text, multi-oriented, perspectively distorted and multilingual text are also addressed. The categories and sub-categories of text are illustrated, benchmark datasets are enumerated, and the performance of the most representative approaches is compared. This review provides a fundamental comparison and analysis of the remaining problems in the field.",
A Knee Point-Driven Evolutionary Algorithm for Many-Objective Optimization,"Evolutionary algorithms (EAs) have shown to be promising in solving many-objective optimization problems (MaOPs), where the performance of these algorithms heavily depends on whether solutions that can accelerate convergence toward the Pareto front and maintaining a high degree of diversity will be selected from a set of nondominated solutions. In this paper, we propose a knee point-driven EA to solve MaOPs. Our basic idea is that knee points are naturally most preferred among nondominated solutions if no explicit user preferences are given. A bias toward the knee points in the nondominated solutions in the current population is shown to be an approximation of a bias toward a large hypervolume, thereby enhancing the convergence performance in many-objective optimization. In addition, as at most one solution will be identified as a knee point inside the neighborhood of each solution in the nondominated front, no additional diversity maintenance mechanisms need to be introduced in the proposed algorithm, considerably reducing the computational complexity compared to many existing multiobjective EAs for many-objective optimization. Experimental results on 16 test problems demonstrate the competitiveness of the proposed algorithm in terms of both solution quality and computational efficiency.","Sociology,
Pareto optimization,
Convergence,
Evolutionary computation,
Measurement"
Top Tension Control of a Flexible Marine Riser by Using Integral-Barrier Lyapunov Function,"This paper presents a boundary controller for a flexible marine riser to suppress the riser's vibration with a top tension constraint. The flexible marine riser is described by a distributed parameter system with a partial differential equation and four ordinary differential equations. The boundary controller is designed at the top boundary of the riser based on an integral-barrier Lyapunov function to suppress the riser's tension at top. Adaptive control is designed when the system parametric uncertainty exists. With the proposed robust adaptive boundary control, uniformed boundedness under the ocean disturbance can be achieved. Stability analysis of the closed-loop system is given using the Lyapunov stability theory. Simulation results illustrate the effectiveness of the proposed boundary controller with top tension constraint.","Vibrations,
Lyapunov methods,
Educational institutions,
Distributed parameter systems,
Adaptive control,
Oceans"
Consistency-Driven Automatic Methodology to Set Interval Numerical Scales of 2-Tuple Linguistic Term Sets and Its Use in the Linguistic GDM With Preference Relation,"The 2-tuple linguistic modeling is a popular tool for computing with words in decision making. In order to deal with the linguistic term sets that are not uniformly and symmetrically distributed, the numerical scale model has been developed to generalize the 2-tuple linguistic modeling. In the numerical scale model, the key task of the 2-tuple based models is the definition of a numerical scale function that establishes a one to one mapping between the linguistic information and numerical values. In this paper, we propose a consistency-driven automatic methodology to set interval numerical scales of 2-tuple linguistic term sets in the decision making problems with linguistic preference relations. This consistency-driven methodology is based on a natural premise regarding the consistency of preference relations. If linguistic preference relations provided by experts are of acceptable consistency, the corresponding transformed numerical preference relations by the established interval numerical scale are also consistent. Compared with the existing approach based on canonical characteristic values, the consistency-driven methodology provides a new way to set the interval numerical scale without the need of the semantics defined by interval type-2 fuzzy sets. Meanwhile, interval multiplicative preference relations are used in the pairwise comparisons method and the presented theory can be utilized in the pairwise comparisons method as it provides a novel approach to automatic construct interval multiplicative preference relations. Finally, we present the framework for the use of the consistency-driven automatic methodology in linguistic group decision making problems and two numerical examples are given to illustrate the feasibility and validity of this proposal.","Pragmatics,
Numerical models,
Computational modeling,
Decision making,
Frequency selective surfaces,
Indexes,
Semantics"
Saliency detection by multi-context deep learning,"Low-level saliency cues or priors do not produce good enough saliency detection results especially when the salient object presents in a low-contrast background with confusing visual appearance. This issue raises a serious problem for conventional approaches. In this paper, we tackle this problem by proposing a multi-context deep learning framework for salient object detection. We employ deep Convolutional Neural Networks to model saliency of objects in images. Global context and local context are both taken into account, and are jointly modeled in a unified multi-context deep learning framework. To provide a better initialization for training the deep neural networks, we investigate different pre-training strategies, and a task-specific pre-training scheme is designed to make the multi-context modeling suited for saliency detection. Furthermore, recently proposed contemporary deep models in the ImageNet Image Classification Challenge are tested, and their effectiveness in saliency detection are investigated. Our approach is extensively evaluated on five public datasets, and experimental results show significant and consistent improvements over the state-of-the-art methods.","Context,
Context modeling,
Predictive models,
Training,
Visualization,
Object detection,
Machine learning"
Approximation-Based Adaptive Tracking Control for MIMO Nonlinear Systems With Input Saturation,"In this paper, an approximation-based adaptive tracking control approach is proposed for a class of multiinput multioutput nonlinear systems. Based on the method of neural network, a novel adaptive controller is designed via backstepping design process. Furthermore, by introducing Nussbaum function, the issue of unknown control directions is handled. In the backstepping design process, the dynamic surface control technique is employed to avoid differentiating certain nonlinear functions repeatedly. Moreover, in order to reduce the number of adaptation laws, we do not use the neural networks to directly approximate the unknown nonlinear functions but the desired control signals. Finally, we provide two examples to illustrate the effectiveness of the proposed approach.","Nonlinear systems,
Adaptive systems,
Neural networks,
MIMO,
Approximation methods,
Backstepping,
Educational institutions"
Matching theory for future wireless networks: fundamentals and applications,"The emergence of novel wireless networking paradigms such as small cell and cognitive radio networks has forever transformed the way in which wireless systems are operated. In particular, the need for self-organizing solutions to manage the scarce spectral resources has become a prevalent theme in many emerging wireless systems. In this article, the first comprehensive tutorial on the use of matching theory, a Nobel Prize winning framework, for resource management in wireless networks is developed. To cater for the unique features of emerging wireless networks, a novel, wireless-oriented classification of matching theory is proposed. Then the key solution concepts and algorithmic implementations of this framework are exposed. The developed concepts are applied in three important wireless networking areas in order to demonstrate the usefulness of this analytical tool. Results show how matching theory can effectively improve the performance of resource allocation in all three applications discussed.","Resource management,
Wireless networks,
Algorithm design and analysis,
Cellular networks,
Cognitive radio,
Interference"
Learning Compact Binary Face Descriptor for Face Recognition,"Binary feature descriptors such as local binary patterns (LBP) and its variations have been widely used in many face recognition systems due to their excellent robustness and strong discriminative power. However, most existing binary face descriptors are hand-crafted, which require strong prior knowledge to engineer them by hand. In this paper, we propose a compact binary face descriptor (CBFD) feature learning method for face representation and recognition. Given each face image, we first extract pixel difference vectors (PDVs) in local patches by computing the difference between each pixel and its neighboring pixels. Then, we learn a feature mapping to project these pixel difference vectors into low-dimensional binary vectors in an unsupervised manner, where 1) the variance of all binary codes in the training set is maximized, 2) the loss between the original real-valued codes and the learned binary codes is minimized, and 3) binary codes evenly distribute at each learned bin, so that the redundancy information in PDVs is removed and compact binary codes are obtained. Lastly, we cluster and pool these binary codes into a histogram feature as the final representation for each face image. Moreover, we propose a coupled CBFD (C-CBFD) method by reducing the modality gap of heterogeneous faces at the feature level to make our method applicable to heterogeneous face recognition. Extensive experimental results on five widely used face datasets show that our methods outperform state-of-the-art face descriptors.","Face,
Binary codes,
Vectors,
Face recognition,
Feature extraction,
Learning systems,
Training"
A Regression Approach to Speech Enhancement Based on Deep Neural Networks,"In contrast to the conventional minimum mean square error (MMSE)-based noise reduction techniques, we propose a supervised method to enhance speech by means of finding a mapping function between noisy and clean speech signals based on deep neural networks (DNNs). In order to be able to handle a wide range of additive noises in real-world situations, a large training set that encompasses many possible combinations of speech and noise types, is first designed. A DNN architecture is then employed as a nonlinear regression function to ensure a powerful modeling capability. Several techniques have also been proposed to improve the DNN-based speech enhancement system, including global variance equalization to alleviate the over-smoothing problem of the regression model, and the dropout and noise-aware training strategies to further improve the generalization capability of DNNs to unseen noise conditions. Experimental results demonstrate that the proposed framework can achieve significant improvements in both objective and subjective measures over the conventional MMSE based technique. It is also interesting to observe that the proposed DNN approach can well suppress highly nonstationary noise, which is tough to handle in general. Furthermore, the resulting DNN model, trained with artificial synthesized data, is also effective in dealing with noisy speech data recorded in real-world scenarios without the generation of the annoying musical artifact commonly observed in conventional enhancement methods.","Speech,
Noise,
Speech enhancement,
Training,
Noise measurement,
IEEE transactions"
Local Receptive Fields Based Extreme Learning Machine,"Extreme learning machine (ELM), which was originally proposed for ""generalized"" single-hidden layer feedforward neural networks (SLFNs), provides efficient unified learning solutions for the applications of feature learning, clustering, regression and classification. Different from the common understanding and tenet that hidden neurons of neural networks need to be iteratively adjusted during training stage, ELM theories show that hidden neurons are important but need not be iteratively tuned. In fact, all the parameters of hidden nodes can be independent of training samples and randomly generated according to any continuous probability distribution. And the obtained ELM networks satisfy universal approximation and classification capability. The fully connected ELM architecture has been extensively studied. However, ELM with local connections has not attracted much research attention yet. This paper studies the general architecture of locally connected ELM, showing that: 1) ELM theories are naturally valid for local connections, thus introducing local receptive fields to the input layer; 2) each hidden node in ELM can be a combination of several hidden nodes (a subnetwork), which is also consistent with ELM theories. ELM theories may shed a light on the research of different local receptive fields including true biological receptive fields of which the exact shapes and formula may be unknown to human beings. As a specific example of such general architectures, random convolutional nodes and a pooling structure are implemented in this paper. Experimental results on the NORB dataset, a benchmark for object recognition, show that compared with conventional deep learning solutions, the proposed local receptive fields based ELM (ELM-LRF) reduces the error rate from 6.5% to 2.7% and increases the learning speed up to 200 times.","Learning systems,
Feedforward neural networks,
Neural networks,
Probability distribution,
Approximation methods,
Training,
Regression analysis,
Feature extraction,
Network architecture,
Iterative methods"
Learning to Rank Using User Clicks and Visual Features for Image Retrieval,"The inconsistency between textual features and visual contents can cause poor image search results. To solve this problem, click features, which are more reliable than textual information in justifying the relevance between a query and clicked images, are adopted in image ranking model. However, the existing ranking model cannot integrate visual features, which are efficient in refining the click-based search results. In this paper, we propose a novel ranking model based on the learning to rank framework. Visual features and click features are simultaneously utilized to obtain the ranking model. Specifically, the proposed approach is based on large margin structured output learning and the visual consistency is integrated with the click features through a hypergraph regularizer term. In accordance with the fast alternating linearization method, we design a novel algorithm to optimize the objective function. This algorithm alternately minimizes two different approximations of the original objective function by keeping one function unchanged and linearizing the other. We conduct experiments on a large-scale dataset collected from the Microsoft Bing image search engine, and the results demonstrate that the proposed learning to rank models based on visual features and user clicks outperforms state-of-the-art algorithms.","Visualization,
Linear programming,
Feature extraction,
Training,
Laplace equations,
Approximation algorithms,
Search engines"
Age and gender classification using convolutional neural networks,"Automatic age and gender classification has become relevant to an increasing amount of applications, particularly since the rise of social platforms and social media. Nevertheless, performance of existing methods on real-world images is still significantly lacking, especially when compared to the tremendous leaps in performance recently reported for the related task of face recognition. In this paper we show that by learning representations through the use of deep-convolutional neural networks (CNN), a significant increase in performance can be obtained on these tasks. To this end, we propose a simple convolutional net architecture that can be used even when the amount of learning data is limited. We evaluate our method on the recent Adience benchmark for age and gender estimation and show it to dramatically outperform current state-of-the-art methods.","Face,
Benchmark testing,
Training,
Estimation,
Face recognition,
Computer architecture,
Neurons"
"Automatic Analysis of Facial Affect: A Survey of Registration, Representation, and Recognition","Automatic affect analysis has attracted great interest in various contexts including the recognition of action units and basic or non-basic emotions. In spite of major efforts, there are several open questions on what the important cues to interpret facial expressions are and how to encode them. In this paper, we review the progress across a range of affect recognition applications to shed light on these fundamental questions. We analyse the state-of-the-art solutions by decomposing their pipelines into fundamental components, namely face registration, representation, dimensionality reduction and recognition. We discuss the role of these components and highlight the models and new trends that are followed in their design. Moreover, we provide a comprehensive analysis of facial representations by uncovering their advantages and limitations; we elaborate on the type of information they encode and discuss how they deal with the key challenges of illumination variations, registration errors, head-pose variations, occlusions, and identity bias. This survey allows us to identify open issues and to define future directions for designing real-world affect recognition systems.","Face,
Histograms,
Face recognition,
Shape,
Lighting,
Training,
Emotion recognition"
A Double-Sided LCC Compensation Network and Its Tuning Method for Wireless Power Transfer,"This paper proposes a double-sided LCC compensation network and its tuning method for wireless power transfer (WPT). With the proposed topology and its tuning method, the resonant frequency is irrelevant with the coupling coefficient between the two coils and is also independent of the load condition, which means that the system can work at a constant switching frequency. Analysis in frequency domain is given to show the characteristics of the proposed method. We also propose a method to tune the network to realize zero voltage switching (ZVS) for the Primary-side switches. Simulation and experimental results verified analysis and validity of the proposed compensation network and the tuning method. A wireless charging system with output power of up to 7.7 kW for electric vehicles was built, and 96% efficiency from dc power source to battery load is achieved.","Coils,
Inductance,
Resonant frequency,
Capacitors,
Couplings,
Zero voltage switching,
Topology"
A Feature-Enriched Completely Blind Image Quality Evaluator,"Existing blind image quality assessment (BIQA) methods are mostly opinion-aware. They learn regression models from training images with associated human subjective scores to predict the perceptual quality of test images. Such opinion-aware methods, however, require a large amount of training samples with associated human subjective scores and of a variety of distortion types. The BIQA models learned by opinion-aware methods often have weak generalization capability, hereby limiting their usability in practice. By comparison, opinion-unaware methods do not need human subjective scores for training, and thus have greater potential for good generalization capability. Unfortunately, thus far no opinion-unaware BIQA method has shown consistently better quality prediction accuracy than the opinion-aware methods. Here, we aim to develop an opinion-unaware BIQA method that can compete with, and perhaps outperform, the existing opinion-aware methods. By integrating the features of natural image statistics derived from multiple cues, we learn a multivariate Gaussian model of image patches from a collection of pristine natural images. Using the learned multivariate Gaussian model, a Bhattacharyya-like distance is used to measure the quality of each image patch, and then an overall quality score is obtained by average pooling. The proposed BIQA method does not need any distorted sample images nor subjective quality scores for training, yet extensive experiments demonstrate its superior quality-prediction performance to the state-of-the-art opinion-aware BIQA methods. The MATLAB source code of our algorithm is publicly available at www.comp.polyu.edu.hk/~cslzhang/IQA/ILNIQE/ILNIQE.htm.",
Anonymous Two-Factor Authentication in Distributed Systems: Certain Goals Are Beyond Attainment,"Despite two decades of intensive research, it remains a challenge to design a practical anonymous two-factor authentication scheme, for the designers are confronted with an impressive list of security requirements (e.g., resistance to smart card loss attack) and desirable attributes (e.g., local password update). Numerous solutions have been proposed, yet most of them are shortly found either unable to satisfy some critical security requirements or short of a few important features. To overcome this unsatisfactory situation, researchers often work around it in hopes of a new proposal (but no one has succeeded so far), while paying little attention to the fundamental question: whether or not there are inherent limitations that prevent us from designing an “ideal” scheme that satisfies all the desirable goals? In this work, we aim to provide a definite answer to this question. We first revisit two foremost proposals, i.e. Tsai et al.'s scheme and Li's scheme, revealing some subtleties and challenges in designing such schemes. Then, we systematically explore the inherent conflicts and unavoidable trade-offs among the design criteria. Our results indicate that, under the current widely accepted adversarial model, certain goals are beyond attainment. This also suggests a negative answer to the open problem left by Huang et al. in 2014. To the best of knowledge, the present study makes the first step towards understanding the underlying evaluation metric for anonymous two-factor authentication, which we believe will facilitate better design of anonymous two-factor protocols that offer acceptable trade-offs among usability, security and privacy.","Smart cards,
Authentication,
Servers,
Protocols,
Resistance,
Privacy"
Study and Handling Methods of Power IGBT Module Failures in Power Electronic Converter Systems,"Power electronics plays an important role in a wide range of applications in order to achieve high efficiency and performance. Increasing efforts are being made to improve the reliability of power electronics systems to ensure compliance with more stringent constraints on cost, safety, and availability in different applications. This paper presents an overview of the major failure mechanisms of IGBT modules and their handling methods in power converter systems improving reliability. The major failure mechanisms of IGBT modules are presented first, and methods for predicting lifetime and estimating the junction temperature of IGBT modules are then discussed. Subsequently, different methods for detecting open- and short-circuit faults are presented. Finally, fault-tolerant strategies for improving the reliability of power electronic systems under field operation are explained and compared in terms of performance and cost.","Insulated gate bipolar transistors,
Reliability,
Silicon,
Soldering,
Electronic packaging thermal management,
Failure analysis"
Event Oriented Dictionary Learning for Complex Event Detection,"Complex event detection is a retrieval task with the goal of finding videos of a particular event in a large-scale unconstrained Internet video archive, given example videos and text descriptions. Nowadays, different multimodal fusion schemes of low-level and high-level features are extensively investigated and evaluated for the complex event detection task. However, how to effectively select the high-level semantic meaningful concepts from a large pool to assist complex event detection is rarely studied in the literature. In this paper, we propose a novel strategy to automatically select semantic meaningful concepts for the event detection task based on both the events-kit text descriptions and the concepts high-level feature descriptions. Moreover, we introduce a novel event oriented dictionary representation based on the selected semantic concepts. Toward this goal, we leverage training images (frames) of selected concepts from the semantic indexing dataset with a pool of 346 concepts, into a novel supervised multitask ℓp-norm dictionary learning framework. Extensive experimental results on TRECVID multimedia event detection dataset demonstrate the efficacy of our proposed method.",
Learning Multiple Linear Mappings for Efficient Single Image Super-Resolution,"Example learning-based superresolution (SR) algorithms show promise for restoring a high-resolution (HR) image from a single low-resolution (LR) input. The most popular approaches, however, are either time- or space-intensive, which limits their practical applications in many resource-limited settings. In this paper, we propose a novel computationally efficient single image SR method that learns multiple linear mappings (MLM) to directly transform LR feature subspaces into HR subspaces. In particular, we first partition the large nonlinear feature space of LR images into a cluster of linear subspaces. Multiple LR subdictionaries are then learned, followed by inferring the corresponding HR subdictionaries based on the assumption that the LR-HR features share the same representation coefficients. We establish MLM from the input LR features to the desired HR outputs in order to achieve fast yet stable SR recovery. Furthermore, in order to suppress displeasing artifacts generated by the MLM-based method, we apply a fast nonlocal means algorithm to construct a simple yet effective similarity-based regularization term for SR enhancement. Experimental results indicate that our approach is both quantitatively and qualitatively superior to other application-oriented SR methods, while maintaining relatively low time and space complexity.","Image reconstruction,
Vectors,
Dictionaries,
Training,
Feature extraction,
Principal component analysis,
Transforms"
Multimodal Deep Autoencoder for Human Pose Recovery,"Video-based human pose recovery is usually conducted by retrieving relevant poses using image features. In the retrieving process, the mapping between 2D images and 3D poses is assumed to be linear in most of the traditional methods. However, their relationships are inherently non-linear, which limits recovery performance of these methods. In this paper, we propose a novel pose recovery method using non-linear mapping with multi-layered deep neural network. It is based on feature extraction with multimodal fusion and back-propagation deep learning. In multimodal fusion, we construct hypergraph Laplacian with low-rank representation. In this way, we obtain a unified feature description by standard eigen-decomposition of the hypergraph Laplacian matrix. In back-propagation deep learning, we learn a non-linear mapping from 2D images to 3D poses with parameter fine-tuning. The experimental results on three data sets show that the recovery error has been reduced by 20%-25%, which demonstrates the effectiveness of the proposed method.","Three-dimensional displays,
Feature extraction,
Visualization,
Machine learning,
Neural networks,
Hidden Markov models,
Electronic mail"
Bit-Scalable Deep Hashing With Regularized Similarity Learning for Image Retrieval and Person Re-Identification,"Extracting informative image features and learning effective approximate hashing functions are two crucial steps in image retrieval. Conventional methods often study these two steps separately, e.g., learning hash functions from a predefined hand-crafted feature space. Meanwhile, the bit lengths of output hashing codes are preset in the most previous methods, neglecting the significance level of different bits and restricting their practical flexibility. To address these issues, we propose a supervised learning framework to generate compact and bit-scalable hashing codes directly from raw images. We pose hashing learning as a problem of regularized similarity learning. In particular, we organize the training images into a batch of triplet samples, each sample containing two images with the same label and one with a different label. With these triplet samples, we maximize the margin between the matched pairs and the mismatched pairs in the Hamming space. In addition, a regularization term is introduced to enforce the adjacency consistency, i.e., images of similar appearances should have similar codes. The deep convolutional neural network is utilized to train the model in an end-to-end fashion, where discriminative image features and hash functions are simultaneously optimized. Furthermore, each bit of our hashing codes is unequally weighted, so that we can manipulate the code lengths by truncating the insignificant bits. Our framework outperforms state-of-the-arts on public benchmarks of similar image search and also achieves promising results in the application of person re-identification in surveillance. It is also shown that the generated bit-scalable hashing codes well preserve the discriminative powers with shorter code lengths.",
A Fast Single Image Haze Removal Algorithm Using Color Attenuation Prior,"Single image haze removal has been a challenging problem due to its ill-posed nature. In this paper, we propose a simple but powerful color attenuation prior for haze removal from a single input hazy image. By creating a linear model for modeling the scene depth of the hazy image under this novel prior and learning the parameters of the model with a supervised learning method, the depth information can be well recovered. With the depth map of the hazy image, we can easily estimate the transmission and restore the scene radiance via the atmospheric scattering model, and thus effectively remove the haze from a single image. Experimental results show that the proposed approach outperforms state-of-the-art haze removal algorithms in terms of both efficiency and the dehazing effect.",
Ballistocardiography and Seismocardiography: A Review of Recent Advances,"In the past decade, there has been a resurgence in the field of unobtrusive cardiomechanical assessment, through advancing methods for measuring and interpreting ballistocardiogram (BCG) and seismocardiogram (SCG) signals. Novel instrumentation solutions have enabled BCG and SCG measurement outside of clinical settings, in the home, in the field, and even in microgravity. Customized signal processing algorithms have led to reduced measurement noise, clinically relevant feature extraction, and signal modeling. Finally, human subjects physiology studies have been conducted using these novel instruments and signal processing tools with promising results. This paper reviews the recent advances in these areas of modern BCG and SCG research.","Sensors,
Sleep apnea,
Electrocardiography,
Accelerometers,
Heart beat,
Biomedical monitoring"
Hesitant Fuzzy Linguistic VIKOR Method and Its Application in Qualitative Multiple Criteria Decision Making,"The hesitant fuzzy linguistic term set (HFLTS) has turned out to be a powerful and flexible technique in representing decision makers' qualitative assessments in the processes of decision making. The aim of this paper is to develop a method to solve the multicriteria decision making (MCDM) problem within the context of HFLTS in which the criteria conflict with each other. To do so, the concepts of ideal solutions for a HFL-MCDM problem have been introduced. In addition, in order to represent the closeness of one solution to the ideal one, we propose a sort of hesitant fuzzy linguistic measures, such as the hesitant fuzzy linguistic group utility measure, the hesitant fuzzy linguistic individual regret measure, and the hesitant fuzzy linguistic compromise measure. Based on these measures, we develop a hesitant fuzzy linguistic VIKOR (HFL-VIKOR) method, which is motivated by the traditional VIKOR method. The general procedures for the HFL-VIKOR method are given. Some numerical examples are provided to demonstrate the advantages and practicality of our method. Finally, we make some discussions on the advantages of the HFL-VIKOR method, as well as future work.","Pragmatics,
Decision making,
Fuzzy sets,
Computational modeling,
Grammar,
Programming,
Indexes"
Distortion-Aware Concurrent Multipath Transfer for Mobile Video Streaming in Heterogeneous Wireless Networks,"The massive proliferation of wireless infrastructures with complementary characteristics prompts the bandwidth aggregation for Concurrent Multipath Transfer (CMT) over heterogeneous access networks. Stream Control Transmission Protocol (SCTP) is the standard transport-layer solution to enable CMT in multihomed communication environments. However, delivering high-quality streaming video with the existing CMT solutions still remains problematic due to the stringent quality of service (QoS) requirements and path asymmetry in heterogeneous wireless networks. In this paper, we advance the state of the art by introducing video distortion into the decision process of multipath data transfer. The proposed distortion-aware concurrent multipath transfer (CMT-DA) solution includes three phases: 1) per-path status estimation and congestion control; 2) quality-optimal video flow rate allocation; 3) delay and loss controlled data retransmission. The term `flow rate allocation' indicates dynamically picking appropriate access networks and assigning the transmission rates. We analytically formulate the data distribution over multiple communication paths to minimize the end-to-end video distortion and derive the solution based on the utility maximization theory. The performance of the proposed CMT-DA is evaluated through extensive semi-physical emulations in Exata involving H.264 video streaming. Experimental results show that CMT-DA outperforms the reference schemes in terms of video peak signal-to-noise ratio (PSNR), goodput, and inter-packet delay.","Streaming media,
Delays,
Nonlinear distortion,
Wireless networks,
Bandwidth,
Mobile computing,
Resource management"
AIWAC: affective interaction through wearable computing and cloud technology,"To reduce the heavy burden from rapidly growing demands of healthcare service, wearable computing-assisted healthcare has been proposed for health monitoring and remote medical care. Although the provisioning of healthcare services can be significantly enhanced via wearable-enabled technologies, great challenges arise due to the lack of a human-centric mechanism for affective interaction. In this article, we propose a novel architecture, Affective Interaction through Wearable Computing and Cloud Technology (AIWAC), which includes three components: collaborative data collection via wearable devices, enhanced sentiment analysis and forecasting models, and controllable affective interactions. Based on the proposed architecture, we present our AIWAC testbed, design a practical mechanism for wearable computing-based emotional interaction, and discuss its open problems, which inspire potential research as a new direction.","Biomedical monitoring,
Medical services,
Sentiment analysis,
Psychology,
Physiology,
Social network services,
Data models,
Wearable computers"
Neural-Based Adaptive Output-Feedback Control for a Class of Nonstrict-Feedback Stochastic Nonlinear Systems,"In this paper, we consider the problem of observer-based adaptive neural output-feedback control for a class of stochastic nonlinear systems with nonstrict-feedback structure. To overcome the design difficulty from the nonstrict-feedback structure, a variable separation approach is introduced by using the monotonically increasing property of system bounding functions. On the basis of the state observer, and by combining the adaptive backstepping technique with radial basis function neural networks' universal approximation capability, an adaptive neural output feedback control algorithm is presented. It is shown that the proposed controller can guarantee that all the signals in the closed-loop system are semi-globally uniformly ultimately bounded in the sense of mean quartic value. Simulation results are provided to show the effectiveness of the proposed control scheme.",
Dynamic Surface Control Using Neural Networks for a Class of Uncertain Nonlinear Systems With Input Saturation,"In this paper, a dynamic surface control (DSC) scheme is proposed for a class of uncertain strict-feedback nonlinear systems in the presence of input saturation and unknown external disturbance. The radial basis function neural network (RBFNN) is employed to approximate the unknown system function. To efficiently tackle the unknown external disturbance, a nonlinear disturbance observer (NDO) is developed. The developed NDO can relax the known boundary requirement of the unknown disturbance and can guarantee the disturbance estimation error converge to a bounded compact set. Using NDO and RBFNN, the DSC scheme is developed for uncertain nonlinear systems based on a backstepping method. Using a DSC technique, the problem of explosion of complexity inherent in the conventional backstepping method is avoided, which is specially important for designs using neural network approximations. Under the proposed DSC scheme, the ultimately bounded convergence of all closed-loop signals is guaranteed via Lyapunov analysis. Simulation results are given to show the effectiveness of the proposed DSC design using NDO and RBFNN.",
Crowded Scene Analysis: A Survey,"Automated scene analysis has been a topic of great interest in computer vision and cognitive science. Recently, with the growth of crowd phenomena in the real world, crowded scene analysis has attracted much attention. However, the visual occlusions and ambiguities in crowded scenes, as well as the complex behaviors and scene semantics, make the analysis a challenging task. In the past few years, an increasing number of works on the crowded scene analysis have been reported, which covered different aspects including crowd motion pattern learning, crowd behavior and activity analyses, and anomaly detection in crowds. This paper surveys the state-of-the-art techniques on this topic. We first provide the background knowledge and the available features related to crowded scenes. Then, existing models, popular algorithms, evaluation protocols, and system performance are provided corresponding to different aspects of the crowded scene analysis. We also outline the available datasets for performance evaluation. Finally, some research problems and promising future directions are presented with discussions.","Tracking,
Image analysis,
Analytical models,
Histograms,
Feature extraction,
Visualization,
Dynamics"
Existence and Uniform Stability Analysis of Fractional-Order Complex-Valued Neural Networks With Time Delays,"This paper deals with the problem of existence and uniform stability analysis of fractional-order complex-valued neural networks with constant time delays. Complex-valued recurrent neural networks is an extension of real-valued recurrent neural networks that includes complex-valued states, connection weights, or activation functions. This paper explains sufficient condition for the existence and uniform stability analysis of such networks. Three numerical simulations are delineated to substantiate the effectiveness of the theoretical results.","Biological neural networks,
Stability analysis,
Delay effects,
Recurrent neural networks,
Artificial neural networks,
Mathematics"
ICDAR 2015 competition on Robust Reading,"Results of the ICDAR 2015 Robust Reading Competition are presented. A new Challenge 4 on Incidental Scene Text has been added to the Challenges on Born-Digital Images, Focused Scene Images and Video Text. Challenge 4 is run on a newly acquired dataset of 1,670 images evaluating Text Localisation, Word Recognition and End-to-End pipelines. In addition, the dataset for Challenge 3 on Video Text has been substantially updated with more video sequences and more accurate ground truth data. Finally, tasks assessing End-to-End system performance have been introduced to all Challenges. The competition took place in the first quarter of 2015, and received a total of 44 submissions. Only the tasks newly introduced in 2015 are reported on. The datasets, the ground truth specification and the evaluation protocols are presented together with the results and a brief summary of the participating methods.","Yttrium,
IP networks"
Structure and Computationally Efficient Simulation-Driven Design of Compact UWB Monopole Antenna,"In this letter, a structure of a small ultra-wideband (UWB) monopole antenna, its design optimization procedure as well as experimental validation are presented. According to our approach, antenna compactness is achieved by means of a meander line for current path enlargement as well as the two parameterized slits providing additional degrees of freedom that help to ensure good impedance matching. For the sake of reliability, the antenna design process (simultaneous adjustment of multiple geometry parameters) is carried out using high-fidelity EM analyses. Surrogate-based optimization involving an auxiliary coarse-discretization EM model it utilized to accomplish the design in practical timeframe. Penalty function approach allows us to reduce the antenna footprint (to only 15.8 × 22 mm2) while maintaining acceptable reflection in the UWB frequency range. Experimental validation of the design is also provided.","Optimization,
Radio frequency,
Ultra wideband antennas,
Reflection,
Connectors,
Reflector antennas"
A Double-Sided LCLC-Compensated Capacitive Power Transfer System for Electric Vehicle Charging,"A double-sided LCLC-compensated capacitive power transfer (CPT) system is proposed for the electric vehicle charging application. Two pairs of metal plates are utilized to form two coupling capacitors to transfer power wirelessly. The LCLC-compensated structure can dramatically reduce the voltage stress on the coupling capacitors and maintain unity power factor at both the input and output. A 2.4-kW CPT system is designed with four 610-mm × 610-mm copper plates and an air gap distance of 150 mm. The experimental prototype reaches a dc-dc efficiency of 90.8% at 2.4-kW output power. At 300-mm misalignment case, the output power drops to 2.1 kW with 90.7% efficiency. With a 300-mm air gap distance, the output power drops to 1.6 kW with 89.1% efficiency.",
Stability Criteria for Recurrent Neural Networks With Time-Varying Delay Based on Secondary Delay Partitioning Method,"A secondary delay partitioning method is proposed to study the stability problem for a class of recurrent neural networks (RNNs) with time-varying delay. The total interval of the time-varying delay is first divided into two parts, and then each part is further divided into several subintervals. To deal with the state variables associated with these subintervals, an extended reciprocal convex combination approach and a double integral term with variable upper and lower limits of integral as a Lyapunov functional are proposed, which help to obtain the stability criterion. The main feature of the proposed result is more effective for the RNNs with fast time-varying delay. A numerical example is used to show the effectiveness of the proposed stability result.","Delays,
Stability criteria,
Numerical stability,
Delay effects,
Linear matrix inequalities,
Upper bound,
Learning systems"
Fault Analysis-Based Logic Encryption,"Globalization of the integrated circuit (IC) design industry is making it easy for rogue elements in the supply chain to pirate ICs, overbuild ICs, and insert hardware Trojans. Due to supply chain attacks, the IC industry is losing approximately $4 billion annually. One way to protect ICs from these attacks is to encrypt the design by inserting additional gates such that correct outputs are produced only when specific inputs are applied to these gates. The state-of-the-art logic encryption technique inserts gates randomly into the design, but does not necessarily ensure that wrong keys corrupt the outputs. Our technique ensures that wrong keys corrupt the outputs. We relate logic encryption to fault propagation analysis in IC testing and develop a fault analysis-based logic encryption technique. This technique enables a designer to controllably corrupt the outputs. Specifically, to maximize the ambiguity for an attacker, this technique targets 50% Hamming distance between the correct and wrong outputs (ideal case) when a wrong key is applied. Furthermore, this 50% Hamming distance target is achieved using a smaller number of additional gates when compared to random logic encryption.",
Video Tracking Using Learned Hierarchical Features,"In this paper, we propose an approach to learn hierarchical features for visual object tracking. First, we offline learn features robust to diverse motion patterns from auxiliary video sequences. The hierarchical features are learned via a two-layer convolutional neural network. Embedding the temporal slowness constraint in the stacked architecture makes the learned features robust to complicated motion transformations, which is important for visual object tracking. Then, given a target video sequence, we propose a domain adaptation module to online adapt the pre-learned features according to the specific target object. The adaptation is conducted in both layers of the deep feature learning module so as to include appearance information of the specific target object. As a result, the learned hierarchical features can be robust to both complicated motion transformations and appearance changes of target objects. We integrate our feature learning algorithm into three tracking methods. Experimental results demonstrate that significant improvement can be achieved using our learned hierarchical features, especially on video sequences with complicated motion transformations.",
Linear Codes From Some 2-Designs,"A classical method of constructing a linear code over GF(q) with a t-design is to use the incidence matrix of the t-design as a generator matrix over GF(q) of the code. This approach has been extensively investigated in the literature. In this paper, a different method of constructing linear codes using specific classes of 2-designs is studied, and linear codes with a few weights are obtained from almost difference sets, difference sets, and a type of 2-designs associated to semibent functions. Two families of the codes obtained in this paper are optimal. The linear codes presented in this paper have applications in secret sharing and authentication schemes, in addition to their applications in consumer electronics, communication and data storage systems. A coding-theory approach to the characterization of highly nonlinear Boolean functions is presented.","Linear codes,
Boolean functions,
Binary codes,
Additives,
Hamming weight,
Cryptography,
Authentication"
Receding Horizon Stabilization and Disturbance Attenuation for Neural Networks With Time-Varying Delay,"This paper is concerned with the problems of receding horizon stabilization and disturbance attenuation for neural networks with time-varying delay. New delay-dependent conditions on the terminal weighting matrices of a new finite horizon cost functional for receding horizon stabilization are established for neural networks with time-varying or time-invariant delays using single- and double-integral Wirtinger-type inequalities. Based on the results, delay-dependent sufficient conditions for the receding horizon disturbance attenuation are given to guarantee the infinite horizon H∞ performance of neural networks with time-varying or time-invariant delays. Three numerical examples are provided to illustrate the effectiveness of the proposed approach.","Biological neural networks,
Delays,
Attenuation,
Symmetric matrices,
Delay effects,
Linear matrix inequalities"
"Recent Advances in Underlay Heterogeneous Networks: Interference Control, Resource Allocation, and Self-Organization","By deploying additional low power nodes (LPNs) within the coverage area of traditional high power nodes (HPNs) and bringing them closer to users, underlay heterogeneous networks (HetNets) can significantly boost the overall spectral efficiency (SE) and energy efficiency (EE) through a full spatial resource reuse. Considering that the severe intra-tier interference among dense LPNs and inter-tier interference between LPNs and HPNs are challenging the successful rollout and commercial operations of underlay HetNets, a great emphasis is given towards advanced techniques that take interference control, radio resource allocation, and self-organization into account to enhance both SE and EE in this paper. The interference control techniques presented in this paper are classified as the spatial interference coordination at the transmitter and the interference cancelation at the receiver. For the radio resource allocation, the multi-dimensional optimization, cross-layer optimization, and cooperative radio resource management are comprehensively summarized. The self-configuration, self-optimization, and self-healing techniques for the self-organized underlay HetNets are surveyed. Furthermore, this paper outlines the potential open issues for underlay HetNets to improve SE and EE when combining with energy harvesting and cloud computing.",
Magnetic Particle Imaging With Tailored Iron Oxide Nanoparticle Tracers,"Magnetic particle imaging (MPI) shows promise for medical imaging, particularly in angiography of patients with chronic kidney disease. As the first biomedical imaging technique that truly depends on nanoscale materials properties, MPI requires highly optimized magnetic nanoparticle tracers to generate quality images. Until now, researchers have relied on tracers optimized for MRI T2*-weighted imaging that are sub-optimal for MPI. Here, we describe new tracers tailored to MPI's unique physics, synthesized using an organic-phase process and functionalized to ensure biocompatibility and adequate in vivo circulation time. Tailored tracers showed up to 3 × greater signal-to-noise ratio and better spatial resolution than existing commercial tracers in MPI images of phantoms.","Magnetic field measurement,
Image reconstruction,
Phantoms,
Magnetic cores,
Magnetic resonance imaging,
Iron"
Modeling and Vibration Control for a Nonlinear Moving String With Output Constraint,"In this paper, boundary control laws are developed to stabilize the transverse vibration for a nonlinear vertically moving string system. The control system is considered with varying length, varying speed, and the constrained boundary output. Based on the integral-barrier Lyapunov function, the exponential stability is proved with the proposed control without consideration of the disturbance. When the external boundary disturbance is taken into account, the disturbance observer is designed to eliminate its effect. The vibration is regulated and the boundary output always remains in the constrained space by appropriately choosing the control parameters. The control design and the stability analysis are based on the original infinite-dimensional dynamic equations. Extensive numerical examples illustrate the performance of the control system.","Vibrations,
Payloads,
PD control,
Mathematical model,
Control design,
Lyapunov methods,
Force"
Two_Arch2: An Improved Two-Archive Algorithm for Many-Objective Optimization,"Many-objective optimization problems (ManyOPs) refer, usually, to those multiobjective problems (MOPs) with more than three objectives. Their large numbers of objectives pose challenges to multiobjective evolutionary algorithms (MOEAs) in terms of convergence, diversity, and complexity. Most existing MOEAs can only perform well in one of those three aspects. In view of this, we aim to design a more balanced MOEA on ManyOPs in all three aspects at the same time. Among the existing MOEAs, the two-archive algorithm (Two_Arch) is a low-complexity algorithm with two archives focusing on convergence and diversity separately. Inspired by the idea of Two_Arch, we propose a significantly improved two-archive algorithm (i.e., Two_Arch2) for ManyOPs in this paper. In our Two_Arch2, we assign different selection principles (indicator-based and Pareto-based) to the two archives. In addition, we design a new Lp-norm-based (p <; 1) diversity maintenance scheme for ManyOPs in Two_Arch2. In order to evaluate the performance of Two_Arch2 on ManyOPs, we have compared it with several MOEAs on a wide range of benchmark problems with different numbers of objectives. The experimental results show that Two_Arch2 can cope with ManyOPs (up to 20 objectives) with satisfactory convergence, diversity, and complexity.",
No-Reference Image Sharpness Assessment in Autoregressive Parameter Space,"In this paper, we propose a new no-reference (NR)/ blind sharpness metric in the autoregressive (AR) parameter space. Our model is established via the analysis of AR model parameters, first calculating the energy- and contrast-differences in the locally estimated AR coefficients in a pointwise way, and then quantifying the image sharpness with percentile pooling to predict the overall score. In addition to the luminance domain, we further consider the inevitable effect of color information on visual perception to sharpness and thereby extend the above model to the widely used YIQ color space. Validation of our technique is conducted on the subsets with blurring artifacts from four large-scale image databases (LIVE, TID2008, CSIQ, and TID2013). Experimental results confirm the superiority and efficiency of our method over existing NR algorithms, the state-of-the-art blind sharpness/blurriness estimators, and classical full-reference quality evaluators. Furthermore, the proposed metric can be also extended to stereoscopic images based on binocular rivalry, and attains remarkably high performance on LIVE3D-I and LIVE3D-II databases.","Measurement,
Computational modeling,
Databases,
Visualization,
Brain modeling,
Image color analysis,
Image edge detection"
Deep Neural Network Approaches to Speaker and Language Recognition,The impressive gains in performance obtained using deep neural networks (DNNs) for automatic speech recognition (ASR) have motivated the application of DNNs to other speech technologies such as speaker recognition (SR) and language recognition (LR). Prior work has shown performance gains for separate SR and LR tasks using DNNs for direct classification or for feature extraction. In this work we present the application of single DNN for both SR and LR using the 2013 Domain Adaptation Challenge speaker recognition (DAC13) and the NIST 2011 language recognition evaluation (LRE11) benchmarks. Using a single DNN trained for ASR on Switchboard data we demonstrate large gains on performance in both benchmarks: a 55% reduction in EER for the DAC13 out-of-domain condition and a 48% reduction in Cavg on the LRE11 30 s test condition. It is also shown that further gains are possible using score or feature fusion leading to the possibility of a single i-vector extractor producing state-of-the-art SR and LR performance.,
Torque-Ripple Minimization and Fast Dynamic Scheme for Torque Predictive Control of Permanent-Magnet Synchronous Motors,"This paper proposes a simple and effective method to reduce torque ripples for the torque predictive control (TPC) of permanent-magnet synchronous motors (PMSMs). The conventional TPC analyzes the relationship among the electrical torque, stator flux, and stator voltage using the magnitude of the stator voltage vector of PMSMs to obtain the angle of the reference voltage vector and accurately control the torque. In addition, the stator-flux control uses the hysteresis method. However, the voltage vector that can be chosen in an inverter is limited because the conventional TPC fixes the magnitude of the reference voltage vector, and thus, a large torque ripple is generated in the low-speed region. The proposed TPC does not fix but varies the magnitude of the reference voltage vector using both the torque and flux error information. Therefore, it not only has the fast dynamic of a direct torque control but also can reduce effectively the torque ripple. The proposed method is proven by the simulation and experimental results, and the proposed algorithm provides an excellent steady-state response and fast dynamics.","Stators,
Torque,
Vectors,
Voltage control,
Rotors,
Equations,
Synchronous motors"
Project-Out Cascaded Regression with an application to face alignment,"Cascaded regression approaches have been recently shown to achieve state-of-the-art performance for many computer vision tasks. Beyond its connection to boosting, cascaded regression has been interpreted as a learning-based approach to iterative optimization methods like the Newton's method. However, in prior work, the connection to optimization theory is limited only in learning a mapping from image features to problem parameters. In this paper, we consider the problem of facial deformable model fitting using cascaded regression and make the following contributions: (a) We propose regression to learn a sequence of averaged Jacobian and Hessian matrices from data, and from them descent directions in a fashion inspired by Gauss-Newton optimization. (b) We show that the optimization problem in hand has structure and devise a learning strategy for a cascaded regression approach that takes the problem structure into account. By doing so, the proposed method learns and employs a sequence of averaged Jacobians and descent directions in a subspace orthogonal to the facial appearance variation; hence, we call it Project-Out Cascaded Regression (PO-CR). (c) Based on the principles of PO-CR, we built a face alignment system that produces remarkably accurate results on the challenging iBUG data set outperforming previously proposed systems by a large margin. Code for our system is available from http://www.cs.nott.ac.uk/~yzt/.",
In Vivo Acoustic Super-Resolution and Super-Resolved Velocity Mapping Using Microbubbles,"The structure of microvasculature cannot be resolved using standard clinical ultrasound (US) imaging frequencies due to the fundamental diffraction limit of US waves. In this work, we use a standard clinical US system to perform in vivo sub-diffraction imaging on a CD1, female mouse aged eight weeks by localizing isolated US signals from microbubbles flowing within the ear microvasculature, and compare our results to optical microscopy. Furthermore, we develop a new technique to map blood velocity at super-resolution by tracking individual bubbles through the vasculature. Resolution is improved from a measured lateral and axial resolution of 112 μm and 94 μm respectively in original US data, to super-resolved images of microvasculature where vessel features as fine as 19 μm are clearly visualized. Velocity maps clearly distinguish opposing flow direction and separated speed distributions in adjacent vessels, thereby enabling further differentiation between vessels otherwise not spatially separated in the image. This technique overcomes the diffraction limit to provide a noninvasive means of imaging the microvasculature at super-resolution, to depths of many centimeters. In the future, this method could noninvasively image pathological or therapeutic changes in the microvasculature at centimeter depths in vivo.",
Vibration Control of a Nonuniform Wind Turbine Tower via Disturbance Observer,"In this paper, the vibration control problem is studied for a wind turbine tower subjected to random wind loads. The tower is modeled as a nonuniform Euler-Bernoulli beam system with distributed parameters by using the Hamilton's principle. The control force is applied at the top boundary of the tower to suppress the vibrations of the tower. Disturbance observer is designed to attenuate the disturbance at the top of the tower. The stability of the whole system is rigorously proved via the Lyapunov analysis and the satisfactory control performance is guaranteed under the proper choice of the design parameters. Numerical results are provided to illustrate that the designed controller is effective in dissipating the vibrations of the tower.",
Reliable Patch Trackers: Robust visual tracking by exploiting reliable patches,"Most modern trackers typically employ a bounding box given in the first frame to track visual objects, where their tracking results are often sensitive to the initialization. In this paper, we propose a new tracking method, Reliable Patch Trackers (RPT), which attempts to identify and exploit the reliable patches that can be tracked effectively through the whole tracking process. Specifically, we present a tracking reliability metric to measure how reliably a patch can be tracked, where a probability model is proposed to estimate the distribution of reliable patches under a sequential Monte Carlo framework. As the reliable patches distributed over the image, we exploit the motion trajectories to distinguish them from the background. Therefore, the visual object can be defined as the clustering of homo-trajectory patches, where a Hough voting-like scheme is employed to estimate the target state. Encouraging experimental results on a large set of sequences showed that the proposed approach is very effective and in comparison to the state-of-the-art trackers. The full source code of our implementation will be publicly available.","Target tracking,
Visualization,
Robustness,
Trajectory,
Monte Carlo methods"
Simultaneous feature learning and hash coding with deep neural networks,"Similarity-preserving hashing is a widely-used method for nearest neighbour search in large-scale image retrieval tasks. For most existing hashing methods, an image is first encoded as a vector of hand-engineering visual features, followed by another separate projection or quantization step that generates binary codes. However, such visual feature vectors may not be optimally compatible with the coding process, thus producing sub-optimal hashing codes. In this paper, we propose a deep architecture for supervised hashing, in which images are mapped into binary codes via carefully designed deep neural networks. The pipeline of the proposed deep architecture consists of three building blocks: 1) a sub-network with a stack of convolution layers to produce the effective intermediate image features; 2) a divide-and-encode module to divide the intermediate image features into multiple branches, each encoded into one hash bit; and 3) a triplet ranking loss designed to characterize that one image is more similar to the second image than to the third one. Extensive evaluations on several benchmark image datasets show that the proposed simultaneous feature learning and hash coding pipeline brings substantial improvements over other state-of-the-art supervised or unsupervised hashing methods.",
Performance Analysis and Optimization for SpMV on GPU Using Probabilistic Modeling,"This paper presents a unique method of performance analysis and optimization for sparse matrix-vector multiplication (SpMV) on GPU. This method has wide adaptability for different types of sparse matrices and is different from existing methods which only adapt to some particular sparse matrices. In addition, our method does not need additional benchmarks to get optimized parameters, which are calculated directly through the probability mass function (PMF). We make the following contributions. (1) We present a PMF to analyze precisely the distribution pattern of non-zero elements in a sparse matrix. The PMF can provide theoretical basis for the compression of a sparse matrix. (2) Compression efficiency of COO, CSR, ELL, and HYB can be analyzed precisely through the PMF, and combined with the hardware parameters of GPU, the performance of SpMV based on COO, CSR, ELL, and HYB can be estimated. Furthermore, the most appropriate format for SpMV can be selected according to estimated value of the performance. Experiments prove that the theoretical estimated values and the tested values have high consistency. (3) For HYB, the optimal segmentation threshold can be found through the PMF to achieve the optimal performance for SpMV. Our performance modeling and analysis are very accurate. The order of magnitude of the estimated speedup and that of the tested speedup for each of the ten tested sparse matrices based on the three formats COO, CSR, and ELL are the same. The percentage of relative difference between an estimated value and a tested value is less than 20 percent for over 80 percent cases. The performance improvement of our algorithm is also effective. The average performance improvement of the optimal solution for HYB is over 15 percent compared with that of the automatic solution provided by CUSPARSE lib.",
Structural Sparse Tracking,"Sparse representation has been applied to visual tracking by finding the best target candidate with minimal reconstruction error by use of target templates. However, most sparse representation based trackers only consider holistic or local representations and do not make full use of the intrinsic structure among and inside target candidates, thereby making the representation less effective when similar objects appear or under occlusion. In this paper, we propose a novel Structural Sparse Tracking (SST) algorithm, which not only exploits the intrinsic relationship among target candidates and their local patches to learn their sparse representations jointly, but also preserves the spatial layout structure among the local patches inside each target candidate. We show that our SST algorithm accommodates most existing sparse trackers with the respective merits. Both qualitative and quantitative evaluations on challenging benchmark image sequences demonstrate that the proposed SST algorithm performs favorably against several state-of-the-art methods.",
Adaptive Output-Feedback Neural Control of Switched Uncertain Nonlinear Systems With Average Dwell Time,"This paper investigates the problem of adaptive neural tracking control via output-feedback for a class of switched uncertain nonlinear systems without the measurements of the system states. The unknown control signals are approximated directly by neural networks. A novel adaptive neural control technique for the problem studied is set up by exploiting the average dwell time method and backstepping. A switched filter and different update laws are designed to reduce the conservativeness caused by adoption of a common observer and a common update law for all subsystems. The proposed controllers of subsystems guarantee that all closed-loop signals remain bounded under a class of switching signals with average dwell time, while the output tracking error converges to a small neighborhood of the origin. As an application of the proposed design method, adaptive output feedback neural tracking controllers for a mass-spring-damper system are constructed.","Switches,
Nonlinear systems,
Adaptive systems,
Backstepping,
Switched systems,
Artificial neural networks"
Is Extreme Learning Machine Feasible? A Theoretical Assessment (Part I),"An extreme learning machine (ELM) is a feedforward neural network (FNN) like learning system whose connections with output neurons are adjustable, while the connections with and within hidden neurons are randomly fixed. Numerous applications have demonstrated the feasibility and high efficiency of ELM-like systems. It has, however, been open if this is true for any general applications. In this two-part paper, we conduct a comprehensive feasibility analysis of ELM. In Part I, we provide an answer to the question by theoretically justifying the following: 1) for some suitable activation functions, such as polynomials, Nadaraya-Watson and sigmoid functions, the ELM-like systems can attain the theoretical generalization bound of the FNNs with all connections adjusted, i.e., they do not degrade the generalization capability of the FNNs even when the connections with and within hidden neurons are randomly fixed; 2) the number of hidden neurons needed for an ELM-like system to achieve the theoretical bound can be estimated; and 3) whenever the activation function is taken as polynomial, the deduced hidden layer output matrix is of full column-rank, therefore the generalized inverse technique can be efficiently applied to yield the solution of an ELM-like system, and, furthermore, for the nonpolynomial case, the Tikhonov regularization can be applied to guarantee the weak regularity while not sacrificing the generalization capability. In Part II, however, we reveal a different aspect of the feasibility of ELM: there also exists some activation functions, which makes the corresponding ELM degrade the generalization capability. The obtained results underlie the feasibility and efficiency of ELM-like systems, and yield various generalizations and improvements of the systems as well.",
Scheduling Precedence Constrained Stochastic Tasks on Heterogeneous Cluster Systems,"Generally, a parallel application consists of precedence constrained stochastic tasks, where task processing times and intertask communication times are random variables following certain probability distributions. Scheduling such precedence constrained stochastic tasks with communication times on a heterogeneous cluster system with processors of different computing capabilities to minimize a parallel application's expected completion time is an important but very difficult problem in parallel and distributed computing. In this paper, we present a model of scheduling stochastic parallel applications on heterogeneous cluster systems. We discuss stochastic scheduling attributes and methods to deal with various random variables in scheduling stochastic tasks. We prove that the expected makespan of scheduling stochastic tasks is greater than or equal to the makespan of scheduling deterministic tasks, where all processing times and communication times are replaced by their expected values. To solve the problem of scheduling precedence constrained stochastic tasks efficiently and effectively, we propose a stochastic dynamic level scheduling (SDLS) algorithm, which is based on stochastic bottom levels and stochastic dynamic levels. Our rigorous performance evaluation results clearly demonstrate that the proposed stochastic task scheduling algorithm significantly outperforms existing algorithms in terms of makespan, speedup, and makespan standard deviation.","Stochastic processes,
Program processors,
Processor scheduling,
Random variables,
Heuristic algorithms,
Dynamic scheduling,
Clustering algorithms"
Tunnel Field-Effect Transistors in 2-D Transition Metal Dichalcogenide Materials,"In this paper, the performance of tunnel field-effect transistors (TFETs) based on 2-D transition metal dichalcogenide (TMD) materials is investigated by atomistic quantum transport simulations. One of the major challenges of TFETs is their low ON-currents. 2-D material-based TFETs can have tight gate control and high electric fields at the tunnel junction, and can, in principle, generate high ON-currents along with a subthreshold swing (SS) smaller than 60 mV/decade. Our simulations reveal that high-performance TMD TFETs not only require good gate control, but also rely on the choice of the right channel material with optimum bandgap, effective mass, and source/drain doping level. Unlike previous works, a full-band atomistic tight-binding method is used self-consistently with 3-D Poisson equation to simulate ballistic quantum transport in these devices. The effect of the choice of the TMD material on the performance of the device and its transfer characteristics are discussed. Moreover, the criteria for high ON-currents are explained with a simple analytic model, showing the related fundamental factors. Finally, the SS and energy delay of these TFETs are compared with conventional CMOS devices.","Photonic band gap,
Doping,
Effective mass,
Logic gates,
Dielectric constant,
Mathematical model,
Threshold voltage"
Characteristic Investigation and Control of a Modular Multilevel Converter-Based HVDC System Under Single-Line-to-Ground Fault Conditions,"This paper presents the analysis and control of a multilevel modular converter (MMC)-based HVDC transmission system under three possible single-line-to-ground fault conditions, with special focus on the investigation of their different fault characteristics. Considering positive-, negative-, and zero-sequence components in both arm voltages and currents, the generalized instantaneous power of a phase unit is derived theoretically according to the equivalent circuit model of the MMC under unbalanced conditions. Based on this model, a novel double-line frequency dc-voltage ripple suppression control is proposed. This controller, together with the negative- and zero-sequence current control, could enhance the overall fault-tolerant capability of the HVDC system without additional cost. To further improve the fault-tolerant capability, the operation performance of the HVDC system with and without single-phase switching is discussed and compared in detail. Simulation results from a three-phase MMC-HVDC system generated with MATLAB/Simulink are provided to support the theoretical analysis and proposed control schemes.",
FERA 2015 - second Facial Expression Recognition and Analysis challenge,"Despite efforts towards evaluation standards in facial expression analysis (e.g. FERA 2011), there is a need for up-to-date standardised evaluation procedures, focusing in particular on current challenges in the field. One of the challenges that is actively being addressed is the automatic estimation of expression intensities. To continue to provide a standardisation platform and to help the field progress beyond its current limitations, the FG 2015 Facial Expression Recognition and Analysis challenge (FERA 2015) will challenge participants to estimate FACS Action Unit (AU) intensity as well as AU occurrence on a common benchmark dataset with reliable manual annotations. Evaluation will be done using a clear and well-defined protocol. In this paper we present the second such challenge in automatic recognition of facial expressions, to be held in conjunction with the 11 IEEE conference on Face and Gesture Recognition, May 2015, in Ljubljana, Slovenia. Three sub-challenges are defined: the detection of AU occurrence, the estimation of AU intensity for pre-segmented data, and fully automatic AU intensity estimation. In this work we outline the evaluation protocol, the data used, and the results of a baseline method for the three sub-challenges.",
Neural Network-Based Adaptive Dynamic Surface Control for Permanent Magnet Synchronous Motors,"This brief considers the problem of neural networks (NNs)-based adaptive dynamic surface control (DSC) for permanent magnet synchronous motors (PMSMs) with parameter uncertainties and load torque disturbance. First, NNs are used to approximate the unknown and nonlinear functions of PMSM drive system and a novel adaptive DSC is constructed to avoid the explosion of complexity in the backstepping design. Next, under the proposed adaptive neural DSC, the number of adaptive parameters required is reduced to only one, and the designed neural controllers structure is much simpler than some existing results in literature, which can guarantee that the tracking error converges to a small neighborhood of the origin. Then, simulations are given to illustrate the effectiveness and potential of the new design technique.","Backstepping,
Artificial neural networks,
Adaptive systems,
Approximation methods,
Explosions,
Complexity theory,
Learning systems"
Synchronization of Nonlinear Coupled Networks via Aperiodically Intermittent Pinning Control,"In this paper, pinning synchronization problem for nonlinear coupled networks is investigated, which can be recurrently connected neural networks, cellular neural networks, Hodgkin-Huxley models, Lorenz chaotic oscillators, and so on. Nodes in the network are assumed to be identical and nodes' dynamical behaviors are described by continuous-time equations. The network topology is undirected and static. At first, the scope of accepted nonlinear coupling functions is defined, and the effect of nonlinear coupling functions on synchronization is carefully discussed. Then, the pinning control technique is used for synchronization, especially the control type is aperiodically intermittent. Some sufficient conditions to guarantee global synchronization are presented. Furthermore, the adaptive approach is also applied on the pinning control, and a centralized adaptive algorithm is designed and its validity is also proved. Finally, several numerical simulations are given to verify the obtained theoretical results.","Synchronization,
Couplings,
Symmetric matrices,
Protocols,
Network topology,
Adaptive systems,
Neural networks"
Face Spoof Detection With Image Distortion Analysis,"Automatic face recognition is now widely used in applications ranging from deduplication of identity to authentication of mobile payment. This popularity of face recognition has raised concerns about face spoof attacks (also known as biometric sensor presentation attacks), where a photo or video of an authorized person's face could be used to gain access to facilities or services. While a number of face spoof detection techniques have been proposed, their generalization ability has not been adequately addressed. We propose an efficient and rather robust face spoof detection algorithm based on image distortion analysis (IDA). Four different features (specular reflection, blurriness, chromatic moment, and color diversity) are extracted to form the IDA feature vector. An ensemble classifier, consisting of multiple SVM classifiers trained for different face spoof attacks (e.g., printed photo and replayed video), is used to distinguish between genuine (live) and spoof faces. The proposed approach is extended to multiframe face spoof detection in videos using a voting-based scheme. We also collect a face spoof database, MSU mobile face spoofing database (MSU MFSD), using two mobile devices (Google Nexus 5 and MacBook Air) with three types of spoof attacks (printed photo, replayed video with iPhone 5S, and replayed video with iPad Air). Experimental results on two public-domain face spoof databases (Idiap REPLAY-ATTACK and CASIA FASD), and the MSU MFSD database show that the proposed approach outperforms the state-of-the-art methods in spoof detection. Our results also highlight the difficulty in separating genuine and spoof faces, especially in cross-database and cross-device scenarios.","Face,
Databases,
Feature extraction,
Face recognition,
Cameras,
Image color analysis,
Testing"
Multimodal deep learning for robust RGB-D object recognition,"Robust object recognition is a crucial ingredient of many, if not all, real-world robotics applications. This paper leverages recent progress on Convolutional Neural Networks (CNNs) and proposes a novel RGB-D architecture for object recognition. Our architecture is composed of two separate CNN processing streams - one for each modality - which are consecutively combined with a late fusion network. We focus on learning with imperfect sensor data, a typical problem in real-world robotics tasks. For accurate learning, we introduce a multi-stage training methodology and two crucial ingredients for handling depth data with CNNs. The first, an effective encoding of depth information for CNNs that enables learning without the need for large depth datasets. The second, a data augmentation scheme for robust learning with depth images by corrupting them with realistic noise patterns. We present state-of-the-art results on the RGB-D object dataset [15] and show recognition in challenging RGB-D real-world noisy settings.",
Sentiment Data Flow Analysis by Means of Dynamic Linguistic Patterns,"Emulating the human brain is one of the core challenges of computational intelligence, which entails many key problems of artificial intelligence, including understanding human language, reasoning, and emotions. In this work, computational intelligence techniques are combined with common-sense computing and linguistics to analyze sentiment data flows, i.e., to automatically decode how humans express emotions and opinions via natural language. The increasing availability of social data is extremely beneficial for tasks such as branding, product positioning, corporate reputation management, and social media marketing. The elicitation of useful information from this huge amount of unstructured data, however, remains an open challenge. Although such data are easily accessible to humans, they are not suitable for automatic processing: machines are still unable to effectively and dynamically interpret the meaning associated with natural language text in very large, heterogeneous, noisy, and ambiguous environments such as the Web. We present a novel methodology that goes beyond mere word-level analysis of text and enables a more efficient transformation of unstructured social data into structured information, readily interpretable by machines. In particular, we describe a novel paradigm for real-time concept-level sentiment analysis that blends computational intelligence, linguistics, and common-sense computing in order to improve the accuracy of computationally expensive tasks such as polarity detection from big social data. The main novelty of the paper consists in an algorithm that assigns contextual polarity to concepts in text and flows this polarity through the dependency arcs in order to assign a final polarity label to each sentence. Analyzing how sentiment flows from concept to concept through dependency relations allows for a better understanding of the contextual role of each concept in text, to achieve a dynamic polarity inference that outperforms state-of-the-art statistical methods in terms of both accuracy and training time.","Semantics,
Pragmatics,
Knowledge based systems,
Electronic circuits,
Sentiment analysis,
Learning systems,
Linguistics,
Biological system modeling,
Behavioral science"
Power System Stability Control for a Wind Farm Based on Adaptive Dynamic Programming,"In this paper, a goal representation heuristic dynamic programming (GrHDP) based controller is developed for the doubly-fed induction generator based wind farm to improve the system transient stability under fault conditions. The proposed controller is based on adaptive dynamic programming (ADP) techniques to approximate the optimal control policy according to the interaction between the controller and the power plant. Compared to existing ADP approaches with one action network and one critic network, our GrHDP architecture introduces an additional network, i.e., the reference network, to form an internal goal/reward representation. This better mapping between the system state and the control action significantly improves the control performance. The effectiveness of the proposed approach is validated via two cases. The first case investigates a revised four-machine two-area system with high wind penetration and a static synchronous compensator. The second case is a practical size power system with wind farm in Liaoning Province in China. Detailed simulation analysis and comparative studies with traditional ADP approaches are presented to demonstrate the superior performance of our method.","Wind farms,
Power system stability,
Automatic voltage control,
Rotors,
Reactive power,
Wind turbines"
Differential Evolution With Auto-Enhanced Population Diversity,"In differential evolution (DE) studies, there are many parameter adaptation methods, aiming at tuning the mutation factor F and the crossover probability CR. However, these methods still cannot resolve the issues of population premature convergence and population stagnation. To address these issues, in this paper, we investigate the population adaptation regarding population diversity at the dimensional level and propose a mechanism named auto-enhanced population diversity (AEPD) to automatically enhance population diversity. AEPD is able to identify the moments when a population becomes converging or stagnating by measuring the distribution of the population in each dimension. When convergence or stagnation is identified at a dimension, the population is diversified at that dimension to an appropriate level or to eliminate the stagnation issue. The AEPD mechanism was incorporated into a popular DE algorithm and it was tested on a set of 25 CEC2005 benchmark functions. The results showed that AEPD significantly improved the performance of the original algorithms. In addition, AEPD helped the algorithms become less sensitive to population size, a parameter widely considered problem dependent for many DE algorithms. The DE algorithm with AEPD also has a superior performance in comparison with several other peer algorithms.","Sociology,
Statistics,
Vectors,
Convergence,
Optimization,
Algorithm design and analysis,
Standards"
Semisupervised Feature Selection via Spline Regression for Video Semantic Recognition,"To improve both the efficiency and accuracy of video semantic recognition, we can perform feature selection on the extracted video features to select a subset of features from the high-dimensional feature set for a compact and accurate video data representation. Provided the number of labeled videos is small, supervised feature selection could fail to identify the relevant features that are discriminative to target classes. In many applications, abundant unlabeled videos are easily accessible. This motivates us to develop semisupervised feature selection algorithms to better identify the relevant video features, which are discriminative to target classes by effectively exploiting the information underlying the huge amount of unlabeled video data. In this paper, we propose a framework of video semantic recognition by semisupervised feature selection via spline regression (S2FS2R). Two scatter matrices are combined to capture both the discriminative information and the local geometry structure of labeled and unlabeled training videos: A within-class scatter matrix encoding discriminative information of labeled training videos and a spline scatter output from a local spline regression encoding data distribution. An ℓ2,1-norm is imposed as a regularization term on the transformation matrix to ensure it is sparse in rows, making it particularly suitable for feature selection. To efficiently solve S2FS2R, we develop an iterative algorithm and prove its convergency. In the experiments, three typical tasks of video semantic recognition, such as video concept detection, video classification, and human action recognition, are used to demonstrate that the proposed S2FS2R achieves better performance compared with the state-of-the-art methods.","Splines (mathematics),
Training,
Semantics,
Feature extraction,
Geometry,
Vectors,
Sparse matrices"
Robust Exemplar Extraction Using Structured Sparse Coding,"Robust exemplar extraction from the noisy sample set is one of the most important problems in pattern recognition. In this brief, we propose a novel approach for exemplar extraction through structured sparse learning. The new model accounts for not only the reconstruction capability and the sparsity, but also the diversity and robustness. To solve the optimization problem, we adopt the alternating directional method of multiplier technology to design an iterative algorithm. Finally, the effectiveness of the approach is demonstrated by experiments of various examples including traffic sign sequences.",
Stereo Matching Using Tree Filtering,"Matching cost aggregation is one of the oldest and still popular methods for stereo correspondence. While effective and efficient, cost aggregation methods typically aggregate the matching cost by summing/averaging over a user-specified, local support region. This is obviously only locally-optimal, and the computational complexity of the full-kernel implementation usually depends on the region size. In this paper, the cost aggregation problem is re-examined and a non-local solution is proposed. The matching cost values are aggregated adaptively based on pixel similarity on a tree structure derived from the stereo image pair to preserve depth edges. The nodes of this tree are all the image pixels, and the edges are all the edges between the nearest neighboring pixels. The similarity between any two pixels is decided by their shortest distance on the tree. The proposed method is non-local as every node receives supports from all other nodes on the tree. The proposed method can be naturally extended to the time domain for enforcing temporal coherence. Unlike previous methods, the non-local property guarantees that the depth edges will be preserved when the temporal coherency between all the video frames are considered. A non-local weighted median filter is also proposed based on the non-local cost aggregation algorithm. It has been demonstrated to outperform all local weighted median filters on disparity/depth upsampling and refinement.","Image edge detection,
Image color analysis,
Runtime,
Computational complexity,
Heuristic algorithms,
Noise,
Filtering"
Coordinated Operational Planning for Wind Farm With Battery Energy Storage System,"This paper proposes a coordinated operational dispatch scheme for a wind farm with a battery energy storage system (BESS). The main advantages of the proposed dispatch scheme are that it can reduce the impacts of wind power forecast errors while prolonging the lifetime of BESS. The scheme starts from the planning stage, where a BESS capacity determination method is proposed to compute the optimal power capacity and energy capacity of BESS based on historical wind power data; and then, at the operation stage, a flexible short-term BESS-wind farm dispatch scheme is proposed based on the forecasted wind power generation scenarios. Three case studies are provided to validate the performance of the proposed method. The results show that the proposed scheme can largely improve the wind farm dispatchability.","Wind farms,
Batteries,
Wind power generation,
Wind forecasting,
Wind speed,
Australia,
System-on-chip"
Design Principles for Energy-Efficient Legged Locomotion and Implementation on the MIT Cheetah Robot,"This paper presents the design principles for highly efficient legged robots, the implementation of the principles in the design of the MIT Cheetah, and the analysis of the high-speed trotting experimental results. The design principles were derived by analyzing three major energy-loss mechanisms in locomotion: heat losses from the actuators, friction losses in transmission, and the interaction losses caused by the interface between the system and the environment. Four design principles that minimize these losses are discussed: employment of high torque-density motors, energy regenerative electronic system, low loss transmission, and a low leg inertia. These principles were implemented in the design of the MIT Cheetah; the major design features are large gap diameter motors, regenerative electric motor drivers, single-stage low gear transmission, dual coaxial motors with composite legs, and the differential actuated spine. The experimental results of fast trotting are presented; the 33-kg robot runs at 22 km/h (6 m/s). The total power consumption from the battery pack was 973 W and resulted in a total cost of transport of 0.5, which rivals running animals' at the same scale. 76% of the total energy consumption is attributed to heat loss from the motor, and the remaining 24% is used in mechanical work, which is dissipated as interaction loss as well as friction losses at the joint and transmission.",
EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding,"The performance of automatic speech recognition (ASR) has improved tremendously due to the application of deep neural networks (DNNs). Despite this progress, building a new ASR system remains a challenging task, requiring various resources, multiple training stages and significant expertise. This paper presents our Eesen framework which drastically simplifies the existing pipeline to build state-of-the-art ASR systems. Acoustic modeling in Eesen involves learning a single recurrent neural network (RNN) predicting context-independent targets (phonemes or characters). To remove the need for pre-generated frame labels, we adopt the connectionist temporal classification (CTC) objective function to infer the alignments between speech and label sequences. A distinctive feature of Eesen is a generalized decoding approach based on weighted finite-state transducers (WFSTs), which enables the efficient incorporation of lexicons and language models into CTC decoding. Experiments show that compared with the standard hybrid DNN systems, Eesen achieves comparable word error rates (WERs), while at the same time speeding up decoding significantly.",
An Evolutionary Game for Distributed Resource Allocation in Self-Organizing Small Cells,"We propose an evolutionary game theory (EGT)-based distributed resource allocation scheme for small cells underlaying a macro cellular network. EGT is a suitable tool to address the problem of resource allocation in self-organizing small cells since it allows the players with bounded-rationality to learn from the environment and take individual decisions for attaining the equilibrium with minimum information exchange. EGT-based resource allocation can also provide fairness among users. We show how EGT can be used for distributed subcarrier and power allocation in orthogonal frequency-division multiple access (OFDMA)-based small cell networks while limiting interference to the macrocell users below given thresholds. Two game models are considered, where the utility of each small cell depends on average achievable signal-to-interference-plus-noise ratio (SINR) and data rate, respectively. Forthe proposed distributed resource allocation method, the average SINR and data rate are obtained based on a stochastic geometry analysis. Replicator dynamics is used to model the strategy adaptation process of the small cell base stations and an evolutionary equilibrium is obtained as the solution. Based on the results obtained using stochastic geometry, the stability of the equilibrium is analyzed. We also extend the formulation by considering information exchange delay and investigate its impact on the convergence of the algorithm. Numerical results are presented to validate ourtheoretical findings and to show the effectiveness of the proposed scheme in comparison to a centralized resource allocation scheme.","Games,
Resource management,
Interference,
Scattering,
Sociology,
Statistics,
Signal to noise ratio"
Blind Image Quality Assessment via Deep Learning,"This paper investigates how to blindly evaluate the visual quality of an image by learning rules from linguistic descriptions. Extensive psychological evidence shows that humans prefer to conduct evaluations qualitatively rather than numerically. The qualitative evaluations are then converted into the numerical scores to fairly benchmark objective image quality assessment (IQA) metrics. Recently, lots of learning-based IQA models are proposed by analyzing the mapping from the images to numerical ratings. However, the learnt mapping can hardly be accurate enough because some information has been lost in such an irreversible conversion from the linguistic descriptions to numerical scores. In this paper, we propose a blind IQA model, which learns qualitative evaluations directly and outputs numerical scores for general utilization and fair comparison. Images are represented by natural scene statistics features. A discriminative deep model is trained to classify the features into five grades, corresponding to five explicit mental concepts, i.e., excellent, good, fair, poor, and bad. A newly designed quality pooling is then applied to convert the qualitative labels into scores. The classification framework is not only much more natural than the regression-based models, but also robust to the small sample size problem. Thorough experiments are conducted on popular databases to verify the model's effectiveness, efficiency, and robustness.","Image quality,
Databases,
Numerical models,
Training,
Visualization,
Image representation,
Measurement"
A Hybrid Chemical Reaction Optimization Scheme for Task Scheduling on Heterogeneous Computing Systems,"Scheduling for directed acyclic graph (DAG) tasks with the objective of minimizing makespan has become an important problem in a variety of applications on heterogeneous computing platforms, which involves making decisions about the execution order of tasks and task-to-processor mapping. Recently, the chemical reaction optimization (CRO) method has proved to be very effective in many fields. In this paper, an improved hybrid version of the CRO method called HCRO (hybrid CRO) is developed for solving the DAG-based task scheduling problem. In HCRO, the CRO method is integrated with the novel heuristic approaches, and a new selection strategy is proposed. More specifically, the following contributions are made in this paper. (1) A Gaussian random walk approach is proposed to search for optimal local candidate solutions. (2) A left or right rotating shift method based on the theory of maximum Hamming distance is used to guarantee that our HCRO algorithm can escape from local optima. (3) A novel selection strategy based on the normal distribution and a pseudo-random shuffle approach are developed to keep the molecular diversity. Moreover, an exclusive-OR (XOR) operator between two strings is introduced to reduce the chance of cloning before new molecules are generated. Both simulation and real-life experiments have been conducted in this paper to verify the effectiveness of HCRO. The results show that the HCRO algorithm schedules the DAG tasks much better than the existing algorithms in terms of makespan and speed of convergence.","Processor scheduling,
Program processors,
Sociology,
Statistics,
Heuristic algorithms,
Computational modeling,
Scheduling"
Local Area Prediction-Based Mobile Target Tracking in Wireless Sensor Networks,"Tracking mobile targets in wireless sensor networks (WSNs) has many important applications. As it is often the case in prior work that the quality of tracking (QoT) heavily depends on high accuracy in localization or distance estimation, which is never perfect in practice. These bring a cumulative effect on tracking, e.g., target missing. Recovering from the effect and also frequent interactions between nodes and a central server result in a high energy consumption. We design a tracking scheme, named t-Tracking, aiming to achieve two major objectives: high QoT and high energy efficiency of the WSN. We propose a set of fully distributed tracking algorithms, which answer queries like whether a target remains in a “specific area” (called a “face” in localized geographic routing, defined in terms of radio connectivity and local interactions of nodes). When a target moves across a face, the nodes of the face that are close to its estimated movements compute the sequence of the target's movements and predict when the target moves to another face. The nodes answer queries from a mobile sink called the “tracker”, which follows the target along with the sequence. t-Tracking has advantages over prior work as it reduces the dependency on requiring high accuracy in localization and the frequency of interactions. It also timely solves the target missing problem caused by node failures, obstacles, etc., making the tracking robust in a highly dynamic environment. We validate its effectiveness considering the objectives in extensive simulations and in a proof-of-concept system implementation.","Target tracking,
Face,
Wireless sensor networks,
Sensors,
Monitoring,
Mobile communication"
Sparsity-Promoting Sensor Selection for Non-Linear Measurement Models,"The problem of choosing the best subset of sensors that guarantees a certain estimation performance is referred to as sensor selection. In this paper, we focus on observations that are related to a general non-linear model. The proposed framework is valid as long as the observations are independent, and its likelihood satisfies the regularity conditions. We use several functions of the Cramér-Rao bound (CRB) as a performance measure. We formulate the sensor selection problem as the design of a sparse vector, which in its original form is a nonconvex ℓ0-(quasi) norm optimization problem. We present relaxed sensor selection solvers that can be efficiently solved in polynomial time. The proposed solvers result in sparse sensing techniques. We also propose a projected subgradient algorithm that is attractive for large-scale problems. The developed theory is applied to sensor placement for localization.","Vectors,
Optimization,
Sensors,
Additives,
Frequency modulation,
Accuracy,
Eigenvalues and eigenfunctions"
Standard Plane Localization in Fetal Ultrasound via Domain Transferred Deep Neural Networks,"Automatic localization of the standard plane containing complicated anatomical structures in ultrasound (US) videos remains a challenging problem. In this paper, we present a learning-based approach to locate the fetal abdominal standard plane (FASP) in US videos by constructing a domain transferred deep convolutional neural network (CNN). Compared with previous works based on low-level features, our approach is able to represent the complicated appearance of the FASP and hence achieve better classification performance. More importantly, in order to reduce the overfitting problem caused by the small amount of training samples, we propose a transfer learning strategy, which transfers the knowledge in the low layers of a base CNN trained from a large database of natural images to our task-specific CNN. Extensive experiments demonstrate that our approach outperforms the state-of-the-art method for the FASP localization as well as the CNN only trained on the limited US training samples. The proposed approach can be easily extended to other similar medical image computing problems, which often suffer from the insufficient training samples when exploiting the deep CNN to represent high-level features.","Training,
Videos,
Biomedical imaging,
Standards,
Feature extraction,
Dictionaries,
Informatics"
Spiking Neural P Systems With Rules on Synapses Working in Maximum Spiking Strategy,"Spiking neural P systems (called SN P systems for short) are a class of parallel and distributed neural-like computation models inspired by the way the neurons process information and communicate with each other by means of impulses or spikes. In this work, we introduce a new variant of SN P systems, called SN P systems with rules on synapses working in maximum spiking strategy, and investigate the computation power of the systems as both number and vector generators. Specifically, we prove that i) if no limit is imposed on the number of spikes in any neuron during any computation, such systems can generate the sets of Turing computable natural numbers and the sets of vectors of positive integers computed by k-output register machine; ii) if an upper bound is imposed on the number of spikes in each neuron during any computation, such systems can characterize semi-linear sets of natural numbers as number generating devices; as vector generating devices, such systems can only characterize the family of sets of vectors computed by sequential monotonic counter machine, which is strictly included in family of semi-linear sets of vectors. This gives a positive answer to the problem formulated in Song et al., Theor. Comput. Sci., vol. 529, pp. 82-95, 2014.",
Lag Synchronization of Switched Neural Networks via Neural Activation Function and Applications in Image Encryption,"This paper investigates the problem of global exponential lag synchronization of a class of switched neural networks with time-varying delays via neural activation function and applications in image encryption. The controller is dependent on the output of the system in the case of packed circuits, since it is hard to measure the inner state of the circuits. Thus, it is critical to design the controller based on the neuron activation function. Comparing the results, in this paper, with the existing ones shows that we improve and generalize the results derived in the previous literature. Several examples are also given to illustrate the effectiveness and potential applications in image encryption.",
Inertial Sensor-Based Stride Parameter Calculation From Gait Sequences in Geriatric Patients,"A detailed and quantitative gait analysis can provide evidence of various gait impairments in elderly people. To provide an objective decision-making basis for gait analysis, simple applicable tests analyzing a high number of strides are required. A mobile gait analysis system, which is mounted on shoes, can fulfill these requirements. This paper presents a method for computing clinically relevant temporal and spatial gait parameters. Therefore, an accelerometer and a gyroscope were positioned laterally below each ankle joint. Temporal gait events were detected by searching for characteristic features in the signals. To calculate stride length, the gravity compensated accelerometer signal was double integrated, and sensor drift was modeled using a piece-wise defined linear function. The presented method was validated using GAITRite-based gait parameters from 101 patients (average age 82.1 years). Subjects performed a normal walking test with and without a wheeled walker. The parameters stride length and stride time showed a correlation of 0.93 and 0.95 between both systems. The absolute error of stride length was 6.26 cm on normal walking test. The developed system as well as the GAITRite showed an increased stride length, when using a four-wheeled walker as walking aid. However, the walking aid interfered with the automated analysis of the GAITRite system, but not with the inertial sensor-based approach. In summary, an algorithm for the calculation of clinically relevant gait parameters derived from inertial sensors is applicable in the diagnostic workup and also during long-term monitoring approaches in the elderly population.","Standards,
Gyroscopes,
Legged locomotion,
Accelerometers,
Gold,
Gravity,
Correlation"
"Shape, Illumination, and Reflectance from Shading","A fundamental problem in computer vision is that of inferring the intrinsic, 3D structure of the world from flat, 2D images of that world. Traditional methods for recovering scene properties such as shape, reflectance, or illumination rely on multiple observations of the same scene to overconstrain the problem. Recovering these same properties from a single image seems almost impossible in comparison-there are an infinite number of shapes, paint, and lights that exactly reproduce a single image. However, certain explanations are more likely than others: surfaces tend to be smooth, paint tends to be uniform, and illumination tends to be natural. We therefore pose this problem as one of statistical inference, and define an optimization problem that searches for the most likely explanation of a single image. Our technique can be viewed as a superset of several classic computer vision problems (shape-from-shading, intrinsic images, color constancy, illumination estimation, etc) and outperforms all previous solutions to those constituent problems.","Lighting,
Shape,
Image color analysis,
GSM,
Computer vision,
Paints,
Optimization"
Symmetry-based text line detection in natural scenes,"Recently, a variety of real-world applications have triggered huge demand for techniques that can extract textual information from natural scenes. Therefore, scene text detection and recognition have become active research topics in computer vision. In this work, we investigate the problem of scene text detection from an alternative perspective and propose a novel algorithm for it. Different from traditional methods, which mainly make use of the properties of single characters or strokes, the proposed algorithm exploits the symmetry property of character groups and allows for direct extraction of text lines from natural images. The experiments on the latest ICDAR benchmarks demonstrate that the proposed algorithm achieves state-of-the-art performance. Moreover, compared to conventional approaches, the proposed algorithm shows stronger adaptability to texts in challenging scenarios.","Proposals,
Training,
Feature extraction,
Benchmark testing,
Image color analysis,
Detectors"
Input Parameters for the Simulation of Silicon Solar Cells in 2014,"Within the silicon photovoltaics (PV) community, there are many approaches, tools, and input parameters for simulating solar cells, making it difficult for newcomers to establish a complete and representative starting point and imposing high requirements on experts to tediously state all assumptions and inputs for replication. In this review, we address these problems by providing complete and representative input parameter sets to simulate six major types of crystalline silicon solar cells. Where possible, the inputs are justified and up-to-date for the respective cell types, and they produce representative measurable cell characteristics. Details of the modeling approaches that can replicate the simulations are presented as well. The input parameters listed here provide a sensible and consistent reference point for researchers on which to base their refinements and extensions.",
"Memristor-Based Cellular Nonlinear/Neural Network: Design, Analysis, and Applications","Cellular nonlinear/neural network (CNN) has been recognized as a powerful massively parallel architecture capable of solving complex engineering problems by performing trillions of analog operations per second. The memristor was theoretically predicted in the late seventies, but it garnered nascent research interest due to the recent much-acclaimed discovery of nanocrossbar memories by engineers at the Hewlett-Packard Laboratory. The memristor is expected to be co-integrated with nanoscale CMOS technology to revolutionize conventional von Neumann as well as neuromorphic computing. In this paper, a compact CNN model based on memristors is presented along with its performance analysis and applications. In the new CNN design, the memristor bridge circuit acts as the synaptic circuit element and substitutes the complex multiplication circuit used in traditional CNN architectures. In addition, the negative differential resistance and nonlinear current-voltage characteristics of the memristor have been leveraged to replace the linear resistor in conventional CNNs. The proposed CNN design has several merits, for example, high density, nonvolatility, and programmability of synaptic weights. The proposed memristor-based CNN design operations for implementing several image processing functions are illustrated through simulation and contrasted with conventional CNNs. Monte-Carlo simulation has been used to demonstrate the behavior of the proposed CNN due to the variations in memristor synaptic weights.","Memristors,
Bridge circuits,
Educational institutions,
Neural networks,
Programming,
Integrated circuit modeling"
Spiking Neural P Systems With Rules on Synapses Working in Maximum Spikes Consumption Strategy,"Spiking neural P systems (SN P systems, for short) are a class of parallel and distributed computation models inspired from the way the neurons process and communicate information by means of spikes. In this paper, we consider a new variant of SN P systems, where each synapse instead of neuron has a set of spiking rules, and the neurons contain only spikes; when the number of spikes in a given neuron is “recognized” by a rule on a synapse leaving from it, the rule is enabled; at a computation step, at most one enabled spiking rule is applied on a synapse, and k spikes are removed from a neuron if the maximum number of spikes that the applied spiking rules on the synapses starting from this neuron consume is k. The computation power of this variant of SN P systems is investigated. Specifically, we prove that such SN P systems can generate or accept any set of Turing computable natural numbers. This result gives an answer to an open problem formulated in Theor. Comput. Sci., vol. 529, pp. 82-95, 2014.","Neurons,
Tin,
Registers,
Nanobioscience,
Biomembranes,
Computational modeling,
Biological system modeling"
Adaptive Multiobjective Particle Swarm Optimization Based on Parallel Cell Coordinate System,"Managing convergence and diversity is essential in the design of multiobjective particle swarm optimization (MOPSO) in search of an accurate and well distributed approximation of the true Pareto-optimal front. Largely due to its fast convergence, particle swarm optimization incurs a rapid loss of diversity during the evolutionary process. Many mechanisms have been proposed in existing MOPSOs in terms of leader selection, archive maintenance, and perturbation to tackle this deficiency. However, few MOPSOs are designed to dynamically adjust the balance in exploration and exploitation according to the feedback information detected from the evolutionary environment. In this paper, a novel method, named parallel cell coordinate system (PCCS), is proposed to assess the evolutionary environment including density, rank, and diversity indicators based on the measurements of parallel cell distance, potential, and distribution entropy, respectively. Based on PCCS, strategies proposed for selecting global best and personal best, maintaining archive, adjusting flight parameters, and perturbing stagnation are integrated into a self-adaptive MOPSO (pccsAMOPSO). The comparative experimental results show that the proposed pccsAMOPSO outperforms the other eight state-of-the-art competitors on ZDT and DTLZ test suites in terms of the chosen performance metrics. An additional experiment for density estimation in MOPSO illustrates that the performance of PCCS is superior to that of adaptive grid and crowding distance in terms of convergence and diversity.","Convergence,
Sociology,
Statistics,
Particle swarm optimization,
Hypercubes,
Estimation,
Optimization"
Gaussian Processes for Data-Efficient Learning in Robotics and Control,"Autonomous learning has been a promising direction in control and robotics for more than a decade since data-driven learning allows to reduce the amount of engineering knowledge, which is otherwise required. However, autonomous reinforcement learning (RL) approaches typically require many interactions with the system to learn controllers, which is a practical limitation in real systems, such as robots, where many interactions can be impractical and time consuming. To address this problem, current learning approaches typically require task-specific knowledge in form of expert demonstrations, realistic simulators, pre-shaped policies, or specific knowledge about the underlying dynamics. In this paper, we follow a different approach and speed up learning by extracting more information from data. In particular, we learn a probabilistic, non-parametric Gaussian process transition model of the system. By explicitly incorporating model uncertainty into long-term planning and controller learning our approach reduces the effects of model errors, a key problem in model-based learning. Compared to state-of-the art RL our model-based policy search method achieves an unprecedented speed of learning. We demonstrate its applicability to autonomous learning in real robot and control tasks.","Computational modeling,
Probabilistic logic,
Approximation methods,
Robots,
Uncertainty,
Data models,
Predictive models"
Lift: Multi-Label Learning with Label-Specific Features,"Multi-label learning deals with the problem where each example is represented by a single instance (feature vector) while associated with a set of class labels. Existing approaches learn from multi-label data by manipulating with identical feature set, i.e. the very instance representation of each example is employed in the discrimination processes of all class labels. However, this popular strategy might be suboptimal as each label is supposed to possess specific characteristics of its own. In this paper, another strategy to learn from multi-label data is studied, where label-specific features are exploited to benefit the discrimination of different class labels. Accordingly, an intuitive yet effective algorithm named LIFT, i.e. multi-label learning with Label specific Features, is proposed. LIFT firstly constructs features specific to each label by conducting clustering analysis on its positive and negative instances, and then performs training and testing by querying the clustering results. Comprehensive experiments on a total of 17 benchmark data sets clearly validate the superiority of LIFT against other well-established multi-label learning algorithms as well as the effectiveness of label-specific features.",
Multiview Matrix Completion for Multilabel Image Classification,"There is growing interest in multilabel image classification due to its critical role in web-based image analytics-based applications, such as large-scale image retrieval and browsing. Matrix completion (MC) has recently been introduced as a method for transductive (semisupervised) multilabel classification, and has several distinct advantages, including robustness to missing data and background noise in both feature and label space. However, it is limited by only considering data represented by a single-view feature, which cannot precisely characterize images containing several semantic concepts. To utilize multiple features taken from different views, we have to concatenate the different features as a long vector. However, this concatenation is prone to over-fitting and often leads to very high time complexity in MC-based image classification. Therefore, we propose to weightedly combine the MC outputs of different views, and present the multiview MC (MVMC) framework for transductive multilabel image classification. To learn the view combination weights effectively, we apply a cross-validation strategy on the labeled set. In particular, MVMC splits the labeled set into two parts, and predicts the labels of one part using the known labels of the other part. The predicted labels are then used to learn the view combination coefficients. In the learning process, we adopt the average precision (AP) loss, which is particular suitable for multilabel image classification, since the ranking-based criteria are critical for evaluating a multilabel classification system. A least squares loss formulation is also presented for the sake of efficiency, and the robustness of the algorithm based on the AP loss compared with the other losses is investigated. Experimental evaluation on two real-world data sets (PASCAL VOC' 07 and MIR Flickr) demonstrate the effectiveness of MVMC for transductive (semisupervised) multilabel image classification, and show that MVMC can exploit complementary properties of different features and output-consistent labels for improved multilabel image classification.",
Discriminatively Trained And-Or Graph Models for Object Shape Detection,"In this paper, we investigate a novel reconfigurable part-based model, namely And-Or graph model, to recognize object shapes in images. Our proposed model consists of four layers: leaf-nodes at the bottom are local classifiers for detecting contour fragments; or-nodes above the leaf-nodes function as the switches to activate their child leaf-nodes, making the model reconfigurable during inference; and-nodes in a higher layer capture holistic shape deformations; one root-node on the top, which is also an or-node, activates one of its child and-nodes to deal with large global variations (e.g. different poses and views). We propose a novel structural optimization algorithm to discriminatively train the And-Or model from weakly annotated data. This algorithm iteratively determines the model structures (e.g. the nodes and their layouts) along with the parameter learning. On several challenging datasets, our model demonstrates the effectiveness to perform robust shape-based object detection against background clutter and outperforms the other state-of-the-art approaches. We also release a new shape database with annotations, which includes more than 1500 challenging shape instances, for recognition and detection.",
"Integrated {LCC}
Compensation Topology for Wireless Charger in Electric and Plug-in Electric Vehicles","This paper presents an integrated LCC compensation topology for electric vehicle/plug-in hybrid electric vehicle wireless chargers. The effect of the coupling between the additional coil and the main coil on the LCC compensation topology is studied. The proposed topology will reduce the size of the additional coil and make the system more compact with extremely high efficiency. The basic characteristics of the proposed topology are analyzed based on fundamental harmonic approximation. Furthermore, based on the steady-state model, three categories of operation modes are presented and analyzed. In order to realize zero-voltage switching, the series capacitor C2 on the secondary side is tuned. A numerical method is used to analyze the impact of different values of ΔC2 on the turnoff current, and the best value of C2 is chosen to build a prototype to verify the analysis.",
Decentralized Supervision of Petri Nets With a Coordinator,"This paper develops a decentralized supervision policy for a Petri net through collaboration between a coordinator and subnet controllers. The coordinator is chosen from the subnet controllers by solving an integer linear programming problem. An optimal objective function is used to minimize the communication cost between the subnet controllers and the coordinator. Furthermore, a protocol to reach an agreement on the firing conditions of common transitions among the subnet controllers is proposed. Observation agreement and control agreement can be achieved by the “AND” operator in logic algebra. Control agreement is used to decide the firing conditions of common transitions in the next step. The firing of common transitions, which will lead to a new marking that violates the given constraints, will be forbidden by the control agreement. A feasibility analysis of the proposed decentralized control framework is discussed. Finally, four examples are presented to illustrate the proposed approach.","Petri nets,
Silicon,
Decentralized control,
Educational institutions,
Vectors,
Manufacturing,
Protocols"
Experimental Link Quality Characterization of Wireless Sensor Networks for Underground Monitoring,"Wireless underground sensor networks (WUSNs) are a category of wireless sensor networks (WSNs) with buried nodes, which communicate wirelessly through soil with sensor nodes located aboveground. As the communication medium (i.e., soil) between traditional over-the-air WSNs and WUSNs differs, communication characteristics have to be fully characterized for WUSNs, specifically to enable development of efficient communication protocols. Characterization of link quality is a fundamental building block for various communication protocols. The aim of this paper is to experimentally investigate the link quality characteristics of the three communication channels available in WUSNs for underground pipeline monitoring to gain further insight into protocol development for WUSNs. To this end, received signal strength (RSS), link quality indicator (LQI), and packet reception ratio (PRR) are characterized for the three communication channels in WUSNs. The RSS and PRR results show that the underground-to-underground channel is highly symmetric and temporally stable, but its range is severely limited, and that the aboveground-to-underground/underground-to-underground channels are asymmetric and exhibit similar temporal properties to over-the-air communication channels. Interestingly, the results show that RSS is a better indicator of PRR than LQI for all three channels under consideration.",
Friendbook: A Semantic-Based Friend Recommendation System for Social Networks,"Existing social networking services recommend friends to users based on their social graphs, which may not be the most appropriate to reflect a user's preferences on friend selection in real life. In this paper, we present Friendbook, a novel semantic-based friend recommendation system for social networks, which recommends friends to users based on their life styles instead of social graphs. By taking advantage of sensor-rich smartphones, Friendbook discovers life styles of users from user-centric sensor data, measures the similarity of life styles between users, and recommends friends to users if their life styles have high similarity. Inspired by text mining, we model a user's daily life as life documents, from which his/her life styles are extracted by using the Latent Dirichlet Allocation algorithm. We further propose a similarity metric to measure the similarity of life styles between users, and calculate users' impact in terms of life styles with a friend-matching graph. Upon receiving a request, Friendbook returns a list of people with highest recommendation scores to the query user. Finally, Friendbook integrates a feedback mechanism to further improve the recommendation accuracy. We have implemented Friendbook on the Android-based smartphones, and evaluated its performance on both small-scale experiments and large-scale simulations. The results show that the recommendations accurately reflect the preferences of users in choosing friends.","Smart phones,
Social network services,
Mobile computing,
Probabilistic logic,
Matrix decomposition,
Data mining,
Vectors"
Secure Data Aggregation Technique for Wireless Sensor Networks in the Presence of Collusion Attacks,"Due to limited computational power and energy resources, aggregation of data from multiple sensor nodes done at the aggregating node is usually accomplished by simple methods such as averaging. However such aggregation is known to be highly vulnerable to node compromising attacks. Since WSN are usually unattended and without tamper resistant hardware, they are highly susceptible to such attacks. Thus, ascertaining trustworthiness of data and reputation of sensor nodes is crucial for WSN. As the performance of very low power processors dramatically improves, future aggregator nodes will be capable of performing more sophisticated data aggregation algorithms, thus making WSN less vulnerable. Iterative filtering algorithms hold great promise for such a purpose. Such algorithms simultaneously aggregate data from multiple sources and provide trust assessment of these sources, usually in a form of corresponding weight factors assigned to data provided by each source. In this paper we demonstrate that several existing iterative filtering algorithms, while significantly more robust against collusion attacks than the simple averaging methods, are nevertheless susceptive to a novel sophisticated collusion attack we introduce. To address this security issue, we propose an improvement for iterative filtering techniques by providing an initial approximation for such algorithms which makes them not only collusion robust, but also more accurate and faster converging.",
Multi-Orientation Scene Text Detection with Adaptive Clustering,"Text detection in natural scene images is an important prerequisite for many content-based image analysis tasks, while most current research efforts only focus on horizontal or near horizontal scene text. In this paper, first we present a unified distance metric learning framework for adaptive hierarchical clustering, which can simultaneously learn similarity weights (to adaptively combine different feature similarities) and the clustering threshold (to automatically determine the number of clusters). Then, we propose an effective multi-orientation scene text detection system, which constructs text candidates by grouping characters based on this adaptive clustering. Our text candidates construction method consists of several sequential coarse-to-fine grouping steps: morphology-based grouping via single-link clustering, orientation-based grouping via divisive hierarchical clustering, and projection-based grouping also via divisive clustering. The effectiveness of our proposed system is evaluated on several public scene text databases, e.g., ICDAR Robust Reading Competition data sets (2011 and 2013), MSRA-TD500 and NEOCR. Specifically, on the multi-orientation text data set MSRA-TD500, the
f
measure of our system is
71
percent, much better than the state-of-the-art performance. We also construct and release a practical challenging multi-orientation scene text data set (USTB-SV1K), which is available at http://prir.ustb.edu.cn/TexStar/MOMV-text-detection/.","Measurement,
Clustering algorithms,
Morphology,
Mathematical model,
Equations,
Image color analysis,
Robustness"
PX4: A node-based multithreaded open source robotics framework for deeply embedded platforms,"We present a novel, deeply embedded robotics middleware and programming environment. It uses a multithreaded, publish-subscribe design pattern and provides a Unix-like software interface for micro controller applications. We improve over the state of the art in deeply embedded open source systems by providing a modular and standards-oriented platform. Our system architecture is centered around a publish-subscribe object request broker on top of a POSIX application programming interface. This allows to reuse common Unix knowledge and experience, including a bash-like shell. We demonstrate with a vertical takeoff and landing (VTOL) use case that the system modularity is well suited for novel and experimental vehicle platforms. We also show how the system architecture allows a direct interface to ROS and to run individual processes either as native ROS nodes on Linux or nodes on the micro controller, maximizing interoperability. Our microcontroller-based execution environment has substantially lower latency and better hardware connectivity than a typical Robotics Linux system and is therefore well suited for fast, high rate control tasks.","Linux,
Hardware,
Computer architecture,
Vehicles,
Software,
Robot sensing systems"
Highly efficient data migration and backup for big data applications in elastic optical inter-data-center networks,"This article discusses the technologies for realizing highly efficient data migration and backup for big data applications in elastic optical inter-data-center (inter-DC) networks. We first describe the impacts of big data applications on underlying network infrastructure and introduce the concept of flexible-grid elastic optical inter-DC networks. Then we model the data migration in such networks as dynamic anycast and propose several efficient algorithms. Joint resource defragmentation is also discussed to further improve network performance. For efficient data backup, we leverage a mutual backup model and investigate how to avoid the prolonged negative impacts on DCs' normal operation by minimizing the DC backup window.","Optical fiber networks,
Bandwidth allocation,
Big data,
Optical fiber networks,
Routing,
Frequency selective surfaces"
A Class of Two-Weight and Three-Weight Codes and Their Applications in Secret Sharing,"In this paper, a class of two-weight and three-weight linear codes over GF(p) is constructed, and their application in secret sharing is investigated. Some of the linear codes obtained are optimal in the sense that they meet certain bounds on linear codes. These codes have applications also in authentication codes, association schemes, and strongly regular graphs, in addition to their applications in consumer electronics, communication and data storage systems.","Linear codes,
Cryptography,
Additives,
Generators,
Authentication,
Consumer electronics,
Data storage systems"
Epidemic Information Dissemination in Mobile Social Networks With Opportunistic Links,"With the advancement of smartphones, mobile social networks (MSNs) have emerged where information can be shared among mobile users via opportunistic peer-to-peer links. Since the social ties and users' behaviors in MSNs have diverse characteristics, the information dissemination in MSNs becomes a new challenge. In particular, mobile users' interested information may vary, which can significantly affect the information dissemination. In this paper, we develop an analytical model to analyze the epidemic information dissemination in MSNs. We first adopt preimmunity and immunity to represent the features of mobile nodes when they change their interests. Then, the information dissemination mechanism is introduced with four proposed dissemination rules according to the process of the epidemic information dissemination. We develop the analytical model through ordinary differential equations to mimic epidemic information dissemination in MSNs. The trace-driven simulation demonstrates that our analytical model is more accurate to mimic epidemic information dissemination than other existing ones.",
Demographic Estimation from Face Images: Human vs. Machine Performance,"Demographic estimation entails automatic estimation of age, gender and race of a person from his face image, which has many potential applications ranging from forensics to social media. Automatic demographic estimation, particularly age estimation, remains a challenging problem because persons belonging to the same demographic group can be vastly different in their facial appearances due to intrinsic and extrinsic factors. In this paper, we present a generic framework for automatic demographic (age, gender and race) estimation. Given a face image, we first extract demographic informative features via a boosting algorithm, and then employ a hierarchical approach consisting of between-group classification, and within-group regression. Quality assessment is also developed to identify low-quality face images that are difficult to obtain reliable demographic estimates. Experimental results on a diverse set of face image databases, FG-NET (1K images), FERET (3K images), MORPH II (75K images), PCSO (100K images), and a subset of LFW (4K images), show that the proposed approach has superior performance compared to the state of the art. Finally, we use crowdsourcing to study the human perception ability of estimating demographics from face images. A side-by-side comparison of the demographic estimates from crowdsourced data and the proposed algorithm provides a number of insights into this challenging problem.",
Software defined networking-based vehicular Adhoc Network with Fog Computing,"Vehicular Adhoc Networks (VANETs) have been attracted a lot of research recent years. Although VANETs are deployed in reality offering several services, the current architecture has been facing many difficulties in deployment and management because of poor connectivity, less scalability, less flexibility and less intelligence. We propose a new VANET architecture called FSDN which combines two emergent computing and network paradigm Software Defined Networking (SDN) and Fog Computing as a prospective solution. SDN-based architecture provides flexibility, scalability, programmability and global knowledge while Fog Computing offers delay-sensitive and location-awareness services which could be satisfy the demands of future VANETs scenarios. We figure out all the SDN-based VANET components as well as their functionality in the system. We also consider the system basic operations in which Fog Computing are leveraged to support surveillance services by taking into account resource manager and Fog orchestration models. The proposed architecture could resolve the main challenges in VANETs by augmenting Vehicle-to-Vehicle (V2V), Vehicle-to-Infrastructure (V2I), Vehicle-to-Base Station communications and SDN centralized control while optimizing resources utility and reducing latency by integrating Fog Computing. Two use-cases for non-safety service (data streaming) and safety service (Lane-change assistance) are also presented to illustrate the benefits of our proposed architecture.","Computer architecture,
Vehicular ad hoc networks,
Vehicles,
Wireless communication,
Protocols,
Cloud computing,
Conferences"
Double-Quadrant State-of-Charge-Based Droop Control Method for Distributed Energy Storage Systems in Autonomous DC Microgrids,"In this paper, a double-quadrant state-of-charge (SoC)-based droop control method for distributed energy storage system is proposed to reach the proper power distribution in autonomous dc microgrids. In order to prolong the lifetime of the energy storage units (ESUs) and avoid the overuse of a certain unit, the SoC of each unit should be balanced and the injected/output power should be gradually equalized. Droop control as a decentralized approach is used as the basis of the power sharing method for distributed energy storage units. In the charging process, the droop coefficient is set to be proportional to the nth order of SoC, while in the discharging process, the droop coefficient is set to be inversely proportional to the nth order of SoC. Since the injected/output power is inversely proportional to the droop coefficient, it is obtained that in the charging process the ESU with higher SoC absorbs less power, while the one with lower SoC absorbs more power. Meanwhile, in the discharging process, the ESU with higher SoC delivers more power and the one with lower SoC delivers less power. Hence, SoC balancing and injected/output power equalization can be gradually realized. The exponent n of SoC is employed in the control diagram to regulate the speed of SoC balancing. It is found that with larger exponent n, the balancing speed is higher. MATLAB/simulink model comprised of three ESUs is implemented and the simulation results are shown to verify the proposed approach.","System-on-chip,
Microgrids,
Power generation,
Batteries,
Educational institutions,
Voltage control"
Multi-Ray Channel Modeling and Wideband Characterization for Wireless Communications in the Terahertz Band,"Terahertz (0.06-10 THz) Band communication is envisioned as a key technology for satisfying the increasing demand for ultra-high-speed wireless links. In this paper, first, a unified multi-ray channel model in the THz Band is developed based on ray tracing techniques, which incorporates the propagation models for the line-of-sight, reflected, scattered, and diffracted paths. The developed theoretical model is validated with the experimental measurements (0.06-1 THz) from the literature. Then, using the developed propagation models, an in-depth analysis on the THz channel characteristics is carried out. In particular, the distance-varying and frequency-selective nature of the Terahertz channel is analyzed. Moreover, the coherence bandwidth and the significance of the delay spread are studied. Furthermore, the wideband channel capacity using flat and water-filling power allocation strategies is characterized. Additionally, the temporal broadening effects of the Terahertz channel are studied. Finally, distance-adaptive and multi-carrier transmissions are suggested to best benefit from the unique relationship between distance and bandwidth. The provided analysis lays out the foundation for reliable and efficient ultra-high-speed wireless communications in the (0.06-10) THz Band.",
Structured Data Fusion,"We present structured data fusion (SDF) as a framework for the rapid prototyping of knowledge discovery in one or more possibly incomplete data sets. In SDF, each data set-stored as a dense, sparse, or incomplete tensor-is factorized with a matrix or tensor decomposition. Factorizations can be coupled, or fused, with each other by indicating which factors should be shared between data sets. At the same time, factors may be imposed to have any type of structure that can be constructed as an explicit function of some underlying variables. With the right choice of decomposition type and factor structure, even well-known matrix factorizations such as the eigenvalue decomposition, singular value decomposition and QR factorization can be computed with SDF. A domain specific language (DSL) for SDF is implemented as part of the software package Tensorlab, with which we offer a library of tensor decompositions and factor structures to choose from. The versatility of the SDF framework is demonstrated by means of four diverse applications, which are all solved entirely within Tensorlab's DSL.","Tensile stress,
Matrix decomposition,
Data integration,
Vectors,
Approximation methods,
Signal processing,
Covariance matrices"
Experimental Evaluation of Frequency Regulation From Commercial Building HVAC Systems,"Automated demand response can be a valuable resource for ancillary services in the power grid. This paper illustrates this value with the first experimental demonstration of frequency regulation from commercial building heating ventilation and air conditioning (HVAC) systems. The experiments were conducted in Pugh Hall, a 40000 sq. ft. commercial building located at the University of Florida. Detailed are the steps required to make this possible, including control architecture, system identification, and control design. Experiments demonstrate: that satisfactory frequency regulation service can be provided by the HVAC system without noticeable effect on the indoor climate, and the ancillary service provided by this system passes the qualification criteria for participating in the Pennsylvania-New Jersey-Maryland (PJM) interconnection's frequency regulation market.",
Joint Optimization of Masks and Deep Recurrent Neural Networks for Monaural Source Separation,"Monaural source separation is important for many real world applications. It is challenging because, with only a single channel of information available, without any constraints, an infinite number of solutions are possible. In this paper, we explore joint optimization of masking functions and deep recurrent neural networks for monaural source separation tasks, including speech separation, singing voice separation, and speech denoising. The joint optimization of the deep recurrent neural networks with an extra masking layer enforces a reconstruction constraint. Moreover, we explore a discriminative criterion for training neural networks to further enhance the separation performance. We evaluate the proposed system on the TSP, MIR-1K, and TIMIT datasets for speech separation, singing voice separation, and speech denoising tasks, respectively. Our approaches achieve 2.30-4.98 dB SDR gain compared to NMF models in the speech separation task, 2.30-2.48 dB GNSDR gain and 4.32-5.42 dB GSIR gain compared to existing models in the singing voice separation task, and outperform NMF and DNN baselines in the speech denoising task.",
Hierarchical Coordination of a Community Microgrid With AC and DC Microgrids,"In this paper, a community microgrid with multiple ac and dc microgrids is introduced and analyzed. Individual microgrids with different frequency and voltage requirements would operate as self-controlled entities, which could also cooperate with neighboring microgrids for providing back-up operations in the community microgrid. A hierarchical coordination strategy with primary, secondary, and tertiary coordination is proposed for the economic operation of an islanded community microgrid. The hierarchical strategy is also applied to a grid-connected community microgrid and the results are discussed. The simulation results verify that the proposed hierarchical coordination strategy is an effective and efficient way for coordinating microgrid flows in an islanded community microgrid, while maintaining the rated frequency and voltage with each microgrid. The simulation results also demonstrate the economic operation of a grid-connected community microgrid in which individual microgrids operate as autonomous agents, while satisfying the community objectives.",
Automatic Contrast Enhancement Technology With Saliency Preservation,"In this paper, we investigate the problem of image contrast enhancement. Most existing relevant technologies often suffer from the drawback of excessive enhancement, thereby introducing noise/artifacts and changing visual attention regions. One frequently used solution is manual parameter tuning, which is, however, impractical for most applications since it is labor intensive and time consuming. In this research, we find that saliency preservation can help produce appropriately enhanced images, i.e., improved contrast without annoying artifacts. We therefore design an automatic contrast enhancement technology with a complete histogram modification framework and an automatic parameter selector. This framework combines the original image, its histogram equalized product, and its visually pleasing version created by a sigmoid transfer function that was developed in our recent work. Then, a visual quality judging criterion is developed based on the concept of saliency preservation, which assists the automatic parameters selection, and finally properly enhanced image can be generated accordingly. We test the proposed scheme on Kodak and Video Quality Experts Group databases, and compare with the classical histogram equalization technique and its variations as well as state-of-the-art contrast enhancement approaches. The experimental results demonstrate that our technique has superior saliency preservation ability and outstanding enhancement effect.","Histograms,
Measurement,
Visualization,
Optimization,
Brightness,
Databases,
Integrated circuits"
Evaluating and Improving the Depth Accuracy of Kinect for Windows v2,"Microsoft Kinect sensor has been widely used in many applications since the launch of its first version. Recently, Microsoft released a new version of Kinect sensor with improved hardware. However, the accuracy assessment of the sensor remains to be answered. In this paper, we measure the depth accuracy of the newly released Kinect v2 depth sensor, and obtain a cone model to illustrate its accuracy distribution. We then evaluate the variance of the captured depth values by depth entropy. In addition, we propose a trilateration method to improve the depth accuracy with multiple Kinects simultaneously. The experimental results are provided to ascertain the proposed model and method.","Sensors,
Accuracy,
Cameras,
Noise,
Equations,
Entropy,
Three-dimensional displays"
Decentralized Adaptive Optimal Control of Large-Scale Systems With Application to Power Systems,"This paper studies the optimal control problem for large-scale systems with unknown parameters and dynamics. By using robust adaptive dynamic programming (RADP) method, a decentralized optimal control design is given for large-scale systems with unmatched uncertainties. The convergence of the proposed RADP algorithm and the asymptotic stability of the closed-loop large-scale system are studied rigorously. Finally, a numerical example of a large-scale power system is adopted to illustrate the effectiveness of the obtained algorithm.",
What is a Salient Object? A Dataset and a Baseline Model for Salient Object Detection,"Salient object detection or salient region detection models, diverging from fixation prediction models, have traditionally been dealing with locating and segmenting the most salient object or region in a scene. While the notion of most salient object is sensible when multiple objects exist in a scene, current datasets for evaluation of saliency detection approaches often have scenes with only one single object. We introduce three main contributions in this paper. First, we take an in-depth look at the problem of salient object detection by studying the relationship between where people look in scenes and what they choose as the most salient object when they are explicitly asked. Based on the agreement between fixations and saliency judgments, we then suggest that the most salient object is the one that attracts the highest fraction of fixations. Second, we provide two new less biased benchmark data sets containing scenes with multiple objects that challenge existing saliency models. Indeed, we observed a severe drop in performance of eight state-of-the-art models on our data sets (40%-70%). Third, we propose a very simple yet powerful model based on superpixels to be used as a baseline for model evaluation and comparison. While on par with the best models on MSRA-5 K data set, our model wins over other models on our data highlighting a serious drawback of existing models, which is convoluting the processes of locating the most salient object and its segmentation. We also provide a review and statistical analysis of some labeled scene data sets that can be used for evaluating salient object detection models. We believe that our work can greatly help remedy the over-fitting of models to existing biased data sets and opens new venues for future research in this fast-evolving field.",
Full duplex cognitive radio: a new design paradigm for enhancing spectrum usage,"With the rapid growth of demand for ever increasing data rates, spectrum resources have become more and more scarce. As a promising technique to increase the efficiency of the spectrum utilization, cognitive radio has great potential to meet such a requirement by allowing unlicensed users to coexist in licensed bands. In conventional CR systems, spectrum sensing is performed at the beginning of each time slot before data transmission. Unfortunately, this results in two major problems: transmission time reduction due to sensing, and sensing accuracy impairment due to data transmission. To tackle these problems, in this article we present a new design paradigm for future CR by exploring full duplex techniques to achieve simultaneous spectrum sensing and data transmission. With FD radios equipped at secondary users (SUs), the SUs can simultaneously sense and access the vacant spectrum, and thus significantly improve sensing performance while increasing data transmission efficiency. The aim of this article is to transform the promising conceptual framework into a practical wireless network design by addressing a diverse set of challenges such as protocol design and theoretical analysis. Several application scenarios with FD-enabled CR are elaborated, and key open research directions and novel algorithms in these systems are discussed.","Full duplex communication,
Cognitive radio,
Throughput,
Relays,
Data communication,
Interference,
Transmitting antennas"
Opportunistic Routing Algorithm for Relay Node Selection in Wireless Sensor Networks,"Energy savings optimization becomes one of the major concerns in the wireless sensor network (WSN) routing protocol design, due to the fact that most sensor nodes are equipped with the limited nonrechargeable battery power. In this paper, we focus on minimizing energy consumption and maximizing network lifetime for data relay in one-dimensional (1-D) queue network. Following the principle of opportunistic routing theory, multihop relay decision to optimize the network energy efficiency is made based on the differences among sensor nodes, in terms of both their distance to sink and the residual energy of each other. Specifically, an Energy Saving via Opportunistic Routing (ENS_OR) algorithm is designed to ensure minimum power cost during data relay and protect the nodes with relatively low residual energy. Extensive simulations and real testbed results show that the proposed solution ENS_OR can significantly improve the network performance on energy saving and wireless connectivity in comparison with other existing WSN routing schemes.",
Impulsive Stabilization and Impulsive Synchronization of Discrete-Time Delayed Neural Networks,"This paper investigates the problems of impulsive stabilization and impulsive synchronization of discrete-time delayed neural networks (DDNNs). Two types of DDNNs with stabilizing impulses are studied. By introducing the time-varying Lyapunov functional to capture the dynamical characteristics of discrete-time impulsive delayed neural networks (DIDNNs) and by using a convex combination technique, new exponential stability criteria are derived in terms of linear matrix inequalities. The stability criteria for DIDNNs are independent of the size of time delay but rely on the lengths of impulsive intervals. With the newly obtained stability results, sufficient conditions on the existence of linear-state feedback impulsive controllers are derived. Moreover, a novel impulsive synchronization scheme for two identical DDNNs is proposed. The novel impulsive synchronization scheme allows synchronizing two identical DDNNs with unknown delays. Simulation results are given to validate the effectiveness of the proposed criteria of impulsive stabilization and impulsive synchronization of DDNNs. Finally, an application of the obtained impulsive synchronization result for two identical chaotic DDNNs to a secure communication scheme is presented.","Synchronization,
Biological neural networks,
Delays,
Mathematical model,
Stability criteria"
Vehicular Communications: Survey and Challenges of Channel and Propagation Models,"Vehicular communication is characterized by a dynamic environment, high mobility, and comparatively low antenna heights on the communicating entities (vehicles and roadside units). These characteristics make vehicular propagation and channel modeling particularly challenging. In this article, we classify and describe the most relevant vehicular propagation and channel models, with a particular focus on the usability of the models for the evaluation of protocols and applications. We first classify the models based on the propagation mechanisms they employ and their implementation approach. We also classify the models based on the channel properties they implement and pay special attention to the usability of the models, including the complexity of implementation, scalability, and the input requirements (e.g., geographical data input). We also discuss the less-explored aspects in vehicular channel modeling, including modeling specific environments (e.g., tunnels, overpasses, and parking lots) and types of communicating vehicles (e.g., scooters and public transportation vehicles). We conclude by identifying the underresearched aspects of vehicular propagation and channel modeling that require further modeling and measurement studies.","Intelligent vehicles,
Channel modeling,
Road traffic,
Data models,
Receivers,
Vehicle ad hoc networks,
Mobile communication,
Vehicular automation"
"FlierMeet: A Mobile Crowdsensing System for Cross-Space Public Information Reposting, Tagging, and Sharing","Community bulletin boards serve an important function for public information sharing in modern society. Posted fliers advertise services, events, and other announcements. However, fliers posted offline suffer from problems such as limited spatial-temporal coverage and inefficient search support. In recent years, with the development of sensor-enhanced mobile devices, mobile crowd sensing (MCS) has been used in a variety of application areas. This paper presents FlierMeet, a crowd-powered sensing system for cross-space public information reposting, tagging, and sharing. The tags learned are useful for flier sharing and preferred information retrieval and suggestion. Specifically, we utilize various contexts (e.g., spatio-temporal info, flier publishing/reposting behaviors, etc.) and textual features to group similar reposts and classify them into categories. We further identify a novel set of crowd-object interaction hints to predict the semantic tags of reposts. To evaluate our system, 38 participants were recruited and 2,035 reposts were captured during an eight-week period. Experiments on this dataset showed that our approach to flier grouping is effective and the proposed features are useful for flier category/semantic tagging.","Semantics,
Sensors,
Mobile communication,
Communities,
Tagging,
Context,
Feature extraction"
Holistic Atlases of Functional Networks and Interactions Reveal Reciprocal Organizational Architecture of Cortical Function,"For decades, it has been largely unknown to what extent multiple functional networks spatially overlap/interact with each other and jointly realize the total cortical function. Here, by developing novel sparse representation of whole-brain fMRI signals and by using the recently publicly released large-scale Human Connectome Project high-quality fMRI data, we show that a number of reproducible and robust functional networks, including both task-evoked and resting state networks, are simultaneously distributed in distant neuroanatomic areas and substantially spatially overlapping with each other, thus forming an initial collection of holistic atlases of functional networks and interactions (HAFNIs). More interestingly, the HAFNIs revealed two distinct patterns of highly overlapped regions and highly specialized regions and exhibited that these two patterns of areas are reciprocally localized, revealing a novel organizational principle of cortical function.","Sparse matrices,
Computer architecture,
Encoding,
Visualization,
Correlation"
COUPON: A Cooperative Framework for Building Sensing Maps in Mobile Opportunistic Networks,"Human-carried or vehicle-mounted sensors can be exploited to collect data ubiquitously for building various sensing maps. Most of existing mobile sensing applications consider users reporting and accessing sensing data through the Internet. However, this approach cannot be applied in the scenarios with poor network coverage or expensive network access. Existing data forwarding schemes for mobile opportunistic networks are not sufficient for sensing applications as spatial-temporal correlation among sensory data has not been explored. In order to build sensing maps satisfying specific sensing quality with low delay and energy consumption, we design COUPON, a novel cooperative sensing and data forwarding framework. We first notice that cooperative sensing scheme can eliminate sampling redundancy and hence save energy. Then we design two cooperative forwarding schemes by leveraging data fusion: Epidemic Routing with Fusion (ERF) and Binary Spray-and-Wait with Fusion (BSWF). Different from previous work assuming that all packets are propagated independently, we consider that packets are spatial-temporal correlated in the forwarding process, and derive the dissemination law of correlated packets. Both the theoretic analysis and simulation results show that our cooperative forwarding schemes can achieve better tradeoff between delivery delay and transmission overhead. We also evaluate our proposed framework and schemes with real mobile traces. Extensive simulations demonstrate that the cooperative sensing scheme can reduce the number of samplings by 93 percent compared with the non-cooperative scheme; ERF can reduce the transmission overhead by 78 percent compared with Epidemic Routing (ER); BSWF can increase the delivery ratio by 16 percent, and reduce the delivery delay and transmission overhead by 5 and 32 percent respectively, compared with Binary Spray-and-Wait (BSW).","Sensors,
Data integration,
Delays,
Mobile communication,
Monitoring,
Protocols,
Mobile computing"
Software-Defined Networking for RSU Clouds in Support of the Internet of Vehicles,"We propose a novel roadside unit (RSU) cloud, a vehicular cloud, as the operational backbone of the vehicle grid in the Internet of Vehicles (IoV). The architecture of the proposed RSU cloud consists of traditional and specialized RSUs employing software-defined networking (SDN) to dynamically instantiate, replicate, and/or migrate services. We leverage the deep programmability of SDN to dynamically reconfigure the services hosted in the network and their data forwarding information to efficiently serve the underlying demand from the vehicle grid. We then present a detailed reconfiguration overhead analysis to reduce reconfigurations, which are costly for service providers. We use the reconfiguration cost analysis to design and formulate an integer linear programming (ILP) problem to model our novel RSU cloud resource management (CRM). We begin by solving for the Pareto optimal frontier (POF) of nondominated solutions, such that each solution is a configuration that minimizes either the number of service instances or the RSU cloud infrastructure delay, for a given average demand. Then, we design an efficient heuristic to minimize the reconfiguration costs. A fundamental contribution of our heuristic approach is the use of reinforcement learning to select configurations that minimize reconfiguration costs in the network over the long term. We perform reconfiguration cost analysis and compare the results of our CRM formulation and heuristic. We also show the reduction in reconfiguration costs when using reinforcement learning in comparison to a myopic approach. We show significant improvement in the reconfigurations costs and infrastructure delay when compared to purist service installations.",
Sparsity-Exploiting Moment-Based Relaxations of the Optimal Power Flow Problem,"Convex relaxations of non-convex optimal power flow (OPF) problems have recently attracted significant interest. While existing relaxations globally solve many OPF problems, there are practical problems for which existing relaxations fail to yield physically meaningful solutions. This paper applies moment relaxations to solve many of these OPF problems. The moment relaxations are developed from the Lasserre hierarchy for solving generalized moment problems. Increasing the relaxation order in this hierarchy results in “tighter” relaxations at the computational cost of larger semidefinite programs. Low-order moment relaxations are capable of globally solving many small OPF problems for which existing relaxations fail. By exploiting sparsity and only applying the higher-order relaxation to specific buses, global solutions to larger problems are computationally tractable through the use of an iterative algorithm informed by a heuristic for choosing where to apply the higher-order constraints. With standard semidefinite programming solvers, the algorithm globally solves many test systems with up to 300 buses for which the existing semidefinite relaxation fails to yield globally optimal solutions.","Relaxation methods,
Load flow,
Optimization,
Mathematical model,
Reactive power"
Multiresolution Graph Fourier Transform for Compression of Piecewise Smooth Images,"Piecewise smooth (PWS) images (e.g., depth maps or animation images) contain unique signal characteristics such as sharp object boundaries and slowly varying interior surfaces. Leveraging on recent advances in graph signal processing, in this paper, we propose to compress the PWS images using suitable graph Fourier transforms (GFTs) to minimize the total signal representation cost of each pixel block, considering both the sparsity of the signal's transform coefficients and the compactness of transform description. Unlike fixed transforms, such as the discrete cosine transform, we can adapt GFT to a particular class of pixel blocks. In particular, we select one among a defined search space of GFTs to minimize total representation cost via our proposed algorithms, leveraging on graph optimization techniques, such as spectral clustering and minimum graph cuts. Furthermore, for practical implementation of GFT, we introduce two techniques to reduce computation complexity. First, at the encoder, we low-pass filter and downsample a high-resolution (HR) pixel block to obtain a low-resolution (LR) one, so that a LR-GFT can be employed. At the decoder, upsampling and interpolation are performed adaptively along HR boundaries coded using arithmetic edge coding, so that sharp object boundaries can be well preserved. Second, instead of computing GFT from a graph in real-time via eigen-decomposition, the most popular LR-GFTs are pre-computed and stored in a table for lookup during encoding and decoding. Using depth maps and computer-graphics images as examples of the PWS images, experimental results show that our proposed multiresolution-GFT scheme outperforms H.264 intra by 6.8 dB on average in peak signal-to-noise ratio at the same bit rate.","Image coding,
Discrete cosine transforms,
Decoding,
Image edge detection,
Transform coding,
Laplace equations"
Optimization Methods for Designing Sequences With Low Autocorrelation Sidelobes,"Unimodular sequences with low autocorrelation are desired in many applications, especially in radar systems and code-division multiple access (CDMA) communication systems. In this paper, we propose a new algorithm to design unimodular sequences with low autocorrelation via directly minimizing the integrated sidelobe level (ISL) of the autocorrelation. The algorithm is derived based on the general framework of majorization-minimization (MM) algorithms and thus shares the monotonic property of such methods, and two acceleration schemes have been considered to accelerate the overall convergence. In addition, the proposed algorithm can be implemented via fast Fourier transform (FFT) operations and thus is computationally efficient. Furthermore, after some modifications the algorithm can be adapted to incorporate spectral constraints, which makes the design more flexible. Numerical experiments show that the proposed algorithms outperform existing ones in terms of both the merit factors of designed sequences and the computational complexity.",
Secure Control Systems: A Quantitative Risk Management Approach,"Critical infrastructures must continuously operate safely and reliably, despite a variety of potential system disturbances. Given their strict operating requirements, such systems are automated and controlled in real time by several digital controllers receiving measurements from sensors and transmitting control signals to actuators. Since these physical systems are often spatially distributed, there is a need for information technology (IT) infrastructures enabling the timely data flow between the system components. These networked control systems are ubiquitous in modern societies [1]. Examples include the electric power network, intelligent transport systems, and industrial processes.","Networked control systems,
Computer crime,
Communication networks,
Detectors,
Risk management,
Power systems planning,
Computer security"
The Impact of API Change- and Fault-Proneness on the User Ratings of Android Apps,"The mobile apps market is one of the fastest growing areas in the information technology. In digging their market share, developers must pay attention to building robust and reliable apps. In fact, users easily get frustrated by repeated failures, crashes, and other bugs; hence, they abandon some apps in favor of their competition. In this paper we investigate how the fault- and change-proneness of APIs used by Android apps relates to their success estimated as the average rating provided by the users to those apps. First, in a study conducted on 5,848 (free) apps, we analyzed how the ratings that an app had received correlated with the fault- and change-proneness of the APIs such app relied upon. After that, we surveyed 45 professional Android developers to assess (i) to what extent developers experienced problems when using APIs, and (ii) how much they felt these problems could be the cause for unfavorable user ratings. The results of our studies indicate that apps having high user ratings use APIs that are less fault- and change-prone than the APIs used by low rated apps. Also, most of the interviewed Android developers observed, in their development experience, a direct relationship between problems experienced with the adopted APIs and the users' ratings that their apps received.",
Multiple/Single-View Human Action Recognition via Part-Induced Multitask Structural Learning,"This paper proposes a unified framework for multiple/single-view human action recognition. First, we propose the hierarchical partwise bag-of-words representation which encodes both local and global visual saliency based on the body structure cue. Then, we formulate the multiple/single-view human action recognition as a part-regularized multitask structural learning (MTSL) problem which has two advantages on both model learning and feature selection: 1) preserving the consistence between the body-based action classification and the part-based action classification with the complementary information among different action categories and multiple views and 2) discovering both action-specific and action-shared feature subspaces to strengthen the generalization ability of model learning. Moreover, we contribute two novel human action recognition datasets, TJU (a single-view multimodal dataset) and MV-TJU (a multiview multimodal dataset). The proposed method is validated on three kinds of challenging datasets, including two single-view RGB datasets (KTH and TJU), two well-known depth dataset (MSR action 3-D and MSR daily activity 3-D), and one novel multiview multimodal dataset (MV-TJU). The extensive experimental results show that this method can outperform the popular 2-D/3-D part model-based methods and several other competing methods for multiple/single-view human action recognition in both RGB and depth modalities. To our knowledge, this paper is the first to demonstrate the applicability of MTSL with part-based regularization on multiple/single-view human action recognition in both RGB and depth modalities.","Hidden Markov models,
Visualization,
Feature extraction,
Joints,
Spatiotemporal phenomena,
Correlation"
Multi-Agent Distributed Optimization via Inexact Consensus ADMM,"Multi-agent distributed consensus optimization problems arise in many signal processing applications. Recently, the alternating direction method of multipliers (ADMM) has been used for solving this family of problems. ADMM based distributed optimization method is shown to have faster convergence rate compared with classic methods based on consensus subgradient, but can be computationally expensive, especially for problems with complicated structures or large dimensions. In this paper, we propose low-complexity algorithms that can reduce the overall computational cost of consensus ADMM by an order of magnitude for certain large-scale problems. Central to the proposed algorithms is the use of an inexact step for each ADMM update, which enables the agents to perform cheap computation at each iteration. Our convergence analyses show that the proposed methods converge well under some convexity assumptions. Numerical results show that the proposed algorithms offer considerably lower computational complexity than the standard ADMM based distributed optimization methods.",
Matrix-Monotonic Optimization for MIMO Systems,"For MIMO systems, due to the deployment of multiple antennas at both the transmitter and the receiver, the design variables, e.g., precoders, equalizers, and training sequences, are usually matrices. It is well known that matrix operations are usually more complicated compared with their vector counterparts. In order to overcome the high complexity resulting from matrix variables, in this paper, we investigate a class of elegant multi-objective optimization problems, namely matrix-monotonic optimization problems (MMOPs). In our work, various representative MIMO optimization problems are unified into a framework of matrix-monotonic optimization, which includes linear transceiver design, nonlinear transceiver design, training sequence design, radar waveform optimization, the corresponding robust design and so on as its special cases. Then, exploiting the framework of matrix-monotonic optimization the optimal structures of the considered matrix variables can be derived first. Based on the optimal structure, the matrix-variate optimization problems can be greatly simplified into the ones with only vector variables. In particular, the dimension of the new vector variable is equal to the minimum number of columns and rows of the original matrix variable. Finally, we also extend our work to some more general cases with multiple matrix variables.","Optimization,
MIMO,
Transceivers,
Robustness,
Linear programming,
Training,
Vectors"
"Comparative Study of Interior Permanent Magnet, Induction, and Switched Reluctance Motor Drives for EV and HEV Applications","With rapid electrification of transportation, it is becoming increasingly important to have a comprehensive understanding of criteria used in motor selection. This paper presents the design and comparative evaluation for an interior permanent magnet synchronous motor (IPMSM) with distributed winding and concentrated winding, induction motor (IM), and switched reluctance motor (SRM) for an electric vehicle (EV) or hybrid electric vehicle (HEV) application. A fast finite element analysis (FEA) modeling approach is addressed for IM design. To account for highly nonlinear motor parameters and achieve high motor efficiency, optimal current trajectories are obtained by extensive mapping for IPMSMs and IM. Optimal turn-ON and turn-OFF angles with current chopping control and angular position control are found for SRM. Additional comparison including noise vibration and harshness (NVH) is also highlighted. Simulation and analytical results show that each motor topology demonstrates its own unique characteristic for EVs/HEVs. Each motor's highest efficiency region is located at different torque-speed regions for the criteria defined. Stator geometry, pole/slot combination, and control strategy differentiate NVH performance.","Torque,
Reluctance motors,
Traction motors,
Rotors,
Stator windings,
Permanent magnet motors"
WiGest: A ubiquitous WiFi-based gesture recognition system,"We present WiGest: a system that leverages changes in WiFi signal strength to sense in-air hand gestures around the user's mobile device. Compared to related work, WiGest is unique in using standard WiFi equipment, with no modifications, and no training for gesture recognition. The system identifies different signal change primitives, from which we construct mutually independent gesture families. These families can be mapped to distinguishable application actions. We address various challenges including cleaning the noisy signals, gesture type and attributes detection, reducing false positives due to interfering humans, and adapting to changing signal polarity. We implement a proof-of-concept prototype using off-the-shelf laptops and extensively evaluate the system in both an office environment and a typical apartment with standard WiFi access points. Our results show that WiGest detects the basic primitives with an accuracy of 87.5% using a single AP only, including through-the-wall non-line-of-sight scenarios. This accuracy increases to 96% using three overheard APs. In addition, when evaluating the system using a multi-media player application, we achieve a classification accuracy of 96%. This accuracy is robust to the presence of other interfering humans, highlighting WiGest's ability to enable future ubiquitous hands-free gesture-based interaction with mobile devices.","Image edge detection,
Discrete wavelet transforms,
Accuracy,
Mobile handsets,
Gesture recognition,
IEEE 802.11 Standard,
Wireless communication"
Passivity and Passification of Memristor-Based Recurrent Neural Networks With Additive Time-Varying Delays,"This paper presents a new design scheme for the passivity and passification of a class of memristor-based recurrent neural networks (MRNNs) with additive time-varying delays. The predictable assumptions on the boundedness and Lipschitz continuity of activation functions are formulated. The systems considered here are based on a different time-delay model suggested recently, which includes additive time-varying delay components in the state. The connection between the time-varying delay and its upper bound is considered when estimating the upper bound of the derivative of Lyapunov functional. It is recognized that the passivity condition can be expressed in a linear matrix inequality (LMI) format and by using characteristic function method. For state feedback passification, it is verified that it is apathetic to use immediate or delayed state feedback. By constructing a Lyapunov-Krasovskii functional and employing Jensen's inequality and reciprocal convex combination technique together with a tighter estimation of the upper bound of the cross-product terms derived from the derivatives of the Lyapunov functional, less conventional delay-dependent passivity criteria are established in terms of LMIs. Moreover, second-order reciprocally convex approach is employed for deriving the upper bound for terms with inverses of squared convex parameters. The model based on the memristor with additive time-varying delays widens the application scope for the design of neural networks. Finally, pertinent examples are given to show the advantages of the derived passivity criteria and the significant improvement of the theoretical approaches.","Delays,
Additives,
Memristors,
Symmetric matrices,
Time-varying systems,
Stability analysis,
Recurrent neural networks"
Transfer Learning for Visual Categorization: A Survey,"Regular machine learning and data mining techniques study the training data for future inferences under a major assumption that the future data are within the same feature space or have the same distribution as the training data. However, due to the limited availability of human labeled training data, training data that stay in the same feature space or have the same distribution as the future data cannot be guaranteed to be sufficient enough to avoid the over-fitting problem. In real-world applications, apart from data in the target domain, related data in a different domain can also be included to expand the availability of our prior knowledge about the target future data. Transfer learning addresses such cross-domain learning problems by extracting useful information from data in a related domain and transferring them for being used in target tasks. In recent years, with transfer learning being applied to visual categorization, some typical problems, e.g., view divergence in action recognition tasks and concept drifting in image classification tasks, can be efficiently solved. In this paper, we survey state-of-the-art transfer learning algorithms in visual categorization applications, such as object recognition, image classification, and human action recognition.","Knowledge transfer,
Visualization,
Training,
Training data,
Adaptation models,
Learning systems,
Testing"
"Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions","The large number of potential applications from bridging web data with knowledge bases have led to an increase in the entity linking research. Entity linking is the task to link entity mentions in text with their corresponding entities in a knowledge base. Potential applications include information extraction, information retrieval, and knowledge base population. However, this task is challenging due to name variations and entity ambiguity. In this survey, we present a thorough overview and analysis of the main approaches to entity linking, and discuss various applications, the evaluation of entity linking systems, and future directions.","Joining processes,
Knowledge based systems,
Encyclopedias,
Internet,
Electronic publishing,
Couplings"
Deploying Wireless Sensor Networks with Fault-Tolerance for Structural Health Monitoring,"Structural health monitoring (SHM) systems are implemented for structures (e.g., bridges, buildings) to monitor their operations and health status. Wireless sensor networks (WSNs) are becoming an enabling technology for SHM applications that are more prevalent and more easily deployable than traditional wired networks. However, SHM brings new challenges to WSNs: engineering-driven optimal deployment, a large volume of data, sophisticated computing, and so forth. In this paper, we address two important challenges: sensor deployment and decentralized computing. We propose a solution, to deploy wireless sensors at strategic locations to achieve the best estimates of structural health (e.g., damage) by following the widely used wired sensor system deployment approach from civil/structural engineering. We found that faults (caused by communication errors, unstable connectivity, sensor faults, etc.) in such a deployed WSN greatly affect the performance of SHM. To make the WSN resilient to the faults, we present an approach, called FTSHM (fault-tolerance in SHM), to repair the WSN and guarantee a specified degree of fault tolerance. FTSHM searches the repairing points in clusters in a distributed manner, and places a set of backup sensors at those points in such a way that still satisfies the engineering requirements. FTSHM also includes an SHM algorithm suitable for decentralized computing in the energy-constrained WSN, with the objective of guaranteeing that the WSN for SHM remains connected in the event of a fault, thus prolonging the WSN lifetime under connectivity and data delivery constraints. We demonstrate the advantages of FTSHM through extensive simulations and real experimental settings on a physical structure.","Wireless sensor networks,
Shape,
Monitoring,
Fault tolerance,
Fault tolerant systems,
Vibrations,
Bridges"
A Novel Observer-Based Output Feedback Controller Design for Discrete-Time Fuzzy Systems,"This paper addresses the problem of observer-based output feedback controller designs for discrete-time T-S fuzzy systems based on a relaxed approach in which the fuzzy Lyapunov functions are used. Different from the existing two-step method, a single-step linear matrix inequality method is provided for the observer-based controller design. It is shown that the controller and observer parameters can be obtained by solving a set of strict linear matrix inequalities that are numerically feasible with commercially available software. The new design method not only overcomes the drawback induced by the two-step approach but also provides less conservative results over some existing results. Finally, the effectiveness of the proposed approach is demonstrated by an example.","Observers,
Fuzzy systems,
Linear matrix inequalities,
Output feedback,
Lyapunov methods"
Single-Phase On-Board Bidirectional PEV Charger for V2G Reactive Power Operation,"This paper presents the design and implementation of a single-phase on-board bidirectional plug-in electric vehicle (PEV) charger that can provide reactive power support to the utility grid in addition to charging the vehicle battery. The topology consists of two-stages: a full-bridge ac-dc boost converter; and a half-bridge bidirectional dc-dc converter. The charger operates in two quadrants in the active-reactive power (PQ) power plane with five different operation modes (i.e., charging-only, charging-capacitive, charging-inductive, capacitive-only, and inductive-only). This paper also presents a unified controller to follow utility PQ commands in a smart grid environment. The cascaded two-stage system controller receives active and reactive power commands from the grid, and results in line current and battery charging current references while also providing a stable dynamic response. The vehicle's battery is not affected during reactive power operation in any of the operation modes. Testing the unified system controller with a 1.44 kVA experimental charger design demonstrates the successful implementation of reactive power support functionality of PEVs for future smart grid applications.",
Discovering Urban Functional Zones Using Latent Activity Trajectories,"The step of urbanization and modern civilization fosters different functional zones in a city, such as residential areas, business districts, and educational areas. In a metropolis, people commute between these functional zones every day to engage in different socioeconomic activities, e.g., working, shopping, and entertaining. In this paper, we propose a data-driven framework to discover functional zones in a city. Specifically, we introduce the concept of latent activity trajectory (LAT), which captures socioeconomic activities conducted by citizens at different locations in a chronological order. Later, we segment an urban area into disjointed regions according to major roads, such as highways and urban expressways. We have developed a topic-modeling-based approach to cluster the segmented regions into functional zones leveraging mobility and location semantics mined from LAT. Furthermore, we identify the intensity of each functional zone using Kernel Density Estimation. Extensive experiments are conducted with several urban scale datasets to show that the proposed framework offers a powerful ability to capture city dynamics and provides valuable calibrations to urban planners in terms of functional zones.","Roads,
Semantics,
Trajectory,
Urban areas,
Collaboration,
Image segmentation"
Deep Reconstruction Models for Image Set Classification,"Image set classification finds its applications in a number of real-life scenarios such as classification from surveillance videos, multi-view camera networks and personal albums. Compared with single image based classification, it offers more promises and has therefore attracted significant research attention in recent years. Unlike many existing methods which assume images of a set to lie on a certain geometric surface, this paper introduces a deep learning framework which makes no such prior assumptions and can automatically discover the underlying geometric structure. Specifically, a Template Deep Reconstruction Model (TDRM) is defined whose parameters are initialized by performing unsupervised pre-training in a layer-wise fashion using Gaussian Restricted Boltzmann Machines (GRBMs). The initialized TDRM is then separately trained for images of each class and class-specific DRMs are learnt. Based on the minimum reconstruction errors from the learnt class-specific models, three different voting strategies are devised for classification. Extensive experiments are performed to demonstrate the efficacy of the proposed framework for the tasks of face and object recognition from image sets. Experimental results show that the proposed method consistently outperforms the existing state of the art methods.","Training,
Image reconstruction,
Manifolds,
Decoding,
Vectors,
Data models,
Surface reconstruction"
Improving Differential Evolution With a Successful-Parent-Selecting Framework,"An effective and efficient successful-parent-selecting framework is proposed to improve the performance of differential evolution (DE) by providing an alternative for the selection of parents during mutation and crossover. The proposed method adapts the selection of parents by storing successful solutions into an archive, and the parents are selected from the archive when a solution is continuously not updated for an unacceptable amount of time. The proposed framework provides more promising solutions to guide the evolution and effectively helps DE escaping the situation of stagnation. The simulation results show that the proposed framework significantly improves the performance of two original DEs and six state-of-the-art algorithms in four real-world optimization problems and 30 benchmark functions.","Vectors,
Sociology,
Statistics,
Optimization,
Linear programming,
Upper bound,
Benchmark testing"
Energy Efficient Virtual Network Embedding for Cloud Networks,"Network virtualization is widely considered to be one of the main paradigms for the future Internet architecture as it provides a number of advantages including scalability, on demand allocation of network resources, and the promise of efficient use of network resources. In this paper, we propose an energy efficient virtual network embedding (EEVNE) approach for cloud computing networks, where power savings are introduced by consolidating resources in the network and data centers. We model our approach in an IP over WDM network using mixed integer linear programming (MILP). The performance of the EEVNE approach is compared with two approaches from the literature: the bandwidth cost approach (CostVNE) and the energy aware approach (VNE-EA). The CostVNE approach optimizes the use of available bandwidth, while the VNE-EA approach minimizes the power consumption by reducing the number of activated nodes and links without taking into account the granular power consumption of the data centers and the different network devices. The results show that the EEVNE model achieves a maximum power saving of 60% (average 20%) compared to the CostVNE model under an energy inefficient data center power profile. We develop a heuristic, real-time energy optimized VNE (REOViNE), with power savings approaching those of the EEVNE model. We also compare the different approaches adopting an energy efficient data center power profile. Furthermore, we study the impact of delay and node location constraints on the energy efficiency of virtual network embedding. We also show how VNE can impact the design of optimally located data centers for minimal power consumption in cloud networks. Finally, we examine the power savings and spectral efficiency benefits that VNE offers in optical orthogonal division multiplexing networks.",
Arbitraging Intraday Wholesale Energy Market Prices With Aggregations of Thermostatic Loads,"We investigate the potential for aggregations of residential thermostatically controlled loads (TCLs), such as air conditioners, to arbitrage intraday wholesale electricity market prices via non-disruptive load control. We present two arbitrage approaches: 1) a benchmark that gives us an optimal policy but requires local computation or real-time communication and 2) an alternative based on a thermal energy storage model, which relies on less computation/communication infrastructure, but is suboptimal. We find that the alternative approach achieves around 60%-80% of the optimal wholesale energy cost savings. We use this approach to compute practical upper bounds for savings via arbitrage with air conditioners in California's intraday energy market. We investigate six sites over four years and find that the savings range from 2-
37 per TCL per year, and depend upon outdoor temperature statistics and price volatility.","Computational modeling,
Energy storage,
Switches,
Thermal energy,
Aggregates,
Load modeling,
Power demand"
Evaluation of output embeddings for fine-grained image classification,"Image classification has advanced significantly in recent years with the availability of large-scale image sets. However, fine-grained classification remains a major challenge due to the annotation cost of large numbers of fine-grained categories. This project shows that compelling classification performance can be achieved on such categories even without labeled training data. Given image and class embeddings, we learn a compatibility function such that matching embeddings are assigned a higher score than mismatching ones; zero-shot classification of an image proceeds by finding the label yielding the highest joint compatibility score. We use state-of-the-art image features and focus on different supervised attributes and unsupervised output embeddings either derived from hierarchies or learned from unlabeled text corpora. We establish a substantially improved state-of-the-art on the Animals with Attributes and Caltech-UCSD Birds datasets. Most encouragingly, we demonstrate that purely unsupervised output embeddings (learned from Wikipedia and improved with finegrained text) achieve compelling results, even outperforming the previous supervised state-of-the-art. By combining different output embeddings, we further improve results.","Context,
Joints,
Encyclopedias,
Electronic publishing,
Internet,
Vocabulary"
Indirect Finite Control Set Model Predictive Control of Modular Multilevel Converters,"The modular multilevel converter (MMC) is a potential candidate for medium/high-power applications, specifically for high-voltage direct current transmission systems. One of the main challenges in the control of an MMC is to eliminate/minimize the circulating currents while the capacitor voltages are maintained balanced. This paper proposes a control strategy for the MMC using finite control set model predictive control (FCS-MPC). A bilinear mathematical model of the MMC is derived and discretized to predict the states of the MMC one step ahead. Within each switching cycle, the best switching state of the MMC is selected based on evaluation and minimization of a defined cost function. The defined cost function is aimed at the elimination of the MMC circulating currents, regulating the arm voltages, and controlling the ac-side currents. To reduce the calculation burden of the MPC, the submodule (SM) capacitor voltage balancing controller based on the conventional sorting method is combined with the proposed FCS-MPC strategy. The proposed FCS-MPC strategy determines the number of inserted/bypassed SMs within each arm of the MMC while the sorting algorithm is used to keep the SM capacitor voltages balanced. Using this strategy, only the summation of SM capacitor voltages of each arm is required for control purposes, which simplifies the communication among the SMs and the central controller. This paper also introduces a modified switching strategy, which not only reduces the calculation burden of the FCS-MPC strategy even more, but also simplifies the SM capacitor voltage balancing algorithm. In addition, this strategy reduces the SM switching frequency and power losses by avoiding the unnecessary switching transitions. The performance of the proposed strategies for a 20-level MMC is evaluated based on the time-domain simulation studies.","Capacitors,
Switches,
Voltage control,
Cost function,
Indexes,
Mathematical model,
Sorting"
Black Phosphorus p-MOSFETs With 7-nm HfO2 Gate Dielectric and Low Contact Resistance,"We report record contact resistance and transconductance in locally back-gated black phosphorus p-MOSFETs with 7-nm thick HfO2 gate dielectrics. Devices with effective gate lengths, Leff, from 0.55 to 0.17 μm were characterized and shown to have contact resistance values as low as 1.14 ± 0.05 Q-mm. In addition, devices with Leff = 0.17 μm displayed extrinsic transconductance exceeding 250 μS/μm and ON-state current approaching 300 μA/μm.",
Exponential Stabilization of Memristor-based Chaotic Neural Networks with Time-Varying Delays via Intermittent Control,"This paper is concerned with the global exponential stabilization of memristor-based chaotic neural networks with both time-varying delays and general activation functions. Here, we adopt nonsmooth analysis and control theory to handle memristor-based chaotic neural networks with discontinuous right-hand side. In particular, several new sufficient conditions ensuring exponential stabilization of memristor-based chaotic neural networks are obtained via periodically intermittent control. In addition, the proposed results here are easy to verify and they also extend the earlier publications. Finally, numerical simulations illustrate the effectiveness of the obtained results.","Biological neural networks,
Memristors,
Delays,
Chaos,
Neurons,
Asymptotic stability"
Goodput-Aware Load Distribution for Real-Time Traffic over Multipath Networks,"Load distribution is a key research issue in deploying the limited network resources available to support traffic transmissions. Developing an effective solution is critical for enhancing traffic performance and network utilization. In this paper, we investigate the problem of load distribution for real-time traffic over multipath networks. Due to the path diversity and unreliability in heterogeneous overlay networks, large end-to-end delay and consecutive packet losses can significantly degrade the traffic flow's goodput, whereas existing studies mainlyfocus on the delay or throughput performance. To address the challenging problems, we propose a Goodput-Aware Load distribuTiON (GALTON) model that includes three phases: (1) path status estimation to accurately sense the quality of each transport link, (2) flow rate assignment to optimize the aggregate goodput of input traffic, and (3) deadline-constrained packet interleaving to mitigate consecutive losses. We present a mathematical formulation for multipath load distribution and derive the solution based on utility theory. The performance of the proposed model is evaluated through semi-physical emulations in Exata involving both real Internet traffic traces and H.264 video streaming. Experimental results show that GALTON outperforms existing traffic distribution models in terms of goodput, video Peak Signal-to-Noise Ratio (PSNR), end-to-end delay, and aggregate loss rate.","Delays,
Load modeling,
Real-time systems,
Radio frequency,
Bandwidth,
Aggregates,
Packet loss"
Physical layer security in wireless cooperative relay networks: state of the art and beyond,"Cooperative relaying is an effective method of increasing the range and reliability of wireless networks, and several relaying strategies have been adopted in major wireless standards. Recently, cooperative relaying has also been considered in the context of PHY security, which is a new security paradigm to supplement traditional cryptographic schemes that usually handle security at the upper layers. In wireless PHY security, relay nodes can be used to exploit the physical layer properties of wireless channels in order to support a secured transmission from a source to a destination in the presence of one or more eavesdroppers. While some breakthroughs have been made in this emerging research area, to date, the problem of how to effectively adopt advanced relaying protocols to enhance PHY security is still far from being fully understood. In this article, we present a comprehensive summary of current state-of-theart PHY security concepts in wireless relay networks. A case study is then provided to quantify the benefits of power allocation and relay location for enhanced security. We finally outline important future research directions in relaying topologies, full-duplex relaying, and cross-layer design that can ignite new interests and ideas on the topic.","Network security,
Wireless networks,
Communication system security,
Relay networks (telecommunications),
Physical layer,
Relays"
Adaptive Synchronization of Memristor-Based Neural Networks with Time-Varying Delays,"In this paper, adaptive synchronization of memristor-based neural networks (MNNs) with time-varying delays is investigated. The dynamical analysis here employs results from the theory of differential equations with discontinuous right-hand sides as introduced by Filippov. Sufficient conditions for the global synchronization of MNNs are established with a general adaptive controller. The update gain of the controller can be adjusted to control the synchronization speed. The obtained results complement and improve the previously known results. Finally, numerical simulations are carried out to demonstrate the effectiveness of the obtained results.",
Acoustic Scene Classification: Classifying environments from the sounds they produce,"In this article, we present an account of the state of the art in acoustic scene classification (ASC), the task of classifying environments from the sounds they produce. Starting from a historical review of previous research in this area, we define a general framework for ASC and present different implementations of its components. We then describe a range of different algorithms submitted for a data challenge that was held to provide a general and fair benchmark for ASC techniques. The data set recorded for this purpose is presented along with the performance metrics that are used to evaluate the algorithms and statistical significance tests to compare the submitted methods.","Feature extraction,
Acoustics,
Hidden Markov models,
Classification algorithms,
Frequency measurement,
Signal processing algorithms,
Image analysis"
RGB-D object recognition and pose estimation based on pre-trained convolutional neural network features,"Object recognition and pose estimation from RGB-D images are important tasks for manipulation robots which can be learned from examples. Creating and annotating datasets for learning is expensive, however. We address this problem with transfer learning from deep convolutional neural networks (CNN) that are pre-trained for image categorization and provide a rich, semantically meaningful feature set. We incorporate depth information, which the CNN was not trained with, by rendering objects from a canonical perspective and colorizing the depth channel according to distance from the object center. We evaluate our approach on the Washington RGB-D Objects dataset, where we find that the generated feature set naturally separates classes and instances well and retains pose manifolds. We outperform state-of-the-art on a number of subtasks and show that our approach can yield superior results when only little training data is available.","Feature extraction,
Image color analysis,
Training,
Support vector machines,
Estimation,
Pipelines,
Accuracy"
Model-Based Predictive Direct Control Strategies for Electrical Drives: An Experimental Evaluation of PTC and PCC Methods,"Model-based predictive direct control methods are advanced control strategies in the field of power electronics. To control an induction machine (IM), the predictive torque control (PTC) method evaluates the electromagnetic torque and stator flux in the cost function. The switching vector selected for the use in the insulated gate bipolar transistors (IGBTs) minimizes the error between references and the predicted values. The system constraints can be easily included. The predictive current control (PCC) strategy assesses the stator current in the cost function. The weighting factor is not necessary. Both the PTC and PCC methods are very useful direct control methods that do not require the use of a modulator. In this paper, the PTC and PCC methods are carried out experimentally for an IM on the same test bench. The behaviors and the robustness in steady state and the performances in transient state are evaluated.","Cost function,
Stators,
Torque,
Inverters,
Electromagnetics,
Rotors"
Automated Vessel Segmentation Using Infinite Perimeter Active Contour Model with Hybrid Region Information with Application to Retinal Images,"Automated detection of blood vessel structures is becoming of crucial interest for better management of vascular disease. In this paper, we propose a new infinite active contour model that uses hybrid region information of the image to approach this problem. More specifically, an infinite perimeter regularizer, provided by using L2 Lebesgue measure of the γ-neighborhood of boundaries, allows for better detection of small oscillatory (branching) structures than the traditional models based on the length of a feature's boundaries (i.e., H1 Hausdorff measure). Moreover, for better general segmentation performance, the proposed model takes the advantage of using different types of region information, such as the combination of intensity information and local phase based enhancement map. The local phase based enhancement map is used for its superiority in preserving vessel edges while the given image intensity information will guarantee a correct feature's segmentation. We evaluate the performance of the proposed model by applying it to three public retinal image datasets (two datasets of color fundus photography and one fluorescein angiography dataset). The proposed model outperforms its competitors when compared with other widely used unsupervised and supervised methods. For example, the sensitivity (0.742), specificity (0.982) and accuracy (0.954) achieved on the DRIVE dataset are very close to those of the second observer's annotations.",
The {\schmi g}-Good-Neighbor Conditional Diagnosability of {\schmi k}-Ary {\schmi n}-Cubes under the PMC Modeland MM* Model,"The diagnosability of a system is defined as the maximum number of faulty processors that the system can guarantee to identify, which plays an important role in measuring of the reliability of multiprocessor systems. In the work of Peng et al. in 2012, they proposed a new measure for fault diagnosis of systems, namely, g-good-neighbor conditional diagnosability. It is defined as the diagnosability of a multiprocessor system under the assumption that every fault-free node contains at least g fault-free neighbors, which can measure the reliability of interconnection networks in heterogeneous environments more accurately than traditional diagnosability. The k-ary n-cube is a family of popular networks. In this study, we first investigate and determine the Rg-connectivity of k-ary n-cube for 0 ≤ g ≤ n. Based on this, we determine the g-good-neighbor conditional diagnosability of k-ary n-cube under the PMC model and MM model for k ≥ 4, n ≥ 3 and 0 ≤ g ≤ n. Our study shows the g-good-neighbor conditional diagnosability of k-ary n-cube is several times larger than the classical diagnosability of k-ary n-cube.","Program processors,
Hypercubes,
Multiprocessing systems,
Circuit faults,
Computational modeling,
Fault diagnosis"
Simultaneously Structured Models With Application to Sparse and Low-Rank Matrices,"Recovering structured models (e.g., sparse or group-sparse vectors, low-rank matrices) given a few linear observations have been well-studied recently. In various applications in signal processing and machine learning, the model of interest is structured in several ways, for example, a matrix that is simultaneously sparse and low rank. Often norms that promote the individual structures are known, and allow for recovery using an order-wise optimal number of measurements (e.g., 11 norm for sparsity, nuclear norm for matrix rank). Hence, it is reasonable to minimize a combination of such norms. We show that, surprisingly, using multiobjective optimization with these norms can do no better, orderwise, than exploiting only one of the structures, thus revealing a fundamental limitation in sample complexity. This result suggests that to fully exploit the multiple structures, we need an entirely new convex relaxation. Further, specializing our results to the case of sparse and low-rank matrices, we show that a nonconvex formulation recovers the model from very few measurements (on the order of the degrees of freedom), whereas the convex problem combining the 11 and nuclear norms requires many more measurements, illustrating a gap between the performance of the convex and nonconvex recovery problems. Our framework applies to arbitrary structure-inducing norms as well as to a wide range of measurement ensembles. This allows us to give sample complexity bounds for problems such as sparse phase retrieval and low-rank tensor completion.","Sparse matrices,
Vectors,
Complexity theory,
Tensile stress,
Symmetric matrices,
Nuclear measurements,
Matrix decomposition"
Scene Recognition by Manifold Regularized Deep Learning Architecture,"Scene recognition is an important problem in the field of computer vision, because it helps to narrow the gap between the computer and the human beings on scene understanding. Semantic modeling is a popular technique used to fill the semantic gap in scene recognition. However, most of the semantic modeling approaches learn shallow, one-layer representations for scene recognition, while ignoring the structural information related between images, often resulting in poor performance. Modeled after our own human visual system, as it is intended to inherit humanlike judgment, a manifold regularized deep architecture is proposed for scene recognition. The proposed deep architecture exploits the structural information of the data, making for a mapping between visible layer and hidden layer. By the proposed approach, a deep architecture could be designed to learn the high-level features for scene recognition in an unsupervised fashion. Experiments on standard data sets show that our method outperforms the state-of-the-art used for scene recognition.","Kernel,
Manifolds,
Computer architecture,
Semantics,
Visualization,
Sparse matrices,
Feature extraction"
An Efficient Distributed Trust Model for Wireless Sensor Networks,"Trust models have been recently suggested as an effective security mechanism for Wireless Sensor Networks (WSNs). Considerable research has been done on modeling trust. However, most current research work only takes communication behavior into account to calculate sensor nodes' trust value, which is not enough for trust evaluation due to the widespread malicious attacks. In this paper, we propose an Efficient Distributed Trust Model (EDTM) for WSNs. First, according to the number of packets received by sensor nodes, direct trust and recommendation trust are selectively calculated. Then, communication trust, energy trust and data trust are considered during the calculation of direct trust. Furthermore, trust reliability and familiarity are defined to improve the accuracy of recommendation trust. The proposed EDTM can evaluate trustworthiness of sensor nodes more precisely and prevent the security breaches more effectively. Simulation results show that EDTM outperforms other similar models, e.g., NBBTE trust model.","Wireless sensor networks,
Reliability,
Security,
Energy consumption,
Uncertainty,
Monitoring,
Wireless communication"
Passivity and Synchronization of Linearly Coupled Reaction-Diffusion Neural Networks With Adaptive Coupling,"In this paper, we study a general array model of coupled reaction-diffusion neural networks (NNs) with adaptive coupling. In order to ensure the passivity of the coupled reaction-diffusion neural networks, some adaptive strategies to tune the coupling strengths among network nodes are designed. By utilizing some inequality techniques and the designed adaptive laws, several sufficient conditions ensuring passivity are obtained. In addition, we reveal the relationship between passivity and synchronization of the coupled reaction-diffusion NNs. Based on the obtained passivity results and the relationship between passivity and synchronization, a global synchronization criterion is established. Finally, numerical simulations are presented to illustrate the correctness and effectiveness of the proposed results.","Artificial neural networks,
Synchronization,
Couplings,
Symmetric matrices,
Neurons,
Equations"
Deep hashing for compact binary codes learning,"In this paper, we propose a new deep hashing (DH) approach to learn compact binary codes for large scale visual search. Unlike most existing binary codes learning methods which seek a single linear projection to map each sample into a binary vector, we develop a deep neural network to seek multiple hierarchical non-linear transformations to learn these binary codes, so that the nonlinear relationship of samples can be well exploited. Our model is learned under three constraints at the top layer of the deep network: 1) the loss between the original real-valued feature descriptor and the learned binary vector is minimized, 2) the binary codes distribute evenly on each bit, and 3) different bits are as independent as possible. To further improve the discriminative power of the learned binary codes, we extend DH into supervised DH (SDH) by including one discriminative term into the objective function of DH which simultaneously maximizes the inter-class variations and minimizes the intra-class variations of the learned binary codes. Experimental results show the superiority of the proposed approach over the state-of-the-arts.","Binary codes,
DH-HEMTs,
Synchronous digital hierarchy,
Training,
Visualization,
Machine learning,
Optimization"
A Hybrid Cloud Approach for Secure Authorized Deduplication,"Data deduplication is one of important data compression techniques for eliminating duplicate copies of repeating data, and has been widely used in cloud storage to reduce the amount of storage space and save bandwidth. To protect the confidentiality of sensitive data while supporting deduplication, the convergent encryption technique has been proposed to encrypt the data before outsourcing. To better protect data security, this paper makes the first attempt to formally address the problem of authorized data deduplication. Different from traditional deduplication systems, the differential privileges of users are further considered in duplicate check besides the data itself. We also present several new deduplication constructions supporting authorized duplicate check in a hybrid cloud architecture. Security analysis demonstrates that our scheme is secure in terms of the definitions specified in the proposed security model. As a proof of concept, we implement a prototype of our proposed authorized duplicate check scheme and conduct testbed experiments using our prototype. We show that our proposed authorized duplicate check scheme incurs minimal overhead compared to normal operations.","Cloud computing,
Encryption,
Servers,
Educational institutions,
Protocols"
A Zigbee-Based Animal Health Monitoring System,"An animal health monitoring system for monitoring the physiological parameters, such as rumination, body temperature, and heart rate with surrounding temperature and humidity, has been developed. The developed system can also analyze the stress level corresponding to thermal humidity index. The IEEE802.15.4 and IEEE1451.2 standards-based sensor module has been developed successfully. The Zigbee device and PIC18F4550 microcontroller are used in the implementation of sensor module. The graphical user interface (GUI) is implemented in LabVIEW 9 according to the IEEE1451.1 standard. The real-time monitoring of physiological and behavioral parameters can be present on the GUI PC. The device is very helpful for inexpensive health care of livestock. A prototype model is developed and tested with high accuracy results.","Temperature sensors,
Animals,
Monitoring,
Heart rate,
Zigbee,
Humidity"
{H}_{ {\infty }} Tracking Control of Completely Unknown Continuous-Time Systems via Off-Policy Reinforcement Learning,This paper deals with the design of an H∞ tracking controller for nonlinear continuous-time systems with completely unknown dynamics. A general bounded L2-gain tracking problem with a discounted performance function is introduced for the H∞ tracking. A tracking Hamilton-Jacobi-Isaac (HJI) equation is then developed that gives a Nash equilibrium solution to the associated min-max optimization problem. A rigorous analysis of bounded L2-gain and stability of the control solution obtained by solving the tracking HJI equation is provided. An upper-bound is found for the discount factor to assure local asymptotic stability of the tracking error dynamics. An off-policy reinforcement learning algorithm is used to learn the solution to the tracking HJI equation online without requiring any knowledge of the system dynamics. Convergence of the proposed algorithm to the solution to the tracking HJI equation is shown. Simulation examples are provided to verify the effectiveness of the proposed method.,"Attenuation,
Mathematical model,
Asymptotic stability,
Heuristic algorithms,
Feedforward neural networks,
Optimal control,
Trajectory"
Quaternion-Based Robust Attitude Control for Uncertain Robotic Quadrotors,"A robust nonlinear attitude control method is proposed for uncertain robotic quadrotors. The proposed controller is developed based on a nonlinear model with the quaternion representation and subject to parameter uncertainties, nonlinearities, and external disturbances. A new state feedback controller is proposed to restrain the effects of nonlinearities and uncertainties on the closed-loop control system. These uncertainties are considered as input equivalent disturbances and their effects are guaranteed to be attenuated. Experimental results are given to show good steady-state and dynamic tracking performance of the closed-loop system by the proposed robust control method compared with other nonlinear control methods.","Robustness,
Quaternions,
Rotors,
Control systems,
Attitude control,
Uncertainty,
Vehicles"
Predictive Control of Power Converters: Designs With Guaranteed Performance,"In this work, a cost function design based on Lyapunov stability concepts for finite control set model predictive control is proposed. This predictive controller design allows one to characterize the performance of the controlled converter, while providing sufficient conditions for local stability for a class of power converters. Simulation and experimental results on a buck dc-dc converter and a two-level dc-ac inverter are conducted to validate the effectiveness of our proposal.",
Interrelationship-Based Selection for Decomposition Multiobjective Optimization,"Multiobjective evolutionary algorithm based on decomposition (MOEA/D), which bridges the traditional optimization techniques and population-based methods, has become an increasingly popular framework for evolutionary multiobjective optimization. It decomposes a multiobjective optimization problem (MOP) into a number of optimization subproblems. Each subproblem is handled by an agent in a collaborative manner. The selection of MOEA/D is a process of choosing solutions by agents. In particular, each agent has two requirements on its selected solution: one is the convergence toward the efficient front, the other is the distinction with the other agents' choices. This paper suggests addressing these two requirements by defining mutual-preferences between subproblems and solutions. Afterwards, a simple yet effective method is proposed to build an interrelationship between subproblems and solutions, based on their mutual-preferences. At each generation, this interrelationship is used as a guideline to select the elite solutions to survive as the next parents. By considering the mutual-preferences between subproblems and solutions (i.e., the two requirements of each agent), the selection operator is able to balance the convergence and diversity of the search process. Comprehensive experiments are conducted on several MOP test instances with complicated Pareto sets. Empirical results demonstrate the effectiveness and competitiveness of our proposed algorithm.",
ActivityNet: A large-scale video benchmark for human activity understanding,"In spite of many dataset efforts for human action recognition, current computer vision algorithms are still severely limited in terms of the variability and complexity of the actions that they can recognize. This is in part due to the simplicity of current benchmarks, which mostly focus on simple actions and movements occurring on manually trimmed videos. In this paper we introduce ActivityNet, a new large-scale video benchmark for human activity understanding. Our benchmark aims at covering a wide range of complex human activities that are of interest to people in their daily living. In its current version, ActivityNet provides samples from 203 activity classes with an average of 137 untrimmed videos per class and 1.41 activity instances per video, for a total of 849 video hours. We illustrate three scenarios in which ActivityNet can be used to compare algorithms for human activity understanding: untrimmed video classification, trimmed activity classification and activity detection.",
Framework of Group Decision Making With Intuitionistic Fuzzy Preference Information,"Group decision making is an essential activity in various fields of operations research and management science. This paper focuses on the intuitionistic fuzzy group decision making problem in which all the experts use the intuitionistic fuzzy preference relations (IFPRs) to express their preferences. To start our discussion, we first propose the novel framework of intuitionistic fuzzy group decision making and clarify the difficulties in deriving the final result which is accepted by all individuals in the group. Next, a consistency checking method, which is based on the multiplicative consistency, is developed to check the consistency of each IFPR furnished by the group of experts. For those IFPRs that do not have the acceptable consistency, an iterative procedure is proposed to improve the consistency. Furthermore, after introducing a novel consensus measure, an interesting consensus-reaching procedure is developed to help the group to find a solution which is accepted by most members in the group. Finally, in order to make our approaches more applicable, a step-by-step algorithm is given. A numerical example concerning the selection of outstanding Ph.D. students for the China Scholarship Council is given to illustrate and validate the proposed approaches.","Decision making,
Vectors,
Educational institutions,
Aggregates,
Scholarships,
Additives,
Maintenance engineering"
On Extended Dissipativity of Discrete-Time Neural Networks With Time Delay,"In this brief, the problem of extended dissipativity analysis for discrete-time neural networks with time-varying delay is investigated. The definition of extended dissipativity of discrete-time neural networks is proposed, which unifies several performance measures, such as the H∞ performance, passivity, l2-l∞ performance, and dissipativity. By introducing a triple-summable term in Lyapunov function, the reciprocally convex approach is utilized to bound the forward difference of the triple-summable term and then the extended dissipativity criterion for discrete-time neural networks with time-varying delay is established. The derived condition guarantees not only the extended dissipativity but also the stability of the neural networks. Two numerical examples are given to demonstrate the reduced conservatism and effectiveness of the obtained results.",
Web-Based Medical Decision Support Systems for Three-Way Medical Decision Making With Game-Theoretic Rough Sets,"The realization of the Web as a common platform, medium, and interface for supporting human activities has attracted many researchers to the study of Web-based support systems (WSS). An important branch of WSS is Web-based decision support systems that provide intelligent support for making effective decisions in different domains. We focus on decision making in Web-based medical decision support systems (WMDSS). Uncertainty is a critical factor that affects decision making and reasoning in the medical field. A three-way decision-making approach is an effective and better choice to lessen the effects of uncertainty. It provides the provision for delaying certain or definite decisions in situations that lack sufficient evidence or accurate information in reaching certain conclusions. Particularly, the option of deferment decisions is added in this approach that provides the flexibility to further examine and investigate the uncertain and doubtful cases. The game-theoretic rough set (GTRS) model is a recent development in rough sets that can be used to determine the three rough set regions in the probabilistic rough sets framework by determining a pair of thresholds. The three regions are used to obtain three-way decision rules in the form of acceptance, rejection, and deferment rules. In this paper, we extend the GTRS model to analyze uncertainty involved in medical decision making. Experimental results with a GTRS-based approach on different health care datasets suggest that the approach may improve the overall quality of decision making in the medical field, as well as other fields. It is hoped that the incorporation of a GTRS component in WMDSS will enrich and enhance its decision-making capabilities.","Uncertainty,
Decision making,
Probabilistic logic,
Games,
Rough sets,
Databases,
Mathematical model"
Power Quality Assessment in Distribution Systems Embedded With Plug-In Hybrid and Battery Electric Vehicles,"The impact of electric vehicles on power quality in electric distribution system is evaluated. Voltage deviations such as under/over voltage and voltage imbalance are probabilistically quantified using Monte Carlo. Moreover, distribution transformers overload and unbalance are assessed for different vehicle types (i.e., plug-in hybrid and battery electric), different vehicle penetration (up to 50%) while considering level 1 and level 2 charging. The results of Monte Carlo reveal that battery electric vehicles can cause more overload to distribution transformers compared to plug-in hybrid electric vehicles. Also level 2 and level 1 can be problematic resulting in secondary bus undervoltage and transformer unbalance, respectively.",
A Supervisory Energy Management Control Strategy in a Battery/Ultracapacitor Hybrid Energy Storage System,"One of the major challenges in a battery/ ultracapacitor hybrid energy storage system (HESS) is to design a supervisory controller for real-time implementation that can yield good power split performance. This paper presents the design of a supervisory energy management strategy that optimally addresses this issue. In this work, a multiobjective optimization problem is formulated to optimize the power split in order to prolong the battery lifetime and to reduce the HESS power losses. In this HESS energy management problem, a detailed dc-dc converter model is considered to include both the conduction losses and the switching losses. The optimization problem is numerically solved for various drive cycle data sets using dynamic programming (DP). Trained using the DP results, an effective and intelligent online implementation of the optimal power split is realized based on neural networks (NNs). The proposed online intelligent energy management controller is applied to a midsize electric vehicles (EV). A rule-based control strategy is also implemented in this work for comparison with the proposed energy management strategy. The proposed online energy management controller effectively splits the load demand and achieves excellent result of the energy efficiency. It is also estimated that the proposed online energy management controller can extend the battery life by over 60%, which greatly outperforms the rule-based control strategy.","Batteries,
DC-DC power converters,
Optimization,
Energy management,
Transportation,
Artificial neural networks"
Optimizing Existing Software With Genetic Programming,"We show that the genetic improvement of programs (GIP) can scale by evolving increased performance in a widely-used and highly complex 50000 line system. Genetic improvement of software for multiple objective exploration (GISMOE) found code that is 70 times faster (on average) and yet is at least as good functionally. Indeed, it even gives a small semantic gain.","Complexity theory,
Genetic programming,
DNA,
Software,
Semantics,
Grammar"
Synchronization of Linearly Coupled Networks With Delays via Aperiodically Intermittent Pinning Control,"In this paper, we investigate the exponential synchronization problem for linearly coupled networks with delay by pinning a simple aperiodically intermittent controller. The network topology can be directed. Different from previous works, the intermittent control can be aperiodic. Two types of delay are considered. The first case is that the delay is time-varying and large, and in this case, there is no restriction imposed on the delay and the control (and/or rest) width. The other one is that the delay is small enough so that it is less than the minimum of control width. Different approaches are provided to investigate these two cases, and some criteria are given to realize exponential synchronization. Furthermore, by applying the adaptive approach to the second model, we establish a general adaptive theory for intermittent control, which can be applied not only to networks without time delay, but also to delayed networks, regardless of whether the intermittent control is periodic or aperiodic. Finally, the numerical simulations are given to verify the validness of the theoretical results.","Synchronization,
Delays,
Delay effects,
Adaptive systems,
Couplings,
Complex networks,
Adaptation models"
An Optimal and Distributed Method for Voltage Regulation in Power Distribution Systems,"This paper addresses the problem of voltage regulation in power distribution networks with deep-penetration of distributed energy resources, e.g., renewable-based generation, and storage-capable loads such as plug-in hybrid electric vehicles. We cast the problem as an optimization program, where the objective is to minimize the losses in the network subject to constraints on bus voltage magnitudes, limits on active and reactive power injections, transmission line thermal limits and losses. We provide sufficient conditions under which the optimization problem can be solved via its convex relaxation. Using data from existing networks, we show that these sufficient conditions are expected to be satisfied by most networks. We also provide an efficient distributed algorithm to solve the problem. The algorithm adheres to a communication topology described by a graph that is the same as the graph that describes the electrical network topology. We illustrate the operation of the algorithm, including its robustness against communication link failures, through several case studies involving 5-, 34-, and 123-bus power distribution systems.",
3D Shape Matching via Two Layer Coding,"View-based 3D shape retrieval is a popular branch in 3D shape analysis owing to the high discriminative property of 2D views. However, many previous works do not scale up to large 3D shape databases. We propose a two layer coding (TLC) framework to conduct shape matching much more efficiently. The first layer coding is applied to pairs of views represented as depth images. The spatial relationship of each view pair is captured with so-called eigen-angle, which is the planar angle between the two views measured at the center of the 3D shape. Prior to the second layer coding, the view pairs are divided into subsets according to their eigen-angles. Consequently, view pairs that differ significantly in their eigen-angles are encoded with different codewords, which implies that spatial arrangement of views is preserved in the second layer coding. The final feature vector of a 3D shape is the concatenation of all the encoded features from different subsets, which is used for efficient indexing directly. TLC is not limited to encode the local features from 2D views, but can be also applied to encoding 3D features. Exhaustive experimental results confirm that TLC achieves state-of-the-art performance in both retrieval accuracy and efficiency.","Three-dimensional displays,
Shape analysis,
Encoding,
Feature extraction,
Solid modeling,
Image retrieval,
Shape measurement"
Fast HEVC Encoding Decisions Using Data Mining,"The High Efficiency Video Coding standard provides improved compression ratio in comparison with its predecessors at the cost of large increases in the encoding computational complexity. An important share of this increase is due to the new flexible partitioning structures, namely the coding trees, the prediction units, and the residual quadtrees, with the best configurations decided through an exhaustive rate-distortion optimization (RDO) process. In this paper, we propose a set of procedures for deciding whether the partition structure optimization algorithm should be terminated early or run to the end of an exhaustive search for the best configuration. The proposed schemes are based on decision trees obtained through data mining techniques. By extracting intermediate data, such as encoding variables from a training set of video sequences, three sets of decision trees are built and implemented to avoid running the RDO algorithm to its full extent. When separately implemented, these schemes achieve average computational complexity reductions (CCRs) of up to 50% at a negligible cost of 0.56% in terms of Bjontegaard Delta (BD) rate increase. When the schemes are jointly implemented, an average CCR of up to 65% is achieved, with a small BD-rate increase of 1.36%. Extensive experiments and comparisons with similar works demonstrate that the proposed early termination schemes achieve the best rate-distortion-complexity tradeoffs among all the compared works.","Encoding,
Computational complexity,
Decision trees,
Video coding,
Training,
Data mining"
An Analysis of RFID Authentication Schemes for Internet of Things in Healthcare Environment Using Elliptic Curve Cryptography,"Advances in information and communication technologies have led to the emergence of Internet of Things (IoT). In the healthcare environment, the use of IoT technologies brings convenience to physicians and patients as they can be applied to various medical areas (such as constant real-time monitoring, patient information management, medical emergency management, blood information management, and health management). The radio-frequency identification (RFID) technology is one of the core technologies of IoT deployments in the healthcare environment. To satisfy the various security requirements of RFID technology in IoT, many RFID authentication schemes have been proposed in the past decade. Recently, elliptic curve cryptography (ECC)-based RFID authentication schemes have attracted a lot of attention and have been used in the healthcare environment. In this paper, we discuss the security requirements of RFID authentication schemes, and in particular, we present a review of ECC-based RFID authentication schemes in terms of performance and security. Although most of them cannot satisfy all security requirements and have satisfactory performance, we found that there are three recently proposed ECC-based authentication schemes suitable for the healthcare environment in terms of their performance and security.","Radiofrequency identification,
Authentication,
Medical devices,
Medical services,
Internet of Things,
Biomedical monitoring,
Intelligent ,
Elliptic curve cryptography,
Cryptography,
Radiofrequency identification,
Computer security"
Pedestrian detection aided by deep learning semantic tasks,"Deep learning methods have achieved great successes in pedestrian detection, owing to its ability to learn discriminative features from raw pixels. However, they treat pedestrian detection as a single binary classification task, which may confuse positive with hard negative samples (Fig.1 (a)). To address this ambiguity, this work jointly optimize pedestrian detection with semantic tasks, including pedestrian attributes (e.g. `carrying backpack') and scene attributes (e.g. `vehicle', `tree', and `horizontal'). Rather than expensively annotating scene attributes, we transfer attributes information from existing scene segmentation datasets to the pedestrian dataset, by proposing a novel deep model to learn high-level features from multiple tasks and multiple data sources. Since distinct tasks have distinct convergence rates and data from different datasets have different distributions, a multi-task deep model is carefully designed to coordinate tasks and reduce discrepancies among datasets. Extensive evaluations show that the proposed approach outperforms the state-of-the-art on the challenging Caltech [9] and ETH [10] datasets where it reduces the miss rates of previous deep models by 17 and 5.5 percent, respectively.","Feature extraction,
Semantics,
Barium,
Vehicles,
Detectors,
Machine learning,
Data models"
Green Internet of Things for Smart World,"Smart world is envisioned as an era in which objects (e.g., watches, mobile phones, computers, cars, buses, and trains) can automatically and intelligently serve people in a collaborative manner. Paving the way for smart world, Internet of Things (IoT) connects everything in the smart world. Motivated by achieving a sustainable smart world, this paper discusses various technologies and issues regarding green IoT, which further reduces the energy consumption of IoT. Particularly, an overview regarding IoT and green IoT is performed first. Then, the hot green information and communications technologies (ICTs) (e.g., green radio-frequency identification, green wireless sensor network, green cloud computing, green machine to machine, and green data center) enabling green IoT are studied, and general green ICT principles are summarized. Furthermore, the latest developments and future vision about sensor cloud, which is a novel paradigm in green IoT, are reviewed and introduced, respectively. Finally, future research directions and open problems about green IoT are presented. Our work targets to be an enlightening and latest guidance for research with respect to green IoT and smart world.",
Security Enhancement of Cooperative Single Carrier Systems,"In this paper, the impact of multiple active eavesdroppers on cooperative single carrier systems with multiple relays and multiple destinations is examined. To achieve the secrecy diversity gains in the form of opportunistic selection, a two-stage scheme is proposed for joint relay and destination selection, in which, after the selection of the relay with the minimum effective maximum signal-to-noise ratio (SNR) to a cluster of eavesdroppers, the destination that has the maximum SNR from the chosen relay is selected. To accurately assess the secrecy performance, exact and asymptotic expressions are obtained in closed form for several security metrics, including the secrecy outage probability, probability of nonzero secrecy rate, and ergodic secrecy rate in frequency selective fading. Based on the asymptotic analysis, key design parameters, such as secrecy diversity gain, secrecy array gain, secrecy multiplexing gain, and power cost, are characterized, from which new insights are drawn. In addition, it is concluded that secrecy performance limits occur when the average received power at the eavesdropper is proportional to the counterpart at the destination. In particular, for the secrecy outage probability, it is confirmed that the secrecy diversity gain collapses to zero with outage floor, whereas for the ergodic secrecy rate, it is confirmed that its slope collapses to zero with capacity ceiling.","Relays,
Security,
Diversity methods,
Signal to noise ratio,
Fading,
Wireless communication,
Receivers"
Adaptive Optimal Control of Highly Dissipative Nonlinear Spatially Distributed Processes With Neuro-Dynamic Programming,"Highly dissipative nonlinear partial differential equations (PDEs) are widely employed to describe the system dynamics of industrial spatially distributed processes (SDPs). In this paper, we consider the optimal control problem of the general highly dissipative SDPs, and propose an adaptive optimal control approach based on neuro-dynamic programming (NDP). Initially, Karhunen-Loève decomposition is employed to compute empirical eigenfunctions (EEFs) of the SDP based on the method of snapshots. These EEFs together with singular perturbation technique are then used to obtain a finite-dimensional slow subsystem of ordinary differential equations that accurately describes the dominant dynamics of the PDE system. Subsequently, the optimal control problem is reformulated on the basis of the slow subsystem, which is further converted to solve a Hamilton-Jacobi-Bellman (HJB) equation. HJB equation is a nonlinear PDE that has proven to be impossible to solve analytically. Thus, an adaptive optimal control method is developed via NDP that solves the HJB equation online using neural network (NN) for approximating the value function; and an online NN weight tuning law is proposed without requiring an initial stabilizing control policy. Moreover, by involving the NN estimation error, we prove that the original closed-loop PDE system with the adaptive optimal control policy is semiglobally uniformly ultimately bounded. Finally, the developed method is tested on a nonlinear diffusion-convection-reaction process and applied to a temperature cooling fin of high-speed aerospace vehicle, and the achieved results show its effectiveness.","Optimal control,
Artificial neural networks,
Equations,
Adaptive systems,
Mathematical model,
Vectors,
Approximation methods"
On orchestrating virtual network functions,"Middleboxes or network appliances like firewalls, proxies, and WAN optimizers have become an integral part of today's ISP and enterprise networks. Middlebox functionalities are usually deployed on expensive and proprietary hardware that require trained personnel for deployment and maintenance. Middleboxes contribute significantly to a network's capital and operational costs. In addition, organizations often require their traffic to pass through a specific sequence of middleboxes for compliance with security and performance policies. This makes the middlebox deployment and maintenance tasks even more complicated. Network Function Virtualization (NFV) is an emerging and promising technology that is envisioned to overcome these challenges. It proposes to move packet processing from dedicated hardware middleboxes to software running on commodity servers. In NFV terminology, software middleboxes are referred to as Virtual Network Functions (VNFs). It is a challenging problem to determine the required number and placement of VNFs that optimize network operational costs and utilization, without violating service level agreements. We call this the VNF Orchestration Problem (VNF-OP) and provide an Integer Linear Programming (ILP) formulation with implementation in CPLEX. We also provide a dynamic programming based heuristic to solve larger instances of VNF-OP. Trace driven simulations on real-world network topologies demonstrate that the heuristic can provide solutions that are within 1.3 times of the optimal solution. Our experiments suggest that a VNF based approach can provide more than 4 χ reduction in the operational cost of a network.","Servers,
Middleboxes,
Software,
Hardware,
Propagation delay"
Improving object detection with deep convolutional networks via Bayesian optimization and structured prediction,"Object detection systems based on the deep convolutional neural network (CNN) have recently made ground-breaking advances on several object detection benchmarks. While the features learned by these high-capacity neural networks are discriminative for categorization, inaccurate localization is still a major source of error for detection. Building upon high-capacity CNN architectures, we address the localization problem by 1) using a search algorithm based on Bayesian optimization that sequentially proposes candidate regions for an object bounding box, and 2) training the CNN with a structured loss that explicitly penalizes the localization inaccuracy. In experiments, we demonstrate that each of the proposed methods improves the detection performance over the baseline method on PASCAL VOC 2007 and 2012 datasets. Furthermore, two methods are complementary and significantly outperform the previous state-of-the-art when combined.","Bayes methods,
Optimization,
Yttrium,
Object detection,
Proposals,
Search problems,
Training"
Predicting Asthma-Related Emergency Department Visits Using Big Data,"Asthma is one of the most prevalent and costly chronic conditions in the United States, which cannot be cured. However, accurate and timely surveillance data could allow for timely and targeted interventions at the community or individual level. Current national asthma disease surveillance systems can have data availability lags of up to two weeks. Rapid progress has been made in gathering nontraditional, digital information to perform disease surveillance. We introduce a novel method of using multiple data sources for predicting the number of asthma-related emergency department (ED) visits in a specific area. Twitter data, Google search interests, and environmental sensor data were collected for this purpose. Our preliminary findings show that our model can predict the number of asthma ED visits based on near-real-time environmental and social media data with approximately 70% precision. The results can be helpful for public health surveillance, ED preparedness, and targeted patient interventions.","Twitter,
Diseases,
Surveillance,
Google,
Predictive models,
Media,
Market research"
Consistent Video Saliency Using Local Gradient Flow Optimization and Global Refinement,"We present a novel spatiotemporal saliency detection method to estimate salient regions in videos based on the gradient flow field and energy optimization. The proposed gradient flow field incorporates two distinctive features: 1) intra-frame boundary information and 2) inter-frame motion information together for indicating the salient regions. Based on the effective utilization of both intra-frame and inter-frame information in the gradient flow field, our algorithm is robust enough to estimate the object and background in complex scenes with various motion patterns and appearances. Then, we introduce local as well as global contrast saliency measures using the foreground and background information estimated from the gradient flow field. These enhanced contrast saliency cues uniformly highlight an entire object. We further propose a new energy function to encourage the spatiotemporal consistency of the output saliency maps, which is seldom explored in previous video saliency methods. The experimental results show that the proposed algorithm outperforms state-of-the-art video saliency detection methods.","Spatiotemporal phenomena,
Visualization,
Image color analysis,
Optical imaging,
Estimation,
Video sequences"
Robust Video Object Cosegmentation,"With ever-increasing volumes of video data, automatic extraction of salient object regions became even more significant for visual analytic solutions. This surge has also opened up opportunities for taking advantage of collective cues encapsulated in multiple videos in a cooperative manner. However, it also brings up major challenges, such as handling of drastic appearance, motion pattern, and pose variations, of foreground objects as well as indiscriminate backgrounds. Here, we present a co segmentation framework to discover and segment out common object regions across multiple frames and multiple videos in a joint fashion. We incorporate three types of cues, i.e., intraframe saliency, interframe consistency, and across-video similarity into an energy optimization framework that does not make restrictive assumptions on foreground appearance and motion model, and does not require objects to be visible in all frames. We also introduce a spatio-temporal scale-invariant feature transform (SIFT) flow descriptor to integrate across-video correspondence from the conventional SIFT-flow into interframe motion flow from optical flow. This novel spatio-temporal SIFT flow generates reliable estimations of common foregrounds over the entire video data set. Experimental results show that our method outperforms the state-of-the-art on a new extensive data set (ViCoSeg).","Optical imaging,
Object segmentation,
Motion segmentation,
Optimization,
Video sequences,
Joints,
Integrated optics"
Is Extreme Learning Machine Feasible? A Theoretical Assessment (Part II),"An extreme learning machine (ELM) can be regarded as a two-stage feed-forward neural network (FNN) learning system that randomly assigns the connections with and within hidden neurons in the first stage and tunes the connections with output neurons in the second stage. Therefore, ELM training is essentially a linear learning problem, which significantly reduces the computational burden. Numerous applications show that such a computation burden reduction does not degrade the generalization capability. It has, however, been open that whether this is true in theory. The aim of this paper is to study the theoretical feasibility of ELM by analyzing the pros and cons of ELM. In the previous part of this topic, we pointed out that via appropriately selected activation functions, ELM does not degrade the generalization capability in the sense of expectation. In this paper, we launch the study in a different direction and show that the randomness of ELM also leads to certain negative consequences. On one hand, we find that the randomness causes an additional uncertainty problem of ELM, both in approximation and learning. On the other hand, we theoretically justify that there also exist activation functions such that the corresponding ELM degrades the generalization capability. In particular, we prove that the generalization capability of ELM with Gaussian kernel is essentially worse than that of FNN with Gaussian kernel. To facilitate the use of ELM, we also provide a remedy to such a degradation. We find that the well-developed coefficient regularization technique can essentially improve the generalization capability. The obtained results reveal the essential characteristic of ELM in a certain sense and give theoretical guidance concerning how to use ELM.","Kernel,
Neurons,
Uncertainty,
Degradation,
Learning systems,
Approximation error"
Demonstration of Cooperative Resource Allocation in an OpenFlow-Controlled Multidomain and Multinational SD-EON Testbed,"The combination of elastic optical networks (EONs) and software-defined networking (SDN) leads to SD-EONs, which bring a new opportunity for enhancing programmability and flexibility of optical networks with more freedom for network operators to customize their infrastructure dynamically. In this paper, we investigate how to apply multidomain scenarios to SD-EONs. We design the functionalities in the control plane to facilitate multidomain tasks, and propose an interdomain protocol to enable OpenFlow controllers in different SD-EON domains to operate cooperatively for multidomain routing and spectrum assignment. The proposed system is implemented and experimentally demonstrated in a multinational SD-EON control plane testbed that consists of two geographically distributed domains located in China and USA, respectively. Experimental results indicate that the proposed system performs well for resource allocation across multiple SD-EON domains.",
Robust Sound Event Classification Using Deep Neural Networks,"The automatic recognition of sound events by computers is an important aspect of emerging applications such as automated surveillance, machine hearing and auditory scene understanding. Recent advances in machine learning, as well as in computational models of the human auditory system, have contributed to advances in this increasingly popular research field. Robust sound event classification, the ability to recognise sounds under real-world noisy conditions, is an especially challenging task. Classification methods translated from the speech recognition domain, using features such as mel-frequency cepstral coefficients, have been shown to perform reasonably well for the sound event classification task, although spectrogram-based or auditory image analysis techniques reportedly achieve superior performance in noise. This paper outlines a sound event classification framework that compares auditory image front end features with spectrogram image-based front end features, using support vector machine and deep neural network classifiers. Performance is evaluated on a standard robust classification task in different levels of corrupting noise, and with several system enhancements, and shown to compare very well with current state-of-the-art classification techniques.",
Speech Emotion Recognition Using Fourier Parameters,"Recently, studies have been performed on harmony features for speech emotion recognition. It is found in our study that the first- and second-order differences of harmony features also play an important role in speech emotion recognition. Therefore, we propose a new Fourier parameter model using the perceptual content of voice quality and the first- and second-order differences for speaker-independent speech emotion recognition. Experimental results show that the proposed Fourier parameter (FP) features are effective in identifying various emotional states in speech signals. They improve the recognition rates over the methods using Mel frequency cepstral coefficient (MFCC) features by 16.2, 6.8 and 16.6 points on the German database (EMODB), Chinese language database (CASIA) and Chinese elderly emotion database (EESDB). In particular, when combining FP with MFCC, the recognition rates can be further improved on the aforementioned databases by 17.5, 10 and 10.5 points, respectively.","Speech,
Speech recognition,
Emotion recognition,
Feature extraction,
Databases,
Mel frequency cepstral coefficient,
Harmonic analysis"
DevNet: A Deep Event Network for multimedia event detection and evidence recounting,"In this paper, we focus on complex event detection in internet videos while also providing the key evidences of the detection results. Convolutional Neural Networks (CNNs) have achieved promising performance in image classification and action recognition tasks. However, it remains an open problem how to use CNNs for video event detection and recounting, mainly due to the complexity and diversity of video events. In this work, we propose a flexible deep CNN infrastructure, namely Deep Event Network (DevNet), that simultaneously detects pre-defined events and provides key spatial-temporal evidences. Taking key frames of videos as input, we first detect the event of interest at the video level by aggregating the CNN features of the key frames. The pieces of evidences which recount the detection results, are also automatically localized, both temporally and spatially. The challenge is that we only have video level labels, while the key evidences usually take place at the frame levels. Based on the intrinsic property of CNNs, we first generate a spatial-temporal saliency map by back passing through DevNet, which then can be used to find the key frames which are most indicative to the event, as well as to localize the specific spatial position, usually an object, in the frame of the highly indicative area. Experiments on the large scale TRECVID 2014 MEDTest dataset demonstrate the promising performance of our method, both for event detection and evidence recounting.","Videos,
Event detection,
Feature extraction,
Multimedia communication,
Training,
Streaming media,
Image recognition"
Disease Inference from Health-Related Questions via Sparse Deep Learning,"Automatic disease inference is of importance to bridge the gap between what online health seekers with unusual symptoms need and what busy human doctors with biased expertise can offer. However, accurately and efficiently inferring diseases is non-trivial, especially for community-based health services due to the vocabulary gap, incomplete information, correlated medical concepts, and limited high quality training samples. In this paper, we first report a user study on the information needs of health seekers in terms of questions and then select those that ask for possible diseases of their manifested symptoms for further analytic. We next propose a novel deep learning scheme to infer the possible diseases given the questions of health seekers. The proposed scheme is comprised of two key components. The first globally mines the discriminant medical signatures from raw features. The second deems the raw features and their signatures as input nodes in one layer and hidden nodes in the subsequent layer, respectively. Meanwhile, it learns the inter-relations between these two layers via pre-training with pseudo-labeled data. Following that, the hidden nodes serve as raw features for the more abstract signature mining. With incremental and alternative repeating of these two components, our scheme builds a sparsely connected deep architecture with three hidden layers. Overall, it well fits specific tasks with fine-tuning. Extensive experiments on a real-world dataset labeled by online doctors show the significant performance gains of our scheme.","Diseases,
Medical diagnostic imaging,
Cancer,
Educational institutions,
Training"
Exact and Stable Covariance Estimation From Quadratic Sampling via Convex Programming,"Statistical inference and information processing of high-dimensional data often require an efficient and accurate estimation of their second-order statistics. With rapidly changing data, limited processing power and storage at the acquisition devices, it is desirable to extract the covariance structure from a single pass over the data and a small number of stored measurements. In this paper, we explore a quadratic (or rank-one) measurement model which imposes minimal memory requirements and low computational complexity during the sampling process, and is shown to be optimal in preserving various low-dimensional covariance structures. Specifically, four popular structural assumptions of covariance matrices, namely, low rank, Toeplitz low rank, sparsity, jointly rank-one and sparse structure, are investigated, while recovery is achieved via convex relaxation paradigms for the respective structure. The proposed quadratic sampling framework has a variety of potential applications, including streaming data processing, high-frequency wireless communication, phase space tomography and phase retrieval in optics, and noncoherent subspace detection. Our method admits universally accurate covariance estimation in the absence of noise, as soon as the number of measurements exceeds the information theoretic limits. We also demonstrate the robustness of this approach against noise and imperfect structural assumptions. Our analysis is established upon a novel notion called the mixed-norm restricted isometry property (RIP-ℓ2/ℓ1), as well as the conventional RIP-ℓ2/ℓ2 for near-isotropic and bounded measurements. In addition, our results improve upon the best-known phase retrieval (including both dense and sparse signals) guarantees using PhaseLift with a significantly simpler approach.","Covariance matrices,
Noise measurement,
Estimation,
Phase measurement,
Sensors,
Noise,
Energy measurement"
An Efficient Identity-Based Conditional Privacy-Preserving Authentication Scheme for Vehicular Ad Hoc Networks,"By broadcasting messages about traffic status to vehicles wirelessly, a vehicular ad hoc network (VANET) can improve traffic safety and efficiency. To guarantee secure communication in VANETs, security and privacy issues must be addressed before their deployment. The conditional privacy-preserving authentication (CPPA) scheme is suitable for solving security and privacy-preserving problems in VANETs, because it supports both mutual authentication and privacy protection simultaneously. Many identity-based CPPA schemes for VANETs using bilinear pairings have been proposed over the last few years to enhance security or to improve performance. However, it is well known that the bilinear pairing operation is one of the most complex operations in modern cryptography. To achieve better performance and reduce computational complexity of information processing in VANET, the design of a CPPA scheme for the VANET environment that does not use bilinear paring becomes a challenge. To address this challenge, we propose a CPPA scheme for VANETs that does not use bilinear paring and we demonstrate that it could supports both the mutual authentication and the privacy protection simultaneously. Our proposed CPPA scheme retains most of the benefits obtained with the previously proposed CPPA schemes. Moreover, the proposed CPPA scheme yields a better performance in terms of computation cost and communication cost making it be suitable for use by the VANET safety-related applications.",
Quality Prediction of Asymmetrically Distorted Stereoscopic 3D Images,"Objective quality assessment of distorted stereoscopic images is a challenging problem, especially when the distortions in the left and right views are asymmetric. Existing studies suggest that simply averaging the quality of the left and right views well predicts the quality of symmetrically distorted stereoscopic images, but generates substantial prediction bias when applied to asymmetrically distorted stereoscopic images. In this paper, we first build a database that contains both single-view and symmetrically and asymmetrically distorted stereoscopic images. We then carry out a subjective test, where we find that the quality prediction bias of the asymmetrically distorted images could lean toward opposite directions (overestimate or underestimate), depending on the distortion types and levels. Our subjective test also suggests that eye dominance effect does not have strong impact on the visual quality decisions of stereoscopic images. Furthermore, we develop an information content and divisive normalization-based pooling scheme that improves upon structural similarity in estimating the quality of single-view images. Finally, we propose a binocular rivalry-inspired multi-scale model to predict the quality of stereoscopic images from that of the single-view images. Our results show that the proposed model, without explicitly identifying image distortion types, successfully eliminates the prediction bias, leading to significantly improved quality prediction of the stereoscopic images.","Three-dimensional displays,
Distortion,
Databases,
Image quality,
Stereo image processing,
Visualization,
Transform coding"
Control Cloud Data Access Privilege and Anonymity With Fully Anonymous Attribute-Based Encryption,"Cloud computing is a revolutionary computing paradigm, which enables flexible, on-demand, and low-cost usage of computing resources, but the data is outsourced to some cloud servers, and various privacy concerns emerge from it. Various schemes based on the attribute-based encryption have been proposed to secure the cloud storage. However, most work focuses on the data contents privacy and the access control, while less attention is paid to the privilege control and the identity privacy. In this paper, we present a semianonymous privilege control scheme AnonyControl to address not only the data privacy, but also the user identity privacy in existing access control schemes. AnonyControl decentralizes the central authority to limit the identity leakage and thus achieves semianonymity. Besides, it also generalizes the file access control to the privilege control, by which privileges of all operations on the cloud data can be managed in a fine-grained manner. Subsequently, we present the AnonyControl-F, which fully prevents the identity leakage and achieve the full anonymity. Our security analysis shows that both AnonyControl and AnonyControl-F are secure under the decisional bilinear Diffie-Hellman assumption, and our performance evaluation exhibits the feasibility of our schemes.",
An Efficient MRF Embedded Level Set Method for Image Segmentation,"This paper presents a fast and robust level set method for image segmentation. To enhance the robustness against noise, we embed a Markov random field (MRF) energy function to the conventional level set energy function. This MRF energy function builds the correlation of a pixel with its neighbors and encourages them to fall into the same region. To obtain a fast implementation of the MRF embedded level set model, we explore algebraic multigrid (AMG) and sparse field method (SFM) to increase the time step and decrease the computation domain, respectively. Both AMG and SFM can be conducted in a parallel fashion, which facilitates the processing of our method for big image databases. By comparing the proposed fast and robust level set method with the standard level set method and its popular variants on noisy synthetic images, synthetic aperture radar (SAR) images, medical images, and natural images, we comprehensively demonstrate the new method is robust against various kinds of noises. In particular, the new level set method can segment an image of size 500 × 500 within 3 s on MATLAB R2010b installed in a computer with 3.30-GHz CPU and 4-GB memory.","Level set,
Image segmentation,
Mathematical model,
Equations,
Noise,
Active contours,
Computational modeling"
Computer-Aided Diagnosis of Mammographic Masses Using Scalable Image Retrieval,"Computer-aided diagnosis of masses in mammograms is important to the prevention of breast cancer. Many approaches tackle this problem through content-based image retrieval techniques. However, most of them fall short of scalability in the retrieval stage, and their diagnostic accuracy is, therefore, restricted. To overcome this drawback, we propose a scalable method for retrieval and diagnosis of mammographic masses. Specifically, for a query mammographic region of interest (ROI), scale-invariant feature transform (SIFT) features are extracted and searched in a vocabulary tree, which stores all the quantized features of previously diagnosed mammographic ROIs. In addition, to fully exert the discriminative power of SIFT features, contextual information in the vocabulary tree is employed to refine the weights of tree nodes. The retrieved ROIs are then used to determine whether the query ROI contains a mass. The presented method has excellent scalability due to the low spatial-temporal cost of vocabulary tree. Extensive experiments are conducted on a large dataset of 11 553 ROIs extracted from the digital database for screening mammography, which demonstrate the accuracy and scalability of our approach.",
Curve Query Processing in Wireless Sensor Networks,"Most existing query processing algorithms for wireless sensor networks (WSNs) can only deal with discrete values. However, since the monitored environment always changes continuously with time, discrete values cannot describe the environment accurately and, hence, may not satisfy a variety of query requirements, such as the queries of the maximal, minimal, and inflection points. It is, therefore, of great interest to introduce new queries capable of processing time-continuous data. This paper investigates curve query processing for WSNs as curve is an effective way to represent continuous sensed data. Specifically, a sensed curve derivation algorithm to support curve query processing in WSNs is first proposed. Then, the aggregation operation is employed as an example to illustrate curve query processing. The corresponding accurate and approximate aggregation algorithms are devised accordingly. We demonstrate that the energy cost of the approximate aggregation algorithm is optimal, provided that the required precision is satisfied. The theoretical analysis and experimental results indicate that the proposed algorithms can achieve high performance in terms of accuracy and energy efficiency.","Approximation algorithms,
Wireless sensor networks,
Monitoring,
Query processing,
Polynomials,
Clustering algorithms,
Algorithm design and analysis"
Vehicle Detection Techniques for Collision Avoidance Systems: A Review,"Over the past decade, vision-based vehicle detection techniques for road safety improvement have gained an increasing amount of attention. Unfortunately, the techniques suffer from robustness due to huge variability in vehicle shape (particularly for motorcycles), cluttered environment, various illumination conditions, and driving behavior. In this paper, we provide a comprehensive survey in a systematic approach about the state-of-the-art on-road vision-based vehicle detection and tracking systems for collision avoidance systems (CASs). This paper is structured based on a vehicle detection processes starting from sensor selection to vehicle detection and tracking. Techniques in each process/step are reviewed and analyzed individually. Two main contributions in this paper are the following: survey on motorcycle detection techniques and the sensor comparison in terms of cost and range parameters. Finally, the survey provides an optimal choice with a low cost and reliable CAS design in vehicle industries.","Vehicles,
Laser radar,
Radar tracking,
Vehicle detection,
Roads,
Cameras"
Modeling and Control of Gate-Controlled Series Capacitor Interfaced With a DFIG-Based Wind Farm,"This paper presents application and control of the gate-controlled series capacitor (GCSC) for series compensation and subsynchronous resonance (SSR) damping in doubly-fed induction generator (DFIG)-based wind farms. The GCSC is a new series FACTS device composed of a fixed capacitor in parallel with a pair of antiparallel gate-commuted switches. The study considers a DFIG-based wind farm, which is connected to a series-compensated transmission line whose parameters are derived from the IEEE first benchmark model for computer simulation of the SSR. The small-signal stability analysis of the system is presented, and the eigenvalues of the system are obtained. Using both modal analysis and time-domain simulation, it is shown that the system is potentially unstable due to the SSR mode. Therefore, the wind farm is equipped with a GCSC to solve the instability of the wind farm resulting from the SSR mode, and an SSR damping controller (SSRDC) is designed for this device using residue-based analysis and root locus diagrams. Using residue-based analysis, the optimal input control signal to the SSRDC is identified, which can damp the SSR mode without destabilizing other modes, and using root-locus analysis, the required gain for the SSRDC is determined. MATLAB/Simulink is used as a tool for modeling, design, and time-domain simulations.","Wind farms,
Wind speed,
Power transmission lines,
Wind turbines,
Shafts,
Rotors,
Capacitors"
Multiobjective Flexible Job Shop Scheduling Using Memetic Algorithms,"In this paper, we propose new memetic algorithms (MAs) for the multiobjective flexible job shop scheduling problem (MO-FJSP) with the objectives to minimize the makespan, total workload, and critical workload. The problem is addressed in a Pareto manner, which aims to search for a set of Pareto optimal solutions. First, by using well-designed chromosome encoding/decoding scheme and genetic operators, the nondominated sorting genetic algorithm II (NSGA-II) is adapted for the MO-FJSP. Then, our MAs are developed by incorporating a novel local search algorithm into the adapted NSGA-II, where some good individuals are chosen from the offspring population for local search using a selection mechanism. Furthermore, in the proposed local search, a hierarchical strategy is adopted to handle the three objectives, which mainly considers the minimization of makespan, while the concern of the other two objectives is reflected in the order of trying all the possible actions that could generate the acceptable neighbor. In the experimental studies, the influence of two alternative acceptance rules on the performance of the proposed MAs is first examined. Afterwards, the effectiveness of key components in our MAs is verified, including genetic search, local search, and the hierarchical strategy in local search. Finally, extensive comparisons are carried out with the state-of-the-art methods specially presented for the MO-FJSP on well-known benchmark instances. The results show that the proposed MAs perform much better than all the other algorithms.",
Mobile code offloading: from concept to practice and beyond,"The emerging mobile cloud has expanded the horizon of application development and deployment with techniques such as code offloading. While offloading has been widely considered for saving energy and increasing responsiveness of mobile devices, the technique still faces many challenges pertaining to practical usage. In this article, we adopt a systemic approach for analyzing the components of a generic code offloading architecture. Based on theoretical and experimental analysis, we identify the key limitations for code offloading in practice and then propose solutions to mitigate these limitations. We develop a generic architecture to evaluate the proposed solutions. The results provide insights regarding the evolution and deployment of code offloading.","Mobile communication,
Servers,
Computer architecture,
Mobile handsets,
Cloud computing,
Runtime"
Interval Type-2 Fuzzy Sets are Generalization of Interval-Valued Fuzzy Sets: Toward a Wider View on Their Relationship,"In this paper, we will present a wider view on the relationship between interval-valued fuzzy sets and interval type-2 fuzzy sets, where we will show that interval-valued fuzzy sets are a particular case of the interval type-2 fuzzy sets. For this reason, both concepts should be treated in a different way. In addition, the view presented in this paper will allow a more general perspective of interval type-2 fuzzy sets, which will allow representing concepts that could not be presented by interval-valued fuzzy sets.","Fuzzy sets,
Computer aided software engineering,
Visualization,
Fuzzy logic,
Educational institutions,
Electronic mail,
Uncertainty"
Spatially Coupled LDPC Codes Constructed From Protographs,"In this paper, we construct protograph-based spatially coupled low-density parity-check (LDPC) codes by coupling together a series of L disjoint, or uncoupled, LDPC code Tanner graphs into a single coupled chain. By varying L , we obtain a flexible family of code ensembles with varying rates and frame lengths that can share the same encoding and decoding architecture for arbitrary L . We demonstrate that the resulting codes combine the best features of optimized irregular and regular codes in one design: capacity approaching iterative belief propagation (BP) decoding thresholds and linear growth of minimum distance with block length. In particular, we show that, for sufficiently large L , the BP thresholds on both the binary erasure channel and the binary-input additive white Gaussian noise channel saturate to a particular value significantly better than the BP decoding threshold and numerically indistinguishable from the optimal maximum a posteriori decoding threshold of the uncoupled LDPC code. When all variable nodes in the coupled chain have degree greater than two, asymptotically the error probability converges at least doubly exponentially with decoding iterations and we obtain sequences of asymptotically good LDPC codes with fast convergence rates and BP thresholds close to the Shannon limit. Further, the gap to capacity decreases as the density of the graph increases, opening up a new way to construct capacity achieving codes on memoryless binary-input symmetric-output channels with low-complexity BP decoding.","Iterative decoding,
Couplings,
Convolutional codes,
Sparse matrices,
Block codes,
Joining processes"
Resampling-Based Ensemble Methods for Online Class Imbalance Learning,"Online class imbalance learning is a new learning problem that combines the challenges of both online learning and class imbalance learning. It deals with data streams having very skewed class distributions. This type of problems commonly exists in real-world applications, such as fault diagnosis of real-time control monitoring systems and intrusion detection in computer networks. In our earlier work, we defined class imbalance online, and proposed two learning algorithms OOB and UOB that build an ensemble model overcoming class imbalance in real time through resampling and time-decayed metrics. In this paper, we further improve the resampling strategy inside OOB and UOB, and look into their performance in both static and dynamic data streams. We give the first comprehensive analysis of class imbalance in data streams, in terms of data distributions, imbalance rates and changes in class imbalance status. We find that UOB is better at recognizing minority-class examples in static data streams, and OOB is more robust against dynamic changes in class imbalance status. The data distribution is a major factor affecting their performance. Based on the insight gained, we then propose two new ensemble methods that maintain both OOB and UOB with adaptive weights for final predictions, called WEOB1 and WEOB2. They are shown to possess the strength of OOB and UOB with good accuracy and robustness.","Training,
Bagging,
Accuracy,
Algorithm design and analysis,
Measurement,
Robustness,
Frequency modulation"
Robust AN-Aided Secure Transmission Scheme in MISO Channels with Simultaneous Wireless Information and Power Transfer,"In this letter, considering the simultaneous wireless information and power transfer scheme, we study the robust artificial noise (AN)-aided secure transmission design in multiple-input-single-output channels where the channel uncertainties are modeled by worst-case model. Our objective is to maximize the worst-case secrecy rate with respect to both the worst-case channel uncertainties and the worst-case eavesdropper among multiple eavesdroppers, under the transmit power constraint and the worst-case energy harvesting constraint. The optimal solution to the problem can be found by two-dimensional (2-D) search. Since the 2-D search algorithm has high computational complexity, we propose to neglect the correlation of the channel uncertainties from the transmitter to the information-decoding receiver and reformulate the problem as a sequence of convex semidefinite programming (SDP) which is solved efficiently by SDP based one-dimensional line search method. It is shown through computer simulations that the proposed robust AN-aided secure transmission schemes have significant performance gain over the non-robust AN-aided secure transmission scheme and the robust secure transmission scheme without the aid of AN.","Receivers,
Uncertainty,
Robustness,
Transmitters,
Communication system security,
Wireless communication,
Search problems"
Learning Spectral Mapping for Speech Dereverberation and Denoising,"In real-world environments, human speech is usually distorted by both reverberation and background noise, which have negative effects on speech intelligibility and speech quality. They also cause performance degradation in many speech technology applications, such as automatic speech recognition. Therefore, the dereverberation and denoising problems must be dealt with in daily listening environments. In this paper, we propose to perform speech dereverberation using supervised learning, and the supervised approach is then extended to address both dereverberation and denoising. Deep neural networks are trained to directly learn a spectral mapping from the magnitude spectrogram of corrupted speech to that of clean speech. The proposed approach substantially attenuates the distortion caused by reverberation, as well as background noise, and is conceptually simple. Systematic experiments show that the proposed approach leads to significant improvements of predicted speech intelligibility and quality, as well as automatic speech recognition in reverberant noisy conditions. Comparisons show that our approach substantially outperforms related methods.","Speech,
Reverberation,
Spectrogram,
Speech processing,
Time-domain analysis,
Noise reduction,
Training"
Cost-Effective Authentic and Anonymous Data Sharing with Forward Security,"Data sharing has never been easier with the advances of cloud computing, and an accurate analysis on the shared data provides an array of benefits to both the society and individuals. Data sharing with a large number of participants must take into account several issues, including efficiency, data integrity and privacy of data owner. Ring signature is a promising candidate to construct an anonymous and authentic data sharing system. It allows a data owner to anonymously authenticate his data which can be put into the cloud for storage or analysis purpose. Yet the costly certificate verification in the traditional public key infrastructure (PKI) setting becomes a bottleneck for this solution to be scalable. Identity-based (ID-based) ring signature, which eliminates the process of certificate verification, can be used instead. In this paper, we further enhance the security of ID-based ring signature by providing forward security: If a secret key of any user has been compromised, all previous generated signatures that include this user still remain valid. This property is especially important to any large scale data sharing system, as it is impossible to ask all data owners to reauthenticate their data even if a secret key of one single user has been compromised. We provide a concrete and efficient instantiation of our scheme, prove its security and provide an implementation to show its practicality.","Public key,
Smart grids,
Educational institutions,
Information management,
Data handling"
Adaptive Modulation Schemes for Visible Light Communications,"A major limitation of existing visible light communication (VLC) systems is the limited modulation bandwidth of light-emitting diodes used in such systems. Using adaptive modulation to improve the spectral efficiency for radio communications has been well studied. For VLC with various physical layer schemes, however, how adaptive modulation works is not well understood yet. The goal of this paper is to provide an in-depth analysis of the achievable spectral efficiency of adaptive modulation for three different schemes for high speed VLC: dc-biased optical orthogonal frequency division multiplexing (DCO-OFDM), asymmetrically clipped optical OFDM (ACO-OFDM), and single-carrier frequency-domain equalization (SC-FDE). We will show that in the low signal-to-noise ratio region, the ACO-OFDM-based adaptive modulation scheme outperforms the other two schemes. SC-FDE-based adaptive modulation achieves a better performance than the DCO-OFDM-based scheme, and it is much simpler than the other two schemes.",
gem5-gpu: A Heterogeneous CPU-GPU Simulator,"gem5-gpu is a new simulator that models tightly integrated CPU-GPU systems. It builds on gem5, a modular full-system CPU simulator, and GPGPUSim, a detailed GPGPU simulator. gem5-gpu routes most memory accesses through Ruby, which is a highly configurable memory system in gem5. By doing this, it is able to simulate many system configurations, ranging from a system with coherent caches and a single virtual address space across the CPU and GPU to a system that maintains separate GPU and CPU physical address spaces. gem5gpu can run most unmodified CUDA 3.2 source code. Applications can launch non-blocking kernels, allowing the CPU and GPU to execute simultaneously. We present gem5-gpu's software architecture and a brief performance validation. We also discuss possible extensions to the simulator. gem5-gpu is open source and available at gem5-gpu.cs.wisc.edu.",
Matrix Completion for Weakly-Supervised Multi-Label Image Classification,"In the last few years, image classification has become an incredibly active research topic, with widespread applications. Most methods for visual recognition are fully supervised, as they make use of bounding boxes or pixelwise segmentations to locate objects of interest. However, this type of manual labeling is time consuming, error prone and it has been shown that manual segmentations are not necessarily the optimal spatial enclosure for object classifiers. This paper proposes a weakly-supervised system for multi-label image classification. In this setting, training images are annotated with a set of keywords describing their contents, but the visual concepts are not explicitly segmented in the images. We formulate the weakly-supervised image classification as a low-rank matrix completion problem. Compared to previous work, our proposed framework has three advantages: (1) Unlike existing solutions based on multiple-instance learning methods, our model is convex. We propose two alternative algorithms for matrix completion specifically tailored to visual data, and prove their convergence. (2) Unlike existing discriminative methods, our algorithm is robust to labeling errors, background noise and partial occlusions. (3) Our method can potentially be used for semantic segmentation. Experimental validation on several data sets shows that our method outperforms state-of-the-art classification algorithms, while effectively capturing each class appearance.",
A Secure Cloud Computing Based Framework for Big Data Information Management of Smart Grid,"Smart grid is a technological innovation that improves efficiency, reliability, economics, and sustainability of electricity services. It plays a crucial role in modern energy infrastructure. The main challenges of smart grids, however, are how to manage different types of front-end intelligent devices such as power assets and smart meters efficiently; and how to process a huge amount of data received from these devices. Cloud computing, a technology that provides computational resources on demands, is a good candidate to address these challenges since it has several good properties such as energy saving, cost saving, agility, scalability, and flexibility. In this paper, we propose a secure cloud computing based framework for big data information management in smart grids, which we call “Smart-Frame.” The main idea of our framework is to build a hierarchical structure of cloud computing centers to provide different types of computing services for information management and big data analysis. In addition to this structural framework, we present a security solution based on identity-based encryption, signature and proxy re-encryption to address critical security issues of the proposed framework.","Smart grids,
Cloud computing,
Information management,
Computer architecture,
Identity-based encryption"
Collaborative Location-Based Sleep Scheduling for Wireless Sensor Networks Integratedwith Mobile Cloud Computing,"Recently, much research has proposed to integrate mobile cloud computing (MCC) with wireless sensor networks (WSNs) so that powerful cloud computing can be exploited to process the data gathered by ubiquitous WSNs and share the results with mobile users. However, all current MCC-WSN integration schemes ignore the following two observations: 1) the specific data mobile users request usually depend on the current locations of mobile users 2) most sensors are usually equipped with non-rechargeable batteries with limited energy. In this paper, motivated by these two observations, two novel collaborative location-based sleep scheduling (CLSS) schemes are proposed for WSNs integrated with MCC. Based on the locations of mobile users, CLSS dynamically determines the awake or asleep status of each sensor node to reduce energy consumption of the integrated WSN. Particularly, CLSS1 focuses on maximizing the energy consumption saving of the integrated WSN while CLSS2 considers also the scalability and robustness of the integrated WSN. Theoretical and simulation results show that for WSNs integrated with MCC, both CLSS1 and CLSS2 can prolong the WSN lifetime while still satisfying the data requests of mobile users.",
Real-Time City-Scale Taxi Ridesharing,"We proposed and developed a taxi-sharing system that accepts taxi passengers' real-time ride requests sent from smart phones and schedules proper taxis to pick up them via ride sharing, subject to time, capacity, and monetary constraints. The monetary constraints provide incentives for both passengers and taxi drivers: passengers will not pay more compared with no ride sharing and get compensated if their travel time is lengthened due to ride sharing; taxi drivers will make money for all the detour distance due to ride sharing. While such a system is of significant social and environmental benefit, e.g., saving energy consumption and satisfying people's commute, real-time taxi-sharing has not been well studied yet. To this end, we devise a mobile-cloud architecture based taxi-sharing system. Taxi riders and taxi drivers use the taxi-sharing service provided by the system via a smart phone App. The Cloud first finds candidate taxis quickly for a taxi ride request using a taxi searching algorithm supported by a spatio-temporal index. A scheduling process is then performed in the cloud to select a taxi that satisfies the request with minimum increase in travel distance. We built an experimental platform using the GPS trajectories generated by over 33,000 taxis over a period of three months. A ride request generator is developed (available at http://cs.uic.edu/~sma/ridesharing) in terms of the stochastic process modelling real ride requests learned from the data set. Tested on this platform with extensive experiments, our proposed system demonstrated its efficiency, effectiveness and scalability. For example, when the ratio of the number of ride requests to the number of taxis is 6, our proposed system serves three times as many taxi riders as that when no ridesharing is performed while saving 11 percent in total travel distance and 7 percent taxi fare per rider.","Real-time systems,
Servers,
Schedules,
Indexes,
Roads,
Smart phones,
Vehicles"
Prototype-Based Discriminative Feature Learning for Kinship Verification,"In this paper, we propose a new prototype-based discriminative feature learning (PDFL) method for kinship verification. Unlike most previous kinship verification methods which employ low-level hand-crafted descriptors such as local binary pattern and Gabor features for face representation, this paper aims to learn discriminative mid-level features to better characterize the kin relation of face images for kinship verification. To achieve this, we construct a set of face samples with unlabeled kin relation from the labeled face in the wild dataset as the reference set. Then, each sample in the training face kinship dataset is represented as a mid-level feature vector, where each entry is the corresponding decision value from one support vector machine hyperplane. Subsequently, we formulate an optimization function by minimizing the intraclass samples (with a kin relation) and maximizing the neighboring interclass samples (without a kin relation) with the mid-level features. To better use multiple low-level features for mid-level feature learning, we further propose a multiview PDFL method to learn multiple mid-level features to improve the verification performance. Experimental results on four publicly available kinship datasets show the superior performance of the proposed methods over both the state-of-the-art kinship verification methods and human ability in our kinship verification task.","Face,
Feature extraction,
Support vector machines,
Optimization,
Training,
Learning systems,
Vectors"
Tensor Canonical Correlation Analysis for Multi-View Dimension Reduction,"Canonical correlation analysis (CCA) has proven an effective tool for two-view dimension reduction due to its profound theoretical foundation and success in practical applications. In respect of multi-view learning, however, it is limited by its capability of only handling data represented by two-view features, while in many real-world applications, the number of views is frequently many more. Although the ad hoc way of simultaneously exploring all possible pairs of features can numerically deal with multi-view data, it ignores the high order statistics (correlation information) which can only be discovered by simultaneously exploring all features. Therefore, in this work, we develop tensor CCA (TCCA) which straightforwardly yet naturally generalizes CCA to handle the data of an arbitrary number of views by analyzing the covariance tensor of the different views. TCCA aims to directly maximize the canonical correlation of multiple (more than two) views. Crucially, we prove that the main problem of multi-view canonical correlation maximization is equivalent to finding the best rank-1 approximation of the data covariance tensor, which can be solved efficiently using the well-known alternating least squares (ALS) algorithm. As a consequence, the high order correlation information contained in the different views is explored and thus a more reliable common subspace shared by all features can be obtained. In addition, a non-linear extension of TCCA is presented. Experiments on various challenge tasks, including large scale biometric structure prediction, internet advertisement classification, and web image annotation, demonstrate the effectiveness of the proposed method.",
Reversible Image Data Hiding with Contrast Enhancement,"In this letter, a novel reversible data hiding (RDH) algorithm is proposed for digital images. Instead of trying to keep the PSNR value high, the proposed algorithm enhances the contrast of a host image to improve its visual quality. The highest two bins in the histogram are selected for data embedding so that histogram equalization can be performed by repeating the process. The side information is embedded along with the message bits into the host image so that the original image is completely recoverable. The proposed algorithm was implemented on two sets of images to demonstrate its efficiency. To our best knowledge, it is the first algorithm that achieves image contrast enhancement by RDH. Furthermore, the evaluation results show that the visual quality can be preserved after a considerable amount of message bits have been embedded into the contrast-enhanced images, even better than three specific MATLAB functions used for image contrast enhancement.","Histograms,
Signal processing algorithms,
Data mining,
Visualization,
PSNR,
Educational institutions,
Electronic mail"
Consensus + Innovations Approach for Distributed Multiagent Coordination in a Microgrid,"Distributed energy resources and demand-side management are expected to become more prevalent in the future electric power system. Coordinating the increased number of grid participants in an efficient and reliable way is going to be a major challenge. A potential solution is the employment of a distributed energy management approach, which uses intelligence distributed over the grid to balance supply and demand. In this paper, we specifically consider the situation in which distributed resources and loads form microgrids within the bulk power system in which the load is supplied by local generation. A distributed energy management approach based on the consensus + innovations method is presented and used to coordinate local generation, flexible load, and storage devices within the microgrid. The approach takes advantage of the fact that, at the optimal allocation settings, the marginal costs given as a function of the power output/consumption need to be equal for all nonbinding network resources. Solutions for single time step, as well as multitime step optimization including intertemporal constraints, are presented.",
Output-Feedback Adaptive Neural Control for Stochastic Nonlinear Time-Varying Delay Systems With Unknown Control Directions,"This paper presents an adaptive output-feedback neural network (NN) control scheme for a class of stochastic nonlinear time-varying delay systems with unknown control directions. To make the controller design feasible, the unknown control coefficients are grouped together and the original system is transformed into a new system using a linear state transformation technique. Then, the Nussbaum function technique is incorporated into the backstepping recursive design technique to solve the problem of unknown control directions. Furthermore, under the assumption that the time-varying delays exist in the system output, only one NN is employed to compensate for all unknown nonlinear terms depending on the delayed output. Moreover, by estimating the maximum of NN parameters instead of the parameters themselves, the NN parameters to be estimated are greatly decreased and the online learning time is also dramatically decreased. It is shown that all the signals of the closed-loop system are bounded in probability. The effectiveness of the proposed scheme is demonstrated by the simulation results.","Artificial neural networks,
Nonlinear systems,
Adaptive systems,
Time-varying systems,
Backstepping,
Control systems,
Delays"
Reconstruction-Based Metric Learning for Unconstrained Face Verification,"In this paper, we propose a reconstruction-based metric learning method to learn a discriminative distance metric for unconstrained face verification. Unlike conventional metric learning methods, which only consider the label information of training samples and ignore the reconstruction residual information in the learning procedure, we apply a reconstruction criterion to learn a discriminative distance metric. For each training example, the distance metric is learned by enforcing a margin between the interclass sparse reconstruction residual and interclass sparse reconstruction residual, so that the reconstruction residual of training samples can be effectively exploited to compute the between-class and within-class variations. To better use multiple features for distance metric learning, we propose a reconstruction-based multimetric learning method to collaboratively learn multiple distance metrics, one for each feature descriptor, to remove uncorrelated information for recognition. We evaluate our proposed methods on the Labelled Faces in the Wild (LFW) and YouTube face data sets and our experimental results clearly show the superiority of our methods over both previous metric learning methods and several state-of-the-art unconstrained face verification methods.","Measurement,
Face,
Training,
Image reconstruction,
Feature extraction,
Learning systems,
Face recognition"
A Kernel Classification Framework for Metric Learning,"Learning a distance metric from the given training samples plays a crucial role in many machine learning tasks, and various models and optimization algorithms have been proposed in the past decade. In this paper, we generalize several state-of-the-art metric learning methods, such as large margin nearest neighbor (LMNN) and information theoretic metric learning (ITML), into a kernel classification framework. First, doublets and triplets are constructed from the training samples, and a family of degree-2 polynomial kernel functions is proposed for pairs of doublets or triplets. Then, a kernel classification framework is established to generalize many popular metric learning methods such as LMNN and ITML. The proposed framework can also suggest new metric learning methods, which can be efficiently implemented, interestingly, using the standard support vector machine (SVM) solvers. Two novel metric learning methods, namely, doublet-SVM and triplet-SVM, are then developed under the proposed framework. Experimental results show that doublet-SVM and triplet-SVM achieve competitive classification accuracies with state-of-the-art metric learning methods but with significantly less training time.","Measurement,
Kernel,
Support vector machines,
Learning systems,
Training,
Polynomials,
Logistics"
Enabling Cloud Storage Auditing With Key-Exposure Resistance,"Cloud storage auditing is viewed as an important service to verify the integrity of the data in public cloud. Current auditing protocols are all based on the assumption that the client's secret key for auditing is absolutely secure. However, such assumption may not always be held, due to the possibly weak sense of security and/or low security settings at the client. If such a secret key for auditing is exposed, most of the current auditing protocols would inevitably become unable to work. In this paper, we focus on this new aspect of cloud storage auditing. We investigate how to reduce the damage of the client's key exposure in cloud storage auditing, and give the first practical solution for this new problem setting. We formalize the definition and the security model of auditing protocol with key-exposure resilience and propose such a protocol. In our design, we employ the binary tree structure and the preorder traversal technique to update the secret keys for the client. We also develop a novel authenticator construction to support the forward security and the property of blockless verifiability. The security proof and the performance analysis show that our proposed protocol is secure and efficient.","Cloud computing,
Protocols,
Public key,
Resilience,
Binary trees,
Resistance"
Compact Modeling of RRAM Devices and Its Applications in 1T1R and 1S1R Array Design,"In this paper, we present a compact model for metal-oxide-based resistive random access memory (RRAM) devices with bipolar switching characteristics. The switching mechanism relies on the dynamics of conductive filament growth/dissolution in the oxide layer. Besides the dc and pulsed I-V characteristics, the model also captures the RRAM retention property and the temperature dynamics. The model parameters and the device variations are calibrated from the experimental data of IMEC HfOx-based RRAM devices. The model has been implemented in Verilog-A, which can be easily adapted into the SPICE simulator for the circuit-level analysis. As case studies, we demonstrate the model's applications on the programming scheme design of the 1-transistor-1-resistor array, as well as the design space exploration of the 1-selector-1-resistor cross-point array toward megabit-level.",
Are Students Representatives of Professionals in Software Engineering Experiments?,"Background: Most of the experiments in software engineering (SE) employ students as subjects. This raises concerns about the realism of the results acquired through students and adaptability of the results to software industry. Aim: We compare students and professionals to understand how well students represent professionals as experimental subjects in SE research. Method: The comparison was made in the context of two test-driven development experiments conducted with students in an academic setting and with professionals in a software organization. We measured the code quality of several tasks implemented by both subject groups and checked whether students and professionals perform similarly in terms of code quality metrics. Results: Except for minor differences, neither of the subject groups is better than the other. Professionals produce larger, yet less complex, methods when they use their traditional development approach, whereas both subject groups perform similarly when they apply a new approach for the first time. Conclusion: Given a carefully scoped experiment on a development approach that is new to both students and professionals, similar performances are observed. Further investigation is necessary to analyze the effects of subject demographics and level of experience on the results of SE experiments.","Measurement,
Industries,
Software,
Context,
Training,
Inspection,
Complexity theory"
Adaptive NN Control of a Class of Nonlinear Systems With Asymmetric Saturation Actuators,"In this note, adaptive neural network (NN) control is investigated for a class of uncertain nonlinear systems with asymmetric saturation actuators and external disturbances. To handle the effect of nonsmooth asymmetric saturation nonlinearity, a Gaussian error function-based continuous differentiable asymmetric saturation model is employed such that the backstepping technique can be used in the control design. The explosion of complexity in traditional backstepping design is avoided using dynamic surface control. Using radial basis function NN, adaptive control is developed to guarantee that all the signals in the closed-loop system are semiglobally uniformly ultimately bounded, and the tracking error converges to a small neighborhood of origin by appropriately choosing design constants. The effectiveness of the proposed control is demonstrated in the simulation study.","Artificial neural networks,
Actuators,
Adaptation models,
Vectors,
Adaptive systems,
Nonlinear systems,
Backstepping"
Large-scale convex optimization for ultra-dense cloud-RAN,"The heterogeneous cloud radio access network (Cloud-RAN) provides a revolutionary way to densify radio access networks. It enables centralized coordination and signal processing for efficient interference management and flexible network adaptation. Thus it can resolve the main challenges for next-generation wireless networks, including higher energy efficiency and spectral efficiency, higher cost efficiency, scalable connectivity, and low latency. In this article we will provide an algorithmic approach to the new design challenges for the dense heterogeneous Cloud-RAN based on convex optimization. As problem sizes scale up with the network size, we will demonstrate that it is critical to take unique structures of design problems and inherent characteristics of wireless channels into consideration, while convex optimization will serve as a powerful tool for such purposes. Network power minimization and channel state information acquisition will be used as two typical examples to demonstrate the effectiveness of convex optimization methods. Then we will present a twostage framework to solve general large-scale convex optimization problems, which is amenable to parallel implementation in the cloud data center.","Array signal processing,
Convex functions,
Mobile communication,
Radio access networks,
Algorithm design and analysis,
Mobile computing,
Cloud computing"
Tracking Optimal Efficiency of Magnetic Resonance Wireless Power Transfer System for Biomedical Capsule Endoscopy,"This paper presents a new method to track the optimal efficiency of a magnetic resonance (MR)-wireless power transfer (WPT) system for biomedical capsule endoscopy. Recently, capsule endoscopy technology has been developed and emerged as an alternative to small bowel endoscopy, gastroscopy, and colonoscopy, all of which cause discomfort to patients because of their relatively large-diameter and flexible cables. However, commercialized capsule endoscopy still suffers from limited battery capacity. This paper presents a theory for tracking the optimal efficiency of an MR-WPT system, along with its experimental verification. An MR-WPT system with a 9-mm-diameter receiver is implemented, which is small enough to fit in the current capsule endoscope. The proposed system improves the efficiency despite variations in the distance, angle, and axial misalignment, with maximum increases of 2.45, 4.69, and 1.48 dB, respectively. Penetrative transfer through biological tissue is demonstrated with a low degradation in efficiency of 0.390 dB. The proposed system was found to have a very low specific absorption rate of 1.74 W/kg, which demonstrated that it is safe to use in the human body.","Coils,
Endoscopes,
Couplings,
Receivers,
Integrated circuit modeling,
Transmitters,
Magnetic resonance"
Learning contact-rich manipulation skills with guided policy search,"Autonomous learning of object manipulation skills can enable robots to acquire rich behavioral repertoires that scale to the variety of objects found in the real world. However, current motion skill learning methods typically restrict the behavior to a compact, low-dimensional representation, limiting its expressiveness and generality. In this paper, we extend a recently developed policy search method [1] and use it to learn a range of dynamic manipulation behaviors with highly general policy representations, without using known models or example demonstrations. Our approach learns a set of trajectories for the desired motion skill by using iteratively refitted time-varying linear models, and then unifies these trajectories into a single control policy that can generalize to new situations. To enable this method to run on a real robot, we introduce several improvements that reduce the sample count and automate parameter selection. We show that our method can acquire fast, fluent behaviors after only minutes of interaction time, and can learn robust controllers for complex tasks, including putting together a toy airplane, stacking tight-fitting lego blocks, placing wooden rings onto tight-fitting pegs, inserting a shoe tree into a shoe, and screwing bottle caps onto bottles.","Trajectory,
Robots,
Training,
Heuristic algorithms,
Cost function,
Neural networks"
Beyond duty cycling: Wake-up radio with selective awakenings for long-lived wireless sensing systems,"Emerging wake-up radio technologies have the potential to bring the performance of sensing systems and of the Internet of Things to the levels of low latency and very low energy consumption required to enable critical new applications. This paper provides a step towards this goal with a twofold contribution. We first describe the design and prototyping of a wake-up receiver (WRx) and its integration to a wireless sensor node. Our WRx features very low power consumption (<; 1.3μW), high sensitivity (up to -55dBm), fast reactivity (wake-up time of 130μs), and selective addressing, a key enabler of new high performance protocols. We then present ALBA-WUR, a cross-layer solution for data gathering in sensing systems that redesigns a previous leading protocol, ALBA-R, extending it to exploit the features of our WRx. We evaluate the performance of ALBA-WUR via simulations, showing that the use of the WRx produces remarkable energy savings (up to five orders of magnitude), and achieves lifetimes that are decades longer than those obtained by ALBA-R in sensing systems with duty cycling, while keeping latencies at bay.","Relays,
Receivers,
Wireless sensor networks,
Color,
Prototypes,
Sensitivity,
Power demand"
A Monolithically-Integrated Chip-to-Chip Optical Link in Bulk CMOS,"Silicon-photonics is an emerging technology that can overcome the tradeoffs faced by traditional electrical I/O. Due to ballooning development costs for advanced CMOS nodes, however, widespread adoption necessitates seamless photonics integration into mainstream processes, with as few process changes as possible. In this work, we demonstrate a silicon-photonic link with optical devices and electronics integrated on the same chip in a 0.18 μm bulk CMOS memory periphery process. To enable waveguides and optics in process-native polysilicon, we introduce deep-trench isolation, placed underneath to prevent optical mode leakage into the bulk silicon substrate, and implant-amorphization to reduce polysilicon loss. A resonant defect-trap photodetector using polysilicon eliminates need for germanium integration and completes the fully polysilicon-based photonics platform. Transceiver circuits take advantage of photonic device integration, achieving 350 fJ/b transmit and 71 μApp BER = 10-12 receiver sensitivity at 5 Gb/s. We show high fabrication uniformity and high-Q resonators, enabling dense wavelength-division multiplexing with 9-wavelength 45 Gb/s transmit/receive data-rates per waveguide/fiber. To combat perturbations to variation- and thermally-sensitive resonant devices, we demonstrate an on-chip thermal tuning feedback loop that locks the resonance to the laser wavelength. A 5 m optical chip-to-chip link achieves 5 Gb/s while consuming 3 pJ/b and 12 pJ/bit of circuit and optical energy, respectively.",
An Improved Protein Structural Classes Prediction Method by Incorporating Both Sequence and Structure Information,"Protein structural classes information is beneficial for secondary and tertiary structure prediction, protein folds prediction, and protein function analysis. Thus, predicting protein structural classes is of vital importance. In recent years, several computational methods have been developed for low-sequence-similarity (25%-40%) protein structural classes prediction. However, the reported prediction accuracies are actually not satisfactory. Aiming to further improve the prediction accuracies, we propose three different feature extraction methods and construct a comprehensive feature set that captures both sequence and structure information. By applying a random forest (RF) classifier to the feature set, we further develop a novel method for structural classes prediction. We test the proposed method on three benchmark datasets (25PDB, 640, and 1189) with low sequence similarity, and obtain the overall prediction accuracies of 93.5%, 92.6%, and 93.4%, respectively. Compared with six competing methods, the accuracies we achieved are 3.4%, 6.2%, and 8.7% higher than those achieved by the best-performing methods, showing the superiority of our method. Moreover, due to the limitation of the size of the three benchmark datasets, we further test the proposed method on three updated large-scale datasets with different sequence similarities (40%, 30%, and 25%). The proposed method achieves above 90% accuracies for all the three datasets, consistent with the accuracies on the above three benchmark datasets. Experimental results suggest our method as an effective and promising tool for structural classes prediction. Currently, a webserver that implements the proposed method is available on http://121.192.180.204:8080/RF_PSCP/Index.html.","Accuracy,
Feature extraction,
Proteins,
Radio frequency,
Benchmark testing,
Amino acids,
Vectors"
Computation Offloading for Service Workflow in Mobile Cloud Computing,"The development of cloud computing and virtualization techniques enables mobile devices to overcome the severity of scarce resource constrained by allowing them to offload computation and migrate several computation parts of an application to powerful cloud servers. A mobile device should judiciously determine whether to offload computation as well as what portion of an application should be offloaded to the cloud. This paper considers a mobile computation offloading problem where multiple mobile services in workflows can be invoked to fulfill their complex requirements and makes decision on whether the services of a workflow should be offloaded. Due to the mobility of portable devices, unstable connectivity of mobile networks can impact the offloading decision. To address this issue, we propose a novel offloading system to design robust offloading decisions for mobile services. Our approach considers the dependency relations among component services and aims to optimize execution time and energy consumption of executing mobile services. To this end, we also introduce a mobility model and a trade-off fault-tolerance mechanism for the offloading system. A genetic algorithm (GA) based offloading method is then designed and implemented after carefully modifying parts of a generic GA to match our special needs for the stated problem. Experimental results are promising and show nearoptimal solutions for all of our studied cases with almost linear algorithmic complexity with respect to the problem size.",
Memristor-Based Multilayer Neural Networks With Online Gradient Descent Training,"Learning in multilayer neural networks (MNNs) relies on continuous updating of large matrices of synaptic weights by local rules. Such locality can be exploited for massive parallelism when implementing MNNs in hardware. However, these update rules require a multiply and accumulate operation for each synaptic weight, which is challenging to implement compactly using CMOS. In this paper, a method for performing these update operations simultaneously (incremental outer products) using memristor-based arrays is proposed. The method is based on the fact that, approximately, given a voltage pulse, the conductivity of a memristor will increment proportionally to the pulse duration multiplied by the pulse magnitude if the increment is sufficiently small. The proposed method uses a synaptic circuit composed of a small number of components per synapse: one memristor and two CMOS transistors. This circuit is expected to consume between 2% and 8% of the area and static power of previous CMOS-only hardware alternatives. Such a circuit can compactly implement hardware MNNs trainable by scalable algorithms based on online gradient descent (e.g., backpropagation). The utility and robustness of the proposed memristor-based circuit are demonstrated on standard supervised learning tasks.",
Multilayer Silicon Nitride-on-Silicon Integrated Photonic Platforms and Devices,"We review and present additional results from our work on multilayer silicon nitride (SiN) on silicon-on-insulator (SOI) integrated photonic platforms over the telecommunication wavelength bands near 1550 and 1310 nm. SiN-on-SOI platforms open the possibility for passive optical functionalities implemented in the SiN layer to be combined with active functionalities in the SOI. SiN layers can be integrated onto SOI using a front-end or back-end of line integration process flow. These photonic platforms support low-loss SiN waveguides, low-loss and low-crosstalk waveguide crossings, and low-loss interlayer transitions using adiabatic tapers. Novel ultra-broadband and efficient grating couplers as well as polarization management devices are enabled by the close coupling between the silicon and SiN layers.",
Bayesian CP Factorization of Incomplete Tensors with Automatic Rank Determination,"CANDECOMP/PARAFAC (CP) tensor factorization of incomplete data is a powerful technique for tensor completion through explicitly capturing the multilinear latent factors. The existing CP algorithms require the tensor rank to be manually specified, however, the determination of tensor rank remains a challenging problem especially for CP rank . In addition, existing approaches do not take into account uncertainty information of latent factors, as well as missing entries. To address these issues, we formulate CP factorization using a hierarchical probabilistic model and employ a fully Bayesian treatment by incorporating a sparsity-inducing prior over multiple latent factors and the appropriate hyperpriors over all hyperparameters, resulting in automatic rank determination. To learn the model, we develop an efficient deterministic Bayesian inference algorithm, which scales linearly with data size. Our method is characterized as a tuning parameter-free approach, which can effectively infer underlying multilinear factors with a low-rank constraint, while also providing predictive distributions over missing entries. Extensive simulations on synthetic data illustrate the intrinsic capability of our method to recover the ground-truth of CP rank and prevent the overfitting problem, even when a large amount of entries are missing. Moreover, the results from real-world applications, including image inpainting and facial image synthesis, demonstrate that our method outperforms state-of-the-art approaches for both tensor factorization and tensor completion in terms of predictive performance.",
"An untethered miniature origami robot that self-folds, walks, swims, and degrades","A miniature robotic device that can fold-up on the spot, accomplish tasks, and disappear by degradation into the environment promises a range of medical applications but has so far been a challenge in engineering. This work presents a sheet that can self-fold into a functional 3D robot, actuate immediately for untethered walking and swimming, and subsequently dissolve in liquid. The developed sheet weighs 0.31 g, spans 1.7 cm square in size, features a cubic neodymium magnet, and can be thermally activated to self-fold. Since the robot has asymmetric body balance along the sagittal axis, the robot can walk at a speed of 3.8 body-length/s being remotely controlled by an alternating external magnetic field. We further show that the robot is capable of conducting basic tasks and behaviors, including swimming, delivering/carrying blocks, climbing a slope, and digging. The developed models include an acetone-degradable version, which allows the entire robot's body to vanish in a liquid. We thus experimentally demonstrate the complete life cycle of our robot: self-folding, actuation, and degrading.","Legged locomotion,
Coils,
Saturation magnetization,
Heating,
Magnetic moments,
Torque"
Boosting for Multi-Graph Classification,"In this paper, we formulate a novel graph-based learning problem, multi-graph classification (MGC), which aims to learn a classifier from a set of labeled bags each containing a number of graphs inside the bag. A bag is labeled positive, if at least one graph in the bag is positive, and negative otherwise. Such a multi-graph representation can be used for many real-world applications, such as webpage classification, where a webpage can be regarded as a bag with texts and images inside the webpage being represented as graphs. This problem is a generalization of multi-instance learning (MIL) but with vital differences, mainly because instances in MIL share a common feature space whereas no feature is available to represent graphs in a multi-graph bag. To solve the problem, we propose a boosting based multi-graph classification framework (bMGC). Given a set of labeled multi-graph bags, bMGC employs dynamic weight adjustment at both bag- and graph-levels to select one subgraph in each iteration as a weak classifier. In each iteration, bag and graph weights are adjusted such that an incorrectly classified bag will receive a higher weight because its predicted bag label conflicts to the genuine label, whereas an incorrectly classified graph will receive a lower weight value if the graph is in a positive bag (or a higher weight if the graph is in a negative bag). Accordingly, bMGC is able to differentiate graphs in positive and negative bags to derive effective classifiers to form a boosting model for MGC. Experiments and comparisons on real-world multi-graph learning tasks demonstrate the algorithm performance.","Graph classification,
Subgraph mining,
Labeling,
Feature extraction,
Algorithm design and analysis,
Classification"
Human Facial Expression Recognition Using Stepwise Linear Discriminant Analysis and Hidden Conditional Random Fields,"This paper introduces an accurate and robust facial expression recognition (FER) system. For feature extraction, the proposed FER system employs stepwise linear discriminant analysis (SWLDA). SWLDA focuses on selecting the localized features from the expression frames using the partial F-test values, thereby reducing the within class variance and increasing the low between variance among different expression classes. For recognition, the hidden conditional random fields (HCRFs) model is utilized. HCRF is capable of approximating a complex distribution using a mixture of Gaussian density functions. To achieve optimum results, the system employs a hierarchical recognition strategy. Under these settings, expressions are divided into three categories based on parts of the face that contribute most toward an expression. During recognition, at the first level, SWLDA and HCRF are employed to recognize the expression category; whereas, at the second level, the label for the expression within the recognized category is determined using a separate set of SWLDA and HCRF, trained just for that category. In order to validate the system, four publicly available data sets were used, and a total of four experiments were performed. The weighted average recognition rate for the proposed FER approach was 96.37% across the four different data sets, which is a significant improvement in contrast to the existing FER methods.",
ACE: An Accurate and Efficient Multi-Entity Device-Free WLAN Localization System,"Device-free (DF) localization in WLANs has been introduced as a value-added service that allows tracking of indoor entities that do not carry any devices. Previous work in DF WLAN localization focused on the tracking of a single entity due to the intractability of the multi-entity tracking problem whose complexity grows exponentially with the number of humans being tracked. In this paper, we introduce ACE: a system that uses a probabilistic energy-minimization framework that combines a conditional random field with a Markov model to capture the temporal and spatial relations between the entities' poses. A novel cross-calibration technique is introduced to reduce the calibration overhead of multiple entities to linear, regardless of the number of humans being tracked. We design an efficient energy-minimization function that can be mapped to a binary graph-cut problem whose solution has a linear complexity on average and a third order polynomial in the worst case. We further employ clustering on the estimated location candidates to reduce outliers and obtain more accurate tracking in the continuous space. Experimental evaluation in two typical testbeds, with a side-by-side comparison with the state-of-the-art, shows that ACE can achieve a multi-entity tracking accuracy of less than 1.3 m. This corresponds to at least 11.8 percent, and up to 33 percent, enhancement in median distance error over the state-of-the-art DF localization systems. In addition, ACEcan estimate the number of entities correctly to within one difference error for 100 percent of the time. This highlights that ACE achieves its goals of having an accurate and efficient multi-entity indoors localization.",
Randomized Dimensionality Reduction for k -Means Clustering,"We study the topic of dimensionality reduction for k-means clustering. Dimensionality reduction encompasses the union of two approaches: 1) feature selection and 2) feature extraction. A feature selection-based algorithm for k-means clustering selects a small subset of the input features and then applies k-means clustering on the selected features. A feature extraction-based algorithm for k-means clustering constructs a small set of new artificial features and then applies k-means clustering on the constructed features. Despite the significance of k-means clustering as well as the wealth of heuristic methods addressing it, provably accurate feature selection methods for k-means clustering are not known. On the other hand, two provably accurate feature extraction methods for k-means clustering are known in the literature; one is based on random projections and the other is based on the singular value decomposition (SVD). This paper makes further progress toward a better understanding of dimensionality reduction for k-means clustering. Namely, we present the first provably accurate feature selection method for k-means clustering and, in addition, we present two feature extraction methods. The first feature extraction method is based on random projections and it improves upon the existing results in terms of time complexity and number of features needed to be extracted. The second feature extraction method is based on fast approximate SVD factorizations and it also improves upon the existing results in terms of time complexity. The proposed algorithms are randomized and provide constant-factor approximation guarantees with respect to the optimal k-means objective value.","Feature extraction,
Approximation methods,
Approximation algorithms,
Clustering algorithms,
Optimized production technology,
Vectors,
Linear matrix inequalities"
Demand Response Using Linear Supply Function Bidding,"In this paper, we consider an abstract market model for demand response where a supply function bidding is applied to match power supply deficit or surplus. We characterize the resulting equilibria in competitive and oligopolistic markets and propose distributed demand response algorithms to achieve the equilibria. We further show that the equilibrium in competitive market maximizes social welfare, and the equilibrium in oligopolistic market has bounded efficiency loss under certain mild assumptions. We also propose distributed demand response algorithms to achieve the equilibria.",
Cascading Failure Analysis With DC Power Flow Model and Transient Stability Analysis,"When the modern electrical infrastructure is undergoing a migration to the Smart Grid, vulnerability and security concerns have also been raised regarding the cascading failure threats in this interconnected transmission system with complex communication and control challenge. The DC power flow-based model has been a popular model to study the cascading failure problem due to its efficiency, simplicity and scalability in simulations of such failures. However, due to the complex nature of the power system and cascading failures, the underlying assumptions in DC power flow-based cascading failure simulators (CFS) may fail to hold during the development of cascading failures. This paper compares the validity of a typical DC power flow-based CFS in cascading failure analysis with a new numerical metric defined as the critical moment (CM). The adopted CFS is first implemented to simulate system behavior after initial contingencies and to evaluate the utility of DC-CFS in cascading failure analysis. Then the DC-CFS is compared against another classic, more precise power system stability methodology, i.e., the transient stability analysis (TSA). The CM is introduced with a case study to assess the utilization of these two models for cascading failure analysis. Comparative simulations on the IEEE 39-bus and 68-bus benchmark reveal important consistency and discrepancy between these two approaches. Some suggestions are provided for using these two models in the power grid cascading failure analysis.",
Quickest Detection of False Data Injection Attack in Wide-Area Smart Grids,"We consider the sequential (i.e., online) detection of false data injection attacks in smart grid, which aims to manipulate the state estimation procedure by injecting malicious data to the monitoring meters. The unknown parameters in the system, namely the state vector, injected malicious data and the set of attacked meters pose a significant challenge for designing a robust, computationally efficient, and high-performance detector. We propose a sequential detector based on the generalized likelihood ratio to address this challenge. Specifically, the proposed detector is designed to be robust to a variety of attacking strategies, and load situations in the power system, and its computational complexity linearly scales with the number of meters. Moreover, it considerably outperforms the existing first-order cumulative sum detector in terms of the average detection delay and robustness to various attacking strategies. For wide-area monitoring in smart grid, we further develop a distributed sequential detector using an adaptive sampling technique called level-triggered sampling. The resulting distributed detector features single bit per sample in terms of the communication overhead, while preserving the high performance of the proposed centralized detector.",
The Use of Averaged-Value Model of Modular Multilevel Converter in DC Grid,"This paper investigates the applicability of averaged-value models (AVMs) for modular multilevel converters (MMCs) operating in a voltage-sourced converter-based-high-voltage dc (VSC-HVDC) grid. The AVM models are benchmarked by comparison with a detailed electromagnetic transient model of the grid, including a fully detailed MMC model. Analysis results show that the AVM is only effective as long as the capacitors are large enough to maintain nearly constant voltage across each MMC submodule. This paper also shows that previously developed MMC averaged models are not able to accurately simulate the transients under dc fault conditions. This paper introduces topology changes to a previously proposed averaged model that results in much improved simulation for such conditions. This paper also shows that the model can be used effectively to study HVDC grids with significant time savings.",
Global Linking of Cell Tracks Using the Viterbi Algorithm,"Automated tracking of living cells in microscopy image sequences is an important and challenging problem. With this application in mind, we propose a global track linking algorithm, which links cell outlines generated by a segmentation algorithm into tracks. The algorithm adds tracks to the image sequence one at a time, in a way which uses information from the complete image sequence in every linking decision. This is achieved by finding the tracks which give the largest possible increases to a probabilistically motivated scoring function, using the Viterbi algorithm. We also present a novel way to alter previously created tracks when new tracks are created, thus mitigating the effects of error propagation. The algorithm can handle mitosis, apoptosis, and migration in and out of the imaged area, and can also deal with false positives, missed detections, and clusters of jointly segmented cells. The algorithm performance is demonstrated on two challenging datasets acquired using bright-field microscopy, but in principle, the algorithm can be used with any cell type and any imaging technique, presuming there is a suitable segmentation algorithm.","Joining processes,
Image segmentation,
Target tracking,
Image sequences,
Clustering algorithms,
Heuristic algorithms,
Microscopy"
Background Subtraction Based on Low-Rank and Structured Sparse Decomposition,"Low rank and sparse representation based methods, which make few specific assumptions about the background, have recently attracted wide attention in background modeling. With these methods, moving objects in the scene are modeled as pixel-wised sparse outliers. However, in many practical scenarios, the distributions of these moving parts are not truly pixel-wised sparse but structurally sparse. Meanwhile a robust analysis mechanism is required to handle background regions or foreground movements with varying scales. Based on these two observations, we first introduce a class of structured sparsity-inducing norms to model moving objects in videos. In our approach, we regard the observed sequence as being constituted of two terms, a low-rank matrix (background) and a structured sparse outlier matrix (foreground). Next, in virtue of adaptive parameters for dynamic videos, we propose a saliency measurement to dynamically estimate the support of the foreground. Experiments on challenging well known data sets demonstrate that the proposed approach outperforms the state-of-the-art methods and works effectively on a wide range of complex videos.","Sparse matrices,
Videos,
Robustness,
Matrix decomposition,
Computer science,
Object segmentation,
Adaptation models"
Assess Sleep Stage by Modern Signal Processing Techniques,"In this paper, two modern adaptive signal processing techniques, empirical intrinsic geometry and synchrosqueezing transform, are applied to quantify different dynamical features of the respiratory and electroencephalographic signals. We show that the proposed features are theoretically rigorously supported, as well as capture the sleep information hidden inside the signals. The features are used as input to multiclass support vector machines with the radial basis function to automatically classify sleep stages. The effectiveness of the classification based on the proposed features is shown to be comparable to human expert classification-the proposed classification of awake, REM, N1, N2, and N3 sleeping stages based on the respiratory signal (resp. respiratory and EEG signals) has the overall accuracy 81.7% (resp. 89.3%) in the relatively normal subject group. In addition, by examining the combination of the respiratory signal with the electroencephalographic signal, we conclude that the respiratory signal consists of ample sleep information, which supplements to the information stored in the electroencephalographic signal.","Sleep,
Electroencephalography,
Transforms,
Mathematical model,
Time-frequency analysis,
Noise,
Feature extraction"
MOMMOP: Multiobjective Optimization for Locating Multiple Optimal Solutions of Multimodal Optimization Problems,"In the field of evolutionary computation, there has been a growing interest in applying evolutionary algorithms to solve multimodal optimization problems (MMOPs). Due to the fact that an MMOP involves multiple optimal solutions, many niching methods have been suggested and incorporated into evolutionary algorithms for locating such optimal solutions in a single run. In this paper, we propose a novel transformation technique based on multiobjective optimization for MMOPs, called MOMMOP. MOMMOP transforms an MMOP into a multiobjective optimization problem with two conflicting objectives. After the above transformation, all the optimal solutions of an MMOP become the Pareto optimal solutions of the transformed problem. Thus, multiobjective evolutionary algorithms can be readily applied to find a set of representative Pareto optimal solutions of the transformed problem, and as a result, multiple optimal solutions of the original MMOP could also be simultaneously located in a single run. In principle, MOMMOP is an implicit niching method. In this paper, we also discuss two issues in MOMMOP and introduce two new comparison criteria. MOMMOP has been used to solve 20 multimodal benchmark test functions, after combining with nondominated sorting and differential evolution. Systematic experiments have indicated that MOMMOP outperforms a number of methods for multimodal optimization, including four recent methods at the 2013 IEEE Congress on Evolutionary Computation, four state-of-the-art single-objective optimization based methods, and two well-known multiobjective optimization based approaches.","Vectors,
Sociology,
Pareto optimization,
Evolutionary computation,
Educational institutions"
Composite Particle Swarm Optimizer With Historical Memory for Function Optimization,"Particle swarm optimization (PSO) algorithm is a population-based stochastic optimization technique. It is characterized by the collaborative search in which each particle is attracted toward the global best position (gbest) in the swarm and its own best position (pbest). However, all of particles' historical promising pbests in PSO are lost except their current pbests. In order to solve this problem, this paper proposes a novel composite PSO algorithm, called historical memory-based PSO (HMPSO), which uses an estimation of distribution algorithm to estimate and preserve the distribution information of particles' historical promising pbests. Each particle has three candidate positions, which are generated from the historical memory, particles' current pbests, and the swarm's gbest. Then the best candidate position is adopted. Experiments on 28 CEC2013 benchmark functions demonstrate the superiority of HMPSO over other algorithms.",
Fault Diagnosis of Electric Power Systems Based on Fuzzy Reasoning Spiking Neural P Systems,"This paper proposes a graphic modeling approach, fault diagnosis method based on fuzzy reasoning spiking neural P systems (FDSNP), for power transmission networks. In FDSNP, fuzzy reasoning spiking neural P systems (FRSN P systems) with trapezoidal fuzzy numbers are used to model candidate faulty sections and an algebraic fuzzy reasoning algorithm is introduced to obtain confidence levels of candidate faulty sections, so as to identify faulty sections. FDSNP offers an intuitive illustration based on a strictly mathematical expression, a good fault-tolerant capacity due to its handling of incomplete and uncertain messages in a parallel manner, a good description for the relationships between protective devices and faults, and an understandable diagnosis model-building process. To test the validity and feasibility of FDSNP, seven cases of a local subsystem in an electrical power system are used. The results of case studies show that FDSNP is effective in diagnosing faults in power transmission networks for single and multiple fault situations with/without incomplete and uncertain SCADA data, and is superior to four methods, reported in the literature, in terms of the correctness of diagnosis results.",
A Variational Approach to Simultaneous Image Segmentation and Bias Correction,"This paper presents a novel variational approach for simultaneous estimation of bias field and segmentation of images with intensity inhomogeneity. We model intensity of inhomogeneous objects to be Gaussian distributed with different means and variances, and then introduce a sliding window to map the original image intensity onto another domain, where the intensity distribution of each object is still Gaussian but can be better separated. The means of the Gaussian distributions in the transformed domain can be adaptively estimated by multiplying the bias field with a piecewise constant signal within the sliding window. A maximum likelihood energy functional is then defined on each local region, which combines the bias field, the membership function of the object region, and the constant approximating the true signal from its corresponding object. The energy functional is then extended to the whole image domain by the Bayesian learning approach. An efficient iterative algorithm is proposed for energy minimization, via which the image segmentation and bias field correction are simultaneously achieved. Furthermore, the smoothness of the obtained optimal bias field is ensured by the normalized convolutions without extra cost. Experiments on real images demonstrated the superiority of the proposed algorithm to other state-of-the-art representative methods.",
A Strategy of Clustering Modification Directions in Spatial Image Steganography,"Most of the recently proposed steganographic schemes are based on minimizing an additive distortion function defined as the sum of embedding costs for individual pixels. In such an approach, mutual embedding impacts are often ignored. In this paper, we present an approach that can exploit the interactions among embedding changes in order to reduce the risk of detection by steganalysis. It employs a novel strategy, called clustering modification directions (CMDs), based on the assumption that when embedding modifications in heavily textured regions are locally heading toward the same direction, the steganographic security might be improved. To implement the strategy, a cover image is decomposed into several subimages, in which message segments are embedded with well-known schemes using additive distortion functions. The costs of pixels are updated dynamically to take mutual embedding impacts into account. Specifically, when neighboring pixels are changed toward a positive/negative direction, the cost of the considered pixel is biased toward the same direction. Experimental results show that our proposed CMD strategy, incorporated into existing steganographic schemes, can effectively overcome the challenges posed by the modern steganalyzers with high-dimensional features.",
Distributed and Decentralized Control of Residential Energy Systems Incorporating Battery Storage,"The recent rapid uptake of residential solar photovoltaic installations provides many challenges for electricity distribution networks designed for one-way power flow from the generator to residential customers via transmission and distribution networks. For grid-connected installations, large amounts of generation during low load periods or intermittent generation can lead to a difficulty in balancing supply and demand, maintaining voltage and frequency stability, and may even result in outages due to overvoltage conditions tripping protection circuits. In this paper, we present four control methodologies to mitigate these difficulties using small-scale distributed battery storage. These four approaches represent three different control architectures: 1) centralized; 2) decentralized; and 3) distributed control. These approaches are validated and compared using data on load and generation profiles from customers in an Australian electricity distribution network.","Batteries,
Decentralized control,
Electricity,
Cost function,
Power demand,
Computational modeling"
Multi-task deep visual-semantic embedding for video thumbnail selection,"Given the tremendous growth of online videos, video thumbnail, as the common visualization form of video content, is becoming increasingly important to influence user's browsing and searching experience. However, conventional methods for video thumbnail selection often fail to produce satisfying results as they ignore the side semantic information (e.g., title, description, and query) associated with the video. As a result, the selected thumbnail cannot always represent video semantics and the click-through rate is adversely affected even when the retrieved videos are relevant. In this paper, we have developed a multi-task deep visual-semantic embedding model, which can automatically select query-dependent video thumbnails according to both visual and side information. Different from most existing methods, the proposed approach employs the deep visual-semantic embedding model to directly compute the similarity between the query and video thumbnails by mapping them into a common latent semantic space, where even unseen query-thumbnail pairs can be correctly matched. In particular, we train the embedding model by exploring the large-scale and freely accessible click-through video and image data, as well as employing a multi-task learning strategy to holistically exploit the query-thumbnail relevance from these two highly related datasets. Finally, a thumbnail is selected by fusing both the representative and query relevance scores. The evaluations on 1,000 query-thumbnail dataset labeled by 191 workers in Amazon Mechanical Turk have demonstrated the effectiveness of our proposed method.",
Probabilistic Common Spatial Patterns for Multichannel EEG Analysis,"Common spatial patterns (CSP) is a well-known spatial filtering algorithm for multichannel electroencephalogram (EEG) analysis. In this paper, we cast the CSP algorithm in a probabilistic modeling setting. Specifically, probabilistic CSP (P-CSP) is proposed as a generic EEG spatio-temporal modeling framework that subsumes the CSP and regularized CSP algorithms. The proposed framework enables us to resolve the overfitting issue of CSP in a principled manner. We derive statistical inference algorithms that can alleviate the issue of local optima. In particular, an efficient algorithm based on eigendecomposition is developed for maximum a posteriori (MAP) estimation in the case of isotropic noise. For more general cases, a variational algorithm is developed for group-wise sparse Bayesian learning for the P-CSP model and for automatically determining the model size. The two proposed algorithms are validated on a simulated data set. Their practical efficacy is also demonstrated by successful applications to single-trial classifications of three motor imagery EEG data sets and by the spatio-temporal pattern analysis of one EEG data set recorded in a Stroop color naming task.","Electroencephalography,
Algorithm design and analysis,
Inference algorithms,
Bayes methods,
Brain models,
Probabilistic logic"
Compact and Efficient Bipolar Coupler for Wireless Power Chargers: Design and Analysis,"Compactness and efficiency are the two basic considerations of the wireless battery chargers for electric vehicles (EVs) and plug-in hybrid EVs. The double-sided LCC compensation topology for wireless power transfer (WPT) has been proved to be one of the efficient solutions lately. However, with the increase of the numbers of compensation components, the volume of the system may become larger, which makes it less attractive. To improve the compactness, a bipolar coupler structure with a compensation-integrated feature is proposed. The inductors of the LCC compensation networks are designed as planar-type and attached to the power-transferring main coils. Extra space and magnetic cores for the compensated inductors outside of the coupler are saved. The cost is that extra couplings between the compensated coils (inductors) and the main coils are induced. To validate the feasibility, the proposed coupler is modeled and investigated by 3-D finite-element analysis tool first. The positioning of the compensated coils, the range of the extra couplings, and the tolerance to misalignment are studied. This is followed by the circuit modeling and characteristic analysis of the proposed WPT topology based on the fundamental harmonic approximation. At last, a 600 mm × 600 mm with a nominal 150-mm-gap wireless charger prototype, operated at a resonant frequency of 95 kHz and a rated power of 5.6 kW has been built and tested. A peak efficiency of 95.36% from a dc power source to the battery load is achieved at rated operation condition.","Coils,
Couplings,
Inductors,
Couplers,
Inductance,
Topology,
Wireless communication"
Enhanced Protein Fold Prediction Method Through a Novel Feature Extraction Technique,"Information of protein 3-dimensional (3D) structures plays an essential role in molecular biology, cell biology, biomedicine, and drug design. Protein fold prediction is considered as an immediate step for deciphering the protein 3D structures. Therefore, protein fold prediction is one of fundamental problems in structural bioinformatics. Recently, numerous taxonomic methods have been developed for protein fold prediction. Unfortunately, the overall prediction accuracies achieved by existing taxonomic methods are not satisfactory although much progress has been made. To address this problem, we propose a novel taxonomic method, called PFPA, which is featured by combining a novel feature set through an ensemble classifier. Particularly, the sequential evolution information from the profiles of PSI-BLAST and the local and global secondary structure information from the profiles of PSI-PRED are combined to construct a comprehensive feature set. Experimental results demonstrate that PFPA outperforms the state-of-the-art predictors. To be specific, when tested on the independent testing set of a benchmark dataset, PFPA achieves an overall accuracy of 73.6%, which is the leading accuracy ever reported. Moreover, PFPA performs well without significant performance degradation on three updated large-scale datasets, indicating the robustness and generalization of PFPA. Currently, a webserver that implements PFPA is freely available on http://121.192.180.204:8080/PFPA/Index.html.","Feature extraction,
Proteins,
Accuracy,
Protein engineering,
Amino acids,
Three-dimensional displays,
Testing"
A New Sensorless Hybrid MPPT Algorithm Based on Fractional Short-Circuit Current Measurement and P&O MPPT,"This paper presents a new maximum power point tracking (MPPT) method for photovoltaic (PV) systems. The proposed method improves the working of the conventional perturb and observe (P&O) method in changing environmental conditions by using the fractional short-circuit current (FSCC) method. It takes the initial operating point of a PV system by using the short-circuit current method and later shifts to the conventional P&O technique. The advantage of having this two-stage algorithm is rapid tracking under changing environmental conditions. In addition, this scheme offers low-power oscillations around MPP and, therefore, more power harvesting compared with the common P&O method. The proposed MPPT decides intelligently about the moment of measuring short-circuit current and is, therefore, an irradiance sensorless scheme. The proposed method is validated with computer software simulation followed by a dSPACE DS1104-based experimental setup. A buck-boost dc-dc converter is used for simulation and experimental confirmation. Furthermore, the reliability of the proposed method is also calculated. The results show that the proposed MPPT technique works satisfactorily under given environmental scenarios.",
Coexistence of WiFi and LTE in unlicensed bands: A proportional fair allocation scheme,"The use of the unlicensed spectrum by LTE networks (LTE-U or LAA-LTE) is being considered by mobile operators in order to satisfy increasing traffic demands and to make better use of the licensed spectrum. However, coexistence issues arise when LTE-U coverage overlaps with other technologies currently operating in unlicensed bands, in particular WiFi. Since LTE uses a TDMA/OFDMA scheduled approach, coexisting WiFi networks may face starvation if the channel is fully occupied by LTE-U transmissions. In this paper we derive a novel proportional fair allocation scheme that ensures fair coexistence between LTE-U and WiFi. Importantly, we find that the proportional fair allocation is qualitatively different from previously considered WiFi-only settings and that since the resulting allocation requires only quite limited knowledge of network parameters it is potentially easy to implement in practice, without the need for message-passing between heterogeneous networks.",
Ergodic Capacity Analysis of Free-Space Optical Links With Nonzero Boresight Pointing Errors,"A unified capacity analysis of a free-space optical (FSO) link that accounts for nonzero boresight pointing errors and both types of detection techniques (i.e. intensity modulation/direct detection as well as heterodyne detection) is addressed in this work. More specifically, an exact closed-form expression for the moments of the end-to-end signal-to-noise ratio (SNR) of a single link FSO transmission system is presented in terms of well-known elementary functions. Capitalizing on these new moments expressions, we present approximate and simple closed-form results for the ergodic capacity at high and low SNR regimes. All the presented results are verified via computer-based Monte-Carlo simulations.",
Efficient Feature Selection and Classification for Vehicle Detection,"The focus of this paper is on the problem of Haar-like feature selection and classification for vehicle detection. Haar-like features are particularly attractive for vehicle detection because they form a compact representation, encode edge and structural information, capture information from multiple scales, and especially can be computed efficiently. Due to the large-scale nature of the Haar-like feature pool, we present a rapid and effective feature selection method via AdaBoost by combining a sample's feature value with its class label. Our approach is analyzed theoretically and empirically to show its efficiency. Then, an improved normalization algorithm for the selected feature values is designed to reduce the intra-class difference, while increasing the inter-class variability. Experimental results demonstrate that the proposed approaches not only speed up the feature selection process with AdaBoost, but also yield better detection performance than the state-of-the-art methods.","Feature extraction,
Vehicles,
Vehicle detection,
Training,
Educational institutions,
Support vector machines,
Information science"
Full-Reference Quality Assessment of Stereoscopic Images by Learning Binocular Receptive Field Properties,"Quality assessment of 3D images encounters more challenges than its 2D counterparts. Directly applying 2D image quality metrics is not the solution. In this paper, we propose a new full-reference quality assessment for stereoscopic images by learning binocular receptive field properties to be more in line with human visual perception. To be more specific, in the training phase, we learn a multiscale dictionary from the training database, so that the latent structure of images can be represented as a set of basis vectors. In the quality estimation phase, we compute sparse feature similarity index based on the estimated sparse coefficient vectors by considering their phase difference and amplitude difference, and compute global luminance similarity index by considering luminance changes. The final quality score is obtained by incorporating binocular combination based on sparse energy and sparse complexity. Experimental results on five public 3D image quality assessment databases demonstrate that in comparison with the most related existing methods, the devised algorithm achieves high consistency with subjective assessment.",
Learning Consistent Feature Representation for Cross-Modal Multimedia Retrieval,"The cross-modal feature matching has gained much attention in recent years, which has many practical applications, such as the text-to-image retrieval. The most difficult problem of cross-modal matching is how to eliminate the heterogeneity between modalities. The existing methods (e.g., CCA and PLS) try to learn a common latent subspace, where the heterogeneity between two modalities is minimized so that cross-matching is possible. However, most of these methods require fully paired samples and suffer difficulties when dealing with unpaired data. Besides, utilizing the class label information has been found as a good way to reduce the semantic gap between the low-level image features and high-level document descriptions. Considering this, we propose a novel and effective supervised algorithm, which can also deal with the unpaired data. In the proposed formulation, the basis matrices of different modalities are jointly learned based on the training samples. Moreover, a local group-based priori is proposed in the formulation to make a better use of popular block based features (e.g., HOG and GIST). Extensive experiments are conducted on four public databases: Pascal VOC2007, LabelMe, Wikipedia, and NUS-WIDE. We also evaluated the proposed algorithm with unpaired data. By comparing with existing state-of-the-art algorithms, the results show that the proposed algorithm is more robust and achieves the best performance, which outperforms the second best algorithm by about 5% on both the Pascal VOC2007 and NUS-WIDE databases.",
Model-Free Dual Heuristic Dynamic Programming,"Model-based dual heuristic dynamic programming (MB-DHP) is a popular approach in approximating optimal solutions in control problems. Yet, it usually requires offline training for the model network, and thus resulting in extra computational cost. In this brief, we propose a model-free DHP (MF-DHP) design based on finite-difference technique. In particular, we adopt multilayer perceptron with one hidden layer for both the action and the critic networks design, and use delayed objective functions to train both the action and the critic networks online over time. We test both the MF-DHP and MB-DHP approaches with a discrete time example and a continuous time example under the same parameter settings. Our simulation results demonstrate that the MF-DHP approach can obtain a control performance competitive with that of the traditional MB-DHP approach while requiring less computational resources.","Computational modeling,
Dynamic programming,
Convergence,
Approximation methods,
Mathematical model,
Linear programming,
Learning systems"
Behavior Rule Specification-Based Intrusion Detection for Safety Critical Medical Cyber Physical Systems,"We propose and analyze a behavior-rule specification-based technique for intrusion detection of medical devices embedded in a medical cyber physical system (MCPS) in which the patient's safety is of the utmost importance. We propose a methodology to transform behavior rules to a state machine, so that a device that is being monitored for its behavior can easily be checked against the transformed state machine for deviation from its behavior specification. Using vital sign monitor medical devices as an example, we demonstrate that our intrusion detection technique can effectively trade false positives off for a high detection probability to cope with more sophisticated and hidden attackers to support ultra safe and secure MCPS applications. Moreover, through a comparative analysis, we demonstrate that our behavior-rule specification-based IDS technique outperforms two existing anomaly-based techniques for detecting abnormal patient behaviors in pervasive healthcare applications.",
Chest pathology detection using deep learning with non-medical training,"In this work, we examine the strength of deep learning approaches for pathology detection in chest radiographs. Convolutional neural networks (CNN) deep architecture classification approaches have gained popularity due to their ability to learn mid and high level image representations. We explore the ability of CNN learned from a non-medical dataset to identify different types of pathologies in chest x-rays. We tested our algorithm on a 433 image dataset. The best performance was achieved using CNN and GIST features. We obtained an area under curve (AUC) of 0.87-0.94 for the different pathologies. The results demonstrate the feasibility of detecting pathology in chest x-rays using deep learning approaches based on non-medical learning. This is a first-of-its-kind experiment that shows that Deep learning with ImageNet, a large scale non-medical image database may be a good substitute to domain specific representations, which are yet to be available, for general medical image recognition tasks.","Pathology,
Machine learning,
Visualization,
X-rays,
Biomedical imaging,
Diagnostic radiography,
Feature extraction"
An Interaction Model for Simulation and Mitigation of Cascading Failures,"In this paper, the interactions between component failures are quantified and the interaction matrix and interaction network are obtained. The quantified interactions can capture the general propagation patterns of the cascades from utilities or simulation, thus helping to better understand how cascading failures propagate and to identify key links and key components that are crucial for cascading failure propagation. By utilizing these interactions a high-level probabilistic model called interaction model is proposed to study the influence of interactions on cascading failure risk and to support online decision-making. It is much more time-efficient to first quantify the interactions between component failures with fewer original cascades from a more detailed cascading failure model and then perform the interaction model simulation than it is to directly simulate a large number of cascades with a more detailed model. Interaction-based mitigation measures are suggested to mitigate cascading failure risk by weakening key links, which can be achieved in real systems by wide-area protection such as blocking of some specific protective relays. The proposed interaction quantifying method and interaction model are validated with line outage data generated by the AC OPA cascading simulations on the IEEE 118-bus system.",
Investigating Critical Frequency Bands and Channels for EEG-Based Emotion Recognition with Deep Neural Networks,"To investigate critical frequency bands and channels, this paper introduces deep belief networks (DBNs) to constructing EEG-based emotion recognition models for three emotions: positive, neutral and negative. We develop an EEG dataset acquired from 15 subjects. Each subject performs the experiments twice at the interval of a few days. DBNs are trained with differential entropy features extracted from multichannel EEG data. We examine the weights of the trained DBNs and investigate the critical frequency bands and channels. Four different profiles of 4, 6, 9, and 12 channels are selected. The recognition accuracies of these four profiles are relatively stable with the best accuracy of 86.65%, which is even better than that of the original 62 channels. The critical frequency bands and channels determined by using the weights of trained DBNs are consistent with the existing observations. In addition, our experiment results show that neural signatures associated with different emotions do exist and they share commonality across sessions and individuals. We compare the performance of deep models with shallow models. The average accuracies of DBN, SVM, LR, and KNN are 86.08%, 83.99%, 82.70%, and 72.60%, respectively.","Electroencephalography,
Feature extraction,
Brain modeling,
Electrodes,
Emotion recognition,
Entropy"
A Beam-Steering Reconfigurable Antenna for WLAN Applications,"A multifunctional reconfigurable antenna (MRA) capable of operating in nine modes corresponding to nine steerable beam directions in the semisphere space {-30°,0°, 30°}; φ ∈ {0°, 45°, 90°, 135°}) is presented. The MRA consists of an aperture-coupled driven patch antenna with a parasitic layer placed above it. The surface of the parasitic layer has a grid of 3 × 3 electrically-small square-shaped metallic pixels. The adjacent pixels are connected by PIN diode switches with ON/OFF status to change the geometry of the parasitic surface, which in turn changes the current distribution on the antenna, thus provides reconfigurability in beam steering direction. The MRA operates in the IEEE 802.11 frequency band (2.4-2.5 GHz) in each mode of operation. The antenna has been fabricated and measured. The measured and simulated impedance and radiation pattern results agree well indicating an average of ~ 6.5 dB realized gain in all modes of operation. System level experimental performance evaluations have also been performed, where an MRA equipped WLAN platform was tested and characterized in typical indoor environments. The results confirm that the MRA equipped WLAN systems could achieve an average of 6 dB Signal to Noise Ratio (SNR) gain compared to legacy omni-directional antenna equipped systems with minimal training overhead.",
Evaluation of Switching Performance of SiC Devices in PWM Inverter-Fed Induction Motor Drives,"Double pulse test (DPT) is a widely accepted method to evaluate the switching characteristics of semiconductor switches, including SiC devices. However, the observed switching performance of SiC devices in a PWM inverter for induction motor drives is almost always worse than the DPT characterization, with slower switching speed, more switching losses, and more serious parasitic ringing. This paper systematically investigates the factors that limit the SiC switching performance from both the motor side and inverter side, including the load characteristics of induction motor and power cable, two more phase legs for the three-phase PWM inverter in comparison with the DPT, and the parasitic capacitive coupling effect between power devices and heat sink. Based on a three-phase PWM inverter with 1200 V SiC MOSFETs, test results show that the induction motor, especially with a relatively long power cable, will significantly impact the switching performance, leading to a switching time increase by a factor of 2, switching loss increase up to 30% in comparison with that yielded from DPT, and serious parasitic ringing with 1.5 μs duration, which is more than 50 times of the corresponding switching time. In addition, the interactions among the three phase legs cannot be ignored unless the decoupling capacitors are mounted close to each phase leg to support the dc bus voltage during switching transients. Also, the coupling capacitance due to the heat sink equivalently increases the junction capacitance of power devices; however, its influence on the switching behavior in the motor drives is small considering the relatively large capacitance of the motor load.","Switches,
Induction motors,
Silicon carbide,
Impedance,
Inverters,
Power cables,
Performance evaluation"
Collaborative Mobile Charging,"The limited battery capacity of sensor nodes has become one of the most critical impediments that stunt the deployment of wireless sensor networks (WSNs). Recent breakthroughs in wireless energy transfer and rechargeable lithium batteries provide a promising alternative to power WSNs: mobile vehicles/robots carrying high volume batteries serve as mobile chargers to periodically deliver energy to sensor nodes. In this paper, we consider how to schedule multiple mobile chargers to optimize energy usage effectiveness, such that every sensor will not run out of energy. We introduce a novel charging paradigm, collaborative mobile charging, where mobile chargers are allowed to intentionally transfer energy between themselves. To provide some intuitive insights into the problem structure, we first consider a scenario that satisfies three conditions, and propose a scheduling algorithm, PushWait, which is proven to be optimal and can cover a one-dimensional WSN of infinite length. Then, we remove the conditions one by one, investigating chargers' scheduling in a series of scenarios ranging from the most restricted one to a general 2D WSN. Through theoretical analysis and simulations, we demonstrate the advantages of the proposed algorithms in energy usage effectiveness and charging coverage.",
Enhancing privacy through caching in location-based services,"Privacy protection is critical for Location-Based Services (LBSs). In most previous solutions, users query service data from the untrusted LBS server when needed, and discard the data immediately after use. However, the data can be cached and reused to answer future queries. This prevents some queries from being sent to the LBS server and thus improves privacy. Although a few previous works recognize the usefulness of caching for better privacy, they use caching in a pretty straightforward way, and do not show the quantitative relation between caching and privacy. In this paper, we propose a caching-based solution to protect location privacy in LBSs, and rigorously explore how much caching can be used to improve privacy. Specifically, we propose an entropy-based privacy metric which for the first time incorporates the effect of caching on privacy. Then we design two novel caching-aware dummy selection algorithms which enhance location privacy through maximizing both the privacy of the current query and the dummies' contribution to cache. Evaluations show that our algorithms provide much better privacy than previous caching-oblivious and caching-aware solutions.","Privacy,
Servers,
Measurement,
Mobile communication,
Entropy,
Algorithm design and analysis,
Computers"
Deep Human Parsing with Active Template Regression,"In this work, the human parsing task, namely decomposing a human image into semantic fashion/body regions, is formulated as an active template regression (ATR) problem, where the normalized mask of each fashion/body item is expressed as the linear combination of the learned mask templates, and then morphed to a more precise mask with the active shape parameters, including position, scale and visibility of each semantic region. The mask template coefficients and the active shape parameters together can generate the human parsing results, and are thus called the structure outputs for human parsing. The deep Convolutional Neural Network (CNN) is utilized to build the end-to-end relation between the input human image and the structure outputs for human parsing. More specifically, the structure outputs are predicted by two separate networks. The first CNN network is with max-pooling, and designed to predict the template coefficients for each label mask, while the second CNN network is without max-pooling to preserve sensitivity to label mask position and accurately predict the active shape parameters. For a new image, the structure outputs of the two networks are fused to generate the probability of each label for each pixel, and super-pixel smoothing is finally used to refine the human parsing result. Comprehensive evaluations on a large dataset well demonstrate the significant superiority of the ATR framework over other state-of-the-arts for human parsing. In particular, the F1-score reaches 64.38 percent by our ATR framework, significantly higher than 44.76 percent based on the state-of-the-art algorithm [28].",
Precharging and DC Fault Ride-Through of Hybrid MMC-Based HVDC Systems,"Compared to half-bridge-based modular multilevel converters (MMCs), full-bridge-based systems have the advantage of blocking the dc fault, but at the expense of increased power semiconductors and power losses. In view of the relationships among ac/dc voltages and currents in full-bridge-based MMC with the negative voltage state, this paper provides a detailed analysis on the link between capacitor voltage variation and the maximum modulation index. A hybrid MMC, consisting of mixed half-bridge and full-bridge circuits to combine their respective advantages is investigated in terms of its precharging process and transient dc fault ride-through capability. Simulation and experiment results demonstrate the feasibility and validity of the proposed strategy for a full-bridge-based MMC and the hybrid MMC.","Capacitors,
Circuit faults,
Voltage control,
Modulation,
Hybrid power systems,
HVDC transmission,
Power system stability"
Transductive Multi-View Zero-Shot Learning,"Most existing zero-shot learning approaches exploit transfer learning via an intermediate semantic representation shared between an annotated auxiliary dataset and a target dataset with different classes and no annotation. A projection from a low-level feature space to the semantic representation space is learned from the auxiliary dataset and applied without adaptation to the target dataset. In this paper we identify two inherent limitations with these approaches. First, due to having disjoint and potentially unrelated classes, the projection functions learned from the auxiliary dataset/domain are biased when applied directly to the target dataset/ domain. We call this problem the projection domain shift problem and propose a novel framework, transductive multi-view embedding, to solve it. The second limitation is the prototype sparsity problem which refers to the fact that for each target class, only a single prototype is available for zero-shot learning given a semantic representation. To overcome this problem, a novel heterogeneous multi-view hypergraph label propagation method is formulated for zero-shot learning in the transductive embedding space. It effectively exploits the complementary information offered by different semantic representations and takes advantage of the manifold structures of multiple representation spaces in a coherent manner. We demonstrate through extensive experiments that the proposed approach (1) rectifies the projection shift between the auxiliary and target domains, (2) exploits the complementarity of multiple semantic representations, (3) significantly outperforms existing methods for both zero-shot and N-shot recognition on three image and video benchmark datasets, and (4) enables novel cross-view annotation tasks.","Semantics,
Prototypes,
Vectors,
Visualization,
Target recognition,
Manifolds,
Pragmatics"
Fuzzy Restricted Boltzmann Machine for the Enhancement of Deep Learning,"In recent years, deep learning caves out a research wave in machine learning. With outstanding performance, more and more applications of deep learning in pattern recognition, image recognition, speech recognition, and video processing have been developed. Restricted Boltzmann machine (RBM) plays an important role in current deep learning techniques, as most of existing deep networks are based on or related to it. For regular RBM, the relationships between visible units and hidden units are restricted to be constants. This restriction will certainly downgrade the representation capability of the RBM. To avoid this flaw and enhance deep learning capability, the fuzzy restricted Boltzmann machine (FRBM) and its learning algorithm are proposed in this paper, in which the parameters governing the model are replaced by fuzzy numbers. This way, the original RBM becomes a special case in the FRBM, when there is no fuzziness in the FRBM model. In the process of learning FRBM, the fuzzy free energy function is defuzzified before the probability is defined. The experimental results based on bar-and-stripe benchmark inpainting and MNIST handwritten digits classification problems show that the representation capability of FRBM model is significantly better than the traditional RBM. Additionally, the FRBM also reveals better robustness property compared with RBM when the training data are contaminated by noises.","Approximation methods,
Markov processes,
Optimization,
Robustness,
Probability distribution,
Training,
Linear programming"
Efficient Reversible Data Hiding Based on Multiple Histograms Modification,"Prediction-error expansion (PEE) is the most successful reversible data hiding (RDH) technique, and existing PEE-based RDH methods are mainly based on the modification of one- or two-dimensional prediction-error histogram (PEH). The two-dimensional PEH-based methods perform generally better than those based on one-dimensional PEH; however, their performance is still unsatisfactory since the PEH modification manner is fixed and independent of image content. In this paper, we propose a new RDH method based on PEE for multiple histograms. Unlike the previous methods, we consider in this paper a sequence of histograms and devise a new embedding mechanism based on multiple histograms modification (MHM). A complexity measurement is computed for each pixel according to its context, and the pixels with a given complexity are collected together to generate a PEH. By varying the complexity to cover the whole image, a sequence of histograms can be generated. Then, two expansion bins are selected in each generated histogram and data embedding is realized based on MHM. Here, the expansion bins are adaptively selected considering the image content such that the embedding distortion is minimized. With such selected expansion bins, the proposed MHM-based RDH method works well. Experimental results show that the proposed method outperforms the conventional PEE and its miscellaneous extensions including both one- or two-dimensional PEH-based ones.","Histograms,
Complexity theory,
Distortion,
Image restoration,
Context,
Data mining,
Image coding"
Dynamic Low-Power Reconfiguration of Real-Time Systems With Periodic and Probabilistic Tasks,"This paper deals with the dynamic low-power reconfiguration of a real-time system. It processes periodic and probabilistic tasks that have hard/soft deadlines corresponding to internal/external events. A runtime event-based reconfiguration scenario is a dynamic operation allowing the addition/removal of the assumed periodic/probabilistic tasks. Thereafter, some tasks may miss their hard deadlines and the power consumption may increase. In order to reconfigure the system to be feasible, i.e., satisfying its real-time constraints with low-power consumption, this research presents a software-agent-based architecture. An intelligent agent is developed, which provides four solutions to reconfigure the system at runtime. For these solutions, in order to reconfigure the probabilistic tasks to be feasible, the agent modifies their temporal parameters dynamically; moreover, in order to feasibly serve the probabilistic tasks and reduce the system's power consumption, the agent provides three virtual processors by dynamically extending the periods of the periodic tasks. A simulation study verifies the effectiveness of the agent.",
End-to-End Communication Delay Analysis in Industrial Wireless Networks,"WirelessHART is a new standard specifically designed for real-time and reliable communication between sensor and actuator devices for industrial process monitoring and control applications. End-to-end communication delay analysis for WirelessHART networks is required to determine the schedulability of real-time data flows from sensors to actuators for the purpose of acceptance test or workload adjustment in response to network dynamics. In this paper, we consider a network model based on WirelessHART, and map the scheduling of real-time periodic data flows in the network to real-time multiprocessor scheduling. We then exploit the response time analysis for multiprocessor scheduling and propose a novel method for the delay analysis that establishes an upper bound of the end-to-end communication delay of each real-time flow in the network. Simulation studies based on both random topologies and real network topologies of a 74-node physical wireless sensor network testbed demonstrate that our analysis provides safe and reasonably tight upper bounds of the end-to-end delays of real-time flows, and hence enables effective schedulability tests for WirelessHART networks.","Delays,
Real-time systems,
Processor scheduling,
Logic gates,
Routing,
Process control,
Monitoring"
A PUF-FSM Binding Scheme for FPGA IP Protection and Pay-Per-Device Licensing,"With its reprogrammability, low design cost, and increasing capacity, field-programmable gate array (FPGA) has become a popular design platform and a target for intellectual property (IP) infringement. Currently available IP protection solutions are usually limited to protect single FPGA configurations and require permanent secret key storage in the FPGA. In addition, they cannot provide a commercially popular pay-per-device licensing solution. In this paper, we propose a novel IP protection mechanism to restrict IP's execution only on specific FPGA devices in order to efficiently protect IPs from being cloned, copied, or used with unauthorized integration. This mechanism can also enforce the pay-per-device licensing, which enables the system developers to purchase IPs from the core vendors at the low price based on usage instead of paying the expensive unlimited IP license fees. In our proposed binding-based mechanism, FPGA vendors embed into each enrolled FPGA device with a physical unclonable function (PUF) customized for FPGAs; IP vendors embed augmented finite-state machines (FSM) into the original IPs such that the FSM can be activated by the PUF responses from the FPGA device. We propose protocols to lock and unlock FPGA IPs, demonstrate how PUF can be embedded onto FPGA devices, and analyze the security vulnerabilities of our PUF-FSM binding method. We implement a 128-bit delay-based PUF on 28-nm FPGAs with only 258 RAM-lookup tables and 256 flipflops. The PUF responses are unique and reliable against environment changes. We also synthesize a variety of FSM benchmark circuits. On large benchmarks, the average timing overhead is 0.64% and power overhead in 0.01%.","Field programmable gate arrays,
Licenses,
IP networks,
Hardware,
Cryptography,
Databases,
Intellectual property"
Space-Vector Versus Nearest-Level Pulse Width Modulation for Multilevel Converters,"This paper studies the inherent relationship between two widely used pulse width modulation (PWM) methods for multilevel converters, i.e., the space vector modulation (SVM) method, also called space vector pulse width modulation, and the nearest-level modulation method. The nearest-level modulation method directly controls the voltage of each phase, while the SVM method simultaneously deals with all phases. It is demonstrated in this paper that the two modulation methods are functionally equivalent: with proper common-mode voltage injections, the nearest-level modulation method is equivalent to the SVM method; by selecting the appropriate redundant switching sequences and the corresponding duty cycles, the SVM method is equivalent to the nearest-level modulation method. Nevertheless, the SVM method can conveniently provide more flexibility of optimizing the switching patterns, without the need of designing sophisticated common-mode voltages. An efficient and flexible modulation method for any multiphase multilevel converter is, therefore, proposed, which combines the advantages of the nearest-level modulation and the SVM methods, i.e., both with less computational burden and high flexibility of optimizing the output waveforms. Simulation and experimental results validate the analysis.","Switches,
Support vector machines,
Vectors,
Phase modulation,
Space vector pulse width modulation"
Adaptive Indirect Fuzzy Sliding Mode Controller for Networked Control Systems Subject to Time-Varying Network-Induced Time Delay,"Two major challenges in networked control systems are the time-varying networked-induced delays and the packet losses. To alleviate these problems, this study presents a novel fuzzy sliding mode controller, where a fuzzy system is used to estimate the nonlinear dynamical system online, and the networked-induced delay is handled by Pade approximation. The problem of packet losses is handled by viewing them as large time-varying delays in the system. The sliding mode-based design procedure used ensures the stability and the robustness of the proposed controller in the presence of disturbances and time-varying networked-induced time delays. Using an appropriate Lyapunov function, it is proved that the tracking error converges to the neighborhood of zero asymptotically. Furthermore, since the adaptation laws of the parameters are derived by using of the Lyapunov function, these laws are also found to be stable. Simulation results show that the proposed fuzzy sliding mode controller is capable of controlling nonlinear dynamical systems over a network, which is subject to bounded external disturbances, time-varying network-induced delays, and packet losses with adequate performance.","Delays,
Packet loss,
Fuzzy systems,
Delay effects,
Control systems,
Approximation methods"
"Deep LAC: Deep localization, alignment and classification for fine-grained recognition","We propose a fine-grained recognition system that incorporates part localization, alignment, and classification in one deep neural network. This is a nontrivial process, as the input to the classification module should be functions that enable back-propagation in constructing the solver. Our major contribution is to propose a valve linkage function (VLF) for back-propagation chaining and form our deep localization, alignment and classification (LAC) system. The VLF can adaptively compromise the errors of classification and alignment when training the LAC model. It in turn helps update localization. The performance on fine-grained object data bears out the effectiveness of our LAC system.",
On the Universality and Non-Universality of Spiking Neural P Systems With Rules on Synapses,"Spiking neural P systems with rules on synapses are a new variant of spiking neural P systems. In the systems, the neuron contains only spikes, while the spiking/forgetting rules are moved on the synapses. It was obtained that such system with 30 neurons (using extended spiking rules) or with 39 neurons (using standard spiking rules) is Turing universal. In this work, this number is improved to 6. Specifically, we construct a Turing universal spiking neural P system with rules on synapses having 6 neurons, which can generate any set of Turing computable natural numbers. As well, it is obtained that spiking neural P system with rules on synapses having less than two neurons are not Turing universal: i) such systems having one neuron can characterize the family of finite sets of natural numbers; ii) the family of sets of numbers generated by the systems having two neurons is included in the family of semi-linear sets of natural numbers.","Neurons,
Registers,
Computational modeling,
Nanobioscience,
Standards,
Biological neural networks,
Fault diagnosis"
Large-Scale Convex Optimization for Dense Wireless Cooperative Networks,"Convex optimization is a powerful tool for resource allocation and signal processing in wireless networks. As the network density is expected to drastically increase in order to accommodate the exponentially growing mobile data traffic, performance optimization problems are entering a new era characterized by a high dimension and/or a large number of constraints, which poses significant design and computational challenges. In this paper, we present a novel two-stage approach to solve large-scale convex optimization problems for dense wireless cooperative networks, which can effectively detect infeasibility and enjoy modeling flexibility. In the proposed approach, the original large-scale convex problem is transformed into a standard cone programming form in the first stage via matrix stuffing, which only needs to copy the problem parameters such as channel state information (CSI) and quality-of-service (QoS) requirements to the prestored structure of the standard form. The capability of yielding infeasibility certificates and enabling parallel computing is achieved by solving the homogeneous self-dual embedding of the primal-dual pair of the standard form. In the solving stage, the operator splitting method, namely, the alternating direction method of multipliers (ADMM), is adopted to solve the large-scale homogeneous self-dual embedding. Compared with second-order methods, ADMM can solve large-scale problems in parallel with modest accuracy within a reasonable amount of time. Simulation results will demonstrate the speedup, scalability, and reliability of the proposed framework compared with the state-of-the-art modeling frameworks and solvers.","Wireless communication,
Optimization,
Standards,
Signal processing algorithms,
Cooperative systems,
Array signal processing,
Convex functions"
Decentralized Optimal Demand-Side Management for PHEV Charging in a Smart Grid,"Plug-in hybrid electric vehicles (PHEV) are expected to become widespread in the near future. However, high penetration of PHEVs can overload the distribution system. In smart grid, the charging of PHEVs can be controlled to reduce the peak load, known as demand-side management (DSM). In this paper, we focus on the DSM for PHEV charging at low-voltage transformers (LVTs). The objective is to flatten the load curve of LVTs, while satisfying each consumer's requirement for their PHEV to be charged to the required level by the specified time. We first formulate this problem as a convex optimization problem and then propose a decentralized water-filling-based algorithm to solve it. A moving horizon approach is utilized to handle the random arrival of PHEVs and the inaccuracy of the forecast nonPHEV load. We focus on decentralized solutions so that computational load can be shared by individual PHEV chargers and the algorithm is scalable. Numerical simulations are given to demonstrate the effectiveness of our algorithm.",
Unknown Tag Identification in Large RFID Systems: An Efficient and Complete Solution,"Radio-Frequency Identification (RFID) technology brings revolutionary changes to many fields like retail industry. One important research issue in large RFID systems is the identification of unknown tags, i.e., tags that just entered the system but have not been interrogated by reader(s) covering them yet. Unknown tag identification plays a critical role in automatic inventory management and misplaced tag discovery, but it is far from thoroughly investigated. Existing solutions either trivially interrogate all the tags in the system and thus are highly time inefficient due to re-identification of already identified tags, or use probabilistic approaches that cannot guarantee complete identification of all the unknown tags. In this paper, we propose a series of protocols that can identify all of the unknown tags with high time efficiency. We develop several novel techniques to quickly deactivate already identified tags and prevent them from replying during the interrogation of unknown tags, which avoids re-identification of these tags and consequently improves time efficiency. To our knowledge, our protocols are the first non-trivial solutions that guarantee complete identification of all the unknown tags. We illustrate the effectiveness of our protocols through both rigorous theoretical analysis and extensive simulations. Simulation results show that our protocols can save up to 70 percent time when compared with the best existing solutions.","Protocols,
Radiofrequency identification,
Vectors,
Indexes,
Labeling,
Educational institutions,
Mobile communication"
An Authenticated Trust and Reputation Calculation and Management System for Cloud and Sensor Networks Integration,"Induced by incorporating the powerful data storage and data processing abilities of cloud computing (CC) as well as ubiquitous data gathering capability of wireless sensor networks (WSNs), CC-WSN integration received a lot of attention from both academia and industry. However, authentication as well as trust and reputation calculation and management of cloud service providers (CSPs) and sensor network providers (SNPs) are two very critical and barely explored issues for this new paradigm. To fill the gap, this paper proposes a novel authenticated trust and reputation calculation and management (ATRCM) system for CC-WSN integration. Considering the authenticity of CSP and SNP, the attribute requirement of cloud service user (CSU) and CSP, the cost, trust, and reputation of the service of CSP and SNP, the proposed ATRCM system achieves the following three functions: 1) authenticating CSP and SNP to avoid malicious impersonation attacks; 2) calculating and managing trust and reputation regarding the service of CSP and SNP; and 3) helping CSU choose desirable CSP and assisting CSP in selecting appropriate SNP. Detailed analysis and design as well as further functionality evaluation results are presented to demonstrate the effectiveness of ATRCM, followed with system security analysis.",
Human Movement Training With a Cable Driven ARm EXoskeleton (CAREX),"In recent years, the authors have proposed lightweight exoskeleton designs for upper arm rehabilitation using multi-stage cable-driven parallel mechanism. Previously, the authors have demonstrated via experiments that it is possible to apply “assist-as-needed” forces in all directions at the end-effector with such an exoskeleton acting on an anthropomorphic machine arm. A human-exoskeleton interface was also presented to show the feasibility of CAREX on human subjects. The goals of this paper are to 1) further address issues when CAREX is mounted on human subjects, e.g., generation of continuous cable tension trajectories 2) demonstrate the feasibility and effectiveness of CAREX on movement training of healthy human subjects and a stroke patient. In this research, CAREX is rigidly attached to an arm orthosis worn by human subjects. The cable routing points are optimized to achieve a relatively large “tensioned” static workspace. A new cable tension planner based on quadratic programming is used to generate continuous cable tension trajectory for smooth motion. Experiments were carried out on eight healthy subjects. The experimental results show that CAREX can help the subjects move closer to a prescribed circular path using the force fields generated by the exoskeleton. The subjects also adapt to the path shortly after training. CAREX was also evaluated on a stroke patient to test the feasibility of its use on patients with neural impairment. The results show that the patient was able to move closer to a prescribed straight line path with the “assist-as-needed” force field.",
Image Forgery Detection Using Adaptive Oversegmentation and Feature Point Matching,"A novel copy-move forgery detection scheme using adaptive oversegmentation and feature point matching is proposed in this paper. The proposed scheme integrates both block-based and keypoint-based forgery detection methods. First, the proposed adaptive oversegmentation algorithm segments the host image into nonoverlapping and irregular blocks adaptively. Then, the feature points are extracted from each block as block features, and the block features are matched with one another to locate the labeled feature points; this procedure can approximately indicate the suspected forgery regions. To detect the forgery regions more accurately, we propose the forgery region extraction algorithm, which replaces the feature points with small superpixels as feature blocks and then merges the neighboring blocks that have similar local color features into the feature blocks to generate the merged regions. Finally, it applies the morphological operation to the merged regions to generate the detected forgery regions. The experimental results indicate that the proposed copy-move forgery detection scheme can achieve much better detection results even under various challenging conditions compared with the existing state-of-the-art copy-move forgery detection methods.","Forgery,
Feature extraction,
Image segmentation,
Discrete wavelet transforms,
Image color analysis,
Digital images"
A Family of Two-Switch Boosting Switched-Capacitor Converters,"A family of “Two-Switch Boosting Switched-Capacitor Converters (TBSC)” is introduced, which distinguishes itself from the prior arts by symmetrically interleaved operation, reduced output ripple, low yet even voltage stress on components, and systematic expandability. Along with the topologies, a modeling method is formulated, which provokes the converter regulation method through duty cycle and frequency adjustment. In addition, the paper also provides guidance for circuit components and parameter selection. A 1-kW 3X TBSC was built to demonstrate the converter feasibility, regulation capability via duty cycle and frequency, which achieved a peak efficiency of 97.5% at the rated power.","Capacitors,
Topology,
Switches,
Stress,
Integrated circuit modeling,
Voltage control,
Pulse width modulation"
Characterization of Leakage and Reliability of SiNx Gate Dielectric by Low-Pressure Chemical Vapor Deposition for GaN-based MIS-HEMTs,"In this paper, we systematically investigated the leakage and breakdown mechanisms of the low-pressure chemical vapor deposition (LPCVD) silicon nitride thin film deposited on AlGaN/GaN heterostructures. The LPCVD-SiNx gate dielectric exhibits low leakage and high breakdown electric field. The dominant mechanism of the leakage current through LPCVD-SiNx gate dielectric is identified to be Poole-Frenkel emission at low electric field and Fowler-Nordheim tunneling at high electric field. Both electric-field-accelerated and temperature-accelerated time-dependent dielectric breakdown of the LPCVD-SiNx gate dielectric were also investigated.","Logic gates,
Dielectrics,
Aluminum gallium nitride,
Wide band gap semiconductors,
Leakage currents,
Gallium nitride,
Electric breakdown"
Context-Sensitive Dynamic Ordinal Regression for Intensity Estimation of Facial Action Units,"Modeling intensity of facial action units from spontaneously displayed facial expressions is challenging mainly because of high variability in subject-specific facial expressiveness, head-movements, illumination changes, etc. These factors make the target problem highly context-sensitive. However, existing methods usually ignore this context-sensitivity of the target problem. We propose a novel Conditional Ordinal Random Field (CORF) model for context-sensitive modeling of the facial action unit intensity, where the W5+ (who, when, what, where, why and how) definition of the context is used. While the proposed model is general enough to handle all six context questions, in this paper we focus on the context questions: who (the observed subject), how (the changes in facial expressions), and when (the timing of facial expressions and their intensity). The context questions who and howare modeled by means of the newly introduced context-dependent covariate effects, and the context question when is modeled in terms of temporal correlation between the ordinal outputs, i.e., intensity levels of action units. We also introduce a weighted softmax-margin learning of CRFs from data with skewed distribution of the intensity levels, which is commonly encountered in spontaneous facial data. The proposed model is evaluated on intensity estimation of pain and facial action units using two recently published datasets (UNBC Shoulder Pain and DISFA) of spontaneously displayed facial expressions. Our experiments show that the proposed model performs significantly better on the target tasks compared to the state-of-the-art approaches. Furthermore, compared to traditional learning of CRFs, we show that the proposed weighted learning results in more robust parameter estimation from the imbalanced intensity data.","Context modeling,
Context,
Gold,
Estimation,
Noise,
Data models,
Support vector machines"
From Feedforward to Recurrent LSTM Neural Networks for Language Modeling,"Language models have traditionally been estimated based on relative frequencies, using count statistics that can be extracted from huge amounts of text data. More recently, it has been found that neural networks are particularly powerful at estimating probability distributions over word sequences, giving substantial improvements over state-of-the-art count models. However, the performance of neural network language models strongly depends on their architectural structure. This paper compares count models to feedforward, recurrent, and long short-term memory (LSTM) neural network variants on two large-vocabulary speech recognition tasks. We evaluate the models in terms of perplexity and word error rate, experimentally validating the strong correlation of the two quantities, which we find to hold regardless of the underlying type of the language model. Furthermore, neural networks incur an increased computational complexity compared to count models, and they differently model context dependences, often exceeding the number of words that are taken into account by count based approaches. These differences require efficient search methods for neural networks, and we analyze the potential improvements that can be obtained when applying advanced algorithms to the rescoring of word lattices on large-scale setups.",
Machine Learning-Based Coding Unit Depth Decisions for Flexible Complexity Allocation in High Efficiency Video Coding,"In this paper, we propose a machine learning-based fast coding unit (CU) depth decision method for High Efficiency Video Coding (HEVC), which optimizes the complexity allocation at CU level with given rate-distortion (RD) cost constraints. First, we analyze quad-tree CU depth decision process in HEVC and model it as a three-level of hierarchical binary decision problem. Second, a flexible CU depth decision structure is presented, which allows the performances of each CU depth decision be smoothly transferred between the coding complexity and RD performance. Then, a three-output joint classifier consists of multiple binary classifiers with different parameters is designed to control the risk of false prediction. Finally, a sophisticated RD-complexity model is derived to determine the optimal parameters for the joint classifier, which is capable of minimizing the complexity in each CU depth at given RD degradation constraints. Comparative experiments over various sequences show that the proposed CU depth decision algorithm can reduce the computational complexity from 28.82% to 70.93%, and 51.45% on average when compared with the original HEVC test model. The Bjøntegaard delta peak signal-to-noise ratio and Bjøntegaard delta bit rate are -0.061 dB and 1.98% on average, which is negligible. The overall performance of the proposed algorithm outperforms those of the state-of-the-art schemes.","Complexity theory,
Video coding,
Support vector machines,
Joints,
Image coding,
Classification algorithms,
Prediction algorithms"
Reliable Fault Diagnosis for Low-Speed Bearings Using Individually Trained Support Vector Machines With Kernel Discriminative Feature Analysis,"This paper proposes a highly reliable fault diagnosis approach for low-speed bearings. The proposed approach first extracts wavelet-based fault features that represent diverse symptoms of multiple low-speed bearing defects. The most useful fault features for diagnosis are then selected by utilizing a genetic algorithm (GA)-based kernel discriminative feature analysis cooperating with one-against-all multicategory support vector machines (OAA MCSVMs). Finally, each support vector machine is individually trained with its own feature vector that includes the most discriminative fault features, offering the highest classification performance. In this study, the effectiveness of the proposed GA-based kernel discriminative feature analysis and the classification ability of individually trained OAA MCSVMs are addressed in terms of average classification accuracy. In addition, the proposed GA-based kernel discriminative feature analysis is compared with four other state-of-the-art feature analysis approaches. Experimental results indicate that the proposed approach is superior to other feature analysis methodologies, yielding an average classification accuracy of 98.06% and 94.49% under rotational speeds of 50 revolutions-per-minute (RPM) and 80 RPM, respectively. Furthermore, the individually trained MCSVMs with their own optimal fault features based on the proposed GA-based kernel discriminative feature analysis outperform the standard OAA MCSVMs, showing an average accuracy of 98.66% and 95.01% for bearings under rotational speeds of 50 RPM and 80 RPM, respectively.","Kernel,
Fault diagnosis,
Genetic algorithms,
Biological cells,
Wavelet packets,
Support vector machines,
Feature extraction"
3D Visual Discomfort Predictor: Analysis of Disparity and Neural Activity Statistics,"Being able to predict the degree of visual discomfort that is felt when viewing stereoscopic 3D (S3D) images is an important goal toward ameliorating causative factors, such as excessive horizontal disparity, misalignments or mismatches between the left and right views of stereo pairs, or conflicts between different depth cues. Ideally, such a model should account for such factors as capture and viewing geometries, the distribution of disparities, and the responses of visual neurons. When viewing modern 3D displays, visual discomfort is caused primarily by changes in binocular vergence while accommodation in held fixed at the viewing distance to a flat 3D screen. This results in unnatural mismatches between ocular fixations and ocular focus that does not occur in normal direct 3D viewing. This accommodation vergence conflict can cause adverse effects, such as headaches, fatigue, eye strain, and reduced visual ability. Binocular vision is ultimately realized by means of neural mechanisms that subserve the sensorimotor control of eye movements. Realizing that the neuronal responses are directly implicated in both the control and experience of 3D perception, we have developed a model-based neuronal and statistical framework called the 3D visual discomfort predictor (3D-VDP) that automatically predicts the level of visual discomfort that is experienced when viewing S3D images. 3D-VDP extracts two types of features: 1) coarse features derived from the statistics of binocular disparities and 2) fine features derived by estimating the neural activity associated with the processing of horizontal disparities. In particular, we deploy a model of horizontal disparity processing in the extrastriate middle temporal region of occipital lobe. We compare the performance of 3D-VDP with other recent discomfort prediction algorithms with respect to correlation against recorded subjective visual discomfort scores, and show that 3D-VDP is statistically superior to the other methods.",
A Novel Algorithm for the Automatic Detection of Sleep Apnea From Single-Lead ECG,"Goal: This paper presents a methodology for the automatic detection of sleep apnea from single-lead ECG. Methods: It uses two novel features derived from the ECG, and two well-known features in heart rate variability analysis, namely the standard deviation and the serial correlation coefficients of the RR interval time series. The first novel feature uses the principal components of the QRS complexes, and it describes changes in their morphology caused by an increased sympathetic activity during apnea. The second novel feature extracts the information shared between respiration and heart rate using orthogonal subspace projections. Respiratory information is derived from the ECG by means of three state-of-the-art algorithms, which are implemented and compared here. All features are used as input to a least-squares support vector machines classifier, using an RBF kernel. In total, 80 ECG recordings were included in the study. Results: Accuracies of about 85% are achieved on a minute-by-minute basis, for two independent datasets including both hypopneas and apneas together. Separation between apnea and normal recordings is achieved with 100% accuracy. In addition to apnea classification, the proposed methodology determines the contamination level of each ECG minute. Conclusion: The performances achieved are comparable with those reported in the literature for fully automated algorithms. Significance: These results indicate that the use of only ECG sensors can achieve good accuracies in the detection of sleep apnea. Moreover, the contamination level of each ECG segment can be used to automatically detect artefacts, and to highlight segments that require further visual inspection.","Electrocardiography,
Sleep apnea,
Heart rate,
Morphology,
Principal component analysis,
Feature extraction,
Eigenvalues and eigenfunctions"
Unsupervised Feature Selection via Nonnegative Spectral Analysis and Redundancy Control,"In many image processing and pattern recognition problems, visual contents of images are currently described by high-dimensional features, which are often redundant and noisy. Toward this end, we propose a novel unsupervised feature selection scheme, namely, nonnegative spectral analysis with constrained redundancy, by jointly leveraging nonnegative spectral clustering and redundancy analysis. The proposed method can directly identify a discriminative subset of the most useful and redundancy-constrained features. Nonnegative spectral analysis is developed to learn more accurate cluster labels of the input images, during which the feature selection is performed simultaneously. The joint learning of the cluster labels and feature selection matrix enables to select the most discriminative features. Row-wise sparse models with a general ℓ2, p-norm (0 <; p ≤ 1) are leveraged to make the proposed model suitable for feature selection and robust to noise. Besides, the redundancy between features is explicitly exploited to control the redundancy of the selected subset. The proposed problem is formulated as an optimization problem with a well-defined objective function solved by the developed simple yet efficient iterative algorithm. Finally, we conduct extensive experiments on nine diverse image benchmarks, including face data, handwritten digit data, and object image data. The proposed method achieves encouraging the experimental results in comparison with several representative algorithms, which demonstrates the effectiveness of the proposed algorithm for unsupervised feature selection.","Redundancy,
Noise measurement,
Optimization,
Spectral analysis,
Correlation,
Integrated circuits,
Clustering algorithms"
Robust and Accurate Shape Model Matching Using Random Forest Regression-Voting,"A widely used approach for locating points on deformable objects in images is to generate feature response images for each point, and then to fit a shape model to these response images. We demonstrate that Random Forest regression-voting can be used to generate high quality response images quickly. Rather than using a generative or a discriminative model to evaluate each pixel, a regressor is used to cast votes for the optimal position of each point. We show that this leads to fast and accurate shape model matching when applied in the Constrained Local Model framework. We evaluate the technique in detail, and compare it with a range of commonly used alternatives across application areas: the annotation of the joints of the hands in radiographs and the detection of feature points in facial images. We show that our approach outperforms alternative techniques, achieving what we believe to be the most accurate results yet published for hand joint annotation and state-of-the-art performance for facial feature point detection.","Shape,
Feature extraction,
Training,
Radio frequency,
Joints,
Facial features,
Detectors"
Matching-CNN meets KNN: Quasi-parametric human parsing,"Both parametric and non-parametric approaches have demonstrated encouraging performances in the human parsing task, namely segmenting a human image into several semantic regions (e.g., hat, bag, left arm, face). In this work, we aim to develop a new solution with the advantages of both methodologies, namely supervision from annotated data and the flexibility to use newly annotated (possibly uncommon) images, and present a quasi-parametric human parsing model. Under the classic K Nearest Neighbor (KNN)-based nonparametric framework, the parametric Matching Convolutional Neural Network (M-CNN) is proposed to predict the matching confidence and displacements of the best matched region in the testing image for a particular semantic region in one KNN image. Given a testing image, we first retrieve its KNN images from the annotated/manually-parsed human image corpus. Then each semantic region in each KNN image is matched with confidence to the testing image using M-CNN, and the matched regions from all KNN images are further fused, followed by a superpixel smoothing procedure to obtain the ultimate human parsing result. The M-CNN differs from the classic CNN [12] in that the tailored cross image matching filters are introduced to characterize the matching between the testing image and the semantic region of a KNN image. The cross image matching filters are defined at different convolutional layers, each aiming to capture a particular range of displacements. Comprehensive evaluations over a large dataset with 7,700 annotated human images well demonstrate the significant performance gain from the quasi-parametric model over the state-of-the-arts [29, 30], for the human parsing task.","Semantics,
Testing,
Impedance matching,
Feature extraction,
Neural networks,
Pipelines"
MMCD: Cooperative Downloading for Highway VANETs,"Advances in low-power wireless communications and microelectronics make a great impact on a transportation system and pervasive deployment of roadside units (RSUs) is promising to provide drive-thru Internet to vehicular users anytime and anywhere. Downloading data packets from the RSU, however, is not always reliable because of high mobility of vehicles and high contention among vehicular users. Using intervehicle communication, cooperative downloading can maximize the amount of data packets downloaded per user request. In this paper, we focus on effective data downloading for real-time applications (e.g., video streaming and online game) where each user request is prioritized by the delivery deadline. We propose a cooperative downloading algorithm, namely, max-throughput and min-delay cooperative downloading (MMCD), which minimizes an average delivery delay of each user request while maximizing the amount of data packets downloaded from the RSU. The performance of MMCD is evaluated by extensive simulations and results demonstrate that our algorithm can reduce mean delivery delay while gaining downloading throughput as high as that of a state-of-the-art method although vehicles highly compete for access to the RSU in a conventional highway scenario.","Vehicles,
Delays,
Throughput,
Roads,
Internet,
Wireless communication,
Scheduling"
Software-defined internet of things for smart urban sensing,"With more people living in cities, urban sensing is urgently required to create a comfortable and convenient living environment. As Internet of Things (IoT) is the fundamental infrastructure to realize urban sensing, it should be flexible to support various application requirements and convenient management of infrastructure. Inspired by software-defined networking, which aims to make networks more flexible, the authors propose a software-defined IoT architecture for smart urban sensing. This architecture decouples urban sensing applications from the physical infrastructure. Centralized controllers are designed to manage physical devices and provide APIs of data acquisition, transmission, and processing services to develop urban sensing applications. With these properties, various applications can coexist on the shared infrastructure, and each application can request controllers to customize its data acquisition, transmission, and processing on-demand by generating specific configurations of physical devices. This article discusses the background, benefits, and design details of the proposed architecture as well as open problems and potential solutions to realize it, which opens a new research direction for IoT and urban sensing.",
"Euclidean Distance Matrices: Essential theory, algorithms, and applications","Euclidean distance matrices (EDMs) are matrices of the squared distances between points. The definition is deceivingly simple; thanks to their many useful properties, they have found applications in psychometrics, crystallography, machine learning, wireless sensor networks, acoustics, and more. Despite the usefulness of EDMs, they seem to be insufficiently known in the signal processing community. Our goal is to rectify this mishap in a concise tutorial. We review the fundamental properties of EDMs, such as rank or (non)definiteness, and show how the various EDM properties can be used to design algorithms for completing and denoising distance data. Along the way, we demonstrate applications to microphone position calibration, ultrasound tomography, room reconstruction from echoes, and phase retrieval. By spelling out the essential algorithms, we hope to fast-track the readers in applying EDMs to their own problems. The code for all of the described algorithms and to generate the figures in the article is available online at http://lcav.epfl.ch/ivan.dokmanic. Finally, we suggest directions for further research.",
New Publicly Verifiable Databases with Efficient Updates,"The notion of verifiable database (VDB) enables a resource-constrained client to securely outsource a very large database to an untrusted server so that it could later retrieve a database record and update it by assigning a new value. Also, any attempt by the server to tamper with the data will be detected by the client. Very recently, Catalano and Fiore [17] proposed an elegant framework to build efficient VDB that supports public verifiability from a new primitive named vector commitment. In this paper, we point out Catalano-Fiore's VDB framework from vector commitment is vulnerable to the so-called forward automatic update (FAU) attack. Besides, we propose a new VDB framework from vector commitment based on the idea of commitment binding. The construction is not only public verifiable but also secure under the FAU attack. Furthermore, we prove that our construction can achieve the desired security properties.",
Passive IP Traceback: Disclosing the Locations of IP Spoofers From Path Backscatter,"It is long known attackers may use forged source IP address to conceal their real locations. To capture the spoofers, a number of IP traceback mechanisms have been proposed. However, due to the challenges of deployment, there has been not a widely adopted IP traceback solution, at least at the Internet level. As a result, the mist on the locations of spoofers has never been dissipated till now. This paper proposes passive IP traceback (PIT) that bypasses the deployment difficulties of IP traceback techniques. PIT investigates Internet Control Message Protocol error messages (named path backscatter) triggered by spoofing traffic, and tracks the spoofers based on public available information (e.g., topology). In this way, PIT can find the spoofers without any deployment requirement. This paper illustrates the causes, collection, and the statistical results on path backscatter, demonstrates the processes and effectiveness of PIT, and shows the captured locations of spoofers through applying PIT on the path backscatter data set. These results can help further reveal IP spoofing, which has been studied for long but never well understood. Though PIT cannot work in all the spoofing attacks, it may be the most useful mechanism to trace spoofers before an Internet-level traceback system has been deployed in real.",
Power System Reliability Evaluation With SCADA Cybersecurity Considerations,"As information and communication networks are highly interconnected with the power grid, cyber security of the supervisory control and data acquisition (SCADA) system has become a critical issue in the electric power sector. By exploiting the vulnerabilities in cyber components and intruding into the local area networks of the control center, corporation, substations, or by injecting false information into communication links, the attackers are able to eavesdrop critical data, reconfigure devices, and send trip commands to the intelligent electronic devices that control the system breakers. Reliability of the power system can thus be impacted by various cyber attacks. In this paper, four attack scenarios for cyber components in networks of the SCADA system are considered, which may trip breakers of physical components. Two Bayesian attack graph models are built to illustrate the attack procedures and to evaluate the probabilities of successful cyber attacks. A mean time-to-compromise model is modified and adopted considering the known and zero-day vulnerabilities on the cyber components, and the frequencies of intrusions through various paths are estimated. With increased breaker trips resulting from the cyber attacks, the loss of load probabilities in the IEEE reliability test system 79 are estimated. The simulation results demonstrate that the power system becomes less reliable as the frequency of successful attacks on the cyber components increases and the skill levels of attackers increase.",
A Compact Planar Printed MIMO Antenna Design,"In this paper, we describe the design of a novel planar multiple-input-multiple-output (MIMO) antenna. The basic idea of the design is the development of a canonical two-port antenna that can be replicated and concatenated together to form MIMO antennas with arbitrary even numbers of ports. The design of the canonical element uses compact folded slots for the radiating elements but includes the use of field cancelation to enhance isolation by incorporating a coupling parasitic element. In addition by properly designing the coupling parasitic and the two-port antenna, coupling between canonical elements is also reduced allowing them to be concatenated together. The canonical element size is 27.5 × 30 mm2 operating at 2.6 GHz and it can be packed together with high densities of up to 22 elements per square wavelength. To validate the design, results from 20-port planar printed MIMO antennas are presented operating at 2.6 GHz with a bandwidth of 100 MHz. The 20-port antenna has size of 1.3λ0 × 0.69λ0 mm2 providing an antenna density of 22 antenna in free space square wavelength (λ02). Even though the individual antennas are densely packed, all combinations of mutual couplings between ports exhibit better than 10 dB isolation. The antennas are printed on an FR-4 printed circuit board (PCB), which is a low-cost substrate and allows straightforward prototyping.","Couplings,
MIMO,
Slot antennas,
Mutual coupling,
Scattering parameters,
Ports (Computers)"
"An Internet of Things Framework for Smart Energy in Buildings: Designs, Prototype, and Experiments","Smart energy in buildings is an important research area of Internet of Things (IoT). As important parts of the smart grids, the energy efficiency of buildings is vital for the environment and global sustainability. Using a LEED-gold-certificated green office building, we built a unique IoT experimental testbed for our energy efficiency and building intelligence research. We first monitor and collect 1-year-long building energy usage data and then systematically evaluate and analyze them. The results show that due to the centralized and static building controls, the actual running of green buildings may not be energy efficient even though they may be “green” by design. Inspired by “energy proportional computing” in modern computers, we propose an IoT framework with smart location-based automated and networked energy control, which uses smartphone platform and cloud-computing technologies to enable multiscale energy proportionality including building-, user-, and organizational-level energy proportionality. We further build a proof-of-concept IoT network and control system prototype and carried out real-world experiments, which demonstrate the effectiveness of the proposed solution. We envision that the broad application of the proposed solution has not only led to significant economic benefits in term of energy saving, improving home/office network intelligence, but also bought in a huge social implication in terms of global sustainability.","Buildings,
Energy consumption,
Cooling,
Energy efficiency,
Resistance heating,
Correlation"
A Novel Droop-Based Average Voltage Sharing Control Strategy for DC Microgrids,"This paper introduced a decentralized voltage control strategy for dc microgrids that is based on the droop method. The proposed distributed secondary voltage control utilizes an average voltage sharing scheme to compensate the voltage deviation caused by the droop control. Through nonexplicit communication, the proposed control strategy can perform precise terminal voltage regulation and enhance the system reliability against system failures. The distributed voltage compensators that resemble a centralized secondary voltage controller are implemented with the bi-proper anti-wind-up design method to solve the integration issues that necessarily lead to the saturation of the controller output efforts. The proposed concept of pilot bus voltage regulation shows the possibility of managing the terminal voltage without centralized structure. Moreover, the network dynamics are illustrated with a focus on cable resonance mode based on the eigenvalue analysis and small-signal modeling; analytical explanations with the development of equivalent circuits give a clear picture regarding how the controller parameters and droop gains affect the system damping performance. The proposed derivative droop control has been demonstrated to damp the oscillation and to improve the system stability during transients. Finally, the effectiveness and feasibility of the proposed control strategy are validated by both simulation and experimental evaluation.",
Constructing a Global Social Service Network for Better Quality of Web Service Discovery,"Web services have had a tremendous impact on the Web for supporting a distributed service-based economy on a global scale. However, despite the outstanding progress, their uptake on a Web scale has been significantly less than initially anticipated. The isolation of services and the lack of social relationships among related services have been identified as reasons for the poor uptake. In this paper, we propose connecting the isolated service islands into a global social service network to enhance the services' sociability on a global scale. First, we propose linked social service-specific principles based on linked data principles for publishing services on the open Web as linked social services. Then, we suggest a new framework for constructing the global social service network following linked social service-specific principles based on complex network theories. Next, an approach is proposed to enable the exploitation of the global social service network, providing Linked Social Services as a Service. Finally, experimental results show that our approach can solve the quality of service discovery problem, improving both the service discovering time and the success rate by exploring service-to-service based on the global social service network.","Quality of service,
Social network services,
Web services,
Publishing,
Distributed databases,
Joining processes,
Ontologies"
From Interval-Valued Data to General Type-2 Fuzzy Sets,"In this paper, a new approach is presented to model interval-based data using fuzzy sets (FSs). Specifically, we show how both crisp and uncertain intervals (where there is uncertainty about the endpoints of intervals) collected from individual or multiple survey participants over single or repeated surveys can be modeled using type-1, interval type-2, or general type-2 FSs based on zSlices. The proposed approach is designed to minimize any loss of information when transferring the interval-based data into FS models, and to avoid, as much as possible, assumptions about the distribution of the data. Furthermore, our approach does not rely on data preprocessing or outlier removal, which can lead to the elimination of important information. Different types of uncertainty contained within the data, namely intra- and inter-source uncertainty, are identified and modeled using the different degrees of freedom of type-2 FSs, thus providing a clear representation and separation of these individual types of uncertainty present in the data. We provide full details of the proposed approach, as well as a series of detailed examples based on both real-world and synthetic data. We perform comparisons with analogue techniques to derive FSs from intervals, namely the interval approach and the enhanced interval approach, and highlight the practical applicability of the proposed approach.",
Online Anomaly Detection in Crowd Scenes via Structure Analysis,"Abnormal behavior detection in crowd scenes is continuously a challenge in the field of computer vision. For tackling this problem, this paper starts from a novel structure modeling of crowd behavior. We first propose an informative structural context descriptor (SCD) for describing the crowd individual, which originally introduces the potential energy function of particle's interforce in solid-state physics to intuitively conduct vision contextual cueing. For computing the crowd SCD variation effectively, we then design a robust multi-object tracker to associate the targets in different frames, which employs the incremental analytical ability of the 3-D discrete cosine transform (DCT). By online spatial-temporal analyzing the SCD variation of the crowd, the abnormality is finally localized. Our contribution mainly lies on three aspects: 1) the new exploration of abnormal detection from structure modeling where the motion difference between individuals is computed by a novel selective histogram of optical flow that makes the proposed method can deal with more kinds of anomalies; 2) the SCD description that can effectively represent the relationship among the individuals; and 3) the 3-D DCT multi-object tracker that can robustly associate the limited number of (instead of all) targets which makes the tracking analysis in high density crowd situation feasible. Experimental results on several publicly available crowd video datasets verify the effectiveness of the proposed method.",
Image Analysis: The New Bottleneck in Plant Phenotyping [Applications Corner],"Plant phenotyping is the identification of effects on the phenotype (i.e., the plant appearance and performance) as a result of genotype differences (i.e., differences in the genetic code) and the environmental conditions to which a plant has been exposed [1]?[3]. According to the Food and Agriculture Organization of the United Nations, large-scale experiments in plant phenotyping are a key factor in meeting the agricultural needs of the future to feed the world and provide biomass for energy, while using less water, land, and fertilizer under a constantly evolving environment due to climate change. Working on model plants (such as Arabidopsis), combined with remarkable advances in genotyping, has revolutionized our understanding of biology but has accelerated the need for precision and automation in phenotyping, favoring approaches that provide quantifiable phenotypic information that could be better used to link and find associations in the genotype [4]. While early on, the collection of phenotypes was manual, currently noninvasive, imaging-based methods are increasingly being utilized [5], [6]. However, the rate at which phenotypes are extracted in the field or in the lab is not matching the speed of genotyping and is creating a bottleneck [1].","Plants (biology),
Agriculture,
Image segmentation,
Computer vision,
Shape analysis,
Image analysis"
Author Topic Model-Based Collaborative Filtering for Personalized POI Recommendations,"From social media has emerged continuous needs for automatic travel recommendations. Collaborative filtering (CF) is the most well-known approach. However, existing approaches generally suffer from various weaknesses. For example , sparsity can significantly degrade the performance of traditional CF. If a user only visits very few locations, accurate similar user identification becomes very challenging due to lack of sufficient information for effective inference. Moreover, existing recommendation approaches often ignore rich user information like textual descriptions of photos which can reflect users' travel preferences. The topic model (TM) method is an effective way to solve the “sparsity problem,” but is still far from satisfactory. In this paper, an author topic model-based collaborative filtering (ATCF) method is proposed to facilitate comprehensive points of interest (POIs) recommendations for social users. In our approach, user preference topics, such as cultural, cityscape, or landmark, are extracted from the geo-tag constrained textual description of photos via the author topic model instead of only from the geo-tags (GPS locations). Advantages and superior performance of our approach are demonstrated by extensive experiments on a large collection of data.",
Cost-Effective and Privacy-Preserving Energy Management for Smart Meters,"Smart meters, designed for information collection and system monitoring in smart grid, report fine-grained power consumption to utility providers. With these highly accurate profiles of energy usage, however, it is possible to identify consumers' specific activities or behavior patterns, thereby giving rise to serious privacy concerns. This paper addresses these concerns by designing a cost-effective and privacy-preserving energy management technique that uses a rechargeable battery. From a holistic perspective, a dynamic programming framework is designed for consumers to strike a tradeoff between smart meter data privacy and the cost of electricity. In general, a major challenge in solving dynamic programming problems lies in the need for the knowledge of future electricity consumption events. By exploring the underlying structure of the original problem, an equivalent problem is derived, which can be solved by using only the current observations. An online control algorithm is then developed to solve the equivalent problem based on the Lyapunov optimization technique. It is shown that without the knowledge of the statistics of the time-varying load requirements and the electricity price processes, the proposed online control algorithm, parametrized by a positive value V , is within O (1/{V) of the optimal solution to the original problem, where the maximum value of V is limited by the battery capacity. The efficacy of the proposed algorithm is demonstrated through extensive numerical analysis using real data.",
Cascade Chaotic System With Applications,"Chaotic maps are widely used in different applications. Motivated by the cascade structure in electronic circuits, this paper introduces a general chaotic framework called the cascade chaotic system (CCS). Using two 1-D chaotic maps as seed maps, CCS is able to generate a huge number of new chaotic maps. Examples and evaluations show the CCS's robustness. Compared with corresponding seed maps, newly generated chaotic maps are more unpredictable and have better chaotic performance, more parameters, and complex chaotic properties. To investigate applications of CCS, we introduce a pseudo-random number generator (PRNG) and a data encryption system using a chaotic map generated by CCS. Simulation and analysis demonstrate that the proposed PRNG has high quality of randomness and that the data encryption system is able to protect different types of data with a high-security level.","Chaos,
Logistics,
Bifurcation,
Encryption,
Trajectory,
Correlation"
Structural Design and Control of a Small-MRF Damper Under 50 N Soft-Landing Applications,"To achieve less than 50 N soft-landing using magneto-rheological fluid (MRF) damper, a novel small-MRF damper has been developed. First, we design a new outer electromagnetic coil comparing with traditional inner coil structure, which can obtain miniature damper easily and control the magnetic field conveniently. Second, we apply silicon steel rather than carbon steel for MRF damper, which can improve the performance of response and demagnetization of the damper. The effectiveness of the innovative design is confirmed by experiments in this paper. The range of soft-landing load can be controlled from 18 to 55 N by adjusting the coil current from 0 to 0.8 A. Additionally, an impact force at the beginning can be eliminated using a modeled synchronous linear current, which indicates that the small-MRF damper has good soft-landing performance. Furthermore, the novel approach provides developing ideas for the miniaturization of the MRF damper.",
Solving the Third-Shift Problem in IC Piracy With Test-Aware Logic Locking,"The increasing IC manufacturing cost encourages a business model where design houses outsource IC fabrication to remote foundries. Despite cost savings, this model exposes design houses to IC piracy as remote foundries can manufacture in excess to sell on the black market. Recent efforts in digital hardware security aim to thwart piracy by using XOR-based chip locking, cryptography, and active metering. To counter direct attacks and lower the exposure of unlocked circuits to the foundry, we introduce a multiplexor-based locking strategy that preserves test response allowing IC testing by an untrusted party before activation. We demonstrate a simple yet effective attack against a locked circuit that does not preserve test response, and validate the effectiveness of our locking strategy on IWLS 2005 benchmarks.","Logic gates,
Integrated circuit modeling,
Vectors,
Fabrication,
Tin,
Cryptography"
A New Framework for Analysis on Stability and Bifurcation in a Class of Neural Networks With Discrete and Distributed Delays,"This paper studies the stability and Hopf bifurcation in a class of high-dimension neural network involving the discrete and distributed delays under a new framework. By introducing some virtual neurons to the original system, the impact of distributed delay can be described in a simplified way via an equivalent new model. This paper extends the existing works on neural networks to high-dimension cases, which is much closer to complex and real neural networks. Here, we first analyze the Hopf bifurcation in this special class of high dimensional model with weak delay kernel from two aspects: one is induced by the time delay, the other is induced by a rate parameter, to reveal the roles of discrete and distributed delays on stability and bifurcation. Sufficient conditions for keeping the original system to be stable, and undergoing the Hopf bifurcation are obtained. Besides, this new framework can also apply to deal with the case of the strong delay kernel and corresponding analysis for different dynamical behaviors is provided. Finally, the simulation results are presented to justify the validity of our theoretical analysis.",
Deep hierarchical parsing for semantic segmentation,"This paper proposes a learning-based approach to scene parsing inspired by the deep Recursive Context Propagation Network (RCPN). RCPN is a deep feed-forward neural network that utilizes the contextual information from the entire image, through bottom-up followed by top-down context propagation via random binary parse trees. This improves the feature representation of every super-pixel in the image for better classification into semantic categories. We analyze RCPN and propose two novel contributions to further improve the model. We first analyze the learning of RCPN parameters and discover the presence of bypass error paths in the computation graph of RCPN that can hinder contextual propagation. We propose to tackle this problem by including the classification loss of the internal nodes of the random parse trees in the original RCPN loss function. Secondly, we use an MRF on the parse tree nodes to model the hierarchical dependency present in the output. Both modifications provide performance boosts over the original RCPN and the new system achieves state-of-the-art performance on Stanford Background, SIFT-Flow and Daimler urban datasets.","Semantics,
Training,
Visualization,
Neural networks,
Image segmentation,
Context,
Accuracy"
A PLL-Less Scheme for Single-Phase Grid Interfaced Load Compensating Solar PV Generation System,"This paper proposes a single-phase double-stage scheme for grid interfaced load compensating solar photovoltaic (PV) generating system. The scheme serves twofold objectives of alleviating power quality issues such as power factor correction and harmonics mitigation, while simultaneously extracting the maximum power generated by the PV unit. A simple notch-filtering control algorithm is designed to facilitate extraction of the real component of load current, exempting the services of a phase locked loop (PLL). The absence of a PLL reduces the system dependence on the proportional-integral (PI) controller tuning, which in turn improves the dynamic response and makes the system quite robust. The proposed solar PV generation system retains its ability of mitigating harmonics on cloudy days and also provides opportunity for night time utilization of available resources. The system has been analyzed under both linear and nonlinear varying loads using and an experimental verification of the results is carried out on a developed prototype of the system.","Power harmonic filters,
Harmonic analysis,
Arrays,
Power conversion,
Active filters"
Ubiquitous Monitoring for Industrial Cyber-Physical Systems Over Relay- Assisted Wireless Sensor Networks,"Ubiquitous monitoring over wireless sensor networks (WSNs) is of increasing interest in industrial cyber-physical systems (CPSs). Question of how to understand a situation of physical system by estimating process parameters is largely unexplored. This paper is concerned with the distributed estimation problem for industrial automation over relay-assisted WSNs. Different from most existing works on WSN with homogeneous sensor nodes, the network considered in this paper consists of two types of nodes, i.e., sensing nodes (SNs), which is capable of sensing and computing, and relay nodes (RNs), which is only capable of simple data aggregation. We first adopt a Kalman filtering (KF) approach to estimate the unknown physical parameters. In order to facilitate the decentralized implementation of the KF algorithm in relay-assisted WSNs, a tree-based broadcasting strategy is provided for distributed sensor fusion. With the fused information, the consensus-based estimation algorithms are proposed for SNs and RNs, respectively. The proposed method is applied to estimate the slab temperature distribution in a hot rolling process monitoring system, which is a typical industrial CPS. It is demonstrated that the introduction of RNs improves temperature estimation efficiency and accuracy compared with the homogeneous WSN with SNs only.","Estimation,
Wireless sensor networks,
Relays,
Tin,
Monitoring,
Kalman filters,
Sensors"
Ancillary Service to the Grid Using Intelligent Deferrable Loads,"Renewable energy sources such as wind and solar power have a high degree of unpredictability and time-variation, which makes balancing demand and supply challenging. One possible way to address this challenge is to harness the inherent flexibility in demand of many types of loads. Introduced in this paper is a technique for decentralized control for automated demand response that can be used by grid operators as ancillary service for maintaining demand-supply balance. A randomized control architecture is proposed, motivated by the need for decentralized decision making, and the need to avoid synchronization that can lead to large and detrimental spikes in demand. An aggregate model for a large number of loads is then developed by examining the mean field limit. A key innovation is a linear time-invariant (LTI) system approximation of the aggregate nonlinear model, with a scalar signal as the input and a measure of the aggregate demand as the output. This makes the approximation particularly convenient for control design at the grid level.","Approximation methods,
Load modeling,
Aggregates,
Markov processes,
Power demand,
Mathematical model,
Computer architecture"
Diversity-induced Multi-view Subspace Clustering,"In this paper, we focus on how to boost the multi-view clustering by exploring the complementary information among multi-view features. A multi-view clustering framework, called Diversity-induced Multi-view Subspace Clustering (DiMSC), is proposed for this task. In our method, we extend the existing subspace clustering into the multi-view domain, and utilize the Hilbert Schmidt Independence Criterion (HSIC) as a diversity term to explore the complementarity of multi-view representations, which could be solved efficiently by using the alternating minimizing optimization. Compared to other multi-view clustering methods, the enhanced complementarity reduces the redundancy between the multi-view representations, and improves the accuracy of the clustering results. Experiments on both image and video face clustering well demonstrate that the proposed method outperforms the state-of-the-art methods.","Kernel,
Linear programming,
Face,
Clustering methods,
Joints,
Convergence,
Glass"
Multichannel Signal Enhancement Algorithms for Assisted Listening Devices: Exploiting spatial diversity using multiple microphones,"In everyday environments, we are frequently immersed by unwanted acoustic noise and interference while we want to listen to acoustic signals, most often speech. Technology for assisted listening is then desired to increase the efficiency of speech communication, reduce listener fatigue, or just allow for enjoying undisturbed sounds (e.g., music). For people with normal hearing, assisted listening devices (ALDs) mainly aim to achieve hearing protection or increase listening comfort; however, for hearing-impaired individuals, as the most prominent user group so far, further progress of assisted listening technology is crucial for better inclusion into our world of pervasive acoustic communication.","Acoustic signal processing,
Noise measurement,
Multichannel communication,
Interference,
Assistive devices,
Speech processing,
Acoustic noise,
Auditory system"
Improved approximation of storage-rate tradeoff for caching via new outer bounds,"Caching is a viable solution for alleviating the severe capacity crunch in modern content centric wireless networks. Parts of popular files are pre-stored in users' cache memories such that at times of heavy demand, users can be served locally from their cache content thereby reducing the peak network load. In this work, we consider a central server assisted caching network where files are jointly delivered to users through multicast transmissions. For such a network, we develop a new information theoretic lower bound on the fundamental cache storage vs. transmission rate tradeoff, which strictly improves upon the best known existing bounds. The new bounds are used to establish the approximate storage vs. rate tradeoff of centralized caching to within a constant multiplicative factor of 8.",
Bayesian Multi-Target Tracking With Merged Measurements Using Labelled Random Finite Sets,"Most tracking algorithms in the literature assume that the targets always generate measurements independently of each other, i.e., the sensor is assumed to have infinite resolution. Such algorithms have been dominant because addressing the presence of merged measurements increases the computational complexity of the tracking problem, and limitations on computing resources often make this infeasible. When merging occurs, these algorithms suffer degraded performance, often due to tracks being terminated too early. In this paper, we use the theory of random finite sets (RFS) to develop a principled Bayesian solution to tracking an unknown and variable number of targets in the presence of merged measurements. We propose two tractable implementations of the resulting filter, with differing computational requirements. The performance of these algorithms is demonstrated by Monte Carlo simulations of a multi-target bearings-only scenario, where measurements become merged due to the effect of finite sensor resolution.","Target tracking,
Signal processing algorithms,
Radar tracking,
Computational modeling,
Bayes methods,
Approximation methods,
Merging"
Undamped Oscillations Generated by Hopf Bifurcations in Fractional-Order Recurrent Neural Networks With Caputo Derivative,"In this paper, a fractional-order recurrent neural network is proposed and several topics related to the dynamics of such a network are investigated, such as the stability, Hopf bifurcations, and undamped oscillations. The stability domain of the trivial steady state is completely characterized with respect to network parameters and orders of the commensurate-order neural network. Based on the stability analysis, the critical values of the fractional order are identified, where Hopf bifurcations occur and a family of oscillations bifurcate from the trivial steady state. Then, the parametric range of undamped oscillations is also estimated and the frequency and amplitude of oscillations are determined analytically and numerically for such commensurate-order networks. Meanwhile, it is shown that the incommensurate-order neural network can also exhibit a Hopf bifurcation as the network parameter passes through a critical value which can be determined exactly. The frequency and amplitude of bifurcated oscillations are determined.","Bifurcation,
Oscillators,
Recurrent neural networks,
Stability analysis,
Numerical stability,
Eigenvalues and eigenfunctions"
Searchable Attribute-Based Mechanism With Efficient Data Sharing for Secure Cloud Storage,"To date, the growth of electronic personal data leads to a trend that data owners prefer to remotely outsource their data to clouds for the enjoyment of the high-quality retrieval and storage service without worrying the burden of local data management and maintenance. However, secure share and search for the outsourced data is a formidable task, which may easily incur the leakage of sensitive personal information. Efficient data sharing and searching with security is of critical importance. This paper, for the first time, proposes a searchable attribute-based proxy reencryption system. When compared with the existing systems only supporting either searchable attribute-based functionality or attribute-based proxy reencryption, our new primitive supports both abilities and provides flexible keyword update service. In particular, the system enables a data owner to efficiently share his data to a specified group of users matching a sharing policy and meanwhile, the data will maintain its searchable property but also the corresponding search keyword(s) can be updated after the data sharing. The new mechanism is applicable to many real-world applications, such as electronic health record systems. It is also proved chosen ciphertext secure in the random oracle model.",
Personal Visualization and Personal Visual Analytics,"Data surrounds each and every one of us in our daily lives, ranging from exercise logs, to archives of our interactions with others on social media, to online resources pertaining to our hobbies. There is enormous potential for us to use these data to understand ourselves better and make positive changes in our lives. Visualization (Vis) and visual analytics (VA) offer substantial opportunities to help individuals gain insights about themselves, their communities and their interests; however, designing tools to support data analysis in non-professional life brings a unique set of research and design challenges. We investigate the requirements and research directions required to take full advantage of Vis and VA in a personal context. We develop a taxonomy of design dimensions to provide a coherent vocabulary for discussing personal visualization and personal visual analytics. By identifying and exploring clusters in the design space, we discuss challenges and share perspectives on future research. This work brings together research that was previously scattered across disciplines. Our goal is to call research attention to this space and engage researchers to explore the enabling techniques and technology that will support people to better understand data relevant to their personal lives, interests, and needs.",
Unified Collaborative and Content-Based Web Service Recommendation,"The last decade has witnessed a tremendous growth of web services as a major technology for sharing data, computing resources, and programs on the web. With increasing adoption and presence of web services, designing novel approaches for efficient and effective web service recommendation has become of paramount importance. Most existing web service discovery and recommendation approaches focus on either perishing UDDI registries, or keyword-dominant web service search engines, which possess many limitations such as poor recommendation performance and heavy dependence on correct and complex queries from users. It would be desirable for a system to recommend web services that align with users' interests without requiring the users to explicitly specify queries. Recent research efforts on web service recommendation center on two prominent approaches: collaborative filtering and content-based recommendation. Unfortunately, both approaches have some drawbacks, which restrict their applicability in web service recommendation. In this paper, we propose a novel approach that unifies collaborative filtering and content-based recommendations. In particular, our approach considers simultaneously both rating data (e.g., QoS) and semantic content data (e.g., functionalities) of web services using a probabilistic generative model. In our model, unobservable user preferences are represented by introducing a set of latent variables, which can be statistically estimated. To verify the proposed approach, we conduct experiments using 3,693 real-world web services. The experimental results show that our approach outperforms the state-of-the-art methods on recommendation performance.","Web services,
Semantics,
Collaboration,
Quality of service,
Data models,
Educational institutions,
Recommender systems"
Diffusion in Social Networks: A Multiagent Perspective,"In recent years, significant attention has been paid to diffusion in social networks (SNs), which is, factually, the collective behavior of a set of autonomous social actors for interacting on something in SNs (such as opinions, viruses, or innovations). While this subject has been intensively reported, there have been relatively few systematic reviews concerning the typical diffusion elements and models that are relevant to this subject. Because multiagent computing has already been widely envisioned to be a powerful paradigm for modeling the collective interactions of autonomous multientity systems. In this survey, we review diffusion in SNs through a multiagent perspective. First, we review the following essential elements in diffusion: 1) diffusion actors (who will diffuse), which can be understood to be the interacting agents; 2) diffusion media (where to be diffused), which can be understood to be the interaction environments in multiagent systems (MASs); and 3) diffusion contents (what to be diffused), which can be understood to be the interaction objects in MASs. Next, based on varying situations of diffusion elements, we review the representative diffusion models (how to diffuse), which can be understood as the decision-making mechanisms and interaction protocols in MASs. For each class of diffusion elements and models, we summarize the existing studies and discuss the challenges for solving the complex diffusion problems by applying multiagent methodologies. Finally, we discuss the advantages and disadvantages of our multiagent perspective by comparing other typical perspectives (the empirical research perspective and the theoretical perspective in empirical research), and we conclude with suggestions for further research.","Tin,
Media,
Protocols,
Technological innovation,
Decision making,
Analytical models,
Communities"
Conflict-aware event-participant arrangement,"With the rapid development of Web 2.0 and Online To Offline (O2O) marketing model, various online event-based social networks (EBSNs), such as Meetup and Whova, are getting popular. An important task of EBSNs is to facilitate the most satisfactory event-participant arrangement for both sides, i.e. events enroll more participants and participants are arranged with personally interesting events. Existing approaches usually focus on the arrangement of each single event to a set of potential users, and ignore the conflicts between different events, which leads to infeasible or redundant arrangements. In this paper, to address the shortcomings of existing approaches, we first identify a more general and useful event-participant arrangement problem, called Global Event-participant Arrangement with Conflict and Capacity (GEACC) problem, focusing on the conflicts of different events and making event-participant arrangements in a global view. Though it is useful, unfortunately, we find that the GEACC problem is NP-hard due to the conflict constraints among events. Thus, we design two approximation algorithms with provable approximation ratios and an exact algorithm with pruning technique to address this problem. Finally, we verify the effectiveness and efficiency of the proposed methods through extensive experiments on real and synthetic datasets.","Approximation methods,
Approximation algorithms,
Algorithm design and analysis,
Economic indicators,
Noise measurement,
Web 2.0,
Social network services"
Semantics-preserving hashing for cross-view retrieval,"With benefits of low storage costs and high query speeds, hashing methods are widely researched for efficiently retrieving large-scale data, which commonly contains multiple views, e.g. a news report with images, videos and texts. In this paper, we study the problem of cross-view retrieval and propose an effective Semantics-Preserving Hashing method, termed SePH. Given semantic affinities of training data as supervised information, SePH transforms them into a probability distribution and approximates it with to-be-learnt hash codes in Hamming space via minimizing the Kullback-Leibler divergence. Then kernel logistic regression with a sampling strategy is utilized to learn the nonlinear projections from features in each view to the learnt hash codes. And for any unseen instance, predicted hash codes and their corresponding output probabilities from observed views are utilized to determine its unified hash code, using a novel probabilistic approach. Extensive experiments conducted on three benchmark datasets well demonstrate the effectiveness and reasonableness of SePH.",
Hibernus: Sustaining Computation During Intermittent Supply for Energy-Harvesting Systems,"A key challenge to the future of energy-harvesting systems is the discontinuous power supply that is often generated. We propose a new approach, Hibernus, which enables computation to be sustained during intermittent supply. The approach has a low energy and time overhead which is achieved by reactively hibernating: saving system state only once, when power is about to be lost, and then sleeping until the supply recovers. We validate the approach experimentally on a processor with FRAM nonvolatile memory, allowing it to reactively hibernate using only energy stored in its decoupling capacitance. When compared to a recently proposed technique, the approach reduces processor time and energy overheads by 76%-100% and 49%-79% respectively.","Nonvolatile memory,
Random access memory,
Ferroelectric films,
Capacitance,
Registers,
Microcontrollers,
Energy harvesting"
A Fully-Integrated Low-Dropout Regulator With Full-Spectrum Power Supply Rejection,"A fully-integrated low-dropout regulator (LDO) with fast transient response and full spectrum power supply rejection (PSR) is proposed to provide a clean supply for noise-sensitive building blocks in wideband communication systems. With the proposed point-of-load LDO, chip-level high-frequency glitches are well attenuated, consequently the system performance is improved. A tri-loop LDO architecture is proposed and verified in a 65 nm CMOS process. In comparison to other fully-integrated designs, the output pole is set to be the dominant pole, and the internal poles are pushed to higher frequencies with only 50 μA of total quiescent current. For a 1.2 V input voltage and 1 V output voltage, the measured undershoot and overshoot is only 43 mV and 82 mV, respectively, for load transient of 0 μA to 10 mA within edge times of 200 ps. It achieves a transient response time of 1.15 ns and the figure-of-merit (FOM) of 5.74 ps. PSR is measured to be better than -12 dB over the whole spectrum (DC to 20 GHz tested). The prototype chip measures 260×90 μm2, including 140 pF of stacked on-chip capacitors.",
Experimental Characterization of Physical Unclonable Function Based on 1 kb Resistive Random Access Memory Arrays,"In this letter, we propose a reliable design of physical unclonable function (PUF) exploiting resistive random access memory (RRAM). Unlike the conventional silicon PUFs based on manufacturing process variation, the randomness of RRAM PUF comes from the stochastic switching mechanism and intrinsic variability of the RRAM devices. RRAM PUF's characteristics, such as uniqueness and reliability, are evaluated on 1 kb HfO2-based 1-transistor-1-resistor (1T1R) arrays. Our experimental results show that the selection of the reference current significantly affects the uniqueness. More dummy cells to generate the reference can improve the uniqueness of RRAM. The reliability of RRAM PUF is determined by the RRAM data retention. A new design is proposed where the sum of the readout currents of multiple RRAM cells is used for generating one response bit, which statistically minimizes the risk of early lifetime failure. The experimental results show that with eight cells per bit, the retention time is more than 50 h at 150 °C or equivalently 10 years at 69 °C. This experimental work demonstrates that RRAM PUF is a viable technology for hardware security primitive with inter-Hamming distance 49.8% and intra-Hamming distance 0%.","Reliability,
Resistance,
Random access memory,
Security,
Nonvolatile memory,
Hafnium oxide"
Global Exponential Synchronization of Multiple Memristive Neural Networks With Time Delay via Nonlinear Coupling,"This paper presents theoretical results on the global exponential synchronization of multiple memristive neural networks with time delays. A novel coupling scheme is introduced, in a general topological structure described by a directed or undirected graph, with a linear diffusive term and discontinuous sign term. Several criteria are derived based on the Lyapunov stability theory to ascertain the global exponential stability of synchronization manifold in the coupling scheme. Simulation results for several examples are given to substantiate the effectiveness of the theoretical results.","Synchronization,
Couplings,
Manganese,
Biological neural networks,
Memristors,
Multi-layer neural network,
Indexes"
Personal Sound Zones: Delivering interface-free audio to multiple listeners,"Sound rendering is increasingly being required to extend over certain regions of space for multiple listeners, known as personal sound zones, with minimum interference to listeners in other regions. In this article, we present a systematic overview of the major challenges that have to be dealt with for multizone sound control in a room. Sound control over multiple zones is formulated as an optimization problem, and a unified framework is presented to compare two state-of-the-art sound control techniques. While conventional techniques have been focusing on point-to-point audio processing, we introduce a wave-domain sound field representation and active room compensation for sound pressure control over a region of space. The design of directional loudspeakers is presented and the advantages of using arrays of directional sources are illustrated for sound reproduction, such as better control of sound fields over wide areas and reduced total number of loudspeaker units, thus making it particularly suitable for establishing personal sound zones.",
Face alignment using cascade Gaussian process regression trees,"In this paper, we propose a face alignment method that uses cascade Gaussian process regression trees (cGPRT) constructed by combining Gaussian process regression trees (GPRT) in a cascade stage-wise manner. Here, GPRT is a Gaussian process with a kernel defined by a set of trees. The kernel measures the similarity between two inputs as the number of trees where the two inputs fall in the same leaves. Without increasing prediction time, the prediction of cGPRT can be performed in the same framework as the cascade regression trees (CRT) but with better generalization. Features for GPRT are designed using shape-indexed difference of Gaussian (DoG) filter responses sampled from local retinal patterns to increase stability and to attain robustness against geometric variances. Compared with the previous CRT-based face alignment methods that have shown state-of-the-art performances, cGPRT using shape-indexed DoG features performed best on the HELEN and 300-W datasets which are the most challenging dataset today.","Shape,
Feature extraction,
Regression tree analysis,
Face,
Kernel,
Training data,
Gaussian processes"
Online Comment-Based Hotel Quality Automatic Assessment Using Improved Fuzzy Comprehensive Evaluation and Fuzzy Cognitive Map,"Online comment has become a popular and efficient way for sellers to acquire feedback from customers and improve their service quality. However, some key issues need to be solved about evaluating and improving the hotel service quality based on online comments automatically, such as how to use the less trustworthy online comments, how to discover the quality defects from online comments, and how to recommend more feasible or economical evaluation indexes to improve the service quality based on online comments. To solve the above problems, this paper first improves fuzzy comprehensive evaluation (FCE) by importing trustworthy degree to it and proposes an automatic hotel service quality assessment method using the improved FCE, which can automatically get more trustworthy evaluation from a large amount of less trustworthy online comments. Then, the causal relations among evaluation indexes are mined from online comments to build the fuzzy cognitive map for the hotel service quality, which is useful to unfold the problematic areas of hotel service quality, and recommend more economical solutions to improving the service quality. Finally, both case studies and experiments are conducted to demonstrate that the proposed methods are effective in evaluating and improving the hotel service quality using online comments.","Quality assessment,
Pattern matching,
Industries,
Urban areas"
Effective semantic pixel labelling with convolutional networks and Conditional Random Fields,"Large amounts of available training data and increasing computing power have led to the recent success of deep convolutional neural networks (CNN) on a large number of applications. In this paper, we propose an effective semantic pixel labelling using CNN features, hand-crafted features and Conditional Random Fields (CRFs). Both CNN and hand-crafted features are applied to dense image patches to produce per-pixel class probabilities. The CRF infers a labelling that smooths regions while respecting the edges present in the imagery. The method is applied to the ISPRS 2D semantic labelling challenge dataset with competitive classification accuracy.","Labeling,
Image edge detection,
Feature extraction,
Accuracy,
Semantics,
Training,
Visualization"
Enabling Efficient Multi-Keyword Ranked Search Over Encrypted Mobile Cloud Data Through Blind Storage,"In mobile cloud computing, a fundamental application is to outsource the mobile data to external cloud servers for scalable data storage. The outsourced data, however, need to be encrypted due to the privacy and confidentiality concerns of their owner. This results in the distinguished difficulties on the accurate search over the encrypted mobile cloud data. To tackle this issue, in this paper, we develop the searchable encryption for multi-keyword ranked search over the storage data. Specifically, by considering the large number of outsourced documents (data) in the cloud, we utilize the relevance score and k-nearest neighbor techniques to develop an efficient multi-keyword search scheme that can return the ranked search results based on the accuracy. Within this framework, we leverage an efficient index to further improve the search efficiency, and adopt the blind storage system to conceal access pattern of the search user. Security analysis demonstrates that our scheme can achieve confidentiality of documents and index, trapdoor privacy, trapdoor unlinkability, and concealing access pattern of the search user. Finally, using extensive simulations, we show that our proposal can achieve much improved efficiency in terms of search functionality and search time compared with the existing proposals.","Vectors,
Servers,
Indexes,
Encryption,
Mobile communication"
Drawing dominant dataset from big sensory data in wireless sensor networks,"The amount of sensory data manifests an explosive growth due to the increasing popularity of Wireless Sensor Networks. The scale of the sensory data in many applications has already exceeds several petabytes annually, which is beyond the computation and transmission capabilities of the conventional WSNs. On the other hand, the information carried by big sensory data has high redundancy because of strong correlation among sensory data. In this paper, we define the concept of e-dominant dataset, which is only a small data set and can represent the vast information carried by big sensory data with the information loss rate being less than e, where e can be arbitrarily small. We prove that drawing the minimum e-dominant dataset is polynomial time solvable and provide a centralized algorithm with 0(n3) time complexity. Furthermore, a distributed algorithm with constant complexity (O(l)) is also designed. It is shown that the result returned by the distributed algorithm can satisfy the e requirement with a near optimal size. Finally, the extensive real experiment results and simulation results are carried out. The results indicate that all the proposed algorithms have high performance in terms of accuracy and energy efficiency.","Sensors,
Correlation,
Wireless sensor networks,
Complexity theory,
Maintenance engineering,
Distributed algorithms,
Nickel"
DECAF: MEG-Based Multimodal Database for Decoding Affective Physiological Responses,"In this work, we present DECAF-a multimodal data set for decoding user physiological responses to affective multimedia content. Different from data sets such as DEAP [15] and MAHNOB-HCI [31], DECAF contains (1) brain signals acquired using the Magnetoencephalogram (MEG) sensor, which requires little physical contact with the user's scalp and consequently facilitates naturalistic affective response, and (2) explicit and implicit emotional responses of 30 participants to 40 one-minute music video segments used in [15] and 36 movie clips, thereby enabling comparisons between the EEG versus MEG modalities as well as movie versus music stimuli for affect recognition. In addition to MEG data, DECAF comprises synchronously recorded near-infra-red (NIR) facial videos, horizontal Electrooculogram (hEOG), Electrocardiogram (ECG), and trapezius-Electromyogram (tEMG) peripheral physiological responses. To demonstrate DECAF's utility, we present (i) a detailed analysis of the correlations between participants' self-assessments and their physiological responses and (ii) single-trial classification results for valence, arousal and dominance, with performance evaluation against existing data sets. DECAF also contains time-continuous emotion annotations for movie clips from seven users, which we use to demonstrate dynamic emotion prediction.","Motion pictures,
Physiology,
Databases,
Emotion recognition,
Educational institutions,
Electroencephalography,
Electrocardiography"
Optimal graph learning with partial tags and multiple features for image and video annotation,"In multimedia annotation, due to the time constraints and the tediousness of manual tagging, it is quite common to utilize both tagged and untagged data to improve the performance of supervised learning when only limited tagged training data are available. This is often done by adding a geometrically based regularization term in the objective function of a supervised learning model. In this case, a similarity graph is indispensable to exploit the geometrical relationships among the training data points, and the graph construction scheme essentially determines the performance of these graph-based learning algorithms. However, most of the existing works construct the graph empirically and are usually based on a single feature without using the label information. In this paper, we propose a semi-supervised annotation approach by learning an optimal graph (OGL) from multi-cues (i.e., partial tags and multiple features) which can more accurately embed the relationships among the data points. We further extend our model to address out-of-sample and noisy label issues. Extensive experiments on four public datasets show the consistent superiority of OGL over state-of-the-art methods by up to 12% in terms of mean average precision.","Linear programming,
Noise measurement,
Yttrium,
Tagging,
Training data,
Image reconstruction,
Supervised learning"
A Dynamic Multiarmed Bandit-Gene Expression Programming Hyper-Heuristic for Combinatorial Optimization Problems,"Hyper-heuristics are search methodologies that aim to provide high-quality solutions across a wide variety of problem domains, rather than developing tailor-made methodologies for each problem instance/domain. A traditional hyper-heuristic framework has two levels, namely, the high level strategy (heuristic selection mechanism and the acceptance criterion) and low level heuristics (a set of problem specific heuristics). Due to the different landscape structures of different problem instances, the high level strategy plays an important role in the design of a hyper-heuristic framework. In this paper, we propose a new high level strategy for a hyper-heuristic framework. The proposed high-level strategy utilizes a dynamic multiarmed bandit-extreme value-based reward as an online heuristic selection mechanism to select the appropriate heuristic to be applied at each iteration. In addition, we propose a gene expression programming framework to automatically generate the acceptance criterion for each problem instance, instead of using human-designed criteria. Two well-known, and very different, combinatorial optimization problems, one static (exam timetabling) and one dynamic (dynamic vehicle routing) are used to demonstrate the generality of the proposed framework. Compared with state-of-the-art hyper-heuristics and other bespoke methods, empirical results demonstrate that the proposed framework is able to generalize well across both domains. We obtain competitive, if not better results, when compared to the best known results obtained from other methods that have been presented in the scientific literature. We also compare our approach against the recently released hyper-heuristic competition test suite. We again demonstrate the generality of our approach when we compare against other methods that have utilized the same six benchmark datasets from this test suite.",
A 0.15 V Input Energy Harvesting Charge Pump With Dynamic Body Biasing and Adaptive Dead-Time for Efficiency Improvement,"A charge pump using 0.13- μm CMOS process for low-voltage energy harvesting is presented. A low-power adaptive dead-time (AD) circuit is used which automatically optimizes the dead-time according to the input voltage. A negative charge pump is also utilized for high efficiency at low input voltages (VIN). The AD circuit improves efficiency by 17% at VIN of 0.2 V compared to the fixed dead time circuit as well as enables the charge pump to work at VIN down to 0.15 V. Dynamic body bias (DBB) and switch-conductance enhancement techniques are applied to a unit stage of the three-stage charge pump. The reverse current flowing through the cross-coupled NMOS switches is prevented and the current transfer is also maximized. Together with the AD circuit and the DBB technique, the maximum output current was improved by 240% as compared to the conventional charge pump design using only the forward body bias.","Charge pumps,
Threshold voltage,
MOSFET,
Leakage currents,
Energy harvesting,
Control systems"
An Emerging Era in the Management of Parkinson's Disease: Wearable Technologies and the Internet of Things,"Current challenges demand a profound restructuration of the global healthcare system. A more efficient system is required to cope with the growing world population and increased life expectancy, which is associated with a marked prevalence of chronic neurological disorders such as Parkinson's disease (PD). One possible approach to meet this demand is a laterally distributed platform such as the Internet of Things (IoT). Real-time motion metrics in PD could be obtained virtually in any scenario by placing lightweight wearable sensors in the patient's clothes and connecting them to a medical database through mobile devices such as cell phones or tablets. Technologies exist to collect huge amounts of patient data not only during regular medical visits but also at home during activities of daily life. These data could be fed into intelligent algorithms to first discriminate relevant threatening conditions, adjust medications based on online obtained physical deficits, and facilitate strategies to modify disease progression. A major impact of this approach lies in its efficiency, by maximizing resources and drastically improving the patient experience. The patient participates actively in disease management via combined objective device- and self-assessment and by sharing information within both medical and peer groups. Here, we review and discuss the existing wearable technologies and the Internet-of-Things concept applied to PD, with an emphasis on how this technological platform may lead to a shift in paradigm in terms of diagnostics and treatment.",
Energy-Aware Scheduling of MapReduce Jobs for Big Data Applications,"The majority of large-scale data intensive applications executed by data centers are based on MapReduce or its open-source implementation, Hadoop. Such applications are executed on large clusters requiring large amounts of energy, making the energy costs a considerable fraction of the data center's overall costs. Therefore minimizing the energy consumption when executing each MapReduce job is a critical concern for data centers. In this paper, we propose a framework for improving the energy efficiency of MapReduce applications, while satisfying the service level agreement (SLA). We first model the problem of energy-aware scheduling of a single MapReduce job as an Integer Program. We then propose two heuristic algorithms, called energy-aware MapReduce scheduling algorithms (EMRSA-I and EMRSA-II), that find the assignments of map and reduce tasks to the machine slots in orderto minimize the energy consumed when executing the application. We perform extensive experiments on a Hadoop cluster to determine the energy consumption and execution time for several workloads from the HiBench benchmark suite including TeraSort, PageRank, and K-means clustering, and then use this data in an extensive simulation study to analyze the performance of the proposed algorithms. The results show that EMRSA-I and EMRSA-II are able to find near optimal job schedules consuming approximately 40 percent less energy on average than the schedules obtained by a common practice scheduler that minimizes the makespan.","Energy consumption,
Algorithm design and analysis,
Clustering algorithms,
Scheduling,
Scheduling algorithms,
Schedules"
Very High Frame Rate Volumetric Integration of Depth Images on Mobile Devices,"Volumetric methods provide efficient, flexible and simple ways of integrating multiple depth images into a full 3D model. They provide dense and photorealistic 3D reconstructions, and parallelised implementations on GPUs achieve real-time performance on modern graphics hardware. To run such methods on mobile devices, providing users with freedom of movement and instantaneous reconstruction feedback, remains challenging however. In this paper we present a range of modifications to existing volumetric integration methods based on voxel block hashing, considerably improving their performance and making them applicable to tablet computer applications. We present (i) optimisations for the basic data structure, and its allocation and integration; (ii) a highly optimised raycasting pipeline; and (iii) extensions to the camera tracker to incorporate IMU data. In total, our system thus achieves frame rates up 47 Hz on a Nvidia Shield Tablet and 910 Hz on a Nvidia GTX Titan XGPU, or even beyond 1.1 kHz without visualisation.","Cameras,
Three-dimensional displays,
Arrays,
Resource management,
Rendering (computer graphics),
Solid modeling,
Interpolation"
Nonrigid Structure From Motion via Sparse Representation,"This paper proposes a new approach for nonrigid structure from motion with occlusion, based on sparse representation. We address the occlusion problem based on the latest developments on sparse representation: matrix completion, which can recover the observation matrix that has high percentages of missing data and can also reduce the noises and outliers in the known elements. We introduce sparse transform to the joint estimation of 3-D shapes and motions. 3-D shape trajectory space is fit by wavelet basis to achieve better modeling of complex motion. Experimental results on datasets without and with occlusion show that our method can better estimate the 3-D shapes and motions, compared with state-of-the-art algorithms.","Shape,
Sparse matrices,
Trajectory,
Discrete cosine transforms,
Wavelet transforms,
Matrix decomposition"
Output-Feedback Adaptive Control of Networked Teleoperation System With Time-Varying Delay and Bounded Inputs,"The output-feedback based controller design problem is investigated for the networked teleoperation system in this paper. A new control scheme is proposed to guarantee the global asymptotic stability of the bilateral teleoperation system with time-varying delays and bounded inputs. First, a new fast terminal sliding-mode velocity observer is proposed to estimate the unknown velocity signals for the teleoperation system. Then, by considering the unknown gravity term, an adaptive SP+Sd-type (saturated proportion plus saturated damping) controller is designed based on the estimated velocity. In the new controllers, the specific sigmoidal function is not used, and any one on a set of saturation functions can be applied. Furthermore, by choosing Lypunov-Krasovskii functional, we show that the master-slave teleoperation system is stable under specific linear matrix inequality conditions. With the given controller design parameters and the upper bound of the input, the allowable maximal transmission delay can be computed by using the proposed stability criteria. Finally, both simulations and experiments are performed to show the effectiveness of the proposed methods.",
Processing Distributed Internet of Things Data in Clouds,"In the fifth installment of ""Blue Skies"" the authors discuss the capabilities and limitations of big data technologies as regards to collecting and analyzing distributed big data sets across multiple datacenters. The need to process distributed big data sets across multiple datacenters arises from the new breed of Internet of Things (IoT) applications.","Cloud computing,
Big data,
Internet of things,
Distributed processing,
Data centers"
Robust Network Traffic Classification,"As a fundamental tool for network management and security, traffic classification has attracted increasing attention in recent years. A significant challenge to the robustness of classification performance comes from zero-day applications previously unknown in traffic classification systems. In this paper, we propose a new scheme of Robust statistical Traffic Classification (RTC) by combining supervised and unsupervised machine learning techniques to meet this challenge. The proposed RTC scheme has the capability of identifying the traffic of zero-day applications as well as accurately discriminating predefined application classes. In addition, we develop a new method for automating the RTC scheme parameters optimization process. The empirical study on real-world traffic data confirms the effectiveness of the proposed scheme. When zero-day applications are present, the classification performance of the new scheme is significantly better than four state-of-the-art methods: random forest, correlation-based classification, semi-supervised clustering, and one-class SVM.","Training,
Clustering algorithms,
Robustness,
Correlation,
Ports (Computers),
Payloads,
IP networks"
New Algorithms for Secure Outsourcing of Large-Scale Systems of Linear Equations,"With the rapid development in availability of cloud services, the techniques for securely outsourcing the prohibitively expensive computations to untrusted servers are getting more and more attentions in the scientific community. In this paper, we investigate secure outsourcing for large-scale systems of linear equations, which are the most popular problems in various engineering disciplines. For the first time, we utilize the sparse matrix to propose a new secure outsourcing algorithm of large-scale linear equations in the fully malicious model. Compared with the state-of-the-art algorithm, the proposed algorithm only requires (optimal) one round communication (while the algorithm requires
L
rounds of interactions between the client and cloud server, where
L
denotes the number of iteration in iterative methods). Furthermore, the client in our algorithm can detect the misbehavior of cloud server with the (optimal) probability 1. Therefore, our proposed algorithm is superior in both efficiency and checkability. We also provide the experimental evaluation that demonstrates the efficiency and effectiveness of our algorithm.","Outsourcing,
Servers,
Mathematical model,
Equations,
Sparse matrices,
Computational modeling,
Security"
Robust Discrete Spectral Hashing for Large-Scale Image Semantic Indexing,"In big data era, the ever-increasing image data has posed significant challenge on modern image retrieval. It is of great importance to index images with semantic keywords efficiently and effectively, especially confronted with fast-evolving property of the web. Learning-based hashing has shown its power in handling large-scale high-dimensional applications, such as image retrieval. Existing solutions normally separate the process of learning binary codes and hash functions into two independent stages to bypass challenge of the discrete constraints on binary codes. In this work, we propose a novel unsupervised hashing approach, namely robust discrete hashing (RDSH), to facilitate large-scale semantic indexing of image data. Specifically, RDSH simultaneously learns discrete binary codes as well as robust hash functions within a unified model. In order to suppress the influence of unreliable binary codes and learn robust hash functions, we also integrate a flexible `2;p loss with nonlinear kernel embedding to adapt to different noise levels. Finally, we devise an alternating algorithm to efficiently optimize RDSH model. Given a test image, we first conduct r-nearest-neighbor search based on Hamming distance of binary codes, and then propagate semantic keywords of neighbors to the test image. Extensive experiments have been conducted on various real-world image datasets to show its superiority to the state-of-the-arts in large-scale semantic indexing.","Binary codes,
Semantics,
Robustness,
Indexing,
Optimization,
Hamming distance"
Evaluating the On-Demand Mobile Charging in Wireless Sensor Networks,"Recently, adopting mobile energy chargers to replenish the energy supply of sensor nodes in wireless sensor networks has gained increasing attention from the research community. Different from energy harvesting systems, the utilization of mobile energy chargers is able to provide more reliable energy supply than the dynamic energy harvested from the surrounding environment. While pioneering works on the mobile recharging problem mainly focus on the optimal offline path planning for the mobile chargers, in this work, we aim to lay the theoretical foundation for the on-demand mobile charging (DMC) problem, where individual sensor nodes request charging from the mobile charger when their energy runs low. Specifically, in this work, we analyze the on-demand mobile charging problem using a simple but efficient Nearest-Job-Next with Preemption (NJNP) discipline for the mobile charger, and provide analytical results on the system throughput and charging latency from the perspectives of the mobile charger and individual sensor nodes, respectively. To demonstrate how the actual system design can benefit from our analytical results, we present two examples on determining the essential system parameters such as the optimal remaining energy level for individual sensor nodes to send out their recharging requests and the minimal energy capacity required for the mobile charger. Through extensive simulation with real-world system settings, we verify that our analytical results match the simulation results well and the system designs based on our analysis are effective.",
Cost-Sensitive Local Binary Feature Learning for Facial Age Estimation,"In this paper, we propose a cost-sensitive local binary feature learning (CS-LBFL) method for facial age estimation. Unlike the conventional facial age estimation methods that employ hand-crafted descriptors or holistically learned descriptors for feature representation, our CS-LBFL method learns discriminative local features directly from raw pixels for face representation. Motivated by the fact that facial age estimation is a cost-sensitive computer vision problem and local binary features are more robust to illumination and expression variations than holistic features, we learn a series of hashing functions to project raw pixel values extracted from face patches into low-dimensional binary codes, where binary codes with similar chronological ages are projected as close as possible, and those with dissimilar chronological ages are projected as far as possible. Then, we pool and encode these local binary codes within each face image as a real-valued histogram feature for face representation. Moreover, we propose a cost-sensitive local binary multi-feature learning method to jointly learn multiple sets of hashing functions using face patches extracted from different scales to exploit complementary information. Our methods achieve competitive performance on four widely used face aging data sets.","Face,
Feature extraction,
Estimation,
Binary codes,
Learning systems,
Training,
Robustness"
Adaptive Neural Control of Nonlinear MIMO Systems With Time-Varying Output Constraints,"In this paper, adaptive neural control is investigated for a class of unknown multiple-input multiple-output nonlinear systems with time-varying asymmetric output constraints. To ensure constraint satisfaction, we employ a system transformation technique to transform the original constrained (in the sense of the output restrictions) system into an equivalent unconstrained one, whose stability is sufficient to solve the output constraint problem. It is shown that output tracking is achieved without violation of the output constraint. More specifically, we can shape the system performance arbitrarily on transient and steady-state stages with the output evolving in predefined time-varying boundaries all the time. A single neural network, whose weights are tuned online, is used in our design to approximate the unknown functions in the system dynamics, while the singularity problem of the control coefficient matrix is avoided without assumption on the prior knowledge of control input's bound. All the signals in the closed-loop system are proved to be semiglobally uniformly ultimately bounded via Lyapunov synthesis. Finally, the merits of the proposed controller are verified in the simulation environment.","Artificial neural networks,
MIMO,
Time-varying systems,
Nonlinear systems,
Approximation methods,
Adaptive systems,
Stability analysis"
Energy-Efficient Resource Allocation and Provisioning Framework for Cloud Data Centers,"Energy efficiency has recently become a major issue in large data centers due to financial and environmental concerns. This paper proposes an integrated energy-aware resource provisioning framework for cloud data centers. The proposed framework: i) predicts the number of virtual machine (VM) requests, to be arriving at cloud data centers in the near future, along with the amount of CPU and memory resources associated with each of these requests, ii) provides accurate estimations of the number of physical machines (PMs) that cloud data centers need in order to serve their clients, and iii) reduces energy consumption of cloud data centers by putting to sleep unneeded PMs. Our framework is evaluated using real Google traces collected over a 29-day period from a Google cluster containing over 12,500 PMs. These evaluations show that our proposed energy-aware resource provisioning framework makes substantial energy savings.",
Modeling User Activity Preference by Leveraging User Spatial Temporal Characteristics in LBSNs,"With the recent surge of location based social networks (LBSNs), activity data of millions of users has become attainable. This data contains not only spatial and temporal stamps of user activity, but also its semantic information. LBSNs can help to understand mobile users' spatial temporal activity preference (STAP), which can enable a wide range of ubiquitous applications, such as personalized context-aware location recommendation and group-oriented advertisement. However, modeling such user-specific STAP needs to tackle high-dimensional data, i.e., user-location-time-activity quadruples, which is complicated and usually suffers from a data sparsity problem. In order to address this problem, we propose a STAP model. It first models the spatial and temporal activity preference separately, and then uses a principle way to combine them for preference inference. In order to characterize the impact of spatial features on user activity preference, we propose the notion of personal functional region and related parameters to model and infer user spatial activity preference. In order to model the user temporal activity preference with sparse user activity data in LBSNs, we propose to exploit the temporal activity similarity among different users and apply nonnegative tensor factorization to collaboratively infer temporal activity preference. Finally, we put forward a context-aware fusion framework to combine the spatial and temporal activity preference models for preference inference. We evaluate our proposed approach on three real-world datasets collected from New York and Tokyo, and show that our STAP model consistently outperforms the baseline approaches in various settings.",
A Circuit-Based Learning Architecture for Multilayer Neural Networks With Memristor Bridge Synapses,"Memristor-based circuit architecture for multilayer neural networks is proposed. It is a first of its kind demonstrating successful circuit-based learning for multilayer neural network built with memristors. Though back-propagation algorithm is a powerful learning scheme for multilayer neural networks, its hardware implementation is very difficult due to complexities of the neural synapses and the operations involved in the learning algorithm. In this paper, the circuit of a multilayer neural network is designed with memristor bridge synapses and the learning is realized with a simple learning algorithm called Random Weight Change (RWC). Though RWC algorithm requires more iterations than back-propagation algorithm, we show that a circuit-based learning using RWC is two orders faster than its software counterpart. The method to build a multilayer neural network using memristor bridge synapses and a circuit-based learning architecture of RWC algorithm is proposed. Comparison between software-based and memristor circuit-based learning are presented via simulations.","Memristors,
Bridge circuits,
Hardware,
Nonhomogeneous media,
Neurons,
Biological neural networks"
Optimal PMU Placement for Power System Dynamic State Estimation by Using Empirical Observability Gramian,"In this paper, the empirical observability Gramian calculated around the operating region of a power system is used to quantify the degree of observability of the system states under specific phasor measurement unit (PMU) placement. An optimal PMU placement method for power system dynamic state estimation is further formulated as an optimization problem which maximizes the determinant of the empirical observability Gramian and is efficiently solved by the NOMAD solver, which implements the Mesh Adaptive Direct Search algorithm. The implementation, validation, and the robustness to load fluctuations and contingencies of the proposed method are carefully discussed. The proposed method is tested on WSCC 3-machine 9-bus system and NPCC 48-machine 140-bus system by performing dynamic state estimation with square-root unscented Kalman filter. The simulation results show that the determined optimal PMU placements by the proposed method can guarantee good observability of the system states, which further leads to smaller estimation errors and larger number of convergent states for dynamic state estimation compared with random PMU placements. Under optimal PMU placements an obvious observability transition can be observed. The proposed method is also validated to be very robust to both load fluctuations and contingencies.","Observability,
Phasor measurement units,
Generators,
Power system dynamics,
State estimation,
Vectors,
Rotors"
Kernel Methods on Riemannian Manifolds with Gaussian RBF Kernels,"In this paper, we develop an approach to exploiting kernel methods with manifold-valued data. In many computer vision problems, the data can be naturally represented as points on a Riemannian manifold. Due to the non-Euclidean geometry of Riemannian manifolds, usual Euclidean computer vision and machine learning algorithms yield inferior results on such data. In this paper, we define Gaussian radial basis function (RBF)-based positive definite kernels on manifolds that permit us to embed a given manifold with a corresponding metric in a high dimensional reproducing kernel Hilbert space. These kernels make it possible to utilize algorithms developed for linear spaces on nonlinear manifold-valued data. Since the Gaussian RBF defined with any given metric is not always positive definite, we present a unified framework for analyzing the positive definiteness of the Gaussian RBF on a generic metric space. We then use the proposed framework to identify positive definite kernels on two specific manifolds commonly encountered in computer vision: the Riemannian manifold of symmetric positive definite matrices and the Grassmann manifold, i.e., the Riemannian manifold of linear subspaces of a Euclidean space. We show that many popular algorithms designed for Euclidean spaces, such as support vector machines, discriminant analysis and principal component analysis can be generalized to Riemannian manifolds with the help of such positive definite Gaussian kernels.","Kernel,
Manifolds,
Hilbert space,
Computer vision,
Symmetric matrices"
Consensus Control of a Class of Lipschitz Nonlinear Systems With Input Delay,"This paper deals with the consensus control design for Lipschitz nonlinear multi-agent systems with input delay. The Artstein-Kwon-Pearson reduction method is employed to deal with the input delay and the integral term that remains in the transformed system is analyzed by using Krasovskii functional. Upon exploring certain features of the Laplacian matrix, sufficient conditions for global stability of the consensus control are identified using Lyapunov method in the time domain. The proposed control only uses relative state information of the agents. The effectiveness of the proposed control design is demonstrated through a simulation study.","Delays,
Laplace equations,
Eigenvalues and eigenfunctions,
Nonlinear systems,
Multi-agent systems,
Control design,
Stability analysis"
Downsampling of Signals on Graphs Via Maximum Spanning Trees,"Downsampling of signals living on a general weighted graph is not as trivial as of regular signals where we can simply keep every other samples. In this paper we propose a simple, yet effective downsampling scheme in which the underlying graph is approximated by a maximum spanning tree (MST) that naturally defines a graph multiresolution. This MST-based method significantly outperforms the two previous downsampling schemes, coloring-based and SVD-based, on both random and specific graphs in terms of computations and partition efficiency quantified by the graph cuts. The benefit of using MST-based downsampling for recently developed critical-sampling graph wavelet transforms in compression of graph signals is demonstrated.","Bipartite graph,
Interpolation,
Signal resolution,
Laplace equations,
Joining processes,
Transforms,
Vegetation"
On the Performance of Free-Space Optical Communication Systems Over Double Generalized Gamma Channel,"Starting with the double generalized Gamma (GG) model to describe turbulence-induced fading in free-space optical (FSO) systems, we propose a new unified model that accounts for the impact of pointing errors and type of receiver detector. More specifically, we present unified closed-form expressions for the cumulative distribution function, the probability density function, the moment generating function, and the moments of the end-to-end signal-to-noise ratio (SNR) of a single link FSO transmission system in terms of the Meijer's G-function. We then use these unified expressions to evaluate performance measures such as the bit error rate, the outage probability, and the ergodic capacity of: 1) a single FSO link operating over double GG fading model; and 2) asymmetric RF-FSO dual-hop relay transmission system with fixed gain relay. Using an asymptotic expansion of the Meijer's G-function at high SNR, we express all the expressions, derived earlier, in terms of elementary functions. All our analytical results are verified using computer based-Monte Carlo simulations.","Signal to noise ratio,
Fading,
Bit error rate,
Relays,
Probability density function,
Atmospheric modeling,
Receivers"
A General Geographical Probabilistic Factor Model for Point of Interest Recommendation,"The problem of point of interest (POI) recommendation is to provide personalized recommendations of places, such as restaurants and movie theaters. The increasing prevalence of mobile devices and of location based social networks (LBSNs) poses significant new opportunities as well as challenges, which we address. The decision process for a user to choose a POI is complex and can be influenced by numerous factors, such as personal preferences, geographical considerations, and user mobility behaviors. This is further complicated by the connection LBSNs and mobile devices. While there are some studies on POI recommendations, they lack an integrated analysis of the joint effect of multiple factors. Meanwhile, although latent factor models have been proved effective and are thus widely used for recommendations, adopting them to POI recommendations requires delicate consideration of the unique characteristics of LBSNs. To this end, in this paper, we propose a general geographical probabilistic factor model (Geo-PFM) framework which strategically takes various factors into consideration. Specifically, this framework allows to capture the geographical influences on a user's check-in behavior. Also, user mobility behaviors can be effectively leveraged in the recommendation model. Moreover, based our Geo-PFM framework, we further develop a Poisson Geo-PFM which provides a more rigorous probabilistic generative process for the entire model and is effective in modeling the skewed user check-in count data as implicit feedback for better POI recommendations. Finally, extensive experimental results on three real-world LBSN datasets (which differ in terms of user mobility, POI geographical distribution, implicit response data skewness, and user-POI observation sparsity), show that the proposed recommendation methods outperform state-of-the-art latent factor models by a significant margin.",
Large Scale Spectral Clustering Via Landmark-Based Sparse Representation,"Spectral clustering is one of the most popular clustering approaches. However, it is not a trivial task to apply spectral clustering to large-scale problems due to its computational complexity of O(n3) , where n is the number of samples. Recently, many approaches have been proposed to accelerate the spectral clustering. Unfortunately, these methods usually sacrifice quite a lot information of the original data, thus result in a degradation of performance. In this paper, we propose a novel approach, called landmark-based spectral clustering, for large-scale clustering problems. Specifically, we select p (≪ n) representative data points as the landmarks and represent the original data points as sparse linear combinations of these landmarks. The spectral embedding of the data can then be efficiently computed with the landmark-based representation. The proposed algorithm scales linearly with the problem size. Extensive experiments show the effectiveness and efficiency of our approach comparing to the state-of-the-art methods.","Sparse matrices,
Vectors,
Clustering algorithms,
Algorithm design and analysis,
Encoding,
Approximation methods,
Optimization"
Automated 3-D Retinal Layer Segmentation of Macular Optical Coherence Tomography Images With Serous Pigment Epithelial Detachments,"Automated retinal layer segmentation of optical coherence tomography (OCT) images has been successful for normal eyes but becomes challenging for eyes with retinal diseases if the retinal morphology experiences critical changes. We propose a method to automatically segment the retinal layers in 3-D OCT data with serous retinal pigment epithelial detachments (PED), which is a prominent feature of many chorioretinal disease processes. The proposed framework consists of the following steps: fast denoising and B-scan alignment, multi-resolution graph search based surface detection, PED region detection and surface correction above the PED region. The proposed technique was evaluated on a dataset with OCT images from 20 subjects diagnosed with PED. The experimental results showed the following. 1) The overall mean unsigned border positioning error for layer segmentation is 7.87±3.36 μm, and is comparable to the mean inter-observer variability ( 7.81±2.56 μm). 2) The true positive volume fraction (TPVF), false positive volume fraction (FPVF) and positive predicative value (PPV) for PED volume segmentation are 87.1%, 0.37%, and 81.2%, respectively. 3) The average running time is 220 s for OCT data of 512 × 64 × 480 voxels.",
Biometric Template Protection: Bridging the performance gap between theory and practice,"Biometric recognition is an integral component of modern identity management and access control systems. Due to the strong and permanent link between individuals and their biometric traits, exposure of enrolled users' biometric information to adversaries can seriously compromise biometric system security and user privacy. Numerous techniques have been proposed for biometric template protection over the last 20 years. While these techniques are theoretically sound, they seldom guarantee the desired noninvertibility, revocability, and nonlinkability properties without significantly degrading the recognition performance. The objective of this work is to analyze the factors contributing to this performance divide and highlight promising research directions to bridge this gap. The design of invariant biometric representations remains a fundamental problem, despite recent attempts to address this issue through feature adaptation schemes. The difficulty in estimating the statistical distribution of biometric features not only hinders the development of better template protection algorithms but also diminishes the ability to quantify the noninvertibility and nonlinkability of existing algorithms. Finally, achieving nonlinkability without the use of external secrets (e.g., passwords) continues to be a challenging proposition. Further research on the above issues is required to cross the chasm between theory and practice in biometric template protection.",
A Profit Maximization Scheme with Guaranteed Quality of Service in Cloud Computing,"As an effective and efficient way to provide computing resources and services to customers on demand, cloud computing has become more and more popular. From cloud service providers' perspective, profit is one of the most important considerations, and it is mainly determined by the configuration of a cloud service platform under given market demand. However, a single long-term renting scheme is usually adopted to configure a cloud platform, which cannot guarantee the service quality but leads to serious resource waste. In this paper, a double resource renting scheme is designed firstly in which short-term renting and long-term renting are combined aiming at the existing issues. This double renting scheme can effectively guarantee the quality of service of all requests and reduce the resource waste greatly. Secondly, a service system is considered as an M/M/m+D queuing model and the performance indicators that affect the profit of our double renting scheme are analyzed, e.g., the average charge, the ratio of requests that need temporary servers, and so forth. Thirdly, a profit maximization problem is formulated for the double renting scheme and the optimized configuration of a cloud platform is obtained by solving the profit maximization problem. Finally, a series of calculations are conducted to compare the profit of our proposed scheme with that of the single renting scheme. The results show that our scheme can not only guarantee the service quality of all requests, but also obtain more profit than the latter.","Servers,
Pricing,
Cloud computing,
Computational modeling,
Quality of service,
Computers,
Energy consumption"
Numerical Analysis and Characterization of THz Propagation Channel for Body-Centric Nano-Communications,"This paper presents the characteristics of electromagnetic waves propagating inside human body at Terahertz frequencies and an initial study of the system performance of nano-network. It has been observed that the path loss is not only the function of distance and frequency but also related to the dielectric loss of human tissues. Numerical results have been compared with analytical studies and a good match has been found which validates the proposed numerical model. Based on the calculation of path losses and noise level for THz wave propagation, the channel capacity is studied to give an insight of future nano-communications within the human body. Results show that at the distance of millimeters, the capacity can reach as high as 100 Terabits per second (Tbps) depending on the environment and exciting pulse types.","Numerical models,
Absorption,
Noise,
Blood,
Skin,
Loss measurement,
Propagation losses"
A truthful incentive mechanism for emergency demand response in colocation data centers,"Data centers are key participants in demand response programs, including emergency demand response (EDR), where the grid coordinates large electricity consumers for demand reduction in emergency situations to prevent major economic losses. While existing literature concentrates on owner-operated data centers, this work studies EDR in multi-tenant colocation data centers where servers are owned and managed by individual tenants. EDR in colocation data centers is significantly more challenging, due to lack of incentives to reduce energy consumption by tenants who control their servers and are typically on fixed power contracts with the colocation operator. Consequently, to achieve demand reduction goals set by the EDR program, the operator has to rely on the highly expensive and/or environmentally-unfriendly on-site energy backup/generation. To reduce cost and environmental impact, an efficient incentive mechanism is therefore in need, motivating tenants' voluntary energy reduction in case of EDR. This work proposes a novel incentive mechanism, Truth-DR, which leverages a reverse auction to provide monetary remuneration to tenants according to their agreed energy reduction. Truth-DR is computationally efficient, truthful, and achieves 2-approximation in colocation-wide social cost. Trace-driven simulations verify the efficacy of the proposed auction mechanism.","Load management,
Servers,
Power grids,
Power demand,
Energy consumption,
Algorithm design and analysis,
Approximation algorithms"
Parallel Simulation of Complex Evacuation Scenarios with Adaptive Agent Models,"Simulation study on evacuation scenarios has gained tremendous attention in recent years. Two major research challenges remain along this direction: (1) how to portray the effect of individuals' adaptive behaviors under various situations in the evacuation procedures and (2) how to simulate complex evacuation scenarios involving huge crowds at the individual level due to the ultrahigh complexity of these scenarios. In this study, a simulation framework for general evacuation scenarios has been developed. Each individual in the scenario is modeled as an adaptable and autonomous agent driven by a weight-based decision-making mechanism. The simulation is intended to characterize the individuals' adaptable behaviors, the interactions among individuals, among small groups of individuals, and between the individuals and the environment. To handle the second challenge, this study adopts GPGPU to sustain massively parallel modeling and simulation of an evacuation scenario. An efficient scheme has been proposed to minimize the overhead to access the global system state of the simulation process maintained by the GPU platform. The simulation results indicate that the “adaptability” in individual behaviors has a significant influence on the evacuation procedure. The experimental results also exhibit the proposed approach's capability to sustain complex scenarios involving a huge crowd consisting of tens of thousands of individuals.","Adaptation models,
Computational modeling,
Graphics processing units,
Decision making,
Educational institutions,
Adaptive systems,
Context modeling"
Discriminative Clustering and Feature Selection for Brain MRI Segmentation,"Automatic segmentation of brain tissues from MRI is of great importance for clinical application and scientific research. Recent advancements in supervoxel-level analysis enable robust segmentation of brain tissues by exploring the inherent information among multiple features extracted on the supervoxels. Within this prevalent framework, the difficulties still remain in clustering uncertainties imposed by the heterogeneity of tissues and the redundancy of the MRI features. To cope with the aforementioned two challenges, we propose a robust discriminative segmentation method from the view of information theoretic learning. The prominent goal of the method is to simultaneously select the informative feature and to reduce the uncertainties of supervoxel assignment for discriminative brain tissue segmentation. Experiments on two brain MRI datasets verified the effectiveness and efficiency of the proposed approach.","Magnetic resonance imaging,
Feature extraction,
Mutual information,
Logistics,
Optimization,
Image segmentation,
Educational institutions"
A SiGe Terahertz Heterodyne Imaging Transmitter With 3.3 mW Radiated Power and Fully-Integrated Phase-Locked Loop,"A high-power 320 GHz transmitter using 130 nm SiGe BiCMOS technology (fT/fmax = 220/280 GHz) is reported. This transmitter consists of a 4 × 4 array of radiators based on coupled harmonic oscillators. By incorporating a signal filter structure called return-path gap coupler into a differential self-feeding oscillator, the proposed 320 GHz radiator simultaneously maximizes the fundamental oscillation power, harmonic generation, as well as on-chip radiation. To facilitate the TX-RX synchronization of a future terahertz (THz) heterodyne imaging chipset, a fully-integrated phase-locked loop (PLL) is also implemented in the transmitter. Such on-chip phase-locking capability is the first demonstration for all THz radiators in silicon. In the far-field measurement, the total radiated power and EIRP of the chip is 3.3 mW and 22.5 dBm, respectively. The transmitter consumes 610 mW DC power, which leads to a DC-to-THz radiation efficiency of 0.54%. To the authors' best knowledge, this work presents the highest radiated power and DC-to-THz radiation efficiency in silicon-based THz radiating sources.",
Multispectral pedestrian detection: Benchmark dataset and baseline,"With the increasing interest in pedestrian detection, pedestrian datasets have also been the subject of research in the past decades. However, most existing datasets focus on a color channel, while a thermal channel is helpful for detection even in a dark environment. With this in mind, we propose a multispectral pedestrian dataset which provides well aligned color-thermal image pairs, captured by beam splitter-based special hardware. The color-thermal dataset is as large as previous color-based datasets and provides dense annotations including temporal correspondences. With this dataset, we introduce multispectral ACF, which is an extension of aggregated channel features (ACF) to simultaneously handle color-thermal image pairs. Multi-spectral ACF reduces the average miss rate of ACF by 15%, and achieves another breakthrough in the pedestrian detection task.","Image color analysis,
Cameras,
Hardware,
Color,
Calibration,
Histograms,
Detectors"
How Many Small Cells Can be Turned Off via Vertical Offloading Under a Separation Architecture?,"To further improve the energy efficiency of heterogeneous networks, a separation architecture called hyper-cellular network (HCN) has been proposed, which decouples the control signaling and data transmission functions. Specifically, the control coverage is guaranteed by macro base stations (MBSs), whereas small cells (SCs) are only utilized for data transmission. Under HCN, SCs can be dynamically turned off when traffic load decreases for energy saving. A fundamental problem then arises: how many SCs can be turned off as traffic varies? In this paper, we address this problem in a theoretical way, where two sleeping schemes (i.e., random and repulsive schemes) with vertical inter-layer offloading are considered. Analytical results indicate the following facts: 1) under the random scheme where SCs are turned off with certain probability, the expected ratio of sleeping SCs is inversely proportional to the traffic load of SC-layer and decreases linearly with the traffic load of MBS-layer; 2) the repulsive scheme, which only turns off the SCs close to MBSs, is less sensitive to the traffic variations; and 3) deploying denser MBSs enables turning off more SCs, which may help to improve network energy-efficiency. Numerical results show that about 50% SCs can be turned off on average under the predefined daily traffic profiles, and 10% more SCs can be further turned off with inter-layer channel borrowing.",
Energy Minimization in Multi-Task Software-Defined Sensor Networks,"After a decade of extensive research on application-specific wireless sensor networks (WSNs), the recent development of information and communication technologies makes it practical to realize the software-defined sensor networks (SDSNs), which are able to adapt to various application requirements and to fully explore the resources of WSNs. A sensor node in SDSN is able to conduct multiple tasks with different sensing targets simultaneously. A given sensing task usually involves multiple sensors to achieve a certain quality-of-sensing, e.g., coverage ratio. It is significant to design an energy-efficient sensor scheduling and management strategy with guaranteed quality-of-sensing for all tasks. To this end, three issues are investigated in this paper: 1) the subset of sensor nodes that shall be activated, i.e., sensor activation, 2) the task that each sensor node shall be assigned, i.e., task mapping, and 3) the sampling rate on a sensor for a target, i.e., sensing scheduling. They are jointly considered and formulated as a mixed-integer with quadratic constraints programming (MIQP) problem, which is then reformulated into a mixed-integer linear programming (MILP) formulation with low computation complexity via linearization. To deal with dynamic events such as sensor node participation and departure, during SDSN operations, an efficient online algorithm using local optimization is developed. Simulation results show that our proposed online algorithm approaches the globally optimized network energy efficiency with much lower rescheduling time and control overhead.","Sensors,
Wireless sensor networks,
Heuristic algorithms,
Educational institutions,
Collaboration,
Resource management,
Power demand"
Manipulating Liquid Metal Droplets in Microfluidic Channels With Minimized Skin Residues Toward Tunable RF Applications,"A nontoxic liquid metal, such as eutectic gallium-indium (EGaIn) alloy, has been used to develop tunable radio frequency (RF) components, such as antennas, inductors, or capacitors, for enabling large tunable range, better linearity, and low loss, using fluidic displacement of the liquid metal. However, EGaIn residue, due to its fast oxidation, limits multiple movement of the EGaIn in the reconfigurable RF components. This paper focuses on the use of surfactants, carrier liquids, and microchannel coating materials that minimize EGaIn fragmentation and EGaIn residues on poly(dimethylsiloxane) (PDMS)-based microfluidic channels during repeated actuation of an EGaIn plug. Using a combination of carrier liquids and microchannel coating materials to minimize EGaIn from leaving residues on the PDMS microfluidic channel, a microstrip transmission line switch as a proof-of-concept reconfigurable RF application using the EGaIn plug is demonstrated. It is switched ON<;4 dB and OFF with a loss of <;18 dB over the frequency range between 4 and 15 GHz.","Liquids,
Plugs,
Metals,
Radio frequency,
Coatings,
Skin"
Decentralized Communication and Control Systems for Power System Operation,"Due to the rapid deployment of phasor measurement units (PMUs) on large power grids, the system operators now have access to high speed high resolution data. A new class of monitoring and control applications are made possible with the PMUs. Although PMU based monitoring systems have been well developed, implementations of PMU based fast acting closed loop wide area control systems are relatively rare. To meet the stringent latency requirements of a wide area controller the communication and power infrastructures have to collaborate strongly. In this paper, a combined process for design and simulation of both communication network and power network has been presented with the objective of damping interarea oscillations. A method to determine the optimal location of data routing hubs so as to minimize the volume of communications is also proposed. The IEEE 118 bus system is used to study the performance of communication system and the wide area power damping control system on both centralized and decentralized topologies, and the results are discussed. One of the conclusions of the paper is that the decentralized communication architectures involving data routing hubs are better suited for control applications requiring fast control actions.",
Truthful Greedy Mechanisms for Dynamic Virtual Machine Provisioning and Allocation in Clouds,"A major challenging problem for cloud providers is designing efficient mechanisms for virtual machine (VM) provisioning and allocation. Such mechanisms enable the cloud providers to effectively utilize their available resources and obtain higher profits. Recently, cloud providers have introduced auction-based models for VM provisioning and allocation which allow users to submit bids for their requested VMs. We formulate the dynamic VM provisioning and allocation problem for the auction-based model as an integer program considering multiple types of resources. We then design truthful greedy and optimal mechanisms for the problem such that the cloud provider provisions VMs based on the requests of the winning users and determines their payments. We show that the proposed mechanisms are truthful, that is, the users do not have incentives to manipulate the system by lying about their requested bundles of VM instances and their valuations. We perform extensive experiments using real workload traces in order to investigate the performance of the proposed mechanisms. Our proposed mechanisms achieve promising results in terms of revenue for the cloud provider.","Resource management,
Cost accounting,
Silicon,
Mechanical factors,
Approximation methods,
Vectors,
Dynamic scheduling"
Electric Vehicle Charging Stations With Renewable Power Generators: A Game Theoretical Analysis,"In this paper, we study the price competition among electric vehicle charging stations (EVCSs) with renewable power generators (RPGs). As electric vehicles (EVs) become more popular, a competition among EVCSs to attract EVs is inevitable. Thereby, each EVCS sets its electricity price to maximize its revenue by taking into account the competition with neighboring EVCSs. We analyze the competitive interactions between EVCSs using game theory, where relevant physical constraints such as the transmission line capacity, the distance between EV and EVCS, and the number of charging outlets at the EVCSs are taken into account. We show that the game played by EVCSs is a supermodular game and there exists a unique pure Nash equilibrium for best response algorithms with arbitrary initial policy. The electricity price and the revenue of EVCSs are evaluated via simulations, which reveal the benefits of having RPGs at the EVCSs.","Electricity,
Games,
Batteries,
Smart grids,
Electric vehicles,
Generators"
A survey of commercial frameworks for the Internet of Things,"In 2011 Ericsson and Cisco estimated 50 billion Internet connected devices by 2020, encouraged by this industry is developing application frameworks to scale the Internet of Things. This paper presents a survey of commercial frameworks and platforms designed for developing and running Internet of Things applications. The survey covers frameworks supported by big players in the software and electronics industries. The frameworks are evaluated against criteria such as architectural approach, industry support, standards based protocols and interoperability, security, hardware requirements, governance and support for rapid application development. There is a multitude of frameworks available and here a total 17 frameworks and platforms are considered. The intention of this paper is to present recent developments in commercial IoT frameworks and furthermore, identify trends in the current design of frameworks for the Internet of Things; enabling massively connected cyber physical systems.","Protocols,
Security,
Interoperability,
Servers,
Internet of things,
Standards"
Privacy and Security in Internet of Things and Wearable Devices,"Enter the nascent era of Internet of Things (IoT) and wearable devices, where small embedded devices loaded with sensors collect information from its surroundings, process it, and relay it to remote locations for further analysis. Albeit looking harmless, these nascent technologies raise security and privacy concerns. We pose the question of the possibility and effects of compromising such devices. Concentrating on the design flow of IoT and wearable devices, we discuss some common design practices and their implications on security and privacy. Two representatives from each category, the Google Nest Thermostat and the Nike+ Fuelband, are selected as examples on how current industry practices of security as an afterthought or an add-on affect the resulting device and the potential consequences to the user's security and privacy. We then discuss design flow enhancements, through which security mechanisms can efficiently be added into a device, vastly differing from traditional practices.",
A Framework for Volt-VAR Optimization in Distribution Systems,"The possibility of leveraging the data provided by smart meters to understand the load characteristics is studied in this paper. The loads are modeled as voltage-dependent elements to increase the accuracy of volt-VAR optimization (VVO) techniques for distribution systems. VVO techniques are part of the distribution management system and may be used for purposes such as loss reduction, voltage profile improvement, and conservation voltage reduction. A deterministic framework is proposed that formulates the VVO problem as a mixed-integer quadratically constrained programming problem, which is solved efficiently using advanced branch-and-cut techniques. The proposed framework is capable of optimally controlling capacitor banks, voltage regulators, and under-load tap changers (ULTCs) for day-ahead operation planning. The results indicate that loss reductions of up to 40% and a total demand reduction of up to 4.8% are achievable under some loading conditions in a radial test system. The effect of the load voltage dependence is also demonstrated through analytical simulations.","Load modeling,
Home appliances,
Substations,
Capacitors,
Voltage measurement,
Reactive power,
Load management"
Low-Temperature Characteristics of HfOx-Based Resistive Random Access Memory,"This letter investigates the low-temperature switching characteristics and conduction mechanism of the Pt/HfOx/TiN resistive random access memory devices. For the first time, Pt/HfOx/TiN devices were demonstrated to be well functional at ultralow temperature (4 K). The switching voltages slightly increase at lower temperature. The failure state in a breakdown sample shows a metallic behavior, while the normal low-resistance states and high-resistance states show a semiconducting behavior. The slope change in the 1/kT plot below 77 K indicates a transition from the nearest-neighboring hopping to the variable range hopping. Different slopes or activation energies are observed at the same resistance level in the same device but after different programming cycles, indicating a cycle-dependent variation of the filament configuration.","Hafnium compounds,
Resistance,
Switches,
Tin,
Temperature measurement,
Electron traps,
Temperature"
Current-Based Mechanical Fault Detection for Direct-Drive Wind Turbines via Synchronous Sampling and Impulse Detection,"Online fault detection is an effective means to improve wind turbine reliability and performance and reduce wind turbine downtime and operating and maintenance costs. Current-based wind turbine fault detection techniques have received more and more attention in academia and industry due to their nonintrusive character and economic advantages. This paper presents a novel computationally efficient high-resolution wideband synchronous sampling algorithm for the mechanical fault detection of variable-speed direct-drive wind turbines (i.e., no gearbox) only using nonstationary generator stator current measurements. The proposed algorithm synchronously resamples the current signals such that the varying characteristic frequencies of the excitations generated by wind turbine faults in the current signals become constant values. An impulse detection algorithm is then proposed to detect the faults by identifying the excitations from the frequency spectra of the synchronously sampled stator current signals. Experimental studies are carried out to demonstrate the effectiveness of the proposed algorithms for the detection of rotor eccentricity and bearing faults of a direct-drive wind turbine operating in variable-speed conditions.",
Efficient GPU Spatial-Temporal Multitasking,"Heterogeneous computing nodes are now pervasive throughout computing, and GPUs have emerged as a leading computing device for application acceleration. GPUs have tremendous computing potential for data-parallel applications, and the emergence of GPUs has led to proliferation of GPU-accelerated applications. This proliferation has also led to systems in which many applications are competing for access to GPU resources, and efficient utilization of the GPU resources is critical to system performance. Prior techniques of temporal multitasking can be employed with GPU resources as well, but not all GPU kernels make full use of the GPU resources. There is, therefore, an unmet need for spatial multitasking in GPUs. Resources used inefficiently by one kernel can be instead assigned to another kernel that can more effectively use the resources. In this paper we propose a software-hardware solution for efficient spatial-temporal multitasking and a software based emulation framework for our system. We pair an efficient heuristic in software with hardware leaky-bucket based thread-block interleaving to implement spatial-temporal multitasking. We demonstrate our techniques on various GPU architecture using nine representative benchmarks from CUDA SDK. Our experiments on Fermi GTX480 demonstrate performance improvement by up to 46% (average 26%) over sequential GPU task execution and 37% (average 18%) over default concurrent multitasking. Compared with the state-of-the-art Kepler K20 using Hyper-Q technology, our technique achieves up to 40% (average 17%) performance improvement over default concurrent multitasking.","Kernel,
Graphics processing units,
Multitasking,
Resource management,
Schedules,
Bandwidth,
Instruction sets"
A Software-Defined Device-to-Device Communication Architecture for Public Safety Applications in 5G Networks,"The device-to-device (D2D) communication paradigm in 5G networks provides an effective infrastructure to enable different smart city applications such as public safety. In future smart cities, dense deployment of wireless sensor networks (WSNs) can be integrated with 5G networks using D2D communication. D2D communication enables direct communication between nearby user equipments (UEs) using cellular or ad hoc links, thereby improving the spectrum utilization, system throughput, and energy efficiency of the network. In this paper, we propose a hierarchal D2D communication architecture where a centralized software-defined network (SDN) controller communicates with the cloud head to reduce the number of requested long-term evolution (LTE) communication links, thereby improving energy consumption. The concept of local and central controller enables our architecture to work in case of infrastructure damage and hotspot traffic situation. The architecture helps to maintain the communication between disaster victims and first responders by installing multi-hop routing path with the support of the SDN controller. In addition, we highlight the robustness and potential of our architecture by presenting a public safety scenario, where a part of the network is offline due to extraordinary events such as disaster or terrorist attacks.","Smart cities,
Energy efficiency,
Public safety,
5G mobile communication"
Data Allocation for Hybrid Memory With Genetic Algorithm,"The gradually widening speed disparity between CPU and memory has become an overwhelming bottleneck for the development of chip multiprocessor systems. In addition, increasing penalties caused by frequent on-chip memory accesses have raised critical challenges in delivering high memory access performance with tight power and latency budgets. To overcome the daunting memory wall and energy wall issues, this paper focuses on proposing a new heterogeneous scratchpad memory architecture, which is configured from SRAM, MRAM, and Z-RAM. Based on this architecture, we propose a genetic algorithm to perform data allocation to different memory units, therefore, reducing memory access cost in terms of power consumption and latency. Extensive and experiments are performed to show the merits of the heterogeneous scratchpad architecture over the traditional pure memory system and the effectiveness of the proposed algorithms.","Random access memory,
Resource management,
Biological cells,
Genetic algorithms,
System-on-chip,
Memory management,
Circuit synthesis"
Prospect Theoretic Analysis of Energy Exchange Among Microgrids,"The energy exchange between microgrids (MGs) that are capable of generating power from renewable energy sources in smart grids is investigated. As MGs are autonomous and have control over their energy exchange, prospect theory is a useful tool to provide a user-centric view on MG power trading. More specifically, in this paper, the energy exchange among MGs that are also connected to a power plant as a backup energy supply is formulated as a prospect theory-based static game and Nash equilibria are provided under various scenarios. The impact of user objective weight is evaluated during the outcome evaluation on the performance of the game. Simulation results show that user subjectivity tends to exaggerate selling and buying probabilities when battery levels are high (and low), and thus decreases the overall utility and increases the amount of the energy bought at either low battery levels or low MG selling prices. Conditions on the pricing system to ensure that the energy exchange system is not impacted by the subjective view of MGs are also provided.","Energy exchange,
Games,
Power generation,
Batteries,
Smart grids,
Decision making,
Generators"
Visual-Patch-Attention-Aware Saliency Detection,"The human visual system (HVS) can reliably perceive salient objects in an image, but, it remains a challenge to computationally model the process of detecting salient objects without prior knowledge of the image contents. This paper proposes a visual-attention-aware model to mimic the HVS for salient-object detection. The informative and directional patches can be seen as visual stimuli, and used as neuronal cues for humans to interpret and detect salient objects. In order to simulate this process, two typical patches are extracted individually and in parallel from the intensity channel and the discriminant color channel, respectively, as the primitives. In our algorithm, an improved wavelet-based salient-patch detector is used to extract the visually informative patches. In addition, as humans are sensitive to orientation features, and as directional patches are reliable cues, we also propose a method for extracting directional patches. These two different types of patches are then combined to form the most important patches, which are called preferential patches and are considered as the visual stimuli applied to the HVS for salient-object detection. Compared with the state-of-the-art methods for salient-object detection, experimental results using publicly available datasets show that our produced algorithm is reliable and effective.","Visualization,
Wavelet transforms,
Image color analysis,
Feature extraction,
Image segmentation,
Computational modeling"
Model-Predictive Direct Power Control With Vector Preselection Technique for Highly Efficient Active Rectifiers,"This paper proposes a novel method to reduce switching losses on the basis of a model-predictive direct power control (MPDPC) method for ac-dc active rectifiers. The main idea is to preselect voltage vectors to decrease switching losses at the next sampling period, and then select one optimum voltage vector among only the preselected voltage vectors to perform direct power control (DPC). The proposed vector preselection scheme enables a predefined cost function to consider only four vectors to control the real and the reactive power at every sampling period. The proposed MPDPC method using only the four preselected vectors stops switching operation of one leg exposed to the largest input current at every sampling period. On the basis of the preselected vectors at each sampling period, the proposed method can effectively reduce the switching losses, as well as accurately perform power control of the active rectifier.","Rectifiers,
Vectors,
Reactive power,
Switches,
Switching loss,
Power control,
Voltage control"
How Shadowing Hurts Vehicular Communications and How Dynamic Beaconing Can Help,"We study the effect of radio signal shadowing dynamics, caused by vehicles and by buildings, on the performance of beaconing protocols in Inter-Vehicular Communication (IVC). Recent research indicates that beaconing, i.e., one hop message broadcast, shows excellent characteristics and can outperform other communication approaches for both safety and efficiency applications, which require low latency and wide area information dissemination, respectively. To mitigate the broadcast storm problem, adaptive beaconing solutions have been proposed and designed. We show how shadowing dynamics of moving obstacles hurt IVC, reducing the performance of beaconing protocols. To the best of our knowledge, this is one of the first studies on identifying the problem and the underlying challenges and proposing the opportunities presented by such challenges. Shadowing also limits the risk of overloading the wireless channel. We demonstrate how these challenges and opportunities can be taken into account and outline a novel approach to dynamic beaconing. It provides low-latency communication (i.e., very short beaconing intervals), while ensuring not to overload the wireless channel. The presented simulation results substantiate our theoretical considerations.",
Speaker Adaptive Training of Deep Neural Network Acoustic Models Using I-Vectors,"In acoustic modeling, speaker adaptive training (SAT) has been a long-standing technique for the traditional Gaussian mixture models (GMMs). Acoustic models trained with SAT become independent of training speakers and generalize better to unseen testing speakers. This paper ports the idea of SAT to deep neural networks (DNNs), and proposes a framework to perform feature-space SAT for DNNs. Using i-vectors as speaker representations, our framework learns an adaptation neural network to derive speaker-normalized features. Speaker adaptive models are obtained by fine-tuning DNNs in such a feature space. This framework can be applied to various feature types and network structures, posing a very general SAT solution. In this paper, we fully investigate how to build SAT-DNN models effectively and efficiently. First, we study the optimal configurations of SAT-DNNs for large-scale acoustic modeling tasks. Then, after presenting detailed comparisons between SAT-DNNs and the existing DNN adaptation methods, we propose to combine SAT-DNNs and model-space DNN adaptation during decoding. Finally, to accelerate learning of SAT-DNNs, a simple yet effective strategy, frame skipping, is employed to reduce the size of training data. Our experiments show that compared with a strong DNN baseline, the SAT-DNN model achieves 13.5% and 17.5% relative improvement on word error rates (WERs), without and with model-space adaptation applied respectively. Data reduction based on frame skipping results in 2 × speed-up for SAT-DNN training, while causing negligible WER loss on the testing data.","Adaptation models,
Training,
Speech,
Acoustics,
Testing,
IEEE transactions,
Speech processing"
G2-Type SRMPC Scheme for Synchronous Manipulation of Two Redundant Robot Arms,"In this paper, to remedy the joint-angle drift phenomenon for manipulation of two redundant robot arms, a novel scheme for simultaneous repetitive motion planning and control (SRMPC) at the joint-acceleration level is proposed, which consists of two subschemes. To do so, the performance index of each SRMPC subscheme is derived and designed by employing the gradient dynamics twice, of which a convergence theorem and its proof are presented. In addition, for improving the accuracy of the motion planning and control, position error, and velocity, error feedbacks are incorporated into the forward kinematics equation and analyzed via Zhang neural-dynamics method. Then the two subschemes are simultaneously reformulated as two quadratic programs (QPs), which are finally unified into one QP problem. Furthermore, a piecewise-linear projection equation-based neural network (PLPENN) is used to solve the unified QP problem, which can handle the strictly convex QP problem in an inverse-free manner. More importantly, via such a unified QP formulation and the corresponding PLPENN solver, the synchronism of two redundant robot arms is guaranteed. Finally, two given tasks are fulfilled by 2 three-link and 2 five-link planar robot arms, respectively. Computer-simulation results validate the efficacy and accuracy of the SRMPC scheme and the corresponding PLPENN solver for synchronous manipulation of two redundant robot arms.","Manipulators,
Joints,
Performance analysis,
Robot kinematics,
Acceleration,
Planning"
A Low-Power Wireless Sensor for Online Ambient Monitoring,"This paper presents the development of a compact battery-powered system that monitors the carbon dioxide level, temperature, relative humidity, absolute pressure, and intensity of light in indoor spaces, and that sends the measurement data using the existent wireless infrastructure based on the IEEE 802.11 b/g standards. The resulted device's characteristics and performance are comparable with the ones provided by recognized solutions, such as ZigBee-based sensor nodes. By combining Wi-Fi connectivity with ambient sensors, this solution can be used for the remote gathering and further processing of measurement data. Testing revealed that the system can operate continuously for up to three years on a single 3 V small battery.","Wireless sensor networks,
Temperature sensors,
Temperature measurement,
Power demand,
Wireless communication,
Humidity"
Smoothed Low Rank and Sparse Matrix Recovery by Iteratively Reweighted Least Squares Minimization,"This paper presents a general framework for solving the low-rank and/or sparse matrix minimization problems, which may involve multiple nonsmooth terms. The iteratively reweighted least squares (IRLSs) method is a fast solver, which smooths the objective function and minimizes it by alternately updating the variables and their weights. However, the traditional IRLS can only solve a sparse only or low rank only minimization problem with squared loss or an affine constraint. This paper generalizes IRLS to solve joint/mixed low-rank and sparse minimization problems, which are essential formulations for many tasks. As a concrete example, we solve the Schatten-p norm and ℓ2,q-norm regularized low-rank representation problem by IRLS, and theoretically prove that the derived solution is a stationary point (globally optimal if p, q ≥ 1). Our convergence proof of IRLS is more general than previous one that depends on the special properties of the Schatten-p norm and ℓ2,q-norm. Extensive experiments on both synthetic and real data sets demonstrate that our IRLS is much more efficient.","Convergence,
Minimization,
Linear programming,
Sparse matrices,
Acceleration,
Algorithm design and analysis,
Robustness"
Perceptual Quality Assessment of Screen Content Images,"Research on screen content images (SCIs) becomes important as they are increasingly used in multi-device communication applications. In this paper, we present a study on perceptual quality assessment of distorted SCIs subjectively and objectively. We construct a large-scale screen image quality assessment database (SIQAD) consisting of 20 source and 980 distorted SCIs. In order to get the subjective quality scores and investigate, which part (text or picture) contributes more to the overall visual quality, the single stimulus methodology with 11 point numerical scale is employed to obtain three kinds of subjective scores corresponding to the entire, textual, and pictorial regions, respectively. According to the analysis of subjective data, we propose a weighting strategy to account for the correlation among these three kinds of subjective scores. Furthermore, we design an objective metric to measure the visual quality of distorted SCIs by considering the visual difference of textual and pictorial regions. The experimental results demonstrate that the proposed SCI perceptual quality assessment scheme, consisting of the objective metric and the weighting strategy, can achieve better performance than 11 state-of-the-art IQA methods. To the best of our knowledge, the SIQAD is the first large-scale database published for quality evaluation of SCIs, and this research is the first attempt to explore the perceptual quality assessment of distorted SCIs.","Visualization,
Quality assessment,
Measurement,
Databases,
Image coding,
Image quality,
Transform coding"
Planar Lens Antennas of Subwavelength Thickness: Collimating Leaky-Waves With Metasurfaces,"High-gain lens antennas with a subwavelength thickness that radiate linearly and circularly polarized waves are reported. The lens antennas are fed with a planar, leaky radial waveguide that generates a TM-polarized Bessel beam (Bessel beam launcher). Two different metasurface lenses are placed a subwavelength distance from the Bessel beam launcher to collimate the radiation with minimal reflection loss. The unit cells of the two metasurface lenses are designed to act as inhomogenous wave plates to convert the polarization from radial to linear and circular, respectively. The lens antennas are fabricated using standard printed circuit board processes, and their performance is experimentally characterized. The antennas achieve an order of magnitude thickness reduction over previously reported lens antennas since the metasurface lenses are directly integrated with the antenna feed.","Lenses,
Antenna measurements,
Frequency measurement,
Gain,
Gain measurement,
Apertures"
Fast Volume Reconstruction From Motion Corrupted Stacks of 2D Slices,"Capturing an enclosing volume of moving subjects and organs using fast individual image slice acquisition has shown promise in dealing with motion artefacts. Motion between slice acquisitions results in spatial inconsistencies that can be resolved by slice-to-volume reconstruction (SVR) methods to provide high quality 3D image data. Existing algorithms are, however, typically very slow, specialised to specific applications and rely on approximations, which impedes their potential clinical use. In this paper, we present a fast multi-GPU accelerated framework for slice-to-volume reconstruction. It is based on optimised 2D/3D registration, super-resolution with automatic outlier rejection and an additional (optional) intensity bias correction. We introduce a novel and fully automatic procedure for selecting the image stack with least motion to serve as an initial registration target. We evaluate the proposed method using artificial motion corrupted phantom data as well as clinical data, including tracked freehand ultrasound of the liver and fetal Magnetic Resonance Imaging. We achieve speed-up factors greater than 30 compared to a single CPU system and greater than 10 compared to currently available state-of-the-art multi-core CPU methods. We ensure high reconstruction accuracy by exact computation of the point-spread function for every input data point, which has not previously been possible due to computational limitations. Our framework and its implementation is scalable for available computational infrastructures and tests show a speed-up factor of 1.70 for each additional GPU. This paves the way for the online application of image based reconstruction methods during clinical examinations. The source code for the proposed approach is publicly available.","Image reconstruction,
Three-dimensional displays,
Magnetic resonance imaging,
Approximation methods,
Spatial resolution"
Re-Identification in the Function Space of Feature Warps,"Person re-identification in a non-overlapping multicamera scenario is an open challenge in computer vision because of the large changes in appearances caused by variations in viewing angle, lighting, background clutter, and occlusion over multiple cameras. As a result of these variations, features describing the same person get transformed between cameras. To model the transformation of features, the feature space is nonlinearly warped to get the “warp functions”. The warp functions between two instances of the same target form the set of feasible warp functions while those between instances of different targets form the set of infeasible warp functions. In this work, we build upon the observation that feature transformations between cameras lie in a nonlinear function space of all possible feature transformations. The space consisting of all the feasible and infeasible warp functions is the warp function space (WFS). We propose to learn a discriminating surface separating these two sets of warp functions in the WFS and to re-identify persons by classifying a test warp function as feasible or infeasible. Towards this objective, a Random Forest (RF) classifier is employed which effectively chooses the warp function components according to their importance in separating the feasible and the infeasible warp functions in the WFS. Extensive experiments on five datasets are carried out to show the superior performance of the proposed approach over state-of-the-art person re-identification methods. We show that our approach outperforms all other methods when large illumination variations are considered. At the same time it has been shown that our method reaches the best average performance over multiple combinations of the datasets, thus, showing that our method is not designed only to address a specific challenge posed by a particular dataset.",
Reputation Measurement and Malicious Feedback Rating Prevention in Web Service Recommendation Systems,"Web service recommendation systems can help service users to locate the right service from the large number of available web services. Avoiding recommending dishonest or unsatisfactory services is a fundamental research problem in the design of web service recommendation systems. Reputation of web services is a widely-employed metric that determines whether the service should be recommended to a user. The service reputation score is usually calculated using feedback ratings provided by users. Although the reputation measurement of web service has been studied in the recent literature, existing malicious and subjective user feedback ratings often lead to a bias that degrades the performance of the service recommendation system. In this paper, we propose a novel reputation measurement approach for web service recommendations. We first detect malicious feedback ratings by adopting the cumulative sum control chart, and then we reduce the effect of subjective user feedback preferences employing the Pearson Correlation Coefficient. Moreover, in order to defend malicious feedback ratings, we propose a malicious feedback rating prevention scheme employing Bloom filtering to enhance the recommendation performance. Extensive experiments are conducted by employing a real feedback rating data set with 1.5 million web service invocation records. The experimental results show that our proposed measurement approach can reduce the deviation of the reputation measurement and enhance the success ratio of the web service recommendation.","Web services,
Quality of service,
Peer-to-peer computing,
Measurement,
Control charts,
Monitoring,
Accuracy"
Performance Optimization Using Partitioned SpMV on GPUs and Multicore CPUs,"This paper presents a sparse matrix partitioning strategy to improve the performance of SpMV on GPUs and multicore CPUs. This method has wide adaptability for different types of sparse matrices, and is different from existing methods which only adapt to some particular sparse matrices. In addition, our partitioning method can obtain dense blocks by analyzing the probability distribution of non-zero elements in a sparse matrix, and result in very low proportion of zero padded. We make the following significant contributions. (1) We present a partitioning strategy of sparse matrices based on probabilistic modeling of non-zero elements in a row. (2) We prove that our method has the highest mean density compared with other strategies according to certain given ratios of partition obtained from the computing powers of heterogeneous processors. (3) We develop a CPU-GPU hybrid parallel computing model for SpMV on GPUs and multicore CPUs in a heterogeneous computing platform. Our partitioning strategy has balanced load distribution and the performance of SpMV is significantly improved when a sparse matrix is partitioned into dense blocks using our method. The average performance improvement of our solution for SpMV is about 15.75 percent on multicore CPUs, compared to that of the other solutions. By considering the rows of a matrix in a unique order based on the probability mass function of the number of non-zeros in a row, the average performance improvement of our solution for SpMV is about 33.52 percent on GPUs and multicore CPUs of a heterogeneous computing platform, compared to that of the partitioning methods based on the original row order of a matrix.","Sparse matrices,
Multicore processing,
Program processors,
Partitioning algorithms,
Computational modeling,
Vectors"
Energy Efficient Self-Sustaining Wireless Neighborhood Area Network Design for Smart Grid,"Neighborhood area network (NAN) is one of the most important sections in smart grid communications. It connects residential customers as part of a two-way communication infrastructure responsible for transmitting power grid sensing and measuring status, as well as the control messages. In this paper, we propose a cost-effective, flexible, and sustainable NAN design using wireless technologies such as IEEE 802.11s and IEEE 802.16, as well as renewable energy such as solar power. We propose an optimization problem to minimize total cost. To solve the problem, we also study the problem of selecting the optimal number of gateways in a NAN. Moreover, in order to achieve fairness for the customers and to meet the most critical latency requirements, we propose geographical deployment methods for gateway data aggregate points (DAPs). Different transmission power of each gateway DAP is also carefully determined for the fairness, as well as for the maximum power efficiency. Unlike other researches using game theoretical approaches in multiaccess systems, we manage to achieve the global optimum solution and our results are more energy efficient.","Logic gates,
Batteries,
Wireless communication,
Smart grids,
Power demand,
Smart meters,
Meteorology"
Kriging Based Surrogate Modeling for Fractional Order Control of Microgrids,"This paper investigates the use of fractional order (FO) controllers for a microgrid. The microgrid employs various autonomous generation systems like wind turbine generator, solar photovoltaic, diesel energy generator, and fuel-cells. Other storage devices like the battery energy storage system and the flywheel energy storage system are also present in the power network. An FO control strategy is employed and the FO-proportional integral derivative (PID) controller parameters are tuned with a global optimization algorithm to meet system performance specifications. A kriging based surrogate modeling technique is employed to alleviate the issue of expensive objective function evaluation for the optimization based controller tuning. Numerical simulations are reported to prove the validity of the proposed methods. The results for both the FO and the integer order controllers are compared with standard evolutionary optimization techniques, and the relative merits and demerits of the kriging based surrogate modeling are discussed. This kind of optimization technique is not only limited to this specific case of microgrid control, but also can be ported to other computationally expensive power system optimization problems.","Microgrids,
Optimization,
Stochastic processes,
Computational modeling,
Energy storage,
Frequency control,
Correlation"
Coordinated static and dynamic cache bypassing for GPUs,"The massive parallel architecture enables graphics processing units (GPUs) to boost performance for a wide range of applications. Initially, GPUs only employ scratchpad memory as on-chip memory. Recently, to broaden the scope of applications that can be accelerated by GPUs, GPU vendors have used caches in conjunction with scratchpad memory as on-chip memory in the new generations of GPUs. Unfortunately, GPU caches face many performance challenges that arise due to excessive thread contention for cache resource. Cache bypassing, where memory requests can selectively bypass the cache, is one solution that can help to mitigate the cache resource contention problem. In this paper, we propose coordinated static and dynamic cache bypassing to improve application performance. At compile-time, we identify the global loads that indicate strong preferences for caching or bypassing through profiling. For the rest global loads, our dynamic cache bypassing has the flexibility to cache only a fraction of threads. In CUDA programming model, the threads are divided into work units called thread blocks. Our dynamic bypassing technique modulates the ratio of thread blocks that cache or bypass at run-time. We choose to modulate at thread block level in order to avoid the memory divergence problems. Our approach combines compile-time analysis that determines the cache or bypass preferences for global loads with run-time management that adjusts the ratio of thread blocks that cache or bypass. Our coordinated static and dynamic cache bypassing technique achieves up to 2.28X (average 1.32X) performance speedup for a variety of GPU applications.","Instruction sets,
Graphics processing units,
Synchronization,
Kernel,
Pipelines,
Arrays,
System-on-chip"
Proof of Concept for Robot-Aided Upper Limb Rehabilitation Using Disturbance Observers,"This paper presents a wearable upper body exoskeleton system with a model-based compensation control framework to support robot-aided shoulder-elbow rehabilitation and power assistance tasks. To eliminate the need for EMG and force sensors, we exploit off-the-shelf compensation techniques developed for robot manipulators. Thus, target rehabilitation tasks are addressed by using only encoder readings. A proof-of-concept evaluation was conducted with live able-bodied participants. The patient-active rehabilitation task was realized via observer-based user torque estimation, in which resistive forces were adjusted using virtual impedance. In the patient-passive rehabilitation task, the proposed controller enabled precise joint tracking with a maximum positioning error of 0.25°. In the power assistance task, the users' muscular activities were reduced up to 85% while exercising with a 5 kg dumbbell. Therefore, the exoskeleton system was regarded as being useful for the target tasks, indicating that it has a potential to promote robot-aided therapy protocols.","Joints,
Friction,
Robots,
Exoskeletons,
Torque,
Dynamics,
Force"
Distributed Online Optimal Energy Management for Smart Grids,"Traditionally, economic dispatch and demand response (DR) are considered separately, or implemented sequentially, which may degrade the energy efficiency of the power grids. One important goal of optimal energy management (OEM) is to maximize the social welfare through the coordination of the suppliers' generations and customers' demands. Thus, it is desirable to consider the interactive operation of economic dispatch and DR, and solve them in an integrated way. This paper proposes a fully distributed online OEM solution for smart grids. The proposed solution considers the economic dispatch of conventional generators, DR of users, and operating conditions of renewable generators all together. The proposed distributed solution is developed based on a market-based self-interests motivation model since this model can realize the global social welfare maximization among system participants. The proposed solution can be implemented with multiagent system with each system participant assigned with an energy management agent. Based on the designed distributed algorithms for price updating and supply-demand mismatch discovery, the OEM among agents can be achieved in a distributed way. Simulation results demonstrate the effectiveness of the proposed solution.",
Distributed Fronthaul Compression and Joint Signal Recovery in Cloud-RAN,"The cloud radio access network (C-RAN) is a promising network architecture for future mobile communications, and one practical hurdle for its large scale implementation is the stringent requirement of high capacity and low latency fronthaul connecting the distributed remote radio heads (RRH) to the centralized baseband pools (BBUs) in the C-RAN. To improve the scalability of C-RAN networks, it is very important to take the fronthaul loading into consideration in the signal detection, and it is very desirable to reduce the fronthaul loading in C-RAN systems. In this paper, we consider uplink C-RAN systems and we propose a distributed fronthaul compression scheme at the distributed RRHs and a joint recovery algorithm at the BBUs by deploying the techniques of distributed compressive sensing (CS). Different from conventional distributed CS, the CS problem in C-RAN system needs to incorporate the underlying effect of multi-access fading for the end-to-end recovery of the transmitted signals from the users. We analyze the performance of the proposed end-to-end signal recovery algorithm and we show that the aggregate measurement matrix in C-RAN systems, which contains both the distributed fronthaul compression and multiaccess fading, can still satisfy the restricted isometry property with high probability. Based on these results, we derive tradeoff results between the uplink capacity and the fronthaul loading in C-RAN systems.","Uplink,
Loading,
Fading,
Joints,
Indexes,
Compressed sensing,
Interference"
Algorithms and Applications for Community Detection in Weighted Networks,"Community detection is an important issue due to its wide use in designing network protocols such as data forwarding in Delay Tolerant Networks (DTN) and worm containment in Online Social Networks (OSN). However, most of the existing community detection algorithms focus on binary networks. Since most networks are naturally weighted such as DTN or OSN, in this article, we address the problems of community detection in weighted networks, exploit community for data forwarding in DTN and worm containment in OSN, and demonstrate how community can facilitate these network designs. Specifically, we propose a novel community detection algorithm, and introduce two metrics: intra-centrality and inter-centrality, to characterize nodes in communities, based on which we propose an efficient data forwarding algorithm for DTN and a worm containment strategy for OSN. Extensive trace-driven simulation results show that the proposed community detection algorithm, the data forwarding algorithm, and the worm containment strategy significantly outperform existing works.","Communities,
Grippers,
Detection algorithms,
Image edge detection,
Algorithm design and analysis,
Relays,
Social network services"
k-Nearest Neighbor Classification over Semantically Secure Encrypted Relational Data,"Data Mining has wide applications in many areas such as banking, medicine, scientific research and among government agencies. Classification is one of the commonly used tasks in data mining applications. For the past decade, due to the rise of various privacy issues, many theoretical and practical solutions to the classification problem have been proposed under different security models. However, with the recent popularity of cloud computing, users now have the opportunity to outsource their data, in encrypted form, as well as the data mining tasks to the cloud. Since the data on the cloud is in encrypted form, existing privacy-preserving classification techniques are not applicable. In this paper, we focus on solving the classification problem over encrypted data. In particular, we propose a secure k-NN classifier over encrypted data in the cloud. The proposed protocol protects the confidentiality of data, privacy of user's input query, and hides the data access patterns. To the best of our knowledge, our work is the first to develop a secure k-NN classifier over encrypted data under the semi-honest model. Also, we empirically analyze the efficiency of our proposed protocol using a real-world dataset under different parameter settings.","Protocols,
Encryption,
Data mining,
Zinc,
Vectors"
Visual Tracking Using Strong Classifier and Structural Local Sparse Descriptors,"Sparse coding methods have achieved great success in visual tracking, and we present a strong classifier and structural local sparse descriptors for robust visual tracking. Since the summary features considering the sparse codes are sensitive to occlusion and other interfering factors, we extract local sparse descriptors from a fraction of all patches by performing a pooling operation. The collection of local sparse descriptors is combined into a boosting-based strong classifier for robust visual tracking using a discriminative appearance model. Furthermore, a structural reconstruction error based weight computation method is proposed to adjust the classification score of each candidate for more precise tracking results. To handle appearance changes during tracking, we present an occlusion-aware template update scheme. Comprehensive experimental comparisons with the state-of-the-art algorithms demonstrated the better performance of the proposed method.","Target tracking,
Training,
Visualization,
Robustness,
Dictionaries,
Multimedia communication"
Vibration Control of a Flexible String With Both Boundary Input and Output Constraints,"This paper investigates control design for a flexible string system with both boundary input and output constraints. Dynamics of the string system are represented as a homogeneous partial differential equation describing the vibrations of the system. First, model-based boundary control is proposed by employing an auxiliary system for handling the input saturation and an integral barrier Lyapunov function for eliminating the effect of output constraint. The exponential stability is achieved through rigorous analysis without any simplification of the dynamics. Subsequently, because the system parameters are unknown, adaptive boundary feedback control is proposed and uniform ultimate boundedness is guaranteed. Finally, the simulation results are provided for demonstrating the effectiveness of the proposed control, where all the signals in the control inputs can be measured using the most common sensors.","Control design,
Vibrations,
Adaptation models,
Mathematical model,
Closed loop systems,
Boundary conditions,
Vibration control"
Enabling Adaptive High-Frame-Rate Video Streaming in Mobile Cloud Gaming Applications,"High-frame-rate (HFR) video is emerging in popular gaming applications to enhance the smooth experience perceived by end users. However, it is challenging to guarantee the delivery quality of HFR video in mobile cloud gaming scenarios because of the high transmission rate and limited wireless resources. To address this critical problem, we develop a novel transmission scheduling framework dubbed AdaPtive HFR vIdeo Streaming (APHIS). The term adaptive indicates this scheme's capability in dynamically adjusting the video traffic load and forward error correction (FEC) coding. First, we propose an online video frame selection algorithm to minimize the total distortion based on the network status, input video data, and delay constraint. Second, we introduce an unequal FEC coding scheme to provide differentiated protection for Intra (I) and Predicted (P) frames with low-latency cost. The proposed APHIS framework is able to appropriately filter video frames and adjust data protection levels to optimize the quality of HFR video streaming. We conduct extensive emulations in Exata involving HFR video encoded with H.264 codec. Experimental results show that APHIS outperforms the reference transmission schemes in terms of video peak signal-to-noise ratio, end-to-end delay, and goodput. Therefore, we recommend APHIS for delivering HFR video streaming in mobile cloud gaming systems.","Streaming media,
Distortion,
Video coding,
Cloud computing,
Forward error correction,
Bandwidth,
Packet loss"
Towards Independence: A BCI Telepresence Robot for People With Severe Motor Disabilities,"This paper presents an important step forward towards increasing the independence of people with severe motor disabilities, by using brain-computer interfaces to harness the power of the Internet of Things. We analyze the stability of brain signals as end-users with motor disabilities progress from performing simple standard on-screen training tasks to interacting with real devices in the real world. Furthermore, we demonstrate how the concept of shared control-which interprets the user's commands in context-empowers users to perform rather complex tasks without a high workload. We present the results of nine end-users with motor disabilities who were able to complete navigation tasks with a telepresence robot successfully in a remote environment (in some cases in a different country) that they had never previously visited. Moreover, these end-users achieved similar levels of performance to a control group of 10 healthy users who were already familiar with the environment.","Mobile robots,
Robot sensing systems,
Electroencephalography,
Brain-computer interfaces,
Performance evaluation,
Wheelchairs,
Computer interfaces,
Medical robots"
Distributed Bisection Method for Economic Power Dispatch in Smart Grid,"In this paper, we present a fully distributed bisection algorithm for the economic dispatch problem (EDP) in a smart grid scenario, with the goal to minimize the aggregated cost of a network of generators, which cooperatively furnish a given amount of power within their individual capacity constraints. Our distributed algorithm adopts the method of bisection, and is based on a consensus-like iterative method, with no need for a central decision maker or a leader node. Under strong connectivity conditions and allowance for local communications, we show that the iterative solution converges to the globally optimal solution. Furthermore, two stopping criteria are presented for the practical implementation of the proposed algorithm, for which sign consensus is defined. Finally, numerical simulations based on the IEEE 14-bus and 118-bus systems are given to illustrate the performance of the algorithm.","Convex functions,
Power demand,
Distributed algorithms,
Cost function,
Iterative methods,
Power generation dispatch,
Smart grids"
Consensus-Based Distributed Cooperative Learning From Closed-Loop Neural Control Systems,"In this paper, the neural tracking problem is addressed for a group of uncertain nonlinear systems where the system structures are identical but the reference signals are different. This paper focuses on studying the learning capability of neural networks (NNs) during the control process. First, we propose a novel control scheme called distributed cooperative learning (DCL) control scheme, by establishing the communication topology among adaptive laws of NN weights to share their learned knowledge online. It is further proved that if the communication topology is undirected and connected, all estimated weights of NNs can converge to small neighborhoods around their optimal values over a domain consisting of the union of all state orbits. Second, as a corollary it is shown that the conclusion on the deterministic learning still holds in the decentralized adaptive neural control scheme where, however, the estimated weights of NNs just converge to small neighborhoods of the optimal values along their own state orbits. Thus, the learned controllers obtained by DCL scheme have the better generalization capability than ones obtained by decentralized learning method. A simulation example is provided to verify the effectiveness and advantages of the control schemes proposed in this paper.","Artificial neural networks,
Orbits,
Vectors,
Topology,
Trajectory,
Eigenvalues and eigenfunctions"
Generalized Labeled Multi-Bernoulli Approximation of Multi-Object Densities,"In multiobject inference, the multiobject probability density captures the uncertainty in the number and the states of the objects as well as the statistical dependence between the objects. Exact computation of the multiobject density is generally intractable and tractable implementations usually require statistical independence assumptions between objects. In this paper we propose a tractable multiobject density approximation that can capture statistical dependence between objects. In particular, we derive a tractable Generalized Labeled Multi-Bernoulli (GLMB) density that matches the cardinality distribution and the first moment of the labeled multiobject distribution of interest. It is also shown that the proposed approximation minimizes the Kullback-Leibler divergence over a special tractable class of GLMB densities. Based on the proposed GLMB approximation we further demonstrate a tractable multiobject tracking algorithm for generic measurement models. Simulation results for a multiobject Track-Before-Detect example using radar measurements in low signal-to-noise ratio (SNR) scenarios verify the applicability of the proposed approach.","Approximation methods,
Radar tracking,
Target tracking,
Estimation,
Density measurement,
Signal to noise ratio,
Standards"
Design and ARM-Embedded Implementation of a Chaotic Map-Based Real-Time Secure Video Communication System,"A systematic methodology is proposed for a chaotic map-based real-time video encryption and decryption system with advanced Reduced Instruction Set Computer machine (ARM)-embedded hardware implementation. According to the anticontrol principle of dynamical systems, first, an 8-D discretetime chaotic map-based system is constructed, which possesses the required property of 1-1 surjection in the integer range [0, N - 1], where N is the number of frame pixels, suitable for position scrambling of each video frame. Then, an 8-D discretetime hyperchaotic system is designed for encryption-decryption of red, green, and blue (RGB) tricolor pixel values. Using the ARM-embedded platform super4412 model with Cortex-A9 processor, together with the standard QT cross-platform, an integrated chaotic map-based real-time secure video communication system is designed, implemented, and evaluated. In addition, the security performance of the designed system is tested using criteria from the National Institute of Standards and Technology statistical test suite. The main feature of this method is that, both scrambling-antiscrambling of RGB tricolor pixel positions and encryption-decryption of pixel values are realized simultaneously for enhancing the security. As is well known, compared with numerical simulations, hardware implementation for such a secure video communication system is very difficult to achieve, but we successfully implemented and tested in a real-world network environment. Both theoretical analysis and experimental results validate the feasibility and real-time performance of the new secure video communication system.","Streaming media,
Chaotic communication,
Encryption,
Real-time systems,
Hardware"
Large-scale spatial join query processing in Cloud,The rapidly increasing amount of location data available in many applications has made it desirable to process their large-scale spatial queries in Cloud for performance and scalability. We report our designs and implementations of two prototype systems that are ready for Cloud deployments: SpatialSpark based on Apache Spark and ISP-MC based on Cloudera Impala. Both systems support indexed spatial joins based on point-in-polygon test and point-to-polyline distance computation. Experiments on the pickup locations of ~170 million taxi trips in New York City and ~10 million global species occurrences records have demonstrated both efficiency and scalability using Amazon EC2 clusters.,"Sparks,
Spatial databases,
Query processing,
Hardware,
Scalability,
Data processing,
Filtering"
Cooperative Beamforming and User Selection for Improving the Security of Relay-Aided Systems,"A relay network in which a source wishes to convey a confidential message to a legitimate destination with the assistance of trusted relays is considered. In particular, cooperative beamforming and user selection techniques are applied to protect the confidential message. The secrecy rate (SR) and secrecy outage probability (SOP) of the network are investigated first, and a tight upper bound for the SR and an exact formula for the SOP are derived. Next, asymptotic approximations for the SR and SOP in the high signal-to-noise ratio (SNR) regime are derived for two different schemes: 1) cooperative beamforming and 2) multiuser selection. Furthermore, a new concept of cooperative diversity gain, namely, adapted cooperative diversity gain (ACDG), which can be used to evaluate the security level of a cooperative relaying network, is investigated. It is shown that the ACDG of cooperative beamforming is equal to the conventional cooperative diversity gain of traditional multiple-input single-output networks, while the ACDG of the multiuser scenario is equal to that of traditional single-input multiple-output networks.","Relays,
Array signal processing,
Network security,
Upper bound,
Diversity methods,
Signal to noise ratio,
Wireless networks"
Face Recognition and Retrieval Using Cross-Age Reference Coding With Cross-Age Celebrity Dataset,"This paper introduces a method for face recognition across age and also a dataset containing variations of age in the wild. We use a data-driven method to address the cross-age face recognition problem, called cross-age reference coding (CARC). By leveraging a large-scale image dataset freely available on the Internet as a reference set, CARC can encode the low-level feature of a face image with an age-invariant reference space. In the retrieval phase, our method only requires a linear projection to encode the feature and thus it is highly scalable. To evaluate our method, we introduce a large-scale dataset called cross-age celebrity dataset (CACD). The dataset contains more than 160 000 images of 2,000 celebrities with age ranging from 16 to 62. Experimental results show that our method can achieve state-of-the-art performance on both CACD and the other widely used dataset for face recognition across age. To understand the difficulties of face recognition across age, we further construct a verification subset from the CACD called CACD-VS and conduct human evaluation using Amazon Mechanical Turk. CACD-VS contains 2,000 positive pairs and 2,000 negative pairs and is carefully annotated by checking both the associated image and web contents. Our experiments show that although state-of-the-art methods can achieve competitive performance compared to average human performance, majority votes of several humans can achieve much higher performance on this task. The gap between machine and human would imply possible directions for further improvement of cross-age face recognition in the future.","Face,
Face recognition,
Feature extraction,
Internet,
Encoding,
Aging,
Accuracy"
Subsynchronous Resonance Mitigation for Series-Compensated DFIG-Based Wind Farm by Using Two-Degree-of-Freedom Control Strategy,"This paper investigates a special class of dynamic power system problem, namely subsynchronous resonance (SSR) resulted from a series-compensated network connecting doubly-fed induction generator (DFIG) based wind farms. A novel two-degree-of-freedom (2DOF) control strategy combined with a damping control loop is designed and analyzed for enhancing the system stability and alleviates the SSR that may arise due to the induction generator effect (IGE). The proposed control strategy is tested at different operating conditions of series compensation levels and low wind speeds to ensure the system stability. The doubly-fed induction generator based wind farms without the proposed control strategy leads to overall system instability during high series compensation and low wind speeds. Hence, the mitigation of the SSR and damping enhancement are critical to the entire power system stability. A reliable way of analyzing the system and designing effective control strategies against SSR based on the eigenvalue analysis and impedance based stability criterion is deployed. Moreover, analytical explanations have been elaborated to verify the procedure of the controller design. Fault ride-though capability has also been investigated with the proposed control strategy that is flexible to be integrated with the FRT schemes so as to assist the wind farm in mitigating the SSR during the fault recovery stage. Finally, time domain simulations are carried out to demonstrate the effectiveness of the proposed control strategy for mitigating the SSR and damping power system oscillations.","Damping,
Rotors,
Eigenvalues and eigenfunctions,
Resistance,
Wind farms,
Mathematical model,
Power system stability"
Position Synchronization in Bilateral Teleoperation Under Time-Varying Communication Delays,"Passivity-based approaches to bilateral teleoperation sacrifice performance to achieve robust stability against time-varying delays. Typically, force and velocity signals are exchanged in passivity-based bilateral teleoperation resulting in good velocity tracking, but may accrue a position drift. Recently, a power-based time domain passivity approach (TDPA) was proposed to passivate the communication channel in bilateral teleoperation with time-varying delays, which has the potential to be less conservative than other time-invariant passivity-based approaches. Several approaches have been proposed to address the problem of position drift in time-invariant passivity-based approaches to bilateral teleoperation, but the problem of position drift with power-based TDPA remains unsolved. We propose a feedback passivity-control-based scheme to achieve position synchronization in bilateral teleoperation with power-based TDPA. Our proposed method encodes position information with velocity to construct a composite signal, which is transmitted across the communication channel to attain position tracking. The proposed method utilizes time delay power network formulation, enabling extension to position-measured force bilateral teleoperation scheme. Simulations and experiments conducted on a custom one degree of freedom teleoperation setup demonstrate robust position tracking performance with our approach under time-varying communication delays and remote environment conditions.","Force,
Communication channels,
Ports (Computers),
Delays,
Delay effects,
Synchronization,
Force measurement"
Design Guidelines for Sub-12 nm Nanowire MOSFETs,"Traditional thinking assumes that a light effective mass (m*), high mobility material will result in better transistor characteristics. However, sub-12-nm metal-oxide-semiconductor field effect transistors (MOSFETs) with light m* may underperform compared to standard Si, as a result of source to drain (S/D) tunneling. An optimum heavier mass can decrease tunneling leakage current, and at the same time, improve gate to channel capacitance because of an increased quantum capacitance (Cq). A single band effective mass model has been used to provide the performance trends independent of material, orientation and strain. This paper provides guidelines for achieving optimum m* for sub-12-nm nanowire down to channel length of 3 nm. Optimum m* are found to range between 0.2-1.0 m0 and more interestingly, these masses can be engineered within Si for both p-type and n-type MOSFETs. m* is no longer a material constant, but a geometry and strain dependent property of the channel material.","Effective mass,
Tunneling,
Logic gates,
Silicon,
MOSFET"
CID2013: A Database for Evaluating No-Reference Image Quality Assessment Algorithms,"This paper presents a new database, CID2013, to address the issue of using no-reference (NR) image quality assessment algorithms on images with multiple distortions. Current NR algorithms struggle to handle images with many concurrent distortion types, such as real photographic images captured by different digital cameras. The database consists of six image sets; on average, 30 subjects have evaluated 12-14 devices depicting eight different scenes for a total of 79 different cameras, 480 images, and 188 subjects (67% female). The subjective evaluation method was a hybrid absolute category rating-pair comparison developed for the study and presented in this paper. This method utilizes a slideshow of all images within a scene to allow the test images to work as references to each other. In addition to mean opinion score value, the images are also rated using sharpness, graininess, lightness, and color saturation scales. The CID2013 database contains images used in the experiments with the full subjective data plus extensive background information from the subjects. The database is made freely available for the research community.",
Priority-Based Time-Slot Allocation in Wireless Body Area Networks During Medical Emergency Situations: An Evolutionary Game-Theoretic Perspective,"In critical medical emergency situations, wireless body area network (WBAN) equipped health monitoring systems treat data packets with critical information regarding patients' health in the same way as data packets bearing regular healthcare information. This snag results in a higher average waiting time for the local data processing units (LDPUs) transmitting data packets of higher importance. In this paper, we formulate an algorithm for Priority-based Allocation of Time Slots (PATS) that considers a fitness parameter characterizing the criticality of health data that a packet carries, energy consumption rate for a transmitting LDPU, and other crucial LDPU properties. Based on this fitness parameter, we design the constant model hawk-dove game that ensures prioritizing the LDPUs based on crucial properties. In comparison with the existing works on priority-based wireless transmission, we measure and take into consideration the urgency, seriousness, and criticality associated with an LDPU and, thus, allocate transmission time slots proportionately. We show that the number of transmitting LDPUs in medical emergency situations can be reduced by 25.97%, in comparison with the existing time-division-based techniques.",
Verifiable Auditing for Outsourced Database in Cloud Computing,"The notion of database outsourcing enables the data owner to delegate the database management to a cloud service provider (CSP) that provides various database services to different users. Recently, plenty of research work has been done on the primitive of outsourced database. However, it seems that no existing solutions can perfectly support the properties of both correctness and completeness for the query results, especially in the case when the dishonest CSP intentionally returns an empty set for the query request of the user. In this paper, we propose a new verifiable auditing scheme for outsourced database, which can simultaneously achieve the correctness and completeness of search results even if the dishonest CSP purposely returns an empty set. Furthermore, we can prove that our construction can achieve the desired security properties even in the encrypted outsourced database. Besides, the proposed scheme can be extended to support the dynamic database setting by incorporating the notion of verifiable database with updates.","Databases,
Encryption,
Servers,
Outsourcing,
Educational institutions"
Mode-Dependent Stochastic Synchronization for Markovian Coupled Neural Networks With Time-Varying Mode-Delays,"This paper investigates the stochastic synchronization problem for Markovian hybrid coupled neural networks with interval time-varying mode-delays and random coupling strengths. The coupling strengths are mutually independent random variables and the coupling configuration matrices are nonsymmetric. A mode-dependent augmented Lyapunov-Krasovskii functional (LKF) is proposed, where some terms involving triple or quadruple integrals are considered, which makes the LKF matrices mode-dependent as much as possible. This gives significant improvement in the synchronization criteria, i.e., less conservative results can be obtained. In addition, by applying an extended Jensen's integral inequality and the properties of random variables, new delay-dependent synchronization criteria are derived. The obtained criteria depend not only on upper and lower bounds of mode-delays but also on mathematical expectations and variances of the random coupling strengths. Finally, two numerical examples are provided to demonstrate the feasibility of the proposed results.","Synchronization,
Neural networks,
Couplings,
Linear matrix inequalities,
Random variables,
Complex networks,
Stochastic processes"
Fractional Extreme Value Adaptive Training Method: Fractional Steepest Descent Approach,"The application of fractional calculus to signal processing and adaptive learning is an emerging area of research. A novel fractional adaptive learning approach that utilizes fractional calculus is presented in this paper. In particular, a fractional steepest descent approach is proposed. A fractional quadratic energy norm is studied, and the stability and convergence of our proposed method are analyzed in detail. The fractional steepest descent approach is implemented numerically and its stability is analyzed experimentally.",
Matching EV Charging Load With Uncertain Wind: A Simulation-Based Policy Improvement Approach,"This paper studies the electric vehicle (EV) charging scheduling problem to match the stochastic wind power. Besides considering the optimality of the expected charging cost, the proposed model innovatively incorporates the matching degree between wind power and EV charging load into the objective function. Fully taking into account the uncertainty and dynamics in wind energy supply and EV charging demand, this stochastic and multistage matching is formulated as a Markov decision process. In order to enhance the computational efficiency, the effort is made in two aspects. Firstly, the problem size is reduced by aggregating EVs according to their remaining parking time. The charging scheduling is carried out on the level of aggregators and the optimality of the original problem is proved to be preserved. Secondly, the simulation-based policy improvement method is developed to obtain an improved charging policy from the base policy. The validation of the proposed model, scalability, and computational efficiency of the proposed methods are systematically investigated via numerical experiments.","Wind power generation,
Wind energy,
Vehicles,
Stochastic processes,
Renewable energy sources,
Wind speed,
Q-factor"
Cross-Domain Feature Learning in Multimedia,"In the Web 2.0 era, a huge number of media data, such as text, image/video, and social interaction information, have been generated on the social media sites (e.g., Facebook, Google, Flickr, and YouTube). These media data can be effectively adopted for many applications (e.g., image/video annotation, image/video retrieval, and event classification) in multimedia. However, it is difficult to design an effective feature representation to describe these data because they have multi-modal property (e.g., text, image, video, and audio) and multi-domain property (e.g., Flickr, Google, and YouTube). To deal with these issues, we propose a novel cross-domain feature learning (CDFL) algorithm based on stacked denoising auto-encoders. By introducing the modal correlation constraint and the cross-domain constraint in conventional auto-encoder, our CDFL can maximize the correlations among different modalities and extract domain invariant semantic features simultaneously. To evaluate our CDFL algorithm , we apply it to three important applications: sentiment classification, spam filtering, and event classification. Comprehensive evaluations demonstrate the encouraging performance of the proposed approach.",
A Game Theory-Based Energy Management System Using Price Elasticity for Smart Grids,"Distributed devices in smart grid systems are decentralized and connected to the power grid through different types of equipment transmit, which will produce numerous energy losses when power flows from one bus to another. One of the most efficient approaches to reduce energy losses is to integrate distributed generations (DGs), mostly renewable energy sources. However, the uncertainty of DG may cause instability issues. Additionally, due to the similar consumption habits of customers, the peak load period of power consumption may cause congestion in the power grid and affect the energy delivery. Energy management with DG regulation is considered to be one of the most efficient solutions for solving these instability issues. In this paper, we consider a power system with both distributed generators and customers, and propose a distributed locational marginal pricing (DLMP)-based unified energy management system (uEMS) model, which, unlike previous works, considers both increasing profit benefits for DGs and increasing stability of the distributed power system (DPS). The model contains two parts: 1) a game theory-based loss reduction allocation (LRA); and 2) a load feedback control (LFC) with price elasticity. In the former component, we develop an iterative loss reduction method using DLMP to remunerate DGs for their participation in energy loss reduction. By using iterative LRA to calculate energy loss reduction, the model accurately rewards DG contribution and offers a fair competitive market. Furthermore, the overall profit of all DGs is maximized by utilizing game theory to calculate an optimal LRA scheme for calculating the distributed loss of every DG in each time slot. In the latter component of the model, we propose an LFC submodel with price elasticity, where a DLMP feedback signal is calculated by customer demand to regulate peak-load value. In uEMS, LFC first determines the DLMP signal of a customer bus by a time-shift load optimization (LO) algorithm based on the changes of customer demand, which is fed back to the DLMP of the customer bus at the next slot-time, allowing for peak-load regulation via price elasticity. Results based on the IEEE 37-bus feeder system show that the proposed uEMS model can increase DG benefits and improve system stability.",
Inverse Sparse Tracker With a Locally Weighted Distance Metric,"Sparse representation has been recently extensively studied for visual tracking and generally facilitates more accurate tracking results than classic methods. In this paper, we propose a sparsity-based tracking algorithm that is featured with two components: 1) an inverse sparse representation formulation and 2) a locally weighted distance metric. In the inverse sparse representation formulation, the target template is reconstructed with particles, which enables the tracker to compute the weights of all particles by solving only one ℓ1 optimization problem and thereby provides a quite efficient model. This is in direct contrast to most previous sparse trackers that entail solving one optimization problem for each particle. However, we notice that this formulation with normal Euclidean distance metric is sensitive to partial noise like occlusion and illumination changes. To this end, we design a locally weighted distance metric to replace the Euclidean one. Similar ideas of using local features appear in other works, but only being supported by popular assumptions like local models could handle partial noise better than holistic models, without any solid theoretical analysis. In this paper, we attempt to explicitly explain it from a mathematical view. On that basis, we further propose a method to assign local weights by exploiting the temporal and spatial continuity. In the proposed method, appearance changes caused by partial occlusion and shape deformation are carefully considered, thereby facilitating accurate similarity measurement and model update. The experimental validation is conducted from two aspects: 1) self validation on key components and 2) comparison with other state-of-the-art algorithms. Results over 15 challenging sequences show that the proposed tracking algorithm performs favorably against the existing sparsity-based trackers and the other state-of-the-art methods.","Target tracking,
Euclidean distance,
Noise,
Object tracking,
Image reconstruction,
Shape"
NextCell: Predicting Location Using Social Interplay from Cell Phone Traces,"Location prediction based on cellular network traces has recently spurred lots of attention. However, predicting user mobility remains a very challenging task due to the fuzziness of human mobility patterns. Our preliminary study included in this paper shows that there is a strong correlation between the calling patterns and co-cell patterns of users (i.e., co-occurrence in the same cell tower at the same time). Based on this finding, we propose NextCell-a novel algorithm that aims to enhance the location prediction by harnessing the social interplay revealed in cellular call records. Moreover, our proposal removes the assumption held in previous schemes that binds locations of cell towers to concrete physical coordinates, e.g., GPS coordinates. We validate our approach with the MIT Reality Mining dataset that involves 32,579 symbolic cell tower locations and 350,000 hours of continuous activity information. Experimental results show that NextCell achieves higher precision and recall than the state-of-the-art schemes at cell tower level in the forthcoming one to six hours.","Poles and towers,
Computer architecture,
Correlation,
GSM,
Microprocessors,
Social network services"
In Situ Diagnostics and Prognostics of Solder Fatigue in IGBT Modules for Electric Vehicle Drives,"This paper proposes an in situ diagnostic and prognostic (D&P) technology to monitor the health condition of insulated gate bipolar transistors (IGBTs) used in EVs with a focus on the IGBTs' solder layer fatigue. IGBTs' thermal impedance and the junction temperature can be used as health indicators for through-life condition monitoring (CM) where the terminal characteristics are measured and the devices' internal temperature-sensitive parameters are employed as temperature sensors to estimate the junction temperature. An auxiliary power supply unit, which can be converted from the battery's 12-V dc supply, provides power to the in situ test circuits and CM data can be stored in the on-board data-logger for further offline analysis. The proposed method is experimentally validated on the developed test circuitry and also compared with finite-element thermoelectrical simulation. The test results from thermal cycling are also compared with acoustic microscope and thermal images. The developed circuitry is proved to be effective to detect solder fatigue while each IGBT in the converter can be examined sequentially during red-light stopping or services. The D&P circuitry can utilize existing on-board hardware and be embedded in the IGBT's gate drive unit.","Temperature measurement,
Insulated gate bipolar transistors,
Fatigue,
Current measurement,
Heating,
Impedance,
Semiconductor device measurement"
Characterization of an enhancement-mode 650-V GaN HFET,"GaN heterojunction field-effect transistors (HFETs) in the 600-V class are relatively new in commercial power electronics. The GaN Systems GS66508 is the first commercially available 650-V enhancement-mode device. Static and dynamic testing has been performed across the full current, voltage, and temperature range to enable GaN-based converter design using this new device. A curve tracer was used to measure Rds-on across the full operating temperature range, as well as the self-commutated reverse conduction (i.e. diode-like) behavior. Other static parameters such as transconductance and gate current were also measured. A double pulse test setup was constructed and used to measure switching loss and time at the fastest achievable switching speed, and the subsequent over-voltages due to the fast switching were characterized. Based on these results and analysis, an accurate loss model has been developed for the GS66508 to allow for GaN-based converter design and comparison with other commercially available devices in the 600-V class.","Logic gates,
Gallium nitride,
HEMTs,
MODFETs,
Switches,
Junctions,
Performance evaluation"
Helper Data Algorithms for PUF-Based Key Generation: Overview and Analysis,"Security-critical products rely on the secrecy and integrity of their cryptographic keys. This is challenging for low-cost resource-constrained embedded devices, with an attacker having physical access to the integrated circuit (IC). Physically, unclonable functions are an emerging technology in this market. They extract bits from unavoidable IC manufacturing variations, remarkably analogous to unique human fingerprints. However, post-processing by helper data algorithms (HDAs) is indispensable to meet the stringent key requirements: reproducibility, high-entropy, and control. The novelty of this paper is threefold. We are the first to provide an in-depth and comprehensive literature overview on HDAs. Second, our analysis does expose new threats regarding helper data leakage and manipulation. Third, we identify several hiatuses/open problems in existing literature.","Entropy,
Integrated circuits,
Equations,
Manufacturing,
Reliability,
Error analysis,
Mathematical model"
A Stochastic Transmission Planning Model With Dependent Load and Wind Forecasts,"This paper introduces a two-stage stochastic program for transmission planning. The model has two dependent random variables, namely, total electric load and available wind power. Given univariate marginal distributions for these two random variables and their correlation coefficient, the joint distribution is modeled using a Gaussian copula. The optimal power flow (OPF) problem is solved based on the linearized direct current (DC) power flow. The Electric Reliability Council of Texas (ERCOT) network model and its load and wind data are used for a test case. A 95% confidence interval is formed on the optimality gap of candidate solutions obtained using a sample average approximation with 200 and 300 samples from the joint distribution of load and wind.","Load modeling,
Power system planning,
Stochastic processes,
Wind power generation,
Wind forecasting"
Privacy-Preserving Ciphertext Multi-Sharing Control for Big Data Storage,"The need of secure big data storage service is more desirable than ever to date. The basic requirement of the service is to guarantee the confidentiality of the data. However, the anonymity of the service clients, one of the most essential aspects of privacy, should be considered simultaneously. Moreover, the service also should provide practical and fine-grained encrypted data sharing such that a data owner is allowed to share a ciphertext of data among others under some specified conditions. This paper, for the first time, proposes a privacy-preserving ciphertext multi-sharing mechanism to achieve the above properties. It combines the merits of proxy re-encryption with anonymous technique in which a ciphertext can be securely and conditionally shared multiple times without leaking both the knowledge of underlying message and the identity information of ciphertext senders/recipients. Furthermore, this paper shows that the new primitive is secure against chosen-ciphertext attacks in the standard model.","Receivers,
Encryption,
Games,
Big data,
Standards"
A Learning Framework for Age Rank Estimation Based on Face Images With Scattering Transform,"This paper presents a cost-sensitive ordinal hyperplanes ranking algorithm for human age estimation based on face images. The proposed approach exploits relative-order information among the age labels for rank prediction. In our approach, the age rank is obtained by aggregating a series of binary classification results, where cost sensitivities among the labels are introduced to improve the aggregating performance. In addition, we give a theoretical analysis on designing the cost of individual binary classifier so that the misranking cost can be bounded by the total misclassification costs. An efficient descriptor, scattering transform, which scatters the Gabor coefficients and pooled with Gaussian smoothing in multiple layers, is evaluated for facial feature extraction. We show that this descriptor is a generalization of conventional bioinspired features and is more effective for face-based age inference. Experimental results demonstrate that our method outperforms the state-of-the-art age estimation approaches.","Estimation,
Aging,
Face,
Manifolds,
Feature extraction,
Kernel,
Active appearance model"
Recursive Undecimated Wavelet Packet Transform and DAG SVM for Induction Motor Diagnosis,"This paper is focused on the design of a new approach dedicated to solve classification problems for the detection of broken rotor bar (BRB) fault in induction motors (IM). This new method finds its origins in a novel combination of both recursive undecimated wavelet packet transform (RUWPT) and directed acyclic graph support vector machines (DAG SVMs). Most often, BRB frequency components are hardly detected in the stator current due to its low magnitude and closeness to the supply frequency component. To overcome this drawback, the RUWPT is applied to extract one parameter able to detect the fault with arbitrary working conditions and a great concern of low load cases. Different multiclass support vector machines (MSVMs) methods are evaluated with respect to accuracy, number of support vectors, and testing time. The experimental results confirm that the DAG SVMs and Symlet wavelet kernel function are fast, robust, and give the best classification accuracy of 99%.","Support vector machines,
Kernel,
Induction motors,
Feature extraction,
Discrete wavelet transforms"
High Resolution Magnetometer Based on a High Frequency Magnetoelectric MEMS-CMOS Oscillator,"This paper demonstrates a miniaturized and high resolution (16 nT/Hz1/2) magnetometer based on a high frequency (168.1 MHz) magnetoelectric Microelectromechanical Systems-Complementary metal-oxidesemiconductor (MEMSCMOS) oscillator. For the first time, a high frequency and high electromechanical performance (quality factor, Q ~ 1084 and electromechanical coupling coefficient, kt2 ~ 1.18%) magnetoelectric micromechanical resonator based on a self-biased aluminum nitride/iron-gallium-boron (AlN/FeGaB) bilayer nanoplate (250/250 nm) is implemented and used to synthesize a low noise frequency source (2.7 Hz/Hz1/2) whose output frequency is highly sensitive to external magnetic field (169 Hz/μT at zero magnetic field bias). The angular sensitivity of the magnetometer for electronic compass applications is also investigated showing an ultrahigh angular resolution of 0.34° for a 10-μT conservative estimate of the earth's magnetic field, due to the strongly anisotropic sensitivity of the self-biased AlN/FeGaB magnetoelectric resonator. This paper represents the first demonstration of a high resolution self-biased MEMS magnetoelectric resonant sensor interfaced to a compact and low power self-sustained CMOS oscillator as direct frequency readout for the implementation of miniaturized and low power magnetometers with detection limit pushed in ~10s nT/Hz1/2 range.","Magnetic resonance,
Magnetometers,
Magnetostriction,
Magnetoelectric effects,
III-V semiconductor materials,
Perpendicular magnetic anisotropy"
Fast Bulk Bitwise AND and OR in DRAM,"Bitwise operations are an important component of modern day programming, and are used in a variety of applications such as databases. In this work, we propose a new and simple mechanism to implement bulk bitwise AND and OR operations in DRAM, which is faster and more efficient than existing mechanisms. Our mechanism exploits existing DRAM operation to perform a bitwise AND/OR of two DRAM rows completely within DRAM. The key idea is to simultaneously connect three cells to a bitline before the sense-amplification. By controlling the value of one of the cells, the sense amplifier forces the bitline to the bitwise AND or bitwise OR of the values of the other two cells. Our approach can improve the throughput of bulk bitwise AND/OR operations by 9:7X and reduce their energy consumption by 50:5X. Since our approach exploits existing DRAM operation as much as possible, it requires negligible changes to DRAM logic. We evaluate our approach using a real-world implementation of a bit-vector based index for databases. Our mechanism improves the performance of commonly-used range queries by 30 percent on average.","Random access memory,
Throughput,
DRAM,
Program processors,
Capacitors,
Computer architecture,
Decoding"
Oriented Correlation Models of Distorted Natural Images With Application to Natural Stereopair Quality Evaluation,"In recent years, bandpass statistical models of natural, photographic images of the world have been used with great success to solve highly diverse problems involving image representation, image repair, image quality assessment (IQA), and image compression. One missing element has been a reliable and generic model of spatial image correlation that reflects the distributions of oriented and relatively oriented spatial structures. We have developed such a model for bandpass pristine images and have generalized it here to also capture the spatial correlation structure of bandpass distorted images. The model applies well to both luminance and depth images. As a demonstration of the usefulness of the generalized model, we develop a new no-reference stereoscopic/3D IQA framework, dubbed stereoscopic/3D blind image naturalness quality index, which utilizes both univariate and generalized bivariate natural scene statistics (NSS) models. We first validate the robustness and effectiveness of these novel bivariate and correlation NSS features extracted from distorted stereopairs, then demonstrate that they are predictive of distortion severity. Our experimental results show that the resulting 3D image quality predictor based in part on the new model outperforms state-of-the-art full- and no-reference 3D IQA algorithms on both symmetrically and asymmetrically distorted stereoscopic image pairs.","Correlation,
Feature extraction,
Three-dimensional displays,
Computational modeling,
Image quality,
Hidden Markov models,
Stereo image processing"
Multimedia Summarization for Social Events in Microblog Stream,"Microblogging services have revolutionized the way people exchange information. Confronted with the ever-increasing numbers of social events and the corresponding microblogs with multimedia contents, it is desirable to provide visualized summaries to help users to quickly grasp the essence of these social events for better understanding. While existing approaches mostly focus only on text-based summary, microblog summarization with multiple media types (e.g., text, image, and video) is scarcely explored. In this paper, we propose a multimedia social event summarization framework to automatically generate visualized summaries from the microblog stream of multiple media types. Specifically, the proposed framework comprises three stages, as follows. 1) A noise removal approach is first devised to eliminate potentially noisy images. An effective spectral filtering model is exploited to estimate the probability that an image is relevant to a given event. 2) A novel cross-media probabilistic model, termed Cross-Media-LDA (CMLDA), is proposed to jointly discover subevents from microblogs of multiple media types. The intrinsic correlations among these different media types are well explored and exploited for reinforcing the cross-media subevent discovery process. 3) Finally, based on the cross-media knowledge of all the discovered subevents, a multimedia microblog summary generation process is designed to jointly identify both representative textual and visual samples, which are further aggregated to form a holistic visualized summary. We conduct extensive experiments on two real-world microblog datasets to demonstrate the superiority of the proposed framework as compared to the state-of-the-art approaches.","Visualization,
Multimedia communication,
Media,
Noise measurement,
Streaming media,
Feature extraction,
Semantics"
A Distributed Generation Control Architecture for Islanded AC Microgrids,"In this paper, we propose a distributed architecture for generation control in islanded ac microgrids with both synchronous generators and inverter-interfaced power supplies. Although they are smaller and have lower ratings, the generation control objectives for an islanded microgrid are similar to those in large power systems, e.g., bulk power transmission networks; specifically, without violating limits on generator power output, frequency must be regulated and generation costs should be minimized. However, in large power systems, the implementation of the generation control functions is centralized, i.e., there is a computer that resides in a centralized location, e.g., a control center, with measurements and control signals telemetered between the generating units and the centrally located computer. The architecture for generation control that we propose in this paper does not rely on such a centrally located computer. Instead, the implementation of the control functions is distributed and relies on iterative algorithms that combine local measurements and certain information acquired from neighboring generating units with local, low-complexity computations. We provide analytical and experimental results that verify the effectiveness of the proposed architecture for generation control in islanded microgrids, and illustrate the performance of the aforementioned distributed algorithms under a variety of scenarios.",
Four-Class Classification of Skin Lesions With Task Decomposition Strategy,"This paper proposes a new computer-aided method for the skin lesion classification applicable to both melanocytic skin lesions (MSLs) and nonmelanocytic skin lesions (NoMSLs). The computer-aided skin lesion classification has drawn attention as an aid for detection of skin cancers. Several researchers have developed methods to distinguish between melanoma and nevus, which are both categorized as MSL. However, most of these studies did not focus on NoMSLs such as basal cell carcinoma (BCC), the most common skin cancer and seborrheic keratosis (SK) despite their high incidence rates. It is preferable to deal with these NoMSLs as well as MSLs especially for the potential users who are not enough capable of diagnosing pigmented skin lesions on their own such as dermatologists in training and physicians with different expertise. We developed a new method to distinguish among melanomas, nevi, BCCs, and SKs. Our method calculates 828 candidate features grouped into three categories: color, subregion, and texture. We introduced two types of classification models: a layered model that uses a task decomposition strategy and flat models to serve as performance baselines. We tested our methods on 964 dermoscopy images: 105 melanomas, 692 nevi, 69 BCCs, and 98 SKs. The layered model outperformed the flat models, achieving detection rates of 90.48%, 82.51%, 82.61%, and 80.61% for melanomas, nevi, BCCs, and SKs, respectively. We also identified specific features effective for the classification task including irregularity of color distribution. The results show promise for enhancing the capability of the computer-aided skin lesion classification.","Malignant tumors,
Skin,
Lesions,
Image color analysis,
Feature extraction,
Educational institutions"
COMMIT: Convex Optimization Modeling for Microstructure Informed Tractography,"Tractography is a class of algorithms aiming at in vivo mapping the major neuronal pathways in the white matter from diffusion magnetic resonance imaging (MRI) data. These techniques offer a powerful tool to noninvasively investigate at the macroscopic scale the architecture of the neuronal connections of the brain. However, unfortunately, the reconstructions recovered with existing tractography algorithms are not really quantitative even though diffusion MRI is a quantitative modality by nature. As a matter of fact, several techniques have been proposed in recent years to estimate, at the voxel level, intrinsic microstructural features of the tissue, such as axonal density and diameter, by using multicompartment models. In this paper, we present a novel framework to reestablish the link between tractography and tissue microstructure. Starting from an input set of candidate fiber-tracts, which are estimated from the data using standard fiber-tracking techniques, we model the diffusion MRI signal in each voxel of the image as a linear combination of the restricted and hindered contributions generated in every location of the brain by these candidate tracts. Then, we seek for the global weight of each of them, i.e., the effective contribution or volume, such that they globally fit the measured signal at best. We demonstrate that these weights can be easily recovered by solving a global convex optimization problem and using efficient algorithms. The effectiveness of our approach has been evaluated both on a realistic phantom with known ground-truth and in vivo brain data. Results clearly demonstrate the benefits of the proposed formulation, opening new perspectives for a more quantitative and biologically plausible assessment of the structural connectivity of the brain.","Convex functions,
Computational modeling,
Estimation,
Nerve fibers,
Magnetic resonance imaging,
Image reconstruction"
An Evolutionary Algorithm with Double-Level Archives for Multiobjective Optimization,"Existing multiobjective evolutionary algorithms (MOEAs) tackle a multiobjective problem either as a whole or as several decomposed single-objective sub-problems. Though the problem decomposition approach generally converges faster through optimizing all the sub-problems simultaneously, there are two issues not fully addressed, i.e., distribution of solutions often depends on a priori problem decomposition, and the lack of population diversity among sub-problems. In this paper, a MOEA with double-level archives is developed. The algorithm takes advantages of both the multiobjective-problem-level and the sub-problem-level approaches by introducing two types of archives, i.e., the global archive and the sub-archive. In each generation, self-reproduction with the global archive and cross-reproduction between the global archive and sub-archives both breed new individuals. The global archive and sub-archives communicate through cross-reproduction, and are updated using the reproduced individuals. Such a framework thus retains fast convergence, and at the same time handles solution distribution along Pareto front (PF) with scalability. To test the performance of the proposed algorithm, experiments are conducted on both the widely used benchmarks and a set of truly disconnected problems. The results verify that, compared with state-of-the-art MOEAs, the proposed algorithm offers competitive advantages in distance to the PF, solution coverage, and search speed.","Optimization,
Sociology,
Statistics,
Vectors,
Convergence,
Shape,
Genetic algorithms"
Multivariate Machine Learning Methods for Fusing Multimodal Functional Neuroimaging Data,"Multimodal data are ubiquitous in engineering, communications, robotics, computer vision, or more generally speaking in industry and the sciences. All disciplines have developed their respective sets of analytic tools to fuse the information that is available in all measured modalities. In this paper, we provide a review of classical as well as recent machine learning methods (specifically factor models) for fusing information from functional neuroimaging techniques such as: LFP, EEG, MEG, fNIRS, and fMRI. Early and late fusion scenarios are distinguished, and appropriate factor models for the respective scenarios are presented along with example applications from selected multimodal neuroimaging studies. Further emphasis is given to the interpretability of the resulting model parameters, in particular by highlighting how factor models relate to physical models needed for source localization. The methods we discuss allow for the extraction of information from neural data, which ultimately contributes to 1) better neuroscientific understanding; 2) enhance diagnostic performance; and 3) discover neural signals of interest that correlate maximally with a given cognitive paradigm. While we clearly study the multimodal functional neuroimaging challenge, the discussed machine learning techniques have a wide applicability, i.e., in general data fusion, and may thus be informative to the general interested reader.","Brain models,
Neuroimaging,
Feature extraction,
Data mining,
Data models,
Multimodal sensors"
Public Integrity Auditing for Dynamic Data Sharing With Multiuser Modification,"In past years, the rapid development of cloud storage services makes it easier than ever for cloud users to share data with each other. To ensure users' confidence of the integrity of their shared data on cloud, a number of techniques have been proposed for data integrity auditing with focuses on various practical features, e.g., the support of dynamic data, public integrity auditing, low communication/computational audit cost, and low storage overhead. However, most of these techniques consider that only the original data owner can modify the shared data, which limits these techniques to client read-only applications. Recently, a few attempts started considering more realistic scenarios by allowing multiple cloud users to modify data with integrity assurance. Nevertheless, these attempts are still far from practical due to the tremendous computational cost on cloud users, especially when high error detection probability is required by the system. In this paper, we propose a novel integrity auditing scheme for cloud data sharing services characterized by multiuser modification, public auditing, high error detection probability, efficient user revocation as well as practical computational/communication auditing performance. Our scheme can resist user impersonation attack, which is not considered in existing techniques that support multiuser modification. Batch auditing of multiple tasks is also efficiently supported in our scheme. Extensive experiments on Amazon EC2 cloud and different client devices (contemporary and mobile devices) show that our design allows the client to audit the integrity of a shared file with a constant computational cost of 340 ms on PC (4.6 s on mobile device) and a bounded communication cost of 77 kB for 99% error detection probability with data corruption rate of 1%.","Cloud computing,
Authentication,
Polynomials,
Servers,
Computational efficiency,
Public key,
Algorithm design and analysis"
Tuning of Synchronous-Frame PI Current Controllers in Grid-Connected Converters Operating at a Low Sampling Rate by MIMO Root Locus,"Current controller performance is key in grid-connected power converters for renewable energy applications. In this context, a challenging scenario is arising in multi-megawatt wind turbines, where sampling and switching frequencies tend to be lower and lower as power ratings increase. This strongly affects achievable control time constant. With this perspective, this paper presents a systematic procedure for accurate dynamics assessment and tuning of synchronous-frame proportional-integral current controllers, which is based on linear control for multiple-input-multiple-output (MIMO) systems. The dominant eigenvalues of the system are calculated with explicit consideration of time-delay and cross-coupling terms, two factors which clearly impair the system dynamics when considering a low sampling frequency. The proposed methodology is summarized as follows. First, the plant and controller matrices are modeled in state space. Subsequently, the characteristic polynomial of the closed-loop system is obtained and a computer-aided parametric analysis is performed to calculate the MIMO root locus as a function of the control gain. By its inspection, it is possible to identify the gain, which minimizes the current closed-loop time constant. This tuning is suitable for wind turbine applications, taking into consideration cascaded-control structures and grid-code requirements. The validity and accuracy of the analysis is fully supported by experimental verification.","MIMO,
Tuning,
Delays,
Approximation methods,
Bandwidth,
Eigenvalues and eigenfunctions,
Couplings"
Video anomaly detection and localization using hierarchical feature representation and Gaussian process regression,"This paper presents a hierarchical framework for detecting local and global anomalies via hierarchical feature representation and Gaussian process regression. While local anomaly is typically detected as a 3D pattern matching problem, we are more interested in global anomaly that involves multiple normal events interacting in an unusual manner such as car accident. To simultaneously detect local and global anomalies, we formulate the extraction of normal interactions from training video as the problem of efficiently finding the frequent geometric relations of the nearby sparse spatio-temporal interest points. A codebook of interaction templates is then constructed and modeled using Gaussian process regression. A novel inference method for computing the likelihood of an observed interaction is also proposed. As such, our model is robust to slight topological deformations and can handle the noise and data unbalance problems in the training data. Simulations show that our system outperforms the main state-of-the-art methods on this topic and achieves at least 80% detection rates based on three challenging datasets.","Ground penetrating radar,
Gaussian processes,
Three-dimensional displays,
Computational modeling,
Training data,
Visualization,
Semantics"
Miniaturized Circularly Polarized Loop Antenna for Biomedical Applications,"A novel circularly polarized antenna is proposed at 902-928 MHz Industrial, Scientific, and Medical band for implantable applications. By properly positioning the feed and shorts, either right-hand circular polarization property or left-hand circular polarization property can be realized. Slow wave concept is utilized by loading patches to the radiated loop antenna to achieve miniaturization. Thus, a compact size of 13 mm × 13 mm × 1.27 mm is obtained. Compared to the unloaded loop antenna of the same size, the centre frequency shifts from 1.93 GHz to 882.5 MHz, which suggests a miniaturization of 54.4%. The simulated results show that a wide bandwidth of 18.2% can be realized with |S11| below -10 dB and axial ratio below 3 dB. The simulated realized gain is -32 dBi at 915 MHz. The measurement is carried out in both skin-mimicking gel and pork, and a bandwidth of 27.8% and 29.4% can be achieved with |S11| below -10 dB, respectively. The measurement of |S21| reveals that circular polarization can be obtained for the proposed configuration.","Skin,
Gain,
Polarization,
Antenna measurements,
Loaded antennas"
Deformation Corrected Compressed Sensing (DC-CS): A Novel Framework for Accelerated Dynamic MRI,"We propose a novel deformation corrected compressed sensing (DC-CS) framework to recover contrast enhanced dynamic magnetic resonance images from undersampled measurements. We introduce a formulation that is capable of handling a wide class of sparsity/compactness priors on the deformation corrected dynamic signal. In this work, we consider example compactness priors such as sparsity in temporal Fourier domain, sparsity in temporal finite difference domain, and nuclear norm penalty to exploit low rank structure. Using variable splitting, we decouple the complex optimization problem to simpler and well understood sub problems; the resulting algorithm alternates between simple steps of shrinkage-based denoising, deformable registration, and a quadratic optimization step. Additionally, we employ efficient continuation strategies to reduce the risk of convergence to local minima. The decoupling enabled by the proposed scheme enables us to apply this scheme to contrast enhanced MRI applications. Through experiments on numerical phantom and in vivo myocardial perfusion MRI datasets, we observe superior image quality of the proposed DC-CS scheme in comparison to the classical k-t FOCUSS with motion estimation/correction scheme, and demonstrate reduced motion artifacts over classical compressed sensing schemes that utilize the compact priors on the original deformation uncorrected signal.","Magnetic resonance imaging,
Image reconstruction,
Convergence,
Dynamics,
Myocardium,
Optimization,
Force"
Nonintrusive Load Monitoring: A Temporal Multilabel Classification Approach,"The article tackles the issues related to the identification of electrical appliances inside residential buildings. Each appliance can be identified from the aggregate power readings at the meter panel. The possibility of applying a temporal multilabel classification approach in the domain of nonintrusive load monitoring is explored (nonevent-based method). A novel set of metafeatures is proposed. The method is tested on sampling rates based on the capabilities of current smart meters. The proposed approach is validated over a dataset of energy readings at residences for a period of a year for 100 houses containing different sets of appliances (water heater, washing machines, etc.). This method is applicable for the demand side management of households in the current limitation of smart meters; from the inhabitants or from the grid operator's point of view.","Home appliances,
Hidden Markov models,
Informatics,
Training,
Monitoring,
Market research,
Time series analysis"
Second-Order Terahertz Bandpass Frequency Selective Surface With Miniaturized Elements,"In this paper, a second-order frequency selective surface (FSS) made of miniaturized elements is proposed and designed for terahertz applications. The FSS is composed of two layers of metallic arrays separated from each other by a polymer dielectric spacer. The unit cells on the front and back layers are smaller than λ0/5, where λ0 is the free space wavelength. The operation principle of the proposed FSS is described through a circuit model, and a synthesis procedure is presented for designing a desired filtering response. A prototype of the FSS is synthesized to operate at a center frequency of 0.42 THz with 45% fractional bandwidth. The designed FSS is fabricated by using microfabrication process. The performance is evaluated by using terahertz time-domain spectroscopy. Measurement results show a low sensitivity of the FSS response to oblique angles of incidence for both of the TE and TM polarizations.","Frequency selective surfaces,
Integrated circuit modeling,
Wires,
Dielectrics,
Filtering theory,
Equivalent circuits,
Impedance"
"Enhancing Multiclass Classification in FARC-HD Fuzzy Classifier: On the Synergy Between
n
-Dimensional Overlap Functions and Decomposition Strategies","There are many real-world classification problems involving multiple classes, e.g., in bioinformatics, computer vision, or medicine. These problems are generally more difficult than their binary counterparts. In this scenario, decomposition strategies usually improve the performance of classifiers. Hence, in this paper, we aim to improve the behavior of fuzzy association rule-based classification model for high-dimensional problems (FARC-HD) fuzzy classifier in multiclass classification problems using decomposition strategies, and more specifically One-versus-One (OVO) and One-versus-All (OVA) strategies. However, when these strategies are applied on FARC-HD, a problem emerges due to the low-confidence values provided by the fuzzy reasoning method. This undesirable condition comes from the application of the product t-norm when computing the matching and association degrees, obtaining low values, which are also dependent on the number of antecedents of the fuzzy rules. As a result, robust aggregation strategies in OVO, such as the weighted voting obtain poor results with this fuzzy classifier. In order to solve these problems, we propose to adapt the inference system of FARC-HD replacing the product t-norm with overlap functions. To do so, we define n-dimensional overlap functions. The usage of these new functions allows one to obtain more adequate outputs from the base classifiers for the subsequent aggregation in OVO and OVA schemes. Furthermore, we propose a new aggregation strategy for OVO to deal with the problem of the weighted voting derived from the inappropriate confidences provided by FARC-HD for this aggregation method. The quality of our new approach is analyzed using 20 datasets and the conclusions are supported by a proper statistical analysis. In order to check the usefulness of our proposal, we carry out a comparison against some of the state-of-the-art fuzzy classifiers. Experimental results show the competitiveness of our method.","Pragmatics,
Fuzzy reasoning,
Proposals,
Computational modeling,
Vectors,
Training,
Electronic mail"
Traditional saliency reloaded: A good old model in new shape,"In this paper, we show that the seminal, biologically-inspired saliency model by Itti et al. [21] is still competitive with current state-of-the-art methods for salient object segmentation if some important adaptions are made. We show which changes are necessary to achieve high performance, with special emphasis on the scale-space: we introduce a twin pyramid for computing Difference-of-Gaussians, which enables a flexible center-surround ratio. The resulting system, called VOCUS2, is elegant and coherent in structure, fast, and computes saliency at the pixel level. It is not only suitable for images with few objects, but also for complex scenes as captured by mobile devices. Furthermore, we integrate the saliency system into an object proposal generation framework to obtain segment-based saliency maps and boost the results for salient object segmentation. We show that our system achieves state-of-the-art performance on a large collection of benchmark data.","Computed tomography,
Smoothing methods"
QoE-driven spectrum assignment for 5G wireless networks using SDR,"The emerging 5G wireless networks are envisioned to provide dramatically increased network capacity by using significantly expanded frequency band. With already crowded radio spectrum, utilization efficiency of frequency resources needs to be substantially improved in 5G to accommodate more users. On the other hand, the extremely wide and dynamic spectrum resources required by 5G create a significant opportunity to develop advanced resource management techniques. In this article, we propose a novel architecture to support 5G spectrum management, which uses various requirements for QoE as the design objective. With the proposed architecture, an intelligent and dynamic QoE-driven spectrum assignment scheme for 5G is introduced. The proposed scheme accomplishes dynamic spectrum assignment for each macrocell by utilizing global information that reflects the dynamic QoE requirement. In addition, we effectively allocate the spectrum bands for various devices relying on the reconfigurable RF front-end of SDR-based devices. The presented architecture is expected to support dynamic and efficient spectrum management for 5G wireless networks. Meanwhile, the intelligent and dynamic QoE-driven spectrum assignment scheme is expected to achieve an improved spectrum utilization rate, which could directly accelerate the development of 5G wireless networks.","Computer architecture,
5G mobile communication,
Macrocell networks,
Microprocessors,
Wireless networks,
Radio spectrum management,
Software defined radio,
Quality of experience"
Multi-manifold deep metric learning for image set classification,"In this paper, we propose a multi-manifold deep metric learning (MMDML) method for image set classification, which aims to recognize an object of interest from a set of image instances captured from varying viewpoints or under varying illuminations. Motivated by the fact that manifold can be effectively used to model the nonlinearity of samples in each image set and deep learning has demonstrated superb capability to model the nonlinearity of samples, we propose a MMDML method to learn multiple sets of nonlinear transformations, one set for each object class, to nonlinearly map multiple sets of image instances into a shared feature subspace, under which the manifold margin of different class is maximized, so that both discriminative and class-specific information can be exploited, simultaneously. Our method achieves the state-of-the-art performance on five widely used datasets.",
Retrieving Similar Styles to Parse Clothing,"Clothing recognition is a societally and commercially important yet extremely challenging problem due to large variations in clothing appearance, layering, style, and body shape and pose. In this paper, we tackle the clothing parsing problem using a retrieval-based approach. For a query image, we find similar styles from a large database of tagged fashion images and use these examples to recognize clothing items in the query. Our approach combines parsing from: pre-trained global clothing models, local clothing models learned on the fly from retrieved examples, and transferred parse-masks (Paper Doll item transfer) from retrieved examples. We evaluate our approach extensively and show significant improvements over previous state-of-the-art for both localization (clothing parsing given weak supervision in the form of tags) and detection (general clothing parsing). Our experimental results also indicate that the general pose estimation problem can benefit from clothing parsing.","Estimation,
Training,
Semantics,
Image color analysis,
Predictive models,
Footwear"
Frequency Regulation and Oscillation Damping Contributions of Variable-Speed Wind Generators in the U.S. Eastern Interconnection (EI),"The U.S. Eastern Interconnection (EI) is one of the largest electric power grids in the world and is expected to have difficulties in dealing with frequency regulation and oscillation damping issues caused by the increasing wind power. On the other side, variable-speed wind generators can actively engage in frequency regulation or oscillation damping with supplementary control loops. This paper creates a 5% wind power penetration simulation scenario based on the 16 000-bus EI system dynamic model and developed the user-defined wind electrical control model in PSSE that incorporates additional frequency regulation and oscillation damping control loops. The potential contributions of variable-speed wind generations to the EI system frequency regulation and oscillation damping are evaluated and simulation results demonstrate that current and future penetrations of wind power are promising in the EI system frequency regulation and oscillation damping.","Generators,
Wind power generation,
Frequency control,
Oscillators,
Damping,
Power system stability,
Wind turbines"
Segment Based Decision Tree Induction With Continuous Valued Attributes,"A key issue in decision tree (DT) induction with continuous valued attributes is to design an effective strategy for splitting nodes. The traditional approach to solving this problem is adopting the candidate cut point (CCP) with the highest discriminative ability, which is evaluated by some frequency based heuristic measures. However, such methods ignore the class permutation of examples in the node, and they cannot distinguish the CCPs with the same or similar frequency information, thus may fail to induce a better and smaller tree. In this paper, a new concept, i.e., segment of examples, is proposed to differentiate the CCPs with same frequency information. Then, a new hybrid scheme that combines the two heuristic measures, i.e., frequency and segment, is developed for splitting DT nodes. The relationship between frequency and the expected number of segments, which is regarded as a random variable, is also given. Experimental comparisons demonstrate that the proposed scheme is not only effective to improve the generalization capability, but also valid to reduce the size of the tree.",
Device-to-device-based heterogeneous radio access network architecture for mobile cloud computing,"The emerging heterogeneous mobile network architecture is designed for an increasing amount of traffic, quality requirements, and new mobile cloud computing demands. This article proposes a hierarchical cloud computing architecture to enhance performance by adding a mobile dynamic cloud formed by powerful mobile devices to a traditional general static cloud. A mobile dynamic cloud is based on heterogeneous wireless architecture where device-to-device communication is used for data transmission between user devices. The main advantage of the proposed architecture is an increase in overall capacity of a mobile network through improved channel utilization and traffic offloading from Long Term Evolution-Advanced to device-to-device communication links. Simulations show that the proposed architecture increases the capacity of a mobile network by up to 10 percent depending on the conditions and amount of offloaded data. The offloading probability is also evaluated by taking into consideration the number of devices in the cloudlet and the content matching values. We have gained insight into how content similarity affects offloading probability much more than the number of devices in a cloudlet.","Mobile communication,
Cloud computing,
Mobile handsets,
Computer architecture,
Mobile computing,
Computational modeling,
IEEE 802.11 Standards,
Radio access networks"
Adaptive Neural Control for Dual-Arm Coordination of Humanoid Robot With Unknown Nonlinearities in Output Mechanism,"To achieve an excellent dual-arm coordination of the humanoid robot, it is essential to deal with the nonlinearities existing in the system dynamics. The literatures so far on the humanoid robot control have a common assumption that the problem of output hysteresis could be ignored. However, in the practical applications, the output hysteresis is widely spread; and its existing limits the motion/force performances of the robotic system. In this paper, an adaptive neural control scheme, which takes the unknown output hysteresis and computational efficiency into account, is presented and investigated. In the controller design, the prior knowledge of system dynamics is assumed to be unknown. The motion error is guaranteed to converge to a small neighborhood of the origin by Lyapunov's stability theory. Simultaneously, the internal force is kept bounded and its error can be made arbitrarily small.","Robot kinematics,
Hysteresis,
Humanoid robots,
Force,
Dynamics,
Vectors"
Wideband Stub-Loaded Slotline Antennas Under Multi-Mode Resonance Operation,"A novel center-fed wideband slotline antenna is proposed using the multi-mode resonance concept. By symmetrically introducing one or two pairs of slot stubs along the slotline resonator near the nulls of electric field distribution of the second odd-order mode, two modes are excited in a single slotline radiator. With the help of these stubs, the second odd-order mode can be gradually merged with its first counterpart, resulting in a wideband radiation characteristic with two resonances. Prototype antennas are then designed and fabricated to experimentally validate the principle and design approach. It is shown that the operation fractional bandwidth of the proposed slotline antenna could be effectively increased to 31.5% while keeping an inherent narrow slot structure.","Slot antennas,
Slot lines,
Broadband antennas,
Wideband,
Antenna measurements,
Dipole antennas,
Resonant frequency"
Initial Alignment by Attitude Estimation for Strapdown Inertial Navigation Systems,"This paper derives a novel initial alignment method for the strapdown inertial navigation system (SINS), which transforms the attitude alignment into an attitude estimation problem. The process model of the proposed initial alignment method by attitude estimation is established by decomposition of the attitude matrix. The measurement model is constructed based on a generalized velocity integration formula that can integrate the inertial measurements over certain fixed time intervals. The contributions of the work presented here are twofold. First, the attitude estimation-based structure enables the proposed method to estimate the gyroscope biases other than the attitude quaternion, which is celebrated for the low-cost SINS. The second is the application of the proposed generalized velocity integration formula to attenuate the accumulated errors in vector observations caused by the traditional velocity integration formula. Experimental road tests are performed with a low-cost SINS, which validate the efficacy of the proposed method.","Vectors,
Quaternions,
Matrix decomposition,
Estimation,
Silicon compounds,
Gyroscopes,
Mathematical model"
Classification of common partial discharge types in oil-paper insulation system using acoustic signals,"This paper addresses classifying different common partial discharge (PD) types under different acoustic emission (AE) measurement conditions. Four types of PDs are considered for the multi-class classification problem, namely; PD from a sharp point to ground plane, surface discharge, PD from a void in the insulation, and PD from semi parallel planes. The collected AE signals are processed using pattern classification techniques to identify their corresponding PD types. The measurement conditions include the influences of various PD locations, oil temperatures, and having a barrier in the line-of-sight between the PD source and the AE sensor. A recognition rate of 94% is achieved when classifying the different PD types measured at the same conditions. In addition, it has been found that the different PD source locations, oil temperatures, and barrier insertion have an impact on the recognition rate. However, by including AE samples at these different conditions in the training process, a recognition rate around 90% for all cases is achieved.","Partial discharges,
Feature extraction,
Power transformer insulation,
Oil insulation,
Discrete Fourier transforms"
Corneal-Imaging Calibration for Optical See-Through Head-Mounted Displays,"In recent years optical see-through head-mounted displays (OST-HMDs) have moved from conceptual research to a market of mass-produced devices with new models and applications being released continuously. It remains challenging to deploy augmented reality (AR) applications that require consistent spatial visualization. Examples include maintenance, training and medical tasks, as the view of the attached scene camera is shifted from the user's view. A calibration step can compute the relationship between the HMD-screen and the user's eye to align the digital content. However, this alignment is only viable as long as the display does not move, an assumption that rarely holds for an extended period of time. As a consequence, continuous recalibration is necessary. Manual calibration methods are tedious and rarely support practical applications. Existing automated methods do not account for user-specific parameters and are error prone. We propose the combination of a pre-calibrated display with a per-frame estimation of the user's cornea position to estimate the individual eye center and continuously recalibrate the system. With this, we also obtain the gaze direction, which allows for instantaneous uncalibrated eye gaze tracking, without the need for additional hardware and complex illumination. Contrary to existing methods, we use simple image processing and do not rely on iris tracking, which is typically noisy and can be ambiguous. Evaluation with simulated and real data shows that our approach achieves a more accurate and stable eye pose estimation, which results in an improved and practical calibration with a largely improved distribution of projection error.","Calibration,
Cornea,
Cameras,
Estimation,
Iris,
Three-dimensional displays"
Multi-Frequency Co-Prime Arrays for High-Resolution Direction-of-Arrival Estimation,"This paper presents multi-frequency operation for increasing the number of resolvable sources in high-resolution direction-of-arrival (DOA) estimation using co-prime arrays. A single-frequency operation requires complicated and involved matrix completion to utilize the full extent of the degrees of freedom (DOFs) offered by the co-prime configuration. This processing complexity is attributed to the missing elements in the corresponding difference coarray. Alternate single-frequency schemes avoid such complexity by utilizing only the filled part of the coarray and, thus, cannot exploit all of the DOFs for DOA estimation. We utilize multiple frequencies to fill the missing coarray elements, thereby enabling the co-prime array to effectively utilize all of the offered DOFs. The sources are assumed to have a sufficient bandwidth to cover all the required operational frequencies. We consider both cases of sources with proportional and nonproportional power spectra at the employed frequencies. The former permits the use of multi-frequency measurements at the co-prime array to construct a virtual covariance matrix corresponding to a filled uniformly spaced coarray at a single frequency. This virtual covariance matrix can be employed for DOA estimation. The nonproportionality of the source spectra casts a more challenging situation, as it is not amenable to producing the same effect as that of an equivalent single-frequency filled coarray. Performance evaluation of the multi-frequency approach based on computer simulations is provided under both cases of proportional and nonproportional source spectra.","Direction-of-arrival estimation,
Estimation,
Covariance matrices,
Sensor arrays,
Array signal processing"
Cyber-physical systems for water sustainability: challenges and opportunities,"Water plays a vital role in the proper functioning of the Earth's ecosystems, and practically all human activities, such as agriculture, manufacturing, transportation, and energy production. The proliferation of industrial and agricultural activities in modern society, however, poses threats to water resources in the form of chemical, biological, and thermal pollution. On the other hand, tremendous advancements in science and technology offer valuable tools to address water sustainability challenges. Key technologies, including sensing technology, wireless communications and networking, hydrodynamic modeling, data analysis, and control, enable intelligently wireless networked water cyber-physical systems (CPS) with embedded sensors, processors, and actuators that can sense and interact with the water environment. This article provides an overview of water CPS for sustainability from four critical aspects: sensing and instrumentation; communications and networking; computing; and control. The article also explores opportunities and design challenges of relevant techniques.","Water pollution,
Green design,
Water resources,
Monitoring,
Computational modeling,
Wireless sensor networks,
Wireless communication,
Ecosystems,
Sustainable development,
Telecommunication services"
Coupled Discriminative Feature Learning for Heterogeneous Face Recognition,"This paper presents a coupled discriminative feature learning (CDFL) method for heterogeneous face recognition (HFR). Different from most existing HFR approaches which use hand-crafted feature descriptors for face representation, our CDFL directly learns discriminative features from raw pixels for face representation. In particular, a couple of image filters is learned in CDFL to simultaneously exploit discriminative information and to reduce the appearance difference of face images captured across different modalities. With the help of the learned filters, CDFL can maximize the interclass variations and minimize the intraclass variations of the learned feature vectors, and meanwhile maximize the correlation of face images of the same person from different modalities by solving a generalized eigenvalue problem. Experimental results on three different heterogeneous face recognition applications show the effectiveness of our proposed approach.","Face,
Feature extraction,
Face recognition,
Vectors,
Nickel,
Correlation,
Eigenvalues and eigenfunctions"
Lightweight Management of Resource-Constrained Sensor Devices in Internet of Things,"It is predicted that billions of intelligent devices and networks, such as wireless sensor networks (WSNs), will not be isolated but connected and integrated with computer networks in future Internet of Things (IoT). In order to well maintain those sensor devices, it is often necessary to evolve devices to function correctly by allowing device management (DM) entities to remotely monitor and control devices without consuming significant resources. In this paper, we propose a lightweight RESTful Web service (WS) approach to enable device management of wireless sensor devices. Specifically, motivated by the recent development of IPv6-based open standards for accessing wireless resource-constrained networks, we consider to implement IPv6 over low-power wireless personal area network (6LoWPAN)/routing protocol for low power and lossy network (RPL)/constrained application protocol (CoAP) protocols on sensor devices and propose a CoAP-based DM solution to allow easy access and management of IPv6 sensor devices. By developing a prototype cloud system, we successfully demonstrate the proposed solution in efficient and effective management of wireless sensor devices.","Protocols,
Wireless sensor networks,
Web services,
Servers,
IEEE 802.15 Standards"
Robust Motion Control of a Linear Motor Positioner Using Fast Nonsingular Terminal Sliding Mode,"A robust motion control system is essential for the linear motor (LM)-based direct drive to provide high speed and high-precision performance. This paper studies a systematic control design method using fast nonsingular terminal sliding mode (FNTSM) for an LM positioner. Compared with the conventional nonsingular terminal sliding mode control, the FNTSM control can guarantee a faster convergence rate of the tracking error in the presence of system uncertainties including payload variations, friction, external disturbances, and measurement noises. Moreover, its control input is inherently continuous, which accordingly avoids the undesired control chattering problem. We further discuss the selection criteria of the controller parameters for the LM to deal with the system dynamic constraints and performance tradeoffs. Finally, we present a robust model-free velocity estimator based on the only available position measurements with quantization noises such that the estimated velocity can be used for feedback signal to the FNTSM controller. Experimental results demonstrate the practical implementation of the FNTSM controller and verify its robustness of more accurate tracking and faster disturbance rejection compared with a conventional NTSM controller and a linear H∞ controller.","Uncertainty,
Robustness,
Noise,
Position measurement,
Convergence,
Noise measurement,
Motion control"
Toward Offering More Useful Data Reliably to Mobile Cloud From Wireless Sensor Network,"The integration of ubiquitous wireless sensor network (WSN) and powerful mobile cloud computing (MCC) is a research topic that is attracting growing interest in both academia and industry. In this new paradigm, WSN provides data to the cloud and mobile users request data from the cloud. To support applications involving WSN-MCC integration, which need to reliably offer data that are more useful to the mobile users from WSN to cloud, this paper first identifies the critical issues that affect the usefulness of sensory data and the reliability of WSN, then proposes a novel WSN-MCC integration scheme named TPSS, which consists of two main parts: 1) time and priority-based selective data transmission (TPSDT) for WSN gateway to selectively transmit sensory data that are more useful to the cloud, considering the time and priority features of the data requested by the mobile user and 2) priority-based sleep scheduling (PSS) algorithm for WSN to save energy consumption so that it can gather and transmit data in a more reliable way. Analytical and experimental results demonstrate the effectiveness of TPSS in improving usefulness of sensory data and reliability of WSN for WSN-MCC integration.","Wireless sensor networks,
Mobile communication,
Reliability,
Logic gates,
Data communication,
Clouds,
Monitoring"
A Unified Approach to Hybrid Coding,"Hybrid analog-digital coding has been used for several communication scenarios, such as joint source-channel coding of Gaussian sources over Gaussian channels and relay communication over Gaussian networks. In this paper, a generalized hybrid coding technique is proposed for communication over discrete memoryless and Gaussian systems, and its utility is demonstrated via three examples-lossy joint source-channel coding over multiple access channels, channel coding over two-way relay channels, and channel coding over diamond networks. The corresponding coding schemes recover and extend several existing results in the literature.","Channel coding,
Joints,
Decoding,
Source coding,
Relay networks (telecommunications)"
A Physics-Based Analytical Model for Perovskite Solar Cells,"Perovskites are promising next-generation absorber materials for low-cost and high-efficiency solar cells. Although perovskite cells are configured similar to the classical solar cells, their operation is unique and requires development of a new physical model for characterization, optimization of the cells, and prediction of the panel performance. In this paper, we develop such a physics-based analytical model to describe the operation of different types of perovskite solar cells, explicitly accounting for nonuniform generation, carrier selective transport layers, and voltage-dependent carrier collection. The model would allow experimentalists to characterize key parameters of existing cells, understand performance bottlenecks, and predict performance of perovskite-based solar panel - the obvious next step to the evolution of perovskite solar cell technology.","Photovoltaic cells,
Analytical models,
Photovoltaic systems,
Charge carrier processes,
PIN photodiodes,
Photoconductivity"
A Parallel Matrix-Based Method for Computing Approximations in Incomplete Information Systems,"As the volume of data grows at an unprecedented rate, large-scale data mining and knowledge discovery present a tremendous challenge. Rough set theory, which has been used successfully in solving problems in pattern recognition, machine learning, and data mining, centers around the idea that a set of distinct objects may be approximated via a lower and upper bound. In order to obtain the benefits that rough sets can provide for data mining and related tasks, efficient computation of these approximations is vital. The recently introduced cloud computing model, MapReduce, has gained a lot of attention from the scientific community for its applicability to large-scale data analysis. In previous research, we proposed a MapReduce-based method for computing approximations in parallel, which can efficiently process complete data but fails in the case of missing (incomplete) data. To address this shortcoming, three different parallel matrix-based methods are introduced to process large-scale, incomplete data. All of them are built on MapReduce and implemented on Twister that is a lightweight MapReduce runtime system. The proposed parallel methods are then experimentally shown to be efficient for processing large-scale data.","Approximation methods,
Vectors,
Information systems,
Data mining,
Rough sets,
Approximation algorithms,
Computational modeling"
Inverse Scattering Via Virtual Experiments and Contrast Source Regularization,"In microwave imaging, the linearity of the relationship between the incident and the scattered field offers the possibility of a posteriori recombining the performed scattering experiments and then to cast the underlying inverse problem with respect to the resulting, virtual, ones. The interest of such a circumstance is that properly designed virtual experiments can enforce particular and convenient conditions. In this paper, we present an application of this paradigm to the popular contrast source inversion (CSI) method. In particular, we first design a set of virtual experiments capable to induce contrast sources exhibiting circular symmetries (with respect to some pivot points). Then, we devise an original and effective regularized CSI scheme, in which a penalty term is added to the usual cost functional, in order to account for the symmetry of the auxiliary unknowns. Notably, the approach does not require any apriori assumption on the unknown contrast, as it relies on the particular nature of the virtual contrast sources. Results with single frequency Fresnel experimental data are given to assess the capabilities of the proposed approach.","Imaging,
Scattering,
Equations,
Inverse problems,
Minimization,
Atmospheric measurements,
Particle measurements"
Fast Subpixel Mapping Algorithms for Subpixel Resolution Change Detection,"Due to rapid changes on the Earth's surface, it is important to perform land cover change detection (CD) at a fine spatial and fine temporal resolution. However, remote sensing images with both fine spatial and temporal resolutions are commonly not available or, where available, may be expensive to obtain. This paper attempts to achieve fine spatial and temporal resolution land cover CD with a new computer technology based on subpixel mapping (SPM): The fine spatial resolution land cover maps (FRMs) are first predicted through SPM of the coarse spatial but fine temporal resolution images, and then, subpixel resolution CD is performed by comparison of class labels in the SPM results. For the first time, five fast SPM algorithms, including bilinear interpolation, bicubic interpolation, subpixel/pixel spatial attraction model, Kriging, and radial basis function interpolation methods, are proposed for subpixel resolution CD. The auxiliary information from the known FRM on one date is incorporated in SPM of coarse images on other dates to increase the CD accuracy. Based on the five fast SPM algorithms and the availability of the FRM, subpixels for each class are predicted by comparison of the estimated soft class values at the target fine spatial resolution and borrowing information from the FRM. Experiments demonstrate the feasibility of the five SPM algorithms using FRM in subpixel resolution CD. They are fast methods to achieve subpixel resolution CD.","Spatial resolution,
Remote sensing,
Earth,
Satellites,
MODIS,
Resource management"
Modeling and Analysis of Random Access Channels With Bursty Arrivals in OFDMA Wireless Networks,"Random access channels (RACHs) in cellular networks are normally designed for Poisson-distributed arrivals with a constant rate. Unexpected bursty arrivals may result in severe collisions in RACHs and thus degrade users' service qualities. This paper presents an analytical model for investigating the transient behavior of the RACHs with bursty arrivals generated in a specific time interval for orthogonal frequency-division multiple access (OFDMA) wireless networks. The proposed model has considered the implementation details of the OFDMA random access procedure (such as periodic access characteristic, uniform random backoff policy, and power-ramping effect) and the effect of new arrivals. The performance metrics of collision probability, success probability, and average access delay and the cumulative distribution function of the number of preamble transmissions and access delay for the successfully accessed mobile station are then derived based on the analytical model. The accuracy of the proposed analytical model was verified through computer simulations, and the results show the effectiveness of the proposed model.","Analytical models,
Delays,
Stochastic processes,
Random variables,
Mathematical model,
Transient analysis,
Probability distribution"
Power punch: Towards non-blocking power-gating of NoC routers,"As chip designs penetrate further into the dark silicon era, innovative techniques are much needed to power off idle or under-utilized system components while having minimal impact on performance. On-chip network routers are potentially good targets for power-gating, but packets in the network can be significantly delayed as their paths may be blocked by powered-off routers. In this paper, we propose Power Punch, a novel performance-aware, power reduction scheme that aims to achieve non-blocking power-gating of on-chip network routers. Two mechanisms are proposed that not only allow power control signals to utilize existing slack at source nodes to wake up powered-off routers along the first few hops before packets are injected, but also allow these signals to utilize hop count slack by staying ahead of packets to ""punch through "" any blocked routers along the imminent path of packets, preventing packets from having to suffer router wakeup latency or packet detour latency. Full system evaluation on PARSEC benchmarks shows Power Punch saves more than 83% of router static energy while having an execution time penalty of less than 0.4%, effectively achieving near non-blocking power-gating of on-chip network routers.","Routing,
Wires,
System-on-chip,
Power control,
Switches,
Ports (Computers),
Pipelines"
A Survey on Barrier Coverage Problem in Directional Sensor Networks,"Barrier coverage guarantees to detect any intruder attempting to cross the barrier of sensor networks. In the majority of studies on barrier coverage using wireless sensor networks, sensors are assumed to have an isotropic sensing model. However, in certain applications like monitoring a region using video cameras, the sensors have directional sensing model. The nature of directional sensor networks demands novel algorithms and solutions. In directional sensor networks, this paper starts from the concept and characteristics of a directional sensing model, and then summarizes the sensing properties and behaviors of directional sensors. In particular, we classify the existing research results into different categories, such as strong barrier and weak barrier, 1-barrier and k-barrier, worst and best-case coverage and exposure path coverage, any-view coverage and full-view coverage, and overview each category in terms of problem definition, assumption, usage, solution, and performance. Finally, the open research problems to be solved and future work are also discussed.","Sensor phenomena and characterization,
Cameras,
Wireless sensor networks,
Educational institutions,
Monitoring,
Robot sensing systems"
A Two-Stage Geometric Method for Pruning Unreliable Links in Protein-Protein Networks,"Protein-protein interactions (PPIs) play essential roles for determining the outcomes of most of the cellular functions of the cell. Although the experimentally detected high-throughput PPI data promise new opportunities for the study of many biological mechanisms including cellular metabolism and protein functions, experimentally detected PPIs have high levels of false positive rate. Therefore, it is of high practical value to develop novel computational tools for pruning low-confidence PPIs. In this paper, we propose a new geometric approach called Leave-One-Out Logistic Metric Embedding (LOO-LME) for assessing the reliability of interactions. Unlike previous approaches which mainly seek to preserve the noisy topological information of the PPI networks in the embedding space, LOO-LME first transforms the learning task into an equivalent discriminant form, then directly deals with the uncertainty in PPI networks using a leave-one-out-style approach. The experimental results show that LOO-LME substantially outperforms previous methods on PPI assessment problems. LOO-LME could thus facilitate further graph-based studies of PPIs and may help infer their hidden underlying biological knowledge.","Optimized production technology,
Proteins,
Logistics,
Reliability,
Extraterrestrial measurements"
On Fuzzy Sampled-Data Control of Chaotic Systems Via a Time-Dependent Lyapunov Functional Approach,"In this paper, a novel approach to fuzzy sampled-data control of chaotic systems is presented by using a time-dependent Lyapunov functional. The advantage of the new method is that the Lyapunov functional is continuous at sampling times but not necessarily positive definite inside the sampling intervals. Compared with the existing works, the constructed Lyapunov functional makes full use of the information on the piecewise constant input and the actual sampling pattern. In terms of a new parameterized linear matrix inequality (LMI) technique, a less conservative stabilization condition is derived to guarantee the exponential stability for the closed-loop fuzzy sampled-data system. By solving a set of LMIs, the fuzzy sampled-data controller can be easily obtained. Finally, the chaotic Lorenz system and Rössler's system are employed to illustrate the feasibility and effectiveness of the proposed method.","Control systems,
Chaotic communication,
Linear matrix inequalities,
Delays,
Fuzzy systems,
Symmetric matrices"
Metamaterial-Based Low-Profile Broadband Aperture-Coupled Grid-Slotted Patch Antenna,"A metamaterial-based broadband low-profile grid-slotted patch antenna is presented. By slotting the radiating patch, a periodic array of series capacitor loaded metamaterial patch cells is formed, and excited through the coupling aperture in a ground plane right underneath and parallel to the slot at the center of the patch. By exciting two adjacent resonant modes simultaneously, broadband impedance matching and consistent radiation are achieved. The dispersion relation of the capacitor-loaded patch cell is applied in the mode analysis. The proposed grid-slotted patch antenna with a low profile of 0.06 λ0 (λ0 is the center operating wavelength in free space) achieves a measured bandwidth of 28% for the |S11| less than -10 dB and maximum gain of 9.8 dBi.",
Feature Space Independent Semi-Supervised Domain Adaptation via Kernel Matching,"Domain adaptation methods aim to learn a good prediction model in a label-scarce target domain by leveraging labeled patterns from a related source domain where there is a large amount of labeled data. However, in many practical domain adaptation learning scenarios, the feature distribution in the source domain is different from that in the target domain. In the extreme, the two distributions could differ completely when the feature representation of the source domain is totally different from that of the target domain. To address the problems of substantial feature distribution divergence across domains and heterogeneous feature representations of different domains, we propose a novel feature space independent semi-supervised kernel matching method for domain adaptation in this work. Our approach learns a prediction function on the labeled source data while mapping the target data points to similar source data points by matching the target kernel matrix to a submatrix of the source kernel matrix based on a Hilbert Schmidt Independence Criterion. We formulate this simultaneous learning and mapping process as a non-convex integer optimization problem and present a local minimization procedure for its relaxed continuous form. We evaluate the proposed kernel matching method using both cross domain sentiment classification tasks of Amazon product reviews and cross language text classification tasks of Reuters multilingual newswire stories. Our empirical results demonstrate that the proposed kernel matching method consistently and significantly outperforms comparison methods on both cross domain classification problems with homogeneous feature spaces and cross domain classification problems with heterogeneous feature spaces.","Kernel,
Optimization,
Minimization,
Laplace equations,
Training,
Manifolds,
Adaptation models"
Multi-View Learning With Incomplete Views,"One underlying assumption of the conventional multi-view learning algorithms is that all examples can be successfully observed on all the views. However, due to various failures or faults in collecting and pre-processing the data on different views, we are more likely to be faced with an incomplete-view setting, where an example could be missing its representation on one view (i.e., missing view) or could be only partially observed on that view (i.e., missing variables). Low-rank assumption used to be effective for recovering the random missing variables of features, but it is disabled by concentrated missing variables and has no effect on missing views. This paper suggests that the key to handling the incomplete-view problem is to exploit the connections between multiple views, enabling the incomplete views to be restored with the help of the complete views. We propose an effective algorithm to accomplish multi-view learning with incomplete views by assuming that different views are generated from a shared subspace. To handle the large-scale problem and obtain fast convergence, we investigate a successive over-relaxation method to solve the objective function. Convergence of the optimization technique is theoretically analyzed. The experimental results on toy data and real-world data sets suggest that studying the incomplete-view problem in multi-view learning is significant and that the proposed algorithm can effectively handle the incomplete views in different applications.","Tensile stress,
Convergence,
Silicon,
Cameras,
Linear programming,
Optimization,
Algorithm design and analysis"
Hybrid Random/Deterministic Parallel Algorithms for Convex and Nonconvex Big Data Optimization,"We propose a decomposition framework for the parallel optimization of the sum of a differentiable (possibly nonconvex) function and a nonsmooth (possibly nonseparable), convex one. The latter term is usually employed to enforce structure in the solution, typically sparsity. The main contribution of this work is a novel parallel, hybrid random/deterministic decomposition scheme wherein, at each iteration, a subset of (block) variables is updated at the same time by minimizing a convex surrogate of the original nonconvex function. To tackle huge-scale problems, the (block) variables to be updated are chosen according to a mixed random and deterministic procedure, which captures the advantages of both pure deterministic and random update-based schemes. Almost sure convergence of the proposed scheme is established. Numerical results show that on huge-scale problems the proposed hybrid random/deterministic algorithm compares favorably to random and deterministic schemes on both convex and nonconvex problems.","Convergence,
Optimization,
Signal processing algorithms,
Big data,
Parallel algorithms,
Indexes,
Image processing"
Task Scheduling with Dynamic Voltage and Frequency Scaling for Energy Minimization in the Mobile Cloud Computing Environment,"Mobile cloud computing (MCC) offers significant opportunities in performance enhancement and energy saving for mobile, battery-powered devices. Applications running on mobile devices may be represented by task graphs. This work investigates the problem of scheduling tasks (which belong to the same or possibly different applications) in the MCC environment. More precisely, the scheduling problem involves the following steps: (i) determining the tasks to be offloaded onto the cloud, (ii) mapping the remaining tasks onto (potentially heterogeneous) local cores in the mobile device, (iii) determining the frequencies for executing local tasks, and (iv) scheduling tasks on the cores (for in-house tasks) and the wireless communication channels (for offloaded tasks) such that the task-precedence requirements and the application completion time constraint are satisfied while the total energy dissipation in the mobile device is minimized. A novel algorithm is presented, which starts from a minimal-delay scheduling solution and subsequently performs energy reduction by migrating tasks among the local cores and the cloud and by applying the dynamic voltage and frequency scaling technique. A linear-time rescheduling algorithm is proposed for the task migration. Simulation results demonstrate significant energy reduction with the application completion time constraint satisfied.","Mobile handsets,
Energy consumption,
Wireless communication,
Cloud computing,
Time factors,
Schedules,
Processor scheduling"
Content-Based Visual Landmark Search via Multimodal Hypergraph Learning,"While content-based landmark image search has recently received a lot of attention and became a very active domain, it still remains a challenging problem. Among the various reasons, high diverse visual content is the most significant one. It is common that for the same landmark, images with a wide range of visual appearances can be found from different sources and different landmarks may share very similar sets of images. As a consequence, it is very hard to accurately estimate the similarities between the landmarks purely based on single type of visual feature. Moreover, the relationships between landmark images can be very complex and how to develop an effective modeling scheme to characterize the associations still remains an open question. Motivated by these concerns, we propose multimodal hypergraph (MMHG) to characterize the complex associations between landmark images. In MMHG, images are modeled as independent vertices and hyperedges contain several vertices corresponding to particular views. Multiple hypergraphs are firstly constructed independently based on different visual modalities to describe the hidden high-order relations from different aspects. Then, they are integrated together to involve discriminative information from heterogeneous sources. We also propose a novel content-based visual landmark search system based on MMHG to facilitate effective search. Distinguished from the existing approaches, we design a unified computational module to support query-specific combination weight learning. An extensive experiment study on a large-scale test collection demonstrates the effectiveness of our scheme over state-of-the-art approaches.","Visualization,
Feature extraction,
Databases,
Image edge detection,
Image color analysis,
Vectors,
Correlation"
Unreeling Xunlei Kankan: Understanding Hybrid CDN-P2P Video-on-Demand Streaming,"The hybrid architecture of content distribution network (CDN) and peer to peer (P2P) is promising in providing online streaming media services. In this paper, we conducted a comprehensive measurement study on Kankan, one of the leading VoD streaming service providers in China that is based on a hybrid CDN-P2P architecture. Our measurements are multi-fold, as follows. 1) Kankan adopts a loosely-coupled hybrid architecture , in which the user requests are handled by its CDN and P2P network independently. 2) Kankan deploys a small-scale CDN densely in three geographic clusters in China. It adopts specific redirection servers to dispatch the nationwide requests. 3) Kankan adopts a dual-server mechanism to enhance start-up video streaming. It also provides the CDN acceleration in case of inefficient P2P streaming performance. 4) According to our studies on the peer cache lists, the video contents stored in Kankan peers update quite slowly. The average lifetime of cached videos is longer than one week. Our results show that, by utilizing the slow-varying contents cached in peers and deploying various CDN enhancement mechanisms , Kankan provides a large-scale VoD streaming service with a small-scale fixed infrastructure. Insights obtained in this study will be valuable for the development and deployment of future hybrid CDN-P2P VoD streaming systems.","Streaming media,
Servers,
Peer-to-peer computing,
Protocols,
Internet,
IP networks,
YouTube"
Real-Time Big Data Analytical Architecture for Remote Sensing Application,"The assets of remote senses digital world daily generate massive volume of real-time data (mainly referred to the term “Big Data”), where insight information has a potential significance if collected and aggregated effectively. In today's era, there is a great deal added to real-time remote sensing Big Data than it seems at first, and extracting the useful information in an efficient manner leads a system toward a major computational challenges, such as to analyze, aggregate, and store, where data are remotely collected. Keeping in view the above mentioned factors, there is a need for designing a system architecture that welcomes both real-time, as well as offline data processing. Therefore, in this paper, we propose real-time Big Data analytical architecture for remote sensing satellite application. The proposed architecture comprises three main units, such as 1) remote sensing Big Data acquisition unit (RSDU); 2) data processing unit (DPU); and 3) data analysis decision unit (DADU). First, RSDU acquires data from the satellite and sends this data to the Base Station, where initial processing takes place. Second, DPU plays a vital role in architecture for efficient processing of real-time Big Data by providing filtration, load balancing, and parallel processing. Third, DADU is the upper layer unit of the proposed architecture, which is responsible for compilation, storage of the results, and generation of decision based on the results received from DPU. The proposed architecture has the capability of dividing, load balancing, and parallel processing of only useful data. Thus, it results in efficiently analyzing real-time remote sensing Big Data using earth observatory system. Furthermore, the proposed architecture has the capability of storing incoming raw data to perform offline analysis on largely stored dumps, when required. Finally, a detailed analysis of remotely sensed earth observatory Big Data for land and sea area are provided using Hadoop. In addition, various algorithms are proposed for each level of RSDU, DPU, and DADU to detect land as well as sea area to elaborate the working of an architecture.","Big data,
Remote sensing,
Data processing,
Real-time systems,
Data analysis"
Completely Pinpointing the Missing RFID Tags in a Time-Efficient Way,"Radio Frequency Identification (RFID) technology has been widely used in inventory management in many scenarios, e.g., warehouses, retail stores, hospitals, etc. This paper investigates a challenging problem of complete identification of missing tags in large-scale RFID systems. Although this problem has attracted extensive attention from academy and industry, the existing work can hardly satisfy the stringent real-time requirements. In this paper, a Slot Filter-based Missing Tag Identification (SFMTI) protocol is proposed to reconcile some expected collision slots into singleton slots and filter out the expected empty slots as well as the unreconcilable collision slots, thereby achieving the improved time-efficiency. The theoretical analysis is conducted to minimize the execution time of the proposed SFMTI. We then propose a cost-effective method to extend SFMTI to the multi-reader scenarios. The extensive simulation experiments and performance results demonstrate that the proposed SFMTI protocol outperforms the most promising Iterative ID-free Protocol (IIP) by reducing nearly 45% of the required execution time, and is just within a factor of 1.18 from the lower bound of the minimum execution time.","Protocols,
Vectors,
Educational institutions,
RFID tags,
Real-time systems,
Electronic mail"
A Parallel File System with Application-Aware Data Layout Policies for Massive Remote Sensing Image Processing in Digital Earth,"Remote sensing applications in Digital Earth are overwhelmed with vast quantities of remote sensing (RS) image data. The intolerable I/O burden introduced by the massive amounts of RS data and the irregular RS data access patterns has made the traditional cluster based parallel I/O systems no longer applicable. We propose a RS data object-based parallel file system for remote sensing applications and implement it with the OrangeFS file system. It provides application-aware data layout policies, together with RS data object based data I/O interfaces, for efficient support of various data access patterns of RS applications from the server side. With the prior knowledge of the desired RS data access patterns, HPGFS could offer relevant space-filling curves to organize the sliced 3-D data bricks and distribute them over I/O servers. In this way, data layouts consistent with expected data access patterns could be created to explore data locality and achieve performance improvement. Moreover, the multi-band RS data with complex structured geographical metadata could be accessed and managed as a single data object. Through experiments on remote sensing applications with different access patterns, we have achieved performance improvement of about 30 percent for I/O and 20 percent overall.","Remote sensing,
File systems,
Layout,
Distributed databases,
Servers,
Sensors,
Earth"
Joint transmit antenna selection and user scheduling for Massive MIMO systems,"It is largely accepted that the innovative technology of large-scale multiantenna systems (named Massive multiple input multiple output (MIMO) systems) will very probably be deployed in the fifth generation of mobile cellular networks. In order to render this technology feasible and efficient, many challenges have to be investigated before. In this paper, we consider the problem of antenna selection and user scheduling in Massive MIMO systems. Our objective is to maximize the sum of broadcasting data rates achieved by all the mobile users in one cell served by a massive MIMO transmitter. The optimal solution of this problem can be obtained through a highly complex exhaustive brute force search (BFS) over all possible combinations of antennas and users. This BFS solution cannot be implemented in practice even for small size systems because of its high computational complexity. Therefore, in this paper, we propose an algorithm that efficiently solves the problem of joint antenna selection and user scheduling. The proposed algorithm aims to maximize the achievable sum-rate and to benefit from both the spatial selectivity gain and multi-user diversity gain offered by the antenna selection and user scheduling, respectively. Compared with the optimal solution obtained by the highly complex BFS, the conducted performance evaluation and complexity analysis show that the proposed algorithm is able to achieve near-optimal performance with low computational complexity.","MIMO,
Transmitting antennas,
Computational complexity,
Joints"
Efficient secure similarity computation on encrypted trajectory data,"Outsourcing database to clouds is a scalable and cost-effective way for large scale data storage, management, and query processing. Trajectory data contain rich spatio-temporal relationships and reveal many forms of individual sensitive information (e.g., home address, health condition), which necessitate them to be encrypted before being outsourced for privacy concerns. However, efficient query processing over encrypted trajectory data is a very challenging task. Though some achievements have been reported very recently for simple queries (e.g., SQL queries, kNN queries) on encrypted data, there is rather limited progress on secure evaluation of trajectory queries because they are more complex and need special treatment. In this paper, we focus on secure trajectory similarity computation that is the cornerstone of secure trajectory query processing. More specifically, we propose an efficient solution to securely compute the similarity between two encrypted trajectories, which reveals nothing about the trajectories, but the final result. We theoretically prove that our solution is secure against the semi-honest adversaries model as all the intermediate information in our protocols can be simulated in polynomial time. Finally we empirically study the efficiency of the proposed method, which demonstrates the feasibility of our solution.","Trajectory,
Protocols,
Encryption,
Query processing"
Comparison study of non-orthogonal multiple access schemes for 5G,"With the development of mobile Internet and Internet of things (IoT), the 5th generation (5G) wireless communications will foresee explosive increase in mobile traffic. To address challenges in 5G such as higher spectral efficiency, massive connectivity, and lower latency, some non-orthogonal multiple access (NOMA) schemes have been recently actively investigated, including power-domain NOMA, multiple access with low-density spreading (LDS), sparse code multiple access (SCMA), multiuser shared access (MUSA), pattern division multiple access (PDMA), etc. Different from conventional orthogonal multiple access (OMA) schemes, NOMA can realize overloading by introducing some controllable interferences at the cost of slightly increased receiver complexity, which can achieve significant gains in spectral efficiency and accommodate much more users. In this paper, we will discuss basic principles and key features of three typical NOMA schemes, i.e., SCMA, MUSA, and PDMA. What's more, their performance in terms of uplink bit error rate (BER) will be compared. Simulation results show that in typical Rayleigh fading channels, SCMA has the best performance, while the BER performance of MUSA and PDMA are very close to each other. In addition, we also analyze the performance of PDMA using the same factor graph as SCMA, which indicates that the performance gain of SCMA over PDMA comes from both the difference of factor graph and the codebook optimization.","Receivers,
Interference,
Silicon carbide,
Signal to noise ratio,
5G mobile communication,
Uplink,
Bit error rate"
Cost-Effective Resource Provisioning for MapReduce in a Cloud,"This paper presents a new MapReduce cloud service model, Cura, for provisioning cost-effective MapReduce services in a cloud. In contrast to existing MapReduce cloud services such as a generic compute cloud or a dedicated MapReduce cloud, Cura has a number of unique benefits. First, Cura is designed to provide a cost-effective solution to efficiently handle MapReduce production workloads that have a significant amount of interactive jobs. Second, unlike existing services that require customers to decide the resources to be used for the jobs, Cura leverages MapReduce profiling to automatically create the best cluster configuration for the jobs. While the existing models allow only a per-job resource optimization for the jobs, Cura implements a globally efficient resource allocation scheme that significantly reduces the resource usage cost in the cloud. Third, Cura leverages unique optimization opportunities when dealing with workloads that can withstand some slack. By effectively multiplexing the available cloud resources among the jobs based on the job requirements, Cura achieves significantly lower resource usage costs for the jobs. Cura's core resource management schemes include cost-aware resource provisioning, VM-aware scheduling and online virtual machine reconfiguration. Our experimental results using Facebook-like workload traces show that our techniques lead to more than 80 percent reduction in the cloud compute infrastructure cost with upto 65 percent reduction in job response times.","Resource management,
Optimization,
Schedules,
Computational modeling,
Time factors,
Scheduling"
Ultra-Scalable CPU-MIC Acceleration of Mesoscale Atmospheric Modeling on Tianhe-2,"In this work an ultra-scalable algorithm is designed and optimized to accelerate a 3D compressible Euler atmospheric model on the CPU-MIC hybrid system of Tianhe-2. We first reformulate the mesocale model to avoid long-latency operations, and then employ carefully designed inter-node and intra-node domain decomposition algorithms to achieve balance utilization of different computing units. Proper communication-computation overlap and concurrent data transfer methods are utilized to reduce the cost of data movement at scale. A variety of optimization techniques on both the CPU side and the accelerator side are exploited to enhance the in-socket performance. The proposed hybrid algorithm successfully scales to 6,144 Tianhe-2 nodes with a nearly ideal weak scaling efficiency, and achieve over 8 percent of the peak performance in double precision. This ultra-scalable hybrid algorithm may be of interest to the community to accelerating atmospheric models on increasingly dominated heterogeneous supercomputers.","Atmospheric modeling,
Computational modeling,
Mathematical model,
Three-dimensional displays,
Microwave integrated circuits,
Central Processing Unit,
Computer architecture"
Sorted Consecutive Local Binary Pattern for Texture Classification,"In this paper, we propose a sorted consecutive local binary pattern (scLBP) for texture classification. Conventional methods encode only patterns whose spatial transitions are not more than two, whereas scLBP encodes patterns regardless of their spatial transition. Conventional methods do not encode patterns on account of rotation-invariant encoding; on the other hand, patterns with more than two spatial transitions have discriminative power. The proposed scLBP encodes all patterns with any number of spatial transitions while maintaining their rotation-invariant nature by sorting the consecutive patterns. In addition, we introduce dictionary learning of scLBP based on kd-tree which separates data with a space partitioning strategy. Since the elements of sorted consecutive patterns lie in different space, it can be generated to a discriminative code with kd-tree. Finally, we present a framework in which scLBPs and the kd-tree can be combined and utilized. The results of experimental evaluation on five texture data sets-Outex, CUReT, UIUC, UMD, and KTH-TIPS2-a-indicate that our proposed framework achieves the best classification rate on the CUReT, UMD, and KTH-TIPS2-a data sets compared with conventional methods. The results additionally indicate that only a marginal difference exists between the best classification rate of conventional methods and that of the proposed framework on the UIUC and Outex data sets.","Image coding,
Dictionaries,
Materials,
Histograms,
Encoding,
Kernel,
Face recognition"
Distributed Smart-Home Decision-Making in a Hierarchical Interactive Smart Grid Architecture,"In this paper, we develop a comprehensive real-time interactive framework for the utility and customers in a smart grid while ensuring grid-stability and quality-of-service (QoS). First, we propose a hierarchical architecture for the utility-customer interaction consisting of sub-components of customer load prediction, renewable generation integration, power-load balancing and demand response (DR). Within this hierarchical architecture, we focus on the problem of real-time scheduling in an abstract grid model consisting of one controller and multiple customer units. A scalable solution to the real-time scheduling problem is proposed by combining solutions to two sub-problems: (1) centralized sequential decision making at the controller to maximize an accumulated reward for the whole micro-grid and (2) distributed auctioning among all customers based on the optimal load profile obtained by solving the first problem to coordinate their interactions. We formulate the centralized sequential decision making at the controller as a hidden mode Markov decision process (HM-MDP). Next, a Vikrey auctioning game is designed to coordinate the actions of the individual smart-homes to actually achieve the optimal solution derived by the controller under realistic gird interaction assumptions. We show that though truthful bidding is a weakly dominant strategy for all smart-homes in the auctioning game, collusive equilibria do exist and can jeopardize the effectiveness and efficiency of the trading opportunity allocation. Analysis on the structure of the Bayesian Nash equilibrium solution set shows that the Vickrey auctioning game can be made more robust against collusion by customers (anticipating distributed smart-homes) by introducing a positive reserve price. The corresponding auctioning game is then shown to converge to the unique incentive compatible truthful bidding Bayesian Nash equilibrium, without jeopardizing the auctioneer's (microgrid controller's) profit. The paper also explicitly discusses how this two-step solution approach can be scaled to be suitable for more complicated smart grid architectures beyond the assumed abstract model.","Microgrids,
Smart grids,
Real-time systems,
Decision making,
Planning,
Games,
Load modeling"
A Global/Local Affinity Graph for Image Segmentation,"Construction of a reliable graph capturing perceptual grouping cues of an image is fundamental for graph-cut based image segmentation methods. In this paper, we propose a novel sparse global/local affinity graph over superpixels of an input image to capture both short- and long-range grouping cues, and thereby enabling perceptual grouping laws, including proximity, similarity, continuity, and to enter in action through a suitable graph-cut algorithm. Moreover, we also evaluate three major visual features, namely, color, texture, and shape, for their effectiveness in perceptual segmentation and propose a simple graph fusion scheme to implement some recent findings from psychophysics, which suggest combining these visual features with different emphases for perceptual grouping. In particular, an input image is first oversegmented into superpixels at different scales. We postulate a gravitation law based on empirical observations and divide superpixels adaptively into small-, medium-, and large-sized sets. Global grouping is achieved using medium-sized superpixels through a sparse representation of superpixels' features by solving a ℓ0-minimization problem, and thereby enabling continuity or propagation of local smoothness over long-range connections. Small- and large-sized superpixels are then used to achieve local smoothness through an adjacent graph in a given feature space, and thus implementing perceptual laws, for example, similarity and proximity. Finally, a bipartite graph is also introduced to enable propagation of grouping cues between superpixels of different scales. Extensive experiments are carried out on the Berkeley segmentation database in comparison with several state-of-the-art graph constructions. The results show the effectiveness of the proposed approach, which outperforms state-of-the-art graphs using four different objective criteria, namely, the probabilistic rand index, the variation of information, the global consistency error, and the boundary displacement error.","Image segmentation,
Visualization,
Image color analysis,
Reliability,
Shape,
Bipartite graph,
Materials"
A Toolkit for Modeling and Simulation of Real-Time Virtual Machine Allocation in a Cloud Data Center,"Resource scheduling in infrastructure as a service (IaaS) is one of the keys for large-scale Cloud applications. Extensive research on all issues in real environment is extremely difficult because it requires developers to consider network infrastructure and the environment, which may be beyond the control. In addition, the network conditions cannot be predicted or controlled. Therefore, performance evaluation of workload models and Cloud provisioning algorithms in a repeatable manner under different configurations and requirements is difficult. There is still lack of tools that enable developers to compare different resource scheduling algorithms in IaaS regarding both computing servers and user workloads. To fill this gap in tools for evaluation and modeling of Cloud environments and applications, we propose CloudSched. CloudSched can help developers identify and explore appropriate solutions considering different resource scheduling algorithms. Unlike traditional scheduling algorithms considering only one factor such as CPU, which can cause hotspots or bottlenecks in many cases, CloudSched treats multidimensional resource such as CPU, memory and network bandwidth integrated for both physical machines and virtual machines (VMs) for different scheduling objectives (algorithms). In this paper, two existing simulation systems at application level for Cloud computing are studied, a novel lightweight simulation system is proposed for real-time VM scheduling in Cloud data centers, and results by applying the proposed simulation system are analyzed and discussed.","Data models,
Servers,
Computational modeling,
Scheduling algorithms,
Cloud computing,
Resource management"
Discriminant analysis on Riemannian manifold of Gaussian distributions for face recognition with image sets,"This paper presents a method named Discriminant Analysis on Riemannian manifold of Gaussian distributions (DARG) to solve the problem of face recognition with image sets. Our goal is to capture the underlying data distribution in each set and thus facilitate more robust classification. To this end, we represent image set as Gaussian Mixture Model (GMM) comprising a number of Gaussian components with prior probabilities and seek to discriminate Gaussian components from different classes. In the light of information geometry, the Gaussians lie on a specific Riemannian manifold. To encode such Riemannian geometry properly, we investigate several distances between Gaussians and further derive a series of provably positive definite probabilistic kernels. Through these kernels, a weighted Kernel Discriminant Analysis is finally devised which treats the Gaussians in GMMs as samples and their prior probabilities as sample weights. The proposed method is evaluated by face identification and verification tasks on four most challenging and largest databases, YouTube Celebrities, COX, YouTube Face DB and Point-and-Shoot Challenge, to demonstrate its superiority over the state-of-the-art.","Kernel,
Manifolds,
Gaussian distribution,
Face recognition,
Covariance matrices,
Data models,
Adaptation models"
A Zero-Voltage-Transition Bidirectional DC/DC Converter,"A three-level (TL) bidirectional dc/dc converter is a suitable choice for power electronic systems with a high-voltage dc link, as the voltage stress on the switches is half and inductor current ripple frequency is twice the converter's switching frequency. This study proposes a zero-voltage transition (ZVT) TL dc/dc converter to enable operation with higher switching frequency in order to achieve higher power density and enhance efficiency. Two identical ZVT cells, each one composed of two resonant inductors, a capacitor, and an auxiliary switch, are integrated with the conventional TL topology to enable soft switching in all four switches in both buck and boost operation modes. In addition, a variable dead-time control is proposed to increase the effective duty ratio at heavy loads. The proposed soft-switching feature has been demonstrated under different loading conditions. A 650-W prototype is designed and fabricated, which exhibits 95.5% at full load.","Inductors,
Capacitors,
Switching frequency,
Switches,
Power electronics,
Computers,
Educational institutions"
Hadoop Recognition of Biomedical Named Entity Using Conditional Random Fields,"Processing large volumes of data has presented a challenging issue, particularly in data-redundant systems. As one of the most recognized models, the conditional random fields (CRF) model has been widely applied in biomedical named entity recognition (Bio-NER). Due to the internally sequential feature, performance improvement of the CRF model is nontrivial, which requires new parallelized solutions. By combining and parallelizing the limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) and Viterbi algorithms, we propose a parallel CRF algorithm called MapReduce CRF (MRCRF) in this paper, which contains two parallel sub-algorithms to handle two time-consuming steps of the CRF model. The MapReduce L-BFGS (MRLB) algorithm leverages the MapReduce framework to enhance the capability of estimating parameters. Furthermore, the MapReduce Viterbi (MRVtb) algorithm infers the most likely state sequence by extending the Viterbi algorithm with another MapReduce job. Experimental results show that the MRCRF algorithm outperforms other competing methods by exhibiting significant performance improvement in terms of time efficiency as well as preserving a guaranteed level of correctness.","Viterbi algorithm,
Training,
Biological system modeling,
Inference algorithms,
Hidden Markov models,
Training data,
Vectors"
Adaptive Neural Output Feedback Control of Output-Constrained Nonlinear Systems With Unknown Output Nonlinearity,"This paper addresses the problem of adaptive neural output-feedback control for a class of special nonlinear systems with the hysteretic output mechanism and the unmeasured states. A modified Bouc-Wen model is first employed to capture the output hysteresis phenomenon in the design procedure. For its fusion with the neural networks and the Nussbaum-type function, two key lemmas are established using some extended properties of this model. To avoid the bad system performance caused by the output nonlinearity, a barrier Lyapunov function technique is introduced to guarantee the prescribed constraint of the tracking error. In addition, a robust filtering method is designed to cancel the restriction that all the system states require to be measured. Based on the Lyapunov synthesis, a new neural adaptive controller is constructed to guarantee the prescribed convergence of the tracking error and the semiglobal uniform ultimate boundedness of all the signals in the closed-loop system. Simulations are implemented to evaluate the performance of the proposed neural control algorithm in this paper.","Hysteresis,
Nonlinear systems,
Adaptive systems,
Magnetic hysteresis,
Adaptation models,
Artificial neural networks,
Closed loop systems"
Fuzzy Prediction Interval Models for Forecasting Renewable Resources and Loads in Microgrids,"An energy management system (EMS) determines the dispatching of generation units based on an optimizer that requires the forecasting of both renewable resources and loads. The forecasting system discussed in this paper includes a representation of the uncertainties associated with renewable resources and loads. The proposed modeling generates fuzzy prediction interval models that incorporate an uncertainty representation of future predictions. The model is demonstrated using solar and wind generation and local load data from a real microgrid in Huatacondo, Chile, for one-day ahead forecasts to obtain the expected values together with fuzzy prediction intervals to represent future measurement bounds with a certain coverage probability. The proposed prediction interval models would help to enable the development of robust microgrid EMS.","Forecasting,
Predictive models,
Microgrids,
Energy management,
Load modeling,
Wind forecasting,
Wind power generation"
Learning Driver Behavior Models from Traffic Observations for Decision Making and Planning,"Estimating and predicting traffic situations over time is an essential capability for sophisticated driver assistance systems and autonomous driving. When longer prediction horizons are needed, e.g., in decision making or motion planning, the uncertainty induced by incomplete environment perception and stochastic situation development over time cannot be neglected without sacrificing robustness and safety. Building consistent probabilistic models of drivers interactions with the environment, the road network and other traffic participants poses a complex problem. In this paper, we model the decision making process of drivers by building a hierarchical Dynamic Bayesian Model that describes physical relationships as well as the driver's behaviors and plans. This way, the uncertainties in the process on all abstraction levels can be handled in a mathematically consistent way. As drivers behaviors are difficult to model, we present an approach for learning continuous, non-linear, context-dependent models for the behavior of traffic participants. We propose an Expectation Maximization (EM) approach for learning the models integrated in the DBN from unlabeled observations. Experiments show a significant improvement in estimation and prediction accuracy over standard models which only consider vehicle dynamics. Finally, a novel approach to tactical decision making for autonomous driving is outlined. It is based on a continuous Partially Observable Markov Decision Process (POMDP) that uses the presented model for prediction.","Behavioral science,
Bayes methods,
Atmospheric measurements,
Particle measurements,
Context modeling,
Predictive models,
Random variables,
Road traffic,
Decision making"
The ManyBugs and IntroClass Benchmarks for Automated Repair of C Programs,"The field of automated software repair lacks a set of common benchmark problems. Although benchmark sets are used widely throughout computer science, existing benchmarks are not easily adapted to the problem of automatic defect repair, which has several special requirements. Most important of these is the need for benchmark programs with reproducible, important defects and a deterministic method for assessing if those defects have been repaired. This article details the need for a new set of benchmarks, outlines requirements, and then presents two datasets, ManyBugs and IntroClass, consisting between them of 1,183 defects in 15 C programs. Each dataset is designed to support the comparative evaluation of automatic repair algorithms asking a variety of experimental questions. The datasets have empirically defined guarantees of reproducibility and benchmark quality, and each study object is categorized to facilitate qualitative evaluation and comparisons by category of bug or program. The article presents baseline experimental results on both datasets for three existing repair methods, GenProg, AE, and TrpAutoRepair, to reduce the burden on researchers who adopt these datasets for their own comparative evaluations.",
Ensemble Multiple Kernel Active Learning For Classification of Multisource Remote Sensing Data,"Incorporating disparate features from multiple sources can provide valuable diverse information for remote sensing data analysis. However, multisource remote sensing data require large quantities of labeled data to train robust supervised classifiers, which are often difficult and expensive to acquire. A mixture-of-kernel approach can facilitate the construction of an effective formulation for acquiring useful samples via active learning (AL). In this paper, we propose an ensemble multiple kernel active learning (EnsembleMKL-AL) framework that incorporates different types of features extracted from multisensor remote sensing data (hyperspectral imagery and LiDAR data) for robust classification. An ensemble of probabilistic multiple kernel classifiers is embedded into a maximum disagreement-based AL system, which adaptively optimizes the kernel for each source during the AL process. At the end of each learning step, a decision fusion strategy is implemented to make a final decision based on the probabilistic outputs. The proposed framework is tested in a multisource environment, including different types of features extracted from hyperspectral and LiDAR data. The experimental results validate the efficacy of the proposed approach. In addition, we demonstrate that using ensemble classifiers and a large number of disparate but relevant features can further improve the performance of an AL-based classification approach.","Kernel,
Feature extraction,
Laser radar,
Hyperspectral imaging,
Training"
Scheduling of Single-Arm Multi-cluster Tools With Wafer Residency Time Constraints in Semiconductor Manufacturing,"This paper studies the challenging problem of scheduling single-arm multi-cluster tools with wafer residency time constraints. They have a linear topology and their bottleneck tool is process-bound. This work aims to find an optimal one-wafer cyclic schedule. With the Petri net model developed in our previous work and the minimal cycle time for a multicluster tool without wafer residency time constraints, it derives the necessary and sufficient schedulability conditions for multicluster tools with wafer residency time constraints for the first time. Then, it gives an algorithm to find an optimal one-wafer cyclic schedule if schedulable. This is done by simply setting the robots' waiting time for each tool. Thus, it is very computationally efficient and applicable to practical problems. An example is presented to illustrate the proposed method.","Schedules,
Time factors,
Robots,
Job shop scheduling,
Semiconductor device modeling,
Algorithm design and analysis,
Educational institutions"
An Anatomically Detailed Arterial Network Model for One-Dimensional Computational Hemodynamics,"Simulation platforms are increasingly becoming complementary tools for cutting-edge cardiovascular research. The interplay among structural properties of the arterial wall, morphometry, anatomy, wave propagation phenomena, and ultimately, cardiovascular diseases continues to be poorly understood. Accurate models are powerful tools to shed light on these open problems. We developed an anatomically detailed computational model of the arterial vasculature to conduct 1-D blood flow simulations to serve as simulation infrastructure to aid cardiovascular research. An average arterial vasculature of a man was outlined in 3-D space to serve as geometrical substrate for the mathematical model. The architecture of this model comprises almost every arterial vessel acknowledged in the medical/anatomical literature, with a resolution down to the luminal area of perforator arteries. Over 2000 arterial vessels compose the model. Anatomical, physiological, and mechanical considerations were employed for the set up of model parameters and to determine criteria for blood flow distribution. Computational fluid dynamics was used to simulate blood flow and wave propagation phenomena in such arterial network. A sensitivity analysis was developed to unveil the contributions of model parameters to the conformation of the pressure waveforms. In addition, parameters were modified to target model to a patient-specific scenario. On the light of the knowledge domain, we conclude that the present model features excellent descriptive and predictive capabilities in both patient-generic and patient-specific cases, presenting a new step toward integrating an unprecedented anatomical description, morphometric, and simulations data to help in understanding complex arterial blood flow phenomena and related cardiovascular diseases.","Arteries,
Computational modeling,
Mathematical model,
Blood,
Numerical models,
Data models,
Materials"
Accurate Segmentation of Cervical Cytoplasm and Nuclei Based on Multiscale Convolutional Network and Graph Partitioning,"In this paper, a multiscale convolutional network (MSCN) and graph-partitioning-based method is proposed for accurate segmentation of cervical cytoplasm and nuclei. Specifically, deep learning via the MSCN is explored to extract scale invariant features, and then, segment regions centered at each pixel. The coarse segmentation is refined by an automated graph partitioning method based on the pretrained feature. The texture, shape, and contextual information of the target objects are learned to localize the appearance of distinctive boundary, which is also explored to generate markers to split the touching nuclei. For further refinement of the segmentation, a coarse-to-fine nucleus segmentation framework is developed. The computational complexity of the segmentation is reduced by using superpixel instead of raw pixels. Extensive experimental results demonstrate that the proposed cervical nucleus cell segmentation delivers promising results and outperforms existing methods.","Shape,
Image segmentation,
Computer architecture,
Feature extraction,
Microprocessors,
Image edge detection,
Image color analysis"
Compressive Imaging via Approximate Message Passing With Image Denoising,"We consider compressive imaging problems, where images are reconstructed from a reduced number of linear measurements. Our objective is to improve over existing compressive imaging algorithms in terms of both reconstruction error and runtime. To pursue our objective, we propose compressive imaging algorithms that employ the approximate message passing (AMP) framework. AMP is an iterative signal reconstruction algorithm that performs scalar denoising at each iteration; in order for AMP to reconstruct the original input signal well, a good denoiser must be used. We apply two wavelet-based image denoisers within AMP. The first denoiser is the “amplitude-scale-invariant Bayes estimator” (ABE), and the second is an adaptive Wiener filter; we call our AMP-based algorithms for compressive imaging AMP-ABE and AMP-Wiener. Numerical results show that both AMP-ABE and AMP-Wiener significantly improve over the state of the art in terms of runtime. In terms of reconstruction quality, AMP-Wiener offers lower mean-square error (MSE) than existing compressive imaging algorithms. In contrast, AMP-ABE has higher MSE, because ABE does not denoise as well as the adaptive Wiener filter.","Wavelet transforms,
Noise measurement,
Imaging,
Runtime,
Image coding,
Signal processing algorithms"
Sum-Rate and Power Scaling of Massive MIMO Systems With Channel Aging,"This paper investigates the achievable sum-rate of massive multiple-input multiple-output (MIMO) systems in the presence of channel aging. For the uplink, by assuming that the base station (BS) deploys maximum ratio combining (MRC) or zero-forcing (ZF) receivers, we present tight closed-form lower bounds on the achievable sum-rate for both receivers with aged channel state information (CSI). In addition, the benefit of implementing channel prediction methods on the sum-rate is examined, and closed-form sum-rate lower bounds are derived. Moreover, the impact of channel aging and channel prediction on the power scaling law is characterized. Extension to the downlink scenario and multicell scenario is also considered. It is found that, for a system with/without channel prediction, the transmit power of each user can be scaled down at most by 1/√M (where M is the number of BS antennas), which indicates that aged CSI does not degrade the power scaling law, and channel prediction does not enhance the power scaling law; instead, these phenomena affect the achievable sum-rate by degrading or enhancing the effective signal to interference and noise ratio, respectively.","Receivers,
Channel estimation,
Uplink,
MIMO,
Antennas,
Downlink"
Jointly learning heterogeneous features for RGB-D activity recognition,"In this paper, we focus on heterogeneous feature learning for RGB-D activity recognition. Considering that features from different channels could share some similar hidden structures, we propose a joint learning model to simultaneously explore the shared and feature-specific components as an instance of heterogenous multi-task learning. The proposed model in an unified framework is capable of: 1) jointly mining a set of subspaces with the same dimensionality to enable the multi-task classifier learning, and 2) meanwhile, quantifying the shared and feature-specific components of features in the subspaces. To efficiently train the joint model, a three-step iterative optimization algorithm is proposed, followed by two inference models. Extensive results on three activity datasets have demonstrated the efficacy of the proposed method. In addition, a novel RGB-D activity dataset focusing on human-object interaction is collected for evaluating the proposed method, which will be made available to the community for RGB-D activity benchmarking and analysis.","Joints,
Feature extraction,
Yttrium,
Solid modeling,
Three-dimensional displays,
Trajectory"
A Framework of Joint Graph Embedding and Sparse Regression for Dimensionality Reduction,"Over the past few decades, a large number of algorithms have been developed for dimensionality reduction. Despite the different motivations of these algorithms, they can be interpreted by a common framework known as graph embedding. In order to explore the significant features of data, some sparse regression algorithms have been proposed based on graph embedding. However, the problem is that these algorithms include two separate steps: (1) embedding learning and (2) sparse regression. Thus their performance is largely determined by the effectiveness of the constructed graph. In this paper, we present a framework by combining the objective functions of graph embedding and sparse regression so that embedding learning and sparse regression can be jointly implemented and optimized, instead of simply using the graph spectral for sparse regression. By the proposed framework, supervised, semisupervised, and unsupervised learning algorithms could be unified. Furthermore, we analyze two situations of the optimization problem for the proposed framework. By adopting an ℓ2,1-norm regularization for the proposed framework, it can perform feature selection and subspace learning simultaneously. Experiments on seven standard databases demonstrate that joint graph embedding and sparse regression method can significantly improve the recognition performance and consistently outperform the sparse regression method.","Educational institutions,
Joints,
Optimization,
Electronic mail,
Principal component analysis,
Vectors,
Algorithm design and analysis"
A New Distributed Parameter Broadband Matching Method for Power Amplifier via Real Frequency Technique,"A general matching method is presented in this paper for broadband power amplifier (PA) design. A novel cost function is proposed for the real frequency technique (RFT), which could straightforwardly describe PA optimal impedance along with frequency change. The new function is also developed to design a broadband transformer for the PA output matching network (MN). Based on Richard transformation, a commensurate transmission line is deployed so that the PA matching could be convenient expressed by a real positive function. More important is that the function could be directly implemented with a distributed MN through synthesis theory. Therefore, this method is practical for computer-aided design and has less calculation amount with new function for the RFT. To verify the method, a step-by-step design of a broadband PA is given. For large signals, power gain is 14.2-16.8 dB across 0.9-2.8 GHz, while output power is around 39.5 dBm. The maximum power-added efficiency is from 52.2% to 85.1%.","Manganese,
Impedance,
Broadband communication,
Power transmission lines,
Transmission line matrix methods,
Cost function,
Load modeling"
Biological Channel Modeling and Implantable UWB Antenna Design for Neural Recording Systems,"Ultrawideband (UWB) short-range communication systems have proved to be valuable in medical technology, particularly for implanted devices, due to their low-power consumption, low cost, small size, and high data rates. Neural activity monitoring in the brain requires high data rate (800 kb/s per neural sensor), and we target a system supporting a large number of sensors, in particular, aggregate transmission above 430 Mb/s (~512 sensors). Knowledge of channel behavior is required to determine the maximum allowable power to 1) respect ANSI guidelines for avoiding tissue damage, and 2) respect FCC guidelines on unlicensed transmissions. We utilize a realistic model of the biological channel to inform the design of antennas for the implanted transmitter and the external receiver under these requirements. Antennas placement is examined under two scenarios having contrasting power constraints. Performance of the system within the biological tissues is examined via simulation and experiment. Our miniaturized antennas, 12 mm x 12 mm, need worst-case receiver sensitivities of -38 and -30.5 dBm for the first and second scenarios, respectively. These sensitivities allow us to successfully detect signals transmitted through tissues in the 3.1-10.6-GHz UWB band.","Receiving antennas,
Transmitting antennas,
Biological tissues,
Directive antennas"
"Review of Imprinted Polymer Microrings as Ultrasound Detectors: Design, Fabrication, and Characterization","Detectors play a vital role in ultrasound sensing and imaging applications. With the rapid development of photoacoustic imaging technology in recent years, novel ultrasound detectors based on optical methods have gained increased attention, among which the imprinted polymer microring is a representative one. This review covers the device design, fabrication, and characterization, with an emphasis on how the imprinting-based fabrication methodology benefits the device performance, which further facilitates photoacoustic imaging and sensing applications. By carefully designing and fabricating the imprint mold, the imprinted polymer microring has a quality factor on the order of 10^{5}
at 780 nm. The device has advantages such as wide acoustic bandwidth response from dc to 350 MHz at -3 dB, low noise equivalent detectable pressure, wide acceptance angle, and so on. The polymer microring has been successfully employed in applications such as photoacoustic imaging and real-time terahertz pulse detection.","Optical waveguides,
Polymers,
Optical resonators,
Acoustics,
Detectors,
Optical sensors"
Projection Metric Learning on Grassmann Manifold with Application to Video based Face Recognition,"In video based face recognition, great success has been made by representing videos as linear subspaces, which typically lie in a special type of non-Euclidean space known as Grassmann manifold. To leverage the kernel-based methods developed for Euclidean space, several recent methods have been proposed to embed the Grassmann manifold into a high dimensional Hilbert space by exploiting the well established Project Metric, which can approximate the Riemannian geometry of Grassmann manifold. Nevertheless, they inevitably introduce the drawbacks from traditional kernel-based methods such as implicit map and high computational cost to the Grassmann manifold. To overcome such limitations, we propose a novel method to learn the Projection Metric directly on Grassmann manifold rather than in Hilbert space. From the perspective of manifold learning, our method can be regarded as performing a geometry-aware dimensionality reduction from the original Grassmann manifold to a lower-dimensional, more discriminative Grassmann manifold where more favorable classification can be achieved. Experiments on several real-world video face datasets demonstrate that the proposed method yields competitive performance compared with the state-of-the-art algorithms.","Manifolds,
Yttrium,
Face,
Kernel,
Hilbert space,
Symmetric matrices"
Modeling and Analysis of a Variable Speed Heat Pump for Frequency Regulation Through Direct Load Control,"This paper presents a dynamic model of a variable speed heat pump (VSHP) in a commercial building that responds to direct load control (DLC) signals, updated every 4 s, for the improvement of grid frequency regulation (GFR). The model is simplified for real-time simulation studies with the time horizon ranging from seconds to hours, but still sufficiently comprehensive to analyze the operational characteristics such as the heat rate and coefficient of performance. A variable speed drive-controlled induction motor model is also established for the adjustment of the VSHP input power. A dynamic model of an experimental room is then developed to estimate the effect of the DLC application to the VSHP on its indoor air temperature for two different cooling systems. Furthermore, small signal analysis is performed to evaluate both the transient response of the DLC-enabled VSHP and its contribution to GFR. Finally, with an isolated microgrid implemented with Matlab/Simulink, simulation studies demonstrate that the VSHP can be effectively exploited as the DLC-enabled load while still ensuring building occupant comfort and long-term device performance.","Mathematical model,
Heat pumps,
Atmospheric modeling,
Water heating,
Frequency control,
Buildings"
Assessing Knowledge Retention of an Immersive Serious Game vs. a Traditional Education Method in Aviation Safety,"Thanks to the increasing availability of consumer head-mounted displays, educational applications of immersive VR could now reach to the general public, especially if they include gaming elements (immersive serious games). Safety education of citizens could be a particularly promising domain for immersive serious games, because people tend not to pay attention to and benefit from current safety materials. In this paper, we propose an HMD-based immersive game for educating passengers about aviation safety that allows players to experience a serious aircraft emergency with the goal of surviving it. We compare the proposed approach to a traditional aviation safety education method (the safety card) used by airlines. Unlike most studies of VR for safety knowledge acquisition, we do not focus only on assessing learning immediately after the experience but we extend our attention to knowledge retention over a longer time span. This is a fundamental requirement, because people need to retain safety procedures in order to apply them when faced with danger. A knowledge test administered before, immediately after and one week after the experimental condition showed that the immersive serious game was superior to the safety card. Moreover, subjective as well as physiological measurements employed in the study showed that the immersive serious game was more engaging and fear-arousing than the safety card, a factor that can contribute to explain the obtained superior retention, as we discuss in the paper.","Games,
Safety,
Aircraft,
Education,
Materials,
Avatars,
Engines"
Multi-Timescale Power Management for Islanded Microgrids Including Storage and Demand Response,"Power management is an essential tool for microgrid (MG) safe and economic operation, particularly in the islanded operation mode. In this paper, a multi-timescale cost-effective power management algorithm (PMA) is proposed for islanded MG operation targeting generation, storage, and demand management. Comprehensive modeling, cost, and emission calculations of the MG components are developed in this paper to facilitate high accuracy management. While the MGs overall power management and operation is carried out every several minutes to hours, depending on the availability of the required data, simulation for highly dynamic devices, such as batteries and electric water heaters (EWHs) used for demand response (DR), are performed every minute. This structure allows accurate, scalable, and practical power management taking into consideration the intrainterval dynamics of battery and EWHs. Two different on/off strategies for EWH control are also proposed for DR application. Then, the PMA is implemented using the two different DR strategies and the results are compared with the no-DR case. Actual solar irradiation, ambient temperature, nonEWH load demand, and hot water consumption data are employed in the simulation studies. The simulation results for the MG studied show the effectiveness of the proposed algorithm to reduce both MGs cost and emission.","Batteries,
Load modeling,
Mathematical model,
Fuels,
Data models,
Water heating,
Radiation effects"
Artificial Bee Colony Algorithm Based on Information Learning,"Inspired by the fact that the division of labor and cooperation play extremely important roles in the human history development, this paper develops a novel artificial bee colony algorithm based on information learning (ILABC, for short). In ILABC, at each generation, the whole population is divided into several subpopulations by the clustering partition and the size of subpopulation is dynamically adjusted based on the last search experience, which results in a clear division of labor. Furthermore, the two search mechanisms are designed to facilitate the exchange of information in each subpopulation and between different subpopulations, respectively, which acts as the cooperation. Finally, the comparison results on a number of benchmark functions demonstrate that the proposed method performs competitively and effectively when compared to the selected state-of-the-art algorithms.","Sociology,
Statistics,
Equations,
Algorithm design and analysis,
Mathematical model,
Clustering algorithms,
Search problems"
Response Policies to Process Module Failure in Single-Arm Cluster Tools Subject to Wafer Residency Time Constraints,"In semiconductor manufacturing, wafer residency time constraints make the scheduling problem of cluster tools complicated. A process module (PM) in cluster tools is prone to failure. It is crucial to deal with any such failure in a proper and timely manner. If there are feasible periodic schedules in operating a cluster tool before and after a PM failure, it is desired to make it operate continuously when such a failure occurs. However, due to wafer residency time constraints, it is highly challenging to control a tool such that it can be correctly transferred from a feasible schedule before failure to another after it. To solve this problem, a Petri net model is developed to describe the dynamic behavior of a single-arm cluster tool and failure response policies are proposed. The proposed policies are formulated via simple control laws for their easy implementation. Examples are given to show them. Note to Practitioners-For single-arm cluster tools with wafer residency constraints, this work proposes the response policies when a PM fails in wafer fabrication. With a Petri net model, when there are feasible cyclic schedules for both before and after failure, policies are presented to respond to a PM failure such that the wafers in a tool can be completed in a feasible way. The policies require polynomially complex calculation and can be implemented on-line to satisfy the real-time requirements. Therefore, they are applicable to practical semiconductor manufacturing systems.","Robots,
Semiconductor device modeling,
Schedules,
Load modeling,
Time factors,
Steady-state,
System recovery"
Constructing a Nonnegative Low-Rank and Sparse Graph With Data-Adaptive Features,"This paper aims at constructing a good graph to discover the intrinsic data structures under a semisupervised learning setting. First, we propose to build a nonnegative low-rank and sparse (referred to as NNLRS) graph for the given data representation. In particular, the weights of edges in the graph are obtained by seeking a nonnegative low-rank and sparse reconstruction coefficients matrix that represents each data sample as a linear combination of others. The so-obtained NNLRS-graph captures both the global mixture of subspaces structure (by the low-rankness) and the locally linear structure (by the sparseness) of the data, hence it is both generative and discriminative. Second, as good features are extremely important for constructing a good graph, we propose to learn the data embedding matrix and construct the graph simultaneously within one framework, which is termed as NNLRS with embedded features (referred to as NNLRS-EF). Extensive NNLRS experiments on three publicly available data sets demonstrate that the proposed method outperforms the state-of-the-art graph construction method by a large margin for both semisupervised classification and discriminative analysis, which verifies the effectiveness of our proposed method.","Sparse matrices,
Robustness,
Noise,
Complexity theory,
Dictionaries,
Algorithm design and analysis,
Optimization"
Cognitive Transmit Beamforming From Binary CSIT,"Transmit beamforming is used to steer radiated power towards a receiver of interest and to limit interference to unintended receivers, thereby facilitating coexistence. Transmit beamforming requires accurate channel state information (CSI) at the transmitter, which is often difficult to acquire, particularly in cognitive underlay settings, where the primary receiver cannot be expected to cooperate with the secondary system to enable it to learn the secondary to primary crosstalk channel. This paper considers cases where it is not realistic to assume channel reciprocity, or that the receivers are capable of accurate CSI estimation and feedback-because they are legacy systems, or have limited computation/energy resources. Transmit beamforming from binary and infrequent CSI is first considered for an isolated link. An online beamforming and learning algorithm is developed using the analytic center cutting plane method and is shown to asymptotically attain optimal performance. A robust maximum-likelihood formulation is next developed to handle feedback errors and correlation drift. The setup is then generalized to a cognitive underlay setting, also exploiting the standard acknowledgement/negative-acknowledgement feedback on the reverse primary link. This is the first solution to jointly tackle secondary signal-to-noise ratio maximization and primary interference mitigation from only rudimentary CSI, without assuming channel reciprocity.","Array signal processing,
Vectors,
Signal to noise ratio,
Correlation,
Interference,
Channel estimation,
Receivers"
A Self-Tuning zSlices-Based General Type-2 Fuzzy PI Controller,"The interval type-2 fuzzy Proportional-Integral (PI) controller (IT2-FPI) might be able to handle high levels of uncertainties to produce a satisfactory control performance, which could be potentially due to the robust performance as a result of the smoother control surface around the steady state. However, the transient state and disturbance rejection performance of the IT2-FPI may degrade in comparison with the type-1 fuzzy PI (T1-FPI) counterpart. This drawback can be resolved via general type-2 fuzzy PI controllers which can provide a tradeoff between the robust control performance of the IT2-FPI and the acceptable transient and disturbance rejection performance of the type-1 PI controllers. In this paper, we will present a zSlices-based general type-2 fuzzy PI controller (zT2-FPI), where the secondary membership functions (SMFs) of the antecedent general type-2 fuzzy sets are adjusted in an online manner. We will examine the effect of the SMF on the closed-system control performance to investigate their induced performance improvements. This paper will focus on the case followed in conventional or self-tuning fuzzy controller design strategies, where the aim is to decrease the integral action sufficiently around the steady state to have robust system performance against noises and parameter variations. The zSlices approach will give the opportunity to construct the zT2-FPI controller as a collection of IT2-FPI and T1-FPI controllers. We will present a new way to design a zT2-FPI controller based on a single tuning parameter where the features of T1-FPI (speed) and IT2-FPI (robustness) are combined without increasing the computational complexity much when compared with the IT2-FPI structure. This will allow the proposed zT2-FPI controller to achieve the desired transient state response and provide an efficient disturbance rejection and robust control performance. We will present several simulation studies on benchmark systems, in addition to real-world experiments that were performed using the PIONEER 3-DX mobile robot that will act as a platform to evaluate the proposed systems. The results will show that the control performance of the self-tuning zT2-FPI control structure enhances both the transient state and disturbance rejection performances when compared with the type-1 and IT2-FPI counterparts. In addition, the self-tuning zT2-FPI is more robust to disturbances, noise, and uncertainties when compared with the type-1 and interval type-2 fuzzy counterparts.","Robustness,
Steady-state,
Equations,
Tuning,
Transient analysis,
Mathematical model,
Fuzzy sets"
Adaptive Fault-Tolerant Stochastic Shape Control With Application to Particle Distribution Control,"This paper investigates the fault-tolerant shape control (FTSC) problem for stochastic distribution systems. For this problem, in addition to measurable input signals, it is assumed that the distribution function of the system output can be evaluated so that it is available. It is also assumed that the system is subject to actuator faults. In this case, the main control objective is for the output of the stochastic distribution system to track a given target distribution even in the presence of actuator faults. By estimating these actuator faults, an effective FTSC strategy is proposed, which consists of a normal control law and an adaptive compensation control law. The former can track the given output distribution with an optimized performance index in the fault-free case, while the latter can automatically reduce (or even eliminate) the adverse effects caused by the actuator faults. The proposed method can be applied to tracking control of output probability density functions. To demonstrate the effectiveness of the proposed scheme, simulation is performed on one numerical example with satisfactory results obtained. In addition, a practical example of soil particle gradation control in geotechnical applications is given in this paper, and the results show that the proposed fault-tolerant scheme is applicable to practical particle size distribution control.","Actuators,
Adaptive estimation,
Stochastic processes,
Linear matrix inequalities,
Fault tolerance,
Fault tolerant systems,
Shape control"
A Bayesian Overlapping Coalition Formation Game for Device-to-Device Spectrum Sharing in Cellular Networks,"We consider the spectrum sharing problem between a set of device-to-device (D2D) links and multiple co-located cellular networks. Each cellular network is controlled by an operator which can provide service to a number of subscribers. Each D2D link can either access a sub-band occupied by a cellular subscriber or obtain an empty sub-band for its exclusive use. We introduce a new spectrum sharing mode for D2D communications in cellular networks by allowing two or more D2D links with exclusive use of sub-bands to share their sub-bands with each other without consulting the operators. We establish a new game theoretic model called Bayesian non-transferable utility overlapping coalition formation (BOCF) game. We show that our proposed game can be used to model and analyze the above spectrum sharing problem. However, we observe that the core of the BOCF game can be empty, and we derive a sufficient condition for which the core is non-empty. We propose a hierarchical matching algorithm which can detect whether the sufficient condition is satisfied and, if it is satisfied, achieve a stable and unique matching structure which coincides with the overlapping coalition agreement profile in the core of the BOCF game.","Games,
Interference,
Bayes methods,
Wireless communication,
Signal to noise ratio,
Optimization,
Resource management"
Depth Sensation Enhancement for Multiple Virtual View Rendering,"Depth information is an indispensable element in depth image-based rendering (DIBR) for three-dimensional (3-D) display. In this paper, we propose a novel depth sensation enhancement method to address the problems in multiple virtual view rendering. First, as the depth sensation is decreased when rendering intermediate multiple virtual views, the basic principle of depth sensation enhancement is derived according to the number of rendering views. Second, with the increase of the scene complexity, it is difficult to ensure the depth sensation of all neighboring objects. The saliency analysis is adopted to give preferred guarantee to the depth sensation between the salient object and its neighbors. Then, the depth sensation enhancement for multiple virtual view rendering is performed based on a defined energy function built by the number of rendering views and the saliency analysis. Finally, considering the temporal consistency between adjacent frames, the depth sensation enhancement is extended to video applications with a newly designed energy function with energy term of temporal consistency preservation. Experimental results on a public database demonstrate that the proposed method can obtain promising performance in depth sensation.","Rendering (computer graphics),
Three-dimensional displays,
Visualization,
Algorithm design and analysis,
Image segmentation,
Color,
Complexity theory"
A Near Optimal QoE-Driven Power Allocation Scheme for Scalable Video Transmissions Over MIMO Systems,"The rapid increasing demands of wireless multimedia applications have boosted the developments of video delivery technologies with cross-layer designs, driven by optimizing quality of experiences (QoEs) of end users. In this paper, a near optimal power allocation scheme, targeting at maximizing QoE, is proposed for transmitting scalable video coding (SVC) based videos over multi-input multi-output (MIMO) systems. Both transmission errors in the physical (PHY) layer and video source coding characteristics in the application (APP) layer are jointly considered in the proposed scheme. A near optimal solution is achieved by decomposing the original optimization problem into several convex optimization sub-problems. Detailed algorithms with corresponding theoretical reasoning are provided. Since forward error corrections (FEC) techniques are widely implemented in modern wireless communication systems, the proposed scheme is further extended to the systems with Reed-Solomon (RS) code and a more practical approach with different modulation and coding schemes (MCSs). The near optimality of our proposed scheme, in terms of measured utilities, is shown by comparing with the exhaustive searched optimal solutions. Simulations with real H.264 SVC video traces demonstrate the effectiveness of our proposed scheme by comparing with other existing schemes in terms of well-accepted video quality assessment methods, such as peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) index.","Streaming media,
MIMO,
Resource management,
Static VAr compensators,
Forward error correction,
Bit error rate,
Wireless communication"
Data Fusion by Matrix Factorization,"For most problems in science and engineering we can obtain data sets that describe the observed system from various perspectives and record the behavior of its individual components. Heterogeneous data sets can be collectively mined by data fusion. Fusion can focus on a specific target relation and exploit directly associated data together with contextual data and data about system's constraints. In the paper we describe a data fusion approach with penalized matrix tri-factorization (DFMF) that simultaneously factorizes data matrices to reveal hidden associations. The approach can directly consider any data that can be expressed in a matrix, including those from feature-based representations, ontologies, associations and networks. We demonstrate the utility of DFMF for gene function prediction task with eleven different data sources and for prediction of pharmacologic actions by fusing six data sources. Our data fusion algorithm compares favorably to alternative data integration approaches and achieves higher accuracy than can be obtained from any single data source alone.","Data integration,
Data models,
Convergence,
Approximation methods,
Diseases,
Linear programming,
Predictive models"
A Bayesian Nonparametric Approach to Image Super-Resolution,"Super-resolution methods form high-resolution images from low-resolution images. In this paper, we develop a new Bayesian nonparametric model for super-resolution. Our method uses a beta-Bernoulli process to learn a set of recurring visual patterns, called dictionary elements, from the data. Because it is nonparametric, the number of elements found is also determined from the data. We test the results on both benchmark and natural images, comparing with several other models from the research literature. We perform large-scale human evaluation experiments to assess the visual quality of the results. In a first implementation, we use Gibbs sampling to approximate the posterior. However, this algorithm is not feasible for large-scale data. To circumvent this, we then develop an online variational Bayes (VB) algorithm. This algorithm finds high quality dictionaries in a fraction of the time needed by the Gibbs sampler.","Dictionaries,
Image resolution,
Inference algorithms,
Data models,
Training,
Bayes methods,
Signal resolution"
A Globally Stabilizing Path Following Controller for Rotorcraft With Wind Disturbance Rejection,"This brief addresses the design and experimental evaluation of a global controller to steer a quadrotor vehicle along a predefined path in the presence of constant wind disturbances. The proposed solution consists of a nonlinear adaptive state feedback controller for thrust and torque actuation that: 1) guarantees global convergence of the closed-loop path following error to zero in the presence of constant wind disturbances and 2) ensures that the actuation can be bounded as a function of the position and velocity errors without imposing a maximum for that bound, allowing for high performance control action. A prototyping and testing architecture, developed to streamline the implementation and tuning of the controller, is also described. Simulation results and experimental results, which include a hovering flight in the slipstream of a mechanical fan, are presented to assess the performance and robustness of the proposed controller.","Vehicles,
Force,
Angular velocity,
Trajectory,
Vehicle dynamics,
Timing,
Lyapunov methods"
Flexibility Envelopes for Power System Operational Planning,"Modern power systems are undergoing a transitional phase, increasingly incorporating renewable energy sources (RES) to harness their economic and environmental benefits. The main challenge with this transitional phase is the management of the increased variability and uncertainty in the power balance. Legacy operation and planning practices are gradually seen as becoming inadequate or ill-adapted in addressing this challenge. One particular gap in the state of the art, which is of great importance, is estimating the operational flexibility potential of individual power system assets and their aggregation at the system level. System operators need to evaluate and plan ahead flexibility adequacy for their power systems in order to ensure feasible and economical operation under high RES penetration. Likewise, asset owners need to integrate the notion of asset flexibility as part of their investment and operations decisions. To this end, we propose the concept of the flexibility envelope to describe the flexibility potential dynamics of a power system and its individual resources in the operational planning time-frame. We demonstrate that the resulting envelope dynamics can be a starting point for flexibility adequacy planning in systems with highly variable generation.","Planning,
Power system dynamics,
Uncertainty,
Dynamic scheduling,
Random processes,
Economics"
GaN-Based Metal-Insulator-Semiconductor High-Electron-Mobility Transistors Using Low-Pressure Chemical Vapor Deposition SiNx as Gate Dielectric,"In this letter, silicon nitride (SiNx) film deposited at 780 °C by low-pressure chemical vapor deposition (LPCVD) was employed as gate dielectric for GaN-based metal-insulator-semiconductor high-electron-mobility transistors. The LPCVD-SiNx exhibit improved gate dielectric performance than the plasma enhanced chemical vapor deposition-SiNx, including smaller forward and reverse gate leakage, and higher forward gate breakdown voltage.","Logic gates,
Gallium nitride,
Dielectrics,
Aluminum gallium nitride,
Leakage currents,
Films,
Silicon nitride"
Understanding image representations by measuring their equivariance and equivalence,"Despite the importance of image representations such as histograms of oriented gradients and deep Convolutional Neural Networks (CNN), our theoretical understanding of them remains limited. Aiming at filling this gap, we investigate three key mathematical properties of representations: equivariance, invariance, and equivalence. Equivariance studies how transformations of the input image are encoded by the representation, invariance being a special case where a transformation has no effect. Equivalence studies whether two representations, for example two different parametrisations of a CNN, capture the same visual information or not. A number of methods to establish these properties empirically are proposed, including introducing transformation and stitching layers in CNNs. These methods are then applied to popular representations to reveal insightful aspects of their structure, including clarifying at which layers in a CNN certain geometric invariances are achieved. While the focus of the paper is theoretical, direct applications to structured-output regression are demonstrated too.","Image representation,
Image reconstruction,
Feature extraction,
Histograms,
Convolutional codes,
Neural networks,
Computer vision"
Optimal linear and cyclic locally repairable codes over small fields,"We consider locally repairable codes over small fields and propose constructions of optimal cyclic and linear codes in terms of the dimension for a given distance and length. Four new constructions of optimal linear codes over small fields with locality properties are developed. The first two approaches give binary cyclic codes with locality two. While the first construction has availability one, the second binary code is characterized by multiple available repair sets based on a binary Simplex code. The third approach extends the first one to q-ary cyclic codes including (binary) extension fields, where the locality property is determined by the properties of a shortened first-order Reed- Muller code. Non-cyclic optimal binary linear codes with locality greater than two are obtained by the fourth construction.","Linear codes,
Additives,
Binary codes,
Concatenated codes,
Maintenance engineering,
Polynomials,
Product codes"
A Stochastic Polygons Model for Glandular Structures in Colon Histology Images,"In this paper, we present a stochastic model for glandular structures in histology images of tissue slides stained with Hematoxylin and Eosin, choosing colon tissue as an example. The proposed Random Polygons Model (RPM) treats each glandular structure in an image as a polygon made of a random number of vertices, where the vertices represent approximate locations of epithelial nuclei. We formulate the RPM as a Bayesian inference problem by defining a prior for spatial connectivity and arrangement of neighboring epithelial nuclei and a likelihood for the presence of a glandular structure. The inference is made via a Reversible-Jump Markov chain Monte Carlo simulation. To the best of our knowledge, all existing published algorithms for gland segmentation are designed to mainly work on healthy samples, adenomas, and low grade adenocarcinomas. One of them has been demonstrated to work on intermediate grade adenocarcinomas at its best. Our experimental results show that the RPM yields favorable results, both quantitatively and qualitatively, for extraction of glandular structures in histology images of normal human colon tissues as well as benign and cancerous tissues, excluding undifferentiated carcinomas.","Silicon,
Glands,
Colon,
Markov processes,
Image segmentation,
Bayes methods,
Image color analysis"
Cooperative Resource Management in Cloud-Enabled Vehicular Networks,"Cloud-enabled vehicular networks are a new paradigm to improve the quality of vehicular services, which have drawn considerable attention in industry and academia. In this paper, we consider the resource management and sharing problem for bandwidth and computing resources to support mobile applications in cloud-enabled vehicular networks. In such an environment, cloud service providers (SPs) can cooperate to form coalitions to share their idle resources with each other. We propose a coalition game model based on two-sided matching theory for cooperation among cloud SPs to share their idle resources. As a result, the resources can be better utilized, and the QoS for users can be improved. Numerical results indicate that our scheme can improve resource utilization and increase by 75% the QoS of the applications compared with that without cooperation. Moreover, the higher service cost of cooperation brings negative effect on coalition formation. The higher cooperation willingness of cloud SPs and the lower service cost support more service applications.","Vehicles,
Bandwidth,
Cloud computing,
Resource management,
Mobile applications,
Quality of service,
Mobile communication"
Characterization of a Benchmark Database for Myoelectric Movement Classification,"In this paper, we characterize the Ninapro database and its use as a benchmark for hand prosthesis evaluation. The database is a publicly available resource that aims to support research on advanced myoelectric hand prostheses. The database is obtained by jointly recording surface electromyography signals from the forearm and kinematics of the hand and wrist while subjects perform a predefined set of actions and postures. Besides describing the acquisition protocol, overall features of the datasets and the processing procedures in detail, we present benchmark classification results using a variety of feature representations and classifiers. Our comparison shows that simple feature representations such as mean absolute value and waveform length can achieve similar performance to the computationally more demanding marginal discrete wavelet transform. With respect to classification methods, the nonlinear support vector machine was found to be the only method consistently achieving high performance regardless of the type of feature representation. Furthermore, statistical analysis of these results shows that classification accuracy is negatively correlated with the subject's Body Mass Index. The analysis and the results described in this paper aim to be a strong baseline for the Ninapro database. Thanks to the Ninapro database (and the characterization described in this paper), the scientific community has the opportunity to converge to a common position on hand movement recognition by surface electromyography, a field capable to strongly affect hand prosthesis capabilities.","Electrodes,
Databases,
Benchmark testing,
Wrist,
Protocols,
Prosthetics,
Standards"
Adaptive Modulation and Coding for Underwater Acoustic OFDM,"Underwater acoustic channels are fast varying spatially and temporally according to environmental conditions. Adaptive modulation and coding (AMC) is appealing for underwater acoustic communications to improve the system efficiency by matching transmission parameters to channel variations. In this paper, we construct an AMC system with a finite number of transmission modes in the context of underwater orthogonal frequency-division multiplexing (OFDM). We propose the effective signal-to-noise ratio (SNR) computed after channel estimation and channel decoding as a new performance metric for mode switching, which is shown to predict the system performance more consistently than the input SNR and the pilot SNR. Real-time AMC tests have been conducted in a recent sea experiment to maximize the transmission rate with a given transmission power.","OFDM,
Modulation,
Encoding,
Channel estimation,
Measurement,
PSNR"
Opportunities for Nonvolatile Memory Systems in Extreme-Scale High-Performance Computing,"For extreme-scale high-performance computing systems, system-wide power consumption has been identified as one of the key constraints moving forward, where DRAM main memory systems account for about 30 to 50 percent of a node's overall power consumption. As the benefits of device scaling for DRAM memory slow, it will become increasingly difficult to keep memory capacities balanced with increasing computational rates offered by next-generation processors. However, several emerging memory technologies related to nonvolatile memory (NVM) devices are being investigated as an alternative for DRAM. Moving forward, NVM devices could offer solutions for HPC architectures. Researchers are investigating how to integrate these emerging technologies into future extreme-scale HPC systems and how to expose these capabilities in the software stack and applications. Current results show several of these strategies could offer high-bandwidth I/O, larger main memory capacities, persistent data structures, and new approaches for application resilience and output postprocessing, such as transaction-based incremental checkpointing and in situ visualization, respectively.","Nonvolatile memory,
Phase change random access memory,
Memory management,
Flash memories,
Market research,
High performance computing,
Scientific computing,
Supercomputers"
Error Bounds of Adaptive Dynamic Programming Algorithms for Solving Undiscounted Optimal Control Problems,"In this paper, we establish error bounds of adaptive dynamic programming algorithms for solving undiscounted infinite-horizon optimal control problems of discrete-time deterministic nonlinear systems. We consider approximation errors in the update equations of both value function and control policy. We utilize a new assumption instead of the contraction assumption in discounted optimal control problems. We establish the error bounds for approximate value iteration based on a new error condition. Furthermore, we also establish the error bounds for approximate policy iteration and approximate optimistic policy iteration algorithms. It is shown that the iterative approximate value function can converge to a finite neighborhood of the optimal value function under some conditions. To implement the developed algorithms, critic and action neural networks are used to approximate the value function and control policy, respectively. Finally, a simulation example is given to demonstrate the effectiveness of the developed algorithms.","Function approximation,
Optimal control,
Approximation algorithms,
Nonlinear systems,
Equations,
Piecewise linear approximation"
A Sensor-Based Dual-Arm Tele-Robotic System,"We present a novel system to achieve coordinated task-based control on a dual-arm industrial robot for the general tasks of visual servoing and bimanual hybrid motion/force control. The industrial robot, consisting of a rotating torso and two seven degree-of-freedom arms, performs autonomous vision-based target alignment of both arms with the aid of fiducial markers, two-handed grasping and force control, and robust object manipulation in a tele-robotic framework. The operator uses hand motions to command the desired position for the object via Microsoft Kinect while the autonomous force controller maintains a stable grasp. Gestures detected by the Kinect are also used to dictate different operation modes. We demonstrate the effectiveness of our approach using a variety of common objects with different sizes, shapes, weights, and surface compliances.","Robot sensing systems,
Service robots,
Force,
Robot kinematics,
Joints,
End effectors"
Quality-Optimized Joint Source Selection and Power Control for Wireless Multimedia D2D Communication Using Stackelberg Game,"In wireless device-to-device (D2D) networks, devices are reluctant to forward packets because of limited energy and possible delays for their own data. The incentive mechanisms that motivate devices to constitute direct communication for wireless multimedia quality optimality in D2D systems have been overlooked in the past. In this paper, we propose a new low-complexity distributed game-theoretic source selection and power control scheme that enhances the multimedia transmission quality with latency constraints. This approach has two major contributions. First, the proposed approach optimally selects the most beneficial source devices by analyzing the interactions between the base station's (BS's) rewarding strategies (denoted by price) and the devices' contributing behaviors (denoted by transmission power) using a Stackelberg game model. Second, optimal transmission power is adjusted for each selected source device in D2D networks by deriving Stackelberg equilibrium, wherein the BS and the device both achieve maximum utility. Computer simulations demonstrate that significant improvement in D2D multimedia transmission quality can be obtained by deploying the proposed scheme.","Games,
Multimedia communication,
Wireless communication,
Power control,
Mobile communication,
Streaming media,
Relays"
Time-Varying Ankle Mechanical Impedance During Human Locomotion,"In human locomotion, we continuously modulate joint mechanical impedance of the lower limb (hip, knee, and ankle) either voluntarily or reflexively to accommodate environmental changes and maintain stable interaction. Ankle mechanical impedance plays a pivotal role at the interface between the neuro-mechanical system and the physical world. This paper reports, for the first time, a characterization of human ankle mechanical impedance in two degrees-of-freedom simultaneously as it varies with time during walking. Ensemble-based linear time-varying system identification methods implemented with a wearable ankle robot, Anklebot, enabled reliable estimation of ankle mechanical impedance from the pre-swing phase through the entire swing phase to the early-stance phase. This included heel-strike and toe-off, key events in the transition from the swing to stance phase or vice versa. Time-varying ankle mechanical impedance was accurately approximated by a second order model consisting of inertia, viscosity, and stiffness in both inversion-eversion and dorsiflexion-plantarflexion directions, as observed in our previous steady-state dynamic studies. We found that viscosity and stiffness of the ankle significantly decreased at the end of the stance phase before toe-off, remained relatively constant across the swing phase, and increased around heel-strike. Closer investigation around heel-strike revealed that viscosity and stiffness in both planes increased before heel-strike occurred. This finding is important evidence of “pretuning” by the central nervous system. In addition, viscosity and stiffness were greater in the sagittal plane than in the frontal plane across all subgait phases, except the early stance phase. Comparison with previous studies and implications for clinical study of neurologically impaired patients are provided.","Legged locomotion,
Impedance,
Joints,
Mathematical model,
Time-varying systems"
Distributed Online Hybrid Cloud Management for Profit-Driven Multimedia Cloud Computing,"It is known that with a hybrid cloud, a multimedia cloud service provider (MCSP) can quickly extend its services to multiple geographical locations with quality-of-service (QoS) guarantees. Meanwhile, to maximize its profit, the MCSP needs an online management mechanism to operate the hybrid cloud efficiently. In this paper, we study how to maximize an MCSP's profit from provisioning multimedia services to geographically distributed users with a hybrid cloud. We first design a service provisioning model to manage the resources in the hybrid cloud. Here, in order to make the model practical and address the different situations in private and public clouds, we consider different time granularities for resource reservations. Then, we leverage the Lyapunov optimization technique to maximize the profit of MCSP and propose an online algorithm that can manage the hybrid cloud in the distributed manner. Specifically , the algorithm determines the access control and routing of each multimedia service request, and allocates the resources in the hybrid cloud accordingly. We also apply the ε-persistent technique to ensure that the worst-case latency of the provisioned requests is bounded. Finally, the proposed algorithm is evaluated with extensive simulations using both synthetical and real traces. Simulation results indicate that the algorithm can manage the hybrid cloud efficiently and maximize the profit of MCSP.","Multimedia communication,
Cloud computing,
Optimization,
Servers,
Multimedia computing,
Resource management,
Quality of service"
"High-Reliability FPGA-Based Systems: Space, High-Energy Physics, and Beyond","Field-programmable gate arrays (FPGAs) have been shown to provide high computational density and efficiency for many computing applications by allowing circuits to be customized to any application of interest. FPGAs also support programmability by allowing the circuit to be changed at a later time through reconfiguration. There is great interest in exploiting these benefits in space and other radiation environments. FPGAs, however, are very sensitive to radiation and great care must be taken to properly address the effects of radiation in FPGA-based systems. This paper will highlight the effects of radiation on FPGA-based systems and summarize the challenges in deploying FPGAs in such environments. Several well-known mitigation methods will be described and the unique ability of FPGAs to customize the system for improved reliability will be discussed. Finally, two case studies summarizing successful deployment of FPGAs in radiation environments will be presented.","Field programmable gate arrays,
Space vehicles,
Reconfigurable architectures,
Computational efficiency,
Aerospace electronics,
Random access memory,
Radiation effects"
Compact and Bandwidth-Enhanced Zeroth-Order Resonant Antenna,"In this letter, a simple bandwidth-enhanced zeroth- order resonant (ZOR) antenna is proposed. The presented antenna is composed of two unit cells of the composite right/left-handed (CRLH) artificial structure and operates in the series resonant mode. In order to enhance the operational bandwidth, in particular, the interdigital capacitor in a unit cell was properly designed so as to reduce the quality factor of the resonator while occupying a relatively small area. Additionally, to facilitate implementation of the short-circuited boundary condition, the coplanar waveguide (CPW) was applied to develop a via-less uniplanar antenna prototype. Experimental results show that the presented ZOR antenna achieves a 10-dB bandwidth of 15.1% and a peak radiation gain of 1.62 dBi with a compact size of 0.14λ0 ×0.22λ0 at the operating frequency. Measured and simulated results are in good agreement.",
Examination of Poststroke Alteration in Motor Unit Firing Behavior Using High-Density Surface EMG Decomposition,"Recent advances in high-density surface electromyogram (EMG) decomposition have made it a feasible task to discriminate single motor unit activity from surface EMG interference patterns, thus providing a noninvasive approach for examination of motor unit control properties. In the current study, we applied high-density surface EMG recording and decomposition techniques to assess motor unit firing behavior alterations poststroke. Surface EMG signals were collected using a 64-channel 2-D electrode array from the paretic and contralateral first dorsal interosseous (FDI) muscles of nine hemiparetic stroke subjects at different isometric discrete contraction levels between 2 to 10 N with a 2 N increment step. Motor unit firing rates were extracted through decomposition of the high-density surface EMG signals and compared between paretic and contralateral muscles. Across the nine tested subjects, paretic FDI muscles showed decreased motor unit firing rates compared with contralateral muscles at different contraction levels. Regression analysis indicated a linear relation between the mean motor unit firing rate and the muscle contraction level for both paretic and contralateral muscles (p <; 0.001), with the former demonstrating a lower increment rate (0.32 pulses per second (pps)/N) compared with the latter (0.67 pps/N). The coefficient of variation (averaged over the contraction levels) of the motor unit firing rates for the paretic muscles (0.21 ± 0.012) was significantly higher than for the contralateral muscles (0.17 ± 0.014) (p <; 0.05). This study provides direct evidence of motor unit firing behavior alterations poststroke using surface EMG, which can be an important factor contributing to hemiparetic muscle weakness.",
In Vivo Irreversible Electroporation Kidney Ablation: Experimentally Correlated Numerical Models,"Irreversible electroporation (IRE) ablation uses brief electric pulses to kill a volume of tissue without damaging the structures contraindicated for surgical resection or thermal ablation, including blood vessels and ureters. IRE offers a targeted nephron-sparing approach for treating kidney tumors, but the relevant organ-specific electrical properties and cellular susceptibility to IRE electric pulses remain to be characterized. Here, a pulse protocol of 100 electric pulses, each 100 μs long, is delivered at 1 pulse/s to canine kidneys at three different voltage-to-distance ratios while measuring intrapulse current, completed 6 h before humane euthanasia. Numerical models were correlated with lesions and electrical measurements to determine electrical conductivity behavior and lethal electric field threshold. Three methods for modeling tissue response to the pulses were investigated (static, linear dynamic, and asymmetrical sigmoid dynamic), where the asymmetrical sigmoid dynamic conductivity function most accurately and precisely matched lesion dimensions, with a lethal electric field threshold of 575 ± 67 V/cm for the protocols used. The linear dynamic model also attains accurate predictions with a simpler function. These findings can aid renal IRE treatment planning under varying electrode geometries and pulse strengths. Histology showed a wholly necrotic core lesion at the highest electric fields, surrounded by a transitional perimeter of differential tissue viability dependent on renal structure.","Conductivity,
Electric fields,
Electrodes,
Lesions,
Kidney,
Numerical models,
Protocols"
LIBRA: Lightweight Data Skew Mitigation in MapReduce,"MapReduce is an effective tool for parallel data processing. One significant issue in practical MapReduce applications is data skew: the imbalance in the amount of data assigned to each task. This causes some tasks to take much longer to finish than others and can significantly impact performance. This paper presents LIBRA, a lightweight strategy to address the data skew problem among the reducers of MapReduce applications. Unlike previous work, LIBRA does not require any pre-run sampling of the input data or prevent the overlap between the map and the reduce stages. It uses an innovative sampling method which can achieve a highly accurate approximation to the distribution of the intermediate data by sampling only a small fraction of the intermediate data during the normal map processing. It allows the reduce tasks to start copying as soon as the chosen sample map tasks (only a small fraction of map tasks which are issued first) complete. It supports the split of large keys when application semantics permit and the total order of the output data. It considers the heterogeneity of the computing resources when balancing the load among the reduce tasks appropriately. LIBRA is applicable to a wide range of applications and is transparent to the users. We implement LIBRA in Hadoop and our experiments show that LIBRA has negligible overhead and can speed up the execution of some popular applications by up to a factor of 4.",
CloudGenius: A Hybrid Decision Support Method for Automating the Migration of Web Application Clusters to Public Clouds,"With the increase in cloud service providers, and the increasing number of compute services offered, a migration of information systems to the cloud demands selecting the best mix of compute services and virtual machine (VM ) images from an abundance of possibilities. Therefore, a migration process for web applications has to automate evaluation and, in doing so, ensure that Quality of Service (QoS) requirements are met, while satisfying conflicting selection criteria like throughput and cost. When selecting compute services for multiple connected software components, web application engineers must consider heterogeneous sets of criteria and complex dependencies across multiple layers, which is impossible to resolve manually. The previously proposed CloudGenius framework has proven its capability to support migrations of single-component web applications. In this paper, we expand on the additional complexity of facilitating migration support for multi-component web applications. In particular, we present an evolutionary migration process for web application clusters distributed over multiple locations, and clearly identify the most important criteria relevant to the selection problem. Moreover, we present a multi-criteria-based selection algorithm based on Analytic Hierarchy Process (AHP). Because the solution space grows exponentially, we developed a Genetic Algorithm (GA)-based approach to cope with computational complexities in a growing cloud market. Furthermore, a use case example proofs CloudGenius' applicability. To conduct experiments, we implemented CumulusGenius, a prototype of the selection algorithm and the GA deployable on hadoop clusters. Experiments with CumulusGenius give insights on time complexities and the quality of the GA.","Cloud computing,
Servers,
Computational modeling,
Decision making,
Genetic algorithms,
Quality of service"
Abandoned Object Detection via Temporal Consistency Modeling and Back-Tracing Verification for Visual Surveillance,"This paper presents an effective approach for detecting abandoned luggage in surveillance videos. We combine short- and long-term background models to extract foreground objects, where each pixel in an input image is classified as a 2-bit code. Subsequently, we introduce a framework to identify static foreground regions based on the temporal transition of code patterns, and to determine whether the candidate regions contain abandoned objects by analyzing the back-traced trajectories of luggage owners. The experimental results obtained based on video images from 2006 Performance Evaluation of Tracking and Surveillance and 2007 Advanced Video and Signal-based Surveillance databases show that the proposed approach is effective for detecting abandoned luggage, and that it outperforms previous methods.","Silicon,
Surveillance,
Image color analysis,
Videos,
Object recognition,
Trajectory,
Visualization"
Compact Modeling of Total Ionizing Dose and Aging Effects in MOS Technologies,"This paper presents a physics-based compact modeling approach that incorporates the impact of total ionizing dose (TID) and stress-induced defects into simulations of metal-oxide-semiconductor (MOS) devices and integrated circuits (ICs). This approach utilizes calculations of surface potential (ψs) to capture the charge contribution from oxide trapped charge and interface traps and to describe their impact on MOS electrostatics and device operating characteristics as a function of ionizing radiation exposure and aging effects. The modeling approach is demonstrated for bulk and silicon-on-insulator (SOI) MOS device. The formulation is verified using TCAD simulations and through the comparison of model calculations and experimental I - V characteristics from irradiated devices. The modeling approach is suitable for simulating TID and aging effects in advanced MOS devices and ICs, and is compatible with modern MOSFET compact modeling techniques. A circuit-level demonstration is given for TID and aging effects in SRAM cells.","Integrated circuit modeling,
Mathematical model,
Aging,
MOSFET,
Semiconductor device modeling,
Approximation methods"
On Reducing the Effect of Covariate Factors in Gait Recognition: A Classifier Ensemble Method,"Robust human gait recognition is challenging because of the presence of covariate factors such as carrying condition, clothing, walking surface, etc. In this paper, we model the effect of covariates as an unknown partial feature corruption problem. Since the locations of corruptions may differ for different query gaits, relevant features may become irrelevant when walking condition changes. In this case, it is difficult to train one fixed classifier that is robust to a large number of different covariates. To tackle this problem, we propose a classifier ensemble method based on the random subspace Method (RSM) and majority voting (MV). Its theoretical basis suggests it is insensitive to locations of corrupted features, and thus can generalize well to a large number of covariates. We also extend this method by proposing two strategies, i.e, local enhancing (LE) and hybrid decision-level fusion (HDF) to suppress the ratio of false votes to true votes (before MV). The performance of our approach is competitive against the most challenging covariates like clothing, walking surface, and elapsed time. We evaluate our method on the USF dataset and OU-ISIR-B dataset, and it has much higher performance than other state-of-the-art algorithms.","Feature extraction,
Legged locomotion,
Gait recognition,
Training,
Analytical models"
Facilitating Image Search With a Scalable and Compact Semantic Mapping,"This paper introduces a novel approach to facilitating image search based on a compact semantic embedding. A novel method is developed to explicitly map concepts and image contents into a unified latent semantic space for the representation of semantic concept prototypes. Then, a linear embedding matrix is learned that maps images into the semantic space, such that each image is closer to its relevant concept prototype than other prototypes. In our approach, the semantic concepts equated with query keywords and the images mapped into the vicinity of the prototype are retrieved by our scheme. In addition, a computationally efficient method is introduced to incorporate new semantic concept prototypes into the semantic space by updating the embedding matrix. This novelty improves the scalability of the method and allows it to be applied to dynamic image repositories. Therefore, the proposed approach not only narrows semantic gap but also supports an efficient image search process. We have carried out extensive experiments on various cross-modality image search tasks over three widely-used benchmark image datasets. Results demonstrate the superior effectiveness, efficiency, and scalability of our proposed approach.","Semantics,
Prototypes,
Training,
Visualization,
Educational institutions,
Linear programming,
Vectors"
"Automatic detection, classification and tracking of objects in the ocean surface from UAVs using a thermal camera","The use of unmanned aerial vehicles (UAVs) that can operate autonomously in dynamic and dangerous operational environments are becoming increasingly common. In such operations, object detection, classification and tracking can often be one of the main goals. In recent years there has been an increased focus on embedded hardware that is both small and powerful, making UAV on-board data processing more viable. Being able to process the video feed on-board the UAV calls for fast and robust real-time algorithms for object identification and tracking. This paper discusses the development and implementation of a machine vision system for a low-cost fixed-wing UAV with a total flying weight of less than 4kg. The machine vision system incorporates the use of a thermal imaging camera and on-board processing power to perform real-time object detection, classification and tracking of objects in the ocean surface. The system is tested on thermal video data from a test flight, and is found to be able to detect 99;6% of objects of interest located in the ocean surface. Of the detected objects, only 5% were false positives. Furthermore, it classifies 93; 3% of the object types it is trained to classify correctly. The classifier is highly agile, allowing the user to quickly define which object characteristics that should be considered during classification, and what types of objects to classify. Finally, the system is found to successfully track 85% of the object types it is actively searching for in a real-time simulation test.","Search problems,
Biographies,
Cameras,
Computers,
Switches,
Object detection,
Irrigation"
Dual Sentiment Analysis: Considering Two Sides of One Review,"Bag-of-words (BOW) is now the most popular way to model text in statistical machine learning approaches in sentiment analysis. However, the performance of BOW sometimes remains limited due to some fundamental deficiencies in handling the polarity shift problem. We propose a model called dual sentiment analysis (DSA), to address this problem for sentiment classification. We first propose a novel data expansion technique by creating a sentiment-reversed review for each training and test review. On this basis, we propose a dual training algorithm to make use of original and reversed training reviews in pairs for learning a sentiment classifier, and a dual prediction algorithm to classify the test reviews by considering two sides of one review. We also extend the DSA framework from polarity (positive-negative) classification to 3-class (positive-negative-neutral) classification, by taking the neutral reviews into consideration. Finally, we develop a corpus-based method to construct a pseudo-antonym dictionary, which removes DSA's dependency on an external antonym dictionary for review reversion. We conduct a wide range of experiments including two tasks, nine datasets, two antonym dictionaries, three classification algorithms, and two types of features. The results demonstrate the effectiveness of DSA in supervised sentiment classification.","Training,
Sentiment analysis,
Dictionaries,
Classification algorithms,
Logistics,
Analytical models,
Pragmatics"
Distributed Consensus-Based Weight Design for Cooperative Spectrum Sensing,"In this paper, we study the distributed spectrum sensing in cognitive radio networks. Existing distributed consensus-based fusion algorithms only ensure equal gain combining of local measurements, whose performance may be incomparable to various centralized soft combining schemes. Motivated by this fact, we consider practical channel conditions and link failures, and develop new weighted soft measurement combining without a centralized fusion center. Following the measurement by its energy detector, each secondary user exchanges its own measurement statistics with its local one-hop neighbors, and chooses the information exchanging rate according to the measurement channel condition, e.g., the signal-to-noise ratio (SNR). We rigorously prove the convergence of the new consensus algorithm, and show all secondary users hold the same global decision statistics from the weighted soft measurement combining throughout the network. We also provide distributed optimal weight design under uncorrelated measurement channels. The convergence rate of the consensus iteration is given under the assumption that each communication link has an independent probability to fail, and the upper bound of the iteration number of the ε-convergence is explicitly given as a function of system parameters. Simulation results show significant improvement of the sensing performance compared to existing consensus-based approaches, and the performance of the distributed weighted design is comparable to the centralized weighted combining scheme.","Sensors,
Weight measurement,
Convergence,
Algorithm design and analysis,
Signal to noise ratio,
Heuristic algorithms,
Diversity reception"
Modeling and Analysis of an Extended Access Barring Algorithm for Machine-Type Communications in LTE-A Networks,"Simultaneous channel accesses from mass machine-type communications (MTC) devices may congest the random-access channels (RACHs) of LTE-A networks. Currently, 3GPP selects extended access barring (EAB) mechanism as the baseline solution to relieve the congestion of RACHs by barring low-priority devices. Different settings of EAB parameters may re-shape the arrival process of MTC traffic and thus, lead to unpredictable performance. This paper presents an analytical model to investigate the performance of the EAB algorithm on the RACHs in LTE-A networks. Computer simulations were conducted to verify the accuracy of the analysis. The optimal values of paging cycle and repetition period of system information block type 14 (SIB14) can then be obtained from the analytical model subject to a target quality-of-service (QoS) constraint.",
Fast Mode Selection for HEVC Intra-Frame Coding With Entropy Coding Refinement Based on a Transparent Composite Model,"In comparison with H.264/Advanced Video Coding, the newest video coding standard, High Efficiency Video Coding (HEVC), improves video coding rate-distortion (RD) performance, but at the price of significant increase in its encoding complexity, especially, in intra-mode decision due to the adoption of more complex block partitions and more candidate intra-prediction modes (IPMs). To reduce the mode decision complexity in HEVC intra-frame coding, while maintaining its RD performance, in this paper, we first formulate the mode decision problem in intra-frame coding as a Bayesian decision problem based on the newly proposed transparent composite model (TCM) for discrete cosine transform coefficients, and then present an outlier-based fast intra-mode decision (OIMD) algorithm. The proposed OIMD algorithm reduces the complexity using outliers identified by TCM to make a fast coding unit split/nonsplit decision and reduce the number of IPMs to be compared. To further take advantage of the outlier information furnished by TCM, we also refine entropy coding in HEVC by encoding the outlier information first, and then the actual mode decision conditionally given the outlier information. The proposed OIMD algorithm can work with and without the proposed entropy coding refinement. Experiments show that for the all-intra-main test configuration of HEVC: 1) when applied alone, the proposed OIMD algorithm reduces, on average, the encoding time (ET) by 50% with 0.7% Bjontegaard distortion (BD)-rate increase and 2) when applied in conjunction with the proposed entropy coding refinement, it reduces, on average, both the ET by 50% and BD-rate by 0.15%.","Video coding,
Discrete cosine transforms,
Complexity theory,
Image coding,
Bayes methods,
Entropy coding"
Learning Understandable Neural Networks With Nonnegative Weight Constraints,"People can understand complex structures if they relate to more isolated yet understandable concepts. Despite this fact, popular pattern recognition tools, such as decision tree or production rule learners, produce only flat models which do not build intermediate data representations. On the other hand, neural networks typically learn hierarchical but opaque models. We show how constraining neurons' weights to be nonnegative improves the interpretability of a network's operation. We analyze the proposed method on large data sets: the MNIST digit recognition data and the Reuters text categorization data. The patterns learned by traditional and constrained network are contrasted to those learned with principal component analysis and nonnegative matrix factorization.","Neurons,
Training,
Biological neural networks,
Data models,
Principal component analysis,
Educational institutions,
Vectors"
Converter Rating Analysis for Photovoltaic Differential Power Processing Systems,"When photovoltaic (PV) cells are connected in series, they experience internal and external mismatch that reduces output power. Differential power processing (DPP) architectures achieve high system efficiency by processing a fraction of the total power while maintaining distributed local maximum power point operation. This paper details the computational methods and analysis used to determine the operation of PV-to-bus and PV-to-PV DPP architectures with rating-limited converters. Simulations for both DPP architectures are used to evaluate system performance over 25 years of operation. Based on data from field studies, a PV power coefficient of variation can be estimated as 0.086 after 25 years. An improvement figure of merit reflecting the ratio of energy produced to that delivered in a conventional system is introduced to evaluate comparative performance. Converter ratings of 15-17% for PV-to-bus and 23-33% for PV-to-PV architectures are identified as appropriate ratings for a 15-submodule system (five PV panels in series). Both DPP architectures with these ratings are shown to deliver up to 2.8% more power compared to a conventional series-string architecture based on the expected panel variation over 25 years of operation. DPP converters also outperform dc optimizers in terms of lifetime performance.","Degradation,
Computer architecture,
Power generation,
Topology,
Short-circuit currents,
Switches,
Inverters"
A \mu -Controller-Based System for Interfacing Selectorless RRAM Crossbar Arrays,"Selectorless crossbar arrays of resistive randomaccess memory (RRAM), also known as memristors, conduct large sneak currents during operation, which can significantly corrupt the accuracy of cross-point analog resistance (Mt) measurements. In order to mitigate this issue, we have designed, built, and tested a memristor characterization and testing (mCAT) instrument that forces redistribution of sneak currents within the crossbar array, dramatically increasing Mt measurement accuracy. We calibrated the mCAT using a custom-made 32 × 32 discrete resistive crossbar array, and subsequently demonstrated its functionality on solid-state TiO2-x RRAM arrays, on wafer and packaged, of the same size. Our platform can measure standalone Mt in the range of 1 kΩ to 1 MΩ with <;1% error. For our custom resistive crossbar, 90% of devices of the same resistance range were measured with <;10% error. The platform's limitations have been quantified using large-scale nonideal crossbar simulations.","Resistance,
Electrical resistance measurement,
Voltage measurement,
Current measurement,
Memristors,
Measurement uncertainty"
Time-Series Classification with COTE: The Collective of Transformation-Based Ensembles,"Recently, two ideas have been explored that lead to more accurate algorithms for time-series classification (TSC). First, it has been shown that the simplest way to gain improvement on TSC problems is to transform into an alternative data space where discriminatory features are more easily detected. Second, it was demonstrated that with a single data representation, improved accuracy can be achieved through simple ensemble schemes. We combine these two principles to test the hypothesis that forming a collective of ensembles of classifiers on different data transformations improves the accuracy of time-series classification. The collective contains classifiers constructed in the time, frequency, change, and shapelet transformation domains. For the time domain, we use a set of elastic distance measures. For the other domains, we use a range of standard classifiers. Through extensive experimentation on 72 datasets, including all of the 46 UCR datasets, we demonstrate that the simple collective formed by including all classifiers in one ensemble is significantly more accurate than any of its components and any other previously published TSC algorithm. We investigate alternative hierarchical collective structures and demonstrate the utility of the approach on a new problem involving classifying Caenorhabditis elegans mutant types.",
We Feel: Mapping Emotion on Twitter,"Research data on predisposition to mental health problems, and the fluctuations and regulation of emotions, thoughts, and behaviors are traditionally collected through surveys, which cannot provide a real-time insight into the emotional state of individuals or communities. Large datasets such as World Health Organization (WHO) statistics are collected less than once per year, whereas social network platforms, such as Twitter, offer the opportunity for real-time analysis of expressed mood. Such patterns are valuable to the mental health research community, to help understand the periods and locations of greatest demand and unmet need. We describe the “We Feel” system for analyzing global and regional variations in emotional expression, and report the results of validation against known patterns of variation in mood.
2.73×
10
9
emotional tweets were collected over a 12-week period, and automatically annotated for emotion, geographic location, and gender. Principal component analysis (PCA) of the data illustrated a dominant in-phase pattern across all emotions, modulated by antiphase patterns for “positive” and “negative” emotions. The first three principal components accounted for over 90% of the variation in the data. PCA was also used to remove the dominant diurnal and weekly variations allowing identification of significant events within the data, with z-scores showing expression of emotions over 80 standard deviations from the mean. We also correlate emotional expression with WHO data at a national level and although no correlations were observed for the burden of depression, the burden of anxiety and suicide rates appeared to correlate with expression of particular emotions.","Twitter,
Principal component analysis,
Fluctuations,
Communities,
Correlation,
Australia,
Standards"
A Low-Complexity Near-ML Differential Spatial Modulation Detector,"Differential spatial modulation (DSM) is a newly-emerging differential scheme tailored to the spatial modulation technique, which selects only one among a group of antennas for transmission at any time instant. DSM, however, gives rise to prohibitive search complexity when the number of transmit antennas is large. In this letter, a low-complexity suboptimal detector is proposed for DSM. It is designed based on the maximum-likelihood criterion but takes more candidates for the antenna activation orders into account. The detection is performed in two steps: the first step is to confine the number of candidates for the modulated symbols to a small portion by exploiting the symmetry of the signal constellation; the second step is to select the most likely modulated symbols from the output of the first step according to the determined antenna activation order via a Viterbi-like algorithm. Analyses and simulations show that the proposed detector achieves near-optimal performance yet largely reduces the search complexity.","Detectors,
Transmitting antennas,
Modulation,
Complexity theory,
Covariance matrices,
Electronic mail"
Distributed Kalman Filtering With Dynamic Observations Consensus,"This paper studies distributed estimation of unstable dynamic random fields observed by a sparsely connected network of sensors. The field dynamics are globally detectable, but not necessarily locally detectable. We propose a consensus+innovations distributed estimator, termed Distributed Information Kalman Filter. We prove under what conditions this estimator is asymptotically unbiased with bounded mean-squared error, smaller than for other alternative distributed estimators. Monte Carlo simulations confirm our theoretical error asymptotic results.","Sensors,
Kalman filters,
Technological innovation,
Power system dynamics,
Vehicle dynamics,
Estimation,
Noise"
Optimum Wirelessly Powered Relaying,"This letter maximizes the achievable throughput of a relay-assisted wirelessly powered communications system, where an energy constrained source, assisted by an energy constrained relay and both powered by a dedicated power beacon (PB), communicates with a destination. Considering the time splitting approach, the source and relay first harvest energy from the PB, which is equipped with multiple antennas, and then transmits the information to destination. Simple closed-form expressions are derived for the optimal PB energy beamforming vector and time split for energy harvesting and information transmission. Numerical results and simulations demonstrate the superior performance compared with some intuitive benchmark beamforming scheme. Also, it is found that placing the relay at the middle of the source-destination path is no longer optimal.","Wireless communication,
Relays,
Throughput,
Energy harvesting,
Array signal processing,
Optimization,
Antennas"
Minimizing Movement for Target Coverage and Network Connectivity in Mobile Sensor Networks,"Coverage of interest points and network connectivity are two main challenging and practically important issues of Wireless Sensor Networks (WSNs). Although many studies have exploited the mobility of sensors to improve the quality of coverage and connectivity, little attention has been paid to the minimization of sensors' movement, which often consumes the majority of the limited energy of sensors and thus shortens the network lifetime significantly. To fill in this gap, this paper addresses the challenges of the Mobile Sensor Deployment (MSD) problem and investigates how to deploy mobile sensors with minimum movement to form a WSN that provides both target coverage and network connectivity. To this end, the MSD problem is decomposed into two sub-problems: the Target COVerage (TCOV) problem and the Network CONnectivity (NCON) problem. We then solve TCOV and NCON one by one and combine their solutions to address the MSD problem. The NP-hardness of TCOV is proved. For a special case of TCOV where targets disperse from each other farther than double of the coverage radius, an exact algorithm based on the Hungarian method is proposed to find the optimal solution. For general cases of TCOV, two heuristic algorithms, i.e., the Basic algorithm based on clique partition and the TV-Greedy algorithm based on Voronoi partition of the deployment region, are proposed to reduce the total movement distance of sensors. For NCON, an efficient solution based on the Steiner minimum tree with constrained edge length is proposed. The combination of the solutions to TCOV and NCON, as demonstrated by extensive simulation experiments, offers a promising solution to the original MSD problem that balances the load of different sensors and prolongs the network lifetime consequently.","Mobile communication,
Mobile computing,
Partitioning algorithms,
Wireless sensor networks,
Heuristic algorithms,
Energy consumption,
Educational institutions"
Semantic data mining: A survey of ontology-based approaches,"Semantic Data Mining refers to the data mining tasks that systematically incorporate domain knowledge, especially formal semantics, into the process. In the past, many research efforts have attested the benefits of incorporating domain knowledge in data mining. At the same time, the proliferation of knowledge engineering has enriched the family of domain knowledge, especially formal semantics and Semantic Web ontologies. Ontology is an explicit specification of conceptualization and a formal way to define the semantics of knowledge and data. The formal structure of ontology makes it a nature way to encode domain knowledge for the data mining use. In this survey paper, we introduce general concepts of semantic data mining. We investigate why ontology has the potential to help semantic data mining and how formal semantics in ontologies can be incorporated into the data mining process. We provide detail discussions for the advances and state of art of ontology-based approaches and an introduction of approaches that are based on other form of knowledge representations.","Data mining,
Ontologies"
MuR-DPA: Top-Down Levelled Multi-Replica Merkle Hash Tree Based Secure Public Auditing for Dynamic Big Data Storage on Cloud,"Cloud computing that provides elastic computing and storage resource on demand has become increasingly important due to the emergence of “big data”. Cloud computing resources are a natural fit for processing big data streams as they allow big data application to run at a scale which is required for handling its complexities (data volume, variety and velocity). With the data no longer under users' direct control, data security in cloud computing is becoming one of the most concerns in the adoption of cloud computing resources. In order to improve data reliability and availability, storing multiple replicas along with original datasets is a common strategy for cloud service providers. Public data auditing schemes allow users to verify their outsourced data storage without having to retrieve the whole dataset. However, existing data auditing techniques suffers from efficiency and security problems. First, for dynamic datasets with multiple replicas, the communication overhead for update verifications is very large, because each update requires updating of all replicas, where verification for each update requires O(log n ) communication complexity. Second, existing schemes cannot provide public auditing and authentication of block indices at the same time. Without authentication of block indices, the server can build a valid proof based on data blocks other than the blocks client requested to verify. In order to address these problems, in this paper, we present a novel public auditing scheme named MuR-DPA. The new scheme incorporated a novel authenticated data structure (ADS) based on the Merkle hash tree (MHT), which we call MR-MHT. To support full dynamic data updates and authentication of block indices, we included rank and level values in computation of MHT nodes. In contrast to existing schemes, level values of nodes in MR-MHT are assigned in a top-down order, and all replica blocks for each data block are organized into a same replica sub-tree. Such a configuration allows efficient verification of updates for multiple replicas. Compared to existing integrity verification and public auditing schemes, theoretical analysis and experimental results show that the proposed MuR-DPA scheme can not only incur much less communication overhead for both update verification and integrity verification of cloud datasets with multiple replicas, but also provide enhanced security against dishonest cloud service providers.","Servers,
Big data,
Cloud computing,
Authentication,
Data structures,
Indexes"
Unsupervised Object Class Discovery via Saliency-Guided Multiple Class Learning,"In this paper, we tackle the problem of common object (multiple classes) discovery from a set of input images, where we assume the presence of one object class in each image. This problem is, loosely speaking, unsupervised since we do not know a priori about the object type, location, and scale in each image. We observe that the general task of object class discovery in a fully unsupervised manner is intrinsically ambiguous; here we adopt saliency detection to propose candidate image windows/patches to turn an unsupervised learning problem into a weakly-supervised learning problem. In the paper, we propose an algorithm for simultaneously localizing objects and discovering object classes via bottom-up (saliency-guided) multiple class learning (bMCL). Our contributions are three-fold: (1) we adopt saliency detection to convert unsupervised learning into multiple instance learning, formulated as bottom-up multiple class learning (bMCL); (2) we propose an integrated framework that simultaneously performs object localization, object class discovery, and object detector training; (3) we demonstrate that our framework yields significant improvements over existing methods for multi-class object discovery and possess evident advantages over competing methods in computer vision. In addition, although saliency detection has recently attracted much attention, its practical usage for high-level vision tasks has yet to be justified. Our method validates the usefulness of saliency detection to output “noisy input” for a top-down method to extract common patterns.","Clustering algorithms,
Unsupervised learning,
Object detection,
Algorithm design and analysis,
Detectors,
Training,
Electronic mail"
Salient Region Detection via Integrating Diffusion-Based Compactness and Local Contrast,"Salient region detection is a challenging problem and an important topic in computer vision. It has a wide range of applications, such as object recognition and segmentation. Many approaches have been proposed to detect salient regions using different visual cues, such as compactness, uniqueness, and objectness. However, each visual cue-based method has its own limitations. After analyzing the advantages and limitations of different visual cues, we found that compactness and local contrast are complementary to each other. In addition, local contrast can very effectively recover incorrectly suppressed salient regions using compactness cues. Motivated by this, we propose a bottom-up salient region detection method that integrates compactness and local contrast cues. Furthermore, to produce a pixel-accurate saliency map that more uniformly covers the salient objects, we propagate the saliency information using a diffusion process. Our experimental results on four benchmark data sets demonstrate the effectiveness of the proposed method. Our method produces more accurate saliency maps with better precision-recall curve and higher F-Measure than other 19 state-of-the-arts approaches on ASD, CSSD, and ECSSD data sets.",
"3D Perception Based Quality Pooling: Stereopsis, Binocular Rivalry, and Binocular Suppression","One of the most challenging ongoing issues in the field of 3D visual research is how to interpret human 3D perception over virtual 3D space between the human eye and a 3D display. When a human being perceives a 3D structure, the brain classifies the scene into the binocular or monocular vision region depending on the availability of binocular depth perception in the unit of a certain region (coarse 3D perception). The details of the scene are then perceived by applying visual sensitivity to the classified 3D structure (fine 3D perception) with reference to the fixation. Furthermore, we include the coarse and fine 3D perception in the quality assessment, and propose a human 3D Perception-based Stereo image quality pooling (3DPS) model. In 3DPS we divide the stereo image into segment units, and classify each segment as either the binocular or monocular vision region. We assess the stereo image according to the classification by applying different visual weights to the pooling method to achieve more accurate quality assessment. In particular, it is demonstrated that 3DPS performs remarkably for quality assessment of stereo images distorted by coding and transmission errors.","Three-dimensional displays,
Visualization,
Sensitivity,
Image segmentation,
Quality assessment,
Image quality"
Cloud-Based Collaborative 3D Mapping in Real-Time With Low-Cost Robots,"This paper presents an architecture, protocol, and parallel algorithms for collaborative 3D mapping in the cloud with low-cost robots. The robots run a dense visual odometry algorithm on a smartphone-class processor. Key-frames from the visual odometry are sent to the cloud for parallel optimization and merging with maps produced by other robots. After optimization the cloud pushes the updated poses of the local key-frames back to the robots. All processes are managed by Rapyuta, a cloud robotics framework that runs in a commercial data center. This paper includes qualitative visualization of collaboratively built maps, as well as quantitative evaluation of localization accuracy, bandwidth usage, processing speeds, and map storage.","Robot sensing systems,
Visualization,
Optimization,
Robot kinematics,
Cloning,
Three-dimensional displays"
Robust Integral of Neural Network and Error Sign Control of MIMO Nonlinear Systems,"This paper presents a novel state-feedback control scheme for the tracking control of a class of multi-input multioutput continuous-time nonlinear systems with unknown dynamics and bounded disturbances. First, the control law consisting of the robust integral of a neural network (NN) output plus sign of the tracking error feedback multiplied with an adaptive gain is introduced. The NN in the control law learns the system dynamics in an online manner, while the NN residual reconstruction errors and the bounded disturbances are overcome by the error sign signal. Since both of the NN output and the error sign signal are included in the integral, the continuity of the control input is ensured. The controller structure and the NN weight update law are novel in contrast with the previous effort, and the semiglobal asymptotic tracking performance is still guaranteed by using the Lyapunov analysis. In addition, the NN weights and all other signals are proved to be bounded simultaneously. The proposed approach also relaxes the need for the upper bounds of certain terms, which are usually required in the previous designs. Finally, the theoretical results are substantiated with simulations.","Artificial neural networks,
Robustness,
Stability analysis,
Approximation methods,
Asymptotic stability,
Nonlinear systems"
Utility Function-Based Real-Time Control of A Battery Ultracapacitor Hybrid Energy System,"This paper discusses a utility function-based control of a battery-ultracapacitor (UC) hybrid energy system. The example system employs the battery semiactive topology. In order to represent different performance and requirements of the battery and UC packs, the two packs are modeled as two independent but related agents using the NetLogo environment. Utility functions are designed to describe the respective preferences of battery and UC packs. Then, the control problem is converted to a multiobjective optimization problem solved by using the Karush-Kuhn-Tucker (KKT) conditions. The weights in the objective functions are chosen based on the location of the knee point in the Pareto set. Both the simulation and experimental results show the utility function-based control provides a comparable performance with the ideal average load demand (ALD)-based control, while the exact preknowledge of the future load demand is not required. The utility function-based control is fast enough to be directly implemented in real time. The discussion in this paper gives a starting point and initial results for dealing with more complex hybrid energy systems.","Batteries,
Optimization,
Load modeling,
Informatics,
Supercapacitors,
DC-DC power converters"
Potential Harmonic Resonance Impacts of PV Inverter Filters on Distribution Systems,"This paper presents a clarification study to identify the potential resonance phenomenon between photovoltaic (PV) inverters and the distribution system. LCL and LC filters are widely applied in PV inverters to mitigate high-order harmonic components generated by PV inverters. There is a possibility that these filters will excite harmonic resonance by interacting with the system impedance. The mechanism of this phenomenon is investigated here by mathematical analysis and measurement. The results indicate that the resonance can be attenuated if the damping resistance, such as damping resistor and residential linear loads, is large enough. Alternatively, three sets of field tests are conducted in the laboratory to verify and clarify the potential harmonic resonance and its factors. Furthermore, a full case of an actual North American distribution system with PV installations is also studied. The results indicate that the harmonic resonance caused by the PV filter is almost attenuated and cannot cause serious problems. At the same time, the filter may have some advantages in mitigating harmonics. Finally, to complete this paper, other sustainable energy resources with voltage-source converters (VSCs) are compared.","Inverters,
Damping,
Impedance,
Harmonic analysis,
Power harmonic filters,
Resistance,
Converters"
Balancing backhaul load in heterogeneous cloud radio access networks,"Inspired by the explosive growth of mobile data traffic, the severe inter-tier interference, and the fierce competition between the total cost of ownership and revenues for mobile operators, the heterogeneous cloud radio access network (H-CRAN) has been proposed as one of the most prominent ways to handle these challenges. The key idea of the H-CRAN is incorporating cloud computing into a heterogeneous network (HetNet) to enhance coordinated multipoint transmission and reception, cooperative radio resource management, and self-organizing networks, which improve both spectral and energy efficiencies of cellular systems. One of the most critical challenges that hinder the implementation of the H-CRAN is the high transmission demand on the backhauls between the baseband unit (BBU) pool and remote radio heads (RRHs). In this article we suggest that we can balance the workload of different RRHs to alleviate the pressure on the transmission links. Our proposed method is different from but compatible with existing compression techniques that have been widely investigated in the literature to lighten the transmission burden of the backhauls. We also describe the technical challenges in existence during the implementation of our proposal and give preliminary ideas of how to address them.","Bandwidth,
Computer architecture,
Data communication,
Interference,
Radio frequency,
Radio access networks,
Cloud computing"
Quality of Energy Provisioning for Wireless Power Transfer,"One fundamental question for wireless power transfer technology is the energy provisioning problem, i.e., how to provide sufficient energy to mobile rechargeable nodes for their continuous operation. Most existing works overlooked the impacts of node speed and battery capacity. However, we find that if the constraints of node speed and battery capacity are considered, the continuous operation of nodes may never be guaranteed, which invalidates the traditional energy provisioning concept. In this paper, we propose a novel metric-Quality of Energy Provisioning (QoEP)-to characterize the expected portion of time that a node sustains normal operation by taking into account node speed and battery capacity. To avoid confining the analysis to a specific mobility model, we study spatial distribution instead. As there exist more than one mobility models corresponding to the same spatial distribution, and different mobility models typically lead to different QoEPs, we investigate upper and lower bounds of QoEP in 1D and 2D cases. We derive tight upper and lower bounds of QoEP for 1D case with a single source, and tight lower bounds and loose upper bounds for general 1D and 2D cases with multiple sources. Finally, we perform extensive simulations to verify our theoretical findings.","Batteries,
Wireless communication,
Wireless sensor networks,
Sensors,
Graphical models,
Distribution functions,
Mobile communication"
"EJS, JIL Server, and LabVIEW: An Architecture for Rapid Development of Remote Labs","Designing and developing web-enabled remote laboratories for pedagogical purposes is not an easy task. Often, developers (generally, educators who know the subjects they teach but lack of the technical and programming skills required to build Internet-based educational applications) end up discarding the idea of exploring these new teaching and learning experiences mainly due to the technical issues that must be mastered. To tackle this problem, authors present a novel technique that allows developers to create remote labs in a quick, didactical, and straightforward way. This framework is based on the use of two well-known software tools in the scope of engineering education, Easy Java Simulations and LabVIEW. The development exploits a new feature of Easy Java Simulations known as EJS-elements that enables Java developers to create and integrate their own authoring libraries (elements) into EJS, thus increasing its application possibilities. Particularly, the EJS element here presented allows to LabVIEW programs be controlled from EJS applications through a communication network. This paper presents the element creation details and how this can be used to create web-enabled experimentation environments for educational purposes. A step by step example of development of a remote lab for automatic control education is described.","Servers,
Java,
Education,
Laboratories,
Remote laboratories"
Measurements of Matching and Noise Performance of a Prototype Readout Chip in 40 nm CMOS Process for Hybrid Pixel Detectors,"The paper presents a prototype integrated circuit built in a 40 nm CMOS process for readout of a hybrid pixel detector. The core of the IC constitutes a matrix of 18 ×24 pixels with the pixel size of 100 μm ×100 μm. The paper explains the functionality and the architecture of the IC, which is designed to operate in both the standard single photon counting mode and the single photon counting mode with interpixel communication to mitigate negative effects of charge sharing. This article focuses on the measurement results of the IC operating in the standard single photon counting mode. The measured ENC is 84e- rms (for the peaking time of 48 ns), the gain is 79.7 μV/e-, while the effective threshold dispersion is 21e- rms.","Transistors,
Noise,
Resistance,
Photonics,
Detectors,
Integrated circuits,
Capacitance"
Versatile CMOS-MEMS integrated piezoelectric platform,"We present the extension of the InvenSense fabrication platform to piezoelectric transduction. The newly proposed CMOS-MEMS Integrated Piezoelectric Platform inherits the wafer bonding advantages of its predecessor, leverages existing semiconductor infrastructure, and is applicable to a wide range of applications.",
Gabor Filter Based on Stochastic Computation,"This letter introduces a design and proof-of-concept implementation of Gabor filters based on stochastic computation for area-efficient hardware. The Gabor filter exhibits a powerful image feature extraction capability, but it requires significant computational power. Using stochastic computation, a sine function used in the Gabor filter is approximated by exploiting several stochastic tanh functions designed based on a state machine. A stochastic Gabor filter realized using the stochastic sine shaper and a stochastic exponential function is simulated and compared with the original Gabor filter that shows almost equivalent behaviour at various frequencies and variance. A root-mean-square error of 0.043 at most is observed. In order to reduce long latency due to stochastic computation, 68 parallel stochastic Gabor filters are implemented in Silterra 0.13 μm CMOS technology. As a result, the proposed Gabor filters achieve a 78% area reduction compared with a conventional Gabor filter while maintaining the comparable speed.","Hardware,
Logic gates,
Educational institutions,
Input variables,
Digital circuits,
Materials,
Computers"
A Micro-Power Two-Step Incremental Analog-to-Digital Converter,"Integrated sensor interface circuits require energy-efficient high-resolution data converters. This paper proposes a two-step incremental A/D converter (IADC) which extends the performance of an Nth-order IADC close to that of a (2N-1)th-order IADC. The implemented device uses the circuitry of a second-order IADC (IADC2) to achieve close to third-order SNR performance. The proposed circuit does not require very high opamp DC gain; the gain can be as low as 60 dB for 100 dB SNR data conversion. The implemented IADC achieves a measured dynamic range of 99.8 dB, and an SNDR of 91 dB for a maximum input 2.2 VPP and a bandwidth of 250 Hz. Fabricated in 65 nm CMOS, the IADC's core area is 0.2 mm2, and it consumes only 10.7 μW. The measured FoMs are 0.76 pJ/conversion and 173.5 dB, both among the best reported results for IADCs. The measured results verify that the proposed two-step IADC is a more energy-efficient data conversion scheme than conventional high-order IADCs.","Quantization (signal),
Modulation,
Hardware,
Clocks,
Multi-stage noise shaping,
Analog-digital conversion"
"Robust Consensus Tracking Control for Multiagent Systems With Initial State Shifts, Disturbances, and Switching Topologies","This paper deals with the consensus tracking control issues of multiagent systems and aims to solve them as accurately as possible over a finite time interval through an iterative learning approach. Based on the iterative rule, distributed algorithms are proposed for every agent using its nearest neighbor knowledge, for which the robustness problem is addressed against initial state shifts, disturbances, and switching topologies. These uncertainties are dynamically changing not only along the time axis but also the iteration axis. It is shown that the matrix norm conditions can be developed to achieve the convergence of the considered consensus tracking objectives, for which necessary and sufficient conditions are presented in terms of linear matrix inequalities to guarantee their feasibility in the sense of the spectral norm. Furthermore, simulation examples are given to illustrate the effectiveness and robustness of the obtained consensus tracking results.","Multi-agent systems,
Robustness,
Convergence,
Vectors,
Zinc,
Switches"
Blind Image Quality Assessment for Stereoscopic Images Using Binocular Guided Quality Lookup and Visual Codebook,"The field of assessing three-dimensional (3-D) visual experience is challenging. In this paper, we propose a new blind image quality assessment for stereoscopic images by using binocular guided quality lookup and visual codebook. To be more specific, in the training stage, we construct phase-tuned quality lookup (PTQL) and phase-tuned visual codebook (PTVC) from the binocular energy responses based on stimuli from different spatial frequencies, orientations, and phase shifts. In the test stage, blind quality pooling can be easily achieved by searching the PTQL and PTVC, and the quality score is obtained by averaging the largest values of all patch's quality. Experimental results on three 3-D image quality assessment databases demonstrate that in comparison with the most related existing methods, the devised algorithm achieves high consistency alignment with subjective assessment and low-complexity pooling.","Stereo image processing,
Visualization,
Three-dimensional displays,
Training,
Image quality,
Databases,
Measurement"
Vector Sparse Representation of Color Image Using Quaternion Matrix Analysis,"Traditional sparse image models treat color image pixel as a scalar, which represents color channels separately or concatenate color channels as a monochrome image. In this paper, we propose a vector sparse representation model for color images using quaternion matrix analysis. As a new tool for color image representation, its potential applications in several image-processing tasks are presented, including color image reconstruction, denoising, inpainting, and super-resolution. The proposed model represents the color image as a quaternion matrix, where a quaternion-based dictionary learning algorithm is presented using the K-quaternion singular value decomposition (QSVD) (generalized K-means clustering for QSVD) method. It conducts the sparse basis selection in quaternion space, which uniformly transforms the channel images to an orthogonal color space. In this new color space, it is significant that the inherent color structures can be completely preserved during vector reconstruction. Moreover, the proposed sparse model is more efficient comparing with the current sparse models for image restoration tasks due to lower redundancy between the atoms of different color channels. The experimental results demonstrate that the proposed sparse image model avoids the hue bias issue successfully and shows its potential as a general and powerful tool in color image analysis and processing domain.",
Context-Based Access Control Systems for Mobile Devices,"Mobile Android applications often have access to sensitive data and resources on the user device. Misuse of this data by malicious applications may result in privacy breaches and sensitive data leakage. An example would be a malicious application surreptitiously recording a confidential business conversation. The problem arises from the fact that Android users do not have control over the application capabilities once the applications have been granted the requested privileges upon installation. In many cases, however, whether an application may get a privilege depends on the specific user context and thus we need a context-based access control mechanism by which privileges can be dynamically granted or revoked to applications based on the specific context of the user. In this paper we propose such an access control mechanism. Our implementation of context differentiates between closely located sub-areas within the same location. We have modified the Android operating system so that context-based access control restrictions can be specified and enforced. We have performed several experiments to assess the efficiency of our access control mechanism and the accuracy of context detection.","Context,
Androids,
Humanoid robots,
Access control,
Global Positioning System,
IEEE 802.11 Standards,
Smart phones"
Towards Effective Bug Triage with Software Data Reduction Techniques,"Software companies spend over 45 percent of cost in dealing with software bugs. An inevitable step of fixing bugs is bug triage, which aims to correctly assign a developer to a new bug. To decrease the time cost in manual work, text classification techniques are applied to conduct automatic bug triage. In this paper, we address the problem of data reduction for bug triage, i.e., how to reduce the scale and improve the quality of bug data. We combine instance selection with feature selection to simultaneously reduce data scale on the bug dimension and the word dimension. To determine the order of applying instance selection and feature selection, we extract attributes from historical bug data sets and build a predictive model for a new bug data set. We empirically investigate the performance of data reduction on totally 600,000 bug reports of two large open source projects, namely Eclipse and Mozilla. The results show that our data reduction can effectively reduce the data scale and improve the accuracy of bug triage. Ourwork provides an approach to leveraging techniques on data processing to form reduced and high-quality bug data in software development and maintenance.","Computer bugs,
Software,
Accuracy,
Text categorization,
Feature extraction,
Prediction algorithms"
Circular Switching Surface Technique: High-Performance Constant Power Load Stabilization for Electric Vehicle Systems,"Electric vehicles make use of energy storage systems, such as batteries and/or ultracapacitors to power the electric power drive train, as well as auxiliary automotive system for control, safety, and comfort. This relatively complex power structure can be described as a distributed multiconverter system. The constant power behavior of tight-speed controllers in the vehicle's traction system and tightly regulated dc-dc converters connected to the HV-DC bus produces instability effects. This paper proposes a simple and practical geometric control, using circular switching surfaces, to address constant power load instability in electric vehicle's power systems. The proposed switching surfaces provide a solution in the geometrical domain to constant power loading conditions, while achieving outstanding dynamic response compared to state-of-the-art controllers. The controller is implemented in a bidirectional Buck + Boost cascade converter as a battery charge/discharge unit and ensures reliable system operation. The predictable and consistent behavior of the converter with constant power load is presented by analyzing the system curves in the normalized state plane with the switching surfaces employed. Simulation and experimental results on a scaled 1-kW Buck + Boost cascade converter validate the proposed switching surfaces and predictions regarding the converter's behavior under constant power loading conditions.",
History-Based Topological Speciation for Multimodal Optimization,"Evolutionary algorithms integrating various niching techniques have been widely used to find multiple optima of an optimization problem. In recent years, an increasing amount of research has been focused on the design and application of speciation-based niching techniques. These techniques rely on speciation to partition a population into subpopulations (species) such that each occupies a different region of attraction (niche) on the fitness landscape. Existing speciation methods are either distance-based or topology-based. Topology-based methods are more flexible and have fewer assumptions than distance-based methods. However, existing topology-based methods all require sampling and evaluating new individuals in order to capture the landscape topography. This incurs additional fitness evaluations (FEs), which is a drawback, especially when the FE budget is limited. In this paper, a new topology-based speciation method named history-based topological speciation (HTS) is proposed. It relies exclusively on search history to capture the landscape topography and, therefore, does not require any additional FEs to be performed. To the best of our knowledge, HTS is the only parameter-free speciation method at the moment. Both theoretical and empirical analyses have been conducted. Theoretical analysis shows that HTS incurs acceptable computational overhead. In the experimental study, HTS outperformed existing topology-based methods on benchmark functions in up to 32-D space and with as many as 50 optima, and the time overhead was practically negligible if a single FE took seconds.","Optimization,
Approximation methods,
History,
Iron,
Sociology,
Statistics,
High-temperature superconductors"
Fast and Epsilon-Optimal Discretized Pursuit Learning Automata,"Learning automata (LA) are powerful tools for reinforcement learning. A discretized pursuit LA is the most popular one among them. During an iteration its operation consists of three basic phases: 1) selecting the next action; 2) finding the optimal estimated action; and 3) updating the state probability. However, when the number of actions is large, the learning becomes extremely slow because there are too many updates to be made at each iteration. The increased updates are mostly from phases 1 and 3. A new fast discretized pursuit LA with assured ε-optimality is proposed to perform both phases 1 and 3 with the computational complexity independent of the number of actions. Apart from its low computational complexity, it achieves faster convergence speed than the classical one when operating in stationary environments. This paper can promote the applications of LA toward the large-scale-action oriented area that requires efficient reinforcement learning tools with assured ε-optimality, fast convergence speed, and low computational complexity for each iteration.","Computational complexity,
Vectors,
Learning automata,
Convergence,
Automata,
Pursuit algorithms,
Cybernetics"
Accelerometer-Based Gait Recognition by Sparse Representation of Signature Points With Clusters,"Gait, as a promising biometric for recognizing human identities, can be nonintrusively captured as a series of acceleration signals using wearable or portable smart devices. It can be used for access control. Most existing methods on accelerometer-based gait recognition require explicit step-cycle detection, suffering from cycle detection failures and intercycle phase misalignment. We propose a novel algorithm that avoids both the above two problems. It makes use of a type of salient points termed signature points (SPs), and has three components: 1) a multiscale SP extraction method, including the localization and SP descriptors; 2) a sparse representation scheme for encoding newly emerged SPs with known ones in terms of their descriptors, where the phase propinquity of the SPs in a cluster is leveraged to ensure the physical meaningfulness of the codes; and 3) a classifier for the sparse-code collections associated with the SPs of a series. Experimental results on our publicly available dataset of 175 subjects showed that our algorithm outperformed existing methods, even if the step cycles were perfectly detected for them. When the accelerometers at five different body locations were used together, it achieved the rank-1 accuracy of 95.8% for identification, and the equal error rate of 2.2% for verification.",
Tweet Segmentation and Its Application to Named Entity Recognition,"Twitter has attracted millions of users to share and disseminate most up-to-date information, resulting in large volumes of data produced everyday. However, many applications in Information Retrieval (IR) and Natural Language Processing (NLP) suffer severely from the noisy and short nature of tweets. In this paper, we propose a novel framework for tweet segmentation in a batch mode, called HybridSeg. By splitting tweets into meaningful segments, the semantic or context information is well preserved and easily extracted by the downstream applications. HybridSeg finds the optimal segmentation of a tweet by maximizing the sum of the stickiness scores of its candidate segments. The stickiness score considers the probability of a segment being a phrase in English (i.e., global context) and the probability of a segment being a phrase within the batch of tweets (i.e., local context). For the latter, we propose and evaluate two models to derive local context by considering the linguistic features and term-dependency in a batch of tweets, respectively. HybridSeg is also designed to iteratively learn from confident segments as pseudo feedback. Experiments on two tweet data sets show that tweet segmentation quality is significantly improved by learning both global and local contexts compared with using global context alone. Through analysis and comparison, we show that local linguistic features are more reliable for learning local context compared with term-dependency. As an application, we show that high accuracy is achieved in named entity recognition by applying segment-based part-of-speech (POS) tagging.","Context,
Encyclopedias,
Electronic publishing,
Internet,
Pragmatics,
Semantics"
E-Tree: An Efficient Indexing Structure for Ensemble Models on Data Streams,"Ensemble learning is a common tool for data stream classification, mainly because of its inherent advantages of handling large volumes of stream data and concept drifting. Previous studies, to date, have been primarily focused on building accurate ensemble models from stream data. However, a linear scan of a large number of base classifiers in the ensemble during prediction incurs significant costs in response time, preventing ensemble learning from being practical for many real-world time-critical data stream applications, such as Web traffic stream monitoring, spam detection, and intrusion detection. In these applications, data streams usually arrive at a speed of GB/second, and it is necessary to classify each stream record in a timely manner. To address this problem, we propose a novel Ensemble-tree (E-tree for short) indexing structure to organize all base classifiers in an ensemble for fast prediction. On one hand, E-trees treat ensembles as spatial databases and employ an R-tree like height-balanced structure to reduce the expected prediction time from linear to sub-linear complexity. On the other hand, E-trees can be automatically updated by continuously integrating new classifiers and discarding outdated ones, well adapting to new trends and patterns underneath data streams. Theoretical analysis and empirical studies on both synthetic and real-world data streams demonstrate the performance of our approach.","Spatial databases,
Indexing,
Data models,
Monitoring,
Market research,
Adaptation models"
Towards Cost-Efficient Video Transcoding in Media Cloud: Insights Learned From User Viewing Patterns,"Video transcoding in an adaptive bitrate streaming (ABR) system is demanded to support video streaming over heterogenous devices and varying networks. However, it could incur a tremendous cost. Meanwhile, most viewers terminate viewing sessions within 20% of their durations; only a small fraction of each video is consumed. Built upon this user viewing pattern, we propose a Partial Transcoding Scheme for content management in media clouds. Particularly, each content is encoded into different bitrates and split into segments. Some of the segments are stored in cache, resulting in storage cost; others are transcoded online in the case of cache miss, resulting in computing cost. We aim to minimize the long-term overall cost by determining whether a segment should be cached or transcoded online. We formulate it as a constrained stochastic optimization problem. Leveraging Lyapunov optimization framework and Lagrangian relaxation, we design an online algorithm which can achieve the optimal solution within provable upper bounds. Experiments demonstrate that our proposed method can reduce 30% of operational cost, compared with the scheme of caching all the segments.","Streaming media,
Transcoding,
Bit rate,
Optimization,
Engines,
Media,
Content management"
Discrete-Time Zhang Neural Network for Online Time-Varying Nonlinear Optimization With Application to Manipulator Motion Generation,"In this brief, a discrete-time Zhang neural network (DTZNN) model is first proposed, developed, and investigated for online time-varying nonlinear optimization (OTVNO). Then, Newton iteration is shown to be derived from the proposed DTZNN model. In addition, to eliminate the explicit matrix-inversion operation, the quasi-Newton Broyden-Fletcher-Goldfarb-Shanno (BFGS) method is introduced, which can effectively approximate the inverse of Hessian matrix. A DTZNN-BFGS model is thus proposed and investigated for OTVNO, which is the combination of the DTZNN model and the quasiNewton BFGS method. In addition, theoretical analyses show that, with step-size h = 1 and/or with zero initial error, the maximal residual error of the DTZNN model has an O(τ2) pattern, whereas the maximal residual error of the Newton iteration has an O(τ) pattern, with τ denoting the sampling gap. Besides, when h ≠ 1 and h ∈ (0, 2), the maximal steady-state residual error of the DTZNN model has an O(τ2) pattern. Finally, an illustrative numerical experiment and an application example to manipulator motion generation are provided and analyzed to substantiate the efficacy of the proposed DTZNN and DTZNN-BFGS models for OTVNO.","Numerical models,
Computational modeling,
Optimization,
Vectors,
Neural networks,
Steady-state,
Approximation methods"
Belief Propagation Algorithms on Noisy Hardware,"The wide recognition that emerging nano-devices will be inherently unreliable motivates the evaluation of information processing algorithms running on noisy hardware as well as the design of robust schemes for reliable performance against hardware errors of varied characteristics. In this paper, we investigate the performance of a popular statistical inference algorithm, belief propagation (BP) on probabilistic graphical models, implemented on noisy hardware, and we propose two robust implementations of the BP algorithm targeting different computation noise distributions. We assume that the BP messages are subject to zero-mean transient additive computation noise. We focus on graphical models satisfying the contraction mapping condition that guarantees the convergence of the noise-free BP. We first upper bound the distances between the noisy BP messages and the fixed point of (noise-free) BP as a function of the iteration number. Next, we propose two implementations of BP, namely, censoring BP and averaging BP, that are robust to computation noise. Censoring BP rejects incorrect computations to keep the algorithm on the right track to convergence, while averaging BP takes the average of the messages in all iterations up to date to mitigate the effects of computation noise. Censoring BP works effectively when, with high probability, the computation noise is exactly zero, and averaging BP, although having a slightly larger overhead, works effectively for general zero-mean computation noise distributions. Sufficient conditions on the convergence of censoring BP and averaging BP are derived. Simulations on the Ising model demonstrate that the two proposed implementations successfully converge to the fixed point achieved by noise-free BP. Additionally, we apply averaging BP to a BP-based image denoising algorithm and as a BP decoder for LDPC codes. In the image denoising application, averaging BP successfully denoises an image even when nominal BP fails to do so in the presence of computation noise. In the BP LDPC decoder application, the power of averaging BP is manifested by the reduction in the residual error rates compared with the nominal BP decoder.","Noise,
Noise measurement,
Computational modeling,
Hardware,
Convergence,
Decoding,
Transient analysis"
Effect of Degradation in Molecular Communication: Impairment or Enhancement?,"In the nanonetworking literature, many solutions have been suggested to enable the nanomachine-to-nanomachine communication. Among these solutions, this paper focuses on what constitutes the basis for molecular communication paradigms- molecular communication via diffusion. In this paper, the channel for a spherical absorbing receiver under messenger molecule degradation is analytically modeled and the formulations are shown to be in agreement with the simulation results of the same topology. Next, the paper identifies how signal characteristics such as pulse peak time and pulse amplitude are affected by degradation. Indeed, it is analytically shown how signal shaping is achieved through degradation. This paper also compares communication under messenger molecule degradation with the case of no-degradation and electromagnetic communication in terms of channel characteristics. Lastly, the paper evaluates the communication performance of the scenarios having various degradation rates. Here, the system performance is assessed according to the traditional network metrics such as the level of intersymbol interference, detection performance, bit error rate, and symbol rate. The results indicate that introducing degradation significantly improves the system performance when the rate of degradation is appropriately selected. The analysis is done by taking different detection thresholds, symbol durations, and communication distances into account.","Degradation,
Receivers,
Molecular communication,
Substrates,
Neurons,
Transmitters"
An Operations Research Game Approach for Resource and Power Allocation in Cooperative Femtocell Networks,"Femtocells are emerging as a key technology to improve coverage and network capacity in indoor environments. When femtocells use different frequency bands than macrocells (i.e., split-spectrum approach), femto-to-femto interference remains the major issue. In particular, congestion cases in which femtocell demands exceed the available resources raise several challenging questions: how much a femtocell can demand? how much it can obtain? and how this shall depends on the interference with its neighbors? Strategic interference management between femtocells via power control and resource allocation mechanisms is needed to avoid performance degradation during congestion cases. In this paper, we model the resource and power allocation problem as an operations research game, where imputations are deduced from cooperative game theory, namely the Shapley value and the Nucleolus, using utility components results of partial optimizations. Based on these evaluations, users' demands are first rescaled to strategically justified values. Then, a power-level and throughput optimization using the rescaled demands is conducted. The performance of the developed solutions is analyzed and extensive simulation results are presented to illustrate their potential advantages. In particular, we show that the Shapley value solution with power control offers the overall best performance in terms of throughput, fairness, spectrum spatial reuse, and transmit power, with a slightly higher time complexity compared to alternative solutions.","Interference,
Games,
Resource management,
Optimization,
Mobile computing,
Femtocell networks"
Hyperspectral Face Recognition With Spatiospectral Information Fusion and PLS Regression,"Hyperspectral imaging offers new opportunities for face recognition via improved discrimination along the spectral dimension. However, it poses new challenges, including low signal-to-noise ratio, interband misalignment, and high data dimensionality. Due to these challenges, the literature on hyperspectral face recognition is not only sparse but is limited to ad hoc dimensionality reduction techniques and lacks comprehensive evaluation. We propose a hyperspectral face recognition algorithm using a spatiospectral covariance for band fusion and partial least square regression for classification. Moreover, we extend 13 existing face recognition techniques, for the first time, to perform hyperspectral face recognition. We formulate hyperspectral face recognition as an image-set classification problem and evaluate the performance of seven state-of-the-art image-set classification techniques. We also test six state-of-the-art grayscale and RGB (color) face recognition algorithms after applying fusion techniques on hyperspectral images. Comparison with the 13 extended and five existing hyperspectral face recognition techniques on three standard data sets show that the proposed algorithm outperforms all by a significant margin. Finally, we perform band selection experiments to find the most discriminative bands in the visible and near infrared response spectrum.","Hyperspectral imaging,
Face recognition,
Databases,
Face,
Vectors,
Gray-scale"
Adaptive Neural Stabilizing Controller for a Class of Mismatched Uncertain Nonlinear Systems by State and Output Feedback,"In this paper, first, an adaptive neural network (NN) state-feedback controller for a class of nonlinear systems with mismatched uncertainties is proposed. By using a radial basis function NN (RBFNN), a bound of unknown nonlinear functions is approximated so that no information about the upper bound of mismatched uncertainties is required. Then, an observer-based adaptive controller based on RBFNN is designed to stabilize uncertain nonlinear systems with immeasurable states. The state-feedback and observer-based controllers are based on Lyapunov and strictly positive real-Lyapunov stability theory, respectively, and it is shown that the asymptotic convergence of the closed-loop system to zero is achieved while maintaining bounded states at the same time. The presented methods are more general than the previous approaches, handling systems with no restriction on the dimension of the system and the number of inputs. Simulation results confirm the effectiveness of the proposed methods in the stabilization of mismatched nonlinear systems.","Artificial neural networks,
Uncertainty,
Vectors,
Nonlinear systems,
Adaptive systems,
Control systems,
Approximation methods"
The Art of Finding Accurate Memristor Model Solutions,"One of the main issues preventing a large-scale exploration of the full potential of memristors in electrical circuits lies in the convergence issues and numerical errors encountered in the computer-aided integration of the differential algebraic equation set governing the peculiar dynamical behavior of these nonlinear two-terminal electrical components. In most cases the complexity of this equation set prevents an analytical derivation of closed-form state solutions. Therefore the investigation of the nonlinear dynamics of memristors and circuits based upon them relies on software-based integration of the mathematical equations. In this paper, we highlight solution accuracy issues which may arise from an improper numerical integration of the equations, and then propose techniques addressing the problems properly. These guidelines represent a useful guide to engineers interested in the numerical analysis of memristor models.","Mathematical model,
Memristors,
Numerical models,
Integrated circuit modeling,
Switches,
Biological system modeling,
Numerical simulation"
Finding Critical Regions and Region-Disjoint Paths in a Network,"Due to their importance to society, communication networks should be built and operated to withstand failures. However, cost considerations make network providers less inclined to take robustness measures against failures that are unlikely to manifest, like several failures coinciding simultaneously in different geographic regions of their network. Considering networks embedded in a two-dimensional plane, we study the problem of finding a critical region-a part of the network that can be enclosed by a given elementary figure of predetermined size-whose destruction would lead to the highest network disruption. We determine that only a polynomial, in the input, number of nontrivial positions for such a figure needs to be considered and propose a corresponding polynomial-time algorithm. In addition, we consider region-aware network augmentation to decrease the impact of a regional failure. We subsequently address the region-disjoint paths problem, which asks for two paths with minimum total weight between a source (s) and a destination (d) that cannot both be cut by a single regional failure of diameter D (unless that failure includes s or d). We prove that deciding whether region-disjoint paths exist is NP-hard and propose a heuristic region-disjoint paths algorithm.","Measurement,
Robustness,
Complexity theory,
IEEE transactions,
Polynomials,
Conferences,
Computational modeling"
Direct Power Control of a Three-Phase Inverter for Grid Input Current Shaping of a Single-Phase Diode Rectifier With a Small DC-Link Capacitor,"This paper describes motor drive system fed by a single-phase diode rectifier without power factor correction (PFC) circuit or the input filter. The system considered in this paper consists of a single-phase diode rectifier, a three-phase inverter, and a small dc-link capacitor. Since dc-link capacitance of the proposed system is few microfarads, the shape of the grid input current is directly affected by electrical output power of the inverter. Using this aspect, two goals of the drive system, controlling torque of the motor and suppressing the grid input current harmonics, can be simultaneously achieved by controlling the output power of the inverter. The proposed method includes the motor current reference generation and the direct output power regulation by modifying the output voltage reference. With the proposed method, the harmonic components of the grid input current can be reduced under the limits of the regulation IEC61000-3-2, lower than those in the conventional method. Also, the cost and size of the inverter system can be significantly reduced by removing electrolytic dc-link capacitor and input filter from the system. The performance of the proposed shaping method was validated by the experimental results using the motor drive system with a 5μF film capacitor at dc link.","Capacitors,
Power generation,
Voltage control,
Inverters,
Motor drives,
Vectors,
Power harmonic filters"
Implementation of Arithmetic Operations With Time-Free Spiking Neural P Systems,"Spiking neural P systems (SN P systems) are a class of distributed parallel computing devices inspired from the way neurons communicate by means of spikes. In most applications of SN P systems, synchronization plays a key role which means the execution of a rule is completed in exactly one time unit (one step). However, such synchronization does not coincide with the biological fact: in biological nervous systems, the execution times of spiking rules cannot be known exactly. Therefore, a “realistic” system called time-free SN P systems were proposed, where the precise execution time of rules is removed. In this paper, we consider building arithmetical operation systems based on time-free SN P systems. Specifically, adder, subtracter, multiplier, and divider are constructed by using time-free SN P systems. The obtained systems always produce the same computation result independently from the execution time of the rules.",
A Novel Design for Memristor-Based Logic Switch and Crossbar Circuits,"Recently, it has been demonstrated that memristors can be utilized as logic gates, control switches as well as memory elements. In this paper, we analyze the different AND, OR, and NOT logic gates which are based on memristors. In addition, a novel design for a memristor-based switch is presented, which can be used in the peripheral read/write circuits of the memristor-based memory. Moreover, methods of consecutive read with long refresh intervals and fast write for the proposed design are also discussed. Another highlight of this work is the analysis of the proposed memristor-based crossbar architecture which has a series of excellent features, such as good-compatibility, high-density, non-volatility, low-power, and good-scalability. Simulation results also show that the proposed memory array has superior performances compared to other memristor-based arrays proposed in the existing technical literature.","Memristors,
Logic gates,
Voltage control,
Computer architecture,
Switches,
Logic circuits"
An Implantable RFID Sensor Tag toward Continuous Glucose Monitoring,"This paper presents a wirelessly powered implantable electrochemical sensor tag for continuous blood glucose monitoring. The system is remotely powered by a 13.56-MHz inductive link and utilizes an ISO 15693 radio frequency identification (RFID) standard for communication. This paper provides reliable and accurate measurement for changing glucose level. The sensor tag employs a long-term glucose sensor, a winding ferrite antenna, an RFID front-end, a potentiostat, a 10-bit sigma-delta analog to digital converter, an on-chip temperature sensor, and a digital baseband for protocol processing and control. A high-frequency external reader is used to power, command, and configure the sensor tag. The only off-chip support circuitry required is a tuned antenna and a glucose microsensor. The integrated chip fabricated in SMIC 0.13-μm CMOS process occupies an area of 1.2 mm × 2 mm and consumes 50 μW. The power sensitivity of the whole system is -4 dBm. The sensor tag achieves a measured glucose range of 0-30 mM with a sensitivity of 0.75 nA/mM.","Sugar,
Wireless sensor networks,
Wireless communication,
Coils,
Monitoring,
Temperature sensors,
Antennas"
"i
2
MapReduce: Incremental MapReduce for Mining Evolving Big Data","As new data and updates are constantly arriving, the results of data mining applications become stale and obsolete over time. Incremental processing is a promising approach to refreshing mining results. It utilizes previously saved states to avoid the expense of re-computation from scratch. In this paper, we propose i2MapReduce, a novel incremental processing extension to MapReduce, the most widely used frameworkfor mining big data. Compared with the state-of-the-art work on Incoop, i2MapReduce (i) performs key-value pair level incremental processing rather than task level re-computation, (ii) supports not only one-step computation but also more sophisticated iterative computation, which is widely used in data mining applications, and (iii) incorporates a set of novel techniques to reduce I/O overhead for accessing preserved fine-grain computation states. We evaluate i2MapReduce using a one-step algorithm and four iterative algorithms with diverse computation characteristics. Experimental results on Amazon EC2 show significant performance improvements of i2MapReduce compared to both plain and iterative MapReduce performing re-computation.","Indexes,
Data mining,
Engines,
Big data,
Programming,
Computational modeling,
Data models"
Robust High Dynamic Range Imaging by Rank Minimization,"This paper introduces a new high dynamic range (HDR) imaging algorithm which utilizes rank minimization. Assuming a camera responses linearly to scene radiance, the input low dynamic range (LDR) images captured with different exposure time exhibit a linear dependency and form a rank-1 matrix when stacking intensity of each corresponding pixel together. In practice, misalignments caused by camera motion, presences of moving objects, saturations and image noise break the rank-1 structure of the LDR images. To address these problems, we present a rank minimization algorithm which simultaneously aligns LDR images and detects outliers for robust HDR generation. We evaluate the performances of our algorithm systematically using synthetic examples and qualitatively compare our results with results from the state-of-the-art HDR algorithms using challenging real world examples.","Cameras,
Minimization,
Dynamic range,
Robustness,
Heuristic algorithms,
Image reconstruction"
Subspace Methods for Data Attack on State Estimation: A Data Driven Approach,"Data attacks on state estimation modify part of system measurements such that the tempered measurements cause incorrect system state estimates. Attack techniques proposed in the literature often require detailed knowledge of system parameters. Such information is difficult to acquire in practice. The subspace methods presented in this paper, on the other hand, learn the system operating subspace from measurements and launch attacks accordingly. Conditions for the existence of an unobservable subspace attack are obtained under the full and partial measurement models. Using the estimated system subspace, two attack strategies are presented. The first strategy aims to affect the system state directly by hiding the attack vector in the system subspace. The second strategy misleads the bad data detection mechanism so that data not under attack are removed. Performance of these attacks are evaluated using the IEEE 14-bus network and the IEEE 118-bus network.","State estimation,
Mathematical model,
Robot sensing systems,
Power grids,
Current measurement,
Real-time systems,
Network topology"
Multimodal Registration via Mutual Information Incorporating Geometric and Spatial Context,"Multimodal image registration is a class of algorithms to find correspondence from different modalities. Since different modalities do not exhibit the same characteristics, finding accurate correspondence still remains a challenge. To deal with this, mutual information (MI)-based registration has been a preferred choice as MI is based on the statistical relationship between both volumes to be registered. However, MI has some limitations. First, MI-based registration often fails when there are local intensity variations in the volumes. Second, MI only considers the statistical intensity relationships between both volumes and ignores the spatial and geometric information about the voxel. In this work, we propose to address these limitations by incorporating spatial and geometric information via a 3D Harris operator. In particular, we focus on the registration between a high-resolution image and a low-resolution image. The MI cost function is computed in the regions where there are large spatial variations such as corner or edge. In addition, the MI cost function is augmented with geometric information derived from the 3D Harris operator applied to the high-resolution image. The robustness and accuracy of the proposed method were demonstrated using experiments on synthetic and clinical data including the brain and the tongue. The proposed method provided accurate registration and yielded better performance over standard registration methods.","Three-dimensional displays,
Image registration,
Joints,
Mutual information,
Image resolution,
Splines (mathematics),
Magnetic resonance imaging"
False rumors detection on Sina Weibo by propagation structures,"This paper studies the problem of automatic detection of false rumors on Sina Weibo, the popular Chinese microblogging social network. Traditional feature-based approaches extract features from the false rumor message, its author, as well as the statistics of its responses to form a flat feature vector. This ignores the propagation structure of the messages and has not achieved very good results. We propose a graph-kernel based hybrid SVM classifier which captures the high-order propagation patterns in addition to semantic features such as topics and sentiments. The new model achieves a classification accuracy of 91.3% on randomly selected Weibo dataset, significantly higher than state-of-the-art approaches. Moreover, our approach can be applied at the early stage of rumor propagation and is 88% confident in detecting an average false rumor just 24 hours after the initial broadcast.",
A Hybrid Neuro-Fuzzy Network Based on Differential Biogeography-Based Optimization for Online Population Classification in Earthquakes,"Timely and accurate identification and classification of victims in earthquakes is crucial for improving rescue efficiency, but available information about victims and their surrounding environment is often vague and imprecise. Rescue wings is a web-based intelligent system that monitors and analyzes the statuses of identified victims to support decision making in earthquake rescue operations. A key component of the system is a Takagi-Sugeno (T-S)-type neuro-fuzzy network for disaster-stricken population classification, and one important input of the network is the output of another T-S-type recurrent neuro-fuzzy network for recognizing the movement patterns from the users' temporal location data. A novel differential biogeography-based optimization (DBBO) algorithm is developed for parameter optimization of both the main network and the subnetwork. Experimental results have shown that the hybrid neuro-fuzzy network exhibits good classification performance in comparison with some other typical neuro-fuzzy networks, and the proposed DBBO outperforms some state-of-the-art evolutionary algorithms in network learning. The solution approach has also been successfully applied to the 2013 Ya'an Earthquake in Sichuan province, China.","Earthquakes,
Fuzzy neural networks,
Optimization,
Indexes,
Input variables,
Algorithm design and analysis,
Sociology"
Influence Maximization on Large-Scale Mobile Social Network: A Divide-and-Conquer Method,"With the proliferation of mobile devices and wireless technologies, mobile social network systems are increasingly available. A mobile social network plays an essential role as the spread of information and influence in the form of “word-of-mouth”. It is a fundamental issue to find a subset of influential individuals in a mobile social network such that targeting them initially (e.g., to adopt a new product) will maximize the spread of the influence (further adoptions of the new product). The problem of finding the most influential nodes is unfortunately NP-hard. It has been shown that a Greedy algorithm with provable approximation guarantees can give good approximation; However, it is computationally expensive, if not prohibitive, to run the greedy algorithm on a large mobile social network. In this paper, a divide-and-conquer strategy with parallel computing mechanism has been adopted. We first propose an algorithm called Community-based Greedy algorithm for mining top-K influential nodes. It encompasses two components: dividing the large-scale mobile social network into several communities by taking into account information diffusion and selecting communities to find influential nodes by a dynamic programming. Then, to further improve the performance, we parallelize the influence propagation based on communities and consider the influence propagation crossing communities. Also, we give precision analysis to show approximation guarantees of our models. Experiments on real large-scale mobile social networks show that the proposed methods are much faster than previous algorithms, meanwhile, with high accuracy.",
Average Absolute Frequency Deviation Value Based Active Islanding Detection Technique,"An average absolute frequency deviation value based active islanding detection technique is proposed in this paper. The inverter's classical q-axis current controller is modeled with a continuous periodic reference current of a small value. During the loss of mains, the island's frequency deviates with respect to the variation in the reference current; this is detected by making the use of an average absolute frequency deviation value. In case of a stable island formation, there is a small periodic frequency deviation owing to the small value of the periodic reference current, and the frequency deviation is so small that it falls inside the nondetection zone (NDZ) of the frequency relay. The main advantage of the proposed algorithm is that it detects the stable island formation but without forcing the island to lose its stable operation. In case of nonislanding switching events, which may transiently impose a significant deviation in the frequency, the possibility of false detection is eliminated by reconfirming the occurrence of islanding once it is suspected. The reference current is kept to a small value to limit the degradation of the power quality and the power factor. Computer simulation is done with MATLAB.","Inverters,
Frequency control,
Islanding,
Switches,
Market research,
Q-factor,
Reactive power"
Distributed Cooperative Secondary Control for Voltage Unbalance Compensation in an Islanded Microgrid,"This paper presents a distributed cooperative control scheme for voltage unbalance compensation (VUC) in an islanded microgrid (MG). By letting each distributed generator (DG) share the compensation effort cooperatively, unbalanced voltage in sensitive load bus (SLB) can be compensated. The concept of contribution level (CL) for compensation is first proposed for each local DG to indicate its compensation ability. A two-layer secondary compensation architecture consisting of a communication layer and a compensation layer is designed for each local DG. A totally distributed strategy involving information sharing and exchange is proposed, which is based on finite-time average consensus and newly developed graph discovery algorithm. This strategy does not require the whole system structure as a prior and can detect the structure automatically. The proposed scheme not only achieves similar VUC performance to the centralized one, but also brings some advantages, such as communication fault tolerance and plug-and-play property. Case studies including communication failure, CL variation, and DG plug-and-play are discussed and tested to validate the proposed method.","Voltage control,
Informatics,
Nickel,
Information management,
Laplace equations,
Eigenvalues and eigenfunctions,
Algorithm design and analysis"
An External Archive Guided Multiobjective Evolutionary Algorithm Based on Decomposition for Combinatorial Optimization,"Domination-based sorting and decomposition are two basic strategies used in multiobjective evolutionary optimization. This paper proposes a hybrid multiobjective evolutionary algorithm integrating these two different strategies for combinatorial optimization problems with two or three objectives. The proposed algorithm works with an internal (working) population and an external archive. It uses a decomposition-based strategy for evolving its working population and uses a domination-based sorting for maintaining the external archive. Information extracted from the external archive is used to decide which search regions should be searched at each generation. In such a way, the domination-based sorting and the decomposition strategy can complement each other. In our experimental studies, the proposed algorithm is compared with a domination-based approach, a decomposition-based one, and one of its enhanced variants on two well-known multiobjective combinatorial optimization problems. Experimental results show that our proposed algorithm outperforms other approaches. The effects of the external archive in the proposed algorithm are also investigated and discussed.","Sociology,
Statistics,
Vectors,
Educational institutions,
Optimization,
Evolutionary computation,
Sorting"
Efficient mixed-integer planning for UAVs in cluttered environments,"We present a new approach to the design of smooth trajectories for quadrotor unmanned aerial vehicles (UAVs), which are free of collisions with obstacles along their entire length. To avoid the non-convex constraints normally required for obstacle-avoidance, we perform a mixed-integer optimization in which polynomial trajectories are assigned to convex regions which are known to be obstacle-free. Prior approaches have used the faces of the obstacles themselves to define these convex regions. We instead use IRIS, a recently developed technique for greedy convex segmentation [1], to pre-compute convex regions of safe space. This results in a substantially reduced number of integer variables, which improves the speed with which the optimization can be solved to its global optimum, even for tens or hundreds of obstacle faces. In addition, prior approaches have typically enforced obstacle avoidance at a finite set of sample or knot points. We introduce a technique based on sums-of-squares (SOS) programming that allows us to ensure that the entire piecewise polynomial trajectory is free of collisions using convex constraints. We demonstrate this technique in 2D and in 3D using a dynamical model in the Drake toolbox for Matlab [2].","Trajectory,
Polynomials,
Iris,
Optimization,
Planning,
Linear programming,
Collision avoidance"
Event-Based Distributed Filtering With Stochastic Measurement Fading,"In this paper, we investigate the distributed filtering problem over wireless sensor networks (WSNs) with bandwidth and energy constraints. To utilize the limited resources efficiently, a novel event-based mechanism is proposed for the sensor node, such that only selected valuable data are broadcasted to its neighboring sensors via the wireless channel according to whether specific events happen. By resorting to graph theory and utilizing stochastic analysis methods, the filter parameters and the event triggering rules are designed, such that the filtering error converges at an exponential rate in the mean square sense. An adaptive algorithm for determining the triggering threshold is developed, which allows the intelligent sensors to tune the boundary of a local event domain in an online manner, so as to keep the average transmission rate level off a desired value. An illustrative example is given to demonstrate the effectiveness of the proposed strategy.","Wireless sensor networks,
Symmetric matrices,
Wireless communication,
Estimation,
Robot sensing systems,
Stability analysis,
Noise"
Deep transfer metric learning,"Conventional metric learning methods usually assume that the training and test samples are captured in similar scenarios so that their distributions are assumed to be the same. This assumption doesn't hold in many real visual recognition applications, especially when samples are captured across different datasets. In this paper, we propose a new deep transfer metric learning (DTML) method to learn a set of hierarchical nonlinear transformations for cross-domain visual recognition by transferring discriminative knowledge from the labeled source domain to the unlabeled target domain. Specifically, our DTML learns a deep metric network by maximizing the inter-class variations and minimizing the intra-class variations, and minimizing the distribution divergence between the source domain and the target domain at the top layer of the network. To better exploit the discriminative information from the source domain, we further develop a deeply supervised transfer metric learning (DSTML) method by including an additional objective on DTML where the output of both the hidden layers and the top layer are optimized jointly. Experimental results on cross-dataset face verification and person re-identification validate the effectiveness of the proposed methods.","Measurement,
Training,
Face,
Learning systems,
Visualization,
Machine learning,
Face recognition"
User-Aware Game Theoretic Approach for Demand Management,"Demand-management programs intend to maintain supply-demand balance and reduce the total energy cost. In this paper, we propose a user-aware demand-management approach that manages residential loads while taking into consideration user preferences. Maximizing users' savings and comfort can be two contradicting objectives. We identify a trade-off between these two objectives and propose an energy consumption optimization model, as well as a game theoretic approach to take this trade-off into account. User comfort is modeled in a simple yet effective way that considers waiting time, type of appliance, as well as a weight factor to prioritize comfort over savings. The proposed game is based on a modified regret matching procedure and borrows advantages of both centralized and decentralized schemes. Through simulations, we show that the proposed approach is scalable, converges in acceptable times, introduces a very limited amount of overhead in the system, achieves very high cost savings, and preserves users' preferences. Extensive simulations are used to evaluate the performance of the optimization model and the proposed approach.","Home appliances,
Schedules,
Games,
Energy consumption,
Optimization,
Companies,
Delays"
Domain Transfer Learning for MCI Conversion Prediction,"Machine learning methods have successfully been used to predict the conversion of mild cognitive impairment (MCI) to Alzheimer's disease (AD), by classifying MCI converters (MCI-C) from MCI nonconverters (MCI-NC). However, most existing methods construct classifiers using data from one particular target domain (e.g., MCI), and ignore data in other related domains (e.g., AD and normal control (NC)) that may provide valuable information to improve MCI conversion prediction performance. To address is limitation, we develop a novel domain transfer learning method for MCI conversion prediction, which can use data from both the target domain (i.e., MCI) and auxiliary domains (i.e., AD and NC). Specifically, the proposed method consists of three key components: 1) a domain transfer feature selection component that selects the most informative feature-subset from both target domain and auxiliary domains from different imaging modalities; 2) a domain transfer sample selection component that selects the most informative sample-subset from the same target and auxiliary domains from different data modalities; and 3) a domain transfer support vector machine classification component that fuses the selected features and samples to separate MCI-C and MCI-NC patients. We evaluate our method on 202 subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI) that have MRI, FDG-PET, and CSF data. The experimental results show the proposed method can classify MCI-C patients from MCI-NC patients with an accuracy of 79.4%, with the aid of additional domain knowledge learned from AD and NC.","Kernel,
Magnetic resonance imaging,
Positron emission tomography,
Alzheimer's disease,
Educational institutions,
Support vector machines"
Band Selection Using Improved Sparse Subspace Clustering for Hyperspectral Imagery Classification,"An improved sparse subspace clustering (ISSC) method is proposed to select an appropriate band subset for hyperspectral imagery (HSI) classification. The ISSC assumes that band vectors are sampled from a union of low-dimensional orthogonal subspaces and each band can be sparsely represented as a linear or affine combination of other bands within its subspace. First, the ISSC represents band vectors with sparse coefficient vectors by solving the L2-norm optimization problem using the least square regression (LSR) algorithm. The sparse and block diagonal structure of the coefficient matrix from LSR leads to correct segmentation of band vectors. Second, the angular similarity measurement is presented and utilized to construct the similarity matrix. Third, the distribution compactness (DC) plot algorithm is used to estimate an appropriate size of the band subset. Finally, spectral clustering is implemented to segment the similarity matrix and the desired ISSC band subset is found. Four groups of experiments on three widely used HSI datasets are performed to test the performance of ISSC for selecting bands in classification. In addition, the following six state-of-the-art band selection methods are used to make comparisons: linear constrained minimum variance-based band correlation constraint (LCMV-BCC), affinity propagation (AP), spectral information divergence (SID), maximum-variance principal component analysis (MVPCA), sparse representation-based band selection (SpaBS), and sparse nonnegative matrix factorization (SNMF). Experimental results show that the ISSC has the second shortest computational time and also outperforms the other six methods in classification accuracy when using an appropriate band number obtained by the DC plot algorithm.",
"Oscillometric Blood Pressure Estimation: Past, Present, and Future","The use of automated blood pressure (BP) monitoring is growing as it does not require much expertise and can be performed by patients several times a day at home. Oscillometry is one of the most common measurement methods used in automated BP monitors. A review of the literature shows that a large variety of oscillometric algorithms have been developed for accurate estimation of BP but these algorithms are scattered in many different publications or patents. Moreover, considering that oscillometric devices dominate the home BP monitoring market, little effort has been made to survey the underlying algorithms that are used to estimate BP. In this review, a comprehensive survey of the existing oscillometric BP estimation algorithms is presented. The survey covers a broad spectrum of algorithms including the conventional maximum amplitude and derivative oscillometry as well as the recently proposed learning algorithms, model-based algorithms, and algorithms that are based on analysis of pulse morphology and pulse transit time. The aim is to classify the diverse underlying algorithms, describe each algorithm briefly, and discuss their advantages and disadvantages. This paper will also review the artifact removal techniques in oscillometry and the current standards for the automated BP monitors.","Estimation,
Algorithm design and analysis,
Biomedical monitoring,
Neural networks,
Blood pressure,
Mathematical model"
An Efficient Cluster-Tree Based Data Collection Scheme for Large Mobile Wireless Sensor Networks,"Wireless Sensor Networks (WSNs) play a vital role in today's real world applications. The effectiveness of WSNs purely depends on the data collection scheme. Numerous data collection schemes such as multipath, chain, tree, cluster and hybrid topologies are available in literature for collecting data in WSNs. However, the existing data collection schemes fail to provide a guaranteed reliable network in terms of mobility, traffic, and end-to-end connection. In this paper, a Velocity Energy-efficient and Link-aware Cluster-Tree (VELCT) scheme for data collection in WSNs is proposed which would effectively mitigate the problems of coverage distance, mobility, delay, traffic, tree intensity, and end-to-end connection. The proposed VELCT constructs the Data Collection Tree (DCT) based on the cluster head location. The data collection node in the DCT does not participate in sensing on this particular round, however, it simply collects the data packet from the cluster head and delivers it to the sink. The designed VELCT scheme minimizes the energy exploitation, reduces the end-to-end delay and traffic in cluster head in WSNs by effective usage of the DCT. The strength of the VELCT algorithm is to construct a simple tree structure, thereby reducing the energy consumption of the cluster head and avoids frequent cluster formation. It also maintains the cluster for a considerable amount of time. Simulation results have demonstrated that VELCT provides better QoS in terms of energy consumption, throughput, end-to-end delay, and network lifetime for mobility-based WSNs.","Sensors,
Wireless sensor networks,
Topology,
Network topology,
Data collection,
Routing,
Protocols"
Per-Core DVFS With Switched-Capacitor Converters for Energy Efficiency in Manycore Processors,"Integrating multiple power converters on-chip improves energy efficiency of manycore architectures. Switched-capacitor (SC) dc-dc converters are compatible with conventional CMOS processes, but traditional implementations suffer from limited conversion efficiency. We propose a dynamic voltage and frequency scaling scheme with SC converters that achieves high converter efficiency by allowing the output voltage to ripple and having the processor core frequency track the ripple. Minimum core energy is achieved by hopping between different converter modes and tuning body-bias voltages. A multicore processor model based on a 28-nm technology shows conversion efficiencies of 90% along with over 25% improvement in the overall chip energy efficiency.","Clocks,
Switches,
Program processors,
Mathematical model,
Adaptation models,
Integrated circuit modeling,
Load modeling"
Genetic Optimal Regression of Relevance Vector Machines for Electricity Pricing Signal Forecasting in Smart Grids,"Price-directed demand in smart grids operating within deregulated electricity markets calls for real-time forecasting of the price of electricity for the purpose of scheduling demand at the nodal level (e.g., appliances, machines, and devices) in a way that minimizes energy cost to the consumer. In this paper, a novel hybrid methodology for electricity price forecasting is introduced and applied on a set of real-world historical data taken from the New England area. The proposed approach is implemented in two steps. In the first step, a set of relevance vector machines (RVMs) is adopted, where each RVM is used for individual ahead-of-time price prediction. In the second step, individual predictions are aggregated to formulate a linear regression ensemble, whose coefficients are obtained as the solution of a single objective optimization problem. Thus, an optimal solution to the problem is found by employing the micro-genetic algorithm and the optimized ensemble is employed for computing the final price forecast. The performance of the proposed methodology is compared with performance of autoregressive-moving-average and naïve forecasting methods, as well as to that taken from each individual RVM. Results clearly demonstrate the superiority of the hybrid methodology over the other tested methods with regard to mean absolute error for electricity signal pricing forecasting.","Forecasting,
Autoregressive processes,
Genetic algorithms,
Predictive models,
Pricing,
Optimization"
Finite-Time Stabilizability and Instabilizability of Delayed Memristive Neural Networks With Nonlinear Discontinuous Controller,"This paper is concerned about the finite-time stabilizability and instabilizability for a class of delayed memristive neural networks (DMNNs). Through the design of a new nonlinear controller, algebraic criteria based on M-matrix are established for the finite-time stabilizability of DMNNs, and the upper bound of the settling time for stabilization is estimated. In addition, finite-time instabilizability algebraic criteria are also established by choosing different parameters of the same nonlinear controller. The effectiveness and the superiority of the obtained results are supported by numerical simulations.","Stability criteria,
Asymptotic stability,
Delays,
Memristors,
Control systems,
Neural networks"
Expert Finding for Question Answering via Graph Regularized Matrix Completion,"Expert finding for question answering is a challenging problem in community-based question answering (CQA) systems, arising in many real applications such as question routing and identification of best answers. In order to provide high-quality experts, many existing approaches learn the user model from their past question-answering activities in CQA systems. However, the past activities of users in most CQA systems are rather few, and thus the user model may not be well inferred in practice. In this paper, we consider the problem of expert finding from the viewpoint of missing value estimation. We then employ users' social networks for inferring user model, and thus improve the performance of expert finding in CQA systems. In addition, we develop a novel graph-regularized matrix completion algorithm for inferring the user model. We further develop two efficient iterative procedures, GRMC-EGM and GRMC-AGM, to solve the optimization problem. GRMC-EGM utilizes the Extended Gradient Method (EGM), while GRMC-AGM applies the Accelerated proximal Gradient search Method (AGM), for the optimization. We evaluate our methods on the well-known question answering system Quora, and the popular social network Twitter. Our empirical study shows the effectiveness of the proposed algorithms in comparison to the state-of-the-art expert finding algorithms.","Linear programming,
Knowledge discovery,
Estimation,
Social network services,
Prediction algorithms,
Gradient methods"
Inside the Virtual Robotics Challenge: Simulating Real-Time Robotic Disaster Response,"This paper presents the software framework established to facilitate cloud-hosted robot simulation. The framework addresses the challenges associated with conducting a task-oriented and real-time robot competition, the Defense Advanced Research Projects Agency (DARPA) Virtual Robotics Challenge (VRC), designed to mimic reality. The core of the framework is the Gazebo simulator, a platform to simulate robots, objects, and environments, as well as the enhancements made for the VRC to maintain a high fidelity simulation using a high degree of freedom and multisensor robot. The other major component used is the CloudSim tool, designed to enhance the automation of robotics simulation using existing cloud technologies. The results from the VRC and a discussion are also detailed in this work. Note to Practitioners - Advances in robot simulation, cloud hosted infrastructure, and web technology have made it possible to accurately and efficiently simulate complex robots and environments on remote servers while providing realistic data streams for human-in-the-loop robot control. This paper presents the software and hardware frameworks established to facilitate cloud-hosted robot simulation, and addresses the challenges associated with conducting a task-oriented robot competition designed to mimic reality. The competition that spurred this innovation was the VRC, a precursor to the DARPA Robotics Challenge, in which teams from around the world utilized custom human-robot interfaces and control code to solve disaster response-related tasks in simulation. Winners of the VRC received both funding and access to Atlas, a humanoid robot developed by Boston Dynamics. The Gazebo simulator, an open source and high fidelity robot simulator, was improved upon to met the needs of the VRC competition. Additionally, CloudSim was created to act as an interface between users and the cloud-hosted simulations. As a result of this work, we have achieved automated deployment of cloud resources for robotic simulations, near real-time simulation performance, and simulation accuracy that closely mimics real hardware. These tools have been released under open source licenses and are freely available, and can be used to help reduce robot and algorithm design and development time, and increase robot software robustness.","Computers,
Real-time systems,
Robot sensing systems,
Computational modeling,
Computer architecture,
Servers"
User-Defined Privacy Grid System for Continuous Location-Based Services,"Location-based services (LBS) require users to continuously report their location to a potentially untrusted server to obtain services based on their location, which can expose them to privacy risks. Unfortunately, existing privacy-preserving techniques for LBS have several limitations, such as requiring a fully-trusted third party, offering limited privacy guarantees and incurring high communication overhead. In this paper, we propose a user-defined privacy grid system called dynamic grid system (DGS); the first holistic system that fulfills four essential requirements for privacy-preserving snapshot and continuous LBS. (1) The system only requires a semi-trusted third party, responsible for carrying out simple matching operations correctly. This semi-trusted third party does not have any information about a user's location. (2) Secure snapshot and continuous location privacy is guaranteed under our defined adversary models. (3) The communication cost for the user does not depend on the user's desired privacy level, it only depends on the number of relevant points of interest in the vicinity of the user. (4) Although we only focus on range and k-nearest-neighbor queries in this work, our system can be easily extended to support other spatial queries without changing the algorithms run by the semi-trusted third party and the database server, provided the required search area of a spatial query can be abstracted into spatial regions. Experimental results show that our DGS is more efficient than the state-of-the-art privacy-preserving technique for continuous LBS.","Cryptography,
Privacy,
Servers,
Mobile communication,
Query processing,
Protocols,
Mobile computing"
Efficient Learning of Image Super-Resolution and Compression Artifact Removal with Semi-Local Gaussian Processes,"Improving the quality of degraded images is a key problem in image processing, but the breadth of the problem leads to domain-specific approaches for tasks such as super-resolution and compression artifact removal. Recent approaches have shown that a general approach is possible by learning application-specific models from examples; however, learning models sophisticated enough to generate high-quality images is computationally expensive, and so specific per-application or per-dataset models are impractical. To solve this problem, we present an efficient semi-local approximation scheme to large-scale Gaussian processes. This allows efficient learning of task-specific image enhancements from example images without reducing quality. As such, our algorithm can be easily customized to specific applications and datasets, and we show the efficiency and effectiveness of our approach across five domains: single-image super-resolution for scene, human face, and text images, and artifact removal in JPEG- and JPEG 2000-encoded images.","Image resolution,
Approximation methods,
Transform coding,
Noise,
Training,
Image enhancement,
Computational modeling"
CrowdTasker: Maximizing coverage quality in Piggyback Crowdsensing under budget constraint,"This paper proposes a novel task allocation framework, CrowdTasker, for mobile crowdsensing. CrowdTasker operates on top of energy-efficient Piggyback Crowdsensing (PCS) task model, and aims to maximize the coverage quality of the sensing task while satisfying the incentive budget constraint. In order to achieve this goal, CrowdTasker first predicts the call and mobility of mobile users based on their historical records. With a flexible incentive model and the prediction results, CrowdTasker then selects a set of users in each sensing cycle for PCS task participation, so that the resulting solution achieves near-maximal coverage quality without exceeding incentive budget. We evaluated CrowdTasker extensively using a large-scale real-world dataset and the results show that CrowdTasker significantly outperformed three baseline approaches by achieving 3%-60% higher coverage quality.","Sensors,
Resource management,
Mobile communication,
Poles and towers,
Prediction algorithms,
Mobile handsets,
Conferences"
Automatic Resonance Alignment of High-Order Microring Filters,"Automatic resonance alignment tuning is performed in high-order series coupled microring filters using a feedback system. By inputting only a reference wavelength, the filter transmission is maximized on resonance, passband ripples are dramatically reduced, and the passband becomes centered at the reference. The method is tested on fifth-order microring filters fabricated in a standard silicon photonics foundry process. Repeatable tuning is demonstrated for filters on multiple dies from the wafer and for arbitrary reference wavelengths within the free spectral range of the microrings.",
High-Level Intuitive Features (HLIFs) for Intuitive Skin Lesion Description,"A set of high-level intuitive features (HLIFs) is proposed to quantitatively describe melanoma in standard camera images. Melanoma is the deadliest form of skin cancer. With rising incidence rates and subjectivity in current clinical detection methods, there is a need for melanoma decision support systems. Feature extraction is a critical step in melanoma decision support systems. Existing feature sets for analyzing standard camera images are comprised of low-level features, which exist in high-dimensional feature spaces and limit the system's ability to convey intuitive diagnostic rationale. The proposed HLIFs were designed to model the ABCD criteria commonly used by dermatologists such that each HLIF represents a human-observable characteristic. As such, intuitive diagnostic rationale can be conveyed to the user. Experimental results show that concatenating the proposed HLIFs with a full low-level feature set increased classification accuracy, and that HLIFs were able to separate the data better than low-level features with statistical significance. An example of a graphical interface for providing intuitive rationale is given.","Image color analysis,
Lesions,
Malignant tumors,
Shape,
Feature extraction,
Skin,
Complexity theory"
Fast RFID grouping protocols,"In RFID systems, the grouping problem is to efficiently group all tags according to a given partition such that tags in the same group will have the same group ID. Unlike previous research on the unicast transmission from a reader to a tag, grouping provides a fundamental mechanism for efficient multicast transmissions and aggregate queries in large RFID-enabled applications. A message can be transmitted to a group of m tags simultaneously in multicast, which improves the efficiency by m times when comparing with unicast. We study fast grouping protocols in large RFID systems. To the best of our knowledge, it is the first attempt to tackle this practically important yet uninvestigated problem. We start with a straightforward solution called the Enhanced Polling Grouping (EPG) protocol. We then propose a time-efficient FIltering Grouping (FIG) protocol that uses Bloom filters to remove the costly ID transmissions. We point out the limitation of the Bloom-filter based solution due to its intrinsic false positive problem, which leads to our final ConCurrent Grouping (CCG) protocol. With a drastically different design, CCG is able to outperform FIG by exploiting collisions to inform multiple tags of their group ID simultaneously and by removing any wasteful slots in its frame-based execution. Simulation results demonstrate that our best protocol CCG can reduce the execution time by a factor of 11 when comparing with a baseline polling protocol.",
An Energy-Efficient and Delay-Aware Wireless Computing System for Industrial Wireless Sensor Networks,"Industrial wireless sensor networks have attracted much attention as a cornerstone to making the smart factories real. Utilizing industrial wireless sensor networks as a base for smart factories makes it possible to optimize the production line without human resources, since it provides industrial Internet of Things service, where various types of data are collected from sensors and mined to control the machines based on the analysis result. On the other hand, a fog computing node, which executes such real-time feedback control, should be capable of real-time data collection, management, and processing. To achieve these requirements, in this paper, we introduce wireless computing system (WCS) as a fog computing node. Since there are a lot of servers and each server has 60 GHz antennas to connect to other servers and sensors, WCS has high collecting and processing capabilities. However, in order to fulfill a demand for real-time feedback control, WCS needs to satisfy an acceptable delay for data collection. In addition, lower power consumption is required in order to reduce the cost for the factory operation. Therefore, we propose an energy-efficient and delay-aware WCS. Since there is a tradeoff relationship between the power consumption and the delay for data collection, our proposed system controls the sleep schedule and the number of links to minimize the power consumption while satisfying an acceptable delay constraint. Furthermore, the effectiveness of our proposed system is evaluated through extensive computer simulations.","Industrial communication,
Wireless sensor networks,
Wireless computing,
Low power electronics,
Delays,
Power consumption,
Data collection"
Kernelized Saliency-Based Person Re-Identification Through Multiple Metric Learning,"Person re-identification in a non-overlapping multi-camera scenario is an open and interesting challenge. While the task can hardly be completed by machines, we, as humans, are inherently able to sample those relevant persons' details that allow us to correctly solve the problem in a fraction of a second. Thus, knowing where a human might fixate to recognize a person is of paramount interest for re-identification. Inspired by the human gazing capabilities, we want to identify the salient regions of a person appearance to tackle the problem. Toward this objective, we introduce the following main contributions. A kernelized graph-based approach is used to detect the salient regions of a person appearance, later used as a weighting tool in the feature extraction process. The proposed person representation combines visual features either considering or not the saliency. These are then exploited in a pairwise-based multiple metric learning framework. Finally, the non-Euclidean metrics that have been separately learned for each feature are fused to re-identify a person. The proposed kernelized saliency-based person re-identification through multiple metric learning has been evaluated on four publicly available benchmark data sets to show its superior performance over the state-of-the-art approaches (e.g., it achieves a rank 1 correct recognition rate of 42.41% on the VIPeR data set).","Feature extraction,
Measurement,
Cameras,
Image color analysis,
Visualization,
Principal component analysis,
Kernel"
Design and Application of the CSRR-Based Planar Sensor for Noninvasive Measurement of Complex Permittivity,"A novel microwave noninvasive planar sensor based on the complementary split ring resonator (CSRR) is proposed for an accurate measurement of the complex permittivity of materials. The CSRR is etched in the ground plane of the planar microstrip line. Two CSRRs of rectangular and circular cross-sections are chosen for the sensitivity analysis, where the later is found to possess higher sensitivity and hence appears to be more appropriate for the sensor design. At resonance, the electric field induced along the plane of CSRR is found to be quite sensitive for the characterization of specimen kept in contact with the sensor. A numerical model is developed here for the calculation of the complex permittivity as a function of resonant frequency and the quality factor data using the electromagnetic simulator, the Computer Simulation Technology. For practical applications, a detailed air gap analysis is carried out to consider the effect of any air gap present between the test sample and the CSRR. The designed sensor is fabricated and tested, and accordingly the numerically established relations are experimentally verified for various reference samples e.g., teflon, polyvinyl chloride, plexiglas, polyethylene, rubber, and wood. Experimentally, it is found that the permittivity measurement using the proposed sensor is possible with a typical error of 3%.","Sensors,
Resonant frequency,
Permittivity,
Q-factor,
Permittivity measurement,
Dielectric constant,
Magnetic fields"
Distributed Containment Control for Multiple Unknown Second-Order Nonlinear Systems With Application to Networked Lagrangian Systems,"In this paper, we consider the distributed containment control problem for multiagent systems with unknown nonlinear dynamics. More specifically, we focus on multiple second-order nonlinear systems and networked Lagrangian systems. We first study the distributed containment control problem for multiple second-order nonlinear systems with multiple dynamic leaders in the presence of unknown nonlinearities and external disturbances under a general directed graph that characterizes the interaction among the leaders and the followers. A distributed adaptive control algorithm with an adaptive gain design based on the approximation capability of neural networks is proposed. We present a necessary and sufficient condition on the directed graph such that the containment error can be reduced as small as desired. As a byproduct, the leaderless consensus problem is solved with asymptotical convergence. Because relative velocity measurements between neighbors are generally more difficult to obtain than relative position measurements, we then propose a distributed containment control algorithm without using neighbors' velocity information. A two-step Lyapunov-based method is used to study the convergence of the closed-loop system. Next, we apply the ideas to deal with the containment control problem for networked unknown Lagrangian systems under a general directed graph. All the proposed algorithms are distributed and can be implemented using only local measurements in the absence of communication. Finally, simulation examples are provided to show the effectiveness of the proposed control algorithms.","Nonlinear systems,
Vectors,
Multi-agent systems,
Algorithm design and analysis,
Uncertainty,
Heuristic algorithms,
Velocity measurement"
Energy-Efficient Manycast Routing and Spectrum Assignment in Elastic Optical Networks for Cloud Computing Environment,"In this paper, we present an energy-efficient manycast routing and spectrum assignment (EEM-RSA) algorithm in elastic optical networks supporting cloud computing applications. The proposed EEM-RSA is adapted for both static and dynamic scenarios. First, an integer linear programing formulation is derived for energy-efficient manycasting and spectrum assignment; then, the corresponding heuristic methods are proposed. To reduce the energy consumption, inactive (idle) elements are turned off, and in the proposed energy-efficient manycasting heuristic, the number of activated elements are minimized. The power consumption of network elements is modeled by considering a constant overhead for the element activation and a variable traffic-dependent term for the element operation. Furthermore, two types of data centers based on their power supply, renewable (green) or nonrenewable (brown), are considered to explore the capability of the proposed algorithms in decreasing green house gases emission. To investigate the impact of renewable energy sources, two approaches are utilized in the destination selection (DS) phase of the EEM-RSA, namely green-energy aware-DS and green-energy unaware-DS. All heuristic algorithms are evaluated by using an event-driven simulator based on the Poisson traffic model. The simulation results reveal that by applying the proposed energy-aware heuristic algorithm, the network energy consumption is reduced at the cost of increasing the blocking probability. However, by designating the shortest path, instead of the path with the lowest power consumption, the blocking probability is reduced, whereas increasing the energy consumption. Thus, we introduce an intermediate solution, referred to as blocking-aware energy-efficient manycasting, which compromises between the power consumption and blocking probability performance metrics.","Routing,
Power demand,
Modulation,
Heuristic algorithms,
Optical fiber networks,
Green products,
Bandwidth"
Supervised Multi-View Canonical Correlation Analysis (sMVCCA): Integrating Histologic and Proteomic Features for Predicting Recurrent Prostate Cancer,"In this work, we present a new methodology to facilitate prediction of recurrent prostate cancer (CaP) following radical prostatectomy (RP) via the integration of quantitative image features and protein expression in the excised prostate. Creating a fused predictor from high-dimensional data streams is challenging because the classifier must 1) account for the “curse of dimensionality” problem, which hinders classifier performance when the number of features exceeds the number of patient studies and 2) balance potential mismatches in the number of features across different channels to avoid classifier bias towards channels with more features. Our new data integration methodology, supervised Multi-view Canonical Correlation Analysis (sMVCCA), aims to integrate infinite views of highdimensional data to provide more amenable data representations for disease classification. Additionally, we demonstrate sMVCCA using Spearman's rank correlation which, unlike Pearson's correlation, can account for nonlinear correlations and outliers. Forty CaP patients with pathological Gleason scores 6-8 were considered for this study. 21 of these men revealed biochemical recurrence (BCR) following RP, while 19 did not. For each patient, 189 quantitative histomorphometric attributes and 650 protein expression levels were extracted from the primary tumor nodule. The fused histomorphometric/proteomic representation via sMVCCA combined with a random forest classifier predicted BCR with a mean AUC of 0.74 and a maximum AUC of 0.9286. We found sMVCCA to perform statistically significantly (p <; 0.05) better than comparative state-of-the-art data fusion strategies for predicting BCR. Furthermore, Kaplan-Meier analysis demonstrated improved BCR-free survival prediction for the sMVCCA-fused classifier as compared to histology or proteomic features alone.","Correlation,
Feature extraction,
Proteomics,
Optimization,
Prostate cancer,
Proteins,
Vectors"
Fundamental limits of RSS fingerprinting based indoor localization,"Indoor localization has been an active research field for decades, where the received signal strength (RSS) fingerprinting based methodology is widely adopted and induces many important localization techniques such as the recently proposed one building the fingerprint database with crowd-sourcing. While efforts have been dedicated to improve the accuracy and efficiency of localization, the fundamental limits of RSS fingerprinting based methodology itself is still unknown in a theoretical perspective. In this paper, we present a general probabilistic model to shed light on a fundamental question: how good the RSS fingerprinting based indoor localization can achieve? Concretely, we present the probability that a user can be localized in a region with certain size, given the RSS fingerprints submitted to the system. We reveal the interaction among the localization accuracy, the reliability of location estimation and the number of measurements in the RSS fingerprinting based location determination. Moreover, we present the optimal fingerprints reporting strategy that can achieve the best accuracy for given reliability and the number of measurements, which provides a design guideline for the RSS fingerprinting based indoor localization facilitated by crowdsourcing paradigm.","Reliability,
Accuracy,
Probabilistic logic,
Databases,
Wireless communication,
Crowdsourcing,
Mobile handsets"
Toward a Realistic Performance Analysis of Storage Systems in Smart Grids,"Energy storage devices (ESDs) have the potential to revolutionize the electricity grid by allowing the smoothing of variable-energy generator output and the time-shifting of demand away from peak times. A common approach to study the impact of ESDs on energy systems is by modeling them as electric circuits in simulations. Although recent circuit models are becoming more accurate, to obtain statistically valid results, extensive simulations need to be run. In some cases, existing datasets are not large enough to obtain statistically significant results. The impact of ESDs on energy systems has also been recently studied using analytical methods, but usually by assuming ideal ESD behavior, such as infinite ESD charging and discharging rates, and zero self-discharge. However, real-life ESDs are far from ideal. We investigate the effect of nonideal ESD behavior on system performance, presenting an analytical ESD model that retains much of the simplicity of an ideal ESD, yet captures many (though not all) nonideal behaviors for a class of ESDs that includes all battery technologies and compressed air energy storage systems. This allows us to compute performance bounds for systems with nonideal ESDs using standard teletraffic techniques. We provide performance results for five widely used ESD technologies and show that our models can closely approximate numerically computed performance bounds.","Electrostatic discharges,
Analytical models,
Computational modeling,
Batteries,
US Department of Defense,
Stochastic processes,
Numerical models"
UbiFlow: Mobility management in urban-scale software defined IoT,"The growing of Internet of Things (IoT) devices has resulted in a number of urban-scale deployments of IoT multinetworks, where heterogeneous wireless communication solutions coexist. Managing the multinetworks for mobile IoT access is a key challenge. Software-defined networking (SDN) is emerging as a promising paradigm for quick configuration of network devices, but its application in multinetworks with frequent IoT access is not well studied. In this paper we present UbiFlow, the first software-defined IoT system for ubiquitous flow control and mobility management in multinetworks. UbiFlow adopts distributed controllers to divide urban-scale SDN into different geographic partitions. A distributed hashing based overlay structure is proposed to maintain network scalability and consistency. Based on this UbiFlow overlay structure, relevant issues pertaining to mobility management such as scalable control, fault tolerance, and load balancing have been carefully examined and studied. The UbiFlow controller differentiates flow scheduling based on the per-device requirement and whole-partition capability. Therefore, it can present a network status view and optimized selection of access points in multinetworks to satisfy IoT flow requests, while guaranteeing network performance in each partition. Simulation and realistic testbed experiments confirm that UbiFlow can successfully achieve scalable mobility management and robust flow scheduling in IoT multinetworks.",
Circuit-Oriented Treatment of Nonlinear Capacitances in Switched-Mode Power Supplies,"Nonlinear, voltage-dependent capacitances of power semiconductor devices are capable of having significant impact on the operation of switched-mode power converters. Particularly at high switching frequency, these nonlinearities play a significant role in determining switching times, losses, and converter dynamics during switching transitions. In order to accommodate the well-established design and analysis techniques commonly used for linear circuits, this paper examines the nonlinear voltage-dependence of switching device capacitances and proposes a circuit-oriented analysis technique that allows the parasitic capacitances to be replaced with linear equivalents. The multitude of developed equivalents are verified through full nonlinear simulation in both MATLAB/Simulink and SPICE, as well as through experimental results.","Capacitance,
Capacitors,
Switching circuits,
Integrated circuit modeling,
Mathematical model,
Switches,
Impedance"
A Bi-Level Branch and Bound Method for Economic Dispatch With Disjoint Prohibited Zones Considering Network Losses,"This paper proposes a bi-level branch-and-bound ((B&B) method to solve the economic dispatch problem with prohibited zones and network losses. The approach employs binary variables for each prohibited zone and utilizes the B-coefficient for network losses, which can be transformed into a mixed-integer quadratically constrained quadratic programming (MIQCQP), where linear relaxation technique is applied on each bilinear term. Due to the complexity in solving the MIQCQP problem, this paper proposes a bi-level B&B method to achieve global optimum. A spatial B&B method is utilized in the higher level to solve the quadratically constrained quadratic programming (QCQP) problem, whereas a simple B&B method is employed in the lower level to solve a mixed-integer quadratic programming (MIQP) problem. The bi-level B&B algorithm that combines spatial and simple B&B methods is actually a deterministic optimization method and can produce global optimal solutions. Numerical results on 6-unit, 15-unit, and 40-unit test systems show that the bi-level B&B method can solve the MIQCQP problem with superior solution quality and convergence characteristics.","Relaxation methods,
Economics,
Quadratic programming,
Power generation dispatch"
Composite event coverage in wireless sensor networks with heterogeneous sensors,"Event monitoring is a popular task carried out by Wireless Sensor Networks (WSNs). A composite event involves multiple properties requiring different types of sensors to monitor. Considering the costs of different deployment of heterogeneous sensors and the total budget for a monitored region, this paper investigates the composite event coverage problem with the purpose of optimizing coverage quality subjecting to the constraint of not exceeding the total budget. This is a novel coverage problem which is different from the traditional ones where deployment costs of sensors, total budget and composite events are not considered. Two exact algorithms are proposed whose time complexities are O(nk) and O(nk-1) respectively in the worst case, and a (1 - e-1)-approximate algorithm are designed. The simulation results indicate the efficiency and effectiveness of the proposed algorithms.",
Design and Analysis of 3D-MAPS (3D Massively Parallel Processor with Stacked Memory),"This paper describes the architecture, design, analysis, and simulation and measurement results of the 3D-MAPS (3D massively parallel processor with stacked memory) chip built with a 1.5 V, 130 nm process technology and a two-tier 3D stacking technology using 1.2 \microm-diameter, 6 \micro m-height through-silicon vias (TSVs) and 3.4\nbsp\microm-diameter face-to-face bond pads. 3D-MAPS consists of a core tier containing 64 cores and a memory tier containing 64 memory blocks. Each core communicates with its dedicated 4KB SRAM block using face-to-face bond pads, which provide negligible data transfer delay between the core and the memory tiers. The maximum operating frequency is 277 MHz and the maximum memory bandwidth is 70.9 GB/s at 277 MHz. The peak measured memory bandwidth usage is 63.8 GB/s and the peak measured power is approximately 4 W based on eight parallel benchmarks.","Three-dimensional displays,
Bandwidth,
Through-silicon vias,
Multicore processing"
Encoding Color Information for Visual Tracking: Algorithms and Benchmark,"While color information is known to provide rich discriminative clues for visual inference, most modern visual trackers limit themselves to the grayscale realm. Despite recent efforts to integrate color in tracking, there is a lack of comprehensive understanding of the role color information can play. In this paper, we attack this problem by conducting a systematic study from both the algorithm and benchmark perspectives. On the algorithm side, we comprehensively encode 10 chromatic models into 16 carefully selected state-of-the-art visual trackers. On the benchmark side, we compile a large set of 128 color sequences with ground truth and challenge factor annotations (e.g., occlusion). A thorough evaluation is conducted by running all the color-encoded trackers, together with two recently proposed color trackers. A further validation is conducted on an RGBD tracking benchmark. The results clearly show the benefit of encoding color information for tracking. We also perform detailed analysis on several issues, including the behavior of various combinations between color model and visual tracker, the degree of difficulty of each sequence for tracking, and how different challenge factors affect the tracking performance. We expect the study to provide the guidance, motivation, and benchmark for future work on encoding color in visual tracking.","Image color analysis,
Visualization,
Target tracking,
Benchmark testing,
Color,
Image coding,
Gray-scale"
High-Speed Printing of Transistors: From Inks to Devices,"The realization of a high-speed printing technique with high resolution and pattern fidelity is critical to making printed electronics a viable technology for electronics manufacturing. The printing requirements of printed electronics are substantially different that those of graphic arts. To make printed electronics a reality, it is necessary to deliver high resolution, good reproducibility, excellent pattern fidelity, high process throughput, and compatibility with the requisite semiconductor, dielectric, and conductor inks. In this paper, we review the physics of pattern formation from pixelated primitives, such as those that exist during inkjet and gravure printing, and will show how control of drop merging and drying can be used to produce high-fidelity shapes, including lines, squares, and intersections. We additionally discuss the physical underpinnings of gravure printing and inkjet printing, and show how these techniques can be scaled to produce high-fidelity highly scaled patterns, including sub-2 micron features at printing speeds of ~1 m/s. Finally, in conjunction with high-performance materials, we describe our realization of high-performance fully printed transistors on plastic, offering high-switching speed, excellent process throughput, and good fidelity over large areas.","Flexible electronics,
Printing,
Shape,
Substrates,
Solvents,
Transistors,
Dielectrics,
Manufacturing processes"
Dynamic defense strategy against advanced persistent threat with insiders,"The landscape of cyber security has been reformed dramatically by the recently emerging Advanced Persistent Threat (APT). It is uniquely featured by the stealthy, continuous, sophisticated and well-funded attack process for long-term malicious gain, which render the current defense mechanisms inapplicable. A novel design of defense strategy, continuously combating APT in a long time-span with imperfect/incomplete information on attacker's actions, is urgently needed. The challenge is even more escalated when APT is coupled with the insider threat (a major threat in cyber-security), where insiders could trade valuable information to APT attacker for monetary gains. The interplay among the defender, APT attacker and insiders should be judiciously studied to shed insights on a more secure defense system. In this paper, we consider the joint threats from APT attacker and the insiders, and characterize the fore-mentioned interplay as a two-layer game model, i.e., a defense/attack game between defender and APT attacker and an information-trading game among insiders. Through rigorous analysis, we identify the best response strategies for each player and prove the existence of Nash Equilibrium for both games. Extensive numerical study further verifies our analytic results and examines the impact of different system configurations on the achievable security level.","Games,
Nash equilibrium,
Cost function,
Computer security,
Joints,
Computers"
Simulation of Phosphorene Field-Effect Transistor at the Scaling Limit,"The ultimate scaling limit and device physics of aggressively scaled phosphorene MOSFETs are examined by self-consistent multiscale quantum transport simulations. The MOSFET structure can effectively suppress the ambipolar conduction and decrease the leakage current, and thereby, is more scalable than the Schottky barrier FET structure. The interplay of quantum mechanical effects and highly anisotropic band structure plays a critical role for phosphorene transistors with a sub 10-nm channel length, in which the optimum choice of the transport crystalline direction is completely different from phosphorene FETs with a longer channel length. Even at a sub-10-nm channel length with considerable quantum tunneling effects, the anisotropic band structure still provides a better device performance in terms of ON-current over other 2-D semiconductors with nearly isotropic band structures, such as MoS2. With the optimum choice of the transport direction, both n- and p-type phosphorene FETs meet the International Technology Roadmap for Semiconductor (ITRS) target at the 5-nm technology node.","MOSFET,
Tunneling,
Leakage currents,
Photonic band gap"
High-Throughput Power-Efficient VLSI Architecture of Fractional Motion Estimation for Ultra-HD HEVC Video Encoding,"Fractional motion estimation (FME) significantly enhances video compression efficiency, but its high computational complexity also limits the real-time processing capability. In this brief, we present a VLSI implementation of FME design in High Efficiency Video Coding for ultrahigh definition video applications. We first propose a bilinear quarter pixel approximation, together with a search pattern based on it to reduce the complexity of interpolation and fractional search process. Furthermore, a data reuse strategy is exploited to reduce the hardware cost of transform. In addition, using the considered pixel parallelism and dedicated access pattern for memory, we fully pipeline the computation and achieve high hardware utilization. This design has been implemented as a 65-nm CMOS chip and verified. The measured throughput reaches 995 Mpixels/s for 7680 × 4320 30 frames/s at 188 MHz, at least 4.7 times faster than prior arts. The corresponding power dissipation is 198.6 mW, with a power efficiency of 0.2 nJ/pixel. Due to the optimization, our work achieves more than 52% improvement on power efficiency, relative to previous works in H.264.",
Variational Mesh Denoising Using Total Variation and Piecewise Constant Function Space,"Mesh surface denoising is a fundamental problem in geometry processing. The main challenge is to remove noise while preserving sharp features (such as edges and corners) and preventing generating false edges. We propose in this paper to combine total variation (TV) and piecewise constant function space for variational mesh denoising. We first give definitions of piecewise constant function spaces and associated operators. A variational mesh denoising method will then be presented by combining TV and piecewise constant function space. It is proved that, the solution of the variational problem (the key part of the method) is in some sense continuously dependent on its parameter, indicating that the solution is robust to small perturbations of this parameter. To solve the variational problem, we propose an efficient iterative algorithm (with an additional algorithmic parameter) based on variable splitting and augmented Lagrangian method, each step of which has closed form solution. Our denoising method is discussed and compared to several typical existing methods in various aspects. Experimental results show that our method outperforms all the compared methods for both CAD and non-CAD meshes at reasonable costs. It can preserve different levels of features well, and prevent generating false edges in most cases, even with the parameters evaluated by our estimation formulae.","Noise reduction,
Face,
TV,
Image edge detection,
Noise,
Noise measurement,
Iterative methods"
Invariant Surface EMG Feature Against Varying Contraction Level for Myoelectric Control Based on Muscle Coordination,"Variations in muscle contraction effort have a substantial impact on performance of pattern recognition based myoelectric control. Though incorporating changes into training phase could decrease the effect, the training time would be increased and the clinical viability would be limited. The modulation of force relies on the coordination of multiple muscles, which provides a possibility to classify motions with different forces without adding extra training samples. This study explores the property of muscle coordination in the frequency domain and found that the orientation of muscle activation pattern vector of the frequency band is similar for the same motion with different force levels. Two novel features based on discrete Fourier transform and muscle coordination were proposed subsequently, and the classification accuracy was increased by around 11% compared to the traditional time domain feature sets when classifying nine classes of motions with three different force levels. Further analysis found that both features decreased the difference among different forces of the same motion p <; 0.005) and maintained the distance among different motions p > 0.1). This study also provided a potential way for simultaneous classification of hand motions and forces without training at all force levels.","Force,
Muscles,
Training,
Vectors,
Wrist,
Testing,
Feature extraction"
Dead-Time Effect Analysis and Compensation for a Sliding-Mode Position Observer-Based Sensorless IPMSM Control System,"This paper presents an extended electromotive-force-based discrete-time sliding-mode observer (DSMO) for rotor position/speed sensorless control of interior permanent-magnet synchronous machines (IPMSMs). Without using voltage sensors to measure IPMSM terminal voltages, the reference voltages generated by the vector control system are used as inputs for the DSMO. However, due to the inverter dead-time effect, the mismatch between the reference voltages and actual terminal voltages will degrade the performance of DSMO. In this paper, the periodically oscillating rotor position estimation error caused by the dead-time is first analyzed. Then, a dead-time compensation scheme is proposed to mitigate this position estimation error. The proposed DSMO with the dead-time compensation scheme is validated on an IPMSM control system used in heavy-duty, off-road, hybrid, and electric vehicles.","Rotors,
Voltage measurement,
Observers,
Voltage control,
Current measurement,
Vectors,
Stators"
Blind Interference Alignment for Cellular Networks,"We propose a blind interference alignment scheme for partially connected cellular networks. The scheme cancels both intracell and intercell interference by relying on receivers with one reconfigurable antenna and by allowing users at the cell edge to be served by all the base stations in their proximity. An outer bound for the degrees of freedom is derived for general partially connected networks with single-antenna receivers when knowledge of the channel state information at the transmitter is not available. It is demonstrated that for symmetric scenarios, this outer bound is achieved by the proposed scheme. On the other hand, for asymmetric scenarios, the achievable degrees of freedom are not always equal to the outer bound. However, the penalty is typically small, and the proposed scheme outperforms other blind interference alignment schemes. Moreover, significant reduction of the supersymbol length is achieved compared with a standard blind interference alignment strategy designed for fully connected networks.","Interference,
NIST,
Receivers,
Transmitting antennas,
Switches"
Object Tracking With Multi-View Support Vector Machines,"How to build an accurate and reliable appearance model to improve the performance is a crucial problem in object tracking. Since the multi-view learning can lead to more accurate and robust representation of the object, in this paper, we propose a novel tracking method via multi-view learning framework by using multiple support vector machines (SVM). The multi-view SVMs tracking method is constructed based on multiple views of features and a novel combination strategy. To realize a comprehensive representation, we select three different types of features, i.e., gray scale value, histogram of oriented gradients (HOG), and local binary pattern (LBP), to train the corresponding SVMs. These features represent the object from the perspectives of description, detection, and recognition, respectively . In order to realize the combination of the SVMs under the multi-view learning framework, we present a novel collaborative strategy with entropy criterion, which is acquired by the confidence distribution of the candidate samples. In addition, to learn the changes of the object and the scenario, we propose a novel update scheme based on subspace evolution strategy. The new scheme can control the model update adaptively and help to address the occlusion problems . We conduct our approach on several public video sequences and the experimental results demonstrate that our method is robust and accurate, and can achieve the state-of-the-art tracking performance.",
Large-scale cognitive cellular systems: resource management overview,"This article presents recent advancements in resource management for large-scale DSA systems. Although the problem of spectrum and power allocation is well addressed in the literature, the need for more efficient algorithms still persists due to the exponential growth of the number of wireless devices. Thus, developing efficient distributed approaches has become an attractive solution that can follow the systems' rapid growth. Despite the number of economicdriven methods that have been presented, such as game theoretic solutions, these methods still rely on excessive information exchange, which results in high delays. Inspired by the success of behavioral techniques, mainly learning and filtering approaches, applications of these techniques to spectrum management have attracted more interest due to their distributivity and minimal requirements of information exchange.","Resource management,
Radio spectrum management,
Quality of service,
Interference,
Wireless communication,
Sensors,
Algorithm design and analysis,
Cellular networks,
Cognitive radio"
Adaptive Resource Allocation for Interference Management in Small Cell Networks,"We consider a femto cellular network consisting of multiple neighboring femtocells, e.g., in an enterprise deployment such as shopping malls, stadiums, or corporate premises. We present a practical but suboptimal channel assignment and interference management algorithm for fractional frequency reuse (FFR) wireless networks. More specifically, we propose an adaptive graph coloring approach for resource allocation with the goal of interference management among femtocells as well as achieving fairness among users. While the global-optimum solution has exponential complexity, our proposed scheme has a linear complexity in the number of femtocells. Although suboptimal, we have evaluated our algorithm in small scenarios, where direct evaluation is possible, and found that the achieved minimum user rate using the proposed algorithm is 85% of the optimal minimum rate. Additionally, we have analyzed several practical design considerations of our proposal such as channel feedback, latency, and computational complexity. We demonstrate the performance of our proposed solution against various alternatives and show that it provides better performance under various environment parameters. For example, in a dense femtocell deployment, the performance was improved by 47% over a full frequency reuse scheme.",
Confidence-aware truth estimation in social sensing applications,"This paper presents a confidence-aware maximum likelihood estimation framework to solve the truth estimation problem in social sensing applications. Social sensing has emerged as a new paradigm of data collection, where a group of individuals volunteer (or are recruited) to share certain observations or measurements about the physical world. A key challenge in social sensing applications lies in ascertaining the correctness of reported observations from unvetted data sources with unknown reliability. We refer to this problem as truth estimation. The prior works have made significant efforts to solve this problem by developing various truth estimation algorithms. However, an important limitation exists: they assumed a data source makes all her/his observations with the same degree of confidence, which may not hold in many real-world social sensing applications. In this paper, we develop a new confidence-aware truth estimation scheme that removes this limitation by explicitly considering different degrees of confidence that sources express on the reported data. The new truth estimation scheme solves a maximum likelihood estimation problem to determine both the correctness of collected data and the reliability of data sources. We compare our confidence-aware scheme with the state-of-the-art baselines through both an extensive simulation study and three real world case studies based on Twitter. The evaluation shows that our new scheme outperforms all compared baselines and significantly improves the accuracy of the truth estimation results in social sensing applications.","Sensors,
Maximum likelihood estimation,
Reliability,
Silicon,
Twitter,
Accuracy"
3D scanning deformable objects with a single RGBD sensor,"We present a 3D scanning system for deformable objects that uses only a single Kinect sensor. Our work allows considerable amount of nonrigid deformations during scanning, and achieves high quality results without heavily constraining user or camera motion. We do not rely on any prior shape knowledge, enabling general object scanning with freeform deformations. To deal with the drift problem when nonrigidly aligning the input sequence, we automatically detect loop closures, distribute the alignment error over the loop, and finally use a bundle adjustment algorithm to optimize for the latent 3D shape and nonrigid deformation parameters simultaneously. We demonstrate high quality scanning results in some challenging sequences, comparing with state of art nonrigid techniques, as well as ground truth data.","Three-dimensional displays,
Deformable models,
Shape,
Cameras,
Surface reconstruction,
Standards,
Noise measurement"
Automatic Deformable MR-Ultrasound Registration for Image-Guided Neurosurgery,"In this work, we present a novel algorithm for registration of 3-D volumetric ultrasound (US) and MR using Robust PaTch-based cOrrelation Ratio (RaPTOR). RaPTOR computes local correlation ratio (CR) values on small patches and adds the CR values to form a global cost function. It is therefore invariant to large amounts of spatial intensity inhomogeneity. We also propose a novel outlier suppression technique based on the orientations of the RaPTOR gradients. Our deformation is modeled with free-form cubic B-splines. We analytically derive the derivatives of RaPTOR with respect to the transformation, i.e., the displacement of the B-spline nodes, and optimize RaPTOR using a stochastic gradient descent approach. RaPTOR is validated on MR and tracked US images of neurosurgery. Deformable registration of the US and MR images acquired, respectively, preoperation and postresection is of significant clinical significance, but challenging due to, among others, the large amount of missing correspondences between the two images. This work is also novel in that it performs automatic registration of this challenging dataset. To validate the results, we manually locate corresponding anatomical landmarks in the US and MR images of tumor resection in brain surgery. Compared to rigid registration based on the tracking system alone, RaPTOR reduces the mean initial mTRE over 13 patients from 5.9 to 2.9 mm, and the maximum initial TRE from 17.0 to 5.9 mm. Each volumetric registration using RaPTOR takes about 30 sec on a single CPU core. An important challenge in the field of medical image analysis is the shortage of publicly available dataset, which can both facilitate the advancement of new algorithms to clinical settings and provide a benchmark for comparison. To address this problem, we will make our manually located landmarks available online.","Measurement,
Optimization,
Tumors,
Robustness,
Nonhomogeneous media,
Biomedical imaging,
Correlation"
Automatic Design of a Hyper-Heuristic Framework With Gene Expression Programming for Combinatorial Optimization Problems,"Hyper-heuristic approaches aim to automate heuristic design in order to solve multiple problems instead of designing tailor-made methodologies for individual problems. Hyper-heuristics accomplish this through a high-level heuristic (heuristic selection mechanism and an acceptance criterion). This automates heuristic selection, deciding whether to accept or reject the returned solution. The fact that different problems, or even instances, have different landscape structures and complexity, the design of efficient high-level heuristics can have a dramatic impact on hyper-heuristic performance. In this paper, instead of using human knowledge to design the high-level heuristic, we propose a gene expression programming algorithm to automatically generate, during the instance-solving process, the high-level heuristic of the hyper-heuristic framework. The generated heuristic takes information (such as the quality of the generated solution and the improvement made) from the current problem state as input and decides which low-level heuristic should be selected and the acceptance or rejection of the resultant solution. The benefit of this framework is the ability to generate, for each instance, different high-level heuristics during the problem-solving process. Furthermore, in order to maintain solution diversity, we utilize a memory mechanism that contains a population of both high-quality and diverse solutions that is updated during the problem-solving process. The generality of the proposed hyper-heuristic is validated against six well-known combinatorial optimization problems, with very different landscapes, provided by the HyFlex software. Empirical results, comparing the proposed hyper-heuristic with state-of-the-art hyper-heuristics, conclude that the proposed hyper-heuristic generalizes well across all domains and achieves competitive, if not superior, results for several instances on all domains.",
A protocol for space charge measurements in full-size HVDC extruded cables,"This position paper, prepared by the IEEE DEIS HVDC Cable Systems Technical Committee, illustrates a protocol recommended for the measurement of space charges in full-size HVDC extruded cables during load cycle qualification tests (either prequalification load cycles or type test load cycles). The protocol accounts for the experimental practices of space charge measurements in the thick insulation of coaxial cables in terms of poling time, depolarization time, heating and cooling of specimens, as well as for the experience gained very recently from such kind of measurements performed in the framework of qualification tests relevant to ongoing HVDC cable system projects. The goal of the protocol is not checking the compliance with any maximum acceptable limit of either space charge or electric field. Rather, this protocol aims at assessing the variation of the electric field profile in the cable insulation wall during poling time at the beginning and at the end of load cycle qualification tests for full-size HVDC extruded cables. Indeed, in the design stage the electric field distributions are determined by the cable geometry and by temperature gradient in the insulation. Thus, the design is based on macroscopic parameters conductivity and permittivity and how they depend upon temperature. Any disturbance of the electric field due to space charge accumulation will only be revealed during space charge measurements either in as-manufactured state or in the aged state after load cycle qualification tests.","Power cables,
Space charge,
HVDC transmission,
Power cable insulation,
Charge measurement"
Reverse Nearest Neighbors in Unsupervised Distance-Based Outlier Detection,"Outlier detection in high-dimensional data presents various challenges resulting from the “curse of dimensionality.” A prevailing view is that distance concentration, i.e., the tendency of distances in high-dimensional data to become indiscernible, hinders the detection of outliers by making distance-based methods label all points as almost equally good outliers. In this paper, we provide evidence supporting the opinion that such a view is too simple, by demonstrating that distance-based methods can produce more contrasting outlier scores in high-dimensional settings. Furthermore, we show that high dimensionality can have a different impact, by reexamining the notion of reverse nearest neighbors in the unsupervised outlier-detection context. Namely, it was recently observed that the distribution of points' reverse-neighbor counts becomes skewed in high dimensions, resulting in the phenomenon known as hubness. We provide insight into how some points (antihubs) appear very infrequently in k-NN lists of other points, and explain the connection between antihubs, outliers, and existing unsupervised outlier-detection methods. By evaluating the classic k-NN method, the angle-based technique designed for high-dimensional data, the density-based local outlier factor and influenced outlierness methods, and antihub-based methods on various synthetic and real-world data sets, we offer novel insight into the usefulness of reverse neighbor counts in unsupervised outlier detection.","Standards,
Correlation,
Euclidean distance,
Context,
Educational institutions,
Noise measurement,
Histograms"
Beam-Scanning Reflectarray Antennas: A technical overview and state of the art.,"A detailed overview of various design methodologies and enabling technologies for beam-scanning reflectarray antennas is presented in this article. Numerous advantages of reflectarrays over reflectors and phased arrays are delineated, and representative beam-scanning reflectarray antenna designs are reviewed. For limited field-of-view beam-scanning systems, utilizing the reflector nature of the reflectarray antenna and the feed-tuning technique can provide a simple solution with good performance. On the other hand, for applications where wideangle scan coverage is required, utilizing the array nature of the reflectarray and the aperture phase-tuning approach are the more suitable choices. There are various enabling technologies available for both design methodologies, making them a suitable choice for the new generation of high-speed, high-gain beam-scanning antennas.","Reflector antennas,
Phased arrays,
Antenna feeds,
Aperture antennas"
Target Identity-aware Network Flow for online multiple target tracking,"In this paper we show that multiple object tracking (MOT) can be formulated in a framework, where the detection and data-association are performed simultaneously. Our method allows us to overcome the confinements of data association based MOT approaches; where the performance is dependent on the object detection results provided at input level. At the core of our method lies structured learning which learns a model for each target and infers the best location of all targets simultaneously in a video clip. The inference of our structured learning is done through a new Target Identity-aware Network Flow (TINF), where each node in the network encodes the probability of each target identity belonging to that node. The proposed Lagrangian relaxation optimization finds the high quality solution to the network. During optimization a soft spatial constraint is enforced between the nodes of the graph which helps reducing the ambiguity caused by nearby targets with similar appearance in crowded scenarios. We show that automatically detecting and tracking targets in a single framework can help resolve the ambiguities due to frequent occlusion and heavy articulation of targets. Our experiments involve challenging yet distinct datasets and show that our method can achieve results better than the state-of-art.",
Novel Coordinated Voltage Control for Hybrid Micro-Grid With Islanding Capability,"This paper proposes a new coordinated voltage control (CVC) method with reactive power management scheme (RPMS) for a hybrid micro-grid (MG). The CVC scheme, based on synchronizing the response speeds of different voltage regulating devices, is coordinated with novel RPMS. Two cases, with and without proposed CVC, were simulated in the power system computer aided design (PSCAD)/electromagnetic transients including dc (EMTDC) environment and compared against each other. The case with proposed CVC shows superior performance, when tested for fault triggered islanding, intentional islanding, and MG internal fault. Further, the proposed CVC with RPMS is compared to a voltage regulation method present in literature. The proposed CVC with RPMS provides better voltage regulation, maximizes the fast dynamic reactive power reserve, and improves the transient response and transient stability margin of the hybrid MG.","Voltage control,
Reactive power,
Density estimation robust algorithm,
Generators,
Power system dynamics,
Medium voltage"
Geodesic Information Flows: Spatially-Variant Graphs and Their Application to Segmentation and Fusion,"Clinical annotations, such as voxel-wise binary or probabilistic tissue segmentations, structural parcellations, pathological regions-of-interest and anatomical landmarks are key to many clinical studies. However, due to the time consuming nature of manually generating these annotations, they tend to be scarce and limited to small subsets of data. This work explores a novel framework to propagate voxel-wise annotations between morphologically dissimilar images by diffusing and mapping the available examples through intermediate steps. A spatially-variant graph structure connecting morphologically similar subjects is introduced over a database of images, enabling the gradual diffusion of information to all the subjects, even in the presence of large-scale morphological variability. We illustrate the utility of the proposed framework on two example applications: brain parcellation using categorical labels and tissue segmentation using probabilistic features. The application of the proposed method to categorical label fusion showed highly statistically significant improvements when compared to state-of-the-art methodologies. Significant improvements were also observed when applying the proposed framework to probabilistic tissue segmentation of both synthetic and real data, mainly in the presence of large morphological variability.","Image segmentation,
Manifolds,
Measurement,
Pathology,
Licenses,
Kernel,
Probabilistic logic"
Performance Analysis of IEEE 802.15.6 MAC Protocol under Non-Ideal Channel Conditions and Saturated Traffic Regime,"Recently, the IEEE 802.15.6 Task Group introduced a new wireless communication standard that provides a suitable framework specifically to support the requirements of wireless body area networks (WBANs). The standardization dictates the physical (PHY) layer and medium access control (MAC) layer protocols for WBAN-based communications. Unlike the pre-existing wireless communication standards, IEEE 802.15.6 standardization supports short-range, extremely low power wireless communication with high quality of service and support for high data rates upto 10 Mbps in the vicinity of living tissues. In this work, we construct a discrete-time Markov chain (DTMC) that efficiently depicts the states of an IEEE 802.15.6 CSMA/CA-based WBAN. Following this, we put forward a thorough analysis of the standard in terms of reliability, throughput, average delay, and power consumption. The work concerns non-ideal channel characteristics and a saturated network traffic regime. The major shortcoming of the existing literature on Markov chain-based analysis of IEEE 802.15.6 is that the authors did not take into consideration the time spent by a node awaiting the acknowledgement frame after transmission of a packet, until time-out occurs. Also, most of the work assume that ideal channel characteristics persist for the network which is hardly the case in practice. This work remains distinctive as we take into account the waiting time of a node after it transmits a packet while constructing the DTMC. Based on the DTMC, we perform a user priority (UP)-wise analysis, and justify the importance of the standard from a medical perspective.",
A Parallel Capacitor Control Strategy for Enhanced FRT Capability of DFIG,"This paper presents a novel dc-link scheme for enhancing the fault ride-through (FRT) capability of doubly fed induction generator-based wind turbine (DFIG-WT). The proposed system consists of parallel capacitors with a dedicated control strategy designed to provide means for power evacuation during grid fault conditions. This technically simple and cost-effective scheme was developed considering transmission line autoreclosing which may cause multiple fault inceptions. Simulation studies were carried out to compare the performance of the introduced solution with a DFIG-WT, equipped with the dc chopper and crowbar. The simulation results demonstrate the enhanced performance of the proposed approach in maintaining the dc-link voltage, transient rotor voltages, and currents within the permissible operating range during a bolted three-phase-to-ground fault. The proposed schemes were also tested in response to asymmetrical grid faults, and the enhancement in transient response has been verified. An experimental setup was developed to emulate the behavior of the dc-link circuit during fault conditions. These experimental results demonstrate the effectiveness of the switching parallel capacitors in preventing dc-link overvoltage during imbalance power operation. The discharging capacitor circuit highlighted the capability of tackling the multiple fault inception problems while adhering to grid code requirements.",
Shape Matching Using Multiscale Integral Invariants,"We present a shape descriptor based on integral kernels. Shape is represented in an implicit form and it is characterized by a series of isotropic kernels that provide desirable invariance properties. The shape features are characterized at multiple scales which form a signature that is a compact description of shape over a range of scales. The shape signature is designed to be invariant with respect to group transformations which include translation, rotation, scaling, and reflection. In addition, the integral kernels that characterize local shape geometry enable the shape signature to be robust with respect to undesirable perturbations while retaining discriminative power. Use of our shape signature is demonstrated for shape matching based on a number of synthetic and real examples.","Shape,
Kernel,
Noise,
Robustness,
Indexes,
Pattern recognition,
Shape measurement"
New Multilevel Converter Based on Cascade Connection of Double Flying Capacitor Multicell Converters and Its Improved Modulation Technique,"This paper proposes a new multilevel converter based on the cascade connection of double flying capacitor multicell (DFCM) converters, as multilevel modules, to decrease the voltage diversity of the flying capacitors. Furthermore, a new switching pattern based on the phase-shifted pulse-width modulation technique is proposed to reduce the voltage ripple across the flying capacitors. Moreover, the proposed modulation technique reduces the rms value of the current flowing through flying capacitors. This results in an increase in the life time of flying capacitors and a decrease in the capacitance of the flying capacitors, to keep the same amount of the ripple, meaning a reduction in the physical size of the converter. In addition, this paper presents an analytical approach to calculate the average and rms currents of the insulated gate bipolar transistors (IGBTs)/diodes in the DFCM converter in a closed-form expression. The derived closed-form equations to calculate the average and rms currents of the IGBTs/diodes are utilized to investigate the conduction power losses in a DFCM converter and the proposed multilevel converter. Numerical results of the derived closed-form equations match the simulation results well, which validates the derived equations. Furthermore, simulation results and experimental measurements of the proposed multilevel power converter, configured by cascading two two-cell five-level DFCM converters, are presented to validate the performance of the proposed converter as well as the suggested modulation technique.","Switches,
Capacitors,
Modulation,
Insulated gate bipolar transistors,
Equations,
Mathematical model,
Topology"
"Dynamic Bayesian Networks for Fault Detection, Identification, and Recovery in Autonomous Spacecraft","This paper describes how to exploit the modeling features and inference capabilities of dynamic Bayesian networks (DBN), in designing and implementing an innovative approach to fault detection, identification, and recovery (FDIR) for autonomous spacecrafts (e.g., a Mars rover). In particular, issues like partial observability, uncertain system evolution and system-environment interaction, as well as the prediction and mitigation of imminent failures can be naturally addressed by the proposed approach. The DBN framework can augment the modeling and analytical power of standard FDIR methodologies, while still being able to be integrated into the usual system modeling procedures (like, for instance, fault tree analysis). An FDIR cycle composed of the tasks of diagnosis (identification of the current state of the system), prognosis (identification of the future state under the current conditions), and recovery (selection of the best set of actions the autonomous system can perform, in order to avoid critical situations) is introduced and characterized through a DBN model. In particular, by considering the execution of recovery actions in response to either a current or a future abnormal situation, both reactive as well as preventive recovery can be addressed respectively. The proposed approach has been implemented in an on-board software architecture called Anomaly resolution and prognostic health management for autonomy (ARPHA), realized during the Verifim study funded by the European Space Agency and jointly performed with Thales/Alenia Italy. We report on some of the results obtained by performing a case study concerning the FDIR analysis of the power supply system of the ExoMars rover, by considering different anomalous and failure simulated scenarios; we conclude that ARPHA is able to properly detect and deal with the simulated problems.","Prognostics and health management,
Bayes methods,
Space vehicles,
Inference algorithms,
Probabilistic logic,
Sensor systems"
Silicon Photonic Segmented Modulator-Based Electro-Optic DAC for 100 Gb/s PAM-4 Generation,"We report on the design and characterization of a silicon-on-insulator traveling-wave multi-electrode Mach-Zehnder modulator (MZM). The 2-bit electro-optic (EO) digital-to-analog converter is formed by dividing a series push-pull MZM into two segments, one for each bit. The EO bandwidth of the longer segment of the MZM is measured to be 48 GHz at 0 V reverse bias. We operate the device at speeds up to 50 GBd to create a four-level pulse amplitude modulation signal, and thus generating 100 Gb/s on a single wavelength without signal processing at the transmitter or the receiver. The pre-forward error correction (FEC) bit error rate is estimated to be lower than the hard-decision FEC threshold of 3.8 × 10-3 over 1 km of standard single-mode fiber, and thus leading to error-free transmission at 100 Gb/s.","Electrooptic modulators,
Bit error rate,
Radio frequency,
Bandwidth,
Optical attenuators"
A Multiobjective Sparse Feature Learning Model for Deep Neural Networks,"Hierarchical deep neural networks are currently popular learning models for imitating the hierarchical architecture of human brain. Single-layer feature extractors are the bricks to build deep networks. Sparse feature learning models are popular models that can learn useful representations. But most of those models need a user-defined constant to control the sparsity of representations. In this paper, we propose a multiobjective sparse feature learning model based on the autoencoder. The parameters of the model are learnt by optimizing two objectives, reconstruction error and the sparsity of hidden units simultaneously to find a reasonable compromise between them automatically. We design a multiobjective induced learning procedure for this model based on a multiobjective evolutionary algorithm. In the experiments, we demonstrate that the learning procedure is effective, and the proposed multiobjective model can learn useful sparse features.",
Optimal Dispatch of Residential Photovoltaic Inverters Under Forecasting Uncertainties,"Efforts to ensure reliable operation of existing low-voltage distribution systems with high photovoltaic (PV) generation have focused on the possibility of inverters providing ancillary services such as active power curtailment and reactive power compensation. Major benefits include the possibility of averting overvoltages, which may otherwise be experienced when PV generation exceeds the demand. This paper deals with ancillary service procurement in the face of solar irradiance forecasting errors. In particular, assuming that forecasted PV irradiance can be described by a random variable with known (empirical) distribution, the proposed uncertainty-aware optimal inverter dispatch (OID) framework indicates which inverters should provide ancillary services with a guaranteed a priori risk level of PV generation surplus. To capture forecasting errors and strike a balance between risk of overvoltages and (re)active power reserves, the concept of conditional value-at-risk is advocated. Due to AC power balance equations and binary inverter selection variables, the formulated OID involves the solution of a nonconvex mixed-integer nonlinear program. However, a computationally affordable convex relaxation is derived by leveraging sparsity-promoting regularization approaches and semidefinite relaxation techniques.",
A High-Performance Keyboard Neural Prosthesis Enabled by Task Optimization,"Communication neural prostheses are an emerging class of medical devices that aim to restore efficient communication to people suffering from paralysis. These systems rely on an interface with the user, either via the use of a continuously moving cursor (e.g., mouse) or the discrete selection of symbols (e.g., keyboard). In developing these interfaces, many design choices have a significant impact on the performance of the system. The objective of this study was to explore the design choices of a continuously moving cursor neural prosthesis and optimize the interface to maximize information theoretic performance. We swept interface parameters of two keyboard-like tasks to find task and subject-specific optimal parameters as measured by achieved bitrate using two rhesus macaques implanted with multielectrode arrays. In this paper, we present the highest performing free-paced neural prosthesis under any recording modality with sustainable communication rates of up to 3.5 bits/s. These findings demonstrate that meaningful high performance can be achieved using an intracortical neural prosthesis, and that, when optimized, these systems may be appropriate for use as communication devices for those with physical disabilities.","Bit rate,
Optimization,
Prosthetics,
Keyboards,
Decoding,
Biomedical measurement,
Animals"
Weighted Couple Sparse Representation With Classified Regularization for Impulse Noise Removal,"Many impulse noise (IN) reduction methods suffer from two obstacles, the improper noise detectors and imperfect filters they used. To address such issue, in this paper, a weighted couple sparse representation model is presented to remove IN. In the proposed model, the complicated relationships between the reconstructed and the noisy images are exploited to make the coding coefficients more appropriate to recover the noise-free image. Moreover, the image pixels are classified into clear, slightly corrupted, and heavily corrupted ones. Different data-fidelity regularizations are then accordingly applied to different pixels to further improve the denoising performance. In our proposed method, the dictionary is directly trained on the noisy raw data by addressing a weighted rank-one minimization problem, which can capture more features of the original data. Experimental results demonstrate that the proposed method is superior to several state-of-the-art denoising methods.",
Adaptive Prioritized Random Linear Coding and Scheduling for Layered Data Delivery From Multiple Servers,"In this paper, we deal with the problem of jointly determining the optimal coding strategy and the scheduling decisions when receivers obtain layered data from multiple servers. The layered data is encoded by means of prioritized random linear coding (PRLC) in order to be resilient to channel loss while respecting the unequal levels of importance in the data, and data blocks are transmitted simultaneously in order to reduce decoding delays and improve the delivery performance. We formulate the optimal coding and scheduling decisions problem in our novel framework with the help of Markov decision processes (MDP), which are effective tools for modeling adapting streaming systems. Reinforcement learning approaches are then proposed to derive reduced computational complexity solutions to the adaptive coding and scheduling problems. The novel reinforcement learning approaches and the MDP solution are examined in an illustrative example for scalable video transmission . Our methods offer large performance gains over competing methods that deliver the data blocks sequentially. The experimental evaluation also shows that our novel algorithms offer continuous playback and guarantee small quality variations which is not the case for baseline solutions. Finally, our work highlights the advantages of reinforcement learning algorithms to forecast the temporal evolution of data demands and to decide the optimal coding and scheduling decisions .","Receivers,
Servers,
Encoding,
Decoding,
Delays,
Streaming media,
Scheduling"
"1/f
Noise and Defects in Microelectronic Materials and Devices","This paper reviews and compares predictions of the Dutta-Horn model of low-frequency excess (1/ f) noise with experimental results for thin metal films, MOS transistors, and GaN/AlGaN high-electron mobility transistors (HEMTs). For metal films, mobility fluctuations associated with carrier-defect scattering lead to 1/f noise. In contrast, for most semiconductor devices, the noise usually results from fluctuations in the number of carriers due to charge exchange between the channel and defects, usually at or near a critical semiconductor/insulator interface. The Dutta-Horn model describes the noise with high precision in most cases. Insight into the physical mechanisms that lead to noise in microelectronic materials and devices has been obtained via total-ionizing-dose irradiation and/or thermal annealing, as illustrated with several examples. With the assistance of the Dutta-Horn model, measurements of the noise magnitude and temperature and/or voltage dependence of the noise enable estimates of the energy distributions of defects that lead to 1/f noise. The microstructure of several defects and/or impurities that cause noise in MOS devices (primarily O vacancies) and GaN/AlGaN HEMTs (e.g., hydrogenated impurity centers, N vacancies, and/or Fe centers) have been identified via experiments and density functional theory calculations.","Noise,
Temperature measurement,
Metals,
Noise measurement,
Frequency measurement,
Thermal noise,
Scattering"
BSIFT: Toward Data-Independent Codebook for Large Scale Image Search,"Bag-of-Words (BoWs) model based on Scale Invariant Feature Transform (SIFT) has been widely used in large-scale image retrieval applications. Feature quantization by vector quantization plays a crucial role in BoW model, which generates visual words from the high- dimensional SIFT features, so as to adapt to the inverted file structure for the scalable retrieval. Traditional feature quantization approaches suffer several issues, such as necessity of visual codebook training, limited reliability, and update inefficiency. To avoid the above problems, in this paper, a novel feature quantization scheme is proposed to efficiently quantize each SIFT descriptor to a descriptive and discriminative bit-vector, which is called binary SIFT (BSIFT). Our quantizer is independent of image collections. In addition, by taking the first 32 bits out from BSIFT as code word, the generated BSIFT naturally lends itself to adapt to the classic inverted file structure for image indexing. Moreover, the quantization error is reduced by feature filtering, code word expansion, and query sensitive mask shielding. Without any explicit codebook for quantization, our approach can be readily applied in image search in some resource-limited scenarios. We evaluate the proposed algorithm for large scale image search on two public image data sets. Experimental results demonstrate the index efficiency and retrieval accuracy of our approach.","Visualization,
Quantization (signal),
Vectors,
Hamming distance,
Indexes,
Training,
Feature extraction"
An Extended Flux Model-Based Rotor Position Estimator for Sensorless Control of Salient-Pole Permanent-Magnet Synchronous Machines,"Starting from the classical dynamic model of salient-pole permanent-magnet synchronous machines (PMSMs) expressed in the stationary reference frame, this paper presents a mathematical model reconstruction process for salient-pole PMSMs, from which an extended flux-based machine model is derived. Compared with the commonly used extended electromotive force-based model, the extended flux-based model has notable advantages of simpler model structure and less sensitive to the variations of machine parameters and operating conditions. A new extended flux model-based rotor position estimator is then proposed for sensorless control of salient-pole PMSMs by utilizing a sliding-mode observer with a dynamic position compensator. The latter improves the dynamic performance and low-speed operating capability of the sensorless control system. Both simulation and experimental results are provided to validate the proposed rotor position estimator and the sensorless control system for salient-pole PMSMs.","Rotors,
Mathematical model,
Observers,
Torque,
Load modeling,
Equations"
SEG-SSC: A Framework Based on Synthetic Examples Generation for Self-Labeled Semi-Supervised Classification,"Self-labeled techniques are semi-supervised classification methods that address the shortage of labeled examples via a self-learning process based on supervised models. They progressively classify unlabeled data and use them to modify the hypothesis learned from labeled samples. Most relevant proposals are currently inspired by boosting schemes to iteratively enlarge the labeled set. Despite their effectiveness, these methods are constrained by the number of labeled examples and their distribution, which in many cases is sparse and scattered. The aim of this paper is to design a framework, named synthetic examples generation for self-labeled semi-supervised classification, to improve the classification performance of any given self-labeled method by using synthetic labeled data. These are generated via an oversampling technique and a positioning adjustment model that use both labeled and unlabeled examples as reference. Next, these examples are incorporated in the main stages of the self-labeling process. The principal aspects of the proposed framework are: 1) introducing diversity to the multiple classifiers used by using more (new) labeled data; 2) fulfilling labeled data distribution with the aid of unlabeled data; and 3) being applicable to any kind of self-labeled method. In our empirical studies, we have applied this scheme to four recent self-labeled methods, testing their capabilities with a large number of data sets. We show that this framework significantly improves the classification capabilities of self-labeled techniques.","Prototypes,
Training,
Reliability,
Prediction algorithms,
Cybernetics,
Manifolds,
Standards"
Resource usage prediction algorithms for optimal selection of multimedia content delivery methods,"This paper proposes two algorithms adopted in a prototype network architecture, for optimal selection of multimedia content delivery methods, as well as balanced delivery load, by exploiting a novel resource prediction engine. The proposed architecture exploits both algorithms for the prediction of future multimedia services demands, by providing the ability to keep optimal the distribution of the streaming data, among Content Delivery Networks, cloud-based providers and Home Media Gateways. In addition, the prediction of the upcoming fluctuations of the network, provides the ability to the proposed network architecture, achieving optimized Quality of Service (QoS) and Quality of Experience (QoE) for the end users. Both algorithms were evaluated to establish their efficiency, towards effectively predicting future network traffic demands. The experimental results validated their performance and indicated fields for further research and experimentation.","Media,
Engines,
Quality of service,
Bandwidth,
Multimedia communication,
Prediction algorithms"
EMR: A Scalable Graph-Based Ranking Model for Content-Based Image Retrieval,"Graph-based ranking models have been widely applied in information retrieval area. In this paper, we focus on a well known graph-based model - the Ranking on Data Manifold model, or Manifold Ranking (MR). Particularly, it has been successfully applied to content-based image retrieval, because of its outstanding ability to discover underlying geometrical structure of the given image database. However, manifold ranking is computationally very expensive, which significantly limits its applicability to large databases especially for the cases that the queries are out of the database (new samples). We propose a novel scalable graph-based ranking model called Efficient Manifold Ranking (EMR), trying to address the shortcomings of MR from two main perspectives: scalable graph construction and efficient ranking computation. Specifically, we build an anchor graph on the database instead of a traditional k-nearest neighbor graph, and design a new form of adjacency matrix utilized to speed up the ranking. An approximate method is adopted for efficient out-of-sample retrieval. Experimental results on some large scale image databases demonstrate that EMR is a promising method for real world retrieval applications.","Graphical models,
Information technology,
Information retrieval,
Filtering theory,
Information storage"
A Robust Deep Model for Improved Classification of AD/MCI Patients,"Accurate classification of Alzheimer's disease (AD) and its prodromal stage, mild cognitive impairment (MCI), plays a critical role in possibly preventing progression of memory impairment and improving quality of life for AD patients. Among many research tasks, it is of a particular interest to identify noninvasive imaging biomarkers for AD diagnosis. In this paper, we present a robust deep learning system to identify different progression stages of AD patients based on MRI and PET scans. We utilized the dropout technique to improve classical deep learning by preventing its weight coadaptation, which is a typical cause of overfitting in deep learning. In addition, we incorporated stability selection, an adaptive learning factor, and a multitask learning strategy into the deep learning framework. We applied the proposed method to the ADNI dataset, and conducted experiments for AD and MCI conversion diagnosis. Experimental results showed that the dropout technique is very effective in AD diagnosis, improving the classification accuracies by 5.9% on average as compared to the classical deep learning methods.","Principal component analysis,
Support vector machines,
Magnetic resonance imaging,
Computational modeling,
Positron emission tomography,
Training,
Feature extraction"
Photonic Approach to Wide-Frequency-Range High-Resolution Microwave/Millimeter-Wave Doppler Frequency Shift Estimation,"High-resolution Doppler frequency shift (DFS) estimation in a wide frequency range is essential for radar, microwave/millimeter-wave, and communication systems. In this paper, a photonic approach to DFS estimation is proposed and experimentally demonstrated, providing a high-resolution and frequency-independent solution. In the proposed approach, the DFS between the transmitted microwave signal and the received echo signal is mapped into a doubled frequency spacing between two target optical sidebands by using two cascaded electrooptic modulators. Subsequently, the DFS is then estimated through the spectrum analysis of a low-frequency electrical signal generated from the frequency beating of the two target sidebands with an improved resolution by a factor of 2. In the experiments, DFSs from -90 to 90 kHz are successfully estimated for microwave/millimeter-wave signals at 10, 15, and 30 GHz, where the estimation errors are lower than ±5 ×10-10 Hz. For radial velocity measurement, these results reveal a range from 0 to 900 m/s and a resolution of 1 ×10-11 m/s at 15-GHz frequency band, or a range from 0 to 450 m/s and a resolution of 5 ×10-12 m/s at 30-GHz band. To eliminate the estimation ambiguity, a reference branch is introduced for generating an indicator frequency to discriminate the sign of DFS and the direction of radial velocity for approaching or receding motion. In addition, extended discussions on the signal-to-noise ratio, the minimum measurable DFS, and other detection features of the proposed approach are presented.","Frequency estimation,
Estimation,
Amplitude modulation,
Optical modulation,
Photonics,
Microwave measurement"
Semisupervised ECG Ventricular Beat Classification With Novelty Detection Based on Switching Kalman Filters,"Automatic processing and accurate diagnosis of pathological electrocardiogram (ECG) signals remains a challenge. As long-term ECG recordings continue to increase in prevalence, driven partly by the ease of remote monitoring technology usage, the need to automate ECG analysis continues to grow. In previous studies, a model-based ECG filtering approach to ECG data from healthy subjects has been applied to facilitate accurate online filtering and analysis of physiological signals. We propose an extension of this approach, which models not only normal and ventricular heartbeats, but also morphologies not previously encountered. A switching Kalman filter approach is introduced to enable the automatic selection of the most likely mode (beat type), while simultaneously filtering the signal using appropriate prior knowledge. Novelty detection is also made possible by incorporating a third mode for the detection of unknown (not previously observed) morphologies, and denoted as X-factor. This new approach is compared to state-of-the-art techniques for the ventricular heartbeat classification in the MIT-BIH arrhythmia and Incart databases. F1 scores of 98.3% and 99.5% were found on each database, respectively, which are superior to other published algorithms' results reported on the same databases. Only 3% of all the beats were discarded as X-factor, and the majority of these beats contained high levels of noise. The proposed technique demonstrates accurate beat classification in the presence of previously unseen (and unlearned) morphologies and noise, and provides an automated method for morphological analysis of arbitrary (unknown) ECG leads.","Electrocardiography,
Heart beat,
Morphology,
Databases,
Noise,
Heart rate variability,
Covariance matrices"
Power Cycle Testing of Power Switches: A Literature Survey,"Reliability of power converters and lifetime prediction has been a major topic of research in the last few decades, especially for traction applications. The main failures in high power semiconductors are caused by thermomechanical fatigue. Power cycling and temperature cycling are the two most common thermal acceleration tests used in assessing reliability. The objective of this paper is to study the various power cycling tests found in the literature and to develop generalized steps in planning application specific power cycling tests. A comparison of different tests based on the failures, duration, test circuits, and monitored electrical parameters is presented.","Logic gates,
Insulated gate bipolar transistors,
Testing,
Temperature measurement,
Inverters,
Threshold voltage,
Temperature sensors"
On the Efficacy of Through-Silicon-Via Inductors,"Through-silicon-vias (TSVs) can potentially be used to implement inductors in 3-D integrated systems for minimal footprint and large inductance. However, different from conventional 2-D spiral inductors, TSV inductors are fully buried in the lossy substrate, thus suffering from low quality factors. In this paper, we systematically examine how various process and design parameters affect their performance. A few interesting phenomena that are unique to TSV inductors are observed. We then propose a novel shield mechanism utilizing the microchannel, a technique conventionally used for heat removal, to reduce the substrate loss. The technique increases the quality factor and inductance of the TSV inductor by up to 21× and 17×, respectively. Finally, since full-wave simulations of 3-D structures are time-consuming, we develop a set of compressed sensing-based design strategies for microchannel-shielded TSV inductors, which only requires a minimal number of simulations. It enables us to implement microchannel-shielded TSV inductors of up to 5.44× reduced area compared with spiral inductors of the same design specs (quality factor, inductance, and frequency). To the best of our knowledge, this is the very first in-depth study on TSV inductors to make them practical for high-frequency applications. We hope our study shall point out a new and exciting research direction for 3-D integrated circuit designers.","Inductors,
Through-silicon vias,
Q-factor,
Inductance,
Substrates,
Metals,
Spirals"
Nested Hierarchical Dirichlet Processes,"We develop a nested hierarchical Dirichlet process (nHDP) for hierarchical topic modeling. The nHDP generalizes the nested Chinese restaurant process (nCRP) to allow each word to follow its own path to a topic node according to a per-document distribution over the paths on a shared tree. This alleviates the rigid, single-path formulation assumed by the nCRP, allowing documents to easily express complex thematic borrowings. We derive a stochastic variational inference algorithm for the model, which enables efficient inference for massive collections of text documents. We demonstrate our algorithm on 1.8 million documents from The New York Times and 2.7 million documents from Wikipedia.","Indexes,
Stochastic processes,
Data models,
Bayes methods,
Atomic measurements,
Random variables,
Pattern analysis"
An Efficient List Decoder Architecture for Polar Codes,"Long polar codes can achieve the symmetric capacity of arbitrary binary-input discrete memoryless channels under a low-complexity successive cancelation (SC) decoding algorithm. However, for polar codes with short and moderate code lengths, the decoding performance of the SC algorithm is inferior. The cyclic-redundancy-check (CRC)-aided SC-list (SCL)-decoding algorithm has better error performance than the SC algorithm for short or moderate polar codes. In this paper, we propose an efficient list decoder architecture for the CRC-aided SCL algorithm, based on both algorithmic reformulations and architectural techniques. In particular, an area efficient message memory architecture is proposed to reduce the area of the proposed decoder architecture. An efficient path pruning unit suitable for large list size is also proposed. For a polar code of length 1024 and rate 1/2, when list size L=2 and 4, the proposed list decoder architecture is implemented under a Taiwan Semiconductor Manufacturing Company (TSMC) 90-nm CMOS technology. Compared with the list decoders in the literature, our decoder achieves 1.24-1.83 times the area efficiency.","Decoding,
Measurement,
Computer architecture,
Quantization (signal),
Degradation,
Approximation algorithms,
Random access memory"
A High Temperature Silicon Carbide mosfet Power Module With Integrated Silicon-On-Insulator-Based Gate Drive,"This paper presents a board-level integrated silicon carbide (SiC) mosfet power module for high temperature and high power density application. Specifically, a silicon-on-insulator (SOI)-based gate driver capable of operating at 200 °C ambient temperature is designed and fabricated. The sourcing and sinking current capability of the gate driver are tested under various ambient temperatures. Also, a 1200 V/100 A SiC mosfet phase-leg power module is developed utilizing high temperature packaging technologies. The static characteristics, switching performance, and short-circuit behavior of the fabricated power module are fully evaluated at different temperatures. Moreover, a buck converter prototype composed of the SOI gate driver and SiC power module is built for high temperature continuous operation. The converter is operated at different switching frequencies up to 100 kHz, with its junction temperature monitored by a thermosensitive electrical parameter and compared with thermal simulation results. The experimental results from the continuous operation demonstrate the high temperature capability of the power module at a junction temperature greater than 225 °C.",
Real-Time Multisensor Data Retrieval for Cloud Robotic Systems,"Cloud technology elevates the potential of robotics with which robots possessing various capabilities and resources may share data and combine new skills through cooperation. With multiple robots, a cloud robotic system enables intensive and complicated tasks to be carried out in an optimal and cooperative manner. Multisensor data retrieval (MSDR) is one of the key fundamental tasks to share the resources. Having attracted wide attention, MSDR is facing severe technical challenges. For example, MSDR is particularly difficult when cloud cluster hosts accommodate unpredictable data requests triggered by multiple robots operating in parallel. In these cases, near real-time responses are essential while addressing the problem of the synchronization of multisensor data simultaneously. In this paper, we present a framework targeting near real-time MSDR, which grants asynchronous access to the cloud from the robots. We propose a market-based management strategy for efficient data retrieval. It is validated by assessing several quality-of-service (QoS) criteria, with emphasis on facilitating data retrieval in near real-time. Experimental results indicate that the MSDR framework is able to achieve excellent performance under the proposed management strategy in typical cloud robotic scenarios.",
Interactive Top-k Spatial Keyword queries,"Conventional top-k spatial keyword queries require users to explicitly specify their preferences between spatial proximity and keyword relevance. In this work we investigate how to eliminate this requirement by enhancing the conventional queries with interaction, resulting in Interactive Top-k Spatial Keyword (ITkSK) query. Having confirmed the feasibility by theoretical analysis, we propose a three-phase solution focusing on both effectiveness and efficiency. The first phase substantially narrows down the search space for subsequent phases by efficiently retrieving a set of geo-textual k-skyband objects as the initial candidates. In the second phase three practical strategies for selecting a subset of candidates are developed with the aim of maximizing the expected benefit for learning user preferences at each round of interaction. Finally we discuss how to determine the termination condition automatically and estimate the preference based on the user's feedback. Empirical study based on real PoI datasets verifies our theoretical observation that the quality of top-k results in spatial keyword queries can be greatly improved through only a few rounds of interactions.","Databases,
Search problems,
Context,
Music,
Australia,
Business,
Weight measurement"
Game-Theoretic Models of Electricity Theft Detection in Smart Utility Networks: Providing New Capabilities with Advanced Metering Infrastructure,"The smart grid refers to the modernization of the power grid infrastructure with new technologies, enabling a more intelligently networked automated system with the goal of improving efficiency, reliability, and security, while providing more transparency and choices to electricity customers. A key technology being widely deployed on the consumption side of the grid is advanced metering infrastructure (AMI).",
An Attack-Resistant Trust Model Based on Multidimensional Trust Metrics in Underwater Acoustic Sensor Network,"Underwater acoustic sensor networks (UASNs) have been widely used in many applications where a variable number of sensor nodes collaborate with each other to perform monitoring tasks. A trust model plays an important role in realizing collaborations of sensor nodes. Although many trust models have been proposed for terrestrial wireless sensor networks (TWSNs) in recent years, it is not feasible to directly use these trust models in UASNs due to unreliable underwater communication channel and mobile network environment. To achieve accurate and energy efficient trust evaluation in UASNs, an attack-resistant trust model based on multidimensional trust metrics (ARTMM) is proposed in this paper. The ARTMM mainly consists of three types of trust metrics, which are link trust, data trust, and node trust. During the process of trust calculation, unreliability of communication channel and mobility of underwater environment are carefully analyzed. Simulation results demonstrate that the proposed trust model is quite suitable for mobile underwater environment. In addition, the performance of the ARTMM is clearly better than that of conventional trust models in terms of both evaluation accuracy and energy consumption.","Mathematical model,
Packet loss,
Computational modeling,
Predictive models,
Bit error rate"
Online Diversity Assessment in Evolutionary Multiobjective Optimization: A Geometrical Perspective,"Many diversity metrics have been proposed for offline diversity measurement of the whole population in multiobjective optimization. Most of the existing methods require knowledge of the exact Pareto optimal front or the ideal vector. For this reason, there is no direct approach to use the diversity metrics in an online manner. In this paper we propose an online diversity metric that is inspired by the geometrical interpretation of convergence and diversity. In addition, the proposed method is able to measure the diversity loss caused by any individual in the population. This information is useful in the selection process as the algorithm can perform a diversity-preservation selection based on the measured diversity loss contributed by each individual. To demonstrate the effectiveness of the proposed metric in enhancing the diversification of the solution set, we implement the metric on the well-known multiobjective evolutionary algorithm with decomposition. The simulation results show the applicability and usability of the proposed online diversity measurement.","Convergence,
Measurement,
Vectors,
Optical fibers,
Optimization,
Indexes,
Linear programming"
Navigo: Interest forwarding by geolocations in vehicular Named Data Networking,"This paper proposes Navigo, a location based packet forwarding mechanism for vehicular Named Data Networking (NDN). Navigo takes a radically new approach to address the challenges of frequent connectivity disruptions and sudden network changes in a vehicle network. Instead of forwarding packets to a specific moving car, Navigo aims to fetch specific pieces of data from multiple potential carriers of the data. The design provides (1) a mechanism to bind NDN data names to the producers' geographic area(s); (2) an algorithm to guide Interests towards data producers using a specialized shortest path over the road topology; and (3) an adaptive discovery and selection mechanism that can identify the best data source across multiple geographic areas, as well as quickly react to changes in the V2X network.","Vehicles,
Routing protocols,
Roads,
IP networks,
IEEE 802.11 Standards,
Vehicular ad hoc networks"
"A Low-Power, Dual-Wavelength Photoplethysmogram (PPG) SoC With Static and Time-Varying Interferer Removal","This paper presents a low-power, reflectance-mode photoplethysmogram (PPG) front end with up to 100 μA of static interferer current removal and 87 dB attenuation of time-varying interferers. The chip nominally consumes 425 μW including signal chain circuits, red and IR LED drive power, clocks, digitization and I/O. Measured data shows the noise of the PPG signal to be dominated by the photodiode sensor photon shot noise.","Light emitting diodes,
System-on-chip,
Harmonic analysis,
Noise,
Power harmonic filters,
Photodiodes,
Dynamic range"
Automatic Segmentation of the Spinal Cord and Spinal Canal Coupled With Vertebral Labeling,"Quantifying spinal cord (SC) atrophy in neurodegenerative and traumatic diseases brings important diagnosis and prognosis information for the clinician. We recently developed the PropSeg method, which allows for fast, accurate and automatic segmentation of the SC on different types of MRI contrast (e.g., T1-, T2- and T2*-weighted sequences) and any field of view. However, comparing measurements from the SC between subjects is hindered by the lack of a generic coordinate system for the SC. In this paper, we present a new framework combining PropSeg and a vertebral level identification method, thereby enabling direct inter- and intra-subject comparison of SC measurements for large cohort studies as well as for longitudinal studies. Our segmentation method is based on the multi-resolution propagation of tubular deformable models. Coupled with an automatic intervertebral disk identification method, our segmentation pipeline provides quantitative metrics of the SC and spinal canal such as cross-sectional areas and volumes in a generic coordinate system based on vertebral levels. This framework was validated on 17 healthy subjects and on one patient with SC injury against manual segmentation. Results have been compared with an existing active surface method and show high local and global accuracy for both SC and spinal canal (Dice coefficients =0.91 ± 0.02) segmentation. Having a robust and automatic framework for SC segmentation and vertebral-based normalization opens the door to bias-free measurement of SC atrophy in large cohorts.","Spinal cord,
Image segmentation,
Irrigation,
Deformable models,
Mathematical model,
Transforms,
Measurement"
Targeting Accurate Object Extraction From an Image: A Comprehensive Study of Natural Image Matting,"With the development of digital multimedia technologies, image matting has gained increasing interests from both academic and industrial communities. The purpose of image matting is to precisely extract the foreground objects with arbitrary shapes from an image or a video frame for further editing. It is generally known that image matting is inherently an ill-posed problem because we need to output three images out of only one input image. In this paper, we provide a comprehensive survey of the existing image matting algorithms and evaluate their performance. In addition to the blue screen matting, we systematically divide all existing natural image matting methods into four categories: 1) color sampling-based; 2) propagation-based; 3) combination of sampling-based and propagation-based; and 4) learning-based approaches. Sampling-based methods assume that the foreground and background colors of an unknown pixel can be explicitly estimated by examining nearby pixels. Propagation-based methods are instead based on the assumption that foreground and background colors are locally smooth. Learning-based methods treat the matting process as a supervised or semisupervised learning problem. Via the learning process, users can construct a linear or nonlinear model between the alpha mattes and the image colors using a training set to estimate the alpha matte of an unknown pixel without any assumption about the characteristics of the testing image. With three benchmark data sets, the various matting algorithms are evaluated and compared using several metrics to demonstrate the strengths and weaknesses of each method both quantitatively and qualitatively. Finally, we conclude this paper by outlining the research trends and suggesting a number of promising directions for future development.",
Elastic virtual network function placement,"Nowadays, many cloud providers offer Virtual Network Function (VNF) services that are dynamically scaled according to the workload. Enterprises enjoy these services by only paying for the actual consumed resources. From a cloud provider's standpoint, the cost of these services must be kept as low as possible, while QoS is maintained and service downtime is minimized. In this paper, we introduce Elastic Virtual Network Function Placement (EVNFP) problem and present a model for minimizing operational costs in providing VNF services. In this model, the elasticity overhead and the trade-off between bandwidth and host resource consumption are considered together, while the previous works ignored this perspective of the problem. We propose a solution called Simple Lazy Facility Location (SLFL) that optimizes the placement of VNF instances in response to on-demand workload. Our experiments suggest that SLFL can accept two times more workload while incurring similar operational cost compared to first-fit and random placements.","Bandwidth,
Elasticity,
Cloud computing,
Conferences,
Manganese,
Entropy,
Engines"
"A Scalable, Low-Latency, High-Throughput, Optical Interconnect Architecture Based on Arrayed Waveguide Grating Routers","This paper proposes, simulates, and experimentally demonstrates an optical interconnect architecture for large-scale computing systems. The proposed architecture, Hierarchical Lightwave Optical Interconnect Network (H-LION), leverages wavelength routing in arrayed waveguide grating routers (AWGRs), and computing nodes (or servers) with embedded routers and wavelength-specific optical I/Os. Within the racks and clusters, the interconnect topology is hierarchical all-to-all exploiting passive AWGRs. For the intercluster communication, the proposed architecture exploits a flat and distributed Thin-CLOS topology based on AWGR-based optical switches. H-LION can scale beyond 100 000 nodes while guaranteeing up to 1.83×saving in number of inter-rack cables, and up to 1.5×saving in number of inter-rack switches, when compared with a legacy three-tier Fat Tree network. Network simulation results show a system-wide network throughput reaching as high as 90% of the total possible capacity in case of synthetic traffic with uniform random distribution. Experiments show 97% intracluster throughput for uniform random traffic, and error-free intercluster communication at 10 Gb/s.","Optical switches,
Computer architecture,
Arrayed waveguide gratings,
Servers,
Optical interconnections,
Ports (Computers)"
Tree quantization for large-scale similarity search and classification,"We propose a new vector encoding scheme (tree quantization) that obtains lossy compact codes for high-dimensional vectors via tree-based dynamic programming. Similarly to several previous schemes such as product quantization, these codes correspond to codeword numbers within multiple codebooks. We propose an integer programming-based optimization that jointly recovers the coding tree structure and the codebooks by minimizing the compression error on a training dataset. In the experiments with diverse visual descriptors (SIFT, neural codes, Fisher vectors), tree quantization is shown to combine fast encoding and state-of-the-art accuracy in terms of the compression error, the retrieval performance, and the image classification error.",Encoding
Intra-Prediction and Generalized Graph Fourier Transform for Image Coding,"Intra-prediction is employed in block-based image coding to reduce energy in the prediction residual before transform coding. Conventional intra-prediction schemes copy directly from known pixels across block boundaries as prediction. In this letter, we first cluster differences between neighboring pixel pairs. Then, for each pixel pair, we add the cluster mean to the known pixel for prediction of the neighboring unknown pixel. The cluster indices are transmitted per block, allowing the decoder to mimic the same intra-prediction. We then propose an optimized transform for the prediction residual, based on a generalized version of previously developed Graph Fourier Transform (GFT). Experimental results show that our generalized intra-prediction plus transform coding outperforms combinations of previous intra-prediction and ADST coding by 2.5 dB in PSNR on average.","Image coding,
Predictive models,
Fourier transforms,
Decoding,
Standards,
Discrete cosine transforms"
Fusing noisy fingerprints with distance bounds for indoor localization,"Fusing fingerprints with mutual distance information potentially improves indoor localization accuracy. Such distance information may be spatial (e.g., via inter-node measurement) or temporal (e.g., via dead reckoning). Previous approaches on distance fusion often require exact distance measurement, assume the knowledge of distance distribution, or apply narrowly to some specific sensing technology or scenario. Due to random signal fluctuation, wireless fingerprints are inherently noisy and distance cannot be exactly measured. We hence propose Wi-Dist, a highly accurate indoor localization framework fusing noisy fingerprints with uncertain mutual distances (given by their bounds). Wi-Dist is a generic framework applicable to a wide range of sensors (peer-assisted, INS, etc.) and wireless fingerprints (Wi-Fi, RFID, CSI, etc.). It achieves low errors by a convex-optimization formulation which jointly considers distance bounds and only the first two moments of measured fingerprint signals. We implement Wi-Dist, and conduct extensive simulation and experimental studies based on Wi-Fi in our international airport and university campus. Our results show that Wi-Dist achieves significantly better accuracy than other state-of-the-art schemes (often by more than 40%).","IEEE 802.11 Standard,
Manganese,
Noise measurement,
Accuracy,
Distance measurement,
Sensors,
Dead reckoning"
Learning multiple collaborative tasks with a mixture of Interaction Primitives,"Robots that interact with humans must learn to not only adapt to different human partners but also to new interactions. Such a form of learning can be achieved by demonstrations and imitation. A recently introduced method to learn interactions from demonstrations is the framework of Interaction Primitives. While this framework is limited to represent and generalize a single interaction pattern, in practice, interactions between a human and a robot can consist of many different patterns. To overcome this limitation this paper proposes a Mixture of Interaction Primitives to learn multiple interaction patterns from unlabeled demonstrations. Specifically the proposed method uses Gaussian Mixture Models of Interaction Primitives to model nonlinear correlations between the movements of the different agents. We validate our algorithm with two experiments involving interactive tasks between a human and a lightweight robotic arm. In the first, we compare our proposed method with conventional Interaction Primitives in a toy problem scenario where the robot and the human are not linearly correlated. In the second, we present a proof-of-concept experiment where the robot assists a human in assembling a box.","Trajectory,
Robot kinematics,
Handover,
Hidden Markov models,
Fasteners"
Energy-Aware Web Browsing on Smartphones,"Smartphone based web browsing wastes a lot of power when downloading webpages due to the special characteristics of the wireless radio interface. In this paper, we identify these special characteristics, and address power consumption issues through two novel techniques. First, we reorganize the computation sequence of the web browser when loading a webpage, so that the web browser can first run the computations that will generate new data transmissions and retrieve these data from the web server. Then, the web browser can put the wireless radio interface into low power state, release the radio resource, and then run the remaining computations. Second, we introduce a practical data mining based method to predict the user reading time of webpages, based on which the smartphone can switch to low power state when the reading time is longer than a threshold. To demonstrate the effectiveness of our energy-aware approaches, we develop a testbed with Android phones on T-Mobile UMTS network. Experimental results show that our approach can reduce the power consumption of smartphone by more than 30 percent during web browsing. Moreover, our solution can further reduce the webpage loading time and increase the network capacity.",
Demonstration of a Degenerate Band Edge in Periodically-Loaded Circular Waveguides,"We demonstrate the existence of a special degeneracy condition, called degenerate band edge (DBE), between two Bloch modes in periodically-loaded circular all-metallic waveguides at microwave frequencies. The DBE condition has been associated with a dramatic reduction in group velocity and with some unique resonance properties, but it has not been shown in hollow waveguide structures yet. Hence, we show here its existence in two periodic waveguide examples. The unit cell of the first structure is composed of a circular waveguide loaded with two inner cylinders with elliptical irises with misaligned angles. The second structure is composed by loading the waveguide with elliptical rings. The demonstration of DBE in those waveguide is explained through a simple multi-transmission line approach where the conditions to obtain DBE are clarified, and suggests that the DBE can occur in several other analogous periodic waveguides. These structures can be potentially used to investigate unconventional gain schemes in traveling wave tubes or other kinds of distributed amplifiers, oscillators and novel pulse compressors.","Dispersion,
Periodic structures,
Loaded waveguides,
Waveguide discontinuities,
Oscillators,
Structural rings"
Placing Virtual Machines to Optimize Cloud Gaming Experience,"Optimizing cloud gaming experience is no easy task due to the complex tradeoff between gamer quality of experience (QoE) and provider net profit. We tackle the challenge and study an optimization problem to maximize the cloud gaming provider's total profit while achieving just-good-enough QoE. We conduct measurement studies to derive the QoE and performance models. We formulate and optimally solve the problem. The optimization problem has exponential running time, and we develop an efficient heuristic algorithm. We also present an alternative formulation and algorithms for closed cloud gaming services with dedicated infrastructures, where the profit is not a concern and overall gaming QoE needs to be maximized. We present a prototype system and testbed using off-the-shelf virtualization software, to demonstrate the practicality and efficiency of our algorithms. Our experience on realizing the testbed sheds some lights on how cloud gaming providers may build up their own profitable services. Last, we conduct extensive trace-driven simulations to evaluate our proposed algorithms. The simulation results show that the proposed heuristic algorithms: (i) produce close-to-optimal solutions, (ii) scale to large cloud gaming services with 20,000 servers and 40,000 gamers, and (iii) outperform the state-of-the-art placement heuristic, e.g., by up to 3.5 times in terms of net profits.","Servers,
Games,
Delays,
Graphics processing units,
Cloud computing,
Heuristic algorithms,
Data models"
Relational User Attribute Inference in Social Media,"Nowadays, more and more people are engaged in social media to generate multimedia information, i.e, creating text and photo profiles and posting multimedia messages. Such multimodal social networking activities reveal multiple user attributes such as age, gender, and personal interest. Inferring user attributes is important for user profiling, retrieval, and personalization. Existing work is devoted to inferring user attributes independently and ignores the dependency relations between attributes. In this work, we investigate the problem of relational user attribute inference by exploring the relations between user attributes and extracting both lexical and visual features from online user-generated content. We systematically study six types of user attributes: gender, age, relationship, occupation, interest, and emotional orientation. In view of methodology, we propose a relational latent SVM (LSVM) model to combine a rich set of user features, attribute inference, and attribute relations in a unified framework. In the model, one attribute is selected as the target attribute and others are selected as the auxiliary attributes to assist the target attribute inference. The model infers user attributes and attribute relations simultaneously. Extensive experiments conducted on a collected dataset from Google+ with full attribute annotations demonstrate the effectiveness of the proposed approach in user attribute inference and attribute-based user retrieval.","Feature extraction,
Media,
Social network services,
Multimedia communication,
Correlation,
Visualization,
Support vector machines"
Extending touch-less interaction on vision based wearable device,"A touch-less interaction technology on vision based wearable device is designed and evaluated. Users interact with the application with dynamic hands/feet gestures in front of the camera. Several proof-of-concept prototypes with eleven dynamic gestures are developed based on the touch-less interaction. At last, a comparing user study evaluation is proposed to demonstrate the usability of the touch-less approach, as well as the impact on user's emotion, running on a wearable framework or Google Glass.","Glass,
Cameras,
Usability,
Google,
Three-dimensional displays,
Smart phones,
Visualization"
Design Considerations of a Fault Current Limiting Dynamic Voltage Restorer (FCL-DVR),"This paper proposes a new fault current limiting dynamic voltage restorer (FCL-DVR) concept. The new topology uses a crowbar bidirectional thyristor switch across the output terminals of a conventional back-to-back DVR. In the event of a load short, the DVR controller will deactivate the faulty phase of the DVR and activate its crowbar thyristor to insert the DVR filter reactor into the grid to limit the fault current. A fault condition is detected by sensing the load current and its rate of change. The FCL-DVR will operate with different protection strategies under different fault conditions. Design of the FCL-DVR involves selecting important parameters, such as DVR power rating, dc link voltage of the DVR, output filter reactors and capacitors, and grid-tied transformers is proposed. The design methodology of the proposed FCL-DVR is fully discussed based on power systems computer aided design (PSCAD)/electromagnetic transients including dc (EMTDC) simulation. A scaled-down experimental verification is also carried out. Both modeling and experimental results confirm the effectiveness of the new FCL-DVR concept for performing both voltage compensation and fault current limiting functions.","Fault currents,
Circuit faults,
Thyristors,
Limiting,
Inverters,
Voltage control,
Topology"
Truthful Auction Mechanisms with Performance Guarantee in Secondary Spectrum Markets,"We study a spectrum auction problem where each request from new spectrum users has spatial, temporal, and spectral features. Our goal is to design truthful auction mechanisms that maximize either the overall social efficiency of new users (a.k.a buyers) or the revenue of the spectrum owner (a.k.a seller). Given that the optimal conflict-free spectrum allocation problem is NP-hard, this paper proposes a series of near-optimal auction mechanisms based on the following approximation techniques: linear programming (LP) relaxation, randomized rounding, derandomized rounding, monotone derandomization, and Lavi-Swamy method. Comparing with the prior art, we make two significant advances: First, our auction mechanisms are not only truthful but also provide theoretically-provable performance guarantee, an important feature that existing work under the same auction model does not have. Second, our auction mechanisms support both spatial and temporal spectral reuse, which makes the problem more challenging than existing work that deals with only spatial or temporal reuse. We perform extensive simulations to study the performance of the proposed mechanisms, and the simulation results corroborate our theoretical analysis.","Channel allocation,
Cost accounting,
Resource management,
Licenses,
Linear programming,
Approximation methods,
Educational institutions"
Optimal binary locally repairable codes via anticodes,"This paper presents a construction for several families of optimal binary locally repairable codes (LRCs) with small locality (2 and 3). This construction is based on various anticodes. It provides binary LRCs which attain the Cadambe-Mazumdar bound. Moreover, most of these codes are optimal with respect to the Griesmer bound.","Generators,
Optimized production technology,
Linear codes,
Standards,
Spread spectrum communication,
Binary codes,
Silicon"
PM-PM: PatchMatch With Potts Model for Object Segmentation and Stereo Matching,"This paper presents a unified variational formulation for joint object segmentation and stereo matching, which takes both accuracy and efficiency into account. In our approach, depth-map consists of compact objects, each object is represented through three different aspects: the perimeter in image space; the slanted object depth plane; and the planar bias, which is to add an additional level of detail on top of each object plane in order to model depth variations within an object. Compared with traditional high quality solving methods in low level, we use a convex formulation of the multilabel Potts Model with PatchMatch stereo techniques to generate depth-map at each image in object level and show that accurate multiple view reconstruction can be achieved with our formulation by means of induced homography without discretization or staircasing artifacts. Our model is formulated as an energy minimization that is optimized via a fast primal-dual algorithm, which can handle several hundred object depth segments efficiently. Performance evaluations in the Middlebury benchmark data sets show that our method outperforms the traditional integer-valued disparity strategy as well as the original PatchMatch algorithm and its variants in subpixel accurate disparity estimation. The proposed algorithm is also evaluated and shown to produce consistently good results for various real-world data sets (KITTI benchmark data sets and multiview benchmark data sets).",
Steady-State Load Identification Method of Inductive Power Transfer System Based on Switching Capacitors,"An online steady-state load identification method is proposed to solve the problems related to frequency drift, system robustness deterioration, difficulties in controller design due to the uncertainties in load and mutual inductance variations of an inductive power transfer (IPT) system. Take a Series-Series-type IPT system as an example, an additional capacitor is added into the system to make the system work in two operating modes, and a mathematical model is established according to the two modes for the system identification. Simulation and experimental results have verified the proposed online load identification method. It has demonstrated that the method is accurate and reliable for identifying uncertain loads and magnetic coupling variations if other system parameters are known. The method can be used to improve the system performance with precise control.",
Self-Powered Piezo-Floating-Gate Smart-Gauges Based on Quasi-Static Mechanical Energy Concentrators and Triggers,"Changes in physical processes like ambient temperature or pressure variations occur at frequencies that are significantly lower than 1 Hz. This poses a challenge for designing self-powered sensors that monitor these quasi-static physical processes and at the same time scavenge operational energy for sensing, computation, and storage from the signal being monitored. In this paper, we present a novel paradigm for designing a self-powered sensor/data logger that exploits the physics of negative-stiffness mechanical energy concentrators with the physics of our previously reported piezoelectricity driven impact ionized hot-electron injection (p-IHEI)-based sensors. The operational principle is based on the sudden transitions from unstable mode branch switching during the elastic postbuckling response of slender columns, which are used to generate high-frequency deformations as an input to the p-IHEI-based sensor. The experimental results demonstrate that the proposed self-powered sensor based on an integrated circuit fabricated in a 0.5-μm CMOS technology can count and record the number of quasi-static input events with frequencies spanning less than 1 Hz.","Mechanical sensors,
Strips,
Piezoelectric transducers,
Loading,
Mechanical energy,
Strain"
"Multiattribute Decision Making Based on Interval-Valued Intuitionistic Fuzzy Sets, PSO Techniques, and Evidential Reasoning Methodology","In this paper, we propose a new multiattribute decision making method based on interval-valued intuitionistic fuzzy sets, particle swarm optimization (PSO) techniques, and the evidential reasoning methodology. The proposed method uses the evidential reasoning methodology to construct objective functions of the programming models and uses PSO techniques to get optimal weights of the attributes to get the aggregated interval-valued intuitionistic fuzzy value of each alternative. Then, it calculates the transformed value of the obtained interval-valued intuitionistic fuzzy value of each alternative. The larger the transformed value, the better the preference order of the alternative. The proposed method can overcome the drawbacks of the existing methods for multiattribute decision making based on interval-valued intuitionistic fuzzy sets. It provides us with a useful way for multiattribute decision making based on interval-valued intuitionistic fuzzy sets, PSO techniques, and the evidential reasoning methodology.",
Delay-Based Reservoir Computing: Noise Effects in a Combined Analog and Digital Implementation,"Reservoir computing is a paradigm in machine learning whose processing capabilities rely on the dynamical behavior of recurrent neural networks. We present a mixed analog and digital implementation of this concept with a nonlinear analog electronic circuit as a main computational unit. In our approach, the reservoir network can be replaced by a single nonlinear element with delay via time-multiplexing. We analyze the influence of noise on the performance of the system for two benchmark tasks: 1) a classification problem and 2) a chaotic time-series prediction task. Special attention is given to the role of quantization noise, which is studied by varying the resolution in the conversion interface between the analog and digital worlds.",
AC-Capacitance Techniques for Interface Trap Analysis in GaN-Based Buried-Channel MIS-HEMTs,"Effective interface trap characterization approaches are indispensable in the development of gate stack and dielectric surface passivation technologies in III-nitride (III-N) insulated-gate power switching transistors for enhanced stability and dynamic performance. In III-N metal-insulator-semiconductor high-electron-mobility transistors (MIS-HEMTs) that feature a buried channel, the polarized barrier layer separates the critical dielectric/III-N interface from the two-dimensional electron gas (2DEG) channel and consequently complicates interface trap analysis. The barrier layer not only causes underestimation/uncertainty in interface trap extraction using conventional ac-conductance method but also allows the Fermi level dipping deep into the bandgap at the pinch-off of the 2DEG channel. To address these issues, we analyze the frequency/temperature dispersions of the second slope in capacitance-voltage characteristics and develop systematic ac-capacitance techniques to realize interface trap mapping in MIS-HEMTs. The correlation between ac-capacitance and pulse-mode hysteresis measurements show that appropriate gate bias need to be selected in the interface trap characterization of MIS-HEMTs, in order to match the time constant of interface traps at the Fermi level with ac frequency and pulsewidth.",
ClusterViz: A Cytoscape APP for Cluster Analysis of Biological Network,"Cluster analysis of biological networks is one of the most important approaches for identifying functional modules and predicting protein functions. Furthermore, visualization of clustering results is crucial to uncover the structure of biological networks. In this paper, ClusterViz, an APP of Cytoscape 3 for cluster analysis and visualization, has been developed. In order to reduce complexity and enable extendibility for ClusterViz, we designed the architecture of ClusterViz based on the framework of Open Services Gateway Initiative. According to the architecture, the implementation of ClusterViz is partitioned into three modules including interface of ClusterViz, clustering algorithms and visualization and export. ClusterViz fascinates the comparison of the results of different algorithms to do further related analysis. Three commonly used clustering algorithms, FAG-EC, EAGLE and MCODE, are included in the current version. Due to adopting the abstract interface of algorithms in module of the clustering algorithms, more clustering algorithms can be included for the future use. To illustrate usability of ClusterViz, we provided three examples with detailed steps from the important scientific articles, which show that our tool has helped several research teams do their research work on the mechanism of the biological networks.","Clustering algorithms,
Algorithm design and analysis,
Partitioning algorithms,
Proteins,
Visualization,
Protein engineering"
Optimal Control of Nonlinear Continuous-Time Systems in Strict-Feedback Form,"This paper proposes a novel optimal tracking control scheme for nonlinear continuous-time systems in strict-feedback form with uncertain dynamics. The optimal tracking problem is transformed into an equivalent optimal regulation problem through a feedforward adaptive control input that is generated by modifying the standard backstepping technique. Subsequently, a neural network-based optimal control scheme is introduced to estimate the cost, or value function, over an infinite horizon for the resulting nonlinear continuous-time systems in affine form when the internal dynamics are unknown. The estimated cost function is then used to obtain the optimal feedback control input; therefore, the overall optimal control input for the nonlinear continuous-time system in strict-feedback form includes the feedforward plus the optimal feedback terms. It is shown that the estimated cost function minimizes the Hamilton-Jacobi-Bellman estimation error in a forward-in-time manner without using any value or policy iterations. Finally, optimal output feedback control is introduced through the design of a suitable observer. Lyapunov theory is utilized to show the overall stability of the proposed schemes without requiring an initial admissible controller. Simulation examples are provided to validate the theoretical results.","Optimal control,
Nonlinear dynamical systems,
Feedforward neural networks,
Vehicle dynamics,
Backstepping,
Adaptive systems"
Benchmark for Algorithms Segmenting the Left Atrium From 3D CT and MRI Datasets,"Knowledge of left atrial (LA) anatomy is important for atrial fibrillation ablation guidance, fibrosis quantification and biophysical modelling. Segmentation of the LA from Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) images is a complex problem. This manuscript presents a benchmark to evaluate algorithms that address LA segmentation. The datasets, ground truth and evaluation code have been made publicly available through the http://www.cardiacatlas.org website. This manuscript also reports the results of the Left Atrial Segmentation Challenge (LASC) carried out at the STACOM'13 workshop, in conjunction with MICCAI'13. Thirty CT and 30 MRI datasets were provided to participants for segmentation. Each participant segmented the LA including a short part of the LA appendage trunk and proximal sections of the pulmonary veins (PVs). We present results for nine algorithms for CT and eight algorithms for MRI. Results showed that methodologies combining statistical models with region growing approaches were the most appropriate to handle the proposed task. The ground truth and automatic segmentations were standardised to reduce the influence of inconsistently defined regions (e.g., mitral plane, PVs end points, LA appendage). This standardisation framework, which is a contribution of this work, can be used to label and further analyse anatomical regions of the LA. By performing the standardisation directly on the left atrial surface, we can process multiple input data, including meshes exported from different electroanatomical mapping systems.",
Learning driving styles for autonomous vehicles from demonstration,"It is expected that autonomous vehicles capable of driving without human supervision will be released to market within the next decade. For user acceptance, such vehicles should not only be safe and reliable, they should also provide a comfortable user experience. However, individual perception of comfort may vary considerably among users. Whereas some users might prefer sporty driving with high accelerations, others might prefer a more relaxed style. Typically, a large number of parameters such as acceleration profiles, distances to other cars, speed during lane changes, etc., characterize a human driver's style. Manual tuning of these parameters may be a tedious and error-prone task. Therefore, we propose a learning from demonstration approach that allows the user to simply demonstrate the desired style by driving the car manually. We model the individual style in terms of a cost function and use feature-based inverse reinforcement learning to find the model parameters that fit the observed style best. Once the model has been learned, it can be used to efficiently compute trajectories for the vehicle in autonomous mode. We show that our approach is capable of learning cost functions and reproducing different driving styles using data from real drivers.",
Robust Estimators for Variance-Based Device-Free Localization and Tracking,"Device-free localization systems, such as variance-based radio tomographic imaging (VRTI), use received signal strength (RSS) variations caused by human motion in a static wireless network to locate and track people in the area of the network, even through walls. However, intrinsic motion, such as branches moving in the wind or rotating or vibrating machinery, also causes RSS variations which degrade the performance of a localization system. In this paper, we propose a new estimator, least squares variance-based radio tomography (LSVRT), which reduces the impact of the variations caused by intrinsic motion. We compare the novel method to subspace variance-based radio tomography (SubVRT) and VRTI. SubVRT also reduces intrinsic noise compared to VRTI, but LSVRT achieves better localization accuracy and does not require manually tuning additional parameters compared to VRTI. We also propose and test an online calibration method so that LSVRT and SubVRT do not require “empty-area” calibration and thus can be used in emergency situations. Experimental results from five data sets collected during three experimental deployments show that both estimators, using online calibration, can reduce localization root mean squared error by more than 40 percent compared to VRTI. In addition, the Kalman filter tracking results from both estimators have 97th percentile error of 1.3 m, a 60 percent reduction compared to VRTI.","Covariance matrices,
Calibration,
Noise,
Mobile computing,
Vectors,
Radio frequency,
Tracking"
A Time Fairness-Based MAC Algorithm for Throughput Maximization in 802.11 Networks,"This paper focuses on designing a distributed medium access control algorithm for fairly sharing network resources among contending stations in an 802.11 wireless network. Because the notion of fairness is not universal and there lacks a rigorous analysis on the relationships among the four types of most popular fairness criteria, we first mathematically prove that there exist certain connections between these types of fairness criteria. We then propose an efficient medium access algorithm that aims at achieving time fairness and throughput enhancement in a fully distributed manner. The core idea of our proposed algorithm lies in that each station needs to select an appropriate contention window size so as to fairly share the channel occupancy time and maximize the throughput under the time fairness constraint. The derivation of the proper contention window size is addressed rigorously. We evaluate the performance of our proposed algorithm through an extensive simulation study, and the evaluation results demonstrate that our proposed algorithm leads to nearly perfect time fairness, high throughput, and low collision overhead.",
Cluster adaptive training for deep neural network,"Although context-dependent DNN-HMM systems have achieved significant improvements over GMM-HMM systems, there still exists big performance degradation if the acoustic condition of the test data mismatches that of the training data. Hence, adaptation and adaptive training of DNN are of great research interest. Previous works mainly focus on adapting the parameters of a single DNN by regularized or selective fine-tuning, applying linear transforms to feature or hidden-layer output, or introducing vector representation of non-speech variability into the input. These methods all require relatively large number of parameters to be estimated during adaptation. In contrast, this paper employs the cluster adaptive training (CAT) framework for DNN adaptation. Here, multiple DNNs are constructed to form the bases of a canonical parametric space. During adaptation, an interpolation vector, specific to a particular acoustic condition, is used to combine the multiple DNN bases into a single adapted DNN. The DNN bases can also be constructed at layer level for more flexibility. The CAT-DNN approach was evaluated on an English switchboard task in unsupervised adaptation mode. It achieved significant WER reductions over the unadapted DNN-HMM, relative 6% to 8.5%, with only 10 parameters.",
Design and Application of a VOC-Monitoring System Based on a ZigBee Wireless Sensor Network,"Monitoring volatile organic compound (VOC) pollution levels in indoor environments is of great importance for the health and comfort of individuals, especially considering that people currently spend >80% of their time indoors. The primary aim of this paper is to design a low-power ZigBee sensor network and internode data reception control framework to use in the real-time acquisition and communication of data concerning air pollutant levels from VOCs. The network consists of end device sensors with photoionization detectors, routers that propagate the network over long distances, and a coordinator that communicates with a computer. The design is based on the ATmega16 microcontroller and the Atmel RF230 ZigBee module, which are used to effectively process communication data with low power consumption. Priority is given to power consumption and sensing efficiency, which are achieved by incorporating various smart tasking and power management protocols. The measured data are displayed on a computer monitor through a graphical user interface. The preliminary experimental results demonstrate that the wireless sensor network system can monitor VOC concentrations with a high level of accuracy and is thus suitable for automated environmental monitoring. Both good indoor air quality and energy conservation can be achieved by integrating the VOC monitoring system proposed in this paper with the residential integrated ventilation controller.","Sensors,
Wireless sensor networks,
Monitoring,
Zigbee,
Energy consumption,
Hardware,
Base stations"
Optimal Scheduling for Multi-Radio Multi-Channel Multi-Hop Cognitive Cellular Networks,"Due to the emerging various data services, current cellular networks have been experiencing a surge of data traffic and are already overloaded; thus, they are not able to meet the ever exploding traffic demand. In this study, we first introduce a multi-radio multi-channel multi-hop cognitive cellular network (M
3
C
2
N) architecture to enhance network throughput. Under the proposed architecture, we then investigate the minimum length scheduling problem by exploring joint frequency allocation, link scheduling, and routing. In particular, we first formulate a maximal independent set based joint scheduling and routing optimization problem called original optimization problem (OOP). It is a mixed integer non-linear programming (MINLP) and generally NP-hard problem. Then, employing a column generation based approach, we develop an
ϵ
-bounded approximation algorithm which can obtain an
ϵ
-bounded approximate result of OOP. Noticeably, in fact we do not need to find the maximal independent sets in the proposed algorithm, which are usually assumed to be given in previous works although finding all of them is NP-complete. We also revisit the minimum length scheduling problem by considering uncertain channel availability. Simulation results show that we can efficiently find the
ϵ
-bounded approximate results and the optimal result as well, i.e., when
ϵ=0%
in the algorithm.",
Conditional Moment Closure Schemes for Studying Stochastic Dynamics of Genetic Circuits,"Inside individual cells, stochastic expression drives random fluctuations in gene product copy numbers, which corrupts functioning of both natural and synthetic genetic circuits. Dynamic models of genetic circuits are formulated stochastically using the chemical master equation framework. Since obtaining probability distributions can be computationally expensive in these models, noise is typically investigated through lower-order statistical moments (mean, variance, correlation, skewness, etc.) of mRNA/proteins levels. However, due to the nonlinearities in genetic circuits, this moment dynamics is typically not closed, in the sense that the time derivative of the lower-order statistical moments depends on high-order moments. Moment equations are closed by expressing higher-order moments as nonlinear functions of lower-order moments, a technique commonly referred to as moment closure. We provide a new moment closure scheme for studying stochastic dynamics of genetic circuits, where genes randomly toggle between transcriptionally active and inactive states. The method is based on conditioning protein levels on active states of genes and then expressing higher-order moments as functions of lower-order conditional moments. The conditional closure scheme is illustrated on different circuit motifs and found to outperform existing closure techniques. Rapid computation of stochasticity through closure methods will enable improved characterization and design of synthetic circuits that exhibit robust performance in spite of noisy expression of underlying genes.","Proteins,
Mathematical model,
Genetics,
Integrated circuit modeling,
Noise,
Random variables,
Stochastic processes"
Multimodal Wearable Sensing for Fine-Grained Activity Recognition in Healthcare,"State-of-the-art in-home activity recognition schemes with wearable devices are mostly capable of detecting coarse-grained activities (sitting, standing, walking, or lying down), but can't distinguish complex activities (sitting on the floor versus the sofa or bed). Such schemes often aren't effective for emerging critical healthcare applications -- for example, in remote monitoring of patients with Alzheimer's disease, bulimia, or anorexia -- because they require a more comprehensive, contextual, and fine-grained recognition of complex daily user activities. Here, a novel approach for in-home, fine-grained activity recognition uses multimodal wearable sensors on multiple body positions, along with lightly deployed Bluetooth beacons in the environment. In particular, this solution exploits measuring user's ambient environment and location context with wearable sensing and Bluetooth beacons, along with user movement captured with accelerometer and gyroscope sensors. The proposed algorithm is a two-level supervised classifier with both levels running on a server. In the first level, multisensor data from wearables on each body position are collected and analyzed using the proposed modified conditional random field (CRF)-based supervised activity classifier. The classified activity state from each of the wearables data are then fused for deciding the user's final activity state. Preliminary experimental results are presented on the classification of 19 complex daily activities of a user at home.",
"1/
f
Noise Characteristics of MoS2 Thin-Film Transistors: Comparison of Single and Multilayer Structures","We report on the transport and low-frequency noise measurements of MoS2 thin-film transistors (TFTs) with thin (2-3 atomic layers) and thick (15-18 atomic layers) channels. The back-gated transistors made with the relatively thick MoS2 channels have advantages of the higher electron mobility and lower noise level. The normalized noise spectral density of the low-frequency 1/f noise in thick MoS2 transistors is of the same level as that in graphene. The MoS2 transistors with the atomically thin channels have substantially higher noise levels. It was established that, unlike in graphene devices, the noise characteristics of MoS2 transistors with thick channels (15-18 atomic planes) could be described by the McWhorter model. Our results indicate that the channel thickness optimization is crucial for practical applications of MoS2 TFTs.","Thin film transistors,
Graphene,
Atomic layer deposition,
Low-frequency noise,
Logic gates"
Semantic-Based Location Recommendation With Multimodal Venue Semantics,"In recent years, we have witnessed a flourishing of location -based social networks. A well-formed representation of location knowledge is desired to cater to the need of location sensing, browsing, navigation and querying. In this paper, we aim to study the semantics of point-of-interest (POI) by exploiting the abundant heterogeneous user generated content (UGC) from different social networks. Our idea is to explore the text descriptions, photos, user check-in patterns, and venue context for location semantic similarity measurement. We argue that the venue semantics play an important role in user check-in behavior. Based on this argument, a unified POI recommendation algorithm is proposed by incorporating venue semantics as a regularizer. In addition to deriving user preference based on user-venue check-in information, we place special emphasis on location semantic similarity. Finally, we conduct a comprehensive performance evaluation of location semantic similarity and location recommendation over a real world dataset collected from Foursquare and Instagram. Experimental results show that the UGC information can well characterize the venue semantics, which help to improve the recommendation performance.","Semantics,
Context,
Educational institutions,
Vectors,
Social network services,
Ice,
Noise"
Tunable Bandpass Filter Based on Partially Magnetized Ferrite LTCC With Embedded Windings for SoP Applications,"Tunable filters that are based on ferrite materials often require large and bulky electromagnets. In this work, we present a tunable filter in the Ku-band, which is realized in multilayer ferrite LTCC substrate with embedded bias windings, thus negating the need of a large electromagnet. Also, because of the embedded windings, the bias fields are not lost at the air-substrate interface and therefore the field and current requirements are reduced by an order of magnitude as compared to the previously reported filters. A simulation strategy that uses full permeability tensor with arbitrarily directed magnetic fields has been used to model the filter on a partially magnetized ferrite substrate. Special attention has also been paid to approximate the non-uniform magneto-static fields produced by the embedded windings. The complete design is implemented in 10 layers of ferrite LTCC, making it the first magnetically tunable filter with embedded windings and extremely small size [(5 × 5 × 1.1) mm3]. The filter demonstrates a measured tunability of 4% and an insertion loss of 2.3 dB. With the small form factor, embedded windings, and low bias requirements, the design is highly suitable for compact and tunable SoP applications.","Ferrites,
Magnetostatics,
Windings,
Magnetic resonance,
Magnetic separation,
Substrates,
Permeability"
On Hierarchical Power Scheduling for the Macrogrid and Cooperative Microgrids,"Although considerable advances have been made in single microgrid (MG) systems, the problem of cooperation among MGs and the macrogrid has attracted considerable interest only recently. As in wireless communications systems, exploiting the temporal, spatial, and technological diversities in multiple cooperative MGs could bring about more efficient power generation and distribution. This paper investigates a hierarchical power scheduling approach to optimally manage power trading, storage, and distribution in a smart power grid with a macrogrid and cooperative MGs. We first formulate the problem as a convex optimization problem and then decompose it into a two-tier formulation. The first-tier problem jointly considers user utility, transmission cost, and grid load variance, while the second-tier problem minimizes the power generation and transmission cost, and exploits distributed storage in the MGs. We develop an effective online algorithm to solve the first-tier problem and prove its asymptotic optimality, as well as a distributed optimal algorithm for solving the second-tier problem. The proposed algorithms are evaluated with trace-driven simulations and are shown to outperform several existing schemes with considerable gains.",
Sparsity-Aware Sensor Collaboration for Linear Coherent Estimation,"In the context of distributed estimation, we consider the problem of sensor collaboration, which refers to the act of sharing measurements with neighboring sensors prior to transmission to a fusion center. While incorporating the cost of sensor collaboration, we aim to find optimal sparse collaboration schemes subject to a certain information or energy constraint. Two types of sensor collaboration problems are studied: minimum energy with an information constraint; and maximum information with an energy constraint. To solve the resulting sensor collaboration problems, we present tractable optimization formulations and propose efficient methods that render near-optimal solutions in numerical experiments. We also explore the situation in which there is a cost associated with the involvement of each sensor in the estimation scheme. In such situations, the participating sensors must be chosen judiciously. We introduce a unified framework to jointly design the optimal sensor selection and collaboration schemes. For a given estimation performance, we empirically show that there exists a trade-off between sensor selection and sensor collaboration.",
Multi-task assignment for crowdsensing in mobile social networks,"Mobile crowdsensing is a new paradigm in which a crowd of mobile users exploit their carried smart devices to conduct complex computation and sensing tasks in mobile social networks (MSNs). In this paper, we focus on the task assignment problem in mobile crowdsensing. Unlike traditional task scheduling problems, the task assignment in mobile crowdsensing must follow the mobility model of users in MSNs. To solve this problem, we propose an oFfline Task Assignment (FTA) algorithm and an oNline Task Assignment (NTA) algorithm. Both FTA and NTA adopt a greedy task assignment strategy. Moreover, we prove that the FTA algorithm is an optimal offline task assignment algorithm, and give a competitive ratio of the NTA algorithm. In addition, we demonstrate the significant performance of our algorithms through extensive simulations, based on four real MSN traces and a synthetic MSN trace.","Mobile communication,
Mobile computing,
Sensors,
Computers,
IEEE 802.11 Standard,
Algorithm design and analysis,
Conferences"
A Patch Antenna With a Varactor-Loaded Slot for Reconfigurable Dual-Band Operation,"A new design approach for a microstrip patch antenna to achieve reconfigurable dual-band operation with tunable frequency ratio is introduced. The approach uses a lumped capacitor in the middle of a slotted patch antenna, which results in two resonant frequencies. The two resonant frequencies and their ratio are functions of the capacitance value. If a varactor with an appropriate biasing network is used, electronic tuning is realized by changing the applied DC voltage. To understand the dual-resonance behavior of the proposed antenna, an equivalent circuit model based on the transmission line theory of the antenna is established, considering the slot effect and the lumped capacitor. The results are verified with full wave simulation. Furthermore, measurements for fabricated antenna prototypes operating in 2-4.5 GHz are carried out for validation, and the performance shows a tunable frequency ratio from 1.45 to 1.93 with a capacitance range from 0.31 to 0.74 pF. It is worthwhile to point out that the radiation patterns are similar at both bands because both resonances are due to the fundamental TM01 mode.","Resonant frequency,
Antenna measurements,
Capacitors,
Dual band,
Patch antennas,
Tuning"
Fully Connected Cascade Artificial Neural Network Architecture for Attention Deficit Hyperactivity Disorder Classification From Functional Magnetic Resonance Imaging Data,"Automated recognition and classification of brain diseases are of tremendous value to society. Attention deficit hyperactivity disorder (ADHD) is a diverse spectrum disorder whose diagnosis is based on behavior and hence will benefit from classification utilizing objective neuroimaging measures. Toward this end, an international competition was conducted for classifying ADHD using functional magnetic resonance imaging data acquired from multiple sites worldwide. Here, we consider the data from this competition as an example to illustrate the utility of fully connected cascade (FCC) artificial neural network (ANN) architecture for performing classification. We employed various directional and nondirectional brain connectivity-based methods to extract discriminative features which gave better classification accuracy compared to raw data. Our accuracy for distinguishing ADHD from healthy subjects was close to 90% and between the ADHD subtypes was close to 95%. Further, we show that, if properly used, FCC ANN performs very well compared to other classifiers such as support vector machines in terms of accuracy, irrespective of the feature used. Finally, the most discriminative connectivity features provided insights about the pathophysiology of ADHD and showed reduced and altered connectivity involving the left orbitofrontal cortex and various cerebellar regions in ADHD.","FCC,
Training,
Artificial neural networks,
Accuracy,
Neurons,
Magnetic resonance imaging,
Computer architecture"
Electrically and Magnetically Biased Graphene-Based Cylindrical Waveguides: Analysis and Applications as Reconfigurable Antennas,"The propagation of surface waves along electrically and magnetically biased graphene-based cylindrical waveguides (GCWs) is investigated in detail. Analytical dispersion equations are derived for several GCW geometries, considering the presence of an inner metallic core and multiple (coaxial-like) graphene layers. The proposed formulation reveals a fundamental connection between surface plasmons found in GCWs/carbon nanotubes and planar graphene structures. Numerical results confirm the higher confinement of modes supported by GCWs compared with their planar counterparts, while keeping a similar level of losses. The proposed structure is applied to develop plasmonic reconfigurable dipole antennas in the low THz band, which provide higher radiation efficiency than current graphene-based radiators, without requiring the presence of bulky lenses. We envision that the proposed GCWs may find application in reconfigurable THz transceivers, near-field application, wireless interconnects, and sensing systems.","Graphene,
Plasmons,
Surface waves,
Magnetic cores,
Magnetic resonance imaging,
Chemicals,
Dispersion"
A Multi-Objective Optimization Scheduling Method Based on the Ant Colony Algorithm in Cloud Computing,"For task-scheduling problems in cloud computing, a multi-objective optimization method is proposed here. First, with an aim toward the biodiversity of resources and tasks in cloud computing, we propose a resource cost model that defines the demand of tasks on resources with more details. This model reflects the relationship between the user's resource costs and the budget costs. A multi-objective optimization scheduling method has been proposed based on this resource cost model. This method considers the makespan and the user's budget costs as constraints of the optimization problem, achieving multi-objective optimization of both performance and cost. An improved ant colony algorithm has been proposed to solve this problem. Two constraint functions were used to evaluate and provide feedback regarding the performance and budget cost. These two constraint functions made the algorithm adjust the quality of the solution in a timely manner based on feedback in order to achieve the optimal solution. Some simulation experiments were designed to evaluate this method's performance using four metrics: 1) the makespan; 2) cost; 3) deadline violation rate; and 4) resource utilization. Experimental results show that based on these four metrics, a multi-objective optimization method is better than other similar methods, especially as it increased 56.6% in the best case scenario.","Scheduling,
Optimization,
Processor scheduling,
Cloud computing,
Ant colony optimization,
Memory management,
Resource management"
An Efficient Second-Order Approach to Factorize Sparse Matrices in Recommender Systems,"Recommender systems are an important kind of learning systems, which can be achieved by latent-factor (LF)-based collaborative filtering (CF) with high efficiency and scalability. LF-based CF models rely on an optimization process with respect to some desired latent features; however, most of them employ first-order optimization algorithms, e.g., gradient decent schemes, to conduct their optimization task, thereby failing in discovering patterns reflected by higher order information. This work proposes to build a new LF-based CF model via second-order optimization to achieve higher accuracy. We first investigate a Hessian-free optimization framework, and employ its principle to avoid direct usage of the Hessian matrix by computing its product with an arbitrary vector. We then propose the Hessian-free optimization-based LF model, which is able to extract latent factors from the given incomplete matrices via a second-order optimization process. Compared with LF models based on first-order optimization algorithms, experimental results on two industrial datasets show that the proposed one can offer higher prediction accuracy with reasonable computational efficiency. Hence, it is a promising model for implementing high-performance recommenders.","Optimization,
Sparse matrices,
Computational modeling,
Approximation methods,
Informatics,
Accuracy,
Linear systems"
Automatic Annotation of Seismocardiogram With High-Frequency Precordial Accelerations,"Seismocardiogram (SCG) is the low-frequency vibrations signal recorded from the chest using accelerometers. Peaks on dorsoventral and sternal SCG correspond to specific cardiac events. Prior research work has shown the potential of extracting such peaks for various types of monitoring and diagnosis applications. However, annotation of these peaks is not a trivial task and complicated in some subjects. In this paper, an automated method is proposed to annotate these peaks. The high-frequency accelerations obtained from the same accelerometer, used to record SCG with, were used to facilitate the annotation of the SCG. Algorithms were developed for detection of isovolumic moment (IM) and aortic valve closure (AC) points of SCG. Four different envelope calculation methods were used: cardiac sound characteristic waveform (CSCW), Shannon, absolute, and Hilbert. The algorithms were evaluated based on a dataset including 18 subjects undergoing lower body negative pressure and were further tested with another dataset, which included 67 subjects. These datasets had been previously manually annotated. The algorithm based on CSCW envelope calculation produced the highest detection accuracy for both IM and AC. The overall CSCW algorithm detection accuracy for the test dataset was 98.7% and 99.1% for the IM and AC points, respectively.","Heart rate,
Accuracy,
Informatics,
Educational institutions,
Electrocardiography,
Acceleration,
Accelerometers"
A Smart Home Test Bed for Undergraduate Education to Bridge the Curriculum Gap From Traditional Power Systems to Modernized Smart Grids,"There is a worldwide trend to modernize old power grid infrastructures to form future smart grids, which will achieve efficient, flexible energy consumption by using the latest technologies in communication, computing, and control. Smart grid initiatives are moving power systems curricula toward smart grids. Although the components of smart grids fall within the broader discipline of electrical and computer engineering, undergraduate students are rarely assigned single design projects that require classic power systems knowledge combined with communication, computing, and control. Therefore, as a significant step toward potential curriculum changes, this paper presents such a project, a smart home test bed based on the pedagogical model of project-based learning (PBL) for undergraduate education. The proposed test bed allows undergraduates to gain key knowledge in smart grid topics, such as flattening demand peaks, real-time price response, wireless sensor networks, machine learning, pattern recognition, embedded system programming, user interface design, circuit design, and databases. This is well aligned with smart grid initiatives and provides a platform for students to develop their creativity in engineering design. It also offers real-life examples to be used for raising general public awareness of energy conservation.","Smart homes,
Smart grids,
Home appliances,
Sensors,
Educational institutions,
Prototypes"
A Topology Potential-Based Method for Identifying Essential Proteins from PPI Networks,"Essential proteins are indispensable for cellular life. It is of great significance to identify essential proteins that can help us understand the minimal requirements for cellular life and is also very important for drug design. However, identification of essential proteins based on experimental approaches are typically time-consuming and expensive. With the development of high-throughput technology in the post-genomic era, more and more protein-protein interaction data can be obtained, which make it possible to study essential proteins from the network level. There have been a series of computational approaches proposed for predicting essential proteins based on network topologies. Most of these topology based essential protein discovery methods were to use network centralities. In this paper, we investigate the essential proteins' topological characters from a completely new perspective. To our knowledge it is the first time that topology potential is used to identify essential proteins from a protein-protein interaction (PPI) network. The basic idea is that each protein in the network can be viewed as a material particle which creates a potential field around itself and the interaction of all proteins forms a topological field over the network. By defining and computing the value of each protein's topology potential, we can obtain a more precise ranking which reflects the importance of proteins from the PPI network. The experimental results show that topology potential-based methods TP and TP-NC outperform traditional topology measures: degree centrality (DC), betweenness centrality (BC), closeness centrality (CC), subgraph centrality (SC), eigenvector centrality (EC), information centrality (IC), and network centrality (NC) for predicting essential proteins. In addition, these centrality measures are improved on their performance for identifying essential proteins in biological network when controlled by topology potential.",
HORA: A Distributed Coverage Hole Repair Algorithm for Wireless Sensor Networks,"In wireless sensor networks, random deployment of nodes may cause serious coverage overlapping among the nodes and the original network may suffer severe coverage problems due to death of the nodes after deployment. In this paper, efficient distributed coverage hole repair algorithms are proposed taking density of the nodes in the post deployment scenario. The proposed algorithms consider limited mobility of the nodes and can select the mobile nodes based on their degree of coverage overlapping. In order to repair coverage holes of the network, nodes with higher degree of density are moved to maintain uniform network density without increasing the coverage degree of the neighbors of a mobile node. Simulation results show that the energy consumption due to mobility of nodes is least as compared to other similar protocols of the Wireless Sensor Networks. Besides, it is observed that substantial amount of coverage overlapping can be minimized and percentage of coverage of the holes can be maximized.",
Energy-Efficient Fault-Tolerant Data Storage and Processing in Mobile Cloud,"Despite the advances in hardware for hand-held mobile devices, resource-intensive applications (e.g., video and image storage and processing or map-reduce type) still remain off bounds since they require large computation and storage capabilities. Recent research has attempted to address these issues by employing remote servers, such as clouds and peer mobile devices. For mobile devices deployed in dynamic networks (i.e., with frequent topology changes because of node failure/unavailability and mobility as in a mobile cloud), however, challenges of reliability and energy efficiency remain largely unaddressed. To the best of our knowledge, we are the first to address these challenges in an integrated manner for both data storage and processing in mobile cloud, an approach we call k-out-of-n computing. In our solution, mobile devices successfully retrieve or process data, in the most energy-efficient way, as long as k out of n remote servers are accessible. Through a real system implementation we prove the feasibility of our approach. Extensive simulations demonstrate the fault tolerance and energy efficiency performance of our framework in larger scale networks.","Mobile communication,
Network topology,
Cloud computing,
Reliability,
Topology,
Mobile handsets,
Peer-to-peer computing"
"A Novel Dual-Band, Dual-Polarized, Miniaturized and Low-Profile Base Station Antenna","In this paper, a novel dual-band, dual-polarized, miniaturized and low-profile base station antenna operating in the frequency bands of 820-960 and 1710-2170 MHz is designed. Elements are arranged such that high-frequency elements are embedded in low frequency elements to reduce volume. A baffle is used to reflect the transmitted power density in the forward direction and also improve isolation between elements. Therefore, surrounding isolation baffles and rectangular baffles are appended around high-frequency elements and low-frequency elements, respectively. The diameter of the proposed antenna cover is only 200 mm, which is smaller than the existing antenna diameter of 280 mm. Compared with the other commonly used antennas, the proposed antenna also has some advantages such as concealment and low profile using a tubular form of radome, which can easily integrate the proposed antenna with the surrounding environment. The measured results verify that the proposed antenna meets the stringent design requirements: voltage standing wave ratio (VSWR) is less than 1.3, the isolation is greater than 30 dB, and the pattern parameters also meet telecommunications industry standards.","Base stations,
Feeds,
Antenna arrays,
Arrays,
Dual band,
Broadband antennas"
On the Easiest and Hardest Fitness Functions,"The hardness of fitness functions is an important research topic in the field of evolutionary computation. In theory, this paper can help with understanding the ability of evolutionary algorithms (EAs). In practice, this paper may provide a guideline to the design of benchmarks. The aim of this paper is to answer the following research questions. Given a fitness function class, which functions are the easiest with respect to an EA? Which are the hardest? How are these functions constructed? This paper provides theoretical answers to these questions. The easiest and hardest fitness functions are constructed for an elitist (1 + 1) EA to maximize a class of fitness functions with the same optima. It is demonstrated that the unimodal functions are the easiest and deceptive functions are the hardest in terms of the time-based fitness landscape. This paper also reveals that in a fitness function class, the easiest function to one algorithm may become the hardest to another algorithm, and vice versa.","Runtime,
Evolutionary computation,
Correlation,
Benchmark testing,
Algorithm design and analysis,
Polynomials,
Electronic mail"
Automatic Liver Segmentation Based on Shape Constraints and Deformable Graph Cut in CT Images,"Liver segmentation is still a challenging task in medical image processing area due to the complexity of the liver's anatomy, low contrast with adjacent organs, and presence of pathologies. This investigation was used to develop and validate an automated method to segment livers in CT images. The proposed framework consists of three steps: 1) preprocessing; 2) initialization; and 3) segmentation. In the first step, a statistical shape model is constructed based on the principal component analysis and the input image is smoothed using curvature anisotropic diffusion filtering. In the second step, the mean shape model is moved using thresholding and Euclidean distance transformation to obtain a coarse position in a test image, and then the initial mesh is locally and iteratively deformed to the coarse boundary, which is constrained to stay close to a subspace of shapes describing the anatomical variability. Finally, in order to accurately detect the liver surface, deformable graph cut was proposed, which effectively integrates the properties and inter-relationship of the input images and initialized surface. The proposed method was evaluated on 50 CT scan images, which are publicly available in two databases Sliver07 and 3Dircadb. The experimental results showed that the proposed method was effective and accurate for detection of the liver surface.","Liver,
Shape,
Image segmentation,
Computed tomography,
Deformable models,
Euclidean distance,
Adaptation models"
Extreme Learning Machine With Composite Kernels for Hyperspectral Image Classification,"Due to its simple, fast, and good generalization ability, extreme learning machine (ELM) has recently drawn increasing attention in the pattern recognition and machine learning fields. To investigate the performance of ELM on the hyperspectral images (HSIs), this paper proposes two spatial-spectral composite kernel (CK) ELM classification methods. In the proposed CK framework, the single spatial or spectral kernel consists of activation-function-based kernel and general Gaussian kernel, respectively. The proposed methods inherit the advantages of ELM and have an analytic solution to directly implement the multiclass classification. Experimental results on three benchmark hyperspectral datasets demonstrate that the proposed ELM with CK methods outperform the general ELM, SVM, and SVM with CK methods.","Kernel,
Feature extraction,
Support vector machines,
Training,
Educational institutions,
Hyperspectral imaging"
GA-Based Optimization of Irregular Subarray Layouts for Wideband Phased Arrays Design,The design of phased arrays generating low sidelobes and grating-lobes-free patterns over wide frequency bandwidths is addressed. The array structure is decomposed in subarrays with irregular polyomino tiles whose locations and orientations are optimized by means of a genetic algorithms-based approach. A set of representative results is reported and discussed to give some insights on the performance of the proposed approach also in comparison to state-of-the-art solutions.,"Phased arrays,
Apertures,
Optimization,
Genetic algorithms,
Gratings"
GA-Based Optimization of Irregular Subarray Layouts for Wideband Phased Arrays Design,,
A multi-objective task scheduling algorithm for heterogeneous multi-cloud environment,"Cloud Computing has become a popular computing paradigm which has gained enormous attention in delivering on-demand services. Task scheduling in cloud computing is an important issue that has been well researched and many algorithms have been developed for the same. However, the goal of most of these algorithms is to minimize the overall completion time (i.e., makespan) without looking into minimization of the overall cost of the service (referred as budget). Moreover, many of them are applicable to single-cloud environment. In this paper, we propose a multi-objective task scheduling algorithm for heterogeneous multi-cloud environment which takes care both these issues. We perform rigorous experiments on some synthetic and benchmark data sets. The experimental results show that the proposed algorithm balances both the makespan and total cost in contrast to two existing task scheduling algorithms in terms of various performance metrics including makespan, total cost and average cloud utilization.","Scheduling,
Benchmark testing,
Servers,
Scheduling algorithms,
Cloud computing,
Minimization,
Measurement"
Energy-aware video streaming on smartphones,"Video streaming on smartphone consumes lots of energy. One common solution is to download and buffer future video data for playback so that the wireless interface can be turned off most of time and then save energy. However, this may waste energy and bandwidth if the user skips or quits before the end of the video. Using a small buffer can reduce the bandwidth wastage, but may consume more energy and introduce rebuffering delay. In this paper, we analyze the power consumption during video streaming considering user skip and early quit scenarios. We first propose an offline method to compute the minimum power consumption, and then introduce an online solution to save energy based on whether the user tends to watch video for a long time or tends to skip. We have implemented the online solution on Android based smartphones. Experimental results and trace-driven simulation results show that that our method can save energy while achieving a better tradeoff between delay and bandwidth compared to existing methods.","Streaming media,
Bandwidth,
Delays,
Wireless communication,
Watches,
Data communication,
Smart phones"
Optimal Sizing of a Vanadium Redox Battery System for Microgrid Systems,"The vanadium redox battery (VRB) has proven to be a reliable and highly efficient energy storage system (ESS) for microgrid applications. However, one challenge in designing a microgrid system is specifying the size of the ESS. This selection is made more complex due to the independent power and energy ratings inherent in VRB systems. Sizing a VRB for both required power output and energy storage capacity requires an in-depth analysis to produce both optimal scheduling capabilities and minimum capital costs. This paper presents an analytical method to determine the optimal ratings of VRB energy storage based on an optimal scheduling analysis and cost-benefit analysis for microgrid applications. A dynamic programming (DP) algorithm is used to solve the optimal scheduling problem considering the efficiency and operating characteristics of the VRBs. The proposed method has been applied to determine the optimal VRB power and energy ratings for both isolated and grid-connected microgrids, which contain PV arrays and fossil-fuel-based generation. We first consider the case in which a grid-tie is not available and diesel generation is the backup source of power. The method is then extended to consider the case in which a utility grid tie is available.","Microgrids,
System-on-chip,
Batteries,
Fuels,
Discharges (electric),
Optimal scheduling,
Generators"
Platform for benchmarking of RF-based indoor localization solutions,"Over the last few years, the number of indoor localization solutions has grown exponentially, and a wide variety of different technologies and approaches are being explored. Unfortunately, there is currently no established standardized evaluation method for comparing their performance. As a result, each solution is evaluated in a different environment using proprietary evaluation metrics. Consequently, it is currently extremely hard to objectively compare the performance of multiple localization solutions with each other. To address the problem, we present the EVARILOS Benchmarking Platform, which enables automated evaluation and comparison of multiple solutions in different environments using multiple evaluation metrics. We propose a testbed-independent benchmarking platform, combined with multiple testbed-dependent plugins for executing experiments and storing performance results. The platform implements the standardized evaluation method described in the EVARILOS Benchmarking Handbook, which is aligned with the upcoming ISO/IEC 18305 standard “Test and Evaluation of Localization and Tracking Systems.” The platform and plug-ins can be used in real time on existing wireless testbed facilities, while also supporting a remote offline evaluation method using precollected data traces. Using these facilities, and analyzing and comparing the performance of three different localization solutions, we demonstrate the need for objective evaluation methods that consider multiple evaluation criteria in different environments.","Localization,
Radio frequency,
Benchmark testing,
Interference,
ISO Standards,
IEC Standards,
Wireless communication"
Degrees of Freedom of MIMO Cellular Networks: Decomposition and Linear Beamforming Design,"This paper investigates the symmetric degrees of freedom (DoF) of multiple-input multiple-output (MIMO) cellular networks with G cells and K users per cell, having N antennas at each base station and M antennas at each user. In particular, we investigate techniques for achievability that are based on either decomposition with asymptotic interference alignment or linear beamforming schemes and show that there are distinct regimes of (G,K,M,N) , where one outperforms the other. We first note that both one-sided and two-sided decomposition with asymptotic interference alignment achieve the same DoF. We then establish specific antenna configurations under which the DoF achieved using decomposition-based schemes is optimal by deriving a set of outer bounds on the symmetric DoF. Using these results, we completely characterize the optimal DoF of any G-cell network with single-antenna users. For linear beamforming schemes, we first focus on small networks and propose a structured approach to linear beamforming based on a notion called packing ratios. Packing ratio describes the interference footprint or shadow cast by a set of transmit beamformers and enables us to identify the underlying structures for aligning interference. Such a structured beamforming design can be shown to achieve the optimal spatially normalized DoF (sDoF) of two-cell two-user/cell network and the two-cell three-user/cell network. For larger networks, we develop an unstructured approach to linear interference alignment, where transmit beamformers are designed to satisfy conditions for interference alignment without explicitly identifying the underlying structures for interference alignment. The main numerical insight of this paper is that such an approach appears to be capable of achieving the optimal sDoF for MIMO cellular networks in regimes where linear beamforming dominates asymptotic decomposition, and a significant portion of sDoF elsewhere. Remarkably, polynomial identity test appears to play a key role in identifying the boundary of the achievable sDoF region in the former case.","MIMO,
Array signal processing,
Interference channels,
Antennas,
Transmitters,
Receivers"
An Origami Reconfigurable Axial-Mode Bifilar Helical Antenna,"This communication presents a new reconfigurable origami bifilar helical antenna. This antenna can change its operating frequencies by changing its height. Also, analytical equations for the design of such antennas are derived based on an equivalent model of a standard helical antenna. An origami bifilar helical antenna is designed and its performance is verified using simulations and measurements.","Helical antennas,
Antenna measurements,
Standards,
Frequency measurement,
Gain measurement,
Gain"
Untraceable Sensor Movement in Distributed IoT Infrastructure,"Recent advances in information and communication technologies and embedded systems have given rise to a new disruptive technology, the Internet of Things (IoTs). IoT allows people and objects in the physical world as well as data and virtual environments to interact with each other so as to create smart environments, such as smart transport systems, smart cities, smart health, and so on. However, IoT raises some important questions and also introduces new challenges for the security of systems and processes and the privacy of individuals, such as their location and movements and so on. In this paper, at first, we propose a distributed IoT system architecture. Subsequently, we propose an anonymous authentication scheme, which can ensure some of the notable properties, such as sensor anonymity, sensor untraceability, resistance to replay attacks, cloning attacks, and so on. It is argued that the proposed authentication scheme will be useful in many distributed IoT applications (such as radio-frequency identification-based IoT system, Biosensor-based IoT healthcare system, and so on), where the privacy of the sensor movement is greatly desirable.","Sensors,
Authentication,
Tin,
Wireless sensor networks,
Computer architecture,
Protocols"
A Printed Unidirectional Antenna With Improved Upper Band-Edge Selectivity Using a Parasitic Loop,"In this communication, a printed unidirectional antenna with improved upper band-edge selectivity is proposed to realize bandpass filtering gain performance. This antenna consists of a printed rectangular loop with two gaps: 1) a parasitic strip and 2) a parasitic loop. The rectangular loop provides good lower band-edge selectivity and the parasitic strip decides the location of upper band-edge selectivity. The parasitic loop, which acts as a director, is used to improve the capacity of upper band-edge selectivity. In addition, the passband bandwidth controllability of the antenna has also been explored. To demonstrate the effectiveness of this design, an antenna prototype is fabricated and tested. Experimental results verified the effectiveness of the proposed design. Measured results show that the fabricated antenna provides a 56.6% passband bandwidth, ranging from 2.18 to 3.9 GHz. Good bandpass filtering gain performance with a flat passband gain better than 4.4 dBi is achieved. Stable unidirectional radiation patterns with nearly identical E
- and H
-plane patterns in the operating bandwidth are also achieved. The measured front-to-back ratio is better than 10 dB.","Antenna measurements,
Antenna radiation patterns,
Filtering,
Gain,
Bandwidth"
Wavelet-Based Regularization for Robust Microwave Imaging in Medical Applications,"Microwave imaging (MWI) is an emerging tool for medical diagnostics, potentially offering unique advantages such as the capability of providing quantitative images of the inspected tissues. This involves, however, solving a challenging nonlinear and ill-posed electromagnetic inverse scattering problem. This paper presents a robust method for quantitative MWI in medical applications where very little, if any, a priori information on the imaging scenario is available. This is accomplished by employing a distorted Born iterative method and a regularization by projection technique, which reconstructs the tissue parameters using a wavelet basis expansion to represent the unknown contrast. This approach is suited for any microwave medical imaging application where the requirement for increased resolution dictates the use of higher frequency data and, consequently, a robust regularization strategy. To demonstrate the robustness of the proposed approach, this paper presents reconstructions of highly heterogeneous anatomically realistic numerical breast phantoms in a canonical 2-D configuration.",
PhaseU: Real-time LOS identification with WiFi,"WiFi technology has fostered numerous mobile computing applications, such as adaptive communication, finegrained localization, gesture recognition, etc., which often achieve better performance or rely on the availability of Line-Of-Sight (LOS) signal propagation. Thus the awareness of LOS and Non-Line-Of-Sight (NLOS) plays as a key enabler for them. Realtime LOS identification on commodity WiFi devices, however, is challenging due to limited bandwidth of WiFi and resulting coarse multipath resolution. In this work, we explore and exploit the phase feature of PHY layer information, harnessing both space diversity with antenna elements and frequency diversity with OFDM subcarriers. On this basis, we propose PhaseU, a real-time LOS identification scheme that works in both static and mobile scenarios on commodity WiFi infrastructure. Experimental results in various indoor scenarios demonstrate that PhaseU consistently outperforms previous approaches, achieving overall LOS and NLOS detection rates of 94.35% and 94.19% in static cases and both higher than 80% in mobile contexts. Furthermore, PhaseU achieves real-time capability with millisecond-level delay for a connected AP and 1-second delay for unconnected APs, which is far beyond existing approaches.","IEEE 802.11 Standard,
Antennas,
Antenna measurements,
Phase measurement,
Real-time systems,
Feature extraction,
Wireless communication"
Multiobjective Design Optimization of IGBT Power Modules Considering Power Cycling and Thermal Cycling,"Insulated-gate bipolar transistor (IGBT) power modules find widespread use in numerous power conversion applications where their reliability is of significant concern. Standard IGBT modules are fabricated for general-purpose applications while little has been designed for bespoke applications. However, conventional design of IGBTs can be improved by the multiobjective optimization technique. This paper proposes a novel design method to consider die-attachment solder failures induced by short power cycling and baseplate solder fatigue induced by the thermal cycling which are among major failure mechanisms of IGBTs. Thermal resistance is calculated analytically and the plastic work design is obtained with a high-fidelity finite-element model, which has been validated experimentally. The objective of minimizing the plastic work and constrain functions is formulated by the surrogate model. The nondominated sorting genetic algorithm-II is used to search for the Pareto-optimal solutions and the best design. The result of this combination generates an effective approach to optimize the physical structure of power electronic modules, taking account of historical environmental and operational conditions in the field.","Insulated gate bipolar transistors,
Multichip modules,
Fatigue,
Resistance,
Strain,
Optimization,
Stress"
Clothing Attributes Assisted Person Reidentification,"Person reidentification across nonoverlapping camera views is a rather challenging task. Due to the difficulties in obtaining identifiable faces, clothing appearance becomes the main cue for identification purposes. In this paper, we present a comprehensive study on clothing attributes assisted person reidentification. First, the body parts and their local features are extracted for alleviating the pose-misalignment issue. A latent support vector machine (LSVM)-based person reidentification approach is proposed to describe the relations among the low-level part features, middle-level clothing attributes, and high-level reidentification labels of person pairs. Motivated by the uncertainties of clothing attributes, we treat them as real-value variables instead of using them as discrete variables. Moreover, a large-scale real-world dataset with 10 camera views and about 200 subjects is collected and thoroughly annotated for this paper. The extensive experiments on this dataset show: 1) part features are more effective than features extracted from the holistic human bounding boxes; 2) the clothing attributes embedded in the LSVM model may further boost reidentification performance compared with support vector machine without clothing attributes; and 3) treating clothing attributes as real-value variables is more effective than using them as discrete variables in person reidentification.","Cameras,
Support vector machines,
Feature extraction,
Computational modeling,
Semantics,
Identification"
Spatio-Temporal Video Segmentation of Static Scenes and Its Applications,"Extracting spatio-temporally consistent segments from a video sequence is a challenging problem due to the complexity of color, motion and occlusions. Most existing spatio-temporal segmentation approaches have inherent difficulties in handling large displacement with significant occlusions . This paper presents a novel framework for spatio-temporal segmentation. With the estimated depth data beforehand by a multi-view stereo technique, we project the pixels to other frames for collecting the boundary and segmentation statistics in a video, and incorporate them into the segmentation energy for spatio-temporal optimization. In order to effectively solve this problem, we introduce an iterative optimization scheme by first initializing segmentation maps for each frame independently, and then link the correspondences among different frames and iteratively refine them with the collected statistics, so that a set of spatio-temporally consistent volume segments are finally achieved. The effectiveness and usefulness of our automatic framework are demonstrated via its applications for 3D reconstruction, video editing and semantic segmentation on a variety of challenging video examples.",
Transfer Learning Improves Supervised Image Segmentation Across Imaging Protocols,"The variation between images obtained with different scanners or different imaging protocols presents a major challenge in automatic segmentation of biomedical images. This variation especially hampers the application of otherwise successful supervised-learning techniques which, in order to perform well, often require a large amount of labeled training data that is exactly representative of the target data. We therefore propose to use transfer learning for image segmentation. Transfer-learning techniques can cope with differences in distributions between training and target data, and therefore may improve performance over supervised learning for segmentation across scanners and scan protocols. We present four transfer classifiers that can train a classification scheme with only a small amount of representative training data, in addition to a larger amount of other training data with slightly different characteristics. The performance of the four transfer classifiers was compared to that of standard supervised classification on two magnetic resonance imaging brain-segmentation tasks with multi-site data: white matter, gray matter, and cerebrospinal fluid segmentation; and white-matter-/MS-lesion segmentation. The experiments showed that when there is only a small amount of representative training data available, transfer learning can greatly outperform common supervised-learning approaches, minimizing classification errors by up to 60%.","Support vector machines,
Training,
Image segmentation,
Training data,
Biomedical imaging,
Kernel,
Protocols"
Fast and Accurate Estimation of RFID Tags,"Radio frequency identification (RFID) systems have been widely deployed for various applications such as object tracking, 3-D positioning, supply chain management, inventory control, and access control. This paper concerns the fundamental problem of estimating RFID tag population size, which is needed in many applications such as tag identification, warehouse monitoring, and privacy-sensitive RFID systems. In this paper, we propose a new scheme for estimating tag population size called Average Run-based Tag estimation (ART). The technique is based on the average run length of ones in the bit string received using the standardized framed slotted Aloha protocol. ART is significantly faster than prior schemes. For example, given a required confidence interval of 0.1% and a required reliability of 99.9%, ART is consistently 7 times faster than the fastest existing schemes (UPE and EZB) for any tag population size. Furthermore, ART's estimation time is provably independent of the tag population sizes. ART works with multiple readers with overlapping regions and can estimate sizes of arbitrarily large tag populations. ART is easy to deploy because it neither requires modification to tags nor to the communication protocol between tags and readers. ART only needs to be implemented on readers as a software module.","Subspace constraints,
Estimation,
Sociology,
Statistics,
Protocols,
Radiofrequency identification,
Reliability"
Simultaneous Hallucination and Recognition of Low-Resolution Faces Based on Singular Value Decomposition,"In video surveillance, the captured face images are usually of low resolution (LR). Thus, a framework based on singular value decomposition (SVD) for performing both face hallucination and recognition simultaneously is proposed in this paper. Conventionally, LR face recognition is carried out by super-resolving the LR input face first, and then performing face recognition to identify the input face. By considering face hallucination and recognition simultaneously, the accuracy of both the hallucination and the recognition can be improved. In this paper, singular values are first proved to be effective for representing face images, and the singular values of a face image at different resolutions have approximately a linear relation. In our algorithm, each face image is represented using SVD. For each LR input face, the corresponding LR and high-resolution (HR) face-image pairs can then be selected from the face gallery. Based on these selected LR-HR pairs, the mapping functions for interpolating the two matrices in the SVD representation for the reconstruction of HR face images can be learned more accurately. Therefore, the final estimation of the high-frequency details of the HR face images will become more reliable and effective. The experimental results demonstrate that our proposed framework can achieve promising results for both face hallucination and recognition.","Face recognition,
Image resolution,
Image reconstruction,
Training,
Databases,
Vectors,
Interpolation"
A game based assistive tool for rehabilitation of dysphonic patients,"An assistive training tool for rehabilitation of dysphonic patients is designed and developed according to the practical clinical needs. The assistive tool employs a space flight game as the attractive logic part, and microphone arrays as input device, which is getting rid of ambient noise by setting a specific orientation. The therapist can guide the patient to play the game as well as the voice training simultaneously side by side, while not interfere the patient voice. The voice information can be recorded and extracted for evaluating the long-time rehabilitation progress. This paper outlines a design science approach for the development of an initial useful software prototype of such a tool, considering `Intuitive', `Entertainment', `Incentive' as main design factors.",
Robust Optimization for Bidirectional Dispatch Coordination of Large-Scale V2G,"This paper proposes a robust optimization (RO) model for bidirectional dispatch coordination of large-scale plug-in electric vehicles (PEVs) in a power grid in which the PEVs are aggregated to manage. The PEV aggregators are considered as a type of dispatchable demand response and energy storage resource with stochastic behaviors, and can supply load or provide ancillary services such as regulation reserve to the grid. The proposed RO model is then reformulated as a mixed-integer quadratic programming model, which can be solved efficiently. Computer simulations are performed for a power grid with ten generators and three PEV aggregators to validate the economic benefit of the RO model for bidirectional dispatch coordination of the PEVs and the robustness of the RO model to the uncertainty of the PEVs' stochastic mobility behaviors.",
Compact Low Power Wireless Gas Sensor Node With Thermo Compensation for Ubiquitous Deployment,"Wireless sensor networks (WSNs) have recently been applied for industrial monitoring, including combustible and flammable gases monitoring. In this work, we present a wireless gas sensor node in which a widely used Wheatstone sensing circuit based on two sensors is exchanged with a single sensor circuit, as well as the associate gas measurement procedure. The core of the measurement procedure is the four-stage heating profile, which enables low power consumption of sensing circuit and thermo compensation adjustment. A thermo compensation algorithm is capable of avoiding the effect of the environmental temperature on the measurements by keeping stable zero-offset within ±1 mV and ensuring low absolute error within 0.1% vol. The thorough design of the sensor node allows it to fit into the 5.5 cm3 packaging, which ensures its true ubiquitous deployment in outdoor and industrial environment.","Wireless sensor networks,
Temperature measurement,
Power demand,
Temperature sensors,
Heating,
Wireless communication"
Weakly Supervised Deep Metric Learning for Community-Contributed Image Retrieval,"Recent years have witnessed the explosive growth of community-contributed images with rich context information, which is beneficial to the task of image retrieval. It can help us to learn a suitable metric to alleviate the semantic gap. In this paper, we propose a new distance metric learning algorithm, namely weakly-supervised deep metric learning (WDML), under the deep learning framework. It utilizes a progressive learning manner to discover knowledge by jointly exploiting the heterogeneous data structures from visual contents and user-provided tags of social images. The semantic structure in the textual space is expected to be well preserved while the problem of the noisy, incomplete or subjective tags is addressed by leveraging the visual structure in the original visual space. Besides, a sparse model with the l2,1 mixed norm is imposed on the transformation matrix of the first layer in the deep architecture to compress the noisy or redundant visual features. The proposed problem is formulated as an optimization problem with a well-defined objective function and a simple yet efficient iterative algorithm is proposed to solve it. Extensive experiments on real-world social image datasets are conducted to verify the effectiveness of the proposed method for image retrieval. Encouraging experimental results are achieved compared with several representative metric learning methods.","Visualization,
Semantics,
Image retrieval,
Noise measurement,
Learning systems,
Data structures"
Extended Kalman Filter-Based Parallel Dynamic State Estimation,"There is a growing need for accurate and efficient real-time state estimation with increasing complexity, interconnection, and insertion of new devices in power systems. In this paper, a massively parallel dynamic state estimator is developed on a graphic processing unit (GPU), which is especially designed for processing large data sets. Within the massively parallel framework, a lateral two-level dynamic state estimator is proposed based on the extended Kalman filter method, utilizing both supervisory control and data acquisition, and phasor measurement unit (PMU) measurements. The measurements at the buses without PMU installations are predicted using previous data. The results of the GPU-based dynamic state estimator are compared with a multithread CPU-based code. Moreover, the effects of direct and iterative linear solvers on the state estimation algorithm are investigated. The simulation results show a total speed-up of up to 15 times for a 4992-bus system.","Phasor measurement units,
Graphics processing units,
State estimation,
Measurement uncertainty,
Parallel processing,
Weight measurement,
Time measurement"
A Digital Liquid State Machine With Biologically Inspired Learning and Its Application to Speech Recognition,"This paper presents a bioinspired digital liquid-state machine (LSM) for low-power very-large-scale-integration (VLSI)-based machine learning applications. To the best of the authors' knowledge, this is the first work that employs a bioinspired spike-based learning algorithm for the LSM. With the proposed online learning, the LSM extracts information from input patterns on the fly without needing intermediate data storage as required in offline learning methods such as ridge regression. The proposed learning rule is local such that each synaptic weight update is based only upon the firing activities of the corresponding presynaptic and postsynaptic neurons without incurring global communications across the neural network. Compared with the backpropagation-based learning, the locality of computation in the proposed approach lends itself to efficient parallel VLSI implementation. We use subsets of the TI46 speech corpus to benchmark the bioinspired digital LSM. To reduce the complexity of the spiking neural network model without performance degradation for speech recognition, we study the impacts of synaptic models on the fading memory of the reservoir and hence the network performance. Moreover, we examine the tradeoffs between synaptic weight resolution, reservoir size, and recognition performance and present techniques to further reduce the overhead of hardware implementation. Our simulation results show that in terms of isolated word recognition evaluated using the TI46 speech corpus, the proposed digital LSM rivals the state-of-the-art hidden Markov-model-based recognizer Sphinx-4 and outperforms all other reported recognizers including the ones that are based upon the LSM or neural networks.",
Observer-Based Control of LLC DC/DC Resonant Converter Using Extended Describing Functions,"This paper presents theoretical and practical results about dynamic analysis, frequency response, and control of a LLC resonant dc/dc converter operating under wide input voltage and load variations. A nonlinear model for the LLC resonant converter was developed using the extended describing function method; then, based on the derived model, a nonlinear observer-based controller was designed and implemented with a digital signal processor. Transient responses obtained under input voltage and output load variations show that the proposed controller is capable to stabilize the output effectively. Experimental results prove the superiority of the proposed observer-based controller over a conventional PID controller.","Mathematical model,
Voltage control,
Steady-state,
Approximation methods,
Observers,
Resonant frequency,
Switching frequency"
EasyConnect: A Management System for IoT Devices and Its Applications for Interactive Design and Art,"Many Internet of Things (IoT) technologies have been used in applications for money flow, logistics flow, people flow, interactive art design, and so on. To manage these increasing disparate devices and connectivity options, ETSI has specified end-to-end machine-to-machine (M2M) system architecture for IoT applications. Based on this architecture, we develop an IoT EasyConnect system to manage IoT devices. In our approach, an IoT device is characterized by its “features” (e.g., temperature, vibration, and display) that are manipulated by the network applications. If a network application handles the individual device features independently, then we can write a software module for each device feature, and the network application can be simply constructed by including these brick-like device feature modules. Based on the concept of device feature, brick-like software modules can provide simple and efficient mechanism to develop IoT device applications and interactions.",
Fool Me If You Can: Mimicking Attacks and Anti-Attacks in Cyberspace,"Botnets have become major engines for malicious activities in cyberspace nowadays. To sustain their botnets and disguise their malicious actions, botnet owners are mimicking legitimate cyber behavior to fly under the radar. This poses a critical challenge in anomaly detection. In this paper, we use web browsing on popular web sites as an example to tackle this problem. First of all, we establish a semi-Markov model for browsing behavior. Based on this model, we find that it is impossible to detect mimicking attacks based on statistics if the number of active bots of the attacking botnet is sufficiently large (no less than the number of active legitimate users). However, we also find it is hard for botnet owners to satisfy the condition to carry out a mimicking attack most of the time. With this new finding, we conclude that mimicking attacks can be discriminated from genuine flash crowds using second order statistical metrics. We define a new fine correntropy metrics and show its effectiveness compared to others. Our real world data set experiments and simulations confirm our theoretical claims. Furthermore, the findings can be widely applied to similar situations in other research fields.",
Systematic Error-Correcting Codes for Rank Modulation,"The rank-modulation scheme has been recently proposed for efficiently storing data in nonvolatile memories. In this paper, we explore [n, k, d] systematic error-correcting codes for rank modulation. Such codes have length n, k information symbols, and minimum distance d. Systematic codes have the benefits of enabling efficient information retrieval in conjunction with memory-scrubbing schemes. We study systematic codes for rank modulation under Kendall's T-metric as well as under the ℓ∞-metric. In Kendall's T-metric, we present [k + 2, k, 3] systematic codes for correcting a single error, which have optimal rates, unless systematic perfect codes exist. We also study the design of multierror-correcting codes, and provide a construction of [k + t + 1, k, 2t + 1] systematic codes, for large-enough k. We use nonconstructive arguments to show that for rank modulation, systematic codes achieve the same capacity as general error-correcting codes. Finally, in the ℓ∞-metric, we construct two [n, k, d] systematic multierror-correcting codes, the first for the case of d = 0(1) and the second for d = Θ(n). In the latter case, the codes have the same asymptotic rate as the best codes currently known in this metric.","Systematics,
Tin,
Modulation,
Measurement,
Error correction codes,
Vectors,
Redundancy"
Dominating Set and Network Coding-Based Routing in Wireless Mesh Networks,"Wireless mesh networks are widely applied in many fields such as industrial controlling, environmental monitoring, and military operations. Network coding is promising technology that can improve the performance of wireless mesh networks. In particular, network coding is suitable for wireless mesh networks as the fixed backbone of wireless mesh is usually unlimited energy. However, coding collision is a severe problem affecting network performance. To avoid this, routing should be effectively designed with an optimum combination of coding opportunity and coding validity. In this paper, we propose a Connected Dominating Set (CDS)-based and Flow-oriented Coding-aware Routing (CFCR) mechanism to actively increase potential coding opportunities. Our work provides two major contributions. First, it effectively deals with the coding collision problem of flows by introducing the information conformation process, which effectively decreases the failure rate of decoding. Secondly, our routing process considers the benefit of CDS and flow coding simultaneously. Through formalized analysis of the routing parameters, CFCR can choose optimized routing with reliable transmission and small cost. Our evaluation shows CFCR has a lower packet loss ratio and higher throughput than existing methods, such as Adaptive Control of Packet Overhead in XOR Network Coding (ACPO), or Distributed Coding-Aware Routing (DCAR).",
Distribution System State Estimation Based on Nonsynchronized Smart Meters,"Distribution systems are undergoing many enhancements and developments to enable the future smart grid, and distribution system state estimation (DSSE) provides the control centers with the information necessary for several of its applications and operational functions. However, the quality of DSSE typically suffers from a lack of adequate/accurate measurements. Recently, many electric utilities have started to install fairly accurate smart meters throughout their distribution networks, which create an opportunity to achieve higher quality DSSE. However, the signals provided by smart meters are generally not synchronized and the difference between the measurement times of smart meters can be significant. Therefore, a complete snapshot of the entire distribution system may not be available. This paper proposes a method to deal with the issue of nonsynchronized measurements coming from smart meters based on the credibility of each available measurement and appropriately adjusting the variance of the measurement devices. To illustrate the effectiveness of the proposed method, two IEEE benchmark systems are used. The results show that the proposed method is robust and improves the accuracy of DSSE compared with the traditional DSSE approach.","Smart meters,
Load management,
Power distribution,
Distributed power generation,
State estimation"
Global Sensor Deployment and Local Coverage-Aware Recovery Schemes for Smart Environments,"One critical issue, for a wireless sensor network (WSN) to operate successfully, is to provide sufficient sensing coverage. Define the smart sensing environment as a sensing system with the capability to sense the environment and respond properly in an automated manner. In this paper, we target on smart sensing environments and deal with heterogeneous sensors (here sensor heterogeneity is defined as sensors having different sensing ranges) equipped with actuation facilities to assist in the sensor self-deployment. A coverage-aware sensor automation (CASA) protocol is proposed to realize an automated smart monitoring network. Two centralized algorithms are included in the CASA protocol suite: enhanced virtual forces algorithm with boundary forces (EVFA-B) and sensor self-organizing algorithm (SSOA). Unlike most previous works that tackle the deployment problem only partially, we intend to address the problem from both global deployment (EVFA-B) and local repairing (SSOA) perspectives. The EVFA-B protocol exerts weighted attractive and repulsive forces on each sensor based on predefined distance thresholds. Resultant forces then guide the sensors to their suitable positions with the objective of enhancing the sensing coverage (after a possibly random placement of sensors). Furthermore, in the presence of sensor energy depletions and/or unexpected failures, our SSOA algorithm is activated to perform local repair by repositioning sensors around the sensing void (uncovered area). This capability of local recovery is advantageous in terms of saving the communication and moving energies. Performance of the proposed sensor deployment strategies is evaluated in terms of surveillance coverage, monitoring density, network self-healing competence, and moving energy consumption. We also implement our CASA protocol suite in a real-life monitoring network (MoNet) to demonstrate the protocol feasibility and validate the MoNet detection capability of emergency events.","Force,
Robot sensing systems,
Monitoring,
Protocols,
Wireless sensor networks,
Automation"
Memristors Empower Spiking Neurons With Stochasticity,"Recent theoretical studies have shown that probabilistic spiking can be interpreted as learning and inference in cortical microcircuits. This interpretation creates new opportunities for building neuromorphic systems driven by probabilistic learning algorithms. However, such systems must have two crucial features: 1) the neurons should follow a specific behavioral model, and 2) stochastic spiking should be implemented efficiently for it to be scalable. This paper proposes a memristor-based stochastically spiking neuron that fulfills these requirements. First, the analytical model of the memristor is enhanced so it can capture the behavioral stochasticity consistent with experimentally observed phenomena. The switching behavior of the memristor model is demonstrated to be akin to the firing of the stochastic spike response neuron model, the primary building block for probabilistic algorithms in spiking neural networks. Furthermore, the paper proposes a neural soma circuit that utilizes the intrinsic nondeterminism of memristive switching for efficient spike generation. The simulations and analysis of the behavior of a single stochastic neuron and a winner-take-all network built of such neurons and trained on handwritten digits confirm that the circuit can be used for building probabilistic sampling and pattern adaptation machinery in spiking networks. The findings constitute an important step towards scalable and efficient probabilistic neuromorphic platforms.","Switches,
Memristors,
Stochastic processes,
Neurons,
Biological system modeling,
Integrated circuit modeling,
Probabilistic logic"
A Generic Model of Memristors With Parasitic Components,"In this paper, a generic model of memristive systems, which can emulate the behavior of real memristive devices is proposed. Non-ideal pinched hysteresis loops are sometimes observed in real memristive devices. For example, the hysteresis loops may deviate from the origin over a broad range of amplitude A and frequency f of the input signal. This deviation from the ideal case is often caused by parasitic circuit elements exhibited by real memristive devices. In this paper, we propose a generic memristive circuit model by adding four parasitic circuit elements, namely, a small capacitance, a small inductance, a small DC current source, and a small DC voltage source, to the memristive device. The adequacy of this model is verified experimentally and numerically with two thermistors (NTC and PTC) memristors.","Memristors,
Thermistors,
Hysteresis,
Integrated circuit modeling,
Mathematical model,
Voltage measurement,
Shape"
Thermally Stable Enhancement-Mode GaN Metal-Isolator-Semiconductor High-Electron-Mobility Transistor With Partially Recessed Fluorine-Implanted Barrier,"Al2O3/AlGaN/GaN enhancement-mode metalisolator-semiconductor high-electron-mobility transistor (MIS-HEMT) featuring a partially recessed (Al) GaN barrier was realized by a fluorine plasma implantation/etch technique. By properly adjusting the RF power driving the fluorine plasma, the fluorine plasma is able to produce two desirable results: 1) a well-controlled slow dry etching for gate recess and 2) implanting fluorine ions into the AlGaN barrier. The fluorine ions become negatively charged in the barrier layer and induce a positive shift in the threshold voltage. The proposed MIS-HEMT exhibits a threshold voltage (VTH) of +0.6 V at a drain current of 10 μA/mm, a maximum drive current of 730 mA/mm, an ON-resistance of 7.07 Ω · mm, and an OFF-state breakdown voltage of 703 V at an OFF-state drain leakage current of 1 μA/mm. From room temperature to 200 °C, the device exhibits a small negative shift of VTH (~0.5 V) that is attributed to the high-quality dielectric/F-implanted-(Al) GaN interface and the partially recessed barrier.","Logic gates,
Thermal stability,
Gallium nitride,
Aluminum gallium nitride,
Plasmas,
Threshold voltage,
HEMTs"
Deadbeat Control for Electrical Drives: A Robust and Performant Design Based on Differential Flatness,"The present contribution introduces a new deadbeat controller design that increases robustness without compromising performance. In conventional deadbeat control, feedback linearization is applied, and the feedback gains are set very high to obtain the minimum-step reference response. This makes the control method highly sensitive to parametric uncertainties. To date, the only remedies have been to tune the deadbeat controller settling time higher and the according disturbance estimator more slowly. Recently proposed remedies based on online parameter estimators show either moderate performance or higher demands on hardware. Therefore, first a feedforward linearization-based controller is introduced to obtain the desired reference response via open-loop control. Thereby, the parametric sensitivity is considerably improved. Then, the new generalized flatness-based controller, a mix between feedback and feedforward linearization, is proposed. The result is a deadbeat controller with high dynamic performance and high robustness with respect to both parameter uncertainties and disturbances. The experimental results on an induction machine demonstrate very fast reference tracking, high robustness to typical parameter uncertainties, and active compensation of time-varying disturbances. The results on a synchronous reluctance machine show that even very large inductance uncertainties can be handled.","Robustness,
Delays,
Feedforward neural networks,
Sensitivity,
Power electronics,
Control systems,
Hardware"
Practical Data Prediction for Real-World Wireless Sensor Networks,"Data prediction is proposed in wireless sensor networks (WSNs) to extend the system lifetime by enabling the sink to determine the data sampled, within some accuracy bounds, with only minimal communication from source nodes. Several theoretical studies clearly demonstrate the tremendous potential of this approach, able to suppress the vast majority of data reports at the source nodes. Nevertheless, the techniques employed are relatively complex, and their feasibility on resource-scarce WSN devices is often not ascertained. More generally, the literature lacks reports from real-world deployments, quantifying the overall system-wide lifetime improvements determined by the interplay of data prediction with the underlying network. These two aspects, feasibility and system-wide gains, are key in determining the practical usefulness of data prediction in real-world WSN applications. In this paper, we describe derivative-based prediction (DBP), a novel data prediction technique much simpler than those found in the literature. Evaluation with real data sets from diverse WSN deployments shows that DBP often performs better than the competition, with data suppression rates up to 99 percent and good prediction accuracy. However, experiments with a real WSN in a road tunnel show that, when the network stack is taken into consideration, DBP only triples lifetime-a remarkable result per se, but a far cry from the data suppression rates above. To fully achieve the energy savings enabled by data prediction, the data and network layers must be jointly optimized. In our testbed experiments, a simple tuning of the MAC and routing stack, taking into account the operation of DBP, yields a remarkable seven-fold lifetime improvement w.r.t. the mainstream periodic reporting.","Wireless sensor networks,
Data models,
Computational modeling,
Predictive models"
A Combined SDC-SDF Architecture for Normal I/O Pipelined Radix-2 FFT,"We present an efficient combined single-path delay commutator-feedback (SDC-SDF) radix-2 pipelined fast Fourier transform architecture, which includes log2 N - 1 SDC stages, and 1 SDF stage. The SDC processing engine is proposed to achieve 100% hardware resource utilization by sharing the common arithmetic resource in the time-multiplexed approach, including both adders and multipliers. Thus, the required number of complex multipliers is reduced to log4 N - 0.5, compared with log2 N - 1 for the other radix-2 SDC/SDF architectures. In addition, the proposed architecture requires roughly minimum number of complex adders log2 N + 1 and complex delay memory 2N + 1.5log2 N - 1.5.",
Double Nuclear Norm-Based Matrix Decomposition for Occluded Image Recovery and Background Modeling,"Robust principal component analysis (RPCA) is a new emerging method for exact recovery of corrupted low-rank matrices. It assumes that the real data matrix has low rank and the error matrix is sparse. This paper presents a method called double nuclear norm-based matrix decomposition (DNMD) for dealing with the image data corrupted by continuous occlusion. The method uses a unified low-rank assumption to characterize the real image data and continuous occlusion. Specifically, we assume all image vectors form a low-rank matrix, and each occlusion-induced error image is a low-rank matrix as well. Compared with RPCA, the low-rank assumption of DNMD is more intuitive for describing occlusion. Moreover, DNMD is solved by alternating direction method of multipliers. Our algorithm involves only one operator: the singular value shrinkage operator. DNMD, as a transductive method, is further extended into inductive DNMD (IDNMD). Both DNMD and IDNMD use nuclear norm for measuring the continuous occlusion-induced error, while many previous methods use L1, L2, or other M-estimators. Extensive experiments on removing occlusion from face images and background modeling from surveillance videos demonstrate the effectiveness of the proposed methods.",
Weighted Component Hashing of Binary Aggregated Descriptors for Fast Visual Search,"Towards low bit rate mobile visual search, recent works have proposed to aggregate the local features and compress the aggregated descriptor (such as Fisher vector, the vector of locally aggregated descriptors) for low latency query delivery as well as moderate search complexity. Even though Hamming distance can be computed very fast, the computational cost of exhaustive linear search over the binary descriptors grows linearly with either the length of a binary descriptor or the number of database images. In this paper, we propose a novel weighted component hashing (WeCoHash) algorithm for long binary aggregated descriptors to significantly improve search efficiency over a large scale image database. Accordingly, the proposed WeCoHash has attempted to address two essential issues in Hashing algorithms: “what to hash” and “how to search.” “What to hash” is tackled by a hybrid approach, which utilizes both image-specific component (i.e., visual word) redundancy and bit dependency within each component of a binary aggregated descriptor to produce discriminative hash values for bucketing. “How to search” is tackled by an adaptive relevance weighting based on the statistics of hash values. Extensive comparison results have shown that WeCoHash is at least 20 times faster than linear search and 10 times faster than local sensitive hash (LSH) when maintaining comparable search accuracy. In particular , the WeCoHash solution has been adopted by the emerging MPEG compact descriptor for visual search (CDVS) standard to significantly speed up the exhaustive search of the binary aggregated descriptors.","Visualization,
Databases,
Accuracy,
Artificial neural networks,
Hamming distance,
Search problems,
Vocabulary"
Stochastic Modeling and Quality Evaluation of Infrastructure-as-a-Service Clouds,"Cloud computing is a recently developed new technology for complex systems with massive service sharing, which is different from the resource sharing of the grid computing systems. In a cloud environment, service requests from users go through numerous provider-specific steps from the instant it is submitted to when the requested service is fully delivered. Quality modeling and analysis of clouds are not easy tasks because of the complexity of the automated provisioning mechanism and dynamically changing cloud environment. This work proposes an analytical model-based approach for quality evaluation of Infrastructure-as-a-Service cloud by considering expected request completion time, rejection probability, and system overhead rate as key quality metrics. It also features with the modeling of different warm-up and cool-down strategies of machines and the ability to identify the optimal balance between system overhead and performance. To validate the correctness of the proposed model, we obtain simulative quality-of-service (QoS) data and conduct a confidence interval analysis. The result can be used to help design and optimize industrial cloud computing systems.","Quality of service,
Analytical models,
Maintenance engineering,
Computational modeling,
Random variables,
Measurement"
Adaptive Image Denoising by Targeted Databases,"We propose a data-dependent denoising procedure to restore noisy images. Different from existing denoising algorithms which search for patches from either the noisy image or a generic database, the new algorithm finds patches from a database that contains relevant patches. We formulate the denoising problem as an optimal filter design problem and make two contributions. First, we determine the basis function of the denoising filter by solving a group sparsity minimization problem. The optimization formulation generalizes existing denoising algorithms and offers systematic analysis of the performance. Improvement methods are proposed to enhance the patch search process. Second, we determine the spectral coefficients of the denoising filter by considering a localized Bayesian prior. The localized prior leverages the similarity of the targeted database, alleviates the intensive Bayesian computation, and links the new method to the classical linear minimum mean squared error estimation. We demonstrate applications of the proposed method in a variety of scenarios, including text images, multiview images, and face images. Experimental results show the superiority of the new algorithm over existing methods.",
A TDC-Free Mostly-Digital FDC-PLL Frequency Synthesizer With a 2.8-3.5 GHz DCO,"This paper presents the first published fully-integrated digital fractional- N PLL based on a second-order frequency-to-digital converter (FDC) instead of a time-to-digital converter (TDC). The PLL's quantization noise is nearly identical to that of a conventional analog delta-sigma modulator based PLL (ΔΣ-PLL). Hence, the quantization noise is highpass shaped and is suppressed by the PLL's loop filter to the point where it is not a dominant contributor to the PLL's output phase noise. However, in contrast to a ΔΣ-PLL, the new PLL has an entirely digital loop filter and its analog components are relatively insensitive to non-ideal analog circuit behavior. Therefore, it offers the performance benefits of a ΔΣ-PLL and the area and scalability benefits of a TDC-based digital PLL. Additionally, the PLL's digitally controlled oscillator (DCO) incorporates a new switched-capacitor frequency control element that is insensitive to supply noise and parasitic coupling. The PLL is implemented in 65 nm CMOS technology, has an active area of 0.56 mm2, dissipates 21 mW from 1.0 and 1.2 V supplies, and its measured phase noise at 3.5 GHz is -123, -135, and -150 dBc/Hz at offsets of 1, 3, and 20 MHz, respectively. The PLL's power consumption is lower than previously published digital PLLs with comparable phase noise performance.","Quantization (signal),
Phase locked loops,
Charge pumps,
Frequency modulation,
Phase noise"
Unravelling the Impact of Temporal and Geographical Locality in Content Caching Systems,"To assess the performance of caching systems, the definition of a proper process describing the content requests generated by users is required. Starting from the analysis of traces of YouTube video requests collected inside operational networks, we identify the characteristics of real traffic that need to be represented and those that instead can be safely neglected. Based on our observations, we introduce a simple, parsimonious traffic model, named shot noise model (SNM), that allows us to capture temporal and geographical locality of content popularity. The SNM is sufficiently simple to be effectively employed in both analytical and scalable simulative studies of caching systems. We demonstrate this by analytically characterizing the performance of the LRU caching policy under the SNM, for both a single cache and a network of caches. With respect to the standard independent reference model (IRM), some paradigmatic shifts, concerning the impact of various traffic characteristics on cache performance, clearly emerge from our results.",
Service Selection for Web Services with Probabilistic QoS,"Web services can be specified from two perspectives, namely functional and non-functional properties. Multiple services may possess the same function while vary in their non-functional properties, or called quality-of-service (QoS). QoS values are important criteria for service selection or recommendation. Most of the former works in web service selection and recommendation treat the QoS values as constants. However, QoS values of a service as perceived by a given user are intrinsically random variables because QoS value prediction can never be precise and there are always some unobserved random effects. In this work, we address the service selection problem by representing services' QoS values as discrete random variables with probability mass functions. The goal is to select a set of atomic services for composing a composite service such that the probability of satisfying constraints imposed on the composite service is high and the execution time is reasonable. Our proposed method starts with an initial web service assignment and incrementally adjusts it using simulated annealing. We conduct several experiments and the results show that our approach generally performs better than previous works, such as the integer programming method and the cost-driven method.",
Impact of Receiver Reaction Mechanisms on the Performance of Molecular Communication Networks,"Molecular communication networks can be used to realise communication between nanoscale devices. In a molecular communication network, transmitters and receivers communicate by using signalling molecules. At the receivers, the signalling molecules react, via a chain of chemical reactions, to produce output molecules. The counts of output molecules over time is the output signal of the receiver. The output signal is noisy due to the stochastic nature of diffusion and chemical reactions. This paper aims to characterise the properties of the output signal. We do this by modelling the transmission medium, transmitter and receiver. In order to simplify the analysis, we model the transmitter as a sequence which specifies the number of molecules emitted by the transmitter over time. This paper considers two receiver reaction mechanisms, reversible conversion and linear catalytic, which can be used to approximate, respectively, ligand-receptor binding and enzymatic reactions. These two mechanisms are chosen because, if we consider them on their own (i.e. without the transmitter and diffusion), the ordinary differential equations describing the mean behaviour of these two reaction mechanisms have the same form; however, if we consider the end-to-end behaviour from the transmitter signal to the mean/variance of the number of output molecules, then these two receiver reaction mechanisms have very different behaviours. We show this by deriving analytical expressions for the mean, variance and frequency properties of the number of output molecules of these two receiver reaction mechanisms. In addition, for reversible conversion, we are able to derive the exact probability distribution of the number of output molecules. Our model allows us to study the impact of design parameters on the communication performance. For example, we assume that our receiver is enclosed by a membrane and we study the impact of the diffusibility of molecules across this membrane on the communication performance.",
DIAT: A Scalable Distributed Architecture for IoT,"The advent of Internet of Things (IoT) has boosted the growth in number of devices around us and kindled the possibility of umpteen number of applications. One of the major challenges in the realization of IoT applications is interoperability among various IoT devices and deployments. Thus, the need for a new architecture-comprising smart control and actuation-has been identified by many researchers. In this paper, we propose a Distributed Internet-like Architecture for Things (DIAT), which will overcome most of the obstacles in the process of large-scale expansion of IoT. It specifically addresses heterogeneity of IoT devices, and enables seamless addition of new devices across applications. In addition, we propose an usage control policy model to support security and privacy in a distributed environment. We propose a layered architecture that provides various levels of abstraction to tackle the issues such as scalability, heterogeneity, security, and interoperability. The proposed architecture is coupled with cognitive capabilities that helps in intelligent decision-making and enables automated service creation. Using a comprehensive use-case, comprising elements from multiple-application domains, we illustrate the usability of the proposed architecture.",
A Scaling Law to Predict the Finite-Length Performance of Spatially-Coupled LDPC Codes,Spatially-coupled low-density parity-check (SC-LDPC) codes are known to have excellent asymptotic properties. Much less is known regarding their finite-length performance. We propose a scaling law to predict the error probability of finite-length spatially coupled code ensembles when transmission takes place over the binary erasure channel. We discuss how the parameters of the scaling law are connected to fundamental quantities appearing in the asymptotic analysis of these ensembles and we verify that the predictions of the scaling law fit well to the data derived from simulations over a wide range of parameters. The ultimate goal of this line of research is to develop analytic tools for the design of SC-LDPC codes under practical constraints.,"Decoding,
Differential equations,
Error probability,
Sockets,
Couplings,
Iterative decoding"
Noninvasive Vascular Elastography With Plane Strain Incompressibility Assumption Using Ultrafast Coherent Compound Plane Wave Imaging,"Plane strain tensor estimation using non-invasive vascular ultrasound elastography (NIVE) can be difficult to achieve using conventional focus beamforming due to limited lateral resolution and frame rate. Recent developments in compound plane wave (CPW) imaging have led to high speed and high resolution imaging. In this study, we present the performance of NIVE using coherent CPW. We show the impact of CPW beamforming on strain estimates compared to conventional focus sequences. To overcome the inherent variability of lateral strains, associated with the low lateral resolution of linear array transducers, we use the plane strain incompressibility to constrain the estimator. Taking advantage of the approximate tenfold increase in frame rate of CPW compared with conventional focus imaging, we introduce a time-ensemble estimation approach to further improve the elastogram quality. By combining CPW imaging with the constrained Lagrangian speckle model estimator, we observe an increase in elastography quality (~10 dB both in signal-to-noise and contrast-to-noise ratios) over a wide range of applied strains (0.02 to 3.2%).",
Nuclear Norm-Based 2-DPCA for Extracting Features From Images,"The 2-D principal component analysis (2-DPCA) is a widely used method for image feature extraction. However, it can be equivalently implemented via image-row-based principal component analysis. This paper presents a structured 2-D method called nuclear norm-based 2-DPCA (N-2-DPCA), which uses a nuclear norm-based reconstruction error criterion. The nuclear norm is a matrix norm, which can provide a structured 2-D characterization for the reconstruction error image. The reconstruction error criterion is minimized by converting the nuclear norm-based optimization problem into a series of F-norm-based optimization problems. In addition, N-2-DPCA is extended to a bilateral projection-based N-2-DPCA (N-B2-DPCA). The virtue of N-B2-DPCA over N-2-DPCA is that an image can be represented with fewer coefficients. N-2-DPCA and N-B2-DPCA are applied to face recognition and reconstruction and evaluated using the Extended Yale B, CMU PIE, FRGC, and AR databases. Experimental results demonstrate the effectiveness of the proposed methods.","Principal component analysis,
Image reconstruction,
Feature extraction,
Covariance matrices,
Vectors,
Lighting,
Linear programming"
Periodic Array of Subwavelength MEMS Cantilevers for Dynamic Manipulation of Terahertz Waves,"We experimentally demonstrate the active manipulation of terahertz (THz) waves using a periodic array of electrostatically actuated subwavelength microelectromechanical system cantilevers, which effectively behave like a metamaterial. The design methodology for achieving desired ON- and OFF-state resonance frequencies through electromechanical optimization is presented. The microcantilever metamaterial has a switching range of 0.29 THz and a modulation depth of 60% at 0.59 THz. Utilizing metal layer thickness to optimize the devices, an improvement of 40% is achieved in switching range. The microcantilever metamaterials are highly miniaturized, extremely scalable, and electrically controlled with attractive electro-optic performance. Multiple cantilevers can be placed in a desired fashion to form complex unit cell geometry to realize advanced THz manipulation, such as polarization switching, bandwidth tunable filters, multicolor imagers, and so on.","Metamaterials,
Magnetic materials,
Modulation,
Optical switches,
Aluminum oxide,
Silicon"
Economical and Balanced Energy Usage in the Smart Home Infrastructure: A Tutorial and New Results,"The smart home infrastructure features the automatic control of various household appliances in the advanced metering infrastructure, which enables the connection of individual smart home systems to a smart grid. In such an infrastructure, each smart meter receives electricity price from utilities and uses a smart controller to schedule the household appliances accordingly. This helps shift the heavy energy load from peak hours to nonpeak hours. Such an architecture significantly improves the reliability of the power grid through reducing the peak energy usage, while benefiting the customers through reducing electricity bills. This paper presents a tutorial on the development of the smart controller to schedule household appliances, which is also known as smart home scheduling. For each individual user, a dynamic programming-based algorithm that schedules household appliances with discrete power levels is introduced. Based on it, a game theoretic framework is designed for multi-user smart home scheduling to mitigate the accumulated energy usage during the peak hours. The simulation results demonstrate that it can reduce the electricity bill by 30.11% while still improving peak-to-average ratio (PAR) in the power grid. Furthermore, the deployment of smart home scheduling techniques in a big city is discussed. In such a context, the parallel computation is explored to tackle the large computational complexity, a machine assignment approximation algorithm is proposed to accelerate the smart home scheduling, and a new hieratical framework is proposed to reduce the communication overhead. The simulation results on large test cases demonstrate that the city level hierarchical smart home scheduling can achieve the bill reduction of 43.04% and the PAR reduction of 47.50% on average.","Home appliances,
Smart homes,
Pricing,
Energy consumption,
Processor scheduling,
Circuit synthesis"
"Staged Development of Robot Skills: Behavior Formation, Affordance Learning and Imitation with Motionese","Inspired by infant development, we propose a three staged developmental framework for an anthropomorphic robot manipulator. In the first stage, the robot is initialized with a basic reach-and- enclose-on-contact movement capability, and discovers a set of behavior primitives by exploring its movement parameter space. In the next stage, the robot exercises the discovered behaviors on different objects, and learns the caused effects; effectively building a library of affordances and associated predictors. Finally, in the third stage, the learned structures and predictors are used to bootstrap complex imitation and action learning with the help of a cooperative tutor. The main contribution of this paper is the realization of an integrated developmental system where the structures emerging from the sensorimotor experience of an interacting real robot are used as the sole building blocks of the subsequent stages that generate increasingly more complex cognitive capabilities. The proposed framework includes a number of common features with infant sensorimotor development. Furthermore, the findings obtained from the self-exploration and motionese guided human-robot interaction experiments allow us to reason about the underlying mechanisms of simple-to-complex sensorimotor skill progression in human infants.","Robot sensing systems,
Robot kinematics,
Trajectory,
Pediatrics,
Grasping,
Visualization"
Carrier-Based Discontinuous PWM Method for Vienna Rectifiers,"Vienna rectifiers, which are nongenerative-boost types of rectifiers, are used in grid-connected applications with a unity power factor such as telecommunication systems and wind turbine systems. These rectifiers are advantageous in that they have low total harmonic distortion and efficiency. There are many switching methods, which are different from those of threelevel topologies, for Vienna rectifiers. In this paper, we propose a carrier-based discontinuous pulse width modulation (CB-DPWM) method. This method is simple compared to the discontinuous PWM (DPWM) method for Vienna rectifiers based on space vectors and guarantees normal rectifier operation for all modulation index (Ma) values. We perform experiments to verify the suitability and performance of the proposed CB-DPWM method.","Rectifiers,
Pulse width modulation,
Switches,
Topology,
Reactive power,
Vectors"
Feedforward Categorization on AER Motion Events Using Cortex-Like Features in a Spiking Neural Network,"This paper introduces an event-driven feedforward categorization system, which takes data from a temporal contrast address event representation (AER) sensor. The proposed system extracts bio-inspired cortex-like features and discriminates different patterns using an AER based tempotron classifier (a network of leaky integrate-and-fire spiking neurons). One of the system's most appealing characteristics is its event-driven processing, with both input and features taking the form of address events (spikes). The system was evaluated on an AER posture dataset and compared with two recently developed bio-inspired models. Experimental results have shown that it consumes much less simulation time while still maintaining comparable performance. In addition, experiments on the Mixed National Institute of Standards and Technology (MNIST) image dataset have demonstrated that the proposed system can work not only on raw AER data but also on images (with a preprocessing step to convert images into AER events) and that it can maintain competitive accuracy even when noise is added. The system was further evaluated on the MNIST dynamic vision sensor dataset (in which data is recorded using an AER dynamic vision sensor), with testing accuracy of 88.14%.","Neurons,
Convolution,
Feature extraction,
Computer architecture,
Feedforward neural networks,
Kernel,
Visualization"
Spectrum and Energy Efficiency in Massive MIMO Enabled HetNets: A Stochastic Geometry Approach,"This letter focuses on the spectrum efficiency (SE) and energy efficiency (EE) of K-tier heterogeneous networks (HetNets), in which massive multiple-input multiple-output (MIMO) is employed in the macro cells. We consider the impact of massive MIMO on flexible cell association. We develop an analytical approach to examine SE and EE of HetNets. We confirm that using flexible cell association can improve the EE of HetNets by offloading data traffic to small cell. This is due to an increase of EE in the macro cell. Moreover, we show that serving moderate number of users in the macro cells with massive MIMO can boost both SE and EE.","MIMO,
Interference,
Fading,
Signal to noise ratio,
Power demand,
Base stations,
Downlink"
Synchronization of Memristor-Based Coupling Recurrent Neural Networks With Time-Varying Delays and Impulses,"Synchronization of an array of linearly coupled memristor-based recurrent neural networks with impulses and time-varying delays is investigated in this brief. Based on the Lyapunov function method, an extended Halanay differential inequality and a new delay impulsive differential inequality, some sufficient conditions are derived, which depend on impulsive and coupling delays to guarantee the exponential synchronization of the memristor-based recurrent neural networks. Impulses with and without delay and time-varying delay are considered for modeling the coupled neural networks simultaneously, which renders more practical significance of our current research. Finally, numerical simulations are given to verify the effectiveness of the theoretical results.","Synchronization,
Delays,
Artificial neural networks,
Memristors,
Recurrent neural networks,
Biological neural networks"
Data Collection Maximization in Renewable Sensor Networks via Time-Slot Scheduling,"In this paper we study data collection in an energy renewable sensor network for scenarios such as traffic monitoring on busy highways, where sensors are deployed along a predefined path (the highway) and a mobile sink travels along the path to collect data from one-hop sensors periodically. As sensors are powered by renewable energy sources, time-varying characteristics of ambient energy sources poses great challenges in the design of efficient routing protocols for data collection in such networks. In this paper we first formulate a novel data collection maximization problem by adopting multi-rate data transmissions and performing transmission time slot scheduling, and show that the problem is NP-hard. We then devise an offline algorithm with a provable approximation ratio for the problem by exploiting the combinatorial property of the problem, assuming that the harvested energy at each node is given and link communications in the network are reliable. We also extend the proposed algorithm by minor modifications to a general case of the problem where the harvested energy at each sensor is not known in advance and link communications are not reliable. We thirdly develop a fast, scalable online distributed algorithm for the problem in realistic sensor networks in which neither the global knowledge of the network topology nor sensor profiles such as sensor locations and their harvested energy profiles is given. Furthermore, we also consider a special case of the problem where each node has only a fixed transmission power, for which we propose an exact solution to the problem. We finally conduct extensive experiments by simulations to evaluate the performance of the proposed algorithms. Experimental results demonstrate that the proposed algorithms are efficient and the solutions obtained are fractional of the optimum.","Mobile communication,
Data collection,
Approximation algorithms,
Mobile computing,
Data communication,
Approximation methods,
Energy consumption"
Random Walk and Graph Cut for Co-Segmentation of Lung Tumor on PET-CT Images,"Accurate lung tumor delineation plays an important role in radiotherapy treatment planning. Since the lung tumor has poor boundary in positron emission tomography (PET) images and low contrast in computed tomography (CT) images, segmentation of tumor in the PET and CT images is a challenging task. In this paper, we effectively integrate the two modalities by making fully use of the superior contrast of PET images and superior spatial resolution of CT images. Random walk and graph cut method is integrated to solve the segmentation problem, in which random walk is utilized as an initialization tool to provide object seeds for graph cut segmentation on the PET and CT images. The co-segmentation problem is formulated as an energy minimization problem which is solved by max-flow/min-cut method. A graph, including two sub-graphs and a special link, is constructed, in which one sub-graph is for the PET and another is for CT, and the special link encodes a context term which penalizes the difference of the tumor segmentation on the two modalities. To fully utilize the characteristics of PET and CT images, a novel energy representation is devised. For the PET, a downhill cost and a 3D derivative cost are proposed. For the CT, a shape penalty cost is integrated into the energy function which helps to constrain the tumor region during the segmentation. We validate our algorithm on a data set which consists of 18 PET-CT images. The experimental results indicate that the proposed method is superior to the graph cut method solely using the PET or CT is more accurate compared with the random walk method, random walk co-segmentation method, and non-improved graph cut method.","Positron emission tomography,
Tumors,
Computed tomography,
Image segmentation,
Lungs,
Context,
Three-dimensional displays"
Resource allocation in heterogeneous cloud radio access networks: advances and challenges,"Base station densification is increasingly used by network operators to provide better throughput and coverage performance to mobile subscribers in dense data traffic areas. Such densification is progressively diffusing the move from traditional macrocell base stations toward heterogeneous networks with diverse cell sizes (e.g., microcell, picocell, femotcell) and diverse radio access technologies (e.g., GSM, CDMA), and LTE). The coexistence of the different network entities brings an additional set of challenges, particularly in terms of the provisioning of high-speed communications and the management of wireless interference. Resource sharing between different entities, largely incompatible in conventional systems due to the lack of interconnections, becomes a necessity. By connecting all the base stations from different tiers to a central processor (referred to as the cloud) through wire/wireline backhaul links, the heterogeneous cloud radio access network, H-CRAN, provides an open, simple, controllable, and flexible paradigm for resource allocation. This article discusses challenges and recent developments in H-CRAN design. It proposes promising resource allocation schemes in H-CRAN: coordinated scheduling, hybrid backhauling, and multicloud association. Simulations results show how the proposed strategies provide appreciable performance improvement compared to methods from recent literature.","Wireless communication,
Resource management,
Radio access networks,
Computer architecture,
Optimal scheduling,
Radio access networks,
Time-frequency analysis,
Cloud computing"
Stochastic Pre-hurricane Restoration Planning for Electric Power Systems Infrastructure,"Proactive preparedness to cope with emergencies, especially those of nature origins, significantly improves the resilience and minimizes the restoration cost of electric power systems. In this paper, a proactive resource allocation model for repair and restoration of potential damages to the power system infrastructure located on the path of an upcoming hurricane is proposed. The objective is to develop an efficient framework for system operators to minimize potential damages to power system components in a cost-effective manner. The problem is modeled as a stochastic integer program with complete recourse. The large-scale mixed-integer equivalence of the original model is solved by the Benders' decomposition method to handle computation burden. The standard IEEE 118-bus system is employed to demonstrate the effectiveness of the proposed model and further discuss its merits.","Maintenance engineering,
Hurricanes,
Stochastic processes,
Random variables,
Planning,
Substations"
Current Status of the IEEE 1451 Standard-Based Sensor Applications,"In this paper, we have discussed the sensor-based applications and what is necessary for the dissimilarities in hardware realization and algorithm. This paper presents the existing state-of-the-art of IEEE 1451 standard-based sensor applications and is mainly focused on standard transducer interface module (STIM), network capable application processor (NCAP), and transducer-independent interface (TII). They have some major factors that are regularly imperative in the development of IEEE 1451 standard-based applications, such as plug and play facility, for one or more than one STIM, communication protocols/network's, architecture, reliability, maintenance, accuracy, easy to use, cost, transducer electronic data sheet, test facility, and so on. The above concerns are also summarized by reference to research articles on STIM, NCAP, and TII. Highlighting is on the predictability of dynamic applications that concentrate on the above mentioned criteria.","Standards,
Transducers,
Monitoring,
Graphical user interfaces,
Intelligent sensors,
Temperature measurement"
Transmission Line Overload Risk Assessment for Power Systems With Wind and Load-Power Generation Correlation,"In the risk-based security assessment, probability and severity of events are the two main factors for measuring the security level of power systems. This paper presents a method for assessing line overload risk of wind-integrated power systems with the consideration of wind and load-power generation correlation. The established risk assessment model fully considers the probability and the consequence of wind uncertainties and line flow fluctuations. The point estimate method is employed to deal with the probability of line overload and the severity function is applied to quantify line flow fluctuations. Moreover, with the Cholesky decomposition, the correlation between loads and power generations are simulated by the spatial transformation of probability distributions of random variables. In addition, Nataf transformation is used to address wind resource correlation. Finally, the line overload risk index is obtained, which can be used as an indicator for quantifying power system security. Numerical results on the modified IEEE 30-bus system and the modified IEEE 118-bus system show that the types and the parameters of the wind speed distribution would affect the risk indices of line overload, and the risk indices obtained with the consideration of wind resource correlation and load correlation would reflect the system security more accurately.","Random variables,
Correlation,
Security,
Wind speed,
Risk management,
Power systems,
Power generation"
Design and Fabrication of S0 Lamb-Wave Thin-Film Lithium Niobate Micromechanical Resonators,"Commercial markets desire integrated multifrequency band-select duplexer and diplexer filters with a wide fractional bandwidth and steep roll-off to satisfy the ever-increasing demand for spectrum. In this paper, we discuss the fabrication and design of lithium niobate (LN) thin-film S0 Lamb-wave resonators on a piezoelectric-on-piezoelectric platform. Filters using these resonators have the potential to fulfill all the above requirements. In particular, we demonstrated one-port high-order S0 Lamb-wave resonators with resonant frequencies from ~400 MHz to ~1 GHz on a black rotated y-136 cut LN thin film. The effective electromechanical coupling factor (k2eff ) ranges from 7% to 12%, while the measured quality factor ranges from 600 to 3300. The highest k2eff × Q achieved on this chip is 194, significantly surpassing contour mode resonators manufactured in other technologies.","Electrodes,
Q-factor,
III-V semiconductor materials,
Crystals,
Resonant frequency,
Couplings,
Fabrication"
Quantifying sources of error in McPAT and potential impacts on architectural studies,"Architectural power modeling tools are widely used by the computer architecture community for rapid evaluations of high-level design choices and design space explorations. Currently, McPAT [31] is the de facto power model, but the literature does not yet contain a careful examination of its modeling accuracy. In addition, the issue of how greatly power modeling error can affect architectural-level studies has not been quantified before. In this work, we present the first rigorous assessment of McPAT's core power and area models with a detailed, validated power modeling toolchain used in current industrial practice. We find that McPAT's predictions can have significant error because some of the models are either incomplete, too high-level, or assume implementations of structures that differ from that of the core at hand. We demonstrate that large errors are possible when using McPAT's dynamic power estimates in the context of voltage noise and thermal hotspots, but for steady-state properties, accurately modeling leakage power is more important. Based on our analysis, we are able to provide guidelines for creating accurate McPAT models, even without access to detailed industrial power modeling tools. We conclude that in spite of its accuracy gaps, McPAT is still a very useful tool for many architectural studies, and its limitations can often be adequately addressed for a given research study of interest.",
Object detection by labeling superpixels,"Object detection is often conducted by object proposal generation and classification sequentially. This paper handles object detection in a superpixel oriented manner instead of the proposal oriented. Specially, this paper takes object detection as a multi-label superpixel labeling problem by minimizing an energy function. It uses the data cost term to capture the appearance, smooth cost term to encode the spatial context and label cost term to favor compact detection. The data cost is learned through a convolutional neural network and the parameters in the labeling model are learned through a structural SVM. Compared with proposal generation and classification based methods, the proposed superpixel labeling method can naturally detect objects missed by proposal generation step and capture the global image context to infer the overlapping objects. The proposed method shows its advantage in Pascal VOC and ImageNet. Notably, it performs better than the ImageNet ILSVRC2014 winner GoogLeNet (45.0% V.S. 43.9% in mAP) with much shallower and fewer CNNs.","Proposals,
Labeling,
Object detection,
Context,
Support vector machines,
Image color analysis,
Training"
Polar Codes for Broadcast Channels,"Polar codes are introduced for discrete memoryless broadcast channels. For m-user deterministic broadcast channels, polarization is applied to map uniformly random message bits from m-independent messages to one codeword while satisfying broadcast constraints. The polarization-based codes achieve rates on the boundary of the private-message capacity region. For two-user noisy broadcast channels, polar implementations are presented for two information-theoretic schemes: 1) Cover's superposition codes and 2) Marton's codes. Due to the structure of polarization, constraints on the auxiliary and channel-input distributions are identified to ensure proper alignment of polarization indices in the multiuser setting. The codes achieve rates on the capacity boundary of a few classes of broadcast channels (e.g., binary-input stochastically degraded). The complexity of encoding and decoding is O(n log n), where n is the block length. In addition, polar code sequences obtain a stretched-exponential decay of O(2-nβ) of the average block error probability where 0 <; β <; 1/2. Reproducible experiments for finite block lengths n = 512, 1024, 2048 corroborate the theory.",
Optimal Power Allocation Scheme for Energy Efficiency Maximization in Distributed Antenna Systems,"In this paper, we present a power allocation method for a distributed antenna system (DAS) to maximize energy efficiency (EE), which is defined as the ratio of the transmission rate to the total consumed power. Different from conventional EE maximization schemes that require iterative numerical methods, we derive the optimal solution as a closed form by solving Karush-Kuhn-Tucker conditions. The obtained closed-form expression is applicable to DAS with an arbitrary number of distributed antenna (DA) ports and general per-DA port power constraints and is also guaranteed to be globally optimum. Then, we provide several interesting observations on the proposed EE maximizing power allocation scheme. Based on these results, we propose a simplified practical power allocation method that employs the DA port selection and computes the power level in a distributed manner. Through Monte Carlo simulations, we show that the proposed optimal power allocation method produces the EE identical to exhaustive search with significantly reduced computational complexity. In addition, it is shown that the proposed simplified power allocation method based on the DA port selection exhibits little performance loss compared to the optimal algorithm with a remarkable reduction in the system overhead.","Ports (Computers),
Resource management,
Closed-form solutions,
Antenna arrays,
Optimization,
Iterative methods"
iGeoRec: A Personalized and Efficient Geographical Location Recommendation Framework,"Geographical influence has been intensively exploited for location recommendations in location-based social networks (LBSNs) due to the fact that geographical proximity significantly affects users' check-in behaviors. However, current studies only model the geographical influence on all users' check-in behaviors as a universal way. We argue that the geographical influence on users' check-in behaviors should be personalized. In this paper, we propose a personalized and efficient geographical location recommendation framework called iGeoRec to take full advantage of the geographical influence on location recommendations. In iGeoRec, there are mainly two challenges: (1) personalizing the geographical influence to accurately predict the probability of a user visiting a new location, and (2) efficiently computing the probability of each user to all new locations. To address these two challenges, (1) we propose a probabilistic approach to personalize the geographical influence as a personal distribution for each user and predict the probability of a user visiting any new location using her personal distribution. Furthermore, (2) we develop an efficient approximation method to compute the probability of any user to all new locations; the proposed method reduces the computational complexity of the exact computation method from O(ILIn3) to O(ILIn) (where ILI is the total number of locations in an LBSN and n is the number of check-in locations of a user). Finally, we conduct extensive experiments to evaluate the recommendation accuracy and efficiency of iGeoRec using two large-scale real data sets collected from the two of the most popular LBSNs: Foursquare and Gowalla. Experimental results show that iGeoRec provides significantly superior performance compared to other state-of-the-art geographical recommendation techniques.","Estimation,
Equations,
Mathematical model,
Approximation methods,
Kernel,
Probabilistic logic,
Computational complexity"
Medium Access Control and Rate Adaptation for Ultrasonic Intrabody Sensor Networks,"The use of wirelessly internetworked miniaturized biomedical devices is promising a significant leap forward in medical treatment of many pervasive diseases. Recognizing the limitations of traditional radio-frequency wireless communications in interconnecting devices within the human body, in this paper, we propose for the first time to develop network protocols for implantable devices based on ultrasonic transmissions. We start off by assessing the theoretical feasibility of using ultrasonic waves in human tissues and by deriving an accurate channel model for ultrasonic intrabody communications. Then, we propose a new ultrasonic transmission and multiple access technique, which we refer to as Ultrasonic WideBand (UsWB). UsWB is based on the idea of transmitting information bits spread over very short pulses following a time-hopping pattern. The short impulse duration results in limited reflection and scattering effects, and the low duty cycle reduces the impact of thermal and mechanical effects, which may be detrimental for human health. We then develop a multiple access technique with distributed control to enable efficient simultaneous access by mutually interfering devices based on minimal and localized information exchange and on measurements at the receiver only. Finally, we demonstrate the performance of UsWB through a multiscale simulator that models the proposed communication system at the acoustic wave level, at the physical (bit) level, and at the network (packet) level. We also validate the simulation results by comparing them to experimental results obtained with a software-defined testbed.",
Indistinguishability Obfuscation from the Multilinear Subgroup Elimination Assumption,"We revisit the question of constructing secure general-purpose indistinguishability obfuscation, with a security reduction based on explicit computational assumptions over multilinear maps. Previous to our work, such reductions were only known to exist based on meta-assumptions and/or ad-hoc assumptions: In the original constructive work of Garg et al. (FOCS 2013), the underlying explicit computational assumption encapsulated an exponential family of assumptions for each pair of circuits to be obfuscated. In the more recent work of Pass et al. (Crypto 2014), the underlying assumption is a meta-assumption that also encapsulates an exponential family of assumptions, and this meta-assumption is invoked in a manner that captures the specific pair of circuits to be obfuscated. The assumptions underlying both these works substantially capture (either explicitly or implicitly) the actual structure of the obfuscation mechanism itself. In our work, we provide the first construction of general-purpose indistinguishability obfuscation proven secure via a reduction to a natural computational assumption over multilinear maps, namely, the Multilinear Subgroup Elimination Assumption. This assumption does not depend on the circuits to be obfuscated (except for its size), and does not correspond to the underlying structure of our obfuscator. The technical heart of our paper is our reduction, which gives a new way to argue about the security of indistinguishability obfuscation.",
Torque Saturation in Bipedal Robotic Walking Through Control Lyapunov Function-Based Quadratic Programs,"This paper presents a novel method to address the actuator saturation for nonlinear hybrid systems by directly incorporating user-defined input bounds in a controller design. In particular, we consider the application of bipedal walking and show that our method [based on a quadratic programming (QP) implementation of a control Lyapunov function (CLF)-based controller] enables a gradual performance degradation while still continuing to walk under increasingly stringent input bounds. We draw on our previous work, which has demonstrated the effectiveness of the CLF-based controllers for stabilizing periodic gaits for biped walkers. This paper presents a framework, which results in more effective handling of control saturations and provides a means for incorporating a whole family of user-defined constraints into the online computation of a CLF-based controller. This paper concludes with an experimental validation of the main results on the bipedal robot MABEL, demonstrating the usefulness of the QP-based CLF approach for real-time robotic control.","Actuators,
Nonlinear systems,
Torque control,
Quadratic programming,
Lyapunov methods,
Hybrid systems,
Real-time systems,
Legged locomotion,
Degradation"
Router for Power Packet Distribution Network: Design and Experimental Verification,"A power packet dispatching system is expected to be one of the advanced power distribution systems for controlling electric power, providing energy on demand, and reducing wasted energy consumption. In this paper, power packet routers are designed and experimentally verified for realizing a networked power packet distribution system. While the previously developed router directly forwards the power packet to a load, the new router forwards the packet to the other router with an information tag reattached to the power payload. In addition, the new router can adjust the starting time for forwarding the received power packet to the other site, thus utilizing storage capacity integrated into the router. The results successfully clarify the feasibility of the power packet distribution network.","Mixers,
Switches,
Dispatching,
Prototypes,
Ports (Computers),
Power systems,
Switching circuits"
Energy-Efficient Cooperative Communications for Multimedia Applications in Multi-Channel Wireless Networks,"The dramatic growth of mobile multimedia communications imposes new requirements on quality-of-service and energy efficiency in wireless networks. In this paper, we study the energy- and spectrum-efficient cooperative communication (ESCC) problem by exploiting the benefits of cooperative communication (CC) for mobile multimedia applications in multi-channel wireless networks. In a static network, it is formulated as a mixed-integer nonlinear programming problem. To solve this problem, we use linearization and reformulation techniques to transform it into a mixed-integer linear programming problem that is solved by a branch-and-bound algorithm with enhanced performance. To deal with the problem in dynamic networks, we propose an online algorithm with low computational complexity and deployment overhead. Extensive simulations are conducted to show that the proposed algorithm can significantly improve the performance of energy efficiency in both static and dynamic networks.",
A 16-Channel Patient-Specific Seizure Onset and Termination Detection SoC With Impedance-Adaptive Transcranial Electrical Stimulator,"A 16-channel noninvasive closed-loop beginning-and end-of-seizure detection SoC is presented. The dual-channel charge recycled (DCCR) analog front end (AFE) achieves chopping and time-multiplexing an amplifier between two channels simultaneously which exploits fast-settling DC servo-loop with current consumption and NEF of 0.9 μA/channel and 3.29/channel, respectively. The dual-detector architecture (D2A) classification processor utilizes two linear support-vector machine (LSVM) classifiers based on digital hysteresis to enhance both the sensitivity and the specificity simultaneously. The pulsating voltage transcranial electrical stimulator (PVTES) automatically configures the number of pulses to control the amount of charge delivered based on skin-electrode impedance variation in efforts to suppress the seizure activity, while burning only 2.45 μW. The 25 mm2 SoC implemented in 0.18 μm CMOS consumes 2.73 μJ/classification for 16 channels with an average sensitivity, specificity, and latency of 95.7%, 98%, and 1 s, respectively.",
An Integrated Approach to Global Synchronization and State Estimation for Nonlinear Singularly Perturbed Complex Networks,"This paper aims to establish a unified framework to handle both the exponential synchronization and state estimation problems for a class of nonlinear singularly perturbed complex networks (SPCNs). Each node in the SPCN comprises both “slow” and “fast” dynamics that reflects the singular perturbation behavior. General sector-like nonlinear function is employed to describe the nonlinearities existing in the network. All nodes in the SPCN have the same structures and properties. By utilizing a novel Lyapunov functional and the Kronecker product, it is shown that the addressed SPCN is synchronized if certain matrix inequalities are feasible. The state estimation problem is then studied for the same complex network, where the purpose is to design a state estimator to estimate the network states through available output measurements such that dynamics (both slow and fast) of the estimation error is guaranteed to be globally asymptotically stable. Again, a matrix inequality approach is developed for the state estimation problem. Two numerical examples are presented to verify the effectiveness and merits of the proposed synchronization scheme and state estimation formulation. It is worth mentioning that our main results are still valid even if the slow subsystems within the network are unstable.","Synchronization,
Complex networks,
State estimation,
Symmetric matrices,
Linear matrix inequalities,
Educational institutions,
Couplings"
Methodology for Standard Cell Compliance and Detailed Placement for Triple Patterning Lithography,"As the feature size of semiconductor process further scales to sub-16 nm technology node, triple patterning lithography (TPL) has been regarded as one of the most promising lithography candidates along with extreme ultraviolet, electron beam lithography, and directly self-assembly. M1 and contact layers, which are usually deployed within standard cells, are the most critical and complex parts for modern digital designs. Traditional design flow that ignores TPL in early stages may limit the potential to resolve all the TPL conflicts. In this paper, we propose a coherent framework, including standard cell compliance and detailed placement, to enable TPL friendly design. Considering TPL constraints during early design stages, such as standard cell compliance, improves the layout decomposability. With the precoloring solutions of standard cells, we present a TPL aware detailed placement where the layout decomposition and placement can be resolved simultaneously. In addition, we propose a linear dynamic programming to solve TPL aware detailed placement with maximum displacement, which can achieve good trade-off in terms of runtime and performance. Experimental results show that our framework can achieve zero conflict, meanwhile can effectively optimize the stitch number and placement wire-length.","Layout,
Standards,
Color,
Timing,
Lithography,
Law"
Extended Bandwidth Lorentz Force Magnetometer Based on Quadrature Frequency Modulation,"In this paper, a Lorentz force magnetometer demonstrates quadrature frequency modulation operation. The Lorentz force magnetometer consists of a conventional 3-port resonator, which is put into oscillation by electrostatic driving and sensing. The bias current flowing through the resonator is proportional to the displacement, and generates Lorentz force in quadrature with the electrostatic force. As a result, the Lorentz force acts as an equivalent spring and the magnetic field can be measured by reading the change in oscillation frequency. The sensor has a sensitivity of 500 Hz/T with a short-term noise floor of 500 nT\surd Hz. The bandwidth of the sensor is increased to 50 Hz, a factor of 12 greater than that of the same resonator operating in amplitude-modulated mode. The short-term noise floor within 50-Hz bandwidth is comparable with CMOS Hall-effect sensors.","Magnetometers,
Magnetic resonance,
Magnetomechanical effects,
Frequency modulation,
Lorentz covariance,
Oscillators"
"A High-Bandwidth MEMS Nanopositioner for On-Chip AFM: Design, Characterization, and Control","We report the design, characterization, and control of a high-bandwidth microelectromechanical systems (MEMS) nanopositioner for on-chip atomic force microscopy (AFM). For the fabrication, a commercially available process based on silicon-on-insulator is used. The device consists of a scan table, moved in the x-y plane by two sets of electrostatic comb actuators, capable of generating strokes in excess of ±5 μm. The first resonance frequencies of the nanopositioner are approximately 4.4 and 5.3 kHz in lateral directions. Electrothermal sensors are used to measure the displacement of the scan table. To enable fast scans, a dynamic model of the system is identified and used to design a feedback controller that damps the oscillatory behavior of the device. The nanopositioner is tested as the scanning stage of an AFM to perform high-speed scans.","Nanopositioning,
Micromechanical devices,
Sensor phenomena and characterization,
System-on-chip,
Bandwidth,
Force"
Variational Bayesian Matrix Factorization for Bounded Support Data,"A novel Bayesian matrix factorization method for bounded support data is presented. Each entry in the observation matrix is assumed to be beta distributed. As the beta distribution has two parameters, two parameter matrices can be obtained, which matrices contain only nonnegative values. In order to provide low-rank matrix factorization, the nonnegative matrix factorization (NMF) technique is applied. Furthermore, each entry in the factorized matrices, i.e., the basis and excitation matrices, is assigned with gamma prior. Therefore, we name this method as beta-gamma NMF (BG-NMF). Due to the integral expression of the gamma function, estimation of the posterior distribution in the BG-NMF model can not be presented by an analytically tractable solution. With the variational inference framework and the relative convexity property of the log-inverse-beta function, we propose a new lower-bound to approximate the objective function. With this new lower-bound, we derive an analytically tractable solution to approximately calculate the posterior distributions. Each of the approximated posterior distributions is also gamma distributed, which retains the conjugacy of the Bayesian estimation. In addition, a sparse BG-NMF can be obtained by including a sparseness constraint to the gamma prior. Evaluations with synthetic data and real life data demonstrate the good performance of the proposed method.",
Wireless Underground Sensor Networks: MI-based communication systems for underground applications.,"Wireless underground sensor networks (WUSNs) can enable many important applications such as intelligent agriculture, pipeline fault diagnosis, mine disaster rescue, concealed border patrol, and crude oil exploration. The key challenge to realize WUSNs is the wireless communication in underground environments. Most existing wireless communication systems utilize a dipole antenna to transmit and receive propagating electromagnetic (EM) waves, a method that does not work well in underground environments due to the high material absorption loss. The magnetic induction (MI) technique provides a promising alternative solution that could address the current problem in underground environments. Although MI-based underground communication has been intensively investigated theoretically, little effort has been made so far to develop a testbed for MI-based underground communication that can validate the theoretical results. In this article, a testbed of several MI-based communication systems is designed and implemented in an in-lab underground environment. The testbed realizes and tests not only the original MI mechanism utilizing a single coil but also recently developed techniques that use the MI waveguide and threedirectional (3D) MI coils. The experiments are conducted in an in-lab underground environment with reconfigurable environmental parameters, such as soil composition and water content. This article provides the principles and guidelines for developing the MI underground communication testbed, which is very complicated and time consuming due to the new communication mechanism and the new wireless transmission medium.","Wireless communication,
Fault diagnosis,
Three-dimensional displays,
Wireless sensor networks,
Fuel processing industries,
Transceivers,
Dipole antennas,
Electromagnetic waves,
Buried object detection,
Disasters"
Effects of Field of View and Visual Complexity on Virtual Reality Training Effectiveness for a Visual Scanning Task,"Virtual reality training systems are commonly used in a variety of domains, and it is important to understand how the realism of a training simulation influences training effectiveness. We conducted a controlled experiment to test the effects of display and scenario properties on training effectiveness for a visual scanning task in a simulated urban environment. The experiment varied the levels of field of view and visual complexity during a training phase and then evaluated scanning performance with the simulator's highest levels of fidelity and scene complexity. To assess scanning performance, we measured target detection and adherence to a prescribed strategy. The results show that both field of view and visual complexity significantly affected target detection during training; higher field of view led to better performance and higher visual complexity worsened performance. Additionally, adherence to the prescribed visual scanning strategy during assessment was best when the level of visual complexity during training matched that of the assessment conditions, providing evidence that similar visual complexity was important for learning the technique. The results also demonstrate that task performance during training was not always a sufficient measure of mastery of an instructed technique. That is, if learning a prescribed strategy or skill is the goal of a training exercise, performance in a simulation may not be an appropriate indicator of effectiveness outside of training-evaluation in a more realistic setting may be necessary.","Training,
Visualization,
Complexity theory,
Virtual reality,
Object detection,
Solid modeling,
Head"
"30 pJ/b, 67 Mbps, Centimeter-to-Meter Range Data Telemetry With an IR-UWB Wireless Link","This paper reports an energy-efficient, impulse radio ultra wideband (IR-UWB) wireless link operating in 3-5 GHz for data telemetry over centimeter-to-meter range distances at rates extended to tens of Mbps. The link comprises an all-digital, integrated transmitter (TX) fabricated in 90 nm 1P/9M CMOS that incorporates a waveform-synthesis pulse generator and a timing generator for on-off-keying (OOK) pulse modulation and phase scrambling. The link also incorporates an energy-detection receiver (RX) realized with commercial off-the-shelf (COTS) components that performs radio-frequency (RF) filtering, amplification, logarithmic power detection for data demodulation and automatic level control for robust operation in the presence of distance variations. Employing a miniaturized, UWB, chip antenna for the TX and RX, wireless transmission of pseudo-random binary sequence (PRBS) data at rates up to 50 Mbps over 10 cm-1 m is shown. Further, employing a high-gain horn antenna for the RX, wireless transmission of PRBS data at rates up to 67 Mbps over 50 cm-4 m is shown with a TX energy consumption of 30 pJ/b (i.e., power consumption of 2 mW) from 1.2 V. The measured bit error rate (BER) in both cases is . Results from wireless recording of the background current of a carbon-fiber microelectrode (CFM) in one fast-scan cyclic voltammetry (FSCV) scan using the IR-UWB link are also included, exhibiting excellent match with those obtained from a conventional frequency-shift-keyed (FSK) link at ~ 433 MHz.","Wireless communication,
Radio frequency,
Antenna measurements,
Ultra wideband antennas,
Delays,
Horn antennas,
Wireless sensor networks"
Open and Low-Cost Virtual and Remote Labs on Control Engineering,"This paper presents an open course in the University Network of Interactive Laboratories, which offers several virtual and remote laboratories on automatic control, accessible to anyone. All the details on one of these labs (a two electric coupled drives system that allows performing control practices in a 2 × 2 MIMO system with industrial applications) and the activities that can be performed with it are given. We use a low-cost solution for developing the virtual and remote labs shared in this open course, based on the use of a free authoring tool Easy Java/Javascript Simulations (EJsS) for building the laboratories' user interfaces and a cheap development platform board (BeagleBone Black). The virtual and remote labs are deployed into a free Learning Management System (Moodle) Web environment that facilitates their management and maintenance.",
Capacitor-Less Photovoltaic Cell-Level Power Balancing using Diffusion Charge Redistribution,"This paper presents a new strategy, diffusion charge redistribution (DCR), for balancing power among photovoltaic cells to increase energy extraction and to improve maximum power-point tracking (MPPT) efficiency under partial shading conditions. With DCR, testing and binning during cell manufacturing can be eliminated and significant cost savings can be achieved during production. The proposed technique performs power balancing by taking advantage of the intrinsic diffusion capacitance of the solar cells and requires no external passive components for energy storage, thereby minimizing power electronics cost and complexity. Strings balanced by this technique exhibit power versus current curves that are convex, which also greatly reduces the cost and complexity of the required MPPT algorithm.","Photovoltaic cells,
Capacitance,
Computer architecture,
Microprocessors,
Capacitors,
Energy storage,
Switches"
Strategies for Independent Deployment and Autonomous Control of PV and Battery Units in Islanded Microgrids,"In this paper, autonomous control strategies are proposed for Photovoltaic (PV) and battery units operating in a droop-controlled islanded microgrid. Based on the proposed strategies, the PV and battery units can be deployed independently in any droop-controlled microgrid. Both the PV unit and the battery unit are controlled as voltage sources that follow multisegment adaptive power/frequency (P/f) characteristic curves. These P/f characteristic curves are adjusted locally in real time based on the available PV power, load demand, and the state of charge of the battery to autonomously coordinate the operation of these units and maintain the power balance in the microgrid. The strategy proposed for the battery unit enables it to autonomously supply power only during peak load periods, to support the droop-controlled units and maintain the power balance in the islanded microgrid. The control strategies are implemented in each unit using multi-loop controllers, without relying on communication, a central management algorithm, or switching logic. Small signal models of the proposed control loops are presented, and the performance of the proposed strategy is validated using simulation and also through experiments on a 3-kVA prototype microgrid.","Batteries,
Microgrids,
Voltage control,
Frequency control,
Control systems,
System-on-chip,
Power electronics"
The Risks of Coverage-Directed Test Case Generation,"A number of structural coverage criteria have been proposed to measure the adequacy of testing efforts. In the avionics and other critical systems domains, test suites satisfying structural coverage criteria are mandated by standards. With the advent of powerful automated test generation tools, it is tempting to simply generate test inputs to satisfy these structural coverage criteria. However, while techniques to produce coverage-providing tests are well established, the effectiveness of such approaches in terms of fault detection ability has not been adequately studied. In this work, we evaluate the effectiveness of test suites generated to satisfy four coverage criteria through counterexample-based test generation and a random generation approach-where tests are randomly generated until coverage is achieved-contrasted against purely random test suites of equal size. Our results yield three key conclusions. First, coverage criteria satisfaction alone can be a poor indication of fault finding effectiveness, with inconsistent results between the seven case examples (and random test suites of equal size often providing similar-or even higher-levels of fault finding). Second, the use of structural coverage as a supplement-rather than a target-for test generation can have a positive impact, with random test suites reduced to a coverage-providing subset detecting up to 13.5 percent more faults than test suites generated specifically to achieve coverage. Finally, Observable MC/DC, a criterion designed to account for program structure and the selection of the test oracle, can-in part-address the failings of traditional structural coverage criteria, allowing for the generation of test suites achieving higher levels of fault detection than random test suites of equal size. These observations point to risks inherent in the increase in test automation in critical systems, and the need for more research in how coverage criteria, test generation approaches, the test oracle used, and system structure jointly influence test effectiveness.",
Magnetic resonance wireless power transfer using three-coil system with single planar receiver for laptop applications,"This paper presents a magnetic resonance wireless power transfer (WPT) system that uses three coils, a planar receiver and operates at 6.78 MHz,. Effective power transfer is ensured by establishing an impedance matching condition for this WPT system. A metamaterial (MTM) array having dimensions of 20 cm X 30 cm is also positioned near the load coil to concentrate the magnetic field and enhance the transfer efficiency. The result is a maximal improvement of 27% in the transfer efficiency at a transfer distance of 50 cm. The impact of a ground plane on the transfer efficiency is also examined. By utilizing the MTM array, making slits on the ground plane and increasing the gap between the ground plane and the load coil, it is possible to mitigate this impact. The highest transfer efficiency improvement is about 55% at a distance of 20 cm with the ground plane. A practical laptop model is fabricated to verify the impact of the load coil angle and position on the transfer efficiency. The result shows that the maximum transfer efficiency with the laptop model is 47.58% with the load coil angle of 90 degree.","Coils,
Arrays,
Spirals,
Portable computers,
Magnetic resonance,
Receivers"
User-Centric View of Jamming Games in Cognitive Radio Networks,"Jamming games between a cognitive radio enabled secondary user (SU) and a cognitive radio enabled jammer are considered, in which end-user decision making is modeled using prospect theory (PT). More specifically, the interactions between a user and a smart jammer regarding their respective choices of transmit power are formulated as a game under the assumption that the end-user decision making under uncertainty does not follow the traditional objective assumptions stipulated by expected utility theory, but rather follows the subjective deviations specified by PT. Two PT-based static jamming games are formulated to describe how subjective SU and jammer choose their transmit power to maximize their individual signal-to-interference-plus-noise ratio (SINR)-based utilities under uncertainties regarding the opponent's actions and channel states, respectively. The Nash equilibria of the games are presented under various channel models and transmission costs. Moreover, a PT-based dynamic jamming game is presented to investigate the long-term interactions between a subjective and a smart jammer according to a Markov decision process with uncertainty on the SU's future actions and the channel variations. Simulation results show that the subjective view of an SU tends to exaggerate the jamming probabilities and decreases its transmission probability, thus reducing the average SINR. On the other hand, the subjectivity of a jammer tends to reduce its jamming probability, and thus increases the SU throughput.","Jamming,
Games,
Cognitive radio,
Uncertainty,
Interference,
Decision making,
Signal to noise ratio"
A Context-Aware Trust-Based Information Dissemination Framework for Vehicular Networks,"Reliable, secure, private, and fast communication in vehicular networks is extremely challenging due to the highly mobile nature of these networks. Contact time between vehicles is very limited and topology is constantly changing. Trusted communication in vehicular networks is of crucial importance because without trust, all efforts for minimizing the delay or maximizing the reliability could be voided. In this paper, we propose a trust-based framework for a safe and reliable information dissemination in vehicular networks. The proposed framework consists of two modules such that the first one applies three security checks to make sure the message is trusted. It assigns a trust value to each road segment and one to each neighborhood, instead of each car. Thus, it scales up easily and is completely distributed. Once a message is evaluated and considered to be trustworthy, our method then in the second module looks for a safe path through which the message is forwarded. Our frameworks are application-centric; in particular, it is capable of preserving traffic requirements specified by each application. Experimental results demonstrate that this framework outperforms other well-known routing protocols since it routes the messages via trusted vehicles.","Vehicles,
Reliability,
Routing,
Delays,
Routing protocols,
Security,
Roads"
Multilevel Spin-Orbit Torque MRAMs,"In this paper, we present two multilevel spin-orbit torque magnetic random access memories (SOT-MRAMs). A single-level SOT-MRAM employs a three-terminal SOT device as a storage element with enhanced endurance, close-to-zero read disturbance, and low write energy. However, the three-terminal device requires the use of two access transistors per cell. To improve the integration density, we propose two multilevel cells (MLCs): 1) series SOT MLC and 2) parallel SOT MLC, both of which store two bits per memory cell. A detailed analysis of the bit-cell suggests that the S-MLC is promising for applications requiring both high density and low write-error rate, and P-MLC is particularly suitable for high-density and low-write-energy applications. We also performed iso-bit-cell area comparison of our MLC designs with previously proposed MLCs that are based on spin-transfer torque MRAM and show 3-16× improvement in write energy.","Magnetic tunneling,
Resistance,
Frequency modulation,
Torque,
Integrated circuits,
Optimization,
Layout"
Improving Estimation of Distribution Algorithm on Multimodal Problems by Detecting Promising Areas,"In this paper, a novel multiple sub-models maintenance technique, named maintaining and processing sub-models (MAPS), is proposed. MAPS aims to enhance the ability of estimation of distribution algorithms (EDAs) on multimodal problems. The advantages of MAPS over the existing multiple sub-models based EDAs stem from the explicit detection of the promising areas, which can save many function evaluations for exploration and thus accelerate the optimization speed. MAPS can be combined with any EDA that adopts a single Gaussian model. The performance of MAPS has been assessed through empirical studies where MAPS is integrated with three different types of EDAs. The experimental results show that MAPS can lead to much faster convergence speed and obtain more stable solutions than the compared algorithms on 12 benchmark problems.",
Robust Beamforming With Partial Channel State Information for Energy Efficient Networks,"In this paper, we investigate robust beamforming to improve the energy efficiency (EE) of wireless networks when only imperfect or partial channel state information (CSI) is available at the transmitter. Due to CSI quantization errors and/or limited feedback information, CSI imperfections can be well modeled by a bounded uncertainty region. We focus on the worst case robust beamforming strategy to optimize the EE of downlink transmission under the deterministic bounded channel model, which merely assumes a maximal channel error magnitude. We start with a single-user single-cell MIMO system and obtain a closed-form design for robust beamforming. For a multicell network, robust beamforming is in a nonconvex fractional form, and the solution cannot be directly extended from the single-cell scenario. To solve this problem efficiently, we resort to a lower bound, instead of the primal problem, and cast it as a semidefinite program (SDP). The robustness and efficiency of the proposed beamforming design are confirmed by computer simulation results.",
Sparse Representation of Electrodermal Activity With Knowledge-Driven Dictionaries,"Biometric sensors and portable devices are being increasingly embedded into our everyday life, creating the need for robust physiological models that efficiently represent, analyze, and interpret the acquired signals. We propose a knowledge-driven method to represent electrodermal activity (EDA), a psychophysiological signal linked to stress, affect, and cognitive processing. We build EDA-specific dictionaries that accurately model both the slow varying tonic part and the signal fluctuations, called skin conductance responses (SCR), and use greedy sparse representation techniques to decompose the signal into a small number of atoms from the dictionary. Quantitative evaluation of our method considers signal reconstruction, compression rate, and information retrieval measures, that capture the ability of the model to incorporate the main signal characteristics, such as SCR occurrences. Compared to previous studies fitting a predetermined structure to the signal, results indicate that our approach provides benefits across all aforementioned criteria. This paper demonstrates the ability of appropriate dictionaries along with sparse decomposition methods to reliably represent EDA signals and provides a foundation for automatic measurement of SCR characteristics and the extraction of meaningful EDA features.","Thyristors,
Sparse matrices,
Skin,
Biomedical measurement,
Signal reconstruction,
Physiology"
Adaptive Robust Output Feedback Control for a Marine Dynamic Positioning System Based on a High-Gain Observer,"This paper develops an adaptive robust output feedback control scheme for dynamically positioned ships with unavailable velocities and unknown dynamic parameters in an unknown time-variant disturbance environment. The controller is designed by incorporating the high-gain observer and radial basis function (RBF) neural networks in vectorial backstepping method. The high-gain observer provides the estimations of the ship position and heading as well as velocities. The RBF neural networks are employed to compensate for the uncertainties of ship dynamics. The adaptive laws incorporating a leakage term are designed to estimate the weights of RBF neural networks and the bounds of unknown time-variant environmental disturbances. In contrast to the existing results of dynamic positioning (DP) controllers, the proposed control scheme relies only on the ship position and heading measurements and does not require a priori knowledge of the ship dynamics and external disturbances. By means of Lyapunov functions, it is theoretically proved that our output feedback controller can control a ship's position and heading to the arbitrarily small neighborhood of the desired target values while guaranteeing that all signals in the closed-loop DP control system are uniformly ultimately bounded. Finally, simulations involving two ships are carried out, and simulation results demonstrate the effectiveness of the proposed control scheme.","Marine vehicles,
Observers,
Vectors,
Output feedback,
Adaptive systems,
Robustness,
Neural networks"
NextMe: Localization Using Cellular Traces in Internet of Things,"The Internet of Things (IoT) opens up tremendous opportunities to location-based industrial applications that leverage both Internet-resident resources and phones' processing power and sensors to provide location information. Location-based service is one of the vital applications in commercial, economic, and public domains. In this paper, we propose a novel localization scheme called NextMe, which is based on cellular phone traces. We find that the mobile call patterns are strongly correlated with the co-locate patterns. We extract such correlation as social interplay from cellular calls, and use it for location prediction from temporal and spatial perspectives. NextMe consists of data preprocessing, call pattern recognition, and a hybrid predictor. To design the call pattern recognition module, we introduce the notions of critical calls and corresponding patterns. In addition, NextMe does not require that the cell tower addresses should be bounded with concrete coordinates, e.g., global positioning system (GPS) coordinates. We validate NextMe across MIT Reality Mining Dataset, involving 500 000 h of continuous behavior information and 112 508 cellular calls. Experimental results show that NextMe achieves fine-grained prediction accuracy at cell tower level in the forthcoming 1-6 h with 12% accuracy enhancement averagely from cellular calls.","Poles and towers,
Computer architecture,
Microprocessors,
Mobile communication,
Pattern recognition,
Mobile handsets,
Internet of Things"
Minimum Cost Multi-Way Data Association for Optimizing Multitarget Tracking of Interacting Objects,"This paper presents a general formulation for a minimum cost data association problem which associates data features via one-to-one, m-to-one and one-to-n links with minimum total cost of the links. A motivating example is a problem of tracking multiple interacting nanoparticles imaged on video frames, where particles can aggregate into one particle or a particle can be split into multiple particles. Many existing multitarget tracking methods are capable of tracking non-interacting targets or tracking interacting targets of restricted degrees of interactions. The proposed formulation solves a multitarget tracking problem for general degrees of inter-object interactions. The formulation is in the form of a binary integer programming problem. We propose a polynomial time solution approach that can obtain a good relaxation solution of the binary integer programming, so the approach can be applied for multitarget tracking problems of a moderate size (for hundreds of targets over tens of time frames). The resulting solution is always integral and obtains a better duality gap than the simple linear relaxation solution of the corresponding problem. The proposed method was validated through applications to simulated multitarget tracking problems and a real multitarget tracking problem.","Target tracking,
Time measurement,
Linear programming,
Radar tracking,
Trajectory,
Visualization,
Video sequences"
Planning Paths for Package Delivery in Heterogeneous Multirobot Teams,"This paper addresses the task scheduling and path planning problem for a team of cooperating vehicles performing autonomous deliveries in urban environments. The cooperating team comprises two vehicles with complementary capabilities, a truck restricted to travel along a street network, and a quadrotor micro-aerial vehicle of capacity one that can be deployed from the truck to perform deliveries. The problem is formulated as an optimal path planning problem on a graph and the goal is to find the shortest cooperative route enabling the quadrotor to deliver items at all requested locations. The problem is shown to be NP-hard. A solution is then proposed using a novel reduction to the Generalized Traveling Salesman Problem, for which well-established heuristic solvers exist. The heterogeneous delivery problem contains as a special case the problem of scheduling deliveries from multiple static warehouses. We propose two additional algorithms, based on enumeration and a reduction to the traveling salesman problem, for this special case. Simulation results compare the performance of the presented algorithms and demonstrate examples of delivery route computations over real urban street maps.",
Reactive avoidance using embedded stereo vision for MAV flight,"High speed, low latency obstacle avoidance is essential for enabling Micro Aerial Vehicles (MAVs) to function in cluttered and dynamic environments. While other systems exist that do high-level mapping and 3D path planning for obstacle avoidance, most of these systems require high-powered CPUs on-board or off-board control from a ground station. We present a novel entirely on-board approach, leveraging a light-weight low power stereo vision system on FPGA. Our approach runs at a frame rate of 60 frames a second on VGA-sized images and minimizes latency between image acquisition and performing reactive maneuvers, allowing MAVs to fly more safely and robustly in complex environments. We also suggest our system as a light-weight safety layer for systems undertaking more complex tasks, like mapping the environment. Finally, we show our algorithm implemented on a lightweight, very computationally constrained platform, and demonstrate obstacle avoidance in a variety of environments.","Field programmable gate arrays,
Mobile communication,
Robots,
Collision avoidance,
Stereo vision,
Optical sensors,
Navigation"
Space-Collaborative Constellation Designs for MIMO Indoor Visible Light Communications,"In conventional multi-input multioutput (MIMO) visible light communication (VLC) techniques such as repetition coding (RC), spatial multiplexing (SMP), and spatial modulation (SM), the transmitted symbols through different light-emitting diodes located different space are usually generated from unipolar pulse amplitude modulation constellations independently. In this letter, we propose a novel constellation design for MIMO indoor VLC systems, in which the two symbols from two spaces collaborate so closely that the average optical power is minimized under the constraint that the minimum Euclidean distance is fixed. Therefore, this new constellation is called space-collaborative constellation (CC). Computer simulations show that the CC always has better error performance than SM and SMP, and also has better error performance than RC for most of good channels as well as for some really bad channels.","Optical transmitters,
MIMO,
Correlation,
Light emitting diodes,
Optical receivers,
Signal to noise ratio"
Adaptive Noise Immune Cluster Ensemble Using Affinity Propagation,"Cluster ensemble is one of the main branches in the ensemble learning area which is an important research focus in recent years. The objective of cluster ensemble is to combine multiple clustering solutions in a suitable way to improve the quality of the clustering result. In this paper, we design a new noise immune cluster ensemble framework named as AP2CE to tackle the challenges raised by noisy datasets. AP2CE not only takes advantage of the affinity propagation algorithm (AP) and the normalized cut algorithm (Ncut), but also possesses the characteristics of cluster ensemble. Compared with traditional cluster ensemble approaches, AP2CE is characterized by several properties. (1) It adopts multiple distance functions instead of a single Euclidean distance function to avoid the noise related to the distance function. (2) AP2CE applies AP to prune noisy attributes and generate a set of new datasets in the subspaces consists of representative attributes obtained by AP. (3) It avoids the explicit specification of the number of clusters. (4) AP2CE adopts the normalized cut algorithm as the consensus function to partition the consensus matrix and obtain the final result. In order to improve the performance of AP2CE, the adaptive AP2CE is designed, which makes use of an adaptive process to optimize a newly designed objective function. The experiments on both synthetic and real datasets show that (1) AP2CE works well on most of the datasets, in particular the noisy datasets; (2) AP2CE is a better choice for most of the datasets when compared with other cluster ensemble approaches; (3) AP2CE has the capability to provide more accurate, stable and robust results.",
Spectrum-Adapted Tight Graph Wavelet and Vertex-Frequency Frames,"We consider the problem of designing spectral graph filters for the construction of dictionaries of atoms that can be used to efficiently represent signals residing on weighted graphs. While the filters used in previous spectral graph wavelet constructions are only adapted to the length of the spectrum, the filters proposed in this paper are adapted to the distribution of graph Laplacian eigenvalues, and therefore lead to atoms with better discriminatory power. Our approach is to first characterize a family of systems of uniformly translated kernels in the graph spectral domain that give rise to tight frames of atoms generated via generalized translation on the graph. We then warp the uniform translates with a function that approximates the cumulative spectral density function of the graph Laplacian eigenvalues. We use this approach to construct computationally efficient, spectrum-adapted, tight vertex-frequency and graph wavelet frames. We give numerous examples of the resulting spectrum-adapted graph filters, and also present an illustrative example of vertex-frequency analysis using the proposed construction.",
A Framework of Cooperative Cell Caching for the Future Mobile Networks,"The demand for rich multimedia services over mobile networks has been soaring at a tremendous pace over recent years. However, the wireless link capacity as well as the bandwidth of the radio access networks and the backhaul network cannot practically cope with the explosive growth in mobile traffic load. In this article, we mainly focus on a new novel framework of cooperative cell caching for future mobile cellular networks, where the base station of each cell can have certain capability of caching popular contents. Then we carry out necessary theoretical modeling-based analysis. We also propose to utilize prefix-tree aggregation to improve the caching performance among cells, and discuss potential deployment issues for caching in 5G mobile networks. Based on trace-driven simulations, we evaluate the performance of the proposed framework.","Mobile communication,
Mobile computing,
Telecommunication traffic,
Computer architecture,
Microprocessors,
Videos,
Radio access networks"
Multi-Target Tracking With Time-Varying Clutter Rate and Detection Profile: Application to Time-Lapse Cell Microscopy Sequences,"Quantitative analysis of the dynamics of tiny cellular and sub-cellular structures, known as particles, in time-lapse cell microscopy sequences requires the development of a reliable multi-target tracking method capable of tracking numerous similar targets in the presence of high levels of noise, high target density, complex motion patterns and intricate interactions. In this paper, we propose a framework for tracking these structures based on the random finite set Bayesian filtering framework. We focus on challenging biological applications where image characteristics such as noise and background intensity change during the acquisition process. Under these conditions, detection methods usually fail to detect all particles and are often followed by missed detections and many spurious measurements with unknown and time-varying rates. To deal with this, we propose a bootstrap filter composed of an estimator and a tracker. The estimator adaptively estimates the required meta parameters for the tracker such as clutter rate and the detection probability of the targets, while the tracker estimates the state of the targets. Our results show that the proposed approach can outperform state-of-the-art particle trackers on both synthetic and real data in this regime.","Clutter,
Target tracking,
Mathematical model,
Insulation life,
Degradation,
Bayes methods,
Time measurement"
Dual-Wavelength Single-Longitudinal-Mode Tm-Doped Fiber Laser Using PM-CMFBG,"We have demonstrated a dual-wavelength thulium-doped fiber laser with single-longitudinal-mode (SLM) operation at ~2-μm region. A polarization-maintaining chirped Moiré fiber Bragg grating was employed as a polarization-dependent narrow-band filter, to suppress multilongitudinal-mode oscillation. Single-and dual-wavelength switchable operation was achieved by simply adjusting the polarization controller. We also showed that the laser lines retained SLM operation with the additional benefit of single polarization. Meanwhile, the dependence of each laser wavelength on the pump power was also investigated in detail.","Optical fiber polarization,
Fiber lasers,
Optical fiber dispersion,
Pump lasers,
Gas lasers,
Laser excitation"
Silk-Backed Structural Optimization of High-Density Flexible Intracortical Neural Probes,"Many chronic neuroscience studies require neural probes that can reliably record with a large number of electrodes in a densely configured array. Previous works have shown that adverse tissue reaction can be significantly reduced as probe shanks are scaled down toward subcellular dimensions. In addition, flexible probes can mitigate shear stress-induced tissue damage due to micromotion. However, both size reduction and flexibility compromise probe's ability to penetrate the pia mater, especially when many electrodes are distributed across multiple probe shanks. In this paper, we present a method to lithographically pattern a biodegradable silk coating that provides temporary mechanical stiffness for the surgical insertion of flexible probes without any conventional design constraints on the probe size, shape, or material. After insertion, the silk is completely dissolved in the tissue, only leaving the flexible minimum-geometry probes inside the brain. We validated the design by successfully inserting silk-backed 64-channel parylene probes into the motor cortex of Long-Evans rats (n = 6) and recorded in vivo neural activity for six weeks.","Probes,
Electrodes,
Shape,
Coatings,
Fabrication,
In vivo,
Substrates"
Enhanced Dual-Band Ambient RF Energy Harvesting With Ultra-Wide Power Range,This letter presents a novel dual-band rectifier with extended power range (EPR) and an optimal incident RF power strategy in the settings where the available RF energy fluctuates considerably. It maintains high power conversion efficiency (PCE) in an ultra-wide input power range by adopting a pHEMT in the proposed topology. Simultaneous RF power incident mode is proposed and preferred to the traditional independent mode for multi-band harvesting. Measured results show that more than 30% PCE is obtained with input power ranging from -15 dBm to 20 dBm and peak PCE of 60% is maintained from 5 to 15 dBm. Positive power gain is achieved from -20 dBm to more than 10 dBm. Investigation about the effect of RF power incident ratio on dual-band harvesting's performance is presented and it provides a good reference for future multi-band harvesting system design.,
"Introducing SLAMBench, a performance and accuracy benchmarking methodology for SLAM","Real-time dense computer vision and SLAM offer great potential for a new level of scene modelling, tracking and real environmental interaction for many types of robot, but their high computational requirements mean that use on mass market embedded platforms is challenging. Meanwhile, trends in low-cost, low-power processing are towards massive parallelism and heterogeneity, making it difficult for robotics and vision researchers to implement their algorithms in a performance-portable way. In this paper we introduce SLAMBench, a publicly-available software framework which represents a starting point for quantitative, comparable and validatable experimental research to investigate trade-offs in performance, accuracy and energy consumption of a dense RGB-D SLAM system. SLAMBench provides a KinectFusion implementation in C++, OpenMP, OpenCL and CUDA, and harnesses the ICL-NUIM dataset of synthetic RGB-D sequences with trajectory and scene ground truth for reliable accuracy comparison of different implementation and algorithms. We present an analysis and breakdown of the constituent algorithmic elements of KinectFusion, and experimentally investigate their execution time on a variety of multicore and GPU-accelerated platforms. For a popular embedded platform, we also present an analysis of energy efficiency for different configuration alternatives.",
Crowdsourced live streaming over the cloud,"Empowered by today's rich tools for media generation and distribution, and the convenient Internet access, crowdsourced streaming generalizes the single-source streaming paradigm by including massive contributors for a video channel. It calls a joint optimization along the path from crowdsourcers, through streaming servers, to the end-users to minimize the overall latency. The dynamics of the video sources, together with the globalized request demands and the high computation demand from each sourcer, make crowdsourced live streaming challenging even with powerful support from modern cloud computing. In this paper, we present a generic framework that facilitates a cost-effective cloud service for crowdsourced live streaming. Through adaptively leasing, the cloud servers can be provisioned in a fine granularity to accommodate geo-distributed video crowdsourcers. We present an optimal solution to deal with service migration among cloud instances of diverse lease prices. It also addresses the location impact to the streaming quality. To understand the performance of the proposed strategies in the realworld, we have built a prototype system running over the planetlab and the Amazon/Microsoft Cloud. Our extensive experiments demonstrate that the effectiveness of our solution in terms of deployment cost and streaming quality.","Streaming media,
Servers,
Cloud computing,
Production,
Media,
Computers"
Rating Image Aesthetics Using Deep Learning,"This paper investigates unified feature learning and classifier training approaches for image aesthetics assessment . Existing methods built upon handcrafted or generic image features and developed machine learning and statistical modeling techniques utilizing training examples. We adopt a novel deep neural network approach to allow unified feature learning and classifier training to estimate image aesthetics. In particular, we develop a double-column deep convolutional neural network to support heterogeneous inputs, i.e., global and local views, in order to capture both global and local characteristics of images . In addition, we employ the style and semantic attributes of images to further boost the aesthetics categorization performance . Experimental results show that our approach produces significantly better results than the earlier reported results on the AVA dataset for both the generic image aesthetics and content -based image aesthetics. Moreover, we introduce a 1.5-million image dataset (IAD) for image aesthetics assessment and we further boost the performance on the AVA test set by training the proposed deep neural networks on the IAD dataset.","Neural networks,
Training,
Visualization,
Computer architecture,
Image color analysis,
Machine learning,
Semantics"
On the Cryptographic Hardness of Finding a Nash Equilibrium,"We prove that finding a Nash equilibrium of a game is hard, assuming the existence of indistinguishability obfuscation and one-way functions with sub-exponential hardness. We do so by showing how these cryptographic primitives give rise to a hard computational problem that lies in the complexity class PPAD, for which finding Nash equilibrium is complete. Previous proposals for basing PPAD-hardness on program obfuscation considered a strong ""virtual black-box"" notion that is subject to severe limitations and is unlikely to be realizable for the programs in question. In contrast, for indistinguishability obfuscation no such limitations are known, and recently, several candidate constructions of indistinguishability obfuscation were suggested based on different hardness assumptions on multilinear maps. Our result provides further evidence of the intractability of finding a Nash equilibrium, one that is extrinsic to the evidence presented so far.","Cryptography,
Nash equilibrium,
Computer science,
Games,
Complexity theory,
Search problems"
An Intelligent Economic Approach for Dynamic Resource Allocation in Cloud Services,"With Inter-Cloud, distributed cloud and open cloud exchange (OCX) emerging, a comprehensive resource allocation approach is fundamental to highly competitive cloud market. Oriented to infrastructure as a service (IaaS), an intelligent economic approach for dynamic resource allocation (IEDA) is proposed with the improved combinatorial double auction protocol devised to enable various kinds of resources traded among multiple consumers and multiple providers at the same time enable task partitioning among multiple providers. To make bidding and asking reasonable in each round of the auction and determine eligible transaction relationship among providers and consumers, a price formation mechanism is proposed, which is consisted of a back propagation neural network (BPNN) based price prediction algorithm and a price matching algorithm. A reputation system is proposed and integrated to exclude dishonest participants from the cloud market. The winner determination problem (WDP) is solved by the improved paddy field algorithm (PFA). Simulation results have shown that IEDA can not only help maximize market surplus and surplus strength but also encourage participants to be honest.","Resource management,
Artificial intelligence,
Cloud computing,
Biological system modeling,
Economics,
Dynamic scheduling,
Prediction algorithms"
Forest Data Collection Using Terrestrial Image-Based Point Clouds From a Handheld Camera Compared to Terrestrial and Personal Laser Scanning,"Stereo images have long been the main practical data source for the high-accuracy retrieval of 3-D information over large areas. However, stereoscopy has been surpassed by laser scanning (LS) techniques in recent years, particularly in forested areas, because the reflection of laser points from object surfaces directly provides 3-D geometric features and because the laser beam has good penetration capacity through forest canopies. In the last few years, image-based point clouds have become a more widely available data source because of advances in matching algorithms and computer hardware. This paper explores the possibility of using consumer cameras for forest field data collection and presents an application of terrestrial image-based point clouds derived from a handheld camera to forest plot inventories. In the experiment, the sample forest plot was photographed in a stop-and-go mode using different routes and camera settings. Five data sets were generated from photographs taken in the field, representing different photographic conditions. The stem detection accuracy ranged between 60% and 84%, and the root-mean-square errors of the estimated diameters at breast height were between 2.98 and 6.79 cm. The performance of image-based point clouds in forest data collection was compared with that of point clouds derived from two LS techniques, i.e., terrestrial LS (the professional level) and personal LS (an emerging technology). The study indicates that the construction of image-based point clouds of forest field data requires only low-cost, low-weight, and easy-to-use equipment and automated data processing. Photographic measurement is easy and relatively fast. The accuracy of tree attribute estimates is close to an acceptable level for forest field inventory but is lower than that achieved with the tested LS techniques.","Three-dimensional displays,
Vegetation,
Cameras,
Data collection,
Accuracy,
Laser beams,
Measurement by laser beam"
LASS: Local-Activity and Social-Similarity Based Data Forwarding in Mobile Social Networks,"This paper aims to design an efficient data forwarding scheme based on local activity and social similarity(LASS) for mobile social networks (MSNs). Various definitions of social similarity have been proposed as the criterion for relay selection, which results in various forwarding schemes. The appropriateness and practicality of various definitions determine the performances of these forwarding schemes. A popular definition has recently been proven to be more efficient than other existing ones, i.e., the more common interests between two nodes, the larger social similarity between them. In this work, we show that schemes based on such definition ignore the fact that members within the same community, i.e., with the same interest, usually have different levels of local activity, which will result in a low efficiency of data delivery. To address this, in this paper, we design a new data forwarding scheme for MSNs based on community detection in dynamic weighted networks, called Local-Activity and Social-Similarity, taking into account the difference of members' internal activity within each community, i.e., local activity. To the best of our knowledge, the proposed scheme is the first one that utilizes different levels of local activity within communities. Through extensive simulations, we demonstrate that LASS achieves better performance than state-of-the-art protocols.","Communities,
Local activities,
Heuristic algorithms,
Mobile communication,
Social network services,
Mobile computing,
Relays"
Feedback Error Learning Control of Magnetic Satellites Using Type-2 Fuzzy Neural Networks With Elliptic Membership Functions,"A novel type-2 fuzzy membership function (MF) in the form of an ellipse has recently been proposed in literature, the parameters of which that represent uncertainties are de-coupled from its parameters that determine the center and the support. This property has enabled the proposers to make an analytical comparison of the noise rejection capabilities of type-1 fuzzy logic systems with its type-2 counterparts. In this paper, a sliding mode control theory-based learning algorithm is proposed for an interval type-2 fuzzy logic system which benefits from elliptic type-2 fuzzy MFs. The learning is based on the feedback error learning method and not only the stability of the learning is proved but also the stability of the overall system is shown by adding an additional component to the control scheme to ensure robustness. In order to test the efficiency and efficacy of the proposed learning and the control algorithm, the trajectory tracking problem of a magnetic rigid spacecraft is studied. The simulations results show that the proposed control algorithm gives better performance results in terms of a smaller steady state error and a faster transient response as compared to conventional control algorithms.",
Multirobot Rendezvous Planning for Recharging in Persistent Tasks,"This paper addresses a multirobot scheduling problem in which autonomous unmanned aerial vehicles (UAVs) must be recharged during a long-term mission. The proposal is to introduce a separate team of dedicated charging robots that the UAVs can dock with in order to recharge. The goal is to schedule and plan minimum cost paths for charging robots such that they rendezvous with and replenish the UAVs, as needed, during the mission. The approach is to discretize the 3-D UAV flight trajectories into sets of projected charging points on the ground, thus allowing the problem to be abstracted onto a partitioned graph. Solutions consist of charging robot paths that collectively charge each of the UAVs. The problem is solved by first formulating the rendezvous planning problem to recharge each UAV once using both an integer linear program and a transformation to the Travelling Salesman Problem. The methods are then leveraged to plan recurring rendezvous' over longer horizons using fixed horizon and receding horizon strategies. Simulation results using realistic vehicle and battery models demonstrate the feasibility and robustness of the proposed approach.",
Autonomous Demand Response Using Stochastic Differential Games,"Demand response (DR) programs are implemented to encourage consumers to reduce their electricity demand when needed, e.g., at peak-load hours, by adjusting their controllable load. In this paper, our focus is on controllable load types that are associated with dynamic systems and can be modeled using differential equations. Examples of such load types include heating, ventilation, and air conditioning; water heating; and refrigeration. In this regard, we propose a new DR model based on a two-level differential game framework. At the beginning of each DR interval, the price is decided by the upper level (aggregator, utility, or market) given the total demand of users in the lower level. At the lower level, for each player (residential or commercial buildings that are equipped with automated load control systems and local renewable generators), given the price from the upper level, the electricity usage of air conditioning unit, and the battery storage charging/discharging schedules, are controlled in order to minimize the user's total electricity cost. The optimal user strategies are derived using the stochastic Hamilton-Jacobi-Bellman equations. We also show that the proposed game can converge to a feedback Nash equilibrium. Based on the effect of real-time pricing on users' daily demand profile, the simulation results demonstrate the properties of the proposed game and show how we can optimize consumers' electricity cost in the presence of time-varying prices.","Buildings,
Games,
Electricity,
Stochastic processes,
Batteries,
Mathematical model,
Optimization"
Colored Traveling Salesman Problem,"The multiple traveling salesman problem (MTSP) is an important combinatorial optimization problem. It has been widely and successfully applied to the practical cases in which multiple traveling individuals (salesmen) share the common workspace (city set). However, it cannot represent some application problems where multiple traveling individuals not only have their own exclusive tasks but also share a group of tasks with each other. This work proposes a new MTSP called colored traveling salesman problem (CTSP) for handling such cases. Two types of city groups are defined, i.e., each group of exclusive cities of a single color for a salesman to visit and a group of shared cities of multiple colors allowing all salesmen to visit. Evidences show that CTSP is NP-hard and a multidepot MTSP and multiple single traveling salesman problems are its special cases. We present a genetic algorithm (GA) with dual-chromosome coding for CTSP and analyze the corresponding solution space. Then, GA is improved by incorporating greedy, hill-climbing (HC), and simulated annealing (SA) operations to achieve better performance. By experiments, the limitation of the exact solution method is revealed and the performance of the presented GAs is compared. The results suggest that SAGA can achieve the best quality of solutions and HCGA should be the choice making good tradeoff between the solution quality and computing time.","Biological cells,
Genetic algorithms,
Sociology,
Statistics,
Encoding,
Traveling salesman problems"
Numerical Analysis of Radiative Recombination and Reabsorption in GaAs/Si Tandem,"We demonstrate a numerical analysis of the device impact of photon reabsorption on single-junction GaAs and tandem GaAs/Si solar cells. A self-consistent optical-electrical model that considers nonideal losses within the devices is developed. For single-junction devices, we find that the impact of photon recycling on the voltage increases monotonically with the injection level. For record-level GaAs solar cells, the voltage boost is 33 mV under open-circuit conditions and 13 mV at the maximum power point. For tandem GaAs/Si solar cells, photon reabsorption moderates the sensitivity of tandem efficiency to both obvious parameters like absorber thickness and implicit parameters like shunt resistance (Rsh) and bulk lifetime. Considering luminescent coupling results in a GaAs top cell that is 9.5% thicker than without luminescent coupling. The tandem device is 50% more sensitive to Rsh changes in the GaAs cell than Rsh changes in the Si cell. The impact of the GaAs top-cell bulk lifetime on tandem efficiency is reduced by 61% if photon reabsorption is not considered. This integrated optoelectronic device model allows one quantification of the implicit effects of photon recycling and luminescent coupling on device parameters for GaAs/Si tandem, providing a valuable tool for high-performance device optimization.","Gallium arsenide,
Silicon,
Photovoltaic cells,
Numerical models,
Radiative recombination,
Computer architecture"
Adaptive Personalized Diet Linguistic Recommendation Mechanism Based on Type-2 Fuzzy Sets and Genetic Fuzzy Markup Language,"Many different real-world applications with a high-level of uncertainty proved the good performance of the type-2 fuzzy sets (T2 FSs). Balanced diet means that the intake of each necessary nutrient meets its adequate demand and actual caloric intake balances with calories burned. Additionally, making a diversity of choice from various types of food is also essential to reduce the risk of developing various chronic diseases. Different people have a different goal and it is hard to measure how healthy the eaten meal is for those who are not the domain experts on the diet. This paper presents an adaptive personalized diet linguistic recommendation mechanism based on type-2 fuzzy logic system (T2 FLS) and genetic fuzzy markup language (GFML). First, an adaptive dietary assessment and recommendation ontology is constructed by domain experts, and then a T2 FS-based GFML, describing the fuzzy knowledge base and the fuzzy rule base of the proposed mechanism, is evolved by using genetic algorithms. Next, a T2 FS-based fuzzy inference mechanism infers the result of the dietary health level based on the evolved type-2 GFML (T2GFML). In addition, the balanced computation mechanism is also proposed to reduce the computational complexity of the T2 FLS for the diet domain knowledge. Finally, the linguistic knowledge discovery mechanism presents the discovered linguistic meaning about the meal's health level to show the involved subjects how to make a personalized diet linguistic recommendation. This type of information about the eaten meal can provide the subjects with a reference to gradually improve their unhealthy eating habit and then become healthier and healthier. Experimental results show that the results of the proposed mechanism for the T2 FLS are better than those for the type-1 fuzzy logic system (T1 FLS).",
On the Optimality of Treating Interference as Noise: General Message Sets,"In a K-user Gaussian interference channel, it has been shown that if for each user the desired signal strength is no less than the sum of the strengths of the strongest interference from this user and the strongest interference to this user (all values in decibel scale), then treating interference as noise (TIN) is optimal from the perspective of generalized degrees of freedom (GDoF) and achieves the entire channel capacity region to within a constant gap. In this paper, we show that for such TINoptimal interference channels, even if the message set is expanded to include an independent message from each transmitter to each receiver, operating the new channel as the original interference channel and treating interference as noise is still optimal for the sum capacity up to a constant gap. Furthermore, we extend the result to the sum-GDoF optimality of TIN in the general setting of X channels with arbitrary numbers of transmitters and receivers.","Receivers,
Transmitters,
Interference channels,
Tin,
Noise,
Channel capacity"
20.4 A 123-phase DC-DC converter-ring with fast-DVS for microprocessors,"Inspired by The Square of Vatican City, a fully integrated step-down switched-capacitor DC-DC converter ring with 100+ phases is designed with a fast dynamic voltage scaling (DVS) feature for the microprocessor in portable or wearable devices. As shown in Fig. 20.4.1, this symmetrical ring-shaped converter surrounds its load in the square and supplies the on-chip power grid, such that a good quality power supply can be easily accessed at any point of the chip edges. There are 30 phases on the top edge and 31 phases on each of the other 3 edges, making 123 phases in total. The phase number and unit cell dimensions of this architecture can easily be adjusted to fit the floor plan of the load. The pads of the converter-ring are placed at the corners, and will not affect the pads of the load. Moreover, by using the proposed VDD-controlled oscillator (VDDCO), the frequency of which is controlled by varying its supply voltage, a hitherto unexplored feature of the multiphase DC-DC architecture is exposed: the control-loop unity gain frequency (UGF) could be designed to be higher than the switching frequency.","Regulators,
Microprocessors,
Voltage control,
Computer architecture,
Solid state circuits,
Transient analysis"
Controllable Surface Haptics via Particle Jamming and Pneumatics,"The combination of particle jamming and pneumatics allows the simultaneous control of shape and mechanical properties in a tactile display. A hollow silicone membrane is molded into an array of thin cells, each filled with coffee grounds such that adjusting the vacuum level in any individual cell rapidly switches it between flexible and rigid states. The array clamps over a pressure-regulated air chamber with internal mechanisms designed to pin the nodes between cells at any given height. Various sequences of cell vacuuming, node pinning, and chamber pressurization allow the surface to balloon into a variety of shapes. Experiments were performed to expand existing physical models of jamming at the inter-particle level to define the rheological characteristics of jammed systems from a macroscopic perspective, relevant to force-displacement interactions that would be experienced by human users. Force-displacement data show that a jammed cell in compression fits a Maxwell model and a cell deflected in the center while supported only at the edges fits a Zener model, each with stiffness and damping parameters that increase at higher levels of applied vacuum. This provides framework to tune and control the mechanical properties of a jamming haptic interface.",
Reducing energy consumption by dynamic resource allocation in C-RAN,"Cloud Radio Access Network (C-RAN) architecture has been proposed as a promising solution to overcome the challenges of Next Generation (5G) cellular networks, in terms of efficiency, capacity, scalability, flexibility and sustainability in a cost-effective and power efficient way. However C-RAN demands a new energy consumption model and its resources optimised. This Paper presented the C-RAN to reduce the network cost further by dynamically allocating centralised Base Band Unit (BBU) resources to Remote Radio Heads (RRHs) depending on the traffic conditions. New energy consumption model for C-RAN has been proposed for capturing the energy consumption of centralised BBU resources which reflect the dynamic allocation of RRHs. An algorithm that optimises the BBU resource allocation has been proposed. BBUs are put to sleep and active states by switching them `OFF' and `ON' respectively according to their resource usage. Numerical results based on simulation settings validated the theoretical analyses and revealed more than 70% power reduction compared to conventional RAN under the EARTH power model.","Power demand,
Computer architecture,
Resource management,
Analytical models,
Energy consumption,
Mobile communication,
Switches"
Greening Geographical Load Balancing,"Energy expenditure has become a significant fraction of data center operating costs. Recently, “geographical load balancing” has been proposed to reduce energy cost by exploiting the electricity price differences across regions. However, this reduction of cost can paradoxically increase total energy use. We explore whether the geographical diversity of Internet-scale systems can also provide environmental gains. Specifically, we explore whether geographical load balancing can encourage use of “green” renewable energy and reduce use of “brown” fossil fuel energy. We make two contributions. First, we derive three distributed algorithms for achieving optimal geographical load balancing. Second, we show that if the price of electricity is proportional to the instantaneous fraction of the total energy that is brown, then geographical load balancing significantly reduces brown energy use. However, the benefits depend strongly on dynamic energy pricing and the form of pricing used.",
Delay-Sensitive Opportunistic Routing for Underwater Sensor Networks,"Acoustic transmission, inherent to aquatic environments and used in underwater sensor networks (UWSNs), presents its own challenges in terms of energy consumption, long propagation delay, and available bandwidth. These UWSN challenges make it difficult to directly adapt ideas which have already been proven reliable in open-air networks. End-to-end latency is one of the key elements for delay-sensitive UWSN applications. In this paper, we apply the idea of opportunistic-based routing (OR) for maximizing goodput while meeting end-to-end latency requirements for delay-sensitive UWSN applications. In doing so, we introduce a new metric called EEL|success(Fi), which is the expected end-to-end latency from node i to the destination when at least one forwarder of Fi successfully receives a packet; we then formulate this UWSN OR routing problem as a nonlinear optimization model. To effectively solve this problem, we propose a two-step heuristic algorithm, which is composed of per-node forwarding set determination and packet forwarding prioritization. The results of a performance study show that our scheme outperforms other existing works in terms of network goodput and energy costs.","Routing,
Relays,
Sensors,
Propagation delay,
Reliability,
Delays"
WicLoc: An indoor localization system based on WiFi fingerprints and crowdsourcing,"WiFi fingerprint-based indoor localization techniques have been proposed and widely used in recent years. Most solutions need a site survey to collect fingerprints from interested locations to construct the fingerprint database. However, the site survey is labor-intensive and time-consuming. To overcome this shortcoming, we record user motions as well as WiFi signals without the active participation of the users to construct the fingerprint database, in place of the previous site survey. In this paper, we develop an indoor localization system called WicLoc, which is based on WiFi fingerprinting and crowdsourcing. We design a fingerprint model to form fingerprints of each location of interest after fingerprint collection. We propose a weighted KNN (K-Nearest Neighbor) algorithm to assign different weights to APs and achieve room-level localization. To obtain the absolute coordinate of users, we design a novel MDS (Multi-Dimensional Scaling) algorithm called MDS-C (Multi-Dimensional Scaling with Calibrations) to calculate coordinates of interested locations in the corridor and rooms, where anchor points are used to calibrate absolute coordinates of users. Experimental results show that our system can achieve a competitive localization accuracy compared with state-of-the-art WiFi fingerprint-based methods while avoiding the labor-intensive site survey.","IEEE 802.11 Standard,
Accuracy,
Training,
Databases,
Fingerprint recognition,
Testing,
Correlation"
Learning Visual Semantic Relationships for Efficient Visual Retrieval,"In this paper, we investigate how to establish the relationship between semantic concepts based on the large-scale realworld click data from image commercial engine, which is a challenging topic because the click data suffers from the noise such as typos, the same concept with different queries, etc. We first define five specific relationships between concepts. We then extract some concept relationship features in textual and visual domain to train the concept relationship models. The relationship of each pair of concepts will thus be classified into one of the five special relationships. We study the efficacy of the conceptual relationships by applying them to augment imperfect image tags, i.e., improve representative power. We further employ a sophisticated hashing approach to transform augmented image tags into binary codes, which are subsequently used for content-based image retrieval task. Experimental results on NUS-WIDE dataset demonstrate the superiority of our proposed approach as compared to state-of-the-art methods.","Visualization,
Semantics,
Feature extraction,
Image retrieval,
Binary codes"
Modeling and Stability Analysis of Automatic Generation Control Over Cognitive Radio Networks in Smart Grids,"Due to its great potential to improve the overall performance of data transmission with its dynamic and adaptive spectrum allocation capability in comparison with many other networking technologies, cognitive radio (CR) networking technology has been increasingly employed in networking and communication infrastructures for smart grids. However, a secondary user (SU) of a CR network has to be squeezed out from a channel when a primary user reclaims the channel, which may occur in a randomized fashion. The random interruption of SU traffic may cause packet losses and delays for SU data, and it will in turn affect the stability of the monitoring and control of smart grids. In this paper, we address this problem and investigate the modeling and stability analysis of the automatic generation control (AGC) of a smart grid for which CR networks are used as the infrastructure for the aggregation and communication of both system-wide information and local measurement data. For this purpose, a randomly switched power system model is proposed for the AGC of the smart grid. By modeling the CR network as an On-Off switch with sojourn times, the stability of the AGC of the smart grid is analyzed. In particular, we investigate the smart grid with two main types of CR networks: 1) the sojourn times are arbitrary but bounded and 2) the sojourn times follow an independent and identical distribution process. The sufficient conditions are obtained for the stability of the AGC of the smart grid with these two CR networks, respectively. Simulation results show the effects of the CR networks on the dynamic performance of the AGC of the smart grid and illustrate the usefulness of the developed sufficient conditions in the design of CR networks in order to ensure the stability of the AGC of the smart grid.","Smart grids,
Power system stability,
Automatic generation control,
Stability analysis,
Power system dynamics,
Asymptotic stability,
Analytical models"
Self-Triggered Communication Enabled Control of Distributed Generation in Microgrids,"Efficient utilization of distributed generation (DG) resources in a microgrid requires coordinated control, which can be realized using multiagent-based system model. The coordinated control requires information exchange among the distributed agents, which can be implemented using either periodic or need-based aperiodic data transmission. For reducing the data communication requirements among the agents, an aperiodic self-triggered communication-based coordinated control is proposed. Centralized as well as distributed self-triggered coordinated control is implemented. The performance evaluation results show that self-triggered aperiodic communication requires lower data rates, while delivering the same performance as that of periodic sampled data control.","Microgrids,
Reactive power,
Distributed power generation,
Data communication,
Power control,
Informatics,
Information exchange"
White-Box Traceable Ciphertext-Policy Attribute-Based Encryption Supporting Flexible Attributes,"Ciphertext-policy attribute-based encryption (CP-ABE) enables fine-grained access control to the encrypted data for commercial applications. There has been significant progress in CP-ABE over the recent years because of two properties called traceability and large universe, greatly enriching the commercial applications of CP-ABE. Traceability is the ability of ABE to trace the malicious users or traitors who intentionally leak the partial or modified decryption keys for profits. Nevertheless, due to the nature of CP-ABE, it is difficult to identify the original key owner from an exposed key since the decryption privilege is shared by multiple users who have the same attributes. On the other hand, the property of large universe in ABE enlarges the practical applications by supporting flexible number of attributes. Several systems have been proposed to obtain either of the above properties. However, none of them achieve the two properties simultaneously in practice, which limits the commercial applications of CP-ABE to a certain extent. In this paper, we propose two practical large universe CP-ABE systems supporting white-box traceability. Compared with existing systems, both the two proposed systems have two advantages: 1) the number of attributes is not polynomially bounded and 2) malicious users who leak their decryption keys could be traced. Moreover, another remarkable advantage of the second proposed system is that the storage overhead for traitor tracing is constant, which are suitable for commercial applications.","Encryption,
Games,
TV,
Educational institutions,
Polynomials"
The PennBMBI: Design of a General Purpose Wireless Brain-Machine-Brain Interface System,"In this paper, a general purpose wireless Brain- Machine -Brain Interface (BMBI) system is presented. The system integrates four battery-powered wireless devices for the implementation of a closed-loop sensorimotor neural interface, including a neural signal analyzer, a neural stimulator, a body-area sensor node and a graphic user interface implemented on the PC end. The neural signal analyzer features a four channel analog front-end with configurable bandpass filter, gain stage, digitization resolution, and sampling rate. The target frequency band is configurable from EEG to single unit activity. A noise floor of 4.69 μVrms is achieved over a bandwidth from 0.05 Hz to 6 kHz . Digital filtering, neural feature extraction, spike detection, sensing-stimulating modulation, and compressed sensing measurement are realized in a central processing unit integrated in the analyzer. A flash memory card is also integrated in the analyzer. A 2-channel neural stimulator with a compliance voltage up to ±12 V is included. The stimulator is capable of delivering unipolar or bipolar, charge-balanced current pulses with programmable pulse shape, amplitude, width, pulse train frequency and latency. A multi-functional sensor node, including an accelerometer, a temperature sensor, a flexiforce sensor and a general sensor extension port has been designed. A computer interface is designed to monitor, control and configure all aforementioned devices via a wireless link, according to a custom designed communication protocol. Wireless closed-loop operation between the sensory devices, neural stimulator, and neural signal analyzer can be configured. The proposed system was designed to link two sites in the brain, bridging the brain and external hardware, as well as creating new sensory and motor pathways for clinical practice. Bench test and in vivo experiments are performed to verify the functions and performances of the system.",
Secrecy Capacity Optimization via Cooperative Relaying and Jamming for WANETs,"Cooperative wireless networking, which is promising in improving the system operation efficiency and reliability by acquiring more accurate and timely information, has attracted considerable attentions to support many services in practice. However, the problem of secure cooperative communication has not been well investigated yet. In this paper, we exploit physical layer security to provide secure cooperative communication for wireless ad hoc networks (WANETs) where involve multiple source-destination pairs and malicious eavesdroppers. By characterizing the security performance of the system by secrecy capacity, we study the secrecy capacity optimization problem in which security enhancement is achieved via cooperative relaying and cooperative jamming. Specifically, we propose a system model where a set of relay nodes can be exploited by multiple source-destination pairs to achieve physical layer security. We theoretically present a corresponding formulation for the relay assignment problem and develop an optimal algorithm to solve it in polynomial time. To further increase the system secrecy capacity, we exploit the cooperative jamming technique and propose a smart jamming algorithm to interfere the eavesdropping channels. Through extensive experiments, we validate that our proposed algorithms significantly increase the system secrecy capacity under various network settings.",
Heterogeneous Cloud Framework for Big Data Genome Sequencing,"The next generation genome sequencing problem with short (long) reads is an emerging field in numerous scientific and big data research domains. However, data sizes and ease of access for scientific researchers are growing and most current methodologies rely on one acceleration approach and so cannot meet the requirements imposed by explosive data scales and complexities. In this paper, we propose a novel FPGA-based acceleration solution with MapReduce framework on multiple hardware accelerators. The combination of hardware acceleration and MapReduce execution flow could greatly accelerate the task of aligning short length reads to a known reference genome. To evaluate the performance and other metrics, we conducted a theoretical speedup analysis on a MapReduce programming platform, which demonstrates that our proposed architecture have efficient potential to improve the speedup for large scale genome sequencing applications. Also, as a practical study, we have built a hardware prototype on the real Xilinx FPGA chip. Significant metrics on speedup, sensitivity, mapping quality, error rate, and hardware cost are evaluated, respectively. Experimental results demonstrate that the proposed platform could efficiently accelerate the next generation sequencing problem with satisfactory accuracy and acceptable hardware cost.",
Scaling Social Media Applications Into Geo-Distributed Clouds,"Federation of geo-distributed cloud services is a trend in cloud computing that, by spanning multiple data centers at different geographical locations, can provide a cloud platform with much larger capacities. Such a geo-distributed cloud is ideal for supporting large-scale social media applications with dynamic contents and demands. Although promising, its realization presents challenges on how to efficiently store and migrate contents among different cloud sites and how to distribute user requests to the appropriate sites for timely responses at modest costs. These challenges escalate when we consider the persistently increasing contents and volatile user behaviors in a social media application. By exploiting social influences among users, this paper proposes efficient proactive algorithms for dynamic, optimal scaling of a social media application in a geo-distributed cloud. Our key contribution is an online content migration and request distribution algorithm with the following features: 1) future demand prediction by novelly characterizing social influences among the users in a simple but effective epidemic model; 2) one-shot optimal content migration and request distribution based on efficient optimization algorithms to address the predicted demand; and 3) a Δ(t)-step look-ahead mechanism to adjust the one-shot optimization results toward the offline optimum. We verify the effectiveness of our online algorithm by solid theoretical analysis, as well as thorough comparisons to ready algorithms including the ideal offline optimum, using large-scale experiments with dynamic realistic settings on Amazon Elastic Compute Cloud (EC2).",
Robust Histogram Shape-Based Method for Image Watermarking,"Cropping and random bending are two common attacks in image watermarking. In this paper we propose a novel image-watermarking method to deal with these attacks, as well as other common attacks. In the embedding process, we first preprocess the host image by a Gaussian low-pass filter. Then, a secret key is used to randomly select a number of gray levels and the histogram of the filtered image with respect to these selected gray levels is constructed. After that, a histogram-shape-related index is introduced to choose the pixel groups with the highest number of pixels and a safe band is built between the chosen and nonchosen pixel groups. A watermark-embedding scheme is proposed to insert watermarks into the chosen pixel groups. The usage of the histogram-shape-related index and safe band results in good robustness. Moreover, a novel high-frequency component modification mechanism is also utilized in the embedding scheme to further improve robustness. At the decoding end, based on the available secret key, the watermarked pixel groups are identified and watermarks are extracted from them. The effectiveness of the proposed image-watermarking method is demonstrated by simulation examples.","Watermarking,
Histograms,
Robustness,
Decoding,
Shape,
Signal processing,
Indexes"
VeriTrust: Verification for Hardware Trust,"Today's integrated circuit designs are vulnerable to a wide range of malicious alterations, namely hardware Trojans (HTs). HTs serve as backdoors to subvert or augment the normal operation of infected devices, which may lead to functionality changes, sensitive information leakages, or denial of service attacks. To tackle such threats, this paper proposes a novel verification technique for hardware trust, namely VeriTrust, which facilitates to detect HTs inserted at design stage. Based on the observation that HTs are usually activated by dedicated trigger inputs that are not sensitized with verification test cases, VeriTrust automatically identifies such potential HT trigger inputs by examining verification corners. The key difference between VeriTrust and existing HT detection techniques based on “unused circuit identification” is that VeriTrust is insensitive to the implementation style of HTs. Experimental results show that VeriTrust is able to detect all HTs evaluated in this paper (constructed based on various HT design methodologies shown in this paper) at the cost of moderate extra verification time.","Hardware,
Frequency modulation,
Measurement,
Integrated circuit modeling,
Design methodology,
Hardware design languages"
Partially Shared Latent Factor Learning With Multiview Data,"Multiview representations reveal the fundamental attributes of the studied instances from different perspectives. Some common perspectives are reviewed by multiple views simultaneously, while some specific ones are reflected by individual views. That is, there are two kinds of properties embedded in the multiview data: 1) consistency and 2) complementarity. Different from most multiview learning approaches only focusing on either consistency or complementarity, this paper proposes a novel semisupervised multiview learning algorithm, called partially shared latent factor (PSLF) learning, which jointly exploits both consistent and complementary information among multiple views. In PSLF, a nonnegative matrix factorization (NMF)-based formulation is adopted to learn a compact and comprehensive partially shared latent representation, which is composed of common latent factors shared by multiple views and some specific latent factors to each view. With the learned representations of multiview data, we introduce a robust sparse regression model to predict the cluster labels of labeled data. By integrating the NMF-based model and the regression model, we obtain a unified formulation and propose a multiplicative-based alternative algorithm for optimization. In addition, PSLF can learn the weights of different views adaptively according to the reconstruction precisions of data matrices. Our experimental study indicates different multiview data that contains consistent and complementary information in different degrees. In addition, the encouraging results of the proposed algorithm are achieved in comparison with the state-of-the-art algorithms on real-world data sets.","Clustering algorithms,
Optimization,
Linear programming,
Sparse matrices,
Semisupervised learning,
Robustness"
Learning-Based Joint Super-Resolution and Deblocking for a Highly Compressed Image,"A highly compressed image is usually not only of low resolution, but also suffers from compression artifacts (blocking artifact is treated as an example in this paper). Directly performing image super-resolution (SR) to a highly compressed image would also simultaneously magnify the blocking artifacts, resulting in an unpleasing visual experience. In this paper, we propose a novel learning-based framework to achieve joint single-image SR and deblocking for a highly-compressed image. We argue that individually performing deblocking and SR (i.e., deblocking followed by SR, or SR followed by deblocking) on a highly compressed image usually cannot achieve a satisfactory visual quality. In our method, we propose to learn image sparse representations for modeling the relationship between low- and high-resolution image patches in terms of the learned dictionaries for image patches with and without blocking artifacts, respectively . As a result, image SR and deblocking can be simultaneously achieved via sparse representation and morphological component analysis (MCA)-based image decomposition. Experimental results demonstrate the efficacy of the proposed algorithm.",
Projection Operators and Moment Invariants to Image Blurring,"In this paper we introduce a new theory of blur invariants. Blur invariants are image features which preserve their values if the image is convolved by a point-spread function (PSF) of a certain class. We present the invariants to convolution with an arbitrary N-fold symmetric PSF, both in Fourier and image domain. We introduce a notion of a primordial image as a canonical form of all blur-equivalent images. It is defined in spectral domain by means of projection operators. We prove that the moments of the primordial image are invariant to blur and we derive recursive formulae for their direct computation without actually constructing the primordial image. We further prove they form a complete set of invariants and show how to extent their invariance also to translation, rotation and scaling. We illustrate by simulated and real-data experiments their invariance and recognition power. Potential applications of this method are wherever one wants to recognize objects on blurred images.","Tin,
Convolution,
Apertures,
Fourier transforms,
Image recognition,
Cameras,
Face recognition"
Parallel Implementation of MAFFT on CUDA-Enabled Graphics Hardware,"Multiple sequence alignment (MSA) constitutes an extremely powerful tool for many biological applications including phylogenetic tree estimation, secondary structure prediction, and critical residue identification. However, aligning large biological sequences with popular tools such as MAFFT requires long runtimes on sequential architectures. Due to the ever increasing sizes of sequence databases, there is increasing demand to accelerate this task. In this paper, we demonstrate how graphic processing units (GPUs), powered by the compute unified device architecture (CUDA), can be used as an efficient computational platform to accelerate the MAFFT algorithm. To fully exploit the GPU's capabilities for accelerating MAFFT, we have optimized the sequence data organization to eliminate the bandwidth bottleneck of memory access, designed a memory allocation and reuse strategy to make full use of limited memory of GPUs, proposed a new modified-run-length encoding (MRLE) scheme to reduce memory consumption, and used high-performance shared memory to speed up I/O operations. Our implementation tested in three NVIDIA GPUs achieves speedup up to 11.28 on a Tesla K20m GPU compared to the sequential MAFFT 7.015.","Graphics processing units,
Instruction sets,
Bioinformatics,
Computational biology,
Algorithm design and analysis"
Affordance detection of tool parts from geometric features,"As robots begin to collaborate with humans in everyday workspaces, they will need to understand the functions of tools and their parts. To cut an apple or hammer a nail, robots need to not just know the tool's name, but they must localize the tool's parts and identify their functions. Intuitively, the geometry of a part is closely related to its possible functions, or its affordances. Therefore, we propose two approaches for learning affordances from local shape and geometry primitives: 1) superpixel based hierarchical matching pursuit (S-HMP); and 2) structured random forests (SRF). Moreover, since a part can be used in many ways, we introduce a large RGB-Depth dataset where tool parts are labeled with multiple affordances and their relative rankings. With ranked affordances, we evaluate the proposed methods on 3 cluttered scenes and over 105 kitchen, workshop and garden tools, using ranked correlation and a weighted F-measure score [26]. Experimental results over sequences containing clutter, occlusions, and viewpoint changes show that the approaches return precise predictions that could be used by a robot. S-HMP achieves high accuracy but at a significant computational cost, while SRF provides slightly less accurate predictions but in real-time. Finally, we validate the effectiveness of our approaches on the Cornell Grasping Dataset [25] for detecting graspable regions, and achieve state-of-the-art performance.","Robots,
Feature extraction,
Shape,
Image segmentation,
Three-dimensional displays,
Geometry,
Conferences"
Simulation Study of a 3-D Device Integrating FinFET and UTBFET,"By integrating 3-D nonplanar fins and 2-D ultrathin bodies, wavy FinFETs merge two formerly competing technologies on a silicon-on-insulator platform to deliver enhanced transistor performance compared with conventional trigate FinFETs with unprecedented levels of chip-area efficiency. This makes it suitable for ultralarge-scale integration high-performance logic at and beyond the 10-nm technology node.","FinFETs,
Logic gates,
Educational institutions,
Solid modeling,
Performance evaluation"
Power Delivery and Leakage Field Control Using an Adaptive Phased Array Wireless Power System,"Efficient wireless power transfer and precise control of power delivery and leakage field strength can be achieved using a phased array wireless power transfer system. This has particular importance for charging multiple devices simultaneously, or charging devices in environments where humans or foreign objects will be in close proximity. The phased array wireless power system consists of two or more phase-synchronized power amplifiers each driving a respective transmit coil. The system can maximize power delivery to an intended receiver in one location while simultaneously minimizing power delivery and leakage fields in other locations. These functions are possible by varying the amplitude and phase of each transmitter. This paper provides an analysis of a phased array wireless power transfer system using near-field magnetically coupled resonators, and derives parameters that can be used to automatically determine the optimal magnitude and phase of each transmitter to deliver power to one or more receivers. Experimental results verify the theoretical analysis and additional features of the full system are demonstrated.","Coils,
Transmitters,
Couplings,
Arrays,
Wireless communication,
Receivers,
Tuning"
Answering why-not questions on spatial keyword top-k queries,"Large volumes of geo-tagged text objects are available on the web. Spatial keyword top-k queries retrieve k such objects with the best score according to a ranking function that takes into account a query location and query keywords. In this setting, users may wonder why some known object is unexpectedly missing from a result; and understanding why may aid users in retrieving better results. While spatial keyword querying has been studied intensively, no proposals exist for how to offer users explanations of why such expected objects are missing from results. We provide techniques that allow the revision of spatial keyword queries such that their results include one or more desired, but missing objects. In doing so, we adopt a query refinement approach to provide a basic algorithm that reduces the problem to a two-dimensional geometrical problem. To improve performance, we propose an index-based ranking estimation algorithm that prunes candidate results early. Extensive experimental results offer insight into design properties of the proposed techniques and suggest that they are efficient in terms of both running time and I/O cost.","Indexes,
Query processing,
Algorithm design and analysis,
Estimation,
Object recognition,
Spatial databases"
Visual Navigation Using Heterogeneous Landmarks and Unsupervised Geometric Constraints,"We present a heterogeneous landmark-based visual navigation approach for a monocular mobile robot. We utilize heterogeneous visual features, such as points, line segments, lines, planes, and vanishing points, and their inner geometric constraints managed by a novel multilayer feature graph (MFG). Our method extends the local bundle adjustment-based visual simultaneous localization and mapping (SLAM) framework by explicitly exploiting the heterogeneous features and their inner geometric relationships in an unsupervised manner. As the result, our heterogeneous landmark-based visual navigation algorithm takes a video stream as input, initializes and iteratively updates MFG based on extracted key frames, and refines robot localization and MFG landmarks through the process. We present pseudocode for the algorithm and analyze its complexity. We have evaluated our method and compared it with state-of-the-art point landmark-based visual SLAM methods using multiple indoor and outdoor datasets. In particular, on the KITTI dataset, our method reduces the translational error by 52.5% under urban sequences where rectilinear structures dominate the scene.",
Learning a non-linear knowledge transfer model for cross-view action recognition,"This paper concerns action recognition from unseen and unknown views. We propose unsupervised learning of a non-linear model that transfers knowledge from multiple views to a canonical view. The proposed Non-linear Knowledge Transfer Model (NKTM) is a deep network, with weight decay and sparsity constraints, which finds a shared high-level virtual path from videos captured from different unknown viewpoints to the same canonical view. The strength of our technique is that we learn a single NKTM for all actions and all camera viewing directions. Thus, NKTM does not require action labels during learning and knowledge of the camera viewpoints during training or testing. NKTM is learned once only from dense trajectories of synthetic points fitted to mocap data and then applied to real video data. Trajectories are coded with a general codebook learned from the same mocap data. NKTM is scalable to new action classes and training data as it does not require re-learning. Experiments on the IXMAS and N-UCLA datasets show that NKTM outperforms existing state-of-the-art methods for cross-view action recognition.","Computational modeling,
Training"
Cooperative Coevolutionary Algorithm-Based Model Predictive Control Guaranteeing Stability of Multirobot Formation,"This paper proposes a novel cooperative coevolutionary algorithm (CCEA)-based distributed model predictive control (MPC) that guarantees asymptotic stability of multiagent systems whose state vectors are coupled and nonseparable in a cost function. While conventional evolutionary algorithm-based MPC approaches cannot guarantee stability, the proposed CCEA-based MPC approach guarantees asymptotic stability regardless of the optimality of the solution that the CCEA-based algorithm generates with a small number of individuals. To guarantee stability, a terminal state constraint is found, and then a repair algorithm is applied to all candidate solutions to meet the constraint. Furthermore, as the proposed CCEA-based algorithm finds the Nash-equilibrium state in a distributed way, robots can quickly move into a desired formation from their locations. A novel dynamic cooperatively coevolving particle swarm optimization (CCPSO), dynamic CCPSO (dCCPSO) in short, is proposed to deal with the formation control problem based on the conventional CCPSO, which was the most recently developed algorithm among CCEAs. Numerical simulations and experimental results demonstrate that the CCEA-based MPC greatly improves the performance of multirobot formation control compared with conventional particle swarm optimization-based MPC.","Robots,
Nash equilibrium,
Asymptotic stability,
Cost function,
Stability analysis,
Prediction algorithms"
Spherical Hashing: Binary Code Embedding with Hyperspheres,"Many binary code embedding schemes have been actively studied recently, since they can provide efficient similarity search, and compact data representations suitable for handling large scale image databases. Existing binary code embedding techniques encode high-dimensional data by using hyperplane-based hashing functions. In this paper we propose a novel hypersphere-based hashing function, spherical hashing, to map more spatially coherent data points into a binary code compared to hyperplane-based hashing functions. We also propose a new binary code distance function, spherical Hamming distance, tailored for our hypersphere-based binary coding scheme, and design an efficient iterative optimization process to achieve both balanced partitioning for each hash function and independence between hashing functions. Furthermore, we generalize spherical hashing to support various similarity measures defined by kernel functions. Our extensive experiments show that our spherical hashing technique significantly outperforms state-of-the-art techniques based on hyperplanes across various benchmarks with sizes ranging from one to 75 million of GIST, BoW and VLAD descriptors. The performance gains are consistent and large, up to 100 percent improvements over the second best method among tested methods. These results confirm the unique merits of using hyperspheres to encode proximity regions in high-dimensional spaces. Finally, our method is intuitive and easy to implement.",
Energy Consumption Optimization for Multihop Cognitive Cellular Networks,"Cellular networks are faced with serious congestions nowadays due to the recent booming growth and popularity of wireless devices and applications. Opportunistically accessing the unused licensed spectrum, cognitive radio can potentially harvest more spectrum resources and enhance the capacity of cellular networks. In this paper, we propose a new multihop cognitive cellular network (MC2N) architecture to facilitate the ever exploding data transmissions in cellular networks. Under the proposed architecture, we then investigate the minimum energy consumption problem by exploring joint frequency allocation, link scheduling, routing, and transmission power control. Specifically, we first formulate a maximum independent set (MIS) based energy consumption optimization problem, which is a non-linear programming problem. Different from most previous work assuming all the MISs are known, finding which is in fact NP-complete, we employ a column generation based approach to circumvent this problem. We develop an ϵ-bounded algorithm, which can obtain a feasible solution that are less than (1 + ϵ) and larger than (1 - ϵ) of the optimal result of MP, and analyzed its computational complexity. We also revisit the minimum energy consumption problem by taking uncertain channel bandwidth into consideration. Simulation results show that we can efficiently find ϵ-bounded approximate results and the optimal result as well.",
Service provider competition and cooperation in cloud-based software defined wireless networks,"Software-defined wireless networking (SDWN) is an emerging paradigm in the era of the Internet of Things. In cloud-based SDWNs, resource management is seperated from the geo-distributed cloud, forming a virtual network topology in the control plane. Thus, a centralized software program is able to control and program the behavior of the entire network. In this article, we focus on resource management in cloud-based SDWNs, and discuss the competition and cooperation between cloud service providers. We present a Nash bargaining game approach to process the resource trading activity among cloud service providers in cloud-based SDWNs. Utility functions have been specifically considered to incorporate operation cost and resource utilization. Illustrative results indicate that cooperation is able to generate more benefits than competition. Moreover, resource sharing among cloud service providers has great significance in efficiently utilizing limited resources and improving quality of service.","Cloud computing,
Resource management,
Wireless networks,
Game theory,
Quality of service,
Computer architecture,
Software defined networking"
AppATP: An Energy Conserving Adaptive Mobile-Cloud Transmission Protocol,"Many mobile applications require frequent wireless transmissions between the content provider and mobile devices, consuming much energy in mobile devices. Motivated by the popularity of prefetch-friendly or delay-tolerant apps (e.g., social networking, app updates, cloud storage), we design and implement an application-layer transmission protocol, AppATP, which leverages cloud computing to manage data transmissions for mobile apps, transferring data to and from mobile devices in an energy efficient manner. Measurements show that significantly amount of energy is consumed by mobile devices during poor connectivity. Based on this observation, AppATP adaptively seizes periods of good bandwidth condition to prefetch frequently used data with minimum energy consumption, while deferring delay-tolerant data during poor network connectivity. Using the stochastic control framework, AppATP only relies on the current network information and data queue sizes to make an online decision on transmission scheduling, and performs well under unpredictable wireless network conditions. We implement AppATP on Samsung Note 2 smartphones and Amazon EC2. Results from both trace-driven simulations and extensive real-world experiments show that AppATP can be applied to a variety of application scenarios while achieving 30-50 percent energy savings for mobile devices.","Mobile handsets,
Bandwidth,
Mobile communication,
Energy consumption,
IEEE 802.11 Standards,
Prefetching,
Data communication"
Automated Health Alerts Using In-Home Sensor Data for Embedded Health Assessment,"We present an example of unobtrusive, continuous monitoring in the home for the purpose of assessing early health changes. Sensors embedded in the environment capture behavior and activity patterns. Changes in patterns are detected as potential signs of changing health. We first present results of a preliminary study investigating 22 features extracted from in-home sensor data. A 1-D alert algorithm was then implemented to generate health alerts to clinicians in a senior housing facility. Clinicians analyze each alert and provide a rating on the clinical relevance. These ratings are then used as ground truth for training and testing classifiers. Here, we present the methodology for four classification approaches that fuse multisensor data. Results are shown using embedded sensor data and health alert ratings collected on 21 seniors over nine months. The best results show similar performance for two techniques, where one approach uses only domain knowledge and the second uses supervised learning for training. Finally, we propose a health change detection model based on these results and clinical expertise. The system of in-home sensors and algorithms for automated health alerts provides a method for detecting health problems very early so that early treatment is possible. This method of passive in-home sensing alleviates compliance issues.","Biomedical monitoring,
Feature extraction,
Monitoring,
Data mining,
Testing,
Sensors,
Electronic mail"
Properties and Power Spectral Densities of CP Based OQAM-OFDM Systems,"Offset quadrature amplitude modulation OFDM (OQAM-OFDM) systems have low sidelobes but require complex receivers for broadband channels. To deal with this problem, cyclic prefix (CP)-based OQAM-OFDM systems have been proposed in the literature. In this paper, we study OQAM-OFDM and two existing CP based OQAM-OFDM systems and propose a new CP based system with good spectrum performance. We investigate their properties and analyze their power spectral densities (PSDs). We show that the continuous-time transmitted CP-OQAM-OFDM signal after the CP insertion is equivalent to a truncated signal obtained by inserting CP and cyclic suffix (CS) to the discrete-time input data symbols in the OQAM-OFDM system, which simplifies the calculation of the PSD of the transmitted CP-OQAM-OFDM signal and also implies that the PSD of the CP-OQAM-OFDM may be affected by the truncation. We show that the perfect reconstruction (PR) condition for the CP-OQAM-OFDM system is actually the same as that for the OQAM-OFDM system when the length of the prototype filter is not more than the length of the transmitted CP-OQAM-OFDM signal of each block excluding the CP. We also compare three CP-based OQAM-OFDM systems with windowed CP-OFDM systems. Numerical results show that the theoretical and simulated PSDs of the transmitted signals match well, CP-based OQAM-OFDM systems perform better than windowed CP-OFDM systems considering both the PSD and bit error rate (BER) performances, and the newly proposed CP-based OQAM-OFDM system has the best PSD performance in the three CP based OQAM-OFDM systems with an increase of the data rate overhead.","OFDM,
Quadrature amplitude modulation,
Receivers,
Prototypes,
Broadband communication,
Bit error rate"
A general graph-based model for recommendation in event-based social networks,"Event-based social networks (EBSNs), such as Meetup and Plancast, which offer platforms for users to plan, arrange, and publish events, have gained increasing popularity and rapid growth. EBSNs capture not only the online social relationship, but also the offline interactions from offline events. They contain rich heterogeneous information, including multiple types of entities, such as users, events, groups and tags, and their interaction relations. Three recommendation tasks, namely recommending groups to users, recommending tags to groups, and recommending events to users, have been explored in three separate studies. However, none of the proposed methods can handle all the three recommendation tasks. In this paper, we propose a general graph-based model, called HeteRS, to solve the three recommendation problems on EBSNs in one framework. Our method models the rich information with a heterogeneous graph and considers the recommendation problem as a query-dependent node proximity problem. To address the challenging issue of weighting the influences between different types of entities, we propose a learning scheme to set the influence weights between different types of entities. Experimental results on two real-world datasets demonstrate that our proposed method significantly outperforms the state-of-the-art methods for all the three recommendation tasks, and the learned influence weights help understanding user behaviors.",
Coupled Spin Torque Nano Oscillators for Low Power Neural Computation,"We present coupled spin torque nano oscillators (STNOs) as electronic neurons for efficient brain-inspired computation. The coupled STNOs show two distinct outputs, depending on whether the frequencies are locked or not. The locking mechanisms are based on magnetic coupling or injection locking. The neuron firing threshold can be set by tuning the locking range of the coupled STNOs. We employ a crossbar array of programmable memory devices like memristors to implement electronic synapses that work seamlessly with the coupled STNOs for hardware implementation of neural networks. Results show that injection locking-based neuron model can be attractive from scaling point of view and computation like character recognition can be performed with energy consumption per neuron of ~1.8× and ~ 3× lower than the digital and the analog CMOS counterpart, respectively.",
"A Miniaturized, Eye-Conformable, and Long-Term Reliable Retinal Prosthesis Using Monolithic Fabrication of Liquid Crystal Polymer (LCP)","A novel retinal prosthetic device was developed using biocompatible liquid crystal polymer (LCP) to address the problems associated with conventional metal- and polymer-based devices: the hermetic metal package is bulky, heavy, and labor-intensive, whereas a thin, flexible, and MEMS-compatible polymer-based system is not durable enough for chronic implantation. Exploiting the advantageous properties of LCP such as a low moisture absorption rate, thermobonding, and thermoforming, we fabricate a small, light-weight, long-term reliable retinal prosthesis that can be conformally attached on the eye-surface. A LCP fabrication process using monolithic integration and conformal deformation was established enabling miniaturization and a batch manufacturing process as well as eliminating the need for feed-through technology. The functionality of the fabricated device was tested through wireless operation in saline solution. Its efficacy and implantation stability were verified through in vivo animal tests by measuring the cortical potential and monitoring implanted dummy devices for more than a year, respectively.","Coils,
Retina,
Metals,
Electrodes,
Prosthetics,
Substrates,
Fabrication"
Broadband Tunable Pre-Bunched Electron Cyclotron Maser for Terahertz Application,"The relativistic electron cyclotron maser (ECM) has been successfully applied to generating high-power THz wave. In order to realize the additional advantages of broadband tuning and high efficiency interaction, this paper is devoted to exploring the THz pre-bunched ECM. Other than a conventional open-cavity tunable gyrotron consecutively switching between axial modes to realize frequency tuning, a pre-bunched ECM system operates on the backward traveling-wave resonance to achieve broadband smooth tuning. Especially, an interaction circuit of specified axial profile of beam-wave detuning frequency is built to achieve high efficiency. An optimized 0.1 THz pre-bunched ECM system using an electron beam of 30 kV voltage and 3 A current is predicted to generate broad bandwidth of 10 GHz and efficiency between 10% ~ 25%. The broadband tuning pre-bunched ECM is promising for a new generation of broadband and high-power THz source.","Cavity resonators,
Electronic countermeasures,
Tuning,
Gyrotrons,
Broadband communication,
Cyclotrons,
Electron beams"
GPU-Accelerated Sparse LU Factorization for Circuit Simulation with Performance Modeling,"The sparse matrix solver by LU factorization is a serious bottleneck in Simulation Program with Integrated Circuit Emphasis (SPICE)-based circuit simulators. The state-of-the-art Graphics Processing Units (GPU) have numerous cores sharing the same memory, provide attractive memory bandwidth and compute capability, and support massive thread-level parallelism, so GPUs can potentially accelerate the sparse solver in circuit simulators. In this paper, an efficient GPU-based sparse solver for circuit problems is proposed. We develop a hybrid parallel LU factorization approach combining task-level and data-level parallelism on GPUs. Work partitioning, number of active thread groups, and memory access patterns are optimized based on the GPU architecture. Experiments show that the proposed LU factorization approach on NVIDIA GTX580 attains an average speedup of 7.02× (geometric mean) compared with sequential PARDISO, and 1.55× compared with 16-threaded PARDISO. We also investigate bottlenecks of the proposed approach by a parametric performance model. The performance of the sparse LU factorization on GPUs is constrained by the global memory bandwidth, so the performance can be further improved by future GPUs with larger memory bandwidth.","Graphics processing units,
Sparse matrices,
Instruction sets,
Integrated circuit modeling,
Parallel processing,
Virtual groups,
Bandwidth"
Hybrid Adaptive Classifier Ensemble,"Traditional random subspace-based classifier ensemble approaches (RSCE) have several limitations, such as viewing the same importance for the base classifiers trained in different subspaces, not considering how to find the optimal random subspace set. In this paper, we design a general hybrid adaptive ensemble learning framework (HAEL), and apply it to address the limitations of RSCE. As compared with RSCE, HAEL consists of two adaptive processes, i.e., base classifier competition and classifier ensemble interaction, so as to adjust the weights of the base classifiers in each ensemble and to explore the optimal random subspace set simultaneously. The experiments on the real-world datasets from the KEEL dataset repository for the classification task and the cancer gene expression profiles show that: 1) HAEL works well on both the real-world KEEL datasets and the cancer gene expression profiles and 2) it outperforms most of the state-of-the-art classifier ensemble approaches on 28 out of 36 KEEL datasets and 6 out of 6 cancer datasets.","Training,
Educational institutions,
Decision trees,
Cancer,
Accuracy,
Gene expression"
Femto-matching: Efficient traffic offloading in heterogeneous cellular networks,"Heterogeneous cellular networks use small base stations, such as femtocells and WiFi APs, to offload traffic from macrocells. While network operators wish to globally balance the traffic, users may selfishly select the nearest base stations and make some base stations overcrowded. In this paper, we propose to use an auction-based algorithm - Femto-Matching, to achieve both load balancing among base stations and fairness among users. Femto-Matching optimally solves the global proportional fairness problem in polynomial time by transforming it into an equivalent matching problem. Furthermore, it can efficiently utilize the capacity of randomly deployed small cells. Our trace-driven simulations show Femto-Matching can reduce the load of macrocells by more than 30% compared to non-cooperative game based strategies.","Femtocells,
Macrocell networks,
Throughput,
Optimization,
Algorithm design and analysis,
Signal to noise ratio"
Dynamic Single-Phase Synchronized Phase and Frequency Estimation at the Distribution Level,"This paper proposes a method for estimating synchronized phase and frequency at the distribution level under both steady-state and dynamic conditions. The discrete Fourier transform-based method is widely used for phasor and frequency estimation, thanks to its low computational burden. However, errors arise when the power system is operating at off-nominal frequency, especially under dynamic conditions such as phase modulation. Additionally, the power grid signal at the distribution level contains more noise and harmonics, which cause phase and frequency estimation errors. In this paper, a synchronized phase and frequency estimation algorithm suitable for measurement at the distribution level is proposed and tested under noise and harmonic conditions, as well as various conditions in the phasor measurement unit Standard (C37.118.1-2011 and C37.118.1a-2014), to verify its measurement accuracy at the distribution level.","Frequency modulation,
Noise,
Frequency estimation,
Harmonic analysis,
Heuristic algorithms,
Power grids"
A Directional Interstitial Antenna for Microwave Tissue Ablation: Theoretical and Experimental Investigation,"Microwave ablation (MWA) is a minimally invasive thermal therapy modality increasingly employed for the treatment of tumors and benign disease. For successful treatment, complete thermal coverage of the tumor and margin of surrounding healthy tissue must be achieved. Currently available interstitial antennas for MWA have cylindrically symmetric radiation patterns. Thus, when treating targets in proximity to critical structures, caution must be taken to prevent unintended thermal damage. A novel coaxial antenna design for MWA with an asymmetrical cylindrical heating pattern is presented in this paper. This radiation pattern is achieved by employing a hemicylindrical reflector positioned at a critical distance from a conventional coaxial monopole antenna. Finite-element method simulations were employed to optimize the geometric dimensions of the antenna with the objective of minimizing the antenna reflection coefficient at the 2.45-GHz operating frequency, and maximizing volume of the ablation zone. Prototype antennas were fabricated and experimentally evaluated. Simulations indicated an optimal S11 of -32 dB at 2.45 GHz in close agreement with experimental measurements of -29 dB. Ex vivo experiments were performed to validate simulations and observe effects to the antennas' heating pattern with the varying input power and geometry of the reflector. Ablation zones up to 20 mm radially were observed in the forward direction, with minimal heating (less than 4 mm) behind the reflector.","Reflector antennas,
Antenna measurements,
Antenna radiation patterns,
Heating,
Microwave antennas,
Directive antennas"
Adaptive Beamforming With Resource Allocation for Distance-Aware Multi-User Indoor Terahertz Communications,"Terahertz (THz) communication is envisioned as a key technology for next-generation ultra-high-speed wireless systems. In this paper, we study an indoor multi-user THz communication system with multiple antenna subarrays. To capture the distance-frequency-dependent characteristics of THz channels, we design a hybrid beamforming scheme with distance-aware multi-carrier transmission, including analog beamforming for user grouping and interference cancellation in radio-frequency (RF) domain and digital beamforming with dynamically selected subarrays at baseband. Specifically, an adaptive power allocation and low-complexity antenna subarray selection policy is developed to serve different users at different distances and reduce the cost of active RF circuits simultaneously, where two greedy subarray selection algorithms are proposed. The effectiveness of the proposed adaptive hybrid beamforming and antenna subarray selection algorithms is verified through simulation results, which achieves significant gains over other nonadaptive and non-distance-aware schemes.","Array signal processing,
Antennas,
Radio frequency,
Baseband,
Bandwidth,
Arrays,
OFDM"
Interval Power Flow Analysis Using Linear Relaxation and Optimality-Based Bounds Tightening (OBBT) Methods,"With increasingly large scale of intermittent and non-dispatchable resources being integrated into power systems, the power flow problem presents greater uncertainty. In order to obtain the upper and lower bounds of power flow solutions including voltage magnitudes, voltage angles and line flows, Cartesian coordinates-based power flow is utilized in this paper. A quadratically constrained quadratic programming (QCQP) model is then established to formulate the interval power flow problem. This non-convex QCQP model is relaxed to linear programming problem by introducing convex and concave enclosures of the original feasible region. To improve the solutions bounds while still encompassing the true interval solution, optimality-based bounds tightening (OBBT) method is employed to find a better outer hull of the feasible region. Numerical results on IEEE 9-bus, 30-bus, 57-bus, and 118-bus test systems validate the effectiveness of the proposed method.","Mathematical model,
Vectors,
Sparse matrices,
Uncertainty,
Linear programming,
Reactive power,
Equations"
From Pixels to Response Maps: Discriminative Image Filtering for Face Alignment in the Wild,"We propose a face alignment framework that relies on the texture model generated by the responses of discriminatively trained part-based filters. Unlike standard texture models built from pixel intensities or responses generated by generic filters (e.g. Gabor), our framework has two important advantages. First, by virtue of discriminative training, invariance to external variations (like identity, pose, illumination and expression) is achieved. Second, we show that the responses generated by discriminatively trained filters (or patch-experts) are sparse and can be modeled using a very small number of parameters. As a result, the optimization methods based on the proposed texture model can better cope with unseen variations. We illustrate this point by formulating both part-based and holistic approaches for generic face alignment and show that our framework outperforms the state-of-the-art on multiple”wild” databases. The code and dataset annotations are available for research purposes from http://ibug.doc.ic.ac.uk/resources.",
24/7 place recognition by view synthesis,"We address the problem of large-scale visual place recognition for situations where the scene undergoes a major change in appearance, for example, due to illumination (day/night), change of seasons, aging, or structural modifications over time such as buildings built or destroyed. Such situations represent a major challenge for current large-scale place recognition methods. This work has the following three principal contributions. First, we demonstrate that matching across large changes in the scene appearance becomes much easier when both the query image and the database image depict the scene from approximately the same viewpoint. Second, based on this observation, we develop a new place recognition approach that combines (i) an efficient synthesis of novel views with (ii) a compact indexable image representation. Third, we introduce a new challenging dataset of 1,125 camera-phone query images of Tokyo that contain major changes in illumination (day, sunset, night) as well as structural changes in the scene. We demonstrate that the proposed approach significantly outperforms other large-scale place recognition techniques on this challenging data.","Lighting,
Databases,
Cameras,
Three-dimensional displays,
Image recognition,
Image reconstruction,
Visualization"
High-Resolution Bistatic ISAR Imaging Based on Two-Dimensional Compressed Sensing,"The theory of compressed sensing (CS) states that an unknown sparse signal can be accurately recovered from a limited number of measurements by solving a sparsity-constrained optimization problem. In this paper, we present a new framework of high-resolution bistatic inverse synthetic aperture radar (Bi-ISAR) imaging based on CS. A phase-preserved CS approach for high-range resolution imaging is proposed. The phase of a Bi-ISAR signal can be extracted by constructing a phase-preserved Fourier basis, which is crucial to azimuth processing of Bi-ISAR imaging. After performing CS reconstruction in range, we present an improved version of CS-based cross-range imaging by combining modified Fourier basis and weighting with CS optimization. Simulated data are used to test the robustness of the Bi-ISAR imaging framework with two-dimensional (2-D) CS method. The results show that the framework is capable of accurate reconstruction of Bi-ISAR image in both range and cross-range.",
Investigating Country Differences in Mobile App User Behavior and Challenges for Software Engineering,"Mobile applications (apps) are software developed for use on mobile devices and made available through app stores. App stores are highly competitive markets where developers need to cater to a large number of users spanning multiple countries. This work hypothesizes that there exist country differences in mobile app user behavior and conducts one of the largest surveys to date of app users across the world, in order to identify the precise nature of those differences. The survey investigated user adoption of the app store concept, app needs, and rationale for selecting or abandoning an app. We collected data from more than 15 countries, including USA, China, Japan, Germany, France, Brazil, United Kingdom, Italy, Russia, India, Canada, Spain, Australia, Mexico, and South Korea. Analysis of data provided by 4,824 participants showed significant differences in app user behaviors across countries, for example users from USA are more likely to download medical apps, users from the United Kingdom and Canada are more likely to be influenced by price, users from Japan and Australia are less likely to rate apps. Analysis of the results revealed new challenges to market-driven software engineering related to packaging requirements, feature space, quality expectations, app store dependency, price sensitivity, and ecosystem effect.",
An Approach to Supporting Incremental Visual Data Classification,"Automatic data classification is a computationally intensive task that presents variable precision and is considerably sensitive to the classifier configuration and to data representation, particularly for evolving data sets. Some of these issues can best be handled by methods that support users' control over the classification steps. In this paper, we propose a visual data classification methodology that supports users in tasks related to categorization such as training set selection; model creation, application and verification; and classifier tuning. The approach is then well suited for incremental classification, present in many applications with evolving data sets. Data set visualization is accomplished by means of point placement strategies, and we exemplify the method through multidimensional projections and Neighbor Joining trees. The same methodology can be employed by a user who wishes to create his or her own ground truth (or perspective) from a previously unlabeled data set. We validate the methodology through its application to categorization scenarios of image and text data sets, involving the creation, application, verification, and adjustment of classification models.","Visualization,
Data models,
Data visualization,
Mathematical model,
Training,
Computational modeling,
Layout"
Database-augmented spectrum sensing algorithm for cognitive radio,"Spectrum sensing is one of the key technologies to realize dynamic spectrum access in cognitive radio (CR). In this paper, a novel database-augmented spectrum sensing algorithm is proposed for a secondary access to the TV White Space (TVWS) spectrum. The proposed database-augmented sensing algorithm is based on an existing geo-location database approach for detecting incumbents like Digital Terrestrial Television (DTT) and Programme Making and Special Events (PMSE) users, but is combined with spectrum sensing to further improve the protection to these primary users (PUs). A closed-form expression of secondary users' (SUs) spectral efficiency is also derived for its opportunistic access of TVWS. By implementing previously developed power control based geo-location database and adaptive spectrum sensing algorithm, the proposed database-augmented sensing algorithm demonstrates a better spectrum efficiency for SUs, and better protection for incumbent PUs than the exiting stand-alone geo-location database model. Furthermore, we analyze the effect of the unregistered PMSE on the reliable use of the channel for SUs.","Sensors,
Databases,
TV,
White spaces,
Bismuth"
Single-Image Dehazing via Optimal Transmission Map Under Scene Priors,"The challenge of single-image dehazing mainly comes from double uncertainty of scene radiance and scene transmission. Most existing methods focus on restoring the visibility of hazy images and tend to derive a rough estimate of scene transmission. Unlike previous work, in this paper we advocate the significance of accurate transmission estimation and recast our problem as deriving the optimal transmission map directly from the haze model under two scene priors. We introduce theoretic and heuristic bounds of scene transmission to guide the optimum and show that the proposed theoretic bound happens to justify the well-known dark channel prior of haze-free images. With the constraints on the solution space, we then incorporate two scene priors, including locally consistent scene radiance and context-aware scene transmission, to formulate a constrained minimization problem and solve it by quadratic programming. The global optimality is guaranteed. Simulations on synthetic data set quantitatively verify the accuracy and show that the transmission map successfully captures fine-grained depth boundaries. Experimental results on color/gray-level images demonstrate that our method outperforms most state of the arts in terms of both accurate transmission maps and realistic haze-free images.",
"Mission Reliability, Cost and Time for Cold Standby Computing Systems with Periodic Backup","Life critical applications like space missions and flight controls require their computing systems to be equipped with some fault-tolerance mechanism to meet stringent reliability requirements by performing the intended function even in the case of element failures. Such benefit, however, cannot come without extra time as well as extra overhead and capital costs. This paper for the first time considers the modeling and evaluation of mission reliability, expected mission time and cost simultaneously for 1-out-of-N: G nonrepairable cold standby computing systems subject to periodic backup actions. Based on the suggested numerical evaluation method, the optimal backup frequency problems are formulated and solved, providing the optimal number of backup operations during the mission to maximize the system reliability or to minimize the mission cost or time. In the case of non-identical system elements, the optimal standby element sequencing problem arises as the order in which the system elements are initiated can impact the system reliability and mission cost and time greatly; such problems are formulated and solved for the 1-out-of-N: G cold standby computing systems with periodic backups. Furthermore, a combined optimization problem is considered, where a combination of the element initiation sequence and backup frequency providing the best combination of mission reliability, cost, and time is found. The proposed methodology can facilitate a reliability-cost-time tradeoff study in the practical design of cold standby systems, thus assist in making the optimal decision on the system's standby and backup policy. Examples are provided for illustrating the considered problems and suggested solution methodology.",
Saliency Based Ulcer Detection for Wireless Capsule Endoscopy Diagnosis,"Ulcer is one of the most common symptoms of many serious diseases in the human digestive tract. Especially for the ulcers in the small bowel where other procedures cannot adequately visualize, wireless capsule endoscopy (WCE) is increasingly being used in the diagnosis and clinical management. Because WCE generates large amount of images from the whole process of inspection, computer-aided detection of ulcer is considered an indispensable relief to clinicians. In this paper, a two-staged fully automated computer-aided detection system is proposed to detect ulcer from WCE images. In the first stage, we propose an effective saliency detection method based on multi-level superpixel representation to outline the ulcer candidates. To find the perceptually and semantically meaningful salient regions, we first segment the image into multi-level superpixel segmentations. Each level corresponds to different initial region sizes of the superpixels. Then we evaluate the corresponding saliency according to the color and texture features in superpixel region of each level. In the end, we fuse the saliency maps from all levels together to obtain the final saliency map. In the second stage, we apply the obtained saliency map to better encode the image features for the ulcer image recognition tasks. Because the ulcer mainly corresponds to the saliency region, we propose a saliency max-pooling method integrated with the Locality-constrained Linear Coding (LLC) method to characterize the images. Experiment results achieve promising 92.65% accuracy and 94.12% sensitivity, validating the effectiveness of the proposed method. Moreover, the comparison results show that our detection system outperforms the state-of-the-art methods on the ulcer classification task.","Image color analysis,
Feature extraction,
Image segmentation,
Image coding,
Estimation,
Visualization,
Vectors"
Connecting Silicon Photonic Circuits to Multicore Fibers by Photonic Wire Bonding,"Photonic wire bonding is demonstrated to enable highly efficient coupling between multicore fibers and planar silicon photonic circuits. The technique relies on in-situ fabrication of three-dimensional interconnect waveguides between the fiber facet and tapered silicon-on-insulator waveguides. Photonic wire bonding can easily compensate inaccuracies of core placement in the fiber cross-section, does not require active alignment, and is well suited for automated fabrication. We report on the design, on fabrication, and on characterization of photonic wire bonds. In a proof-of-principle experiment, a four-core fiber is coupled to a silicon photonic chip, leading to measured coupling losses as small as 1.7 dB.","Optical fiber couplers,
Photonics,
Wires,
Insertion loss,
Loss measurement"
Multilevel image thresholding by fireworks algorithm,"This paper presents implementation of the recent fireworks algorithm adjusted for solving multilevel image thresholding problem. This is an important problem since it is often used in image processing for the purpose of image segmentation. Since the number of possible threshold combinations grows exponentially with the number of desirable thresholds, standard deterministic methods could not generate satisfying results when tackling this problem. To test the performance of our proposed approach, we employed Kapur's maximum entropy thresholding function on standard benchmark images where the optimal solutions are known (up to five thresholding points) from the exhaustive search. Results show that our approach has great potential in this field.",
BUS-VANET: A BUS Vehicular Network Integrated with Traffic Infrastructure,"With the development of wireless communications, Vehicular Ad Hoc Network (VANET) has received considerable attention on information sharing and data delivery services. In order to collect and control traffic conditions, Intelligent Transportations Systems (ITS) has deployed a number of Road Side Units (RSUs) along the roads to collect and deliver traffic information to the Traffic Control Center (TCC) for analyzing traffic data. Although some VANET architectures have been proposed based on the predictable routes and schedules of buses, none of them considered taking advantage of such traffic infrastructures which already been supplied by ITS and combine them with scheduled buses. In this paper, we propose a two-tier BUSVANET that is fully integrated with RSUs and TCC as traffic infrastructures. In this new architecture, the communications of vehicles, not only benefit from the existence of buses, but also consider the effects of using RSUs and TCC. RSUs are used to ensure service coverage while TCC is helpful for locating the destination vehicle quickly. We also investigate how much benefits can be obtained by taking advantage of this type of traffic infrastructure.","Vehicular ad how networks,
Traffic control,
Intelligent networks,
Wireless communication,
Information management"
Silicon-Controlled Rectifier for Electrostatic Discharge Protection Solutions With Minimal Snapback and Reduced Overshoot Voltage,"An electrostatic discharge (ESD) protection structure constructed by the stacking of multiple anode gate-cathode gate directly connected silicon-controlled rectifiers (DCSCRs), fabricated in a 0.18-μm CMOS technology is reported in this letter. Two embedded diodes in the DCSCR dictate the turn-ON mechanism and hence give rise to a trigger voltage equal to twice the diode's turn-ON voltage. This approach enables the DCSCR to offer a diode-like transmission line pulsing IV characteristic with a minimal snapback and a SCR-like high-ESD robustness. At 25 °C, DCSCR has an acceptable nanoampere-level leakage current. Besides, it is verified that the DCSCR can significantly reduce overshoot voltage when stressed by very-fast-rising pulses. As such, an ESD clamp constructed by stacking a selected number of DCSCRs can offer a flexible trigger/holding voltage and is suitable for low and medium voltage ESD protection applications.","Electrostatic discharges,
Thyristors,
Stacking,
Logic gates,
Leakage currents,
Transmission line measurements,
CMOS integrated circuits"
A Learning-to-Rank Approach to Software Defect Prediction,"Software defect prediction can help to allocate testing resources efficiently through ranking software modules according to their defects. Existing software defect prediction models that are optimized to predict explicitly the number of defects in a software module might fail to give an accurate order because it is very difficult to predict the exact number of defects in a software module due to noisy data. This paper introduces a learning-to-rank approach to construct software defect prediction models by directly optimizing the ranking performance. In this paper, we build on our previous work, and further study whether the idea of directly optimizing the model performance measure can benefit software defect prediction model construction. The work includes two aspects: one is a novel application of the learning-to-rank approach to real-world data sets for software defect prediction, and the other is a comprehensive evaluation and comparison of the learning-to-rank method against other algorithms that have been used for predicting the order of software modules according to the predicted number of defects. Our empirical studies demonstrate the effectiveness of directly optimizing the model performance measure for the learning-to-rank approach to construct defect prediction models for the ranking task.","Software,
Predictive models,
Data models,
Software metrics,
Testing,
Radio frequency"
Inter-block consistent soft decoding of JPEG images with sparsity and graph-signal smoothness priors,"Given the prevalence of JPEG compressed images on the Internet, image reconstruction from the compressed format remains an important and practical problem. Instead of simply reconstructing a pixel block from the centers of assigned DCT coefficient quantization bins (hard decoding), we propose to jointly reconstruct a neighborhood group of pixel patches using two image priors while satisfying the quantization bin constraints. First, we assume that a pixel patch can be approximated as a sparse linear combination of atoms from an offline-learned over-complete dictionary. Second, we assume that a patch, when interpreted as a graph-signal, is smooth with respect to an appropriately defined graph that captures the estimated structure of the target image. Finally, neighboring patches in the optimization have sufficient overlaps and are forced to be consistent, so that blocking artifacts typical in JPEG decoded images are avoided. To find the optimal group of patches, we formulate a constrained optimization problem and propose a fast alternating algorithm to find locally optimal solutions. Experimental results show that our proposed algorithm outperforms state-of-the-art soft decoding algorithms by up to 1.47dB in PSNR.","Discrete cosine transforms,
Decoding,
Transform coding,
Image coding,
Quantization (signal),
Optimization,
Image reconstruction"
Fine-grained visual categorization via multi-stage metric learning,"Fine-grained visual categorization (FGVC) is to categorize objects into subordinate classes instead of basic classes. One major challenge in FGVC is the co-occurrence of two issues: 1) many subordinate classes are highly correlated and are difficult to distinguish, and 2) there exists the large intra-class variation (e.g., due to object pose). This paper proposes to explicitly address the above two issues via distance metric learning (DML). DML addresses the first issue by learning an embedding so that data points from the same class will be pulled together while those from different classes should be pushed apart from each other; and it addresses the second issue by allowing the flexibility that only a portion of the neighbors (not all data points) from the same class need to be pulled together. However, feature representation of an image is often high dimensional, and DML is known to have difficulty in dealing with high dimensional feature vectors since it would require O(d2) for storage and O(d3) for optimization. To this end, we proposed a multi-stage metric learning framework that divides the large-scale high dimensional learning problem to a series of simple subproblems, achieving O(d) computational complexity. The empirical study with FVGC benchmark datasets verifies that our method is both effective and efficient compared to the state-of-the-art FGVC approaches.",
NMF-Based Speech Enhancement Using Bases Update,"This letter presents a speech enhancement technique combining statistical models and non-negative matrix factorization (NMF) with on-line update of speech and noise bases. The statistical model-based enhancement methods have been known to be less effective to non-stationary noises while the template-based enhancement techniques can deal with them quite well. However, the template-based enhancement techniques usually rely on a priori information. To overcome the shortcomings of both approaches, we propose a novel speech enhancement method that combines the statistical model-based enhancement scheme with the NMF-based gain function. For a better performance in time-varying noise environments, both the speech and noise bases of NMF are adapted simultaneously with the help of the estimated speech presence probability. Experimental results showed that the proposed method outperformed not only the statistical model-based and NMF approaches, but also their combination in various noise environments.","Noise,
Speech,
Speech enhancement,
Computational modeling,
Training,
Gain,
Vectors"
Active gate driver for fast switching and cross-talk suppression of SiC devices in a phase-leg configuration,"This paper presents an active gate driver for Silicon Carbide (SiC) devices to fully utilize their potentials of high switching-speed capability in a phase-leg configuration. Based on the SiC device's intrinsic properties, a gate assist circuit consisting of two auxiliary transistors with two diodes is introduced to actively control the gate voltages and gate loop impedances of both devices in a phase-leg during different switching transients. Compared to a conventional gate driver, the proposed circuit has the capability of increasing the switching speed of the phase-leg power devices, suppressing the cross-talk to below device limits. Based on CREE's 2nd generation 1200-V SiC MOSFETs, the test results demonstrate the effectiveness of this active gate driver under various operating conditions. The switching time decreases by up to 28% during turn-on and 50% during turn-off in the prototype circuit, resulting in up to 31% reduction in switching energy loss. In addition, spurious gate voltages induced by cross-talk are limited within the required range.","Logic gates,
Switches,
Transient analysis,
Silicon carbide,
Voltage control,
Switching circuits,
Resistors"
Investigation of Skewing Effects on the Vibration Reduction of Three-Phase Switched Reluctance Motors,"Switched reluctance motors (SRMs) are gaining in popularity because of their robustness, low cost, and excellent high-speed characteristics. However, they are known to cause vibration and noise primarily due to the radial pulsating force resulting from their double-saliency structure. This paper investigates the effect of skewing the stator and/or rotor on the vibration reduction of the three-phase SRMs by developing four 12/8-pole SRMs, including a conventional SRM, a skewed rotor-SRM (SR-SRM), a skewed stator-SRM (SS-SRM), and a skewed stator and rotor-SRM (SSR-SRM). The radial force distributed on the stator yoke under different skewing angles is extensively studied by the finite-element method and experimental tests on the four prototypes. The inductance and torque characteristics of the four motors are also compared, and a control strategy by modulating the turn-ON and turn-OFF angles for the SR-SRM and the SS-SRM are also presented. Furthermore, experimental results validate the numerical models and the effectiveness of the skewing in reducing the motor vibration. Test results also suggest that skewing the stator is more effective than skewing the rotor in the SRMs.","Reluctance motors,
Force,
Stators,
Rotors,
Vibrations,
Finite element analysis,
Torque"
Intention-aware online POMDP planning for autonomous driving in a crowd,"This paper presents an intention-aware online planning approach for autonomous driving amid many pedestrians. To drive near pedestrians safely, efficiently, and smoothly, autonomous vehicles must estimate unknown pedestrian intentions and hedge against the uncertainty in intention estimates in order to choose actions that are effective and robust. A key feature of our approach is to use the partially observable Markov decision process (POMDP) for systematic, robust decision making under uncertainty. Although there are concerns about the potentially high computational complexity of POMDP planning, experiments show that our POMDP-based planner runs in near real time, at 3 Hz, on a robot golf cart in a complex, dynamic environment. This indicates that POMDP planning is improving fast in computational efficiency and becoming increasingly practical as a tool for robot planning under uncertainty.","Vehicles,
Planning,
Uncertainty,
Vegetation,
Robot sensing systems,
Vehicle dynamics"
An optimal operating frequency selection scheme in spectrum handoff for cognitive radio networks,"Recently, cognitive radio (CR) technology has emerged as a promising solution to alleviate the spectrum scarcity problem. CR technology allows an unlicensed user to exploit the frequency bands unused by licensed users in an opportunistic manner. However, there is a critical issue when unlicensed users change their operating frequencies in the licensed bands. When an unlicensed user changes its operating frequency from a high frequency to a low frequency during a spectrum handoff, its transmission coverage enlarges, which increases the probability of interference to licensed users. In addition, when the unlicensed user changes its operating frequency from a low frequency to a high frequency during a spectrum handoff, its transmission coverage shrinks, which leads to the possibility of connection failure between the transmitting pair. In this paper, an optimal scheme is proposed to select a new operating frequency when an unlicensed user changes its operating frequency. The optimal frequency is obtained by considering the trade-offs between the probability of interference to licensed users and the probability of successful transmissions as well as the end-to-end throughput in both single-hop and multi-hop scenarios. Results show that the optimal operating frequency selected using the proposed scheme achieves the highest value of the objective function. To the best of our knowledge, this is the first paper that investigates the optimal operating frequency selection that considers the impact of the frequency to the transmission coverage in CR networks.","Cognitive radio,
Interference,
Ad hoc networks,
Linear programming,
Spread spectrum communication,
Delays"
Learning Compact Feature Descriptor and Adaptive Matching Framework for Face Recognition,"Dense feature extraction is becoming increasingly popular in face recognition tasks. Systems based on this approach have demonstrated impressive performance in a range of challenging scenarios. However, improvements in discriminative power come at a computational cost and with a risk of over-fitting. In this paper, we propose a new approach to dense feature extraction for face recognition, which consists of two steps. First, an encoding scheme is devised that compresses high-dimensional dense features into a compact representation by maximizing the intrauser correlation. Second, we develop an adaptive feature matching algorithm for effective classification. This matching method, in contrast to the previous methods, constructs and chooses a small subset of training samples for adaptive matching, resulting in further performance gains. Experiments using several challenging face databases, including labeled Faces in the Wild data set, Morph Album 2, CUHK optical-infrared, and FERET, demonstrate that the proposed approach consistently outperforms the current state of the art.","Face,
Training,
Feature extraction,
Image coding,
Face recognition,
Facial features,
Correlation"
Beyond Multimedia Adaptation: Quality of Experience-Aware Multi-Sensorial Media Delivery,"Multiple sensorial media (mulsemedia) combines multiple media elements which engage three or more of human senses, and as most other media content, requires support for delivery over the existing networks. This paper proposes an adaptive mulsemedia framework (ADAMS) for delivering scalable video and sensorial data to users. Unlike existing two-dimensional joint source-channel adaptation solutions for video streaming, the ADAMS framework includes three joint adaptation dimensions: video source, sensorial source, and network optimization. Using an MPEG-7 description scheme, ADAMS recommends the integration of multiple sensorial effects (i.e., haptic, olfaction, air motion, etc.) as metadata into multimedia streams. ADAMS design includes both coarse- and fine-grained adaptation modules on the server side: mulsemedia flow adaptation and packet priority scheduling. Feedback from subjective quality evaluation and network conditions is used to develop the two modules. Subjective evaluation investigated users' enjoyment levels when exposed to mulsemedia and multimedia sequences, respectively and to study users' preference levels of some sensorial effects in the context of mulsemedia sequences with video components at different quality levels. Results of the subjective study inform guidelines for an adaptive strategy that selects the optimal combination for video segments and sensorial data for a given bandwidth constraint and user requirement. User perceptual tests show how ADAMS outperforms existing multimedia delivery solutions in terms of both user perceived quality and user enjoyment during adaptive streaming of various mulsemedia content. In doing so, it highlights the case for tailored, adaptive mulsemedia delivery over traditional multimedia adaptive transport mechanisms.","Haptic interfaces,
Streaming media,
Multimedia communication,
Media,
Olfactory,
Motion pictures,
Transform coding"
Independent Doubly Adaptive Rejection Metropolis Sampling Within Gibbs Sampling,"Bayesian methods have become very popular in signal processing lately, even though performing exact Bayesian inference is often unfeasible due to the lack of analytical expressions for optimal Bayesian estimators. In order to overcome this problem, Monte Carlo (MC) techniques are frequently used. Several classes of MC schemes have been developed, including Markov Chain Monte Carlo (MCMC) methods, particle filters and population Monte Carlo approaches. In this paper, we concentrate on the Gibbs-type approach, where automatic and fast samplers are needed to draw from univariate (full-conditional) densities. The Adaptive Rejection Metropolis Sampling (ARMS) technique is widely used within Gibbs sampling, but suffers from an important drawback: an incomplete adaptation of the proposal in some cases. In this work, we propose an alternative adaptive MCMC algorithm (IA2RMS) that overcomes this limitation, speeding up the convergence of the chain to the target, allowing us to simplify the construction of the sequence of proposals, and thus reducing the computational cost of the entire algorithm. Note that, although IA2RMS has been developed as an extremely efficient MCMC-within-Gibbs sampler, it also provides an excellent performance as a stand-alone algorithm when sampling from univariate distributions. In this case, the convergence of the proposal to the target is proved and a bound on the complexity of the proposal is provided. Numerical results, both for univariate (stand-alone IA2RMS) and multivariate (IA2RMS-within-Gibbs) distributions, show that IA2RMS outperforms ARMS and other classical techniques, providing a correlation among samples close to zero.","Proposals,
Signal processing algorithms,
Monte Carlo methods,
Bayes methods,
Signal processing,
Computational efficiency,
Algorithm design and analysis"
Design of Class E Resonant Rectifiers and Diode Evaluation for VHF Power Conversion,"Resonant rectifiers have important applications in very-high-frequency (VHF) power conversion systems, including dc-dc converters, wireless power transfer systems, and energy recovery circuits for radio-frequency systems. In many of these applications, it is desirable for the rectifier to appear as a resistor at its ac input port. However, for a given dc output voltage, the input impedance of a resonant rectifier varies in magnitude and phase as output power changes. This paper presents a design methodology for class E rectifiers that maintain near-resistive input impedance along with the experimental demonstration of this approach. Resonant rectifiers operating at 30 MHz over 10:1 and 2:1 power ranges are used to validate the design methodology and identify its limits. Furthermore, a number of Si Schottky diodes are experimentally evaluated for VHF rectification and categorized based on performance.","Rectifiers,
Capacitance,
Impedance,
Inductors,
Inductance,
Power generation,
Resonant frequency"
Resource sharing in heterogeneous cloud radio access networks,"Heterogeneous cloud radio access networks incorporate the heterogeneous network and cloud radio access network concepts for next generation cellular networks. H-CRANs exploit the heterogeneity of macro and small cells from HetNets, enabling cellular networks to achieve higher spectral efficiency. Meanwhile, concepts from C-RANs involving baseband units and remote radio heads enable H-CRANs to insert a centralized point of processing for cellular networks, reducing capital and operational expenditures. In this article, we investigate resource sharing in H-CRANs at three levels: spectrum, infrastructure, and network. For each level, we discuss the benefits and challenges, highlighting key enabling technologies that make resource sharing feasible in H-CRANs, such as software defined radio, virtualization, network function virtualization, and software defined networking. Through these technologies, H-CRANs can be virtualized in an overlay network capable of achieving enhanced infrastructure and spectrum sharing.",
Performance Study of Layered Division Multiplexing Based on SDR Platform,"Two of the main drawbacks of the current broadcasting services are, on the one hand, the lack of flexibility to adapt to the new generation systems requirements, and on the other hand, the incapability of taking a piece of the current mobile services market. In this paper, layered division multiplexing (LDM), which grew out of the concept of Cloud Txn, is presented as a very promising technique for answering those challenges and enhancing the capacity of broadcasting systems. The major contribution of this paper is to present the first comprehensive study of the LDM performance behavior. In particular, in this paper, the theoretical considerations of the LDM implementation are completed with the first computer based simulations and laboratory tests, covering a wide range of stationary channels and the mobile TU-6 channel. The results will support LDM as a strong candidate for multiplexing different services in the next generation broadcasting systems, increasing both flexibility and performance.",
Learning Computational Models of Video Memorability from fMRI Brain Imaging,"Generally, various visual media are unequally memorable by the human brain. This paper looks into a new direction of modeling the memorability of video clips and automatically predicting how memorable they are by learning from brain functional magnetic resonance imaging (fMRI). We propose a novel computational framework by integrating the power of low-level audiovisual features and brain activity decoding via fMRI. Initially, a user study experiment is performed to create a ground truth database for measuring video memorability and a set of effective low-level audiovisual features is examined in this database. Then, human subjects' brain fMRI data are obtained when they are watching the video clips. The fMRI-derived features that convey the brain activity of memorizing videos are extracted using a universal brain reference system. Finally, due to the fact that fMRI scanning is expensive and time-consuming, a computational model is learned on our benchmark dataset with the objective of maximizing the correlation between the low-level audiovisual features and the fMRI-derived features using joint subspace learning. The learned model can then automatically predict the memorability of videos without fMRI scans. Evaluations on publically available image and video databases demonstrate the effectiveness of the proposed framework.","Visualization,
Feature extraction,
Computational modeling,
Predictive models,
Brain models"
Robust Group Sparse Beamforming for Multicast Green Cloud-RAN With Imperfect CSI,"In this paper, we investigate the network power minimization problem for the multicast cloud radio access network (Cloud-RAN) with imperfect channel state information (CSI). The key observation is that network power minimization can be achieved by adaptively selecting active remote radio heads (RRHs) via controlling the group-sparsity structure of the beamforming vector. However, this yields a non-convex combinatorial optimization problem, for which we propose a three-stage robust group sparse beamforming algorithm. In the first stage, a quadratic variational formulation of the weighted mixed ℓ1/ℓ2-norm is proposed to induce the group-sparsity structure in the aggregated beamforming vector, which indicates those RRHs that can be switched off. A perturbed alternating optimization algorithm is then proposed to solve the resultant non-convex group-sparsity inducing optimization problem by exploiting its convex substructures. In the second stage, we propose a PhaseLift technique based algorithm to solve the feasibility problem with a given active RRH set, which helps determine the active RRHs. Finally, the semidefinite relaxation (SDR) technique is adopted to determine the robust multicast beamformers. Simulation results will demonstrate the convergence of the perturbed alternating optimization algorithm, as well as, the effectiveness of the proposed algorithm to minimize the network power consumption for multicast Cloud-RAN.","Array signal processing,
Robustness,
Optimization,
Signal processing algorithms,
Power demand,
Quality of service,
Minimization"
Automated Assembly of Vascular-Like Microtube With Repetitive Single-Step Contact Manipulation,"Fabricated vessel-mimetic microtubes are essential for delivering sufficient nutrient to engineered composite tissues. In this paper, vascular-like microtubes are engineered by automated assembly of donut-shaped micromodules that embed fibroblast cells. A microrobotic system is set up with dual manipulators of 30-nm positioning resolution under an optical microscope. The system assembles the micromodules by repeated single-step pick-up motions. This process is specifically designed to avoid human interference and ensure high reproducibility for automation. We optimized the single-step motion by calibrating the key parameters (the micromodule dimensions) in a force analysis. The optimal motion achieved a 98% pick-up success rate. The automated repetitive single-step assembly is achieved by an algorithm that acquires the 3-D location and tracks the micromanipulator without being affected by low contrast. The accuracy of the acquired 3-D location was experimentally determined as approximately 1 pixel (2 μm under 4× magnification), and the tracking under different observation conditions is proved effective. Finally, we automatically assembled microtubes at 6 micromodules/min, sufficiently fast for fabricating macroscopic vessel-mimetic substitutes in biological applications.","Assembly,
Three-dimensional displays,
Force,
Manipulators,
Shafts,
Biomedical optical imaging,
Substrates"
Model Predictive Control of Central Chiller Plant With Thermal Energy Storage Via Dynamic Programming and Mixed-Integer Linear Programming,"This work considers the optimal scheduling problem for a campus central plant equipped with a bank of multiple electrical chillers and a thermal energy storage (TES). Typically, the chillers are operated in ON/OFF modes to charge TES and supply chilled water to satisfy the campus cooling demands. A bilinear model is established to describe the system dynamics of the central plant. A model predictive control (MPC) problem is formulated to obtain optimal set-points to satisfy the campus cooling demands and minimize daily electricity cost. At each time step, the MPC problem is represented as a large-scale mixed-integer nonlinear programming problem. We propose a heuristic algorithm to obtain suboptimal solutions for it via dynamic programming (DP) and mixed integer linear programming (MILP). The system dynamics is linearized along the simulated trajectories of the system. The optimal TES operation profile is obtained by solving a DP problem at every horizon, and the optimal chiller operations are obtained by solving an MILP problem at every time step with a fixed TES operation profile. Simulation results show desired performance and computational tractability of the proposed algorithm. This work was motivated by the supervisory control need for a campus central plant. Plant operators have to decide a scheduling strategy to mix and match various chillers with a thermal energy storage to satisfy the campus cooling demands, while minimizing the operation cost. This work mathematically characterizes the system dynamics of a campus central plant and establishes a linear model to predict campus cooling load. It proposes a model predictive control (MPC) strategy to optimally schedule the campus central plant based on plant system dynamics and predicted campus cooling load. A heuristic algorithm is proposed to obtain suboptimal solutions for the MPC problem. The effectiveness and efficiency of the proposed approach are well demonstrated for the central plant at the University of California, Irvine.","Cooling,
Electricity,
Heuristic algorithms,
Mathematical model,
Buildings,
Nonlinear dynamical systems,
Optimization"
A Novel Algorithm for Estimating Refurbished Three-Phase Induction Motors Efficiency Using Only No-Load Tests,"Induction motors fail due to many reasons, and many are rewound two or more times during their lifetimes. It is generally assumed that a rewound motor is not as efficient as the original motor. Precise estimation of efficiency of a refurbished motor or any existing motor is crucial in industries for energy savings, auditing, and management. Full-load and partial-load efficiency can be measured by using the dynamometer. This paper presents a novel technique for estimating refurbished induction motors' full-load and partial-load efficiencies from only no-load tests. The technique can be applied in any electric motor workshop and eliminates the need for the dynamometer procedure. It also eliminates the need for the locked-rotor test. Experimental and field results of testing eight induction motors are presented, and the degree of accuracy is shown by comparing the estimated efficiencies against the measured values. To provide the necessary credits to the proposed technique, an error analysis is conducted to investigate the level of uncertainty through testing three induction motors, and the results of uncertainty of the direct measurements and no-load measurements using the proposed technique are presented.","Induction motors,
IEEE standards,
Loss measurement,
Algorithm design and analysis,
Temperature measurement,
Resistance,
Conferences"
Fast HEVC Inter CU Decision Based on Latent SAD Estimation,"The emerging high efficiency video coding (HEVC) standard has improved compression performance significantly in comparison with H.264/AVC. However, more intensive computational complexity has been introduced by adopting a number of new coding tools. In this paper, a fast inter CU decision is proposed based on the latent sum of absolute differences (SAD) estimation. Firstly, a two-layer motion estimation (ME) method is designed to take advantage of the latent SAD cost. The new ME method can obtain the SAD costs for both the upper CU and its sub-CUs. Secondly, a concept of motion compensation rate- distortion (R-D) cost is defined, and an exponential model is proposed to express the relationship between the motion compensation R-D cost and the SAD cost. Then, a fast CU decision approach is designed based on the exponential model. The fast CU decision is implemented by comparing a derived threshold with the SAD cost difference between the upper and sub SAD costs. Experimental results show that the proposed algorithm achieves an average of 52% and 58.4% reductions of the coding time at the cost of 1.61% and 2% bit-rate increases under the low delay and random access conditions, respectively.","Motion compensation,
Motion estimation,
Video coding,
Distortion,
Rate-distortion,
Optimization"
Directed Information Graphs,"We propose a graphical model for representing networks of stochastic processes, the minimal generative model graph. It is based on reduced factorizations of the joint distribution over time. We show that under appropriate conditions, it is unique and consistent with another type of graphical model, the directed information graph, which is based on a generalization of Granger causality. We demonstrate how directed information quantifies Granger causality in a particular sequential prediction setting. We also develop efficient methods to estimate the topological structure from data that obviate estimating the joint statistics. One algorithm assumes upper bounds on the degrees and uses the minimal dimension statistics necessary. In the event that the upper bounds are not valid, the resulting graph is nonetheless an optimal approximation in terms of Kullback-Leibler (KL) divergence. Another algorithm uses near-minimal dimension statistics when no bounds are known, but the distribution satisfies a certain criterion. Analogous to how structure learning algorithms for undirected graphical models use mutual information estimates, these algorithms use directed information estimates. We characterize the sample-complexity of two plug-in directed information estimators and obtain confidence intervals. For the setting when point estimates are unreliable, we propose an algorithm that uses confidence intervals to identify the best approximation that is robust to estimation error. Last, we demonstrate the effectiveness of the proposed algorithms through the analysis of both synthetic data and real data from the Twitter network. In the latter case, we identify which news sources influence users in the network by merely analyzing tweet times.","Graphical models,
Approximation algorithms,
Joints,
Approximation methods,
Mutual information,
Social network services,
Topology"
Social Access vs. Privacy in Wearable Computing: A Case Study of Autism,"People with high-functioning autism face challenges in communication and social interaction. This article considers the possibility, and perhaps inevitability, of wearable devices such as Google Glass being used as real-time assistive technologies for this group, with the intent of enabling them to better access our complex social world. Social impairments, by their very nature, highlight issues of communication, personal information, and social judgment. In considering such assistive technology in this context, the authors explore new tensions between privacy issues and assistive technologies, especially those of a do-it-yourself nature, which are not immediately solvable within our current privacy frameworks. This article is part of a special issue on privacy and security.","Privacy,
Autism,
Context awareness,
Real-time systems,
Internet,
Data privacy,
Computer security,
Wearable computing"
Reexamination of Photovoltaic Hot Spotting to Show Inadequacy of the Bypass Diode,"Hot spotting is a reliability problem in photovoltaic (PV) panels where a mismatched cell heats up significantly and degrades panel performance. High temperatures due to hot spotting can damage cell encapsulant and lead to second breakdown; both cause permanent damage to the PV panel. Although bypass diodes are used for protection and qualification tests are used to reduce cell mismatch, these strategies are shown to be insufficient for hot spot prevention. This paper reexamines the hot spot problem in PV strings through simulation and load-line analysis. Results show that cells in typical panel string lengths are susceptible to hot spotting because of reverse bias behavior. A number of existing and emerging solutions aimed at hot spot prevention are discussed and evaluated. Commercially available active bypass switches are an improvement over passive diodes but do not prevent hot spotting. Cells with low breakdown voltages limit power dissipation but are not fully vetted as a long-term solution. A combination of hot spot detection and open-circuit protection is a complete solution to hot spotting.","Schottky diodes,
Power dissipation,
Photovoltaic systems,
Electric breakdown,
Heating,
Degradation"
Plasma Enhanced Atomic Layer Deposition Passivated HfO2/AlN/In0.53Ga0.47As MOSCAPs With Sub-Nanometer Equivalent Oxide Thickness and Low Interface Trap Density,"The impact of in situ plasma-enhanced atomic layer deposition passivation on the electrical properties of HfO2/In0.53Ga0.47As metal-oxide-semiconductor capacitors (MOSCAPs) has been studied. Excellent interface quality of high-k/III-V is achieved by aluminum nitride (AlN) interfacial passivation layer, including strong inversion behaviors and unpinned Fermi level. The band alignment of HfO2/AlN/In0.53Ga0.47As structure with the valence band offsets of 2.81 ± 0.1 eV and the conduction band offsets of 1.9 ± 0.1 eV was obtained. Better interface and optimized high-k dielectric qualities are achieved using post remote-plasma treatment with either N2/H2 or NH3 gases. Sub-nanometer equivalent oxide thickness HfO2/AlN/In0.53Ga0.47As MOSCAPs with low interface trap density and low leakage current density have been characterized.","Hafnium oxide,
Aluminum nitride,
Passivation,
Indium gallium arsenide,
Capacitance-voltage characteristics,
Atomic layer deposition,
III-V semiconductor materials"
Distributed Systems of Microservices Using Docker and Serfnode,"We review container technology and the challenge of service discovery in micro service architectures and introduce Serf node, a fully decentralized open source solution to the service discovery problem, based on the Serf project. Serf node is a non-intrusive Docker image that composes one or more arbitrary Docker containers. The new images can be deployed into a cluster of Serf nodes, where it advertises itself and provides service discovery mechanisms, monitoring, and self-healing. The resulting cluster is a homogeneous and complete graph, with no master node. We survey existing solutions to the service discovery problem and compare them to Serf node. As an example of the extensibility of Serf node, we show the construction of a file system synchronization solution between Docker containers using Git.","Containers,
Monitoring,
Computer architecture,
Servers,
Synchronization,
Protocols,
Complexity theory"
Design of an Ultra-low Voltage 9T SRAM With Equalized Bitline Leakage and CAM-Assisted Energy Efficiency Improvement,This paper presents a 9T multi-threshold (MTCMOS) SRAM macro with equalized bitline leakage and a content-addressable-memory-assisted (CAM-assisted) write performance boosting technique for energy efficiency improvement. A 3T-based read port is proposed to equalize read bitline (RBL) leakage and to improve RBL sensing margin by eliminating data-dependence on bitline leakage current. A miniature CAM-assisted circuit is integrated to conceal the slow data development with HVT devices after data flipping in write operation and therefore enhance the write performance for energy efficiency. A 16 kb SRAM test chip is fabricated in 65 nm CMOS technology. The operating voltage of the test chip is scalable from 1.2 V down to 0.26 V with the read access time from 6 ns to 0.85 μs. Minimum energy of 2.07 pJ is achieved at 0.4 V with 40.3% improvement compared to the SRAM without the aid of the CAM. Energy efficiency is enhanced by 29.4% between 0.38 V ~ 0.6 V by the proposed CAM-assisted circuit.,"Delays,
Computer aided manufacturing,
Arrays,
SRAM cells,
Sensors,
Leakage currents"
Entanglement Sampling and Applications,"A natural measure for the amount of quantum information that a physical system E holds about another system A = A1, .. . , An is given by the min-entropy Hmin(A|E). In particular, the min-entropy measures the amount of entanglement between E and A, and is the relevant measure when analyzing a wide variety of problems ranging from randomness extraction in quantum cryptography, decoupling used in channel coding, to physical processes such as thermalization or the thermodynamic work cost (or gain) of erasing a quantum system. As such, it is a central question to determine the behavior of the minentropy after some process M. is applied to the system A. Here, we introduce a new generic tool relating the resulting min-entropy to the original one, and apply it to several settings of interest. A simple example of such a process is the one of sampling, where a subset S of the systems A1, ... , An is selected at random. Our tool allows us to quantify the entanglement that E has with the selected systems AS, i.e., Hmin(AS|ES) as a function of the original Hmin(A|E). We give two applications of this result. First, it directly provides the first local quantum-to-classical randomness extractors for use in quantum cryptography, as well as decoupling operations acting on only a small fraction AS of the input A. Moreover, it gives lower bounds on the dimension of k-out-of-n fully quantum random access encodings. Another natural example of such a process is a measurement in, e.g., BB84 bases commonly used in quantum cryptography. We establish the first entropic uncertainty relations with quantum side information that are nontrivial whenever E is not maximally entangled with A. As a consequence, we are able to prove optimality of quantum cryptographic schemes in the noisy-storage model. This model allows for the secure implementation of two-party cryptographic primitives under the assumption that the adversary cannot store quantum information perfectly. A special case is the bounded-quantum-storage model (BQSM), which assumes that the adversary's quantum memory device is noise free but limited in size. Ever since the inception of the BQSM, it has been a vexing open question to determine whether the security is possible as long as the adversary can only.","Quantum entanglement,
Noise measurement,
Cryptography,
Entropy,
Protocols"
Learning Balanced and Unbalanced Graphs via Low-Rank Coding,"Graphs have been widely applied in modeling the relationships and structures in real-world applications. Graph construction is the most critical part in these models, while how to construct an effective graph is still an open problem. In this paper, we propose a novel approach to graph construction based on two observations. First, by virtue of recent advances in low-rank subspace recovery, the similarity between every two samples evaluated in the low-rank code space is more robust than that in the sample space. Second, a sparse and balanced graph can greatly increase the performance of learning tasks, such as label propagation in graph based semi-supervised learning. The k-NN sparsification can provide fast solutions to constructing unbalanced sparse graphs, and b-matching constraint is a necessary route for generating balanced graphs. These observations motivate us to jointly learn the low-rank codes and balanced (or unbalanced) graph simultaneously. In particular, two non-convex models are built by incorporating k-NN constraint and b-matching constraint into the low-rank representation model, respectively. We design a majorization-minimization augmented Lagrange multiplier (MM-ALM) algorithm to solve the proposed models. Extensive experimental results on four image databases demonstrate the superiority of our graphs over several state-of-the-art graphs in data clustering, transductive and inductive semi-supervised learning.","Measurement,
Semisupervised learning,
Sparse matrices,
Data models,
Algorithm design and analysis,
Linear programming,
Optimization"
JOTS: Joint Online Tracking and Segmentation,"We present a novel Joint Online Tracking and Segmentation (JOTS) algorithm which integrates the multi-part tracking and segmentation into a unified energy optimization framework to handle the video segmentation task. The multi-part segmentation is posed as a pixel-level label assignment task with regularization according to the estimated part models, and tracking is formulated as estimating the part models based on the pixel labels, which in turn is used to refine the model. The multi-part tracking and segmentation are carried out iteratively to minimize the proposed objective function by a RANSAC-style approach. Extensive experiments on the SegTrack and SegTrack v2 databases demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods.","Labeling,
Target tracking,
Computational modeling,
Image segmentation,
Minimization,
Motion segmentation"
Improving transient stability of photovoltaic-hydro microgrids using virtual synchronous machines,"Transient stability of photovoltaic-hydro microgrid systems is poor due to lack of inertia and the intermittent nature of photovoltaic systems. The stability of such systems can be improved by using virtual synchronous machines which add inertia into the system to allow for higher PV penetration without losing stability. A PV-hydro system was simulated in MATLAB/Simulink to analyze the transient stability problems due to PV fluctuations and/or load or generation changes. Virtual synchronous machine was added which reduced the frequency deviations and the high rate of change of frequency. The results indicate that the transient stability of photovoltaic-hydro microgrid systems can be improved by using virtual synchronous machines using a minimum amount of energy storage. However, the power requirements of the virtual synchronous machine's converter was found to be high compared to the overall system size. Furthermore, high PV penetration levels were achieved by adding virtual synchronous machine to the system.","Microgrids,
Transient analysis,
Power system stability,
Damping,
Benchmark testing,
Stability analysis"
Fast LIDAR localization using multiresolution Gaussian mixture maps,"This paper reports on a fast multiresolution scan matcher for vehicle localization in urban environments for self-driving cars. State-of-the-art approaches to vehicle localization rely on observing road surface reflectivity with a three-dimensional (3D) light detection and ranging (LIDAR) scanner to achieve centimeter-level accuracy. However, these approaches can often fail when faced with adverse weather conditions that obscure the view of the road paint (e.g., puddles and snowdrifts) or poor road surface texture. We propose a new scan matching algorithm that leverages Gaussian mixture maps to exploit the structure in the environment; these maps are a collection of Gaussian mixtures over the z-height distribution. We achieve real-time performance by developing a novel branch-and-bound, multiresolution approach that makes use of rasterized lookup tables of these Gaussian mixtures. Results are shown on two datasets that are 3.0 km: a standard trajectory and another under adverse weather conditions.",
Spatial Coherence-Based Batch-Mode Active Learning for Remote Sensing Image Classification,"Batch-mode active learning (AL) approaches are dedicated to the training sample set selection for classification, regression, and retrieval problems, where a batch of unlabeled samples is queried at each iteration by considering both the uncertainty and diversity criteria. However, for remote sensing applications, the conventional methods do not consider the spatial coherence between the training samples, which will lead to the unnecessary cost. Based on the above two points, this paper proposes a spatial coherence-based batch-mode AL method. First, mean shift clustering is used for the diversity criterion, and thus the number of new queries can be varied in the different iterations. Second, the spatial coherence is represented by a two-level segmentation map which is used to automatically label part of the new queries. To get a stable and correct second-level segmentation map, a new merging strategy is proposed for the mean shift segmentation. The experimental results with two real remote sensing image data sets confirm the effectiveness of the proposed techniques, compared with the other state-of-the-art methods.","Uncertainty,
Training,
Labeling,
Merging,
Image segmentation,
Redundancy,
Remote sensing"
When smart grid meets geo-distributed cloud: An auction approach to datacenter demand response,"Datacenter demand response is envisioned as a promising tool for mitigating operational stability issues faced by smart grids. It enables significant potentials in peak load reduction and facilitates the incorporation of distributed generation. Monetary refund from the smart grid can also alleviate the cloud's burden in escalating electricity cost. However, the current demand response paradigm is inefficient towards incentivizing a cloud that runs over geo-distributed datacenters. Leveraging auction theory, this work presents an efficient incentive mechanism to elicit demand response from geo-distributed clouds. To determine the winning bids and their corresponding payments, the cloud that acts as the auctioneer needs to solve a set of winner determination problems that are highly challenging. By integrating techniques from the Gibbs sampling method and the alternating direction method of multipliers, we propose a decentralized algorithm for each datacenter to make autonomous decisions on winning bid selection and workload management, striking a balance among the economic efficiency, truthfulness and the computational efficiency. Through extensive trace-driven evaluations, we demonstrate that our incentive mechanism constitutes a win-win mechanism for both the geo-distributed cloud and the smart grid.",
TASC:Topic-Adaptive Sentiment Classification on Dynamic Tweets,"Sentiment classification is a topic-sensitive task, i.e., a classifier trained from one topic will perform worse on another. This is especially a problem for the tweets sentiment analysis. Since the topics in Twitter are very diverse, it is impossible to train a universal classifier for all topics. Moreover, compared to product review, Twitter lacks data labeling and a rating mechanism to acquire sentiment labels. The extremely sparse text of tweets also brings down the performance of a sentiment classifier. In this paper, we propose a semi-supervised topic-adaptive sentiment classification (TASC) model, which starts with a classifier built on common features and mixed labeled data from various topics. It minimizes the hinge loss to adapt to unlabeled data and features including topic-related sentiment words, authors' sentiments and sentiment connections derived from“@” mentions of tweets, named as topic-adaptive features. Text and non-text features are extracted and naturally split into two views for co-training. The TASC learning algorithm updates topic-adaptive features based on the collaborative selection of unlabeled data, which in turn helps to select more reliable tweets to boost the performance. We also design the adapting model along a timeline (TASC-t) for dynamic tweets. An experiment on 6 topics from published tweet corpuses demonstrates that TASC outperforms other well-known supervised and ensemble classifiers. It also beats those semi-supervised learning methods without feature adaption. Meanwhile, TASC-t can also achieve impressive accuracy and F-score. Finally, with timeline visualization of “river” graph, people can intuitively grasp the ups and downs of sentiments' evolvement, and the intensity by color gradation.","Feature extraction,
Twitter,
Adaptation models,
Support vector machines,
Sentiment analysis,
Data visualization,
Google"
Integrative Data Analysis of Multi-Platform Cancer Data with a Multimodal Deep Learning Approach,"Identification of cancer subtypes plays an important role in revealing useful insights into disease pathogenesis and advancing personalized therapy. The recent development of high-throughput sequencing technologies has enabled the rapid collection of multi-platform genomic data (e.g., gene expression, miRNA expression, and DNA methylation) for the same set of tumor samples. Although numerous integrative clustering approaches have been developed to analyze cancer data, few of them are particularly designed to exploit both deep intrinsic statistical properties of each input modality and complex cross-modality correlations among multi-platform input data. In this paper, we propose a new machine learning model, called multimodal deep belief network (DBN), to cluster cancer patients from multi-platform observation data. In our integrative clustering framework, relationships among inherent features of each single modality are first encoded into multiple layers of hidden variables, and then a joint latent model is employed to fuse common features derived from multiple input modalities. A practical learning algorithm, called contrastive divergence (CD), is applied to infer the parameters of our multimodal DBN model in an unsupervised manner. Tests on two available cancer datasets show that our integrative data analysis approach can effectively extract a unified representation of latent features to capture both intra- and cross-modality correlations, and identify meaningful disease subtypes from multi-platform cancer data. In addition, our approach can identify key genes and miRNAs that may play distinct roles in the pathogenesis of different cancer subtypes. Among those key miRNAs, we found that the expression level of miR-29a is highly correlated with survival time in ovarian cancer patients. These results indicate that our multimodal DBN based data analysis approach may have practical applications in cancer pathogenesis studies and provide useful guidelines for personalized cancer therapy.","Cancer,
Bioinformatics,
Genomics,
Data models,
Data analysis,
Computational biology,
DNA"
"Conditional Diagnosability of (n,k)
-Star Networks Under the Comparison Diagnosis Model","The (n,k)-star graph, denoted by Sn,k, is an enhanced version of n-dimensional star graphs Sn, that has better scalability than Sn, and possesses several good properties, compared with hypercubes. Diagnosis has been one of the most important issues for maintaining multiprocessor-system reliability. Conditional diagnosability, which is more general than classical diagnosability, measures the multiprocessor-system diagnosability under the assumption that all neighbors of any processor in the system cannot fail simultaneously. In this paper, we investigate the conditional diagnosability of Sn,k for ( n ≥ 3 and k=1) and ( n ≥ 4 and 2 ≤ k ≤ n) under the comparison diagnosis model.","Multiprocessing systems,
Hypercubes,
Fault diagnosis,
Computer science,
Educational institutions"
Variability Aware Simulation Based Design- Technology Cooptimization (DTCO) Flow in 14 nm FinFET/SRAM Cooptimization,"In this paper, we use an automated tool flow in a 14 nm CMOS fin-shaped field-effect transistor (FinFET)/ static random access memory (SRAM) simulation-based design-technology cooptimization (DTCO) including both process-induced and intrinsic statistical variabilities. A 22 nm FinFET CMOS technology is used to illustrate the sensitivity to process-induced fin shape variation and to motivate this paper. Predictive Technology Computer Aided Design (TCAD) simulations have been carried out to evaluate the transistor performance ahead of silicon. Draft-diffusion simulations calibrated to the ensemble Monte Carlo simulation results are used to explore the process and the statistical variability space. This has been enabled by the automation of the tool flow and the dataset handling. The interplay between the process and the statistical variability has been examined in details. A two-stage compact model strategy is used to capture the interplay between process and statistical variability. To close the DTCO loop, the static noise margin and write noise margin sensitivity to cell design parameters and variability in FinFET-based SRAM designs are studied in details.",
Video Affective Content Analysis: A Survey of State-of-the-Art Methods,"Video affective content analysis has been an active research area in recent decades, since emotion is an important component in the classification and retrieval of videos. Video affective content analysis can be divided into two approaches: direct and implicit. Direct approaches infer the affective content of videos directly from related audiovisual features. Implicit approaches, on the other hand, detect affective content from videos based on an automatic analysis of a user's spontaneous response while consuming the videos. This paper first proposes a general framework for video affective content analysis, which includes video content, emotional descriptors, and users' spontaneous nonverbal responses, as well as the relationships between the three. Then, we survey current research in both direct and implicit video affective content analysis, with a focus on direct video affective content analysis. Lastly, we identify several challenges in this field and put forward recommendations for future research.",
Toward Automating Clinical Assessments: A Survey of the Timed Up and Go,"Older adults often suffer from functional impairments that affect their ability to perform everyday tasks. To detect the onset and changes in abilities, healthcare professionals administer standardized assessments. Recently, technology has been utilized to complement these clinical assessments to gain a more objective and detailed view of functionality. In the clinic and at home, technology is able to provide more information about patient performance and reduce subjectivity in outcome measures. The timed up and go (TUG) test is one such assessment recently instrumented with technology in several studies, yielding promising results toward the future of automating clinical assessments. Potential benefits of technological TUG implementations include additional performance parameters, generated reports, and the ability to be self-administered in the home. In this paper, we provide an overview of the TUG test and technologies utilized for TUG instrumentation. We then critically review the technological advancements and follow up with an evaluation of the benefits and limitations of each approach. Finally, we analyze the gaps in the implementations and discuss challenges for future research toward automated self-administered assessment in the home.",
Memristor-based linear feedback shift register based on material implication logic,Memristor as an emerging history dependent nanometer scaled element will play an important role in future nanoelectronic computing technologies. Some pure and hybrid memristor-based implementation techniques have been proposed in recent years. Material implication logic is one of the significant areas for memristor-based logic implementation. In this paper a memristor-based linear feedback shift register is implemented based on material implication logic. It is implemented by 8 memristors which is considerably used less area in comparison with conventional CMOS-based peers. Also the proposed memristor-based LFSR circuit needs 55 computational steps for generating a 4-bits number.,"Memristors,
Logic gates,
CMOS integrated circuits,
Resistance,
Linear feedback shift registers,
Computer architecture,
CMOS technology"
Malware Propagation in Large-Scale Networks,"Malware is pervasive in networks, and poses a critical threat to network security. However, we have very limited understanding of malware behavior in networks to date. In this paper, we investigate how malware propagates in networks from a global perspective. We formulate the problem, and establish a rigorous two layer epidemic model for malware propagation from network to network. Based on the proposed model, our analysis indicates that the distribution of a given malware follows exponential distribution, power law distribution with a short exponential tail, and power law distribution at its early, late and final stages, respectively. Extensive experiments have been performed through two real-world global scale malware data sets, and the results confirm our theoretical findings.","Malware,
Mathematical model,
Computational modeling,
Educational institutions,
Recruitment,
Mobile communication,
Internet"
A highly efficient method for blind image quality assessment,"Blind image quality assessment (BIQA) has attracted a great deal of attention due to the increasing demand in industry and the promising recent progress in academia. To bridge the gap between academic research accomplishment and industrial needs, high efficiency BIQA approaches that allow for real-time computation are highly desirable. In this paper, we propose a novel BIQA method by selecting statistical features extracted from binary patterns of local image structures. This allows us to largely reduce the feature space to eventually one dimension. Somewhat surprisingly, such a single feature, faster-than-real-time approach named local pattern statistics index (LPSI) exhibits impressive generalization ability across different distortion types and achieves competitive quality prediction performance in comparison with state-of-the-art approaches on public databases such as LIVE II and TID2008.",
"STAR: Strategy-Proof Double Auctions for Multi-Cloud, Multi-Tenant Bandwidth Reservation","Bandwidth reservation has been recognized as a value-added service to the cloud provider in recent years. We consider an open market of cloud bandwidth reservation, in which cloud providers offer bandwidth reservation services to cloud tenants, especially online streaming service providers, who have strict requirements on the amount of bandwidth to guarantee their quality of services. In this paper, we model the open market as a double-sided auction, and propose the first family of STrategy-proof double Auctions for multi-cloud, multi-tenant bandwidth Reservation (STAR). STAR contains two auction mechanisms. The first one, STAR-Grouping, divides the tenants into groups by a bid-independent way, and carefully matches the cloud providers with the tenant groups to form good trades. The second one, STAR-Padding, greedily matches the cloud providers with the tenants, and fills the partially reserved cloud provider(s) with a novel virtual padding tenant who can be a component of the auctioneer. Our analysis shows that both of the two auction mechanisms achieve strategy-proofness and ex-post budget balance. Our evaluation results show that they achieve good performance in terms of social welfare, cloud bandwidth utilization, and tenant satisfaction ratio.",
Development of a Wearable Sensing Glove for Measuring the Motion of Fingers Using Linear Potentiometers and Flexible Wires,"In this paper, a wearable sensing glove for measuring the motion of the fingers is proposed. The system consists of linear potentiometers, flexible wires, and linear springs, which makes it compact and lightweight so that it does not interfere with the natural motion of the fingers. Inspired by the way wrinkles on finger joints are smoothed out when the finger is flexed, a flexible wire is attached to the back of each finger. As the flexible wire moves due to the motion of the finger, the joint angles are calculated by measuring the change in length of wire. Linear potentiometers with linear springs were used to maintain the tension of the wires in order to measure the wire length change consistently. Because the motion of the proximal interphalangeal (PIP) joint is dependent on that of the distal interphalangeal (DIP) joint, only two linear potentiometers were used for each finger. A compact sensing module including 10 linear potentiometers and springs was attached to a glove. The proposed system can widely be applied for the systems, which require to measure finger motions accurately, e.g., virtual reality or teleoperation systems. Such feasible applications were actually implemented and introduced in this paper.",
Stereo parallel tracking and mapping for robot localization,"This paper describes a visual SLAM system based on stereo cameras and focused on real-time localization for mobile robots. To achieve this, it heavily exploits the parallel nature of the SLAM problem, separating the time-constrained pose estimation from less pressing matters such as map building and refinement tasks. On the other hand, the stereo setting allows to reconstruct a metric 3D map for each frame of stereo images, improving the accuracy of the mapping process with respect to monocular SLAM and avoiding the well-known bootstrapping problem. Also, the real scale of the environment is an essential feature for robots which have to interact with their surrounding workspace. A series of experiments, on-line on a robot as well as off-line with public datasets, are performed to validate the accuracy and real-time performance of the developed method.","Cameras,
Simultaneous localization and mapping,
Robot vision systems,
Feature extraction,
Visualization"
Partially Parallel Encoder Architecture for Long Polar Codes,"Due to the channel achieving property, the polar code has become one of the most favorable error-correcting codes. As the polar code achieves the property asymptotically, however, it should be long enough to have a good error-correcting performance. Although the previous fully parallel encoder is intuitive and easy to implement, it is not suitable for long polar codes because of the huge hardware complexity required. In this brief, we analyze the encoding process in the viewpoint of very-large-scale integration implementation and propose a new efficient encoder architecture that is adequate for long polar codes and effective in alleviating the hardware complexity. As the proposed encoder allows high-throughput encoding with small hardware complexity, it can be systematically applied to the design of any polar code and to any level of parallelism.",
Parallel Reproducible Summation,"Reproducibility, i.e. getting bitwise identical floating point results from multiple runs of the same program, is a property that many users depend on either for debugging or correctness checking in many codes [10]. However, the combination of dynamic scheduling of parallel computing resources, and floating point nonassociativity, makes attaining reproducibility a challenge even for simple reduction operations like computing the sum of a vector of numbers in parallel. We propose a technique for floating point summation that is reproducible independent of the order of summation. Our technique uses Rump's algorithm for error-free vector transformation [7], and is much more efficient than using (possibly very) high precision arithmetic. Our algorithm reproducibly computes highly accurate results with an absolute error bound of n · 2-28 macheps maxiIviI at a cost of 7n FLOPs and a small constant amount of extra memory usage. Higher accuracies are also possible by increasing the number of error-free transformations. As long as all operations are performed in to-nearest rounding mode, results computed by the proposed algorithms are reproducible for any run on any platform. In particular, our algorithm requires the minimum number of reductions, i.e. one reduction of an array of six double precision floating point numbers per sum, and hence is well suited for massively parallel environments.","Vectors,
Program processors,
Accuracy,
Standards,
Algorithm design and analysis,
Numerical analysis,
Computational modeling"
Feature Selection via Global Redundancy Minimization,"Feature selection has been an important research topic in data mining, because the real data sets often have high-dimensional features, such as the bioinformatics and text mining applications. Many existing filter feature selection methods rank features by optimizing certain feature ranking criterions, such that correlated features often have similar rankings. These correlated features are redundant and don't provide large mutual information to help data mining. Thus, when we select a limited number of features, we hope to select the top non-redundant features such that the useful mutual information can be maximized. In previous research, Ding et al. recognized this important issue and proposed the minimum Redundancy Maximum Relevance Feature Selection (mRMR) model to minimize the redundancy between sequentially selected features. However, this method used the greedy search, thus the global feature redundancy wasn't considered and the results are not optimal. In this paper, we propose a new feature selection framework to globally minimize the feature redundancy with maximizing the given feature ranking scores, which can come from any supervised or unsupervised methods. Our new model has no parameter so that it is especially suitable for practical data mining application. Experimental results on benchmark data sets show that the proposed method consistently improves the feature selection results compared to the original methods. Meanwhile, we introduce a new unsupervised global and local discriminative feature selection method which can be unified with the global feature redundancy minimization framework and shows superior performance.","Redundancy,
Minimization,
Data mining,
Correlation,
Optimization,
Mutual information,
Computational efficiency"
Learning Efficient Sparse and Low Rank Models,"Parsimony, including sparsity and low rank, has been shown to successfully model data in numerous machine learning and signal processing tasks. Traditionally, such modeling approaches rely on an iterative algorithm that minimizes an objective function with parsimony-promoting terms. The inherently sequential structure and data-dependent complexity and latency of iterative optimization constitute a major limitation in many applications requiring real-time performance or involving large-scale data. Another limitation encountered by these modeling techniques is the difficulty of their inclusion in discriminative learning scenarios. In this work, we propose to move the emphasis from the model to the pursuit algorithm, and develop a process-centric view of parsimonious modeling, in which a learned deterministic fixed-complexity pursuit process is used in lieu of iterative optimization. We show a principled way to construct learnable pursuit process architectures for structured sparse and robust low rank models, derived from the iteration of proximal descent algorithms. These architectures learn to approximate the exact parsimonious representation at a fraction of the complexity of the standard optimization methods. We also show that appropriate training regimes allow to naturally extend parsimonious models to discriminative settings. State-of-the-art results are demonstrated on several challenging problems in image and audio processing with several orders of magnitude speed-up compared to the exact optimization algorithms.","Data models,
Dictionaries,
Vectors,
Robustness,
Computational modeling,
Encoding,
Optimization"
WizBee: Wise ZigBee Coexistence via Interference Cancellation with Single Antenna,"Coexistence of Wi-Fi and ZigBee in 2.4 GHz ISM band is a long standing and challenging problem. Previous solutions either require modifications of current ZigBee protocols or Wi-Fi re-configurations, which is not feasible in large-scale wireless sensor networks. In this paper, we present WizBee, a coexistence system using single-antenna sink without changing current Wi-Fi and ZigBee design. WizBee is based on an observation that Wi-Fi signal is about 5 to 20 dB stronger than ZigBee signal in symmetric area, which leaves much room for applying interference cancelation technique to mitigate Wi-Fi interference, and extract ZigBee signals. However, we need to cancel the Wi-Fi interference perfectly for residual ZigBee signal decoding, which needs more accurate channel coefficient across data transmissions in spite of cross technology interference. For robust and accurate Wi-Fi decoding, we use soft Viterbi decoding with weighted confidence value over interfered subcarriers. Consequently, our solution uses decoded data for channel coefficient estimation instead of conventional training symbol based methods. The key insight is that, the signal recovery opportunity for cross technology coexistence, lies in multi-domain information, such as power, frequency and coding discrepancies. Using these information properly will improve the coexistence network throughput effectively. We implemented WizBee in USRP/GNURadio software radio platform, and studied the decoding performance of interference cancelation technique. Our extensive evaluations under real wireless conditions show that WizBee improves ZigBee throughput up to 1.9x, with median throughput gain of 1.2x.","IEEE 802.11 Standards,
Zigbee,
Interference,
Decoding,
Channel estimation,
Mobile computing,
Antennas"
An Integrated Dynamic Voltage Restorer-Ultracapacitor Design for Improving Power Quality of the Distribution Grid,"Cost of various energy storage technologies is decreasing rapidly and the integration of these technologies into the power grid is becoming a reality with the advent of smart grid. Dynamic voltage restorer (DVR) is one product that can provide improved voltage sag and swell compensation with energy storage integration. Ultracapacitors (UCAP) have low-energy density and high-power density ideal characteristics for compensation of voltage sags and voltage swells, which are both events that require high power for short spans of time. The novel contribution of this paper lies in the integration of rechargeable UCAP-based energy storage into the DVR topology. With this integration, the UCAP-DVR system will have active power capability and will be able to independently compensate temporary voltage sags and swells without relying on the grid to compensate for faults on the grid like in the past. UCAP is integrated into dc-link of the DVR through a bidirectional dc-dc converter, which helps in providing a stiff dc-link voltage, and the integrated UCAP-DVR system helps in compensating temporary voltage sags and voltage swells, which last from 3 s to 1 min. Complexities involved in the design and control of both the dc-ac inverter and the dc-dc converter are discussed. The simulation model of the overall system is developed and compared to the experimental hardware setup.","Voltage fluctuations,
Inverters,
Voltage control,
Energy storage,
Power quality,
Power conversion"
Digital Topology and Geometry in Medical Imaging: A Survey,"Digital topology and geometry refers to the use of topologic and geometric properties and features for images defined in digital grids. Such methods have been widely used in many medical imaging applications, including image segmentation, visualization, manipulation, interpolation, registration, surface-tracking, object representation, correction, quantitative morphometry etc. Digital topology and geometry play important roles in medical imaging research by enriching the scope of target outcomes and by adding strong theoretical foundations with enhanced stability, fidelity, and efficiency. This paper presents a comprehensive yet compact survey on results, principles, and insights of methods related to digital topology and geometry with strong emphasis on understanding their roles in various medical imaging applications. Specifically, this paper reviews methods related to distance analysis and path propagation, connectivity, surface-tracking, image segmentation, boundary and centerline detection, topology preservation and local topological properties, skeletonization, and object representation, correction, and quantitative morphometry. A common thread among the topics reviewed in this paper is that their theory and algorithms use the principle of digital path connectivity, path propagation, and neighborhood analysis.",
A Miniaturized Wide-Beamwidth Circularly Polarized Planar Antenna via Two Pairs of Folded Dipoles in a Square Contour,"A circularly polarized (CP) antenna with a wide axial-ratio (AR) beamwidth is presented by placing the two pairs of folded dipoles in a square contour. First, our study demonstrates that the CP radiation can be achieved at the broadside by setting a 90° phase difference between the verticaland horizontal-paired folded dipole radiators. Second, a radiation pattern subtraction approach is presented to explain how the radiation beamwidth of the paired folded dipoles could be appropriately widened or narrowed according to the radiation pattern subtraction of two opposite electric current densities in the folded dipoles. Using this approach, the E-plane beamwidth of a pair of folded dipoles is made certainly widened, whereas its H-plane counterpart becomes narrowed. On this basis, theEand H-plane radiation patterns can still be made approximately identical with each other over a wide range of polar angle, even though the distance between dipoles is deliberately shortened. As such, the desired CP antenna with shortened dipole-to-dipole distance and unaffected wide AR beamwidth can be achieved using two pairs of parallel folded dipoles with shortened distance between them instead of linear dipoles in [24]. Finally, a CP printed antenna is designed and fabricated on a single dielectric substrate. Experimental results are found in good agreement with the simulated ones in terms of radiation patterns, gain, AR, efficiency, and reflection coefficient. In particular, the 3-dB AR beamwidth at the central frequency of 1.6 GHz is extended to 135° at XZ-plane and 142° at YZ-plane. Moreover, the overall size of the constituted CP antenna with folded dipoles is decreased to 0.43 λ0 × 0.43 λ0 (λ0 is the wavelength in free space).",
How Much Control is Enough for Network Connectivity Preservation and Collision Avoidance?,"For a multiagent system in free space, the agents are required to generate sufficiently large cohesive force for network connectivity preservation and sufficiently large repulsive force for collision avoidance. This paper gives an energy function based approach for estimating the control force in a general setting. In particular, the force estimated for network connectivity preservation and collision avoidance is separated from the force for other collective behavior of the agents. Moreover, the estimation approach is applied in three typical collective control scenarios including swarming, flocking, and flocking without velocity measurement.",
Safeguarding massive MIMO aided hetnets using physical layer security,"This paper exploits the potential of physical layer security in massive multiple-input multiple-output (MIMO) aided two-tier heterogeneous networks (HetNets). We focus on the downlink secure transmission in the presence of multiple eavesdroppers. We first address the impact of massive MIMO on the maximum receive power based user association. We then derive the tractable upper bound expressions for the secrecy outage probability of a HetNets user. We show that the implementation of massive MIMO significantly improves the secrecy performance, which indicates that physical layer security could be a promising solution for safeguarding massive MIMO HetNets. Furthermore, we show that the secrecy outage probability of HetNets user first degrades and then improves with increasing the density of PBSs.","MIMO,
Fading,
Security,
Macrocell networks,
Physical layer,
Downlink,
Base stations"
An Underwater Color Image Quality Evaluation Metric,"Quality evaluation of underwater images is a key goal of underwater video image retrieval and intelligent processing. To date, no metric has been proposed for underwater color image quality evaluation (UCIQE). The special absorption and scattering characteristics of the water medium do not allow direct application of natural color image quality metrics especially to different underwater environments. In this paper, subjective testing for underwater image quality has been organized. The statistical distribution of the underwater image pixels in the CIELab color space related to subjective evaluation indicates the sharpness and colorful factors correlate well with subjective image quality perception. Based on these, a new UCIQE metric, which is a linear combination of chroma, saturation, and contrast, is proposed to quantify the non-uniform color cast, blurring, and low-contrast that characterize underwater engineering and monitoring images. Experiments are conducted to illustrate the performance of the proposed UCIQE metric and its capability to measure the underwater image enhancement results. They show that the proposed metric has comparable performance to the leading natural color image quality metrics and the underwater grayscale image quality metrics available in the literature, and can predict with higher accuracy the relative amount of degradation with similar image content in underwater environments. Importantly, UCIQE is a simple and fast solution for real-time underwater video processing. The effectiveness of the presented measure is also demonstrated by subjective evaluation. The results show better correlation between the UCIQE and the subjective mean opinion score.","Image color analysis,
Real-time systems,
Image quality,
Image enhancement,
Monitoring"
Passive Microwave Substrate Integrated Cavity Resonator for Humidity Sensing,"This paper presents an original passive microwave substrate integrated cavity resonator [substrate integrated waveguides (SIWs)] as an environment sensor for humidity detection. The proposed structures are based on a high quality factor (Q ~ 300) substrate integrated cavity resonator operating at 3.6 and 4.15 GHz. The detection principle is based on a frequency shift due to the permittivity variation of the humid air. This variation can be detected and used as the sensor indication. The frequency shift has been estimated analytically using the dielectric perturbation method for the resonator prototypes. The structure of the presented SIW resonators has been tested in the presence of humidity and shows sensitive characteristics in the range of 0%-80% relative humidity in accordance with the proposed model. A comparison of sensitivity performance between the new structure and other reported microwave components for environmental sensing is also presented. Measurements of repeatability and reliability for the proposed structure are discussed as well. As a new microwave component type, the proposed substrate integrated environmental sensor has the advantage of providing a new fabrication solution for radio frequency environmental sensing and greatly simplifies the sensor's manufacturing processes and cost.","Humidity,
Resonant frequency,
Microwave theory and techniques,
Substrates,
Sensors,
Dielectrics,
Cavity resonators"
Asymmetric Cyclical Hashing for Large Scale Image Retrieval,"This paper addresses a problem in the hashing technique for large scale image retrieval: learn a compact hash code to reduce the storage cost with performance comparable to that of the long hash code. A longer hash code yields a better precision rate of retrieved images. However, it also requires a larger storage, which limits the number of stored images. Current hashing methods employ the same code length for both queries and stored images. We propose a new hashing scheme using two hash codes with different lengths for queries and stored images, i.e., the asymmetric cyclical hashing. A compact hash code is used to reduce the storage requirement, while a long hash code is used for the query image. The image retrieval is performed by computing the Hamming distance of the long hash code of the query and the cyclically concatenated compact hash code of the stored image to yield a high precision and recall rate. Experiments on benchmarking databases consisting up to one million images show the effectiveness of the proposed method.","Image retrieval,
Hamming distance,
Kernel,
Euclidean distance,
Principal component analysis,
Internet"
A Fully Tunable Two-Pole Bandpass Filter,"In this letter, a two-pole tunable combline filter that allows for operational agility of the center frequency, passband bandwidth, and locations of upper and lower transmission zeros is proposed. To increase the tunable range of constant absolute-bandwidth for all frequency tuning states, a novel T-type bandwidth-control network was devised between resonators to flexibly tune the coupling coefficient without limitations imposed by the available varactor capacitance. By use of tunable source-load coupling, two tunable transmission zeros were produced on both sides of the passband to significantly improve filter selectivity and to dynamically afford interference suppression. A second-order 1.7-2.7 GHz filter with 1 dB constant bandwidth tuning from 50 to 110 MHz and transmission zero locations tuning from 300 to 700 MHz with respect to the passband was developed and fabricated. Good agreement was obtained between the simulated and experimental results.","Bandwidth,
Tuning,
Filtering theory,
Couplings,
Varactors,
Resonant frequency,
Frequency measurement"
First-person pose recognition using egocentric workspaces,"We tackle the problem of estimating the 3D pose of an individual's upper limbs (arms+hands) from a chest mounted depth-camera. Importantly, we consider pose estimation during everyday interactions with objects. Past work shows that strong pose+viewpoint priors and depth-based features are crucial for robust performance. In egocentric views, hands and arms are observable within a well defined volume in front of the camera. We call this volume an egocentric workspace. A notable property is that hand appearance correlates with workspace location. To exploit this correlation, we classify arm+hand configurations in a global egocentric coordinate frame, rather than a local scanning window. This greatly simplify the architecture and improves performance. We propose an efficient pipeline which 1) generates synthetic workspace exemplars for training using a virtual chest-mounted camera whose intrinsic parameters match our physical camera, 2) computes perspective-aware depth features on this entire volume and 3) recognizes discrete arm+hand pose classes through a sparse multi-class SVM. We achieve state-of-the-art hand pose recognition performance from egocentric RGB-D images in real-time.","Three-dimensional displays,
Cameras,
Joints,
Training,
Kinematics,
Support vector machines"
Multicore triangle computations without tuning,"Triangle counting and enumeration has emerged as a basic tool in large-scale network analysis, fueling the development of algorithms that scale to massive graphs. Most of the existing algorithms, however, are designed for the distributed-memory setting or the external-memory setting, and cannot take full advantage of a multicore machine, whose capacity has grown to accommodate even the largest of real-world graphs. This paper describes the design and implementation of simple and fast multicore parallel algorithms for exact, as well as approximate, triangle counting and other triangle computations that scale to billions of nodes and edges. Our algorithms are provably cache-friendly, easy to implement in a language that supports dynamic parallelism, such as Cilk Plus or OpenMP, and do not require parameter tuning. On a 40-core machine with two-way hyper-threading, our parallel exact global and local triangle counting algorithms obtain speedups of 17-50x on a set of real-world and synthetic graphs, and are faster than previous parallel exact triangle counting algorithms. We can compute the exact triangle count of the Yahoo Web graph (over 6 billion edges) in under 1.5 minutes. In addition, for approximate triangle counting, we are able to approximate the count for the Yahoo graph to within 99.6% accuracy in under 10 seconds, and for a given accuracy we are much faster than existing parallel approximate triangle counting implementations.",
Hybrid Modulation of Dual Inverter for Open-End Permanent Magnet Synchronous Motor,"This paper analyzes the dual inverter driven open-end permanent magnet synchronous motor (PMSM) system and proposes control method which can generate maximum output power in overall speed range for integrated starter/alternator. Dual inverter driven open-end machine system consists of two inverters which are connected to the both ends of the machine winding. By disconnecting one inverter from the power source, the dc-link voltage of flying capacitor can be boosted through the machine. Because one inverter is connected to the only power source, output power of the machine is regulated by the source connected inverter. In this paper, modulation method for maximizing output power of inverter and motor with reduced harmonic and loss is proposed. It is a hybrid modulation combining six-step and pulse width modulations. With proposed method, efficiency and operation area are improved and cost of entire driving system is also decreased due to the removing of dc-dc converter. Analyses, strategies, control method, and simulation results are descripted. The experiments with PMSM are accomplished to verify the feasibility of proposed method.","Inverters,
Modulation,
Capacitors,
Vectors,
Reactive power,
Voltage control,
Power generation"
Microfabrication Methods for Biodegradable Polymeric Carriers for Drug Delivery System Applications: A Review,"A drug delivery system is used for targeting drugs to specific cells. Various drug carriers, that also reduce the side effects of unbound drugs, have been introduced and commercialized in the pharmaceutical field. Among them, synthetic biodegradable polymers have received much attention attributed to their low toxicity, controllable biodegradation rates, manufacturability, and low costs. This paper reviews the salient characteristics of biodegradable polymers as drug carriers and their microfabrication methods. The reviewed microfabrication methods include laser micromachining, rapid prototyping, replication, emulsification, microfluidic fabrication, and X-ray-lithography-based methods. For these microfabrication methods, critical dimensions, feature variety, solvent compatibility, production throughput, and tooling requirements are also summarized.","Plastics,
Drugs,
Polymers,
Surface emitting lasers,
Microfabrication"
An odd-even model for diagnosis of shorts on NoC interconnects,"Interconnect shorts in a network-on-chip (NoC) have caused data overloading and misrouting that make an extra burden on performance metrics. Therefore, diagnosis of shorts on NoC interconnects has taken special interest. Existing works on diagnosis of shorts on NoC interconnects have two major issues-high test time and less scalability. This paper presents a distributed packet address driven test strategy that addresses shorts on NoC interconnects and tackles these issues. High test time is reduced significantly by lowering the test rounds. The scalability is established by applying proposed test strategy on different NoCs. Simulations achieve 100% test and fault coverages, and demonstrate impact of interconnect shorts for a subset of performance metrics in actual traffic in the network.","Wires,
Testing,
Routing,
Payloads,
Adaptation models,
Measurement,
Scalability"
A 240 GHz Fully Integrated Wideband QPSK Receiver in 65 nm CMOS,"Operation at millimeter-wave/sub-terahertz frequencies allows one to realize very high data-rate transceivers for wireless chip-to-chip communication. In this paper, a 240 GHz 16 Gbps QPSK receiver is demonstrated in 65 nm CMOS technology. The receiver employs a direct-conversion mixer-first architecture with an integrated slotted loop antenna. A 240 GHz LO chain drives the passive mixers to down-convert the modulated data to baseband. The baseband signal is then amplified using high gain, wide bandwidth amplifiers. The receiver has a noise figure of 15 dB with a conversion gain of 25 dB calculated from measurement data. The receiver achieves a data rate of 10 Gbps (with ) and a maximum data rate of 16 Gbps (with BER of 10-4) with a receiver efficiency of 16 pJ/bit.","Mixers,
Receivers,
Noise,
Baseband,
Gain,
CMOS integrated circuits,
Antennas"
Design of Single-Switch Inverters for Variable Resistance/Load Modulation Operation,"Single-Switch inverters such as the conventional Class-E inverter are often highly load sensitive, and maintain zero-voltage switching over only a narrow range of load resistances. This paper introduces a design methodology that enables rapid synthesis of Class E and related single-switch inverters that maintain ZVS operation over a wide range of resistive loads. We treat the design of Class-E inverters for variable resistance operation and show how the proposed methodology relates to circuit transformations on traditional Class-E designs. We also illustrate the use of this transformation approach to realize Φ2 inverters for variable-resistance operation. The proposed methodology is demonstrated and experimentally validated at 27.12 MHz in a Class E and Φ2 inverter designs that operate efficiently over 12:1 load resistance range for an 8:1 and 10:1 variation in output power, respectively, and a 25-W peak output power.","Inverters,
Resistance,
Modulation,
Zero voltage switching,
Switches,
Power generation,
Impedance"
Improving Privacy and Security in Decentralized Ciphertext-Policy Attribute-Based Encryption,"In previous privacy-preserving multiauthority attribute-based encryption (PPMA-ABE) schemes, a user can acquire secret keys from multiple authorities with them knowing his/her attributes and furthermore, a central authority is required. Notably, a user's identity information can be extracted from his/her some sensitive attributes. Hence, existing PPMA-ABE schemes cannot fully protect users' privacy as multiple authorities can collaborate to identify a user by collecting and analyzing his attributes. Moreover, ciphertext-policy ABE (CP-ABE) is a more efficient public-key encryption, where the encryptor can select flexible access structures to encrypt messages. Therefore, a challenging and important work is to construct a PPMA-ABE scheme where there is no necessity of having the central authority and furthermore, both the identifiers and the attributes can be protected to be known by the authorities. In this paper, a privacy-preserving decentralized CP-ABE (PPDCP-ABE) is proposed to reduce the trust on the central authority and protect users' privacy. In our PPDCP-ABE scheme, each authority can work independently without any collaboration to initial the system and issue secret keys to users. Furthermore, a user can obtain secret keys from multiple authorities without them knowing anything about his global identifier and attributes.",
An FPGA-Based Multicore System for Real-Time Bearing Fault Diagnosis Using Ultrasampling Rate AE Signals,"The demand for online fault diagnosis has recently increased in order to prevent severe unexpected failures in machinery. To address this issue, this paper first proposes a comprehensive bearing fault diagnosis algorithm, which consists of fault signature extraction through time-frequency analysis and one-against-all multiclass support vector machines in order to make reliable decisions. In addition, acoustic emission (AE) signals sampled at 1 MHz are used for the early identification of bearing failures. Despite the fact that the proposed fault diagnosis methodology shows satisfactory classification accuracy, its computation complexity limits its use in real-time applications. Therefore, this paper also presents a high-performance multicore architecture, including 64 processing elements operating at 50 MHz in a Xilinx Virtex-7 field-programmable gate array device to support online fault diagnosis. The experimental results indicate that the multicore approach executes 1339.3x and 1293.1x faster than the high-performance Texas Instrument (TI) TMS320C6713 and TMS320C6748 digital signal processors (DSPs), respectively, by exploiting the massive parallelism inherent in the bearing fault diagnosis algorithm. In addition, the multicore approach outperforms the equivalent sequential approach that runs on the TI DSPs by substantially reducing the energy consumption.","Fault diagnosis,
Support vector machines,
Computer architecture,
Machinery,
Accuracy,
Discrete wavelet transforms,
Real-time systems"
A Query Approach for Influence Maximization on Specific Users in Social Networks,"Influence maximization is introduced to maximize the profit of viral marketing in social networks. The weakness of influence maximization is that it does not distinguish specific users from others, even if some items can be only useful for the specific users. For such items, it is a better strategy to focus on maximizing the influence on the specific users. In this paper, we formulate an influence maximization problem as query processing to distinguish specific users from others. We show that the query processing problem is NP-hard and its objective function is submodular. We propose an expectation model for the value of the objective function and a fast greedy-based approximation method using the expectation model. For the expectation model, we investigate a relationship of paths between users. For the greedy method, we work out an efficient incremental updating of the marginal gain to our objective function. We conduct experiments to evaluate the proposed method with real-life datasets, and compare the results with those of existing methods that are adapted to the problem. From our experimental results, the proposed method is at least an order of magnitude faster than the existing methods in most cases while achieving high accuracy.",
Hiding information in noise: fundamental limits of covert wireless communication,"Widely deployed encryption-based security prevents unauthorized decoding, but does not ensure undetectability of communication. However, covert, or low probability of detection/intercept communication is crucial in many scenarios ranging from covert military operations and the organization of social unrest, to privacy protection for users of wireless networks. In addition, encrypted data or even just the transmission of a signal can arouse suspicion, and even the most theoretically robust encryption can often be defeated by a determined adversary using non-computational methods such as side-channel analysis. Various covert communication techniques have been developed to address these concerns, including steganography for finite-alphabet noiseless applications and spread-spectrum systems for wireless communications. After reviewing these covert communication systems, this article discusses new results on the fundamental limits of their capabilities, and provides a vision for the future of such systems as well.","OFDM,
Cryptography,
Physical layer,
Spread spectrum communication,
Wireless networks,
Time-frequency analysis,
Network security"
Online sketching hashing,"Recently, hashing based approximate nearest neighbor (ANN) search has attracted much attention. Extensive new algorithms have been developed and successfully applied to different applications. However, two critical problems are rarely mentioned. First, in real-world applications, the data often comes in a streaming fashion but most of existing hashing methods are batch based models. Second, when the dataset becomes huge, it is almost impossible to load all the data into memory to train hashing models. In this paper, we propose a novel approach to handle these two problems simultaneously based on the idea of data sketching. A sketch of one dataset preserves its major characters but with significantly smaller size. With a small size sketch, our method can learn hash functions in an online fashion, while needs rather low computational complexity and storage space. Extensive experiments on two large scale benchmarks and one synthetic dataset demonstrate the efficacy of the proposed method.","Yttrium,
Covariance matrices,
Artificial neural networks,
Approximation algorithms,
Approximation methods,
Load modeling,
Data models"
A Multi-Agent System Framework for Real-Time Electric Load Management in MVAC All-Electric Ship Power Systems,"All-electric ship power systems include less generation capacity and smaller rotating inertia compared with large power systems. The systems include large portions of nonlinear loads and dynamic loads, which may reduce the stability margin. Moreover, various operational constraints, such as system frequency constraint, motor voltage constraint and dynamic cable constraint, need to be satisfied in operational real time. Further, pulse loads draw very high short-time power in an intermittent way, which may significantly deteriorate the power quality of the system. In this paper, a novel multi-agent system cooperative controller for a medium voltage AC (MVAC) system of all-electric ship power systems is developed to balance load and generation in real time while satisfying system's operational constraints and considering load priorities. The new method coordinates the pulse load and the propulsion load to reduce the impact of pulse load changes on the power quality of all-electric ship power systems. The dynamic behavior of the new method is evaluated using case studies in PSCAD software.","Marine vehicles,
Propulsion,
Power system stability,
Generators,
Real-time systems,
Multi-agent systems"
Defining and Measuring Success in Online Citizen Science: A Case Study of Zooniverse Projects,"Although current literature highlights a wide variety of potential citizen science project outcomes, no prior studies have systematically assessed performance against a comprehensive set of criteria. The study reported here is the first to propose a novel framework for assessing citizen science projects against multiple dimensions of success. The authors apply this framework to a sample of projects that form part of the online Zooniverse platform and position these projects against a success matrix that measures both contribution to science and public engagement levels relative to other projects in the sample. Their results indicate that better-performing projects tend to be those that are more established, as well as those in the area of astronomy. Implications for citizen science practitioners include the need to consider the impact of core competencies on project performance, as well as the importance of relationships between the central organization and science teams.","Atmospheric measurements,
Particle measurements,
Extraterrestrial measurements,
Scientific computing,
Globalization,
Position measurement,
Collaboration,
Research and development"
Performance Analysis of a Low-Power High-Speed Hybrid 1-bit Full Adder Circuit,"In this paper, a hybrid 1-bit full adder design employing both complementary metal-oxide-semiconductor (CMOS) logic and transmission gate logic is reported. The design was first implemented for 1 bit and then extended for 32 bit also. The circuit was implemented using Cadence Virtuoso tools in 180-and 90-nm technology. Performance parameters such as power, delay, and layout area were compared with the existing designs such as complementary pass-transistor logic, transmission gate adder, transmission function adder, hybrid pass-logic with static CMOS output drive full adder, and so on. For 1.8-V supply at 180-nm technology, the average power consumption (4.1563 μW) was found to be extremely low with moderately low delay (224 ps) resulting from the deliberate incorporation of very weak CMOS inverters coupled with strong transmission gates. Corresponding values of the same were 1.17664 μW and 91.3 ps at 90-nm technology operating at 1.2-V supply voltage. The design was further extended for implementing 32-bit full adder also, and was found to be working efficiently with only 5.578-ns (2.45-ns) delay and 112.79-μW (53.36-μW) power at 180-nm (90-nm) technology for 1.8-V (1.2-V) supply voltage. In comparison with the existing full adder designs, the present implementation was found to offer significant improvement in terms of power and speed.",
HaTen2: Billion-scale tensor decompositions,"How can we find useful patterns and anomalies in large scale real-world data with multiple attributes? For example, network intrusion logs, with (source-ip, target-ip, port-number, timestamp)? Tensors are suitable for modeling these multi-dimensional data, and widely used for the analysis of social networks, web data, network traffic, and in many other settings. However, current tensor decomposition methods do not scale for tensors with millions and billions of rows, columns and `fibers', that often appear in real datasets. In this paper, we propose HaTen2, a scalable distributed suite of tensor decomposition algorithms running on the MapReduce platform. By carefully reordering the operations, and exploiting the sparsity of real world tensors, HaTen2 dramatically reduces the intermediate data, and the number of jobs. As a result, using HaTen2, we analyze big real-world tensors that can not be handled by the current state of the art, and discover hidden concepts.",
Learning Discriminative Sparse Representations for Hyperspectral Image Classification,"In sparse representation (SR) driven hyperspectral image classification, signal-to-reconstruction rule-based classification may lack generalization performance. In order to overcome this limitation, we presents a new method for discriminative sparse representation of hyperspectral data by learning a reconstructive dictionary and a discriminative classifier in a SR model regularized with total variation (TV). The proposed method features the following components. First, we adopt a spectral unmixing by variable splitting augmented Lagrangian and TV method to guarantee the spatial homogeneity of sparse representations. Second, we embed dictionary learning in the method to enhance the representative power of sparse representations via gradient descent in a class-wise manner. Finally, we adopt a sparse multinomial logistic regression (SMLR) model and design a class-oriented optimization strategy to obtain a powerful classifier, which improves the performance of the learnt model for specific classes. The first two components are beneficial to produce discriminative sparse representations. Whereas, adopting SMLR allows for effectively modeling the discriminative information. Experimental results with both simulated and real hyperspectral data sets in a number of experimental comparisons with other related approaches demonstrate the superiority of the proposed method.","Dictionaries,
Optimization,
Hyperspectral imaging,
TV,
Logistics,
Feature extraction"
Holistic Measures for Evaluating Prediction Models in Smart Grids,"The performance of prediction models is often based on “abstract metrics” that estimate the model's ability to limit residual errors between the observed and predicted values. However, meaningful evaluation and selection of prediction models for end-user domains requires holistic and application-sensitive performance measures. Inspired by energy consumption prediction models used in the emerging “big data” domain of Smart Power Grids, we propose a suite of performance measures to rationally compare models along the dimensions of scale independence, reliability, volatility and cost. We include both application independent and dependent measures, the latter parameterized to allow customization by domain experts to fit their scenario. While our measures are generalizable to other domains, we offer an empirical analysis using real energy use data for three Smart Grid applications: planning, customer education and demand response, which are relevant for energy sustainability. Our results underscore the value of the proposed measures to offer a deeper insight into models' behavior and their impact on real applications, which benefit both data mining researchers and practitioners.","Predictive models,
Data models,
Smart grids,
Measurement uncertainty,
Reliability,
Computational modeling"
Fault tolerant shipboard MVDC architectures,"Medium Voltage DC (MVDC) architectures are identified from the literature search that are suitable for a highly survivable 20kVdc shipboard Integrated Power System (IPS). “Breaker-based” architectures enable fast fault isolation through the use of Solid State Protective Device (SSPD) technology. “Breaker-less” architectures require based generator power converter and Solid State Transformer (SST) interfaces that can fold back outputs and coordinate with no load switches to isolate faults. Estimated size/weights and survivability of various “breaker-based” and “breaker-less topologies are compared. “Breaker-Less”, Current Source Converter (CSC) based architectures have the highest power density but at the cost of lower survivability. Expanding the role of galvanically isolating converters within the system (i.e. SSTs) increases power density and survivability.",
Acoustic Features for the Identification of Coronary Artery Disease,"Goal: Earlier studies have documented that coronary artery disease (CAD) produces weak murmurs, which might be detected through analysis of heart sounds. An electronic stethoscope with a digital signal processing unit could be a low cost and easily applied method for diagnosis of CAD. The current study is a search for heart sound features which might identify CAD. Methods: Nine different types of features from five overlapping frequency bands were obtained and analyzed using 435 recordings from 133 subjects. Results: New features describing an increase in low-frequency power in CAD patients were identified. The features of the different types were relatively strongly correlated. Using a quadratic discriminant function, multiple features were combined into a CAD-score. The area under the receiving operating characteristic for the CAD score was 0.73 (95% CI: 0.69-0.78). Conclusion: The result confirms that there is a potential in heart sounds for the diagnosis of CAD, but that further improvements are necessary to gain clinical relevance.",
Dual-Space Control of Extremely Fast Parallel Manipulators: Payload Changes and the 100G Experiment,"In this paper, three control schemes are proposed and experimentally compared on the R4 redundantly actuated parallel manipulator for applications with very high accelerations. First, a proportional-integral-differential (PID) in operational space is proposed to adequately take into consideration the actuation redundancy. Because of its lack of performance, a dual-space feedforward control scheme based on the dynamic model of R4 is proposed. The improvements obtained with this controller allowed the implementation of an experiment, which consisted in the tracking of a trajectory with a maximum acceleration of more than 100G. However, such a controller may have loss of performance in case of any operational change (such as different payloads). Therefore, a dual-space adaptive control scheme is proposed. The stability analysis of the R4 parallel robot when controlled by the proposed dual-space adaptive controller is provided. The objective of this paper is to show that the proposed dual-space adaptive controller not only maintains its good performance independently of the operational conditions but also has a better performance than both the PID and the dual-space feedforward controllers, even when the latter is best configured for the given case (which confirms its applicability in an industrial environment).",
Sparse Coding-Inspired Optimal Trading System for HFT Industry,"The financial industry has witnessed an exceptionally fast progress of incorporating information processing techniques in designing knowledge-based automated systems for high-frequency trading (HFT). This paper proposes a sparse coding-inspired optimal trading (SCOT) system for real-time high-frequency financial signal representation and trading. Mathematically, SCOT simultaneously learns the dictionary, sparse features, and the trading strategy in a joint optimization, yielding optimal feature representations for the specific trading objective. The learning process is modeled as a bilevel optimization and solved by the online gradient descend method with fast convergence. In this dynamic context, the system is tested on the real financial market to trade the index futures in the Shanghai exchange center.",
Connection Discovery Using Big Data of User-Shared Images in Social Media,"Billions of user-shared images are generated by individuals in many social networks today, and this particular form of user data is widely accessible to others due to the nature of online social sharing. When user social graphs are only accessible to exclusive parties, these user-shared images are proved to be an easier and effective alternative to discover user connections. This work investigated over 360 000 user shared images from two social networks, Skyrock and 163 Weibo, in which 3 million follower/ followee relationships are involved. It is observed that the shared images from users with a follower / followee relationship show relatively higher similarities . A multimedia big data system that utilizes this observed phenomenon is proposed as an alternative to user- generated tags and social graphs for follower/followee recommendation and gender identification. To the best of our knowledge, this is the first attempt in this field to prove and formulate such a phenomenon for mass user-shared images along with more practical prediction methods. These findings are useful for information or services recommendations in any social network with intensive image sharing, as well as for other interesting personalization applications, particularly when there is no access to those exclusive user social graphs.","Social network services,
Visualization,
Feature extraction,
Multimedia communication,
Tagging,
Europe,
Detectors"
Silicon Photonics for Advanced Optical Interconnections,"After a brief review on silicon photonics research and development in China, the progress of silicon photonic components for coherent transceiver is described in details. The performance of the silicon modulators in high capacity, low-cost advanced intensity modulation and direct detection optical interconnection systems is also reported, and special properties of silicon photonic components, which lead to low power consumption, are discussed. These results show that silicon photonics has great prospect in advanced optical interconnection systems.","Modulation,
Optical waveguides,
Photodetectors,
Silicon photonics,
Optical interconnections,
Power demand"
An Isolated Industrial Power System Driven by Wind-Coal Power for Aluminum Productions: A Case Study of Frequency Control,"Due to the uneven geographical distribution between load and wind power, currently it is difficult to integrate the large-scale wind power into the State Grid in China. There are significant wind curtailments for wind farms due to system restrictions. This paper proposes a new way of utilizing wind power, i.e., in-situ consumption, as an alternative to the costly development of long-distance transmission of large-scale wind power. Electrolytic aluminum load, which is one of the most typical high energy consuming loads, is employed to absorb the excess wind power in western China. An actual isolated industrial power system for aluminum production driven by wind power and coal-fired power is described. The penetration level of wind power in the isolated power system is up to 48.8%. The power imbalance between generation and load demand caused by wind power fluctuation or the tripping of coal-fired generators can dramatically impact the frequency stability of the isolated power system, which is of small inertia. An online identification method of power imbalance based on Wide Area Measurement System (WAMS) is presented. According to the characteristics of the electrolytic aluminum load, a system frequency control method by regulating the bus voltages of aluminum loads to eliminate the power imbalance is introduced. The simulation is done in Real Time Digital Simulator (RTDS) and the results verify the validity of the proposed frequency control method.","Aluminum,
Generators,
Wind power generation,
Power system stability,
Frequency control,
Voltage control"
A Secure Data Aggregation Scheme Based on Appropriate Cryptographic Primitives in Heterogeneous Wireless Sensor Networks,"Energy cost of transmitting a single bit of information is approximately the same as that needed for processing a thousand operations in a typical sensor node. Thus, a practical way to prolong a wireless sensor network lifetime is to reduce the sensor energy consumption in data transmissions. Data aggregation is an efficient way to minimize energy consumption on sensors. In this paper, we propose a practical secure data aggregation scheme, Sen-SDA, based on an additive homomorphic encryption scheme, an identity-based signature scheme, and a batch verification technique with an algorithm for filtering injected false data. We then investigate the feasibility of our scheme using low-cost microcontrollers choosing two popular IEEE 802.15.4-compliant wireless sensor network hardware platforms, MICAz and Tmote Sky, used in real-life deployments.","Wireless sensor networks,
Aggregates,
Encryption,
Public key,
Sensors"
Characterizing User Behavior in Mobile Internet,"Smart devices bring us the ubiquitous mobile accessing to Internet, making mobile Internet grow rapidly. Using the mobile traffic data collected at core metropolitan 2G and 3G networks of China over a week, this paper studies the mobile user behavior from three aspects: 1) data usage; 2) mobility pattern; and 3) application usage. We classify mobile users into different groups to study the resource consumption in mobile Internet. We observe that traffic heavy users and high mobility users tend to consume massive data and radio resources simultaneously. Both the data usage and the mobility pattern are closely related to the application access behavior of the users. Users can be clustered through their application usage behavior, and application categories can be identified by the ways to attract the users. Our analysis provides an comprehensive understanding of user behavior in mobile Internet, which may be used by network operators to design appropriate mechanisms in resource provision and mobility management for resource consumers based on different categories of applications.",
Human Interactive Patterns in Temporal Networks,"Modern information and communication technologies provide digital traces of human interactive activities, which offer novel avenues to map and analyze temporal features of human interaction networks. This paper explores mesoscopic patterns of human interactive activities from six real-world interaction networks with temporal-topological isomorphic subgraphs, i.e., temporal motifs. We discover two dominant mutual motifs, “Star,” “Ordered-chain,” and one dominant directed motif, “Ping-Pong,” which characterize the interactive patterns of “Leader,” “Queue,” and “Feedback,” respectively. Moreover,temporal dynamics shows that bursts are universal in human mesoscopic patterns, and the evolution of three dominant temporal motifs indicates the existence of characteristic time. Finally, we analyze temporal robustness and generalization to verify that 3-event temporal motifs are a simple yet powerful tool to capture the mesoscopic patterns of human interactive activities.",
Relative Entropy-Based Waveform Design for MIMO Radar Detection in the Presence of Clutter and Interference,"This paper considers the waveform design problem for multiple-input multiple-output (MIMO) radars in order to improve the detection performance of the systems. We assume that target echoes are embedded in (signal-dependent) clutter as well as (colored) interference. Considering the optimal (Neyman-Pearson) detector, obtaining waveforms which maximize the detection probability for a fixed value of the probability of false alarm is intractable. Therefore, we employ relative entropy associated with the detection problem as the figure of merit for the waveform design. We devise an iterative method based on minorization-maximization (MM) technique to tackle the nonconvex design problem. This method also includes a novel trick for replacing a nonconvex constraint set (associated with an equivalent form of the design problem) with a convex one iteratively. The proposed method increases the design metric monotonically and is guaranteed to converge. We extend the devised method for using in design with peak-to-average power ratio (PAR) and similarity constraints. The method can be applied to both statistical and colocated MIMO radars. Several numerical examples are included to demonstrate the effectiveness of the proposed method.","MIMO radar,
Clutter,
Covariance matrices,
Receiving antennas,
Detectors,
MIMO"
A joint power adaptation and spectrum handoff scheme in mobile cognitive radio networks,"Cognitive radio (CR) technology is regarded as a promising solution by enabling unlicensed users to exploit the licensed spectrum unused by the licensed user in an opportunistic manner. Since in a mobile CR network, if unlicensed users move away from each other, their relative distance changes. Thus, the unlicensed user transmission power needs to be adapted to maintain their communications. In the meantime, since the spectrum availability is location-varying, the unlicensed users may also need to perform spectrum handoffs to avoid harmful interference to PUs caused by the increase of the transmission power. In this paper, in order to address this problem, a joint power adaptation and spectrum handoff scheme is proposed in mobile CR networks. The throughput of the unlicensed user transmission is used to evaluate the performance of the proposed algorithm. Simulation results show that our proposed algorithm achieves very high throughput when the unlicensed receiver is mobile. To the best of our knowledge, this is the first paper that jointly investigates both the power adaptation and the spectrum handoff in mobile CR ad hoc networks.","Throughput,
Mobile communication,
Cognitive radio,
Receivers,
Mobile computing,
Ad hoc networks,
Transmitters"
Continuous Sensor Placement,"Existing solutions to the sensor placement problem are based on sensor selection, in which the best subset of available sampling locations is chosen such that a desired estimation accuracy is achieved. However, the achievable estimation accuracy of sensor placement via sensor selection is limited to the initial set of sampling locations, which are typically obtained by gridding the continuous sampling domain. To circumvent this issue, we propose a framework of continuous sensor placement. A continuous variable is augmented to the grid-based model, which allows for off-the-grid sensor placement. The proposed offline design problem can be solved using readily available convex optimization solvers.","Estimation,
Convex functions,
Accuracy,
Sensors,
Signal to noise ratio,
Vectors,
Memory"
Massive MIMO for Wireless Sensing With a Coherent Multiple Access Channel,"We consider the detection and estimation of a zero-mean Gaussian signal in a wireless sensor network with a coherent multiple access channel, when the fusion center (FC) is configured with a large number of antennas and the wireless channels between the sensor nodes and FC experience Rayleigh fading. For the detection problem, we study the Neyman-Pearson (NP) detector and energy detector (ED) and find optimal values for the sensor transmission gains. For the NP detector, which requires channel state information (CSI), we show that detection performance remains asymptotically constant with the number of FC antennas if the sensor transmit power decreases proportionally with the increase in the number of antennas. Performance bounds show that the benefit of multiple antennas at the FC disappears as the transmit power grows. The results of the NP detector are also generalized to the linear minimum mean-squared error estimator. For the ED, which does not require CSI, we derive optimal gains that maximize the deflection coefficient of the detector, and we show that a constant deflection can be asymptotically achieved if the sensor transmit power scales as the inverse square root of the number of FC antennas. Unlike the NP detector, for high sensor power, the multi-antenna ED is observed to empirically have significantly better performance than the single-antenna implementation. A number of simulation results are included to validate the analysis.","Detectors,
Wireless sensor networks,
Transmitting antennas,
Wireless communication,
Estimation,
Channel estimation"
Robot Guided Crowd Evacuation,"The congregation of crowd undoubtedly constitutes an important risk factor, which may endanger the safety of the gathered people. The solution reported against this significant threat to citizens safety is to consider careful planning and measures. Thereupon, in this paper, we address the crowd evacuation problem by suggesting an innovative technological solution, namely, the use of mobile robot agents. The contribution of the proposed evacuation system is twofold: (i) it proposes an accurate Cellular Automaton simulation model capable of assessing the human behavior during emergency situations and (ii) it takes advantage of the simulation output to provide sufficient information to the mobile robotic guide, which in turn approaches and redirects a group of people towards a less congestive exit at a time. A custom-made mobile robotic platform was accordingly designed and developed. Last, the performance of the proposed robot guided evacuation model has been examined in real-world scenarios exhibiting significant performance improvement during the crucial first response time window.","Computational modeling,
Mobile communication,
Safety,
Mobile robots,
Robot sensing systems,
Automata"
9.5 efficient digital quadrature transmitter based on IQ cell sharing,"As new complex communication standards employ various modulation methods in various frequency bands, interest in the software-defined radio (SDR) transceiver to support the standards is increasing. For the flexible transceiver, a digital-intensive transmitter has many advantages and has been pursued intensively. The efficiency of the transmitter chain is strongly dependent on the PA, and switching PAs, such as Class-D and F PAs, are used due to their high efficiency. A polar transmitter is suited for the switching operation and receives a large attention. However, a CORDIC is needed for l/Q-to-Polar conversion, and it is very complex. Moreover, the polar signal has a large bandwidth compared to the l/Q signal bandwidth. On the contrary, the quadrature transmitter that does not require the CORDIC, is simple and low computing cost with low power consumption. Due to the favorable characteristics, the quadrature transmitters have been studied. [1] employs an RFDAC based on a Gilbert mixer. It operates in a current mode and the output impedance varies with the number of on-cells. Due to the impedance variation, it is difficult to have a high linearity. In [2], the input digital code is processed by delta-sigma modulation for smaller digital bits and enhanced resolution. However the modulator generates quantization noise. In [3-6], a voltage-mode transmitter is employed with a power combiner based on a switched capacitor. The output impedance is constant, determined by the total capacitance regardless of the on/off cell condition. Moreover, this architecture delivers much higher output power and efficiency than previously reported works. [4] used delta-sigma modulation with cascade PWM to improve linearity. In [5], a quadrature architecture was employed to eliminate the problems of the polar architecture. Due to the 90° phase difference of conventional digital l/Q LOs, the output power of the conventional quadrature transmitter has lower than that of polar, maximum 3dB lower when the magnitude of I and Q are equal.","Radio transmitters,
Computer architecture,
Switches,
Microprocessors,
Capacitors,
Power generation"
A Collaborative Intrusion Detection Mechanism Against False Data Injection Attack in Advanced Metering Infrastructure,"Smart meters are inherent components in advanced metering infrastructure (AMI) in the smart power grid. They are serving as the crucial interfaces through which the cyber, physical, and social domains of the smart grid can interact with each other. Due to the complicated interactions, smart meters may face a large variety of threats. In this paper, we exploit the colored Petri net to describe the information flows among units in a smart meter. Then, we propose a threat model for smart meters. Considering the constrained computation and storage resources of a smart meter, we present a collaborative intrusion detection mechanism against false data injection attack. The proposed scheme can work regardless of changes in a smart meter's software. Numerical results demonstrate the low cost and effectiveness of our proposed intrusion detection mechanism.","Smart meters,
Intrusion detection,
Memory management,
Writing,
Smart grids,
Software"
Real-Time Human Movement Retrieval and Assessment With Kinect Sensor,"The difficulty of vision-based posture estimation is greatly decreased with the aid of commercial depth camera, such as Microsoft Kinect. However, there is still much to do to bridge the results of human posture estimation and the understanding of human movements. Human movement assessment is an important technique for exercise learning in the field of healthcare. In this paper, we propose an action tutor system which enables the user to interactively retrieve a learning exemplar of the target action movement and to immediately acquire motion instructions while learning it in front of the Kinect. The proposed system is composed of two stages. In the retrieval stage, nonlinear time warping algorithms are designed to retrieve video segments similar to the query movement roughly performed by the user. In the learning stage, the user learns according to the selected video exemplar, and the motion assessment including both static and dynamic differences is presented to the user in a more effective and organized way, helping him/her to perform the action movement correctly. The experiments are conducted on the videos of ten action types, and the results show that the proposed human action descriptor is representative for action video retrieval and the tutor system can effectively help the user while learning action movements.",
Backscattering Neural Tags for Wireless Brain-Machine Interface Systems,"Brain-machine interface (BMI) technology has tremendous potential to revolutionize healthcare by greatly improving the quality of life of millions of people suffering from a wide variety of neurological conditions. Radio-frequency identification (RFID)-inspired backscattering is a promising approach for wireless powering of miniature neural sensors required in BMI interfaces. We analyze the functionality of millimeter-size loop antennas in the wireless powering of miniature cortical implants through measurements in a human head equivalent liquid phantom and in the head of a postmortem pig. For the first time, we present the design and measurement of a miniature 1×1×1 mm3 backscattering device based on a cubic loop connected with an RFID integrated circuit (IC). Our measurement results show that this very small loop receives sufficient electromagnetic power to activate the IC when the device is implanted in a pig's head. This demonstrates the feasibility of extremely small implant antennas in challenging wireless biomedical systems.","Implants,
Antenna measurements,
Wireless communication,
Transmitting antennas,
Wireless sensor networks,
Integrated circuits"
Path-guided artificial potential fields with stochastic reachable sets for motion planning in highly dynamic environments,"Highly dynamic environments pose a particular challenge for motion planning due to the need for constant evaluation or validation of plans. However, due to the wide range of applications, an algorithm to safely plan in the presence of moving obstacles is required. In this paper, we propose a novel technique that provides computationally efficient planning solutions in environments with static obstacles and several dynamic obstacles with stochastic motions. Path-Guided APF-SR works by first applying a sampling-based technique to identify a valid, collision-free path in the presence of static obstacles. Then, an artificial potential field planning method is used to safely navigate through the moving obstacles using the path as an attractive intermediate goal bias. In order to improve the safety of the artificial potential field, repulsive potential fields around moving obstacles are calculated with stochastic reachable sets, a method previously shown to significantly improve planning success in highly dynamic environments. We show that Path-Guided APF-SR outperforms other methods that have high planning success in environments with 300 stochastically moving obstacles. Furthermore, planning is achievable in environments in which previously developed methods have failed.","Collision avoidance,
Planning,
Robot kinematics,
Vehicle dynamics,
Navigation,
Heuristic algorithms"
Learning View-Model Joint Relevance for 3D Object Retrieval,"3D object retrieval has attracted extensive research efforts and become an important task in recent years. It is noted that how to measure the relevance between 3D objects is still a difficult issue. Most of the existing methods employ just the model-based or view-based approaches, which may lead to incomplete information for 3D object representation. In this paper, we propose to jointly learn the view-model relevance among 3D objects for retrieval, in which the 3D objects are formulated in different graph structures. With the view information, the multiple views of 3D objects are employed to formulate the 3D object relationship in an object hypergraph structure. With the model data, the model-based features are extracted to construct an object graph to describe the relationship among the 3D objects. The learning on the two graphs is conducted to estimate the relevance among the 3D objects, in which the view/model graph weights can be also optimized in the learning process. This is the first work to jointly explore the view-based and model-based relevance among the 3D objects in a graph-based framework. The proposed method has been evaluated in three data sets. The experimental results and comparison with the state-of-the-art methods demonstrate the effectiveness on retrieval accuracy of the proposed 3D object retrieval method.","Three-dimensional displays,
Solid modeling,
Data models,
Joints,
Cameras,
Shape,
Feature extraction"
Fast Wavefront Propagation (FWP) for Computing Exact Geodesic Distances on Meshes,"Computing geodesic distances on triangle meshes is a fundamental problem in computational geometry and computer graphics. To date, two notable classes of algorithms, the Mitchell-Mount-Papadimitriou (MMP) algorithm and the Chen-Han (CH) algorithm, have been proposed. Although these algorithms can compute exact geodesic distances if numerical computation is exact, they are computationally expensive, which diminishes their usefulness for large-scale models and/or time-critical applications. In this paper, we propose the fast wavefront propagation (FWP) framework for improving the performance of both the MMP and CH algorithms. Unlike the original algorithms that propagate only a single window (a data structure locally encodes geodesic information) at each iteration, our method organizes windows with a bucket data structure so that it can process a large number of windows simultaneously without compromising wavefront quality. Thanks to its macro nature, the FWP method is less sensitive to mesh triangulation than the MMP and CH algorithms. We evaluate our FWP-based MMP and CH algorithms on a wide range of large-scale real-world models. Computational results show that our method can improve the speed by a factor of 3-10.",
Optimizing Speech Intelligibility in a Noisy Environment: A unified view,"Modern communication technology facilitates communication from anywhere to anywhere. As a result, low speech intelligibility has become a common problem, which is exacerbated by the lack of feedback to the talker about the rendering environment. In recent years, a range of algorithms has been developed to enhance the intelligibility of speech rendered in a noisy environment. We describe methods for intelligibility enhancement from a unified vantage point. Before one defines a measure of intelligibility, the level of abstraction of the representation must be selected. For example, intelligibility can be measured on the message, the sequence of words spoken, the sequence of sounds, or a sequence of states of the auditory system. Natural measures of intelligibility defined at the message level are mutual information and the hit-or-miss criterion. The direct evaluation of high-level measures requires quantitative knowledge of human cognitive processing. Lower-level measures can be derived from higher-level measures by making restrictive assumptions. We discuss the implementation and performance of some specific enhancement systems in detail, including speech intelligibility index (SII)-based systems and systems aimed at enhancing the sound-field where it is perceived by the listener. We conclude with a discussion of the current state of the field and open problems.","Acoustic signal processing,
Acoustic noise,
Acoustic measurements,
Distortion measurement,
Mutual information,
Psychoacoustic models,
Speech processing,
Assitive devices,
Noise measurement"
Social Attribute-Aware Force Model: Exploiting Richness of Interaction for Abnormal Crowd Detection,"Interactions among pedestrians usually play an important role in understanding crowd behavior. However, there are great challenges, such as occlusions, motion, and appearance variance, on accurate analysis of pedestrian interactions. In this paper, we introduce a novel social attribute-aware force model (SAFM) for detection of abnormal crowd events. The proposed model incorporates social characteristics of crowd behaviors to improve the description of interactive behaviors. To this end, we first efficiently estimate the scene scale in an unsupervised manner. Then, we introduce the concepts of social disorder and congestion attributes to characterize the interaction of social behaviors, and construct our crowd interaction model on the basis of social force by an online fusion strategy. These attributes encode social interaction characteristics and offer robustness against motion pattern variance. Abnormal event detection is finally performed based on the proposed SAFM. In addition, the attribute-aware interaction force indicates the possible locations of anomalous interactions. We validate our method on the publicly available data sets for abnormal detection, and the experimental results show promising performance compared with alternative and state-of-the-art methods.",
Innovative Schemes for Resource Allocation in the Cloud for Media Streaming Applications,"Media streaming applications have recently attracted a large number of users in the Internet. With the advent of these bandwidth-intensive applications, it is economically inefficient to provide streaming distribution with guaranteed QoS relying only on central resources at a media content provider. Cloud computing offers an elastic infrastructure that media content providers (e.g., Video on Demand (VoD) providers) can use to obtain streaming resources that match the demand. Media content providers are charged for the amount of resources allocated (reserved) in the cloud. Most of the existing cloud providers employ a pricing model for the reserved resources that is based on non-linear time-discount tariffs (e.g., Amazon CloudFront and Amazon EC2). Such a pricing scheme offers discount rates depending non-linearly on the period of time during which the resources are reserved in the cloud. In this case, an open problem is to decide on both the right amount of resources reserved in the cloud, and their reservation time such that the financial cost on the media content provider is minimized. We propose a simple-easy to implement-algorithm for resource reservation that maximally exploits discounted rates offered in the tariffs, while ensuring that sufficient resources are reserved in the cloud. Based on the prediction of demand for streaming capacity, our algorithm is carefully designed to reduce the risk of making wrong resource allocation decisions. The results of our numerical evaluations and simulations show that the proposed algorithm significantly reduces the monetary cost of resource allocations in the cloud as compared to other conventional schemes.",
A 12-bit 8.47-fJ/Conversion-Step Capacitor-Swapping SAR ADC in 110-nm CMOS,"This paper presents a 12-bit energy-efficient successive approximation register analog-to-digital converter (ADC). By incorporating the proposed capacitor-swapping technique, which eliminates the problematic MSB mismatch transition of a binary-weighted capacitor digital-to-analog converter, the 12-bit linearity of the ADC is achieved without increasing the capacitor size for improved matching. The small capacitor size results in low power consumption. In addition, an on-the-fly programmable dynamic comparator is used for quick comparisons with low noise contributions within the limited power budget. The ADC is fabricated using a 110-nm CMOS process. It consumes 16.47 μW from a 0.9-V supply at a conversion-rate of 1 MS/s. The measured DNL and INL are within 0.3 LSB and 0.56 LSB, respectively. The measured SNDR and SFDR are at 67.3 dB and 87 dB, respectively. The ENOB performance is 10.92 b, which is equivalent to a figure-of-merit of 8.47 fJ/conversion-step.","Capacitors,
Capacitance,
Switches,
Linearity,
Noise,
Redundancy,
Arrays"
Hardware Efficient Mixed Radix-25/16/9 FFT for LTE Systems,"In this paper, we propose a hardware-efficient mixed generalized high-radix (GHR) reconfigurable fast Fourier transform (FFT) processor for long-term evolution applications. The GHR processor based on radix-25/16/9 uses a 2-D factorization scheme as the high-radix unit and a 1-D factorization method as the system data routing technology. The 2-D factorization scheme is implemented by an enhanced delay element matrix structure, which supports 25-, 16-, 9-, 8-, 5-, 4-, 3-, and 2-point FFTs. Two different designs were implemented. One design (called discrete Fourier transform core) supports 34 different transform sizes from 12 to 1296 points, while the other design (called FFT core) supports five different power-of-two sizes from 128 to 2048 points. The 1-D factorization method is performed by a coprime accessing technology, which accesses the data in parallel without conflict using a RAM. The GHR combines 2-D and 1-D factorization techniques and improves the throughput by a factor of two to four with comparable hardware cost compared with the previous designs. The speed-area ratio of the proposed scheme is nearly two times better than that of previous FFT processors. Application-specified integrated circuit implementation results based on a 0.18-μm technology are also provided.","Discrete Fourier transforms,
Hardware,
Indexes,
Routing,
Adders,
Delays,
Long Term Evolution"
A novel methodology for efficient throughput evaluation in virtualized routers,"This paper analyzes a novel methodology for calculating the throughput in a device, which hosts multiple virtualized network interconnect devices (i.e. virtual routers). The proposed methodology, which extends the well-known procedure (for non-virtualized IP routers) adopted from RFC 2544, considers the impact of heterogeneity of the offered load at the level of virtual routers. The utility of this methodology is demonstrated, analyzing the throughput of virtualized routers by four different virtualization platforms that use two different techniques, which are the paravirtualization (Xen and Citrix Xen) and the OS-level virtualization (Linux Containers and Jails). The results indicate that the virtualization platforms behave differently to distribution of traffic load among virtual routers. Finally, the need for the proposed methodology is motivated by performing extensive throughput tests on the aforementioned platforms at different work points of the network device (i.e. different offered traffic load distribution between virtual routers).","Virtualization,
Throughput,
Kernel,
Performance evaluation,
Telecommunication traffic,
Hardware"
Decentralized Estimation and Control for Preserving the Strong Connectivity of Directed Graphs,"In order to accomplish cooperative tasks, decentralized systems are required to communicate among each other. Thus, maintaining the connectivity of the communication graph is a fundamental issue. Connectivity maintenance has been extensively studied in the last few years, but generally considering undirected communication graphs. In this paper, we introduce a decentralized control and estimation strategy to maintain the strong connectivity property of directed communication graphs. In particular, we introduce a hierarchical estimation procedure that implements power iteration in a decentralized manner, exploiting an algorithm for balancing strongly connected directed graphs. The output of the estimation system is then utilized for guaranteeing preservation of the strong connectivity property. The control strategy is validated by means of analytical proofs and simulation results.","Estimation,
Laplace equations,
Maintenance engineering,
Multi-robot systems,
Mobile robots,
Computer architecture"
Architectural Aspects of Self-Aware and Self-Expressive Computing Systems: From Psychology to Engineering,Work on human self-awareness is the basis for a framework to develop computational systems that can adaptively manage complex dynamic tradeoffs at runtime. An architectural case study in cloud computing illustrates the framework's potential benefits.,"Human factors,
Behavioral science,
Computer architecture,
Emotion recognition"
CAFO: Cost aware flip optimization for asymmetric memories,"Phase Change Memory (PCM) and spin-transfer torque random access memory (STT-RAM) are emerging as new memory technologies to replace DRAM and NAND flash that are impeded by physical limitations. Programming PCM cells degrades their endurance while programming STT-RAM cells incurs a high bit error rate. Accordingly, several schemes have been proposed to service write requests while programing as few memory cells as possible. Nevertheless, those schemes did not address the asymmetry in programming memory cells that characterizes both PCM and STT-RAM. For instance, writing a bit value of 0 on PCM cells is more detrimental to endurance than 1 while writing a bit value of 1 on STT-RAM cells is more prone to error than 0. In this paper, we propose CAFO as a new cost aware flip reduction scheme. Essentially, CAFO encompasses a cost model that computes the cost of servicing write requests through assigning different costs to each cell that requires programming. Subsequently, CAFO encodes the data to be written into a form that incurs less cost through its cost aware encoding module. Overall, CAFO is capable of cutting down the write cost by up to 65% more than existing schemes.",
A Projection Neural Network for Constrained Quadratic Minimax Optimization,"This paper presents a projection neural network described by a dynamic system for solving constrained quadratic minimax programming problems. Sufficient conditions based on a linear matrix inequality are provided for global convergence of the proposed neural network. Compared with some of the existing neural networks for quadratic minimax optimization, the proposed neural network in this paper is capable of solving more general constrained quadratic minimax optimization problems, and the designed neural network does not include any parameter. Moreover, the neural network has lower model complexities, the number of state variables of which is equal to that of the dimension of the optimization problems. The simulation results on numerical examples are discussed to demonstrate the effectiveness and characteristics of the proposed neural network.","Optimization,
Biological neural networks,
Mathematical model,
Convergence,
Linear programming,
Lyapunov methods"
Distributed Sensing for High-Quality Structural Health Monitoring Using WSNs,"Due to the low cost and ease of deployment, wireless sensor networks (WSNs) are emerging as sensing paradigms that the structural engineering field has begun to consider as substitutes for traditional tethered structural health monitoring (SHM) systems. Different from other applications of WSNs such as environmental monitoring, SHM applications are much more data intensive and it is not feasible to stream the raw data back to the server due to the severe bandwidth and energy limitations of low-power sensor networks. In-network processing is a promising approach to address this problem but designing distributed versions for the sophisticated SHM algorithms is much more challenging because SHM algorithms are computationally intensive, and involve data-level collaboration of multiple sensors. In this paper, we select a classical SHM algorithm: the eigen-system realization algorithm (ERA), and propose a few distributed ERAs suitable for WSNs. In particular, we first design a method to incrementally calculate the ERA and then propose three schemes upon which the incremental ERA can be carried out along an Hamiltonian path, along a path in the minimum connected dominating set (MCDS) and along the shortest path tree (SPT). The efficacy of these schemes are demonstrated and compared through both simulation experiment. We believe the proposed schemes can also serve as a guideline when applying WSNs for other applications like SHM which are also data-intensive and involve sophisticated signal processing of collected information.",
A Groebner Bases Theory-Based Method for Selective Harmonic Elimination,"An algebraic method is proposed for selective harmonic elimination PWM (SHEPWM). By computing its Groebner bases under the pure lexicographic monomial order, the nonlinear high-order SHE equations are converted to an equivalent triangular form, and then a recursive algorithm is used to solve the triangular equations one by one. Based on the proposed method, a user-friendly software package has been developed and some computation results are given. Unlike the commonly used numerical and intelligent methods, this method does not need to choose the initial values and can find all the solutions. Also, this method can give a definite answer to the question of whether the SHE equations have solutions or not, and the accuracy of the solved switching angles are much higher than that of the reference method. Compared with the existing algebraic methods, such as the resultant elimination method, the calculation efficiency is improved. Experimental verification is also shown in this paper.","Polynomials,
Mathematical model,
Switches,
Harmonic analysis,
Inverters,
Pulse width modulation"
X-Band Tunable Frequency Selective Surface Using MEMS Capacitive Loads,"A tunable frequency selective surface (FSS) based on slotted ground is presented. Tuning of the resonance frequency is achieved by using a metallic MEMS bridge over the slot. The bridge acts as a capacitive load, increasing the equivalent capacitance, and so decreasing the resonance frequency. Electromagnetic and electromechanical simulations are performed to investigate the designed FSS. S-parameter measurements of the FSS unit cell are performed in a waveguide simulator, showing more than 1.7 GHz frequency shift in the X-band, achieved by using only one MEMS bridge. A measured bandwidth of 400 MHz at the resonance frequency of 9.59 GHz is achieved. The designed MEMS bridge benefits from an unconventional method of using SU-8 as the sacrificial layer, resulting in low loss at high frequencies (3.2 dB loss at the resonance frequency of 9.59 GHz). Devices with different heights of the MEMS bridge were fabricated to study the variation in the resonance frequency. The MEMS bridge was tested at fixed heights. Simulated and measured results show excellent agreement. An FSS array is designed based on the FSS unit cell results. The design procedure to maximize the quality factor and controllable frequency range, and improve the radiation characteristics of the FSS array is discussed. Further simulations are performed to examine the performance of the FSS array with regards to grating lobes, oblique incidence and tunability.",
Predictive Deep Boltzmann Machine for Multiperiod Wind Speed Forecasting,"It is important to forecast the wind speed for managing operations in wind power plants. However, wind speed prediction is extremely complex and difficult due to the volatility and deviation of the wind. As existing forecasting methods directly model the raw wind speed data, it is difficult for them to provide higher inference accuracy. Differently, this paper presents a sophisticated deep-learning technique for short-term and long-term wind speed forecast, i.e., the predictive deep Boltzmann machine (PDBM) and corresponding learning algorithm. The proposed deep model forecasts wind speed by analyzing the higher level features abstracted from lower level features of the wind speed data. These automatically learnt features are very informative and appropriate for the prediction. The proposed PDBM is a deep stochastic model that can represent the wind speed very well, and is inspired by two aspects. 1) The stochastic model is suitable to capture the probabilistic characteristics of wind speed. 2) Recent developments in neural networks with deep architectures show that deep generative models have competitive capability to approximate nonlinear and nonsmooth functions. The evaluation of the proposed PDBM model is depicted by both hour-ahead and day-ahead prediction experiments based on real wind speed datasets. The prediction accuracy of the PDBM model outperforms existing methods by more than 10%.","Wind speed,
Wind forecasting,
Predictive models,
Training,
Time series analysis,
Wind power generation,
Machine learning"
A Microactuation and Sensing Platform With Active Lockdown for In Situ Calibration of Scale Factor Drifts in Dual-Axis Gyroscopes,"This paper presents the design and experimental results of a microvibratory actuation and sensing platform to provide on-chip physical stimulus for in situ calibration of long-term scale factor drifts in multiaxis microelectromechanical systems (MEMS) inertial sensors. The platform consists of a three degrees-of-freedom micromotion stage that can provide piezoelectric actuation for X/Y-tilting reference stimuli, compensation of undesired off-axis motion, integrated sensing of applied periodic stimulus, and electrostatic position lock-down for shock protection. A dual-axis MEMS gyroscope is mounted on top of the microplatform, and its electrical interconnects are provided through microfabricated highly flexible parylene cables with virtually zero-loading. The piezoelectric stage is measured to provide up to 280°/s angular ac excitation to a 25-mg inertial sensor payload at an expense of <;100 μW, while providing an analog sensing signal (11 mV/°/s) to determine the applied rate with a precision of 1.2 °/s. The estimated scale factor has <; 0.8% deviation from rate-table characterized values on the same-model gyroscope samples. With further improvements in control precision and angular velocity estimation, the introduced platform is expected enable on-chip self-calibration of long-term scale-factor drifts to <; 100 ppm.","Gyroscopes,
Calibration,
Micromechanical devices,
Electrodes,
Temperature sensors,
Electrostatics"
Measurement of shear and slip with a GelSight tactile sensor,"Artificial tactile sensing is still underdeveloped, especially in sensing shear and slip on a contact surface. For a robot hand to manually explore the environment or perform a manipulation task such as grasping, sensing of shear forces and detecting incipient slip is important. In this paper, we introduce a method of sensing the normal, shear and torsional load on the contact surface with a GelSight tactile sensor [1]. In addition, we demonstrate the detection of incipient slip. The method consists of inferring the state of the contact interface based on analysis of the sequence of images of GelSights elastomer medium, whose deformation under the external load indicates the conditions of contact. Results with a robot gripper like experimental setup show that the method is effective in detecting interactions with an object during stable grasp as well as at incipient slip. The method is also applicable to other optical based tactile sensors.","Force,
Surface topography,
Tactile sensors,
Entropy"
Correcting Time-Continuous Emotional Labels by Modeling the Reaction Lag of Evaluators,"An appealing scheme to characterize expressive behaviors is the use of emotional dimensions such as activation (calm versus active) and valence (negative versus positive). These descriptors offer many advantages to describe the wide spectrum of emotions. Due to the continuous nature of fast-changing expressive vocal and gestural behaviors, it is desirable to continuously track these emotional traces, capturing subtle and localized events (e.g., with FEELTRACE). However, time-continuous annotations introduce challenges that affect the reliability of the labels. In particular, an important issue is the evaluators' reaction lag caused by observing, appraising, and responding to the expressive behaviors. An empirical analysis demonstrates that this delay varies from 1 to 6 seconds, depending on the annotator, expressive dimension, and actual behaviors. Our experiments show accuracy improvements even with fixed delays (1-3 seconds). This paper proposes to compensate for this reaction lag by finding the time-shift that maximizes the mutual information between the expressive behaviors and the time-continuous annotations. The approach is implemented by making different assumptions about the evaluators' reaction lag. The benefits of compensating for the delay is demonstrated with emotion classification experiments. On average, the classifiers trained with facial and speech features show more than 7 percent relative improvements over baseline classifiers trained and tested without shifting the time-continuous annotations.","Delays,
Gold,
Mutual information,
Feature extraction,
Databases,
Emotion recognition,
Acoustics"
Cloud Computing Service: The Caseof Large Matrix Determinant Computation,"Cloud computing paradigm provides an alternative and economical service for resource-constrained clients to perform large-scale data computation. Since large matrix determinant computation (DC) is ubiquitous in the fields of science and engineering, a first step is taken in this paper to design a protocol that enables clients to securely, verifiably, and efficiently outsource DC to a malicious cloud. The main idea to protect the privacy is employing some transformations on the original matrix to get an encrypted matrix which is sent to the cloud; and then transforming the result returned from the cloud to get the correct determinant of the original matrix. Afterwards, a randomized Monte Carlo verification algorithm with one-sided error is introduced, whose superiority in designing inexpensive result verification algorithm for secure outsourcing is well demonstrated. In addition, it is analytically shown that the proposed protocol simultaneously fulfills the goals of correctness, security, robust cheating resistance, and high-efficiency. Extensive theoretical analysis and experimental evaluation also show its high-efficiency and immediate practicability. It is hoped that the proposed protocol can shed light in designing other novel secure outsourcing protocols, and inspire powerful companies and working groups to finish the programming of the demanded all-inclusive scientific computations outsourcing software system. It is believed that such software system can be profitable by means of providing large-scale scientific computation services for so many potential clients.","Outsourcing,
Protocols,
Vectors,
Cryptography,
Cloud computing,
Computational modeling"
Finding the Secret of Image Saliency in the Frequency Domain,"There are two sides to every story of visual saliency modeling in the frequency domain. On the one hand, image saliency can be effectively estimated by applying simple operations to the frequency spectrum. On the other hand, it is still unclear which part of the frequency spectrum contributes the most to popping-out targets and suppressing distractors. Toward this end, this paper tentatively explores the secret of image saliency in the frequency domain. From the results obtained in several qualitative and quantitative experiments, we find that the secret of visual saliency may mainly hide in the phases of intermediate frequencies. To explain this finding, we reinterpret the concept of discrete Fourier transform from the perspective of template-based contrast computation and thus develop several principles for designing the saliency detector in the frequency domain. Following these principles, we propose a novel approach to design the saliency detector under the assistance of prior knowledge obtained through both unsupervised and supervised learning processes. Experimental results on a public image benchmark show that the learned saliency detector outperforms 18 state-of-the-art approaches in predicting human fixations.","Fourier transforms,
Frequency-domain analysis,
Computational modeling,
Artificial intelligence,
Discrete Fourier transforms,
Prediction models,
Discrete cosine transforms"
Super-Resolution Land Cover Mapping Based on Multiscale Spatial Regularization,"Super-resolution mapping (SRM) is a method for allocating land cover classes at a fine scale according to coarse fraction images. Based on a spatial regularization framework, this paper proposes a new regularization method for SRM that integrates multiscale spatial information from the fine scale as a smooth term and from the coarse scale as a penalty term. The smooth term is considered a homogeneity constraint, and the penalty term is used to characterize the heterogeneity constraint. Specifically, the smooth term depends on the local fine scale spatial consistency, and is used to smooth edges and eliminate speckle points. The penalty term depends on the coarse scale local spatial differences, and suppresses the over-smoothing effect from the fine scale information while preserving more details (e.g., connectivity and aggregation of linear land cover patterns). We validated our method using simulated and synthetic images, and compared the results to four representative SRM algorithms. Our numerical experiments demonstrated that the proposed method can produce more accurate maps, reduce differences in the number of patches, visually preserve smoother edges and more details, reject speckle points, and suppress over-smoothing.","Spatial resolution,
Linear programming,
Manganese,
Accuracy,
Remote sensing,
Indexes"
Support-Vector-Machine-Enhanced Markov Model for Short-Term Wind Power Forecast,"Wind ramps introduce significant uncertainty into wind power generation. Reliable system operation, however, requires accurate detection and forecast of wind ramps, especially at high penetration levels. In this paper, to deal with the wind ramp dynamics, a support vector machine (SVM)-enhanced Markov model is developed for short-term wind power forecast, based on one key observation from the measurement data that wind ramps often occur with specific patterns. Specifically, using the historical data of the wind turbine power outputs recorded at an actual wind farm, data analytics-based finite-state Markov models are first developed to model the normal fluctuations of wind generation, while taking into account the diurnal nonstationarity and the seasonality of wind generation. Next, the forecast by the SVM is integrated cohesively into the finite-state Markov models. Based on the SVM-enhanced Markov model, both short-term distributional forecasts and point forecasts are then derived. Numerical test results, using real wind generation data traces, demonstrate the significantly improved accuracy of the proposed forecast approach.","Wind forecasting,
Markov processes,
Wind power generation,
Support vector machines,
Predictive models,
Wind farms"
FPGA Trojans Through Detecting and Weakening of Cryptographic Primitives,"This paper investigates a novel attack vector against cryptography realized on FPGAs, which poses a serious threat to real-world applications. We demonstrate how a targeted bitstream modification can seriously weaken cryptographic algorithms, which we show with the examples of AES and 3-DES. The attack is performed by modifying the FPGA bitstream that configures the hardware elements during initialization. Recently, it has been shown that cloning of FPGA designs is feasible, even if the bitstream is encrypted. However, due to its proprietary file format, a meaningful modification is challenging. While some previous work addressed bitstream reverse-engineering, so far it has not been evaluated how difficult it is to detect and modify cryptographic elements. We outline two possible practical attacks that have serious security implications. We target the S-boxes of block ciphers that can be implemented in look-up tables or stored as precomputed set of values in the memory of the FPGA. We demonstrate that it is possible to detect and apply meaningful changes to cryptographic elements inside an unknown, proprietary, and undocumented bitstream. Our proposed attack does not require any knowledge of the internal routing. Furthermore, we show how an AES key can be revealed within seconds. Finally, we discuss countermeasures that can raise the bar for an adversary to successfully perform this kind of attack.",
FESTAL: Fault-Tolerant Elastic Scheduling Algorithm for Real-Time Tasks in Virtualized Clouds,"As clouds have been deployed widely in various fields, the reliability and availability of clouds become the major concern of cloud service providers and users. Thereby, fault tolerance in clouds receives a great deal of attention in both industry and academia, especially for real-time applications due to their safety critical nature. Large amounts of researches have been conducted to realize fault tolerance in distributed systems, among which fault-tolerant scheduling plays a significant role. However, few researches on the fault-tolerant scheduling study the virtualization and the elasticity, two key features of clouds, sufficiently. To address this issue, this paper presents a fault-tolerant mechanism which extends the primary-backup model to incorporate the features of clouds. Meanwhile, for the first time, we propose an elastic resource provisioning mechanism in the fault-tolerant context to improve the resource utilization. On the basis of the fault-tolerant mechanism and the elastic resource provisioning mechanism, we design novel fault-tolerant elastic scheduling algorithms for real-time tasks in clouds named FESTAL, aiming at achieving both fault tolerance and high resource utilization in clouds. Extensive experiments injecting with random synthetic workloads as well as the workload from the latest version of the Google cloud tracelogs are conducted by CloudSim to compare FESTAL with three baseline algorithms, i.e., Non-M igration-FESTAL (NMFESTAL), Non-Overlapping-FESTAL (NOFESTAL), and Elastic First Fit (EFF). The experimental results demonstrate that FESTAL is able to effectively enhance the performance of virtualized clouds.",
Matching Pursuit LASSO Part I: Sparse Recovery Over Big Dictionary,"Large-scale sparse recovery (SR) by solving ℓ1-norm relaxations over Big Dictionary is a very challenging task. Plenty of greedy methods have therefore been proposed to address big SR problems, but most of them require restricted conditions for the convergence. Moreover, it is non-trivial for them to incorporate the ℓ1-norm regularization that is required for robust signal recovery. We address these issues in this paper by proposing a Matching Pursuit LASSO (MPL) algorithm, based on a novel quadratically constrained linear program (QCLP) formulation, which has several advantages over existing methods. Firstly, it is guaranteed to converge to a global solution. Secondly, it greatly reduces the computation cost of the ℓ1-norm methods over Big Dictionaries. Lastly, the exact sparse recovery condition of MPL is also investigated.","Matching pursuit algorithms,
Signal processing algorithms,
Dictionaries,
Convergence,
Algorithm design and analysis,
Indexes,
Quantum cascade lasers"
A Miniature-Implantable Antenna for MedRadio-Band Biomedical Telemetry,"This letter presents a compact implantable antenna for biotelemetry in the Medical Device Radiocommunications Service (MedRadio) band (401-406 MHz). By employing meandering and shorting strategy, the whole dimension (including the superstrate) of the proposed antenna can be significantly reduced to 12.5 ×12.5 ×1.27 mm3, equivalent to 0.0168λ0 ×0.0168λ0 ×0.0017λ0 ( λ0 is the free-space wavelength at 403 MHz). Instead of common miniaturization methods used for implantable antennas, such as stacking multilayers and embedding slots on the ground plane, the proposed antenna is fabricated on the single-layer substrate with a full ground plane. Therefore, the proposed antenna is characterized by the advantages of easy manufacture, low cost, light mass and less sensitivity to package environment. The simulated and measured bandwidths are 6.15% and 7.26%, respectively. The peak realized gain is -32.49 dBi at 403 MHz. The maximum specific absorption rate (SAR) value satisfies the IEEE standard safety guidelines. A prototype is fabricated and measured in vitro to verify the validity of the presented design.","Antennas,
Antenna measurements,
Phantoms,
Biomedical measurement,
Substrates,
Muscles"
"MErging the Interface: Power, area and accuracy co-optimization for RRAM crossbar-based mixed-signal computing system","The invention of resistive-switching random access memory (RRAM) devices and RRAM crossbar-based computing system (RCS) demonstrate a promising solution for better performance and power efficiency. The interfaces between analog and digital units, especially AD/DAs, take up most of the area and power consumption of RCS and are always the bottleneck of mixed-signal computing systems. In this work, we propose a novel architecture, MEI, to minimize the overhead of AD/DA by MErging the Interface into the RRAM cross-bar. An optional ensemble method, the Serial Array Adaptive Boosting (SAAB), is also introduced to take advantage of the area and power saved by MEI and boost the accuracy and robustness of RCS. On top of these two methods, a design space exploration is proposed to achieve trade-offs among accuracy, area, and power consumption. Experimental results on 6 diverse benchmarks demonstrate that, compared with the traditional architecture with AD/DAs, MEI is able to save 54.63%~86.14% area and reduce 61.82%~86.80% power consumption under quality guarantees; and SAAB can further improve the accuracy by 5.76% on average and ensure the system performance under noisy conditions.",
Reduced out-of-band radiation-based filter optimization for UFMC systems in 5G,"Universal-filtered multi-carrier (UFMC) technique is considered as a potential candidate for future communication systems due to its robustness against inter-carrier interference (ICI), suitability for non-contiguous fragmented available spectrum resources and low latency scenario in 5G network. In this paper, we present a novel pulse shaping approach in UFMC to reduce the spectral leakage into nearby subbands used for same or other users with low complexity and high throughput. In the new scheme, we apply Bohman filter-based pulse shaping with combination of antipodal symbol-pairs to the edge-subcarriers of the subbands, and consequently reduce the out-of-band radiation. This scheme outperforms the current state-of-the art and offers better signal-to-interference ratio (SIR) to improve the robustness against carrier frequency offset (CFO) for energy saving in loosely synchronized scenario. We further validate the proposed scheme on field programmable gate array (FPGA) hardware prototype.","OFDM,
Field programmable gate arrays,
Nickel,
Hardware,
Prototypes,
Read only memory,
Radiation detectors"
SODA: Software defined FPGA based accelerators for big data,"FPGA has been an emerging field in novel big data architectures and systems, due to its high efficiency and low power consumption. It enables the researchers to deploy massive accelerators within one single chip. In this paper, we present a software defined FPGA based accelerators for big data, named SODA, which could reconstruct and reorganize the acceleration engines according to the requirement of the various dataintensive applications. SODA decomposes large and complex applications into coarse grained single-purpose RTL code libraries that perform specialized tasks in out-of-order hardware. We built a prototyping system with constrained shortest path Finding (CSPF) case studies to evaluate SODA framework. SODA is able to achieve up to 43.75X speedup at 128 node application. Furthermore, hardware cost of the SODA framework demonstrates that it can achieve high speedup with moderate hardware utilization.","Hardware,
Field programmable gate arrays,
Operating systems,
Computer architecture,
Programming,
Program processors"
Household Electricity Demand Forecast Based on Context Information and User Daily Schedule Analysis From Meter Data,"The very short-term load forecasting (VSTLF) problem is of particular interest for use in smart grid and automated demand response applications. An effective solution for VSTLF can facilitate real-time electricity deployment and improve its quality. In this paper, a novel approach to model the very short-term load of individual households based on context information and daily schedule pattern analysis is proposed. Several daily behavior pattern types were obtained by analyzing the time series of daily electricity consumption, and context features from various sources were collected and used to establish a rule set for use in anticipating the likely behavior pattern type of a specific day. Meanwhile, an electricity consumption volume prediction model was developed for each behavior pattern type to predict the load at a specific time point in a day. This study was concerned with solving the VSTLF for individual households in Taiwan. The proposed approach obtained an average mean absolute percentage error (MAPE) of 3.23% and 2.44% for forecasting individual household load and aggregation load 30-min ahead, respectively, which is more favorable than other methods.",
Computer-Aided Prostate Cancer Diagnosis From Digitized Histopathology: A Review on Texture-Based Systems,"Prostate cancer (PCa) is currently diagnosed by microscopic evaluation of biopsy samples. Since tissue assessment heavily relies on the pathologists level of expertise and interpretation criteria, it is still a subjective process with high intra- and interobserver variabilities. Computer-aided diagnosis (CAD) may have a major impact on detection and grading of PCa by reducing the pathologists reading time, and increasing the accuracy and reproducibility of diagnosis outcomes. However, the complexity of the prostatic tissue and the large volumes of data generated by biopsy procedures make the development of CAD systems for PCa a challenging task. The problem of automated diagnosis of prostatic carcinoma from histopathology has received a lot of attention. As a result, a number of CAD systems, have been proposed for quantitative image analysis and classification. This review aims at providing a detailed description of selected literature in the field of CAD of PCa, emphasizing the role of texture analysis methods in tissue description. It includes a review of image analysis tools for image preprocessing, feature extraction, classification, and validation techniques used in PCa detection and grading, as well as future directions in pursuit of better texture-based CAD systems.","Pattern recognition,
Image analysis,
Prostate cancer,
Computer aided diagnosis,
Image texture analysis"
Characterizing data deliverability of greedy routing in wireless sensor networks,"As a popular routing protocol in wireless sensor networks (WSNs), greedy routing has received great attention. The previous works characterize its data deliverability in WSNs by the probability of all nodes successfully sending their data to the base station. Their analysis, however, neither provides the information of the quantitative relation between successful data delivery ratio and transmission power of sensor nodes nor considers the impact of the network congestion or link collision on the data deliverability. To address these problems, in this paper, we characterize the data deliverability of greedy routing by the ratio of successful data transmissions from sensors to the base station. We introduce η-guaranteed delivery which means that the ratio of successful data deliveries is not less than η, and study the relationship between the transmission power of sensors and the probability of achieving η-guaranteed delivery. Furthermore, with considering the effect of network congestion and link collision, we provide a more precise and full characterization for the deliverability of greedy routing. Extensive simulation and real-world experimental results show the correctness and tightness of the upper bound of the smallest transmission power for achieving η-guaranteed delivery.","Routing,
Wireless sensor networks,
Interference,
Base stations,
Signal to noise ratio,
Protocols,
Analytical models"
Waveform Design With Unit Modulus and Spectral Shape Constraints via Lagrange Programming Neural Network,"To maximize the transmitted power available in active sensing, the probing waveform should be of constant modulus. On the other hand, in order to adapt to the increasingly crowed radio frequency spectrum and prevent mutual interferences, there are also requirements in the waveform spectral shape. That is to say, the waveform must fulfill constraints in both time and frequency domains. In this work, designing these waveforms is formulated as a nonlinear constrained optimization problem. By introducing auxiliary variable neurons and Lagrange neurons, we solve it using the Lagrange programming neural network. We also analyze the local stability conditions of the dynamic neuron model. Simulation results show that our proposed algorithm is a competitive alternative for waveform design with unit modulus and arbitrary spectral shapes.","Neurons,
Artificial neural networks,
Spectral shape,
Stability analysis,
Lagrangian functions,
Algorithm design and analysis"
AlGaAs Photovoltaics for Indoor Energy Harvesting in mm-Scale Wireless Sensor Nodes,"Indoor photovoltaic energy harvesting is a promising candidate to power millimeter (mm)-scale systems. The theoretical efficiency and electrical performance of photovoltaics under typical indoor lighting conditions are analyzed. Commercial crystalline Si and fabricated GaAs and Al0.2Ga0.8As photovoltaic cells were experimentally measured under simulated AM 1.5 solar irradiation and indoor illumination conditions using a white phosphor light-emitting diode to study the effects of input spectra and illuminance on performance. The Al0.2Ga0.8As cells demonstrated the highest performance with a power conversion efficiency of 21%, with open-circuit voltages >0.65 V under low lighting conditions. The GaAs and Al0.2Ga0.8As cells each provide a power density of ~100 nW/mm2 or more at 250 lx, sufficient for the perpetual operation of present-day low-power mm-scale wireless sensor nodes.","Lighting,
Photovoltaic cells,
Gallium arsenide,
Silicon,
Density measurement,
Photovoltaic systems"
A Framework of Constructions of Minimal Storage Regenerating Codes With the Optimal Access/Update Property,"In this paper, we present a generic framework for constructing systematic minimum storage regenerating codes with two parity nodes based on the invariant subspace technique. Codes constructed in our framework not only contain some best known codes as special cases, but also include some new codes with key properties, such as the optimal access property and the optimal update property. In particular, for a given storage capacity of an individual node, one of the new codes has the largest number of systematic nodes and two of the new codes have the largest number of systematic nodes with the optimal update property.",
Path Planning for Single Unmanned Aerial Vehicle by Separately Evolving Waypoints,"Evolutionary algorithm-based unmanned aerial vehicle (UAV) path planners have been extensively studied for their effectiveness and flexibility. However, they still suffer from a drawback that the high-quality waypoints in previous candidate paths can hardly be exploited for further evolution, since they regard all the waypoints of a path as an integrated individual. Due to this drawback, the previous planners usually fail when encountering lots of obstacles. In this paper, a new idea of separately evaluating and evolving waypoints is presented to solve this problem. Concretely, the original objective and constraint functions of UAVs path planning are decomposed into a set of new evaluation functions, with which waypoints on a path can be evaluated separately. The new evaluation functions allow waypoints on a path to be evolved separately and, thus, high-quality waypoints can be better exploited. On this basis, the waypoints are encoded in a rotated coordinate system with an external restriction and evolved with JADE, a state-of-the-art variant of the differential evolution algorithm. To test the capabilities of the new planner on planning obstacle-free paths, five scenarios with increasing numbers of obstacles are constructed. Three existing planners and four variants of the proposed planner are compared to assess the effectiveness and efficiency of the proposed planner. The results demonstrate the superiority of the proposed planner and the idea of separate evolution.","Planning,
Path planning,
Space missions,
Robots,
Missiles,
Turning,
Unmanned aerial vehicles"
SHAHED: A MapReduce-based system for querying and visualizing spatio-temporal satellite data,"Remote sensing data collected by satellites are now made publicly available by several space agencies. This data is very useful for scientists pursuing research in several applications including climate change, desertification, and land use change. The benefit of this data comes from its richness as it provides an archived history for over 15 years of satellite observations for natural phenomena such as temperature and vegetation. Unfortunately, the use of such data is very limited due to the huge size of archives (> 500TB) and the limited capabilities of traditional applications. This paper introduces SHAHED; a MapReduce-based system for querying, visualizing, and mining large scale satellite data. SHAHED considers both the spatial and temporal aspects of the data to provide efficient query processing at large scale. The core of SHAHED is composed of four main components. The uncertainty component recovers missing data in the input which comes from cloud coverage and satellite mis-alignment. The indexing component provides a novel multi-resolution quad-tree-based spatio-temporal index structure, which indexes satellite data efficiently with minimal space overhead. The querying component answers selection and aggregate queries in real-time using the constructed index. Finally, the visualization component uses MapReduce programs to generate heat map images and videos for user queries. A set of experiments running on a live system deployed on a cluster of machines show the efficiency of the proposed design. All the features supported by SHAHED are made accessible through an easy to use Web interface that hides the complexity of the system and provides a nice user experience.",
Energy-Efficient Resource Allocation for Fractional Frequency Reuse in Heterogeneous Networks,"Next generation wireless networks face the challenge of increasing energy consumption while satisfying the unprecedented increase in the data rate demand. To address this problem, we propose a utility-based energy-efficient resource allocation algorithm for the downlink transmissions in heterogeneous networks (HetNets). We consider the fractional frequency reuse (FFR) method in order to mitigate the intra- and inter-cell interference. The proposed algorithm divides the resource allocation problem into frequency and power assignment problems and sequentially solves them. The proposed power control algorithm uses the gradient ascent method to control the transmit power of macrocell base stations (MeNBs) as most of the power in the network is consumed there. We present the optimality conditions of the resource allocation problem and the convergence of the proposed algorithm. In order to mitigate the inter-cell interference further, we study the interference pricing mechanisms and obtain an upper bound to the maximum energy efficiency problem including the inter-cell interference contributions. The performance of the proposed algorithm is studied in a Long Term Evolution (LTE) system. Our simulation results demonstrate that the proposed algorithm provides substantial improvements in the energy efficiency and throughput of the network. It is also shown that interference pricing provides only marginal improvements over the proposed algorithm.","Interference,
Resource management,
Base stations,
Power demand,
Throughput,
Pricing,
Power control"
"TFET-Based Circuit Design Using the Transconductance Generation Efficiency
g
m
/
I
d
Method","Tunnel field effect transistors (TFETs) have emerged as one of the most promising post-CMOS transistor technologies. In this paper, we: 1) review the perspectives of such devices for low-power high-frequency analog integrated circuit applications (e.g., GHz operation with sub-0.1 mW power consumption); 2) discuss and employ a compact TFET device model in the context of the gm/Id integrated analog circuit design methodology; and 3) compare several proposed TFET technologies for such applications. The advantages of TFETs arise since these devices can operate in the sub-threshold region with larger transconductance-to-current ratio than traditional FETs, which is due to the current turn-on mechanism being interband tunneling rather than thermionic emission. Starting from technology computer-aided design and/or analytical models for Si-FinFETs, graphene nano-ribbon (GNR) TFETs and InAs/GaSb TFETs at the 15-nm gate-length node, as well as InAs double-gate TFETs at the 20-nm gate-length node, we conclude that GNR TFETs might promise larger bandwidths at low-voltage drives due to their high current densities in the sub-threshold region. Based on this analysis and on theoretically predicted properties, GNR TFETs are identified as one of the most attractive field effect transistor technologies proposed-to-date for ultra-low power analog applications.","Mathematical model,
Logic gates,
Field effect transistors,
Integrated circuit modeling,
Analytical models,
Circuit synthesis"
Graph-Based Approaches for Over-Sampling in the Context of Ordinal Regression,"The classification of patterns into naturally ordered labels is referred to as ordinal regression or ordinal classification. Usually, this classification setting is by nature highly imbalanced, because there are classes in the problem that are a priori more probable than others. Although standard over-sampling methods can improve the classification of minority classes in ordinal classification, they tend to introduce severe errors in terms of the ordinal label scale, given that they do not take the ordering into account. A specific ordinal over-sampling method is developed in this paper for the first time in order to improve the performance of machine learning classifiers. The method proposed includes ordinal information by approaching over-sampling from a graph-based perspective. The results presented in this paper show the good synergy of a popular ordinal regression method (a reformulation of support vector machines) with the graph-based proposed algorithms, and the possibility of improving both the classification and the ordering of minority classes. A cost-sensitive version of the ordinal regression method is also introduced and compared with the over-sampling proposals, showing in general lower performance for minority classes.","Support vector machines,
Investment,
Context,
Standards,
Labeling,
Educational institutions,
Training"
Array Miniaturization Through QCTO-SI Metamaterial Radomes,"The array miniaturization problem is addressed by means of a material-by-design approach. More specifically, an innovative strategy that integrates a quasi-conformal transformation optics (QCTO) technique and a source inversion method is proposed to design radome-coated arrays exhibiting the same radiation properties of wider virtual arrangements comprising more antenna elements. Toward this end, the state-of-the-art QCTO theory is generalized to account for source constraints within the synthesis process. Representative numerical examples are provided to assess the reliability, the flexibility, and the effectiveness of the proposed synthesis approach as well as the possibility to realize suboptimal radomes with simplified, but cheaper/easier, structures (e.g., structures based on tiles of isotropic dielectrics).","Arrays,
Geometry,
Layout,
Apertures,
Metamaterials,
Dielectrics,
Lenses"
More about VLAD: A leap from Euclidean to Riemannian manifolds,"This paper takes a step forward in image and video coding by extending the well-known Vector of Locally Aggregated Descriptors (VLAD) onto an extensive space of curved Riemannian manifolds. We provide a comprehensive mathematical framework that formulates the aggregation problem of such manifold data into an elegant solution. In particular, we consider structured descriptors from visual data, namely Region Covariance Descriptors and linear subspaces that reside on the manifold of Symmetric Positive Definite matrices and the Grassmannian manifolds, respectively. Through rigorous experimental validation, we demonstrate the superior performance of this novel Riemannian VLAD descriptor on several visual classification tasks including video-based face recognition, dynamic scene recognition, and head pose classification.",
Short-Term Electric Load Forecasting Using Echo State Networks and PCA Decomposition,"In this paper, we approach the problem of forecasting a time series (TS) of an electrical load measured on the Azienda Comunale Energia e Ambiente (ACEA) power grid, the company managing the electricity distribution in Rome, Italy, with an echo state network (ESN) considering two different leading times of 10 min and 1 day. We use a standard approach for predicting the load in the next 10 min, while, for a forecast horizon of one day, we represent the data with a high-dimensional multi-variate TS, where the number of variables is equivalent to the quantity of measurements registered in a day. Through the orthogonal transformation returned by PCA decomposition, we reduce the dimensionality of the TS to a lower number k of distinct variables; this allows us to cast the original prediction problem in k different one-step ahead predictions. The overall forecast can be effectively managed by k distinct prediction models, whose outputs are combined together to obtain the final result. We employ a genetic algorithm for tuning the parameters of the ESN and compare its prediction accuracy with a standard autoregressive integrated moving average model.","Forecasting,
Time series analysis,
Load management,
Predictive models,
Genetic algorithms,
Smart grids"
High-Throughput Reliable Multicast in Multi-Hop Wireless Mesh Networks,"This paper presents a cross-layer approach for enabling high-throughput reliable multicast in multi-hop wireless mesh networks. The building block of our approach is a multicast routing metric, called the expected multicast transmission count (EMTX). EMTX is designed to capture the combined effects of MAC-layer retransmission-based reliability, wireless broadcast advantage, and link quality awareness. The EMTX of single-hop transmission of a multicast packet from a sender is the expected number of multicast transmissions (including retransmissions) required for its next-hop recipients to receive the packet successfully. We formulate the EMTX-based multicast problem with the objective of minimizing the sum of EMTX over all forwarding nodes in the multicast tree, aiming to reduce network bandwidth consumption while ensure high end-to-end packet delivery ratio for the multicast traffic. We provide rigorous mathematical formulations and methods to find near-optimal solutions of the problem computationally efficiently. We present centralized and distributed algorithms, and demonstrate their effectiveness in tackling the EMTX-based multicast problem with a combination of theoretical and numerical results. Simulation experiments show that, in comparison with two baseline approaches, EMTX-based multicast routing reduces the number of hop-by-hop transmissions per packet by up to 40 percent and yet improves the multicast throughput by up to 24 percent.",
Quality of Contributed Service and Market Equilibrium for Participatory Sensing,"User-contributed or crowd-sourced information is becoming increasingly common. In this paper, we consider the specific case of participatory sensing whereby people contribute information captured by sensors, typically those on a smartphone, and share the information with others. We propose a new metric called quality of contributed service (QCS) which characterizes the information quality and timeliness of a specific real-time sensed quantity achieved in a participatory manner. Participatory sensing has the problem that contributions are sporadic and infrequent. To overcome this, we formulate a market-based framework for participatory sensing with plausible models of the market participants comprising data contributors, service consumers and a service provider. We analyze the market equilibrium and obtain a closed form expression for the resulting QCS at market equilibrium. Next, we examine the effects of realistic behaviors of the market participants and the nature of the market equilibrium that emerges through extensive simulations. Our results show that, starting from purely random behavior, the market and its participants can converge to the market equilibrium with good QCS within a short period of time.","Crowdsourcing,
Mobile computing,
Consumer behavior,
Behavioral science,
Human factors,
Economics,
Market research,
Crowdsourcing,
Smart phones,
Market opportunities"
An Air Index for Spatial Query Processing in Road Networks,"Spatial queries such as range query and kNN query in road networks have received a growing number of attention in real life. Considering the large population of the users and the high overhead of network distance computation, it is extremely important to guarantee the efficiency and scalability of query processing. Motivated by the scalable and secure properties of wireless broadcast model, this paper presents an air index called Network Partition Index (NPI) to support efficient spatial query processing in road networks via wireless broadcast. The main idea is to partition the road network into a number of regions and then build the index to carry some pre-computation information of each region. We also propose multiple client-side algorithms to facilitate the processing of different spatial queries such as kNN query, range query and CNN query. A comprehensive experimental study has been conducted to demonstrate the efficiency of our scheme.","Roads,
Indexes,
Wireless communication,
Mobile communication,
Query processing,
Servers,
Mobile computing"
A stochastic geometry analysis of D2D overlaying multi-channel downlink cellular networks,"Based on the tool of stochastic geometry, we present in this paper a framework for analyzing the coverage probability and ergodic rate in a D2D overlaying multi-channel downlink cellular network. Different from previous works, 1) we consider a flexible new scheme for mobile UEs to select operation mode individually, under which a mobile UE decides to establish a cellular link (with a BS) or a D2D link (with a neighboring UE) based on the pilot signal strength received from its nearest BS; 2) we allow a mobile UE which is located far from BSs to connect to a nearby BS via another intermediate UE in a two-hop manner. Our results indicate that the developed framework is very helpful for network designers to efficiently determine the optimal network parameters at which the optimum system performance can be achieved. Furthermore, as corroborated by extensive numerical results, enabling the D2D link based two-hop connection can significantly improve the network coverage performance, especially for the low SIR regime.",
A Direct PCA-Based Approach for Real-Time Description of Physiological Organ Deformations,"Dynamic magnetic resonance (MR)-imaging can provide functional and positional information in real-time, which can be conveniently used online to control a cancer therapy, e.g., using high intensity focused ultrasound or radio therapy. However, a precise real-time correction for motion is fundamental in abdominal organs to ensure an optimal treatment dose associated with a limited toxicity in nearby organs at risk. This paper proposes a real-time direct principal component analysis (PCA)-based technique which offers a robust approach for motion estimation of abdominal organs and allows correcting motion related artifacts. The PCA was used to detect spatio-temporal coherences of the periodic organ motion in a learning step. During the interventional procedure, physiological contributions were characterized quantitatively using a small set of parameters. A coarse-to-fine resolution scheme is proposed to improve the stability of the algorithm and afford a predictable constant latency of 80 ms. The technique was evaluated on 12 free-breathing volunteers and provided an improved real-time description of motion related to both breathing and cardiac cycles. A reduced learning step of 10 s was sufficient without any need for patient-specific control parameters, rendering the method suitable for clinical use.","Real-time systems,
Principal component analysis,
Physiology,
Minimization,
Motion estimation,
Kidney,
Liver"
Compressed Sensing MRI via Two-stage Reconstruction,"Compressed sensing (CS) has been applied to magnetic resonance imaging for the acceleration of data collection. However, existing CS techniques usually produce images with residual artifacts, particularly at high reduction factors. In this paper, we propose a novel, two-stage reconstruction scheme, which takes advantage of the properties of k-space data and under-sampling patterns that are useful in CS. In this algorithm, the under-sampled k-space data is segmented into low-frequency and high-frequency domains. Then, in stage one, using dense measurements, the low-frequency region of k-space data is faithfully reconstructed. The fully reconstituted low-frequency k-space data from the first stage is then combined with the high-frequency k-space data to complete the second stage reconstruction of the whole of k-space. With this two-stage approach, each reconstruction inherently incorporates a lower data under-sampling rate and more homogeneous signal magnitudes than conventional approaches. Because the restricted isometric property is easier to satisfy, the reconstruction consequently produces lower residual errors at each step. Compared with a conventional CS reconstruction, for the cases of cardiac cine, brain and angiogram imaging, the proposed method achieves a more accurate reconstruction with an improvement of 2-4 dB in peak signal-to-noise ratio respectively, using reduction factors of up to 6.","Image reconstruction,
Magnetic resonance imaging,
Image segmentation,
Wavelet coefficients,
PSNR,
Biomedical measurement"
Relational Collaborative Topic Regression for Recommender Systems,"Due to its successful application in recommender systems, collaborative filtering (CF) has become a hot research topic in data mining and information retrieval. In traditional CF methods, only the feedback matrix, which contains either explicit feedback (also called ratings) or implicit feedback on the items given by users, is used for training and prediction. Typically, the feedback matrix is sparse, which means that most users interact with few items. Due to this sparsity problem, traditional CF with only feedback information will suffer from unsatisfactory performance. Recently, many researchers have proposed to utilize auxiliary information, such as item content (attributes), to alleviate the data sparsity problem in CF. Collaborative topic regression (CTR) is one of these methods which has achieved promising performance by successfully integrating both feedback information and item content information. In many real applications, besides the feedback and item content information, there may exist relations (also known as networks) among the items which can be helpful for recommendation. In this paper, we develop a novel hierarchical Bayesian model called Relational Collaborative Topic Regression (RCTR), which extends CTR by seamlessly integrating the user-item feedback information, item content information, and network structure among items into the same model. Experiments on real-world datasets show that our model can achieve better prediction accuracy than the state-of-the-art methods with lower empirical training time. Moreover, RCTR can learn good interpretable latent structures which are useful for recommendation.","Vectors,
Collaboration,
Predictive models,
Training,
Accuracy,
Recommender systems,
Sparse matrices"
Fuzzy Stochastic Optimal Guaranteed Cost Control of Bio-Economic Singular Markovian Jump Systems,"This paper establishes a bio-economic singular Markovian jump model by considering the price of the commodity as a Markov chain. The controller is designed for this system such that its biomass achieves the specified range with the least cost in a finite-time. Firstly, this system is described by Takagi-Sugeno fuzzy model. Secondly, a new design method of fuzzy state-feedback controllers is presented to ensure not only the regularity, nonimpulse, and stochastic singular finite-time boundedness of this kind of systems, but also an upper bound achieved for the cost function in the form of strict linear matrix inequalities. Finally, two examples including a practical example of eel seedling breeding are given to illustrate the merit and usability of the approach proposed in this paper.","Sociology,
Statistics,
Biological system modeling,
Economics,
Cost function,
Stochastic processes,
Mathematical model"
Role Discovery in Networks,"Roles represent node-level connectivity patterns such as star-center, star-edge nodes, near-cliques or nodes that act as bridges to different regions of the graph. Intuitively, two nodes belong to the same role if they are structurally similar. Roles have been mainly of interest to sociologists, but more recently, roles have become increasingly useful in other domains. Traditionally, the notion of roles were defined based on graph equivalences such as structural, regular, and stochastic equivalences. We briefly revisit these early notions and instead propose a more general formulation of roles based on the similarity of a feature representation (in contrast to the graph representation). This leads us to propose a taxonomy of three general classes of techniques for discovering roles that includes (i) graph-based roles, (ii) feature-based roles, and (iii) hybrid roles. We also propose a flexible framework for discovering roles using the notion of similarity on a feature-based representation. The framework consists of two fundamental components: (a) role feature construction and (b) role assignment using the learned feature representation. We discuss the different possibilities for discovering feature-based roles and the tradeoffs of the many techniques for computing them. Finally, we discuss potential applications and future directions and challenges.","Communities,
Taxonomy,
Computational modeling,
Social network services,
Stochastic processes,
Correlation,
Bridges"
Landmark Classification With Hierarchical Multi-Modal Exemplar Feature,"Landmark image classification attracts increasing research attention due to its great importance in real applications, ranging from travel guide recommendation to 3-D modelling and visualization of geolocation. While large amount of efforts have been invested, it still remains unsolved by academia and industry. One of the key reasons is the large intra-class variance rooted from the diverse visual appearance of landmark images. Distinguished from most existing methods based on scalable image search, we approach the problem from a new perspective and model landmark classification as multi-modal categorization , which enjoys advantages of low storage overhead and high classification efficiency. Toward this goal, a novel and effective feature representation, called hierarchical multi-modal exemplar (HMME) feature, is proposed to characterize landmark images. In order to compute HMME, training images are first partitioned into the regions with hierarchical grids to generate candidate images and regions. Then, at the stage of exemplar selection, hierarchical discriminative exemplars in multiple modalities are discovered automatically via iterative boosting and latent region label mining. Finally, HMME is generated via a region-based locality-constrained linear coding (RLLC), which effectively encodes semantics of the discovered exemplars into HMME. Meanwhile, dimension reduction is applied to reduce redundant information by projecting the raw HMME into lower-dimensional space. The final HMME enjoys advantages of discriminative and linearly separable. Experimental study has been carried out on real world landmark datasets, and the results demonstrate the superior performance of the proposed approach over several state-of-the-art techniques.",
Eye Gaze Tracking With a Web Camera in a Desktop Environment,"This paper addresses the eye gaze tracking problem using a low cost and more convenient web camera in a desktop environment, as opposed to gaze tracking techniques requiring specific hardware, e.g, infrared high-resolution camera and infrared light sources, as well as a cumbersome calibration process. In the proposed method, we first track the human face in a real-time video sequence to extract the eye regions. Then, we combine intensity energy and edge strength to obtain the iris center and utilize the piecewise eye corner detector to detect the eye corner. We adopt a sinusoidal head model to simulate the 3-D head shape, and propose an adaptive weighted facial features embedded in the pose from the orthography and scaling with iterations algorithm, whereby the head pose can be estimated. Finally, the eye gaze tracking is accomplished by integration of the eye vector and the head movement information. Experiments are performed to estimate the eye movement and head pose on the BioID dataset and pose dataset, respectively. In addition, experiments for gaze tracking are performed in real-time video sequences under a desktop environment. The proposed method is not sensitive to the light conditions. Experimental results show that our method achieves an average accuracy of around 1.28° without head movement and 2.27° with minor movement of the head.",
Video Compression Artifact Reduction via Spatio-Temporal Multi-Hypothesis Prediction,"Annoying compression artifacts exist in most of lossy coded videos at low bit rates, which are caused by coarse quantization of transform coefficients or motion compensation from distorted frames. In this paper, we propose a compression artifact reduction approach that utilizes both the spatial and the temporal correlation to form multi-hypothesis predictions from spatio-temporal similar blocks. For each transform block, three predictions with their reliabilities are estimated, respectively. The first prediction is constructed by inversely quantizing transform coefficients directly, and its reliability is determined by the variance of quantization noise. The second prediction is derived by representing each transform block with a temporal auto-regressive (TAR) model along its motion trajectory, and its corresponding reliability is estimated from local prediction errors of the TAR model. The last prediction infers the original coefficients from similar blocks in non-local regions, and its reliability is estimated based on the distribution of coefficients in these similar blocks. Finally, all the predictions are adaptively fused according to their reliabilities to restore high-quality videos. The experimental results show that the proposed method can efficiently reduce most of the compression artifacts and improve both subjective and objective quality of block transform coded videos.","Noise,
Image coding,
Reliability,
Quantization (signal),
Image reconstruction,
Discrete cosine transforms"
Nontechnical Loss and Outage Detection Using Fractional-Order Self-Synchronization Error-Based Fuzzy Petri Nets in Micro-Distribution Systems,"Load management is a challenging issue in micro-distribution systems dealing with power utilities. To efficiently detect fraudulent and abnormal consumption, this paper proposes the use of fractional-order self-synchronization error-based Fuzzy Petri nets (FPNs) to detect nontechnical losses and outage events. Under the advanced metering infrastructure technique, the Sprott system is a feature extractor, which tracks the differences between profiled usages and irregular usages, such as illegal and fault events. Thus, fraudulent consumption, outages, and service restoration activities can be pointed out, randomly initiated, and terminated in a real-time application. Multiple FPNs-based making-decision systems are used to locate abnormalities. Computer simulations are conducted using an IEEE 30-bus power system and medium-scale micro-distribution systems to show the effectiveness of the proposed method.","Feature extraction,
Real-time systems,
Time-frequency analysis,
Electricity,
Support vector machines,
Mathematical model,
Equations"
Optimal Experimental Design for Gene Regulatory Networks in the Presence of Uncertainty,"Of major interest to translational genomics is the intervention in gene regulatory networks (GRNs) to affect cell behavior; in particular, to alter pathological phenotypes. Owing to the complexity of GRNs, accurate network inference is practically challenging and GRN models often contain considerable amounts of uncertainty. Considering the cost and time required for conducting biological experiments, it is desirable to have a systematic method for prioritizing potential experiments so that an experiment can be chosen to optimally reduce network uncertainty. Moreover, from a translational perspective it is crucial that GRN uncertainty be quantified and reduced in a manner that pertains to the operational cost that it induces, such as the cost of network intervention. In this work, we utilize the concept of mean objective cost of uncertainty (MOCU) to propose a novel framework for optimal experimental design. In the proposed framework, potential experiments are prioritized based on the MOCU expected to remain after conducting the experiment. Based on this prioritization, one can select an optimal experiment with the largest potential to reduce the pertinent uncertainty present in the current network model. We demonstrate the effectiveness of the proposed method via extensive simulations based on synthetic and real gene regulatory networks.","Uncertainty,
Bioinformatics,
Computational biology,
Biological system modeling,
Design methodology,
Computational modeling"
Robust 2DPCA With Non-greedy \ell _{1} -Norm Maximization for Image Analysis,"2-D principal component analysis based on ℓ1-norm (2DPCA-L1) is a recently developed approach for robust dimensionality reduction and feature extraction in image domain. Normally, a greedy strategy is applied due to the difficulty of directly solving the ℓ1-norm maximization problem, which is, however, easy to get stuck in local solution. In this paper, we propose a robust 2DPCA with non-greedy ℓ1-norm maximization in which all projection directions are optimized simultaneously. Experimental results on face and other datasets confirm the effectiveness of the proposed approach.",
Ultrasound RF Time Series for Classification of Breast Lesions,"This work reports the use of ultrasound radio frequency (RF) time series analysis as a method for ultrasound-based classification of malignant breast lesions. The RF time series method is versatile and requires only a few seconds of raw ultrasound data with no need for additional instrumentation. Using the RF time series features, and a machine learning framework, we have generated malignancy maps, from the estimated cancer likelihood, for decision support in biopsy recommendation. These maps depict the likelihood of malignancy for regions of size 1 mm2 within the suspicious lesions. We report an area under receiver operating characteristics curve of 0.86 (95% confidence interval [CI]: 0.84%-0.90%) using support vector machines and 0.81 (95% CI: 0.78-0.85) using Random Forests classification algorithms, on 22 subjects with leave-one-subject-out cross-validation. Changing the classification method yielded consistent results which indicates the robustness of this tissue typing method. The findings of this report suggest that ultrasound RF time series, along with the developed machine learning framework, can help in differentiating malignant from benign breast lesions, subsequently reducing the number of unnecessary biopsies after mammography screening.","Radio frequency,
Lesions,
Time series analysis,
Ultrasonic imaging,
Cancer,
Breast,
Biopsy"
An Efficient Approach to Generating Location-Sensitive Recommendations in Ad-hoc Social Network Environments,"Social recommendation has been popular and successful in various urban sustainable applications such as online sharing, products recommendation and shopping services. These applications allow users to form several implicit social networks through their daily social interactions. The users in such social networks can rate some interesting items and give comments. The majority of the existing studies have investigated the rating prediction and recommendation of items based on user-item bipartite graph and user-user social graph, so called social recommendation. However, the spatial factor was not considered in their recommendation mechanisms. With the rapid development of the service of location-based social networks, the spatial information gradually affects the quality and correlation of rating and recommendation of items. This paper proposes spatial social union (SSU), an approach of similarity measurement between two users that integrates the interconnection among users, items and locations. The SSU-aware location-sensitive recommendation algorithm is then devised. We evaluate and compare the proposed approach with the existing rating prediction and item recommendation algorithms subject to a real-life data set. Experimental results show that the proposed SSU-aware recommendation algorithm is more effective in recommending items with the better consideration of user's preference and location.","Social network services,
Bipartite graph,
Ad hoc networks,
Communities,
Prediction algorithms,
Collaboration,
Educational institutions"
Supervised Hashing Using Graph Cuts and Boosted Decision Trees,"To build large-scale query-by-example image retrieval systems, embedding image features into a binary Hamming space provides great benefits. Supervised hashing aims to map the original features to compact binary codes that are able to preserve label based similarity in the binary Hamming space. Most existing approaches apply a single form of hash function, and an optimization process which is typically deeply coupled to this specific form. This tight coupling restricts the flexibility of those methods, and can result in complex optimization problems that are difficult to solve. In this work we proffer a flexible yet simple framework that is able to accommodate different types of loss functions and hash functions. The proposed framework allows a number of existing approaches to hashing to be placed in context, and simplifies the development of new problem-specific hashing methods. Our framework decomposes the hashing learning problem into two steps: binary code (hash bit) learning and hash function learning. The first step can typically be formulated as binary quadratic problems, and the second step can be accomplished by training a standard binary classifier. For solving large-scale binary code inference, we show how it is possible to ensure that the binary quadratic problems are submodular such that efficient graph cut methods may be used. To achieve efficiency as well as efficacy on large-scale high-dimensional data, we propose to use boosted decision trees as the hash functions, which are nonlinear, highly descriptive, and are very fast to train and evaluate. Experiments demonstrate that the proposed method significantly outperforms most state-of-the-art methods, especially on high-dimensional data.","Binary codes,
Optimization,
Hamming distance,
Training,
Kernel,
Decision trees,
Inference algorithms"
Day-Ahead Power Output Forecasting for Small-Scale Solar Photovoltaic Electricity Generators,"Because of the rapid growth of small-scale solar electricity generation over the past few years, forecasting solar power output is becoming more important. However, changes in weather conditions cause solar power generation to be highly volatile. This paper analyses the challenges of solar power forecasting and then presents a similar day-based forecasting tool to do 24-h-ahead forecasting for small-scale solar power output forecasting.","Forecasting,
Weather forecasting,
Predictive models,
Clouds,
Engines,
Electricity"
A Generalized Spatial Correlation Model for 3D MIMO Channels Based on the Fourier Coefficients of Power Spectrums,"Previous studies have confirmed the adverse impact of fading correlation on the mutual information (MI) of two-dimensional (2D) multiple-input multiple-output (MIMO) systems. More recently, the trend is to enhance the system performance by exploiting the channels degrees of freedom in the elevation, which necessitates the derivation and characterization of three-dimensional (3D) channels in the presence of spatial correlation. In this paper, an exact closed-form expression for the Spatial Correlation Function (SCF) is derived for 3D MIMO channels. The proposed method resorts to the spherical harmonic expansion (SHE) of plane waves and the trigonometric expansion of Legendre and associated Legendre polynomials. The resulting expression depends on the underlying arbitrary angular distributions and antenna patterns through the Fourier Series (FS) coefficients of power azimuth and elevation spectrums. The novelty of the proposed method lies in the SCF being valid for any 3D propagation environment. The developed SCF determines the covariance matrices at the transmitter and the receiver that form the Kronecker channel model. In order to quantify the effects of correlation on system performance, the information-theoretic deterministic equivalents of the MI for the Kronecker model are utilized in both mono-user and multi-user cases. Numerical results validate the proposed analytical expressions and elucidate the dependence of the system performance on azimuth and elevation angular spreads and antenna patterns. Some useful insights into the behavior of MI as a function of downtilt angles are provided. The derived model will help evaluate the performance of correlated 3D MIMO channels in the future.","Correlation,
MIMO,
Three-dimensional displays,
Channel models,
Closed-form solutions,
Azimuth,
Antennas"
Reactive Motion Planning for Unmanned Aerial Surveillance of Risk-Sensitive Areas,"This paper proposes a reactive motion-planning approach for persistent surveillance of risk-sensitive areas by a team of unmanned aerial vehicles (UAVs). The planner, termed PARCov (Planner for Autonomous Risk-sensitive Coverage), seeks to: i) maximize the area covered by sensors mounted on each UAV; ii) provide persistent surveillance; iii) maintain high sensor data quality; and iv) reduce detection risk. To achieve the stated objectives, PARCov combines into a cost function the detection risk with an uncertainty measure designed to keep track of the regions that have been surveyed and the times they were last surveyed. PARCov reduces the uncertainty and detection risk by moving each quadcopter toward a low-cost region in its vicinity. By reducing the uncertainty, PARCov is able to increase the coverage and provide persistent surveillance. Moreover, a nonlinear optimization formulation is used to determine the optimal altitude for flying each quadcopter in order to maximize the sensor data quality while minimizing risk.",
Large Margin Local Estimate With Applications to Medical Image Classification,"Medical images usually exhibit large intra-class variation and inter-class ambiguity in the feature space, which could affect classification accuracy. To tackle this issue, we propose a new Large Margin Local Estimate (LMLE) classification model with sub-categorization based sparse representation. We first sub-categorize the reference sets of different classes into multiple clusters, to reduce feature variation within each subcategory compared to the entire reference set. Local estimates are generated for the test image using sparse representation with reference subcategories as the dictionaries. The similarity between the test image and each class is then computed by fusing the distances with the local estimates in a learning-based large margin aggregation construct to alleviate the problem of inter-class ambiguity. The derived similarities are finally used to determine the class label. We demonstrate that our LMLE model is generally applicable to different imaging modalities, and applied it to three tasks: interstitial lung disease (ILD) classification on high-resolution computed tomography (HRCT) images, phenotype binary classification and continuous regression on brain magnetic resonance (MR) imaging. Our experimental results show statistically significant performance improvements over existing popular classifiers.","Educational institutions,
Vectors,
Biomedical imaging,
Dictionaries,
Measurement,
Feature extraction,
Australia"
Year,,
Effects of Applied Bias and High Field Stress on the Radiation Response of GaN/AlGaN HEMTs,The sensitivity of GaN/AlGaN HEMTs to 1.8 MeV proton irradiation is greatly enhanced by biasing the devices during irradiation and/or applying high field stress before irradiation. The resulting defect energy distributions are evaluated after irradiation and/or high field stress via low-frequency noise measurements. Significant increases are observed in acceptor densities for defects with ~ 0.2 and ~ 0.7 eV energy levels. These defects appear to dominate the degradation in threshold voltage and transconductance for these devices. Density functional theory (DFT) calculations show that N vacancy-related defects in GaN and hydrogenated O N complexes in AlGaN are strong candidates for the defects with ~ 0.2 eV energy levels in these devices. We also present evidence that the previously unidentified ~ 0.7 eV defect in GaN is a N anti-site defect (N Ga).,
Quality-Related Fault Detection Approach Based on Orthogonal Signal Correction and Modified PLS,"Partial least squares (PLS) is an efficient tool widely used in multivariate statistical process monitoring. Since standard PLS performs oblique projection to input space X, it has limitations in distinguishing quality-related and quality-unrelated faults. Several postprocessing modifications of PLS, such as total projection to latent structures (T-PLS), have been proposed to solve this issue. Further studies have found that these modifications fail to reduce false alarm rates (FARs) of quality-unrelated faults when fault amplitude increases. To cope with this problem, this paper proposes an enhanced quality-related fault detection approach based on orthogonal signal correction (OSC) and modified-PLS (M-PLS). The proposed approach removes variation orthogonal to output space Y from input space X before PLS modeling, and further decomposes X into two orthogonal subspaces in which quality-related and quality-unrelated statistical indicators are designed separately. Compared with T-PLS, the proposed approach has a more robust performance and a lower computational load. Two case studies, including a numerical example and the Tennessee Eastman (TE) process, show the effeteness of the proposed approach.","Fault detection,
Monitoring,
Standards,
Informatics,
Vectors,
Load modeling,
Systematics"
A Novel Scheme for Nanoparticle Steering in Blood Vessels Using a Functionalized Magnetic Field,"Magnetic drug targeting is a drug delivery approach in which therapeutic magnetizable particles are injected, generally into blood vessels, and magnets are then used to guide and concentrate them in the diseased target organ. Although many analytical, simulation, and experimental studies on capturing schemes for drug targeting have been conducted, there are few studies on delivering the nanoparticles to the target region. Furthermore, the sticking phenomenon of particles to vessels walls near the injection point, and far from the target region, has not been addressed sufficiently. In this paper, the sticking issue and its relationship to nanoparticle steering are investigated in detail using numerical simulations. For wide ranges of blood vessel size, blood velocity, particle size, and applied magnetic field, three coefficient numbers are uniquely generalized: vessel elongation, normal exit time, and force rate. With respect these new parameters, we investigated particle distribution trends for a Y-shaped channel and computed ratios of correctly guided particles and particles remaining in the vessel. We found that the sticking of particles to vessels occurred because of low blood flow velocity near the vessel walls, which is the main reason for low targeting efficiency when using a constant magnetic gradient. To reduce the sticking ratio of nanoparticles, we propose a novel field function scheme that uses a simple time-varying function to separate the particles from the walls and guide them to the target point. The capabilities of the proposed scheme were examined by several simulations of both Y-shaped channels and realistic three-dimensional (3-D) model channels extracted from brain vessels. The results showed a significant decrease in particle adherence to walls during the delivery stage and confirmed the effectiveness of the proposed magnetic field function method for steering nanoparticles for targeted drug delivery.","Nanoparticles,
Magnetic fields,
Drugs,
Force,
Magnetic moments,
Saturation magnetization,
Blood vessels"
FlowRanger: A request prioritizing algorithm for controller DoS attacks in Software Defined Networks,"Software Defined Networking (SDN) introduces a new communication network management paradigm and has gained much attention from academia and industry. However, the centralized nature of SDN is a potential vulnerability to the system since attackers may launch denial of services (DoS) attacks against the controller. Existing solutions limit requests rate to the controller by dropping overflowed requests, but they also drop legitimate requests to the controller. To address this problem, we propose FlowRanger, a buffer prioritizing solution for controllers to handle routing requests based on their likelihood to be attacking requests, which derives the trust values of the requesting sources. Based on their trust values, FlowRanger classifies routing requests into multiple buffer queues with different priorities. Thus, attacking requests are served with a lower priority than regular requests. Our simulation results demonstrates that FlowRanger can significantly enhance the request serving rate of regular users under DoS attacks against the controller. To the best of our knowledge, our work is the first solution to battle against controller DoS attacks on the controller side.","Computer crime,
Routing,
Next generation networking,
Processor scheduling,
Switches"
Short-Range Low-VHF Channel Characterization in Cluttered Environments,"The lower VHF band has potential for low-power, short-range communications, as well as for geolocation applications, in both indoor and urban environments. Most prior work at low VHF focuses on longer range path loss modeling, often with one node elevated. In this paper, we study indoor/outdoor near-ground scenarios through experiments and electromagnetic wave propagation simulations. These include the effects of indoor penetration through walls and obstacles, as well as indoor/outdoor cases, for both line of sight (LoS) and nonLoS (NLoS), at ranges up to 200 m. Mounting our receiver (Rx) on a robotic platform enabled the collection of thousands of measurements over an extended indoor/outdoor test area. We measure the channel transfer function, employing bandpass waveform sampling, with pulse and tone probe signals. Based on statistical tests, we show that the measured channels have a nearly ideal scalar attenuation and delay transfer function, with minimal phase distortion, and little to no evidence of multipath propagation. Compared with higher VHF and above, the measured short-range VHF channels do not exhibit small-scale fading, which simplifies communications Rx signal processing, and enables phase-based geolocation techniques.","Distortion measurement,
Receivers,
Transfer functions,
Phase distortion,
Antenna measurements,
Phase measurement,
Loss measurement"
A Distributed Amplifier System for Bilayer Lipid Membrane (BLM) Arrays With Noise and Individual Offset Cancellation,"Lipid bilayer membrane (BLM) arrays are required for high throughput analysis, for example drug screening or advanced DNA sequencing. Complex microfluidic devices are being developed but these are restricted in terms of array size and structure or have integrated electronic sensing with limited noise performance. We present a compact and scalable multichannel electrophysiology platform based on a hybrid approach that combines integrated state-of-the-art microelectronics with low-cost disposable fluidics providing a platform for high-quality parallel single ion channel recording. Specifically, we have developed a new integrated circuit amplifier based on a novel noise cancellation scheme that eliminates flicker noise derived from devices under test and amplifiers. The system is demonstrated through the simultaneous recording of ion channel activity from eight bilayer membranes. The platform is scalable and could be extended to much larger array sizes, limited only by electronic data decimation and communication capabilities.","Noise,
CMOS integrated circuits,
Apertures,
Field programmable gate arrays,
Lipidomics,
Electrodes,
Universal Serial Bus"
Interaction part mining: A mid-level approach for fine-grained action recognition,"Modeling human-object interactions and manipulating motions lies in the heart of fine-grained action recognition. Previous methods heavily rely on explicit detection of the object being interacted, which requires intensive human labour on object annotation. To bypass this constraint and achieve better classification performance, in this work, we propose a novel fine-grained action recognition pipeline by interaction part proposal and discriminative mid-level part mining. Firstly, we generate a large number of candidate object regions using off-the-shelf object proposal tool, e.g., BING. Secondly, these object regions are matched and tracked across frames to form a large spatio-temporal graph based on the appearance matching and the dense motion trajectories through them. We then propose an efficient approximate graph segmentation algorithm to partition and filter the graph into consistent local dense sub-graphs. These sub-graphs, which are spatio-temporal sub-volumes, represent our candidate interaction parts. Finally, we mine discriminative mid-level part detectors from the features computed over the candidate interaction parts. Bag-of-detection scores based on a novel Max-N pooling scheme are computed as the action representation for a video sample. We conduct extensive experiments on human-object interaction datasets including MPII Cooking and MSR Daily Activity 3D. The experimental results demonstrate that the proposed framework achieves consistent improvements over the state-of-the-art action recognition accuracies on the benchmarks, without using any object annotation.",
An Interleaved Full Nyquist High-Speed DAC Technique,"A 9 bit 11 GS/s DAC is presented that achieves an SFDR of more than 50 dB across Nyquist and IM3 below -50 dBc across Nyquist. The DAC uses a two-times interleaved architecture to suppress spurs that typically limit DAC performance. Despite requiring two current-steering DACs for the interleaved architecture, the relative low demands on performance of these sub-DACs imply that they can be implemented in an area and power efficient way. Together with a quad-switching architecture to decrease demands on the power supply and bias generation and employing the multiplexer switches in triode, the total core area is only 0.04 mm 2 while consuming 110 mW from a single 1.0 V supply.","Switches,
Multiplexing,
Timing,
Linearity,
Power supplies,
Loading,
Computer architecture"
Cascaded Collaborative Regression for Robust Facial Landmark Detection Trained Using a Mixture of Synthetic and Real Images With Dynamic Weighting,"A large amount of training data is usually crucial for successful supervised learning. However, the task of providing training samples is often time-consuming, involving a considerable amount of tedious manual work. In addition, the amount of training data available is often limited. As an alternative, in this paper, we discuss how best to augment the available data for the application of automatic facial landmark detection. We propose the use of a 3D morphable face model to generate synthesized faces for a regression-based detector training. Benefiting from the large synthetic training data, the learned detector is shown to exhibit a better capability to detect the landmarks of a face with pose variations. Furthermore, the synthesized training data set provides accurate and consistent landmarks automatically as compared to the landmarks annotated manually, especially for occluded facial parts. The synthetic data and real data are from different domains; hence the detector trained using only synthesized faces does not generalize well to real faces. To deal with this problem, we propose a cascaded collaborative regression algorithm, which generates a cascaded shape updater that has the ability to overcome the difficulties caused by pose variations, as well as achieving better accuracy when applied to real faces. The training is based on a mix of synthetic and real image data with the mixing controlled by a dynamic mixture weighting schedule. Initially, the training uses heavily the synthetic data, as this can model the gross variations between the various poses. As the training proceeds, progressively more of the natural images are incorporated, as these can model finer detail. To improve the performance of the proposed algorithm further, we designed a dynamic multi-scale local feature extraction method, which captures more informative local features for detector training. An extensive evaluation on both controlled and uncontrolled face data sets demonstrates the merit of the proposed algorithm.","Face,
Shape,
Training,
Feature extraction,
Three-dimensional displays,
Solid modeling,
Detectors"
Data Partition Learning With Multiple Extreme Learning Machines,"As demonstrated earlier, the learning accuracy of the single-layer-feedforward-network (SLFN) is generally far lower than expected, which has been a major bottleneck for many applications. In fact, for some large real problems, it is accepted that after tremendous learning time (within finite epochs), the network output error of SLFN will stop or reduce increasingly slowly. This report offers an extreme learning machine (ELM)-based learning method, referred to as the parent-offspring progressive learning method. The proposed method works by separating the data points into various parts, and then multiple ELMs learn and identify the clustered parts separately. The key advantages of the proposed algorithms as compared to the traditional supervised methods are twofold. First, it extends the ELM learning method from a single neural network to a multinetwork learning system, as the proposed multiELM method can approximate any target continuous function and classify disjointed regions. Second, the proposed method tends to deliver a similar or much better generalization performance than other learning methods. All the methods proposed in this paper are tested on both artificial and real datasets.","Partitioning algorithms,
Learning systems,
Artificial neural networks,
Training,
Training data,
Clustering algorithms,
Testing"
Actions in the Eye: Dynamic Gaze Datasets and Learnt Saliency Models for Visual Recognition,"Systems based on bag-of-words models from image features collected at maxima of sparse interest point operators have been used successfully for both computer visual object and action recognition tasks. While the sparse, interest-point based approach to recognition is not inconsistent with visual processing in biological systems that operate in `saccade and fixate' regimes, the methodology and emphasis in the human and the computer vision communities remains sharply distinct. Here, we make three contributions aiming to bridge this gap. First, we complement existing state-of-the art large scale dynamic computer vision annotated datasets like Hollywood-2 [1] and UCF Sports [2] with human eye movements collected under the ecological constraints of visual action and scene context recognition tasks. To our knowledge these are the first large human eye tracking datasets to be collected and made publicly available for video, vision.imar.ro/eyetracking (497,107 frames, each viewed by 19 subjects), unique in terms of their (a) large scale and computer vision relevance, (b) dynamic, video stimuli, (c) task control, as well as free-viewing. Second, we introduce novel dynamic consistency and alignment measures, which underline the remarkable stability of patterns of visual search among subjects. Third, we leverage the significant amount of collected data in order to pursue studies and build automatic, end-to-end trainable computer vision systems based on human eye movements. Our studies not only shed light on the differences between computer vision spatio-temporal interest point image sampling strategies and the human fixations, as well as their impact for visual recognition performance, but also demonstrate that human fixations can be accurately predicted, and when used in an end-to-end automatic system, leveraging some of the advanced computer vision practice, can lead to state of the art results.","Visualization,
Computer vision,
Computational modeling,
Context,
Communities,
Training,
Image recognition"
Sparsifying Transform Learning With Efficient Optimal Updates and Convergence Guarantees,"Many applications in signal processing benefit from the sparsity of signals in a certain transform domain or dictionary. Synthesis sparsifying dictionaries that are directly adapted to data have been popular in applications such as image denoising, inpainting, and medical image reconstruction. In this paper, we focus instead on the sparsifying transform model, and study the learning of well-conditioned square sparsifying transforms. The proposed algorithms alternate between a l0 “norm”-based sparse coding step, and a non-convex transform update step. We derive the exact analytical solution for each of these steps. The proposed solution for the transform update step achieves the global minimum in that step, and also provides speedups over iterative solutions involving conjugate gradients. We establish that our alternating algorithms are globally convergent to the set of local minimizers of the nonconvex transform learning problems. In practice, the algorithms are insensitive to initialization. We present results illustrating the promising performance and significant speed-ups of transform learning over synthesis K-SVD in image denoising.","Transforms,
Signal processing algorithms,
Analytical models,
Encoding,
Dictionaries,
Data models,
Algorithm design and analysis"
MPMTP: Multipath Multimedia Transport Protocol using Systematic Raptor Codes over Wireless Networks,"This paper presents a multipath multimedia transport protocol (MPMTP), which exploits path diversity over heterogeneous wireless networks. The goal of MPMTP is to provide a seamless high-quality video streaming service by using multiple wireless networks simultaneously. In MPMTP, systematic Raptor codes are adopted to mitigate video quality degradation caused by wireless channel errors as well as to alleviate a head-of-line blocking problem in multipath environments, and their encoding parameters such as code rate, symbol size, and the number of source symbols are determined on the fly by considering the wireless channel state, Raptor encoding and decoding complexity, and receiver buffer occupancy. Furthermore, MPMTP performs packet scheduling considering not only wireless network conditions but also packet payload characteristics for smooth video playback. The proposed MPMTP is fully implemented in a Linux kernel and examined over real wireless network environments.","Streaming media,
Encoding,
Decoding,
Wireless networks,
Delays,
Receivers,
Scheduling algorithms"
CCLS: An Efficient Local Search Algorithm for Weighted Maximum Satisfiability,"The maximum satisfiability (MAX-SAT) problem, especially the weighted version, has extensive applications. Weighted MAX-SAT instances encoded from real-world applications may be very large, which calls for efficient approximate methods, mainly stochastic local search (SLS) ones. However, few works exist on SLS algorithms for weighted MAX-SAT. In this paper, we propose a new heuristic called CCM for weighted MAX-SAT. The CCM heuristic prefers to select a CCMP variable. By combining CCM with random walk, we design a simple SLS algorithm dubbed CCLS for weighted MAX-SAT. The CCLS algorithm is evaluated against a state-of-the-art SLS solver IRoTS and two state-of-the-art complete solvers namely akmaxsat_ls and New WPM2, on a broad range of weighted MAX-SAT instances. Experimental results illustrate that the quality of solution found by CCLS is much better than that found by IRoTS, akmaxsat_ls and New WPM2 on most industrial, crafted and random instances, indicating the efficiency and the robustness of the CCLS algorithm. Furthermore, CCLS is evaluated in the weighted and unweighted MAX-SAT tracks of incomplete solvers in the Eighth Max-SAT Evaluation (Max-SAT 2013), and wins four tracks in this evaluation, illustrating that the performance of CCLS exceeds the current state-of-the-art performance of SLS algorithms on solving MAX-SAT instances.","Charge coupled devices,
Algorithm design and analysis,
Search problems,
Complexity theory,
Heuristic algorithms,
Electronic mail,
Robustness"
Anatomy-specific classification of medical images using deep convolutional nets,"Automated classification of human anatomy is an important prerequisite for many computer-aided diagnosis systems. The spatial complexity and variability of anatomy throughout the human body makes classification difficult. “Deep learning” methods such as convolutional networks (ConvNets) outperform other state-of-the-art methods in image classification tasks. In this work, we present a method for organ- or body-part-specific anatomical classification of medical images acquired using computed tomography (CT) with ConvNets. We train a ConvNet, using 4,298 separate axial 2D key-images to learn 5 anatomical classes. Key-images were mined from a hospital PACS archive, using a set of 1,675 patients. We show that a data augmentation approach can help to enrich the data set and improve classification performance. Using ConvNets and data augmentation, we achieve anatomy-specific classification error of 5.9 % and area-under-the-curve (AUC) values of an average of 0.998 in testing. We demonstrate that deep learning can be used to train very reliable and accurate classifiers that could initialize further computer-aided diagnosis.","Computed tomography,
Medical diagnostic imaging,
Convolution,
Lungs,
Training,
Neural networks"
A novel spectrum sensing scheduling scheme for PU and SU signal differentiation in CR networks,"In cognitive radio (CR) networks, spectrum sensing is an essential operation for unlicensed users to discover available spectrum opportunities for communications. However, current spectrum sensing techniques have a drawback that they can only detect the existence of signals but they cannot differentiate whether the detected signals come from licensed users or unlicensed users. This drawback leads to a significant waste of spectrum resources, which greatly limits the spectrum utilization of unlicensed users. In this paper, we investigate the issue of differentiating the licensed user and unlicensed user signals. A novel spectrum sensing scheduling scheme is proposed to solve this issue. Under the proposed spectrum sensing scheduling scheme, accurate sensing results on licensed users are obtained. Simulation results show that the proposed spectrum sensing scheduling scheme outperforms the scenario without signal differentiation in terms of higher unlicensed user throughput. To the best of our knowledge, this is the first work that investigates the signal differentiation issue between licensed users and unlicensed users in CR networks.","Sensors,
Data communication,
Markov processes,
Throughput,
Probability,
Steady-state,
Accuracy"
Supporting superpages in non-contiguous physical memory,"For memory-intensiv e workloads with large memory footprints, superpages are effective to avoid address translation overhead, which can be a critical performance bottleneck. A superpage is a large virtual memory page that is mapped to an equivalently-sized amount of contiguous physical memory pages. Superpage mapping assumes physical memory does not contain retired pages, which is an important technique to improve memory resilience: the OS avoids allocating physical pages that have detected errors. Retired pages create unusable ""holes"" in the physical memory. We show that even a small percentage of retired pages makes it very difficult to find enough contiguous memory to form superpages. To address this problem, we propose GTSM, or gap-tolerant sequential mapping, that allows superpages to be formed even in the presence of retired physical pages. A new page table format is also proposed to support GTSM. This format has similar storage efficiency as traditional superpaging to hold address translations in the last-level cache. To further compress the page table and improve cache hit rates for address translation in large memory footprint workloads, we also propose an extended format that reduces the page table size by 50%. In comparison to an ideal memory without any retired physical pages, we show that our technique, with retired pages, achieves nearly 96.8% of the performance of traditional 2MB superpaging.","Indexes,
Random access memory,
Retirement,
Memory management,
Error correction codes,
Nonvolatile memory,
Hardware"
DEEP-CARVING: Discovering visual attributes by carving deep neural nets,"Most of the approaches for discovering visual attributes in images demand significant supervision, which is cumbersome to obtain. In this paper, we aim to discover visual attributes in a weakly supervised setting that is commonly encountered with contemporary image search engines. For instance, given a noun (say forest) and its associated attributes (say dense, sunlit, autumn), search engines can now generate many valid images for any attribute-noun pair (dense forests, autumn forests, etc). However, images for an attributenoun pair do not contain any information about other attributes (like which forests in the autumn are dense too). Thus, a weakly supervised scenario occurs: each of the M attributes corresponds to a class such that a training image in class m ∈ {1, . . . , M} contains a single label that indicates the presence of the mth attribute only. The task is to discover all the attributes present in a test image. Deep Convolutional Neural Networks (CNNs) [20] have enjoyed remarkable success in vision applications recently. However, in a weakly supervised scenario, widely used CNN training procedures do not learn a robust modelfor predicting multiple attribute labels simultaneously. The primary reason is that the attributes highly co-occur within the training data, and unlike objects, do not generally exist as well-defined spatial boundaries within the image. To ameliorate this limitation, we propose Deep-Carving, a novel training procedure with CNNs, that helps the net efficiently carve itselffor the task of multiple attribute prediction. During training, the responses of the feature maps are exploited in an ingenious way to provide the net with multiple pseudo-labels (for training images) for subsequent iterations. The process is repeated periodically after a fixed number of iterations, and enables the net carve itself iteratively for efficiently disentangling features. Additionally, we contribute a noun-adjective pairing inspired Natural Scenes Attributes Dataset to the research community, CAMITNSAD, containing a number of co-occurring attributes within a noun category. We describe, in detail, salient aspects of this dataset. Our experiments on CAMITNSAD and the SUN Attributes Dataset [29], with weak supervision, clearly demonstrate that the Deep-Carved CNNs consistently achieve considerable improvement in the precision of attribute prediction over popular baseline methods.","Training,
Visualization,
Entropy,
Computer architecture,
Search engines,
Predictive models,
Robustness"
Advanced Hybrid Transient Stability and EMT Simulation for VSC-HVDC Systems,"This paper deals with advanced hybrid transient stability and electromagnetic-transient (EMT) simulation of combined ac/dc power systems containing large amounts of renewable energy sources interfaced through voltage-source converter-high-voltage direct current (VSC-HVDC). The concerning transient stability studies require the dynamic phenomena of interest to be included with adequate detail and reasonable simulation speed. Hybrid simulation offers this functionality, and this contribution focuses on its application to (multiterminal) VSC-HVDC systems. Existing numerical interfacing methods have been evaluated and improved for averaged VSC modeling. These innovations include: 1) ac system equivalent impedance refactorization after faults; 2) amended interaction protocols for improved Thévenin equivalent source updating inside the EMT-type simulation; and 3) a special new interaction protocol for improved phasor determination during faults. The improvements introduced in this contribution lead to more accurate ac/VSC-HVDC transient stability assessment compared to conventional interfacing techniques.","Computational modeling,
Numerical models,
Transient analysis,
Stability analysis,
Power system stability,
Numerical stability,
Protocols"
A comparative study: MongoDB vs. MySQL,"In this paper we will try to present a comparative study of non-relational databases and relational databases. We mainly focus our presentation on one implementation of the NoSQL database technology, namely MongoDB, and make a comparison with another implementation of relational databases, namely MySQL, and thus justifying why MongoDB is more efficient than MySQL. We will also present the advantages of using a non-relational database compared to a relational database, integrated in a forum in the field of personal and professional development. The NoSQL database used to develop the forum is MongoDB, and was chosen from a variety of non-relational databases, thanks to some aspects that we will highlight in this article. The database integration in the framework will also be presented.","Relational databases,
Syntactics,
Electronic mail,
Computer science,
Arrays,
Indexes"
Smartphone-Based Wound Assessment System for Patients With Diabetes,"Diabetic foot ulcers represent a significant health issue. Currently, clinicians and nurses mainly base their wound assessment on visual examination of wound size and healing status, while the patients themselves seldom have an opportunity to play an active role. Hence, a more quantitative and cost-effective examination method that enables the patients and their caregivers to take a more active role in daily wound care potentially can accelerate wound healing, save travel cost and reduce healthcare expenses. Considering the prevalence of smartphones with a high-resolution digital camera, assessing wounds by analyzing images of chronic foot ulcers is an attractive option. In this paper, we propose a novel wound image analysis system implemented solely on the Android smartphone. The wound image is captured by the camera on the smartphone with the assistance of an image capture box. After that, the smartphone performs wound segmentation by applying the accelerated mean-shift algorithm. Specifically, the outline of the foot is determined based on skin color, and the wound boundary is found using a simple connected region detection method. Within the wound boundary, the healing status is next assessed based on red-yellow-black color evaluation model. Moreover, the healing status is quantitatively assessed, based on trend analysis of time records for a given patient. Experimental results on wound images collected in UMASS-Memorial Health Center Wound Clinic (Worcester, MA) following an Institutional Review Board approved protocol show that our system can be efficiently used to analyze the wound healing status with promising accuracy.","Wounds,
Foot,
Image color analysis,
Algorithm design and analysis,
Image segmentation,
Diabetes,
Vectors"
Personalized route recommendation using big trajectory data,"When planning routes, drivers usually consider a multitude of different travel costs, e.g., distances, travel times, and fuel consumption. Different drivers may choose different routes between the same source and destination because they may have different driving preferences (e.g., time-efficient driving v.s. fuel-efficient driving). However, existing routing services support little in modeling multiple travel costs and personalization-they usually deliver the same routes that minimize a single travel cost (e.g., the shortest routes or the fastest routes) to all drivers. We study the problem of how to recommend personalized routes to individual drivers using big trajectory data. First, we provide techniques capable of modeling and updating different drivers' driving preferences from the drivers' trajectories while considering multiple travel costs. To recommend personalized routes, we provide techniques that enable efficient selection of a subset of trajectories from all trajectories according to a driver's preference and the source, destination, and departure time specified by the driver. Next, we provide techniques that enable the construction of a small graph with appropriate edge weights reflecting how the driver would like to use the edges based on the selected trajectories. Finally, we recommend the shortest route in the small graph as the personalized route to the driver. Empirical studies with a large, real trajectory data set from 52,211 taxis in Beijing offer insight into the design properties of the proposed techniques and suggest that they are efficient and effective.","Trajectory,
Vehicles,
Roads,
Indexes,
Global Positioning System,
Fuels"
Shadow Remover: Image Shadow Removal Based on Illumination Recovering Optimization,"In this paper, we present a novel shadow removal system for single natural images as well as color aerial images using an illumination recovering optimization method. We first adaptively decompose the input image into overlapped patches according to the shadow distribution. Then, by building the correspondence between the shadow patch and the lit patch based on texture similarity, we construct an optimized illumination recovering operator, which effectively removes the shadows and recovers the texture detail under the shadow patches. Based on coherent optimization processing among the neighboring patches, we finally produce high-quality shadow-free results with consistent illumination. Our shadow removal system is simple and effective, and can process shadow images with rich texture types and nonuniform shadows. The illumination of shadow-free results is consistent with that of surrounding environment. We further present several shadow editing applications to illustrate the versatility of the proposed method.",
An Efficient Green Control Algorithm in Cloud Computing for Cost Optimization,"Cloud computing is a new paradigm for delivering remote computing resources through a network. However, achieving an energy-efficiency control and simultaneously satisfying a performance guarantee have become critical issues for cloud providers. In this paper, three power-saving policies are implemented in cloud systems to mitigate server idle power. The challenges of controlling service rates and applying the N-policy to optimize operational cost within a performance guarantee are first studied. A cost function has been developed in which the costs of power consumption, system congestion and server startup are all taken into consideration. The effect of energy-efficiency controls on response times, operating modes and incurred costs are all demonstrated. Our objectives are to find the optimal service rate and mode-switching restriction, so as to minimize cost within a response time guarantee under varying arrival rates. An efficient green control (EGC) algorithm is first proposed for solving constrained optimization problems and making costs/performances tradeoffs in systems with different power-saving policies. Simulation results show that the benefits of reducing operational costs and improving response times can be verified by applying the power-saving policies combined with the proposed algorithm as compared to a typical system under a same performance guarantee.","Servers,
Cloud computing,
Switches,
Optimization,
Energy efficiency,
Power demand,
Virtual machining"
A Hybrid Memetic Framework for Coverage Optimization in Wireless Sensor Networks,"One of the critical concerns in wireless sensor networks (WSNs) is the continuous maintenance of sensing coverage. Many particular applications, such as battlefield intrusion detection and object tracking, require a full-coverage at any time, which is typically resolved by adding redundant sensor nodes. With abundant energy, previous studies suggested that the network lifetime can be maximized while maintaining full coverage through organizing sensor nodes into a maximum number of disjoint sets and alternately turning them on. Since the power of sensor nodes is unevenly consumed over time, and early failure of sensor nodes leads to coverage loss, WSNs require dynamic coverage maintenance. Thus, the task of permanently sustaining full coverage is particularly formulated as a hybrid of disjoint set covers and dynamic-coverage-maintenance problems, and both have been proven to be nondeterministic polynomial-complete. In this paper, a hybrid memetic framework for coverage optimization (Hy-MFCO) is presented to cope with the hybrid problem using two major components: 1) a memetic algorithm (MA)-based scheduling strategy and 2) a heuristic recursive algorithm (HRA). First, the MA-based scheduling strategy adopts a dynamic chromosome structure to create disjoint sets, and then the HRA is utilized to compensate the loss of coverage by awaking some of the hibernated nodes in local regions when a disjoint set fails to maintain full coverage. The results obtained from real-world experiments using a WSN test-bed and computer simulations indicate that the proposed Hy-MFCO is able to maximize sensing coverage while achieving energy efficiency at the same time. Moreover, the results also show that the Hy-MFCO significantly outperforms the existing methods with respect to coverage preservation and energy efficiency.","Wireless sensor networks,
Robot sensing systems,
Scheduling,
Organizing,
Heuristic algorithms,
Genetic algorithms"
Open Set Fingerprint Spoof Detection Across Novel Fabrication Materials,"A fingerprint spoof detector is a pattern classifier that is used to distinguish a live finger from a fake (spoof) one in the context of an automated fingerprint recognition system. Most spoof detectors are learning-based and rely on a set of training images. Consequently, the performance of any such spoof detector significantly degrades when encountering spoofs fabricated using novel materials not found in the training set. In real-world applications, the problem of fingerprint spoof detection must be treated as an open set recognition problem where incomplete knowledge of the fabrication materials used to generate spoofs is present at training time, and novel materials may be encountered during system deployment. To mitigate the security risk posed by novel spoofs, this paper introduces: 1) the use of the Weibull-calibrated SVM (W-SVM), which is relatively robust for open set recognition, as a novel-material detector and a spoof detector and 2) a scheme for the automatic adaptation of the W-SVM-based spoof detector to new spoof materials that leverages interoperability across classifiers. Experiments conducted on new partitions of the LivDet 2011 database designed for open set evaluation suggest: 1) a 97% increase in the error rate of the existing spoof detectors when tested using new spoof materials and 2) up to 44% improvement in spoof detection performance across spoof materials when the proposed adaptive approach is used.","Detectors,
Support vector machines,
Fabrication,
Training,
Feature extraction,
Training data,
Databases"
A Hybrid Hierarchical Control Plane for Flow-Based Large-Scale Software-Defined Networks,"The decoupled architecture and the fine-grained flow-control feature limit the scalability of a flow-based software-defined network (SDN). In order to address this problem, some studies construct a flat control plane architecture; others build a hierarchical control plane architecture to improve the scalability of an SDN. However, the two kinds of structure still have unresolved issues: A flat control plane structure cannot solve the superlinear computational complexity growth of the control plane when the SDN scales to a large size, and the centralized abstracted hierarchical control plane structure brings a path stretch problem. To address these two issues, we propose Orion, a hybrid hierarchical control plane for large-scale networks. Orion can effectively reduce the computational complexity of an SDN control plane by several orders of magnitude. We also design an abstracted hierarchical routing method to solve the path stretch problem. Furthermore, we propose a hierarchical fast reroute method to illustrate how to achieve fast rerouting in the proposed hybrid hierarchical control plane. Orion is implemented to verify the feasibility of the hybrid hierarchical approach. Finally, we verify the effectiveness of Orion from both the theoretical and experimental aspects.",
Optimal Stochastic Coordinated Beamforming for Wireless Cooperative Networks With CSI Uncertainty,"Transmit optimization and resource allocation for wireless cooperative networks with channel state information (CSI) uncertainty are important but challenging problems in terms of both the uncertainty modeling and performance optimization. In this paper, we establish a generic stochastic coordinated beamforming (SCB) framework that provides flexibility in the channel uncertainty modeling, while guaranteeing optimality in the transmission strategies. We adopt a general stochastic model for the CSI uncertainty, which is applicable for various practical scenarios. The SCB problem turns out to be a joint chance constrained program (JCCP) and is known to be highly intractable. In contrast to all of the previous algorithms for JCCP that can only find feasible but sub-optimal solutions, we propose a novel stochastic DC (difference-of-convex) programming algorithm with optimality guarantee, which can serve as the benchmark for evaluating heuristic and sub-optimal algorithms. The key observation is that the highly intractable probability constraint can be equivalently reformulated as a dc constraint. This further enables efficient algorithms to achieve optimality. Simulation results will illustrate the convergence, conservativeness, stability and performance gains of the proposed algorithm.","Uncertainty,
Signal processing algorithms,
Stochastic processes,
Programming,
Approximation methods,
Approximation algorithms,
Array signal processing"
Wear Relief for High-Density Phase Change Memory Through Cell Morphing Considering Process Variation,"Due to the scalability and large leakage power, dynamic random-access memory (DRAM) has a lot of challenges in scaling. As an alternative, phase change memory (PCM) has demonstrated promising potential to serve as the main memory in deep submicrometer regime. The broad resistance range of PCM cells enables several cell modes with various densities, pertaining to multiple level cell (MLC), triple state cell (TSC), and single level cell (SLC). High-density mode outperforms low-density ones in terms of capacity and cost-per-bit, but suffers from a weaker cell endurance. Wear leveling strategies are proposed to enhance the memory endurance but encounter more challenges with the aggravating process variation. Due to endurance variations, physical domains are fabricated with irregular tenacity. As a result, balanced write traffic, which is the objective of traditional wear leveling, cannot fully exploit the PCM endurance since the weak parts will be worn out sooner than others. In this paper, considering process variation, we propose a cell morphing based wear leveling scheme. Cell morphing refers to the cell mode transformation between high density (e.g., MLC) and low densities (e.g., TSC and SLC). Instead of redistributing write operations, the proposed wear leveling scheme dynamically transforms weak and frequently written portions into low-density mode for endurance benefits. Multitier cell morphing schemes are proposed to support mode transformation among multiple density levels. The experimental results show 236% endurance improvement for single-tier cell morphing and 209% for two-tier cell morphing with 2% low-density page percentage, when compared with the most related work.",
Minimum Energy Routing and Jamming to Thwart Wireless Network Eavesdroppers,"There is a rich recent literature on information-theoretically secure communication at the physical layer of wireless networks, where secret communication between a single transmitter and receiver has been studied extensively. In this paper, we consider how single-hop physical layer security techniques can be extended to multi-hop wireless networks. We show that guaranteed security can be achieved in multi-hop networks by augmenting physical layer security techniques, such as cooperative jamming, with the higher layer network mechanisms, such as routing. Specifically, we consider the secure minimum energy routing problem, in which the objective is to compute a minimum energy path between two network nodes subject to constraints on the end-to-end communication secrecy and goodput over the path. This problem is formulated as a constrained optimization of transmission power and link selection, which is proved to be NP-hard. Nevertheless, we show that efficient algorithms exist to compute both exact and approximate solutions for the problem. In particular, we develop an exact solution of pseudo-polynomial complexity, as well as an ε-optimal approximation of polynomial complexity. Simulation results are also provided to show the utility of our algorithms and quantify their energy savings compared to a combination of (standard) security-agnostic minimum energy routing and physical layer security. In the simulated scenarios, we observe that, by jointly optimizing link selection at the network layer and cooperative jamming at the physical layer, our algorithms reduce the network energy consumption by half.","Jamming,
Security,
Physical layer,
Routing,
Wireless communication,
Communication system security,
Interference"
"Characterization Methods for the Detection of Multiple Voice Disorders: Neurological, Functional, and Laryngeal Diseases","This paper evaluates the accuracy of different characterization methods for the automatic detection of multiple speech disorders. The speech impairments considered include dysphonia in people with Parkinson's disease (PD), dysphonia diagnosed in patients with different laryngeal pathologies (LP), and hypernasality in children with cleft lip and palate (CLP). Four different methods are applied to analyze the voice signals including noise content measures, spectral-cepstral modeling, nonlinear features, and measurements to quantify the stability of the fundamental frequency. These measures are tested in six databases: three with recordings of PD patients, two with patients with LP, and one with children with CLP. The abnormal vibration of the vocal folds observed in PD patients and in people with LP is modeled using the stability measures with accuracies ranging from 81% to 99% depending on the pathology. The spectral-cepstral features are used in this paper to model the voice spectrum with special emphasis around the first two formants. These measures exhibit accuracies ranging from 95% to 99% in the automatic detection of hypernasal voices, which confirms the presence of changes in the speech spectrum due to hypernasality. Noise measures suitably discriminate between dysphonic and healthy voices in both databases with speakers suffering from LP. The results obtained in this study suggest that it is not suitable to use every kind of features to model all of the voice pathologies; conversely, it is necessary to study the physiology of each impairment to choose the most appropriate set of features.","Pathology,
Speech,
Noise,
Speech processing,
Noise measurement,
Parkinson's disease"
Factorization-Based Texture Segmentation,"This paper introduces a factorization-based approach that efficiently segments textured images. We use local spectral histograms as features, and construct an M × N feature matrix using M-dimensional feature vectors in an N-pixel image. Based on the observation that each feature can be approximated by a linear combination of several representative features, we factor the feature matrix into two matrices-one consisting of the representative features and the other containing the weights of representative features at each pixel used for linear combination. The factorization method is based on singular value decomposition and nonnegative matrix factorization. The method uses local spectral histograms to discriminate region appearances in a computationally efficient way and at the same time accurately localizes region boundaries. The experiments conducted on public segmentation data sets show the promise of this simple yet powerful approach.","Image segmentation,
Histograms,
Matrix decomposition,
Least squares approximations,
Accuracy,
Algorithm design and analysis"
Probabilistic Optimal Tree Hopping for RFID Identification,"Radio frequency identification (RFID) systems are widely used in various applications such as supply chain management, inventory control, and object tracking. Identifying RFID tags in a given tag population is the most fundamental operation in RFID systems. While the Tree Walking (TW) protocol has become the industrial standard for identifying RFID tags, little is known about the mathematical nature of this protocol, and only some ad hoc heuristics exist for optimizing it. In this paper, first we analytically model the TW protocol, and then using that model, propose the Tree Hopping (TH) protocol that optimizes TW both theoretically and practically. The key novelty of TH is to formulate tag identification as an optimization problem and find the optimal solution that ensures the minimal average number of queries or identification time as per the requirement. With this solid theoretical underpinning, for different tag population sizes ranging from 100 to 100 K tags, TH significantly outperforms the best prior tag identification protocols on the metrics of the total number of queries per tag, the total identification time per tag, and the average number of responses per tag by an average of 40%, 59%, and 67%, respectively, when tag IDs are nonuniformly distributed in the ID space, and of 50%, 10%, and 30%, respectively, when tag IDs are uniformly distributed.",
On Equivalence of FIS and ELM for Interpretable Rule-Based Knowledge Representation,"This paper presents a fuzzy extreme learning machine (F-ELM) that embeds fuzzy membership functions and rules into the hidden layer of extreme learning machine (ELM). Similar to the concept of ELM that employed the random initialization technique, three parameters of F-ELM are randomly assigned. They are the standard deviation of the membership functions, matrix-C (rule-combination matrix), and matrix-D [don't care (DC) matrix]. Fuzzy if-then rules are formulated by the rule-combination Matrix of F-ELM, and a DC approach is adopted to minimize the number of input attributes in the rules. Furthermore, F-ELM utilizes the output weights of the ELM to form the target class and confidence factor for each of the rules. This is to indicate that the corresponding consequent parameters are determined analytically. The operations of F-ELM are equivalent to a fuzzy inference system. Several benchmark data sets and a real world fault detection and diagnosis problem have been used to empirically evaluate the efficacy of the proposed F-ELM in handling pattern classification tasks. The results show that the accuracy rates of F-ELM are comparable (if not superior) to ELM with distinctive ability of providing explicit knowledge in the form of interpretable rule base.","Artificial neural networks,
Neurons,
Fuzzy logic,
Pragmatics,
Training,
Accuracy,
Computational modeling"
Semantic object segmentation via detection in weakly labeled video,"Semantic object segmentation in video is an important step for large-scale multimedia analysis. In many cases, however, semantic objects are only tagged at video-level, making them difficult to be located and segmented. To address this problem, this paper proposes an approach to segment semantic objects in weakly labeled video via object detection. In our approach, a novel video segmentation-by-detection framework is proposed, which first incorporates object and region detectors pre-trained on still images to generate a set of detection and segmentation proposals. Based on the noisy proposals, several object tracks are then initialized by solving a joint binary optimization problem with min-cost flow. As such tracks actually provide rough configurations of semantic objects, we thus refine the object segmentation while preserving the spatiotemporal consistency by inferring the shape likelihoods of pixels from the statistical information of tracks. Experimental results on Youtube-Objects dataset and SegTrack v2 dataset demonstrate that our method outperforms state-of-the-arts and shows impressive results.","Proposals,
Semantics,
Shape,
Image segmentation,
Noise measurement,
Object segmentation,
Detectors"
A Natural Walking Monitor for Pulmonary Patients Using Mobile Phones,"Mobile devices have the potential to continuously monitor health by collecting movement data including walking speed during natural walking. Natural walking is walking without artificial speed constraints present in both treadmill and nurse-assisted walking. Fitness trackers have become popular which record steps taken and distance, typically using a fixed stride length. While useful for everyday purposes, medical monitoring requires precise accuracy and testing on real patients with a scientifically valid measure. Walking speed is closely linked to morbidity in patients and widely used for medical assessment via measured walking. The 6-min walk test (6MWT) is a standard assessment for chronic obstructive pulmonary disease and congestive heart failure. Current generation smartphone hardware contains similar sensor chips as in medical devices and popular fitness devices. We developed a middleware software, MoveSense, which runs on standalone smartphones while providing comparable readings to medical accelerometers. We evaluate six machine learning methods to obtain gait speed during natural walking training models to predict natural walking speed and distance during a 6MWT with 28 pulmonary patients and ten subjects without pulmonary condition. We also compare our model's accuracy to popular fitness devices. Our universally trained support vector machine models produce 6MWT distance with 3.23% error during a controlled 6MWT and 11.2% during natural free walking. Furthermore, our model attains 7.9% error when tested on five subjects for distance estimation compared to the 50-400% error seen in fitness devices during natural walking.","Legged locomotion,
Monitoring,
Biomedical monitoring,
Predictive models,
Training,
Diseases"
Accurate and Robust Line Segment Extraction Using Minimum Entropy With Hough Transform,"The Hough transform is a popular technique used in the field of image processing and computer vision. With a Hough transform technique, not only the normal angle and distance of a line but also the line-segment's length and midpoint (centroid) can be extracted by analysing the voting distribution around a peak in the Hough space. In this paper, a method based on minimum-entropy analysis is proposed to extract the set of parameters of a line segment. In each column around a peak in Hough space, the voting values specify probabilistic distributions. The corresponding entropies and statistical means are computed. The line-segment's normal angle and length are simultaneously computed by fitting a quadratic polynomial curve to the voting entropies. The line-segment's midpoint and normal distance are computed by fitting and interpolating a linear curve to the voting means. The proposed method is tested on simulated images for detection accuracy by providing comparative results. Experimental results on real-world images verify the method as well. The proposed method for line-segment detection is both accurate and robust in the presence of quantization error, background noise, or pixel disturbances.","Entropy,
Image segmentation,
Transforms,
Interpolation,
Quantization (signal),
Accuracy,
Polynomials"
"Toward Continuous, Noninvasive Assessment of Ventricular Function and Hemodynamics: Wearable Ballistocardiography","Ballistocardiography, the measurement of the reaction forces of the body to cardiac ejection of blood, is one of the few techniques available for unobtrusively assessing the mechanical aspects of cardiovascular health outside clinical settings. Recently, multiple experimental studies involving healthy subjects and subjects with various cardiovascular diseases have demonstrated that the ballistocardiogram (BCG) signal can be used to trend cardiac output, contractility, and beat-by-beat ventricular function for arrhythmias. The majority of these studies has been performed with “fixed” BCG instrumentation-such as weighing scales or chairs-rather than wearable measurements. Enabling wearable, and thus continuous, recording of BCG signals would greatly expand the capabilities of the technique; however, BCG signals measured using wearable devices are morphologically dissimilar to measurements from “fixed” instruments, precluding the analysis and interpretation techniques from one domain to be applied to the other. In particular, the time intervals between the electrocardiogram (ECG) and BCG-namely, the R-J interval, a surrogate for measuring contractility changes-are significantly different for the accelerometer compared to a “fixed” BCG measurement. This paper addresses this need for quantitatively normalizing wearable BCG measurement to “fixed” measurements with a systematic experimental approach. With these methods, the same analysis and interpretation techniques developed over the past decade for “fixed” BCG measurement can be successfully translated to wearable measurements.",
Network Structural Balance Based on Evolutionary Multiobjective Optimization: A Two-Step Approach,"Research on network structural balance has been of great concern to scholars from diverse fields. In this paper, a two-step approach is proposed for the first time to address the network structural balance problem. The proposed approach involves evolutionary multiobjective optimization, followed by model selection. In the first step, an improved version of the multiobjective discrete particle swarm optimization framework developed in our previous work is suggested. The suggested framework is then employed to implement network multiresolution clustering. In the second step, a problem-specific model selection strategy is devised to select the best Pareto solution (PS) from the Pareto front produced by the first step. The best PS is then decoded into the corresponding network community structure. Based on the discovered community structure, imbalanced edges are determined. Afterward, imbalanced edges are flipped so as to make the network structurally balanced. Extensive experiments on synthetic and real-world signed networks demonstrate the effectiveness of the proposed approach.","Social network services,
Communities,
Indexes,
Pareto optimization,
Image edge detection,
Sociology"
A Privacy-Preserving Framework for Large-Scale Content-Based Information Retrieval,"We propose a privacy protection framework for large-scale content-based information retrieval. It offers two layers of protection. First, robust hash values are used as queries to prevent revealing original content or features. Second, the client can choose to omit certain bits in a hash value to further increase the ambiguity for the server. Due to the reduced information, it is computationally difficult for the server to know the client's interest. The server has to return the hash values of all possible candidates to the client. The client performs a search within the candidate list to find the best match. Since only hash values are exchanged between the client and the server, the privacy of both parties is protected. We introduce the concept oftunable privacy, where the privacy protection level can be adjusted according to a policy. It is realized through hash-based piecewise inverted indexing. The idea is to divide a feature vector into pieces and index each piece with a subhash value. Each subhash value is associated with an inverted index list. The framework has been extensively tested using a large image database. We have evaluated both retrieval performance and privacy-preserving performance for a particular content identification application. Two different constructions of robust hash algorithms are used. One is based on random projections; the other is based on the discrete wavelet transform. Both algorithms exhibit satisfactory performance in comparison with state-of-the-art retrieval schemes. The results show that the privacy enhancement slightly improves the retrieval performance. We consider the majority voting attack for estimating the query category and identification. Experiment results show that this attack is a threat when there are near-duplicates, but the success rate decreases with the number of omitted bits and the number of distinct items.","Servers,
Privacy,
Data privacy,
Robustness,
Multimedia communication,
Indexes"
Spatiotemporal Saliency Detection for Video Sequences Based on Random Walk With Restart,"A novel saliency detection algorithm for video sequences based on the random walk with restart (RWR) is proposed in this paper. We adopt RWR to detect spatially and temporally salient regions. More specifically, we first find a temporal saliency distribution using the features of motion distinctiveness, temporal consistency, and abrupt change. Among them, the motion distinctiveness is derived by comparing the motion profiles of image patches. Then, we employ the temporal saliency distribution as a restarting distribution of the random walker. In addition, we design the transition probability matrix for the walker using the spatial features of intensity, color, and compactness. Finally, we estimate the spatiotemporal saliency distribution by finding the steady-state distribution of the walker. The proposed algorithm detects foreground salient objects faithfully, while suppressing cluttered backgrounds effectively, by incorporating the spatial transition matrix and the temporal restarting distribution systematically. Experimental results on various video sequences demonstrate that the proposed algorithm outperforms conventional saliency detection algorithms qualitatively and quantitatively.","Feature extraction,
Spatiotemporal phenomena,
Video sequences,
Image color analysis,
Computational modeling,
Detection algorithms,
Motion measurement"
RFID cardinality estimation with blocker tags,"The widely used RFID tags impose serious privacy concerns as a tag responds to queries from readers no matter they are authorized or not. The common solution is to use a commercially available blocker tag which behaves as if a set of tags with known blocking IDs are present. The use of blocker tags makes RFID estimation much more challenging as some genuine tag IDs are covered by the blocker tag and some are not. In this paper, we propose REB, the first RFID estimation scheme with the presence of blocker tags. REB uses the framed slotted Aloha protocol specified in the C1G2 standard. For each round of the Aloha protocol, REB first executes the protocol on the genuine tags and the blocker tag, and then virtually executes the protocol on the known blocking IDs using the same Aloha protocol parameters. The basic idea of REB is to conduct statistically inference from the two sets of responses and estimate the number of genuine tags. We conduct extensive simulations to evaluate the performance of REB, in terms of time-efficiency and estimation reliability. The experimental results reveal that our REB scheme runs tens of times faster than the fastest identification protocol with the same accuracy requirement.","Estimation,
Radiofrequency identification,
Protocols,
Accuracy,
Computers,
Privacy,
Conferences"
A Unified Semi-Supervised Community Detection Framework Using Latent Space Graph Regularization,"Community structure is one of the most important properties of complex networks and is a foundational concept in exploring and understanding networks. In real world, topology information alone is often inadequate to accurately find community structure due to its sparsity and noises. However, potential useful prior information can be obtained from domain knowledge in many applications. Thus, how to improve the community detection performance by combining network topology with prior information becomes an interesting and challenging problem. Previous efforts on utilizing such priors are either dedicated or insufficient. In this paper, we firstly present a unified interpretation to a group of existing community detection methods. And then based on this interpretation, we propose a unified semi-supervised framework to integrate network topology with prior information for community detection. If the prior information indicates that some nodes belong to the same community, we encode it by adding a graph regularization term to penalize the latent space dissimilarity of these nodes. This framework can be applied to many widely-used matrix-based community detection methods satisfying our interpretation, such as nonnegative matrix factorization, spectral clustering, and their variants. Extensive experiments on both synthetic and real networks show that the proposed framework significantly improves the accuracy of community detection, especially on networks with unclear structures.",
SecDep: A user-aware efficient fine-grained secure deduplication scheme with multi-level key management,"Nowadays, many customers and enterprises backup their data to cloud storage that performs deduplication to save storage space and network bandwidth. Hence, how to perform secure deduplication becomes a critical challenge for cloud storage. According to our analysis, the state-of-the-art secure deduplication methods are not suitable for cross-user finegrained data deduplication. They either suffer brute-force attacks that can recover files falling into a known set, or incur large computation (time) overheads. Moreover, existing approaches of convergent key management incur large space overheads because of the huge number of chunks shared among users. Our observation that cross-user redundant data are mainly from the duplicate files, motivates us to propose an efficient secure deduplication scheme SecDep. SecDep employs User-Aware Convergent Encryption (UACE) and Multi-Level Key management (MLK) approaches. (1) UACE combines cross-user file-level and inside-user chunk-level deduplication, and exploits different secure policies among and inside users to minimize the computation overheads. Specifically, both of file-level and chunk-level deduplication use variants of Convergent Encryption (CE) to resist brute-force attacks. The major difference is that the file-level CE keys are generated by using a server-aided method to ensure security of cross-user deduplication, while the chunk-level keys are generated by using a user-aided method with lower computation overheads. (2) To reduce key space overheads, MLK uses file-level key to encrypt chunk-level keys so that the key space will not increase with the number of sharing users. Furthermore, MLK splits the file-level keys into share-level keys and distributes them to multiple key servers to ensure security and reliability of file-level keys. Our security analysis demonstrates that SecDep ensures data confidentiality and key security. Our experiment results based on several large real-world datasets show that SecDep is more time-efficient and key-space-efficient than the state-of-the-art secure deduplication approaches.","Encryption,
Servers,
Protocols,
Resists"
Steganography Using Reversible Texture Synthesis,"We propose a novel approach for steganography using a reversible texture synthesis. A texture synthesis process resamples a smaller texture image, which synthesizes a new texture image with a similar local appearance and an arbitrary size. We weave the texture synthesis process into steganography to conceal secret messages. In contrast to using an existing cover image to hide messages, our algorithm conceals the source texture image and embeds secret messages through the process of texture synthesis. This allows us to extract the secret messages and source texture from a stego synthetic texture. Our approach offers three distinct advantages. First, our scheme offers the embedding capacity that is proportional to the size of the stego texture image. Second, a steganalytic algorithm is not likely to defeat our steganographic approach. Third, the reversible capability inherited from our scheme provides functionality, which allows recovery of the source texture. Experimental results have verified that our proposed algorithm can provide various numbers of embedding capacities, produce a visually plausible texture images, and recover the source texture.","Kernel,
Indexes,
Shape,
Media,
Image quality,
Weaving,
Digital images"
"Simulation tools for model-based robotics: Comparison of Bullet, Havok, MuJoCo, ODE and PhysX","There is growing need for software tools that can accurately simulate the complex dynamics of modern robots. While a number of candidates exist, the field is fragmented. It is difficult to select the best tool for a given project, or to predict how much effort will be needed and what the ultimate simulation performance will be. Here we introduce new quantitative measures of simulation performance, focusing on the numerical challenges that are typical for robotics as opposed to multi-body dynamics and gaming. We then present extensive simulation results, obtained within a new software framework for instantiating the same model in multiple engines and running side-by-side comparisons. Overall we find that each engine performs best on the type of system it was designed and optimized for: MuJoCo wins the robotics-related tests, while the gaming engines win the gaming-related tests without a clear leader among them. The simulations are illustrated in the accompanying movie.","Engines,
Joints,
Accuracy,
Computational modeling,
Robot kinematics,
Mathematical model"
Nonasymptotic and Second-Order Achievability Bounds for Coding With Side-Information,"We present a novel nonasymptotic or finite blocklength achievability bounds for three side-information problems in network information theory. These include: 1) the Wyner-Ahlswede-Körner (WAK) problem of almost-lossless source coding with rate-limited side-information; 2) the Wyner-Ziv (WZ) problem of lossy source coding with side-information at the decoder; and 3) the Gel'fand-Pinsker (GP) problem of channel coding with noncausal state information available at the encoder. The bounds are proved using ideas from channel simulation and channel resolvability. Our bounds for all three problems improve on all previous nonasymptotic bounds on the error probability of the WAK, WZ, and GP problems-in particular those derived by Verdú. Using our novel nonasymptotic bounds, we recover the general formulas for the optimal rates of these side-information problems. Finally, we also present achievable second-order coding rates by applying the multidimensional Berry-Esséen theorem to our new nonasymptotic bounds. Numerical results show that the second-order coding rates obtained using our nonasymptotic achievability bounds are superior to those obtained using existing finite blocklength bounds.","Error probability,
Decoding,
Source coding,
Joints,
Rate-distortion"
"Underwater Optical Imaging: The Past, the Present, and the Prospects","This paper discusses the current state of underwater optical imaging in the context of physics, technology, biology, and history. The paper encompasses not only the history of human's ability to see underwater, but also the adaptations that various organisms living in oceans or lakes have developed. The continued development of underwater imaging systems at military, commercial, and consumer levels portends well for both increased visibility and accessibility by these various segments. However, the fundamental limits imposed by the environment, as currently understood, set the ultimate constraints. Physics, biology, computer modeling, processing, and the development of technology that ranges from simple cameras and lights to more advanced gated and modulated illumination are described. The future prospects for continuing advancements are also discussed.","Animals,
Optical imaging,
Sea measurements,
Oceans,
Photonics,
Absorption"
Higher-Order Motion-Compensation for In Vivo Cardiac Diffusion Tensor Imaging in Rats,"Motion of the heart has complicated in vivo applications of cardiac diffusion MRI and diffusion tensor imaging (DTI), especially in small animals such as rats where ultra-high-performance gradient sets are currently not available. Even with velocity compensation via, for example, bipolar encoding pulses, the variable shot-to-shot residual motion-induced spin phase can still give rise to pronounced artifacts. This study presents diffusion-encoding schemes that are designed to compensate for higher-order motion components, including acceleration and jerk, which also have the desirable practical features of minimal TEs and high achievable b-values. The effectiveness of these schemes was verified numerically on a realistic beating heart phantom, and demonstrated empirically with in vivo cardiac diffusion MRI in rats. Compensation for acceleration, and lower motion components, was found to be both necessary and sufficient for obtaining diffusion-weighted images of acceptable quality and SNR, which yielded the first in vivo cardiac DTI demonstrated in the rat. These findings suggest that compensation for higher order motion, particularly acceleration, can be an effective alternative solution to high-performance gradient hardware for improving in vivo cardiac DTI.","Diffusion tensor imaging,
Encoding,
Acceleration,
Heart,
In vivo,
Animals"
Stratified Sampling Voxel Classification for Segmentation of Intraretinal and Subretinal Fluid in Longitudinal Clinical OCT Data,"Automated three-dimensional retinal fluid (named symptomatic exudate-associated derangements, SEAD) segmentation in 3D OCT volumes is of high interest in the improved management of neovascular Age Related Macular Degeneration (AMD). SEAD segmentation plays an important role in the treatment of neovascular AMD, but accurate segmentation is challenging because of the large diversity of SEAD size, location, and shape. Here a novel voxel classification based approach using a layer-dependent stratified sampling strategy was developed to address the class imbalance problem in SEAD detection. The method was validated on a set of 30 longitudinal 3D OCT scans from 10 patients who underwent anti-VEGF treatment. Two retinal specialists manually delineated all intraretinal and subretinal fluid. Leave-one-patient-out evaluation resulted in a true positive rate and true negative rate of 96% and 0.16% respectively. This method showed promise for image guided therapy of neovascular AMD treatment.","Histograms,
Retina,
Noise,
Anisotropic magnetoresistance,
Image segmentation,
Brightness,
Transforms"
Mechanical Designs for Inorganic Stretchable Circuits in Soft Electronics,"Mechanical concepts and designs in inorganic circuits for different levels of stretchability are reviewed in this paper, through discussions of the underlying mechanics and material theories, fabrication procedures for the constituent microscale/nanoscale devices, and experimental characterization. All of the designs reported here adopt heterogeneous structures of rigid and brittle inorganic materials on soft and elastic elastomeric substrates, with mechanical design layouts that isolate large deformations to the elastomer, thereby avoiding potentially destructive plastic strains in the brittle materials. The overall stiffnesses of the electronics, their stretchability, and curvilinear shapes can be designed to match the mechanical properties of biological tissues. The result is a class of soft stretchable electronic systems that are compatible with traditional high-performance inorganic semiconductor technologies. These systems afford promising options for applications in portable biomedical and health-monitoring devices. Mechanics theories and modeling play a key role in understanding the underlining physics and optimization of these systems.","Strain,
Substrates,
Integrated circuit interconnections,
Silicon,
Gallium arsenide,
Manufacturing,
Packaging"
Industrial Automation as a Cloud Service,"New cloud services are being developed to support a wide variety of real-life applications. In this paper, we introduce a new cloud service: industrial automation, which includes different functionalities from feedback control and telemetry to plant optimization and enterprise management. We focus our study on the feedback control layer as the most time-critical and demanding functionality. Today's large-scale industrial automation projects are expensive and time-consuming. Hence, we propose a new cloud-based automation architecture, and we analyze cost and time savings under the proposed architecture. We show that significant cost and time savings can be achieved, mainly due to the virtualization of controllers and the reduction of hardware cost and associated labor. However, the major difficulties in providing cloud-based industrial automation systems are timeliness and reliability. Offering automation functionalities from the cloud over the Internet puts the controlled processes at risk due to varying communication delays and potential failure of virtual machines and/or links. Thus, we design an adaptive delay compensator and a distributed fault tolerance algorithm to mitigate delays and failures, respectively. We theoretically analyze the performance of the proposed architecture when compared to the traditional systems and prove zero or negligible change in performance. To experimentally evaluate our approach, we implement our controllers on commercial clouds and use them to control: (i) a physical model of a solar power plant, where we show that the fault-tolerance algorithm effectively makes the system unaware of faults, and (ii) industry-standard emulation with large injected delays and disturbances, where we show that the proposed cloud-based controllers perform indistinguishably from the best-known counterparts: local controllers.",
Enhanced Motor Imagery Training Using a Hybrid BCI With Feedback,"Goal: Motor imagery-related mu/beta rhythms, which can be voluntarily modulated by subjects, have been widely used in EEG-based brain computer interfaces (BCIs). Moreover, it has been suggested that motor imagery-specific EEG differences can be enhanced by feedback training. However, the differences observed in the EEGs of naive subjects are typically not sufficient to provide reliable EEG control and thus result in unintended feedback. Such feedback can frustrate subjects and impede training. In this study, a hybrid BCI paradigm combining motor imagery and steady-state visually evoked potentials (SSVEPs) has been proposed to provide effective continuous feedback for motor imagery training. Methods: During the initial training sessions, subjects must focus on flickering buttons to evoke SSVEPs as they perform motor imagery tasks. The output/feedback of the hybrid BCI is based on hybrid features consisting of motor imagery- and SSVEP-related brain signals. In this context, the SSVEP plays a more important role than motor imagery in generating feedback. As the training progresses, the subjects can gradually decrease their visual attention to the flickering buttons, provided that the feedback is still effective. In this case, the feedback is mainly based on motor imagery. Results: Our experimental results demonstrate that subjects generate distinguishable brain patterns of hand motor imagery after only five training sessions lasting approximately 1.5 h each. Conclusion: The proposed hybrid feedback paradigm can be used to enhance motor imagery training. Significance: This hybrid BCI system with feedback can effectively identify the intentions of the subjects.","Training,
Electroencephalography,
Calibration,
Feature extraction,
Accuracy,
Correlation,
Brain modeling"
An evolutionary game-theoretic framework for cyber-threat information sharing,"The initiative to protect against future cyber crimes requires a collaborative effort from all types of agencies spanning industry, academia, federal institutions, and military agencies. Therefore, a Cybersecurity Information Exchange (CYBEX) framework is required to facilitate breach/patch related information sharing among the participants (firms) to combat cyber attacks. In this paper, we formulate a non-cooperative cybersecurity information sharing game that can guide: (i) the firms (players)1 to independently decide whether to “participate in CYBEX and share” or not; (ii) the CYBEX framework to utilize the participation cost dynamically as incentive (to attract firms toward self-enforced sharing) and as a charge (to increase revenue). We analyze the game from an evolutionary game-theoretic strategy and determine the conditions under which the players' self-enforced evolutionary stability can be achieved. We present a distributed learning heuristic to attain the evolutionary stable strategy (ESS) under various conditions. We also show how CYBEX can wisely vary its pricing for participation to increase sharing as well as its own revenue, eventually evolving toward a win-win situation.","Sociology,
Statistics,
Games,
Investment,
Information management,
Computer security"
ZnO Nanowire-Reduced Graphene Oxide Hybrid Based Portable NH3 Gas Sensing Electron Device,"A ZnO nanowire-reduced graphene oxide (ZnO-rGO) based portable ammonia (NH3) gas sensing electron device working at room temperature has been demonstrated for the first time. The sensor is developed on a microelectrode of micro-electromechanical systems and supported by peripheral circuits and a hosting computer, which enables the real-time detection of NH3 at room temperature. In contrast to the traditional sensors based on pure graphene or ZnO nanowires alone, the ZnO-rGO based gas sensing electron device can detect low-concentration (1 ppm) NH3 with higher sensitivity (~7.2%). Besides, this sensor exhibits satisfying properties at sensing NH3 with the concentration as low as 500 ppb at room temperature.","Electron devices,
Graphene,
Zinc oxide,
Temperature sensors,
Gas detectors,
Nanowires"
Broadband Dual-Polarized F-Probe Fed Stacked Patch Antenna for Base Stations,"A broadband dual polarized patch antenna for base stations is proposed. The proposed antenna consists of two-layer patches fed by four capacitive F-probes. A balanced feeding with 180 ° phase shifts is used to realize the high isolation and low cross polarization. Surrounding copper frame is added to reduce the back radiation. A prototype of the proposed antenna is fabricated. It has a measured 45% relative bandwidth (1.71-2.72 GHz) for , which covers the DCS/PCS/UMTS/LTE2300/LTE2500 bands. The measured isolation between the two ports is about 30 dB and XPD is above 23 dB at broadside. The proposed antenna is suitable for applications in mobile communication base stations.","Broadband antennas,
Ports (Computers),
Patch antennas,
Broadband communication,
Antenna measurements"
A Two-Layer Recurrent Neural Network for Nonsmooth Convex Optimization Problems,"In this paper, a two-layer recurrent neural network is proposed to solve the nonsmooth convex optimization problem subject to convex inequality and linear equality constraints. Compared with existing neural network models, the proposed neural network has a low model complexity and avoids penalty parameters. It is proved that from any initial point, the state of the proposed neural network reaches the equality feasible region in finite time and stays there thereafter. Moreover, the state is unique if the initial point lies in the equality feasible region. The equilibrium point set of the proposed neural network is proved to be equivalent to the Karush-Kuhn-Tucker optimality set of the original optimization problem. It is further proved that the equilibrium point of the proposed neural network is stable in the sense of Lyapunov. Moreover, from any initial point, the state is proved to be convergent to an equilibrium point of the proposed neural network. Finally, as applications, the proposed neural network is used to solve nonlinear convex programming with linear constraints and L1-norm minimization problems.","Programming,
Recurrent neural networks,
Convex functions,
Biological neural networks,
Optimization,
Complexity theory"
Efficiency Evaluation of the Modular Multilevel Converter Based on Si and SiC Switching Devices for Medium/High-Voltage Applications,"The modular multilevel converter (MMC) is the most promising converter topology for medium- and high-power applications. One of the main concerns in the operation of the MMC, particularly for high-power applications, is its efficiency, which should be maximized. Silicon Carbide (SiC)-based devices have the potential to provide significant efficiency improvement compared with silicon devices. However, the possibility and impact of using SiC-based devices instead of silicon devices for high-power conversion have not been thoroughly explored. This paper reports on the results obtained from a detailed study to evaluate the performance of MMCs based on medium-voltage SiC MOSFETs and diodes with hybrid MMCs that employ silicon IGBTs and SiC diodes. The results are based on detailed circuit simulations that use simple physics-based circuit models. The study suggests the potential for significant efficiency gain for MMCs based on SiC power devices.","Silicon carbide,
MOSFET,
Silicon,
Switches,
Insulated gate bipolar transistors,
Schottky diodes,
JFETs"
SmartEye: Real-time and efficient cloud image sharing for disaster environments,"Rapid disaster relief is important to save human lives and reduce property loss. With the wide use of smartphones and their ubiquitous easy access to the Internet, sharing and uploading images to the cloud via smartphones offer a nontrivial opportunity to provide information of disaster zones. However, due to limited available bandwidth and energy, smartphone-based crowdsourcing fails to support the real-time data analytics. The key to efficiently and timely share and analyze the images is to determine the value/worth of the images based on their significance and redundancy, and only upload those valuable and unique images. In this paper, we propose a near-realtime and cost-efficient scheme, called SmartEye, in the cloud-assisted disaster environment. The idea behind SmartEye is to implement QoS-aware in-network deduplication over DiffServ in the software-defined networks (SDN). Due to the ease of use, simplicity and scalability, DiffServ supports the in-network deduplication to meet the needs of differentiated QoS. SmartEye aggregates the flows with similar features via a semantic hashing, and provides communication services for the aggregated, not a single, flow. To achieve these goals, we leverage two main optimization schemes, including semantic hashing and space-efficient filters. Efficient image sharing is helpful to disaster detection and scene recognition. To demonstrate the feasibility of SmartEye, we conduct two real-world case studies in which the loss in Typhoon Haiyan (2013) and Hurricane Sandy (2012) can be identified in a timely fashion by analyzing massive data consisting of more than 22 million images using our SmartEye system. Extensive experimental results illustrate that SmartEye is efficient and effective to achieve real-time analytics in disasters.","Servers,
Feature extraction,
Bandwidth,
Diffserv networks,
Smart phones,
Quality of service,
Computers"
Topological Interference Management With Transmitter Cooperation,"Interference networks with no channel state information at the transmitter except for the knowledge of the connectivity graph have been recently studied under the topological interference management framework. In this paper, we consider a similar problem with topological knowledge but in a distributed broadcast channel setting, i.e., a network where transmitter cooperation is enabled. We show that the topological information can also be exploited in this case to strictly improve the degrees of freedom (DoF) as long as the network is not fully connected, which is a reasonable assumption in practice. Achievability schemes from graph theoretic and interference alignment perspectives are proposed. Together with outer bounds built upon generator sequence, the concept of compound channel settings, and the relation to index coding, we characterize the symmetric DoF for the so-called regular networks with constant number of interfering links, and identify the sufficient and/or necessary conditions for the arbitrary network topologies to achieve a certain amount of symmetric DoF.",
On the performance of a persymmetric adaptive matched filter,"We examine the adaptive detection problem in the presence of colored noise with an unknown covariance matrix, by exploiting a persymmetric structure in the received signal. The persymmetric adaptive matched filter (PS-AMF) is used to address this problem, which can significantly alleviate the requirement of secondary data. In G. Pailloux et al. “Persymmetric adaptive radar detectors,” (2011) the probability of false alarm of the PS-AMF has been obtained in terms of the Gaussian hypergeometric function. In this paper, finite-sum expressions for the probability of false alarm of the PS-AMF are derived, which are more convenient to use in calculating the detection threshold. Moreover, the detection probabilities of the PS-AMF for both nonfluctuating and fluctuating target models are derived. In the fluctuating model, the amplitude of the target echoes is described by a generalized Chi distribution that involves the Rayleigh distribution as a special case. These theoretical results are all confirmed using Monte Carlo (MC) simulations.","Covariance matrices,
Detectors,
Probability,
Training data,
Symmetric matrices,
Radar detection,
Colored noise"
DREAMS: Dynamic resource allocation for MapReduce with data skew,"MapReduce has become a popular model for large-scale data processing in recent years. However, existing MapRe-duce schedulers still suffer from an issue known as partitioning skew, where the output of map tasks is unevenly distributed among reduce tasks. In this paper, we present DREAMS, a framework that provides run-time partitioning skew mitigation. Unlike previous approaches that try to balance the workload of reducers by repartitioning the intermediate data assigned to each reduce task, in DREAMS we cope with partitioning skew by adjusting task run-time resource allocation. We show that our approach allows DREAMS to eliminate the overhead of data repartitioning. Through experiments using both real and synthetic workloads running on a 11-node virtual virtualised Hadoop cluster, we show that DREAMS can effectively mitigate negative impact of partitioning skew, thereby improving job performance by up to 20.3%.","Resource management,
Containers,
Predictive models,
Mathematical model,
Monitoring,
Biomedical monitoring,
Yarn"
Sensor Scheduling for Multi-Modal Confident Information Coverage in Sensor Networks,"Network lifetime maximization with guaranteed coverage is an important issue in wireless sensor networks. Based on our recently proposed confident information coverage (CIC) model, this paper studies the multi-modal confident information coverage (M2CIC) problem. Assuming that each node is equipped with different types of sensors, the objective is to schedule the multi-modal sensors' activity, such that the confident information coverage for each sensing modality can be guaranteed while the network lifetime can be maximized. We model the M2CIC problem as a multi-modal set cover problem (M2SC) and prove its NP-completeness. For solving the M2SC problem, we design two energy-efficient heuristics including a centralized one and a distributed one. In the proposed algorithms, different modal sensors are organized into a family of set covers, each of which can provide confident information coverage for all the monitored physical phenomena. Simulation results show that both the proposed algorithms can efficiently prolong the network lifetime and outperform two classical peer algorithms in terms of the extended network lifetime.",
SDSecurity: A Software Defined Security experimental framework,"The emerging Software Defined Systems (SDSys) is a recent paradigm, which has been introduced to reduce the overhead in the control and management operations of complex computing systems. The main concept behind this technology is around isolating the data plane from the control plane. Traditional security mechanisms are facing more challenges in providing sufficient levels of protection and efficiency. SDSys for security has been proposed to address these challenges. Software Defined Security (SDSec) provides a flexible and centralized security solution by abstracting the security mechanisms from the hardware layer to a software layer. In this paper we present a novel experimental framework to provide a novel virtualized testbed environment for SDSec systems. This work builds on the Mininet simulator, where its core components, the host, switch and the controller, are customized to build the proposed experimental simulation framework for SDSec. To the best of the authors' knowledge, this is the first experimental framework and simulator for SDSec solutions. The developed simulator, will not only support the development and testing of SDSecurity solutions, it will also serve as an experimentation tool for researchers and for benchmarking purposes. The developed simulator could also be used as an educational tool to train students and novice researchers.",
Multi-Spectral Fusion Based Approach for Arbitrarily Oriented Scene Text Detection in Video Images,"Scene text detection from video as well as natural scene images is challenging due to the variations in background, contrast, text type, font type, font size, and so on. Besides, arbitrary orientations of texts with multi-scripts add more complexity to the problem. The proposed approach introduces a new idea of convolving Laplacian with wavelet sub-bands at different levels in the frequency domain for enhancing low resolution text pixels. Then, the results obtained from different sub-bands (spectral) are fused for detecting candidate text pixels. We explore maxima stable extreme regions along with stroke width transform for detecting candidate text regions. Text alignment is done based on the distance between the nearest neighbor clusters of candidate text regions. In addition, the approach presents a new symmetry driven nearest neighbor for restoring full text lines. We conduct experiments on our collected video data as well as several benchmark data sets, such as ICDAR 2011, ICDAR 2013, and MSRA-TD500 to evaluate the proposed method. The proposed approach is compared with the state-of-the-art methods to show its superiority to the existing methods.",
Fine-Grained Image Search,"Large-scale image search has been attracting lots of attention from both academic and commercial fields. The conventional bag-of-visual-words (BoVW) model with inverted index is verified efficient at retrieving near-duplicate images, but it is less capable of discovering fine-grained concepts in the query and returning semantically matched search results. In this paper, we suggest that instance search should return not only near-duplicate images, but also fine-grained results, which is usually the actual intention of a user. We propose a new and interesting problem named fine-grained image search, which means that we prefer those images containing the same fine-grained concept with the query. We formulate the problem by constructing a hierarchical database and defining an evaluation method. We thereafter introduce a baseline system using fine-grained classification scores to represent and co-index images so that the semantic attributes are better incorporated in the online querying stage. Large-scale experiments reveal that promising search results are achieved with reasonable time and memory consumption. We hope this paper will be the foundation for future work on image search. We also expect more follow-up efforts along this research topic and look forward to commercial fine-grained image search engines.","Semantics,
Search problems,
Birds,
Visualization,
Indexes,
Search engines"
Entropic One-Class Classifiers,"The one-class classification problem is a well-known research endeavor in pattern recognition. The problem is also known under different names, such as outlier and novelty/anomaly detection. The core of the problem consists in modeling and recognizing patterns belonging only to a so-called target class. All other patterns are termed nontarget, and therefore, they should be recognized as such. In this paper, we propose a novel one-class classification system that is based on an interplay of different techniques. Primarily, we follow a dissimilarity representation-based approach; we embed the input data into the dissimilarity space (DS) by means of an appropriate parametric dissimilarity measure. This step allows us to process virtually any type of data. The dissimilarity vectors are then represented by weighted Euclidean graphs, which we use to determine the entropy of the data distribution in the DS and at the same time to derive effective decision regions that are modeled as clusters of vertices. Since the dissimilarity measure for the input data is parametric, we optimize its parameters by means of a global optimization scheme, which considers both mesoscopic and structural characteristics of the data represented through the graphs. The proposed one-class classifier is designed to provide both hard (Boolean) and soft decisions about the recognition of test patterns, allowing an accurate description of the classification process. We evaluate the performance of the system on different benchmarking data sets, containing either feature-based or structured patterns. Experimental results demonstrate the effectiveness of the proposed technique.","Entropy,
Pattern recognition,
Data models,
Computational modeling,
Training,
Linear programming,
Optimization"
The Road From Classical to Quantum Codes: A Hashing Bound Approaching Design Procedure,"Powerful quantum error correction codes (QECCs) are required for stabilizing and protecting fragile qubits against the undesirable effects of quantum decoherence. Similar to classical codes, hashing bound approaching QECCs may be designed by exploiting a concatenated code structure, which invokes iterative decoding. Therefore, in this paper, we provide an extensive step-by-step tutorial for designing extrinsic information transfer (EXIT) chart-aided concatenated quantum codes based on the underlying quantum-to-classical isomorphism. These design lessons are then exemplified in the context of our proposed quantum irregular convolutional code (QIRCC), which constitutes the outer component of a concatenated quantum code. The proposed QIRCC can be dynamically adapted to match any given inner code using EXIT charts, hence achieving a performance close to the hashing bound. It is demonstrated that our QIRCC-based optimized design is capable of operating within 0.4 dB of the noise limit.","Encoding,
Quantum computing,
Error correction codes,
Quantum entanglement,
Cascading style sheets,
Turbo codes"
Clustering Game Behavior Data,"Recent years have seen a deluge of behavioral data from players hitting the game industry. Reasons for this data surge are many and include the introduction of new business models, technical innovations, the popularity of online games, and the increasing persistence of games. Irrespective of the causes, the proliferation of behavioral data poses the problem of how to derive insights therefrom. Behavioral data sets can be large, time-dependent and high-dimensional. Clustering offers a way to explore such data and to discover patterns that can reduce the overall complexity of the data. Clustering and other techniques for player profiling and play style analysis have, therefore, become popular in the nascent field of game analytics. However, the proper use of clustering techniques requires expertise and an understanding of games is essential to evaluate results. With this paper, we address game data scientists and present a review and tutorial focusing on the application of clustering techniques to mine behavioral game data. Several algorithms are reviewed and examples of their application shown. Key topics such as feature normalization are discussed and open problems in the context of game analytics are pointed out.","Games,
Clustering algorithms,
Algorithm design and analysis,
Data models,
Context,
Vectors,
Industries"
Automatic Composition of Semantic Web Services Based on Fuzzy Predicate Petri Nets,"Web service composition is a challenging research issue. This paper presents an automatic Web service composition method that deals with both input/output compatibility and behavioral constraint compatibility of fuzzy semantic services. First, user input and output requirements are modeled as a set of facts and a goal statement in the Horn clauses, respectively. A service composition problem is transformed into a Horn clause logic reasoning problem. Next, a Fuzzy Predicate Petri Net (FPPN) is applied to model the Horn clause set, and T-invariant technique is used to determine the existence of composite services fulfilling the user input/output requirements. Then, two algorithms are presented to obtain the composite service satisfying behavioral constraints, as well as to construct an FPPN model that shows the calling order of the selected services.","Semantics,
Web services,
Semantic Web,
Ontologies,
Petri nets,
Cognition,
Educational institutions"
A Novel SURE-Based Criterion for Parametric PSF Estimation,"We propose an unbiased estimate of a filtered version of the mean squared error - the blur-SURE (Stein's unbiased risk estimate)-as a novel criterion for estimating an unknown point spread function (PSF) from the degraded image only. The PSF is obtained by minimizing this new objective functional over a family of Wiener processings. Based on this estimated blur kernel, we then perform nonblind deconvolution using our recently developed algorithm. The SURE-based framework is exemplified with a number of parametric PSF, involving a scaling factor that controls the blur size. A typical example of such parametrization is the Gaussian kernel. The experimental results demonstrate that minimizing the blur-SURE yields highly accurate estimates of the PSF parameters, which also result in a restoration quality that is very similar to the one obtained with the exact PSF, when plugged into our recent multi-Wiener SURE-LET deconvolution algorithm. The highly competitive results obtained outline the great potential of developing more powerful blind deconvolution algorithms based on SURE-like estimates.","Estimation,
Minimization,
Deconvolution,
Noise,
Kernel,
Covariance matrices,
Image restoration"
Toward Automatic Activity Classification and Movement Assessment During a Sports Training Session,"Motion analysis technologies have been widely used to monitor the potential for injury and enhance athlete performance. However, most of these technologies are expensive, can only be used in laboratory environments, and examine only a few trials of each movement action. In this paper, we present a novel ambulatory motion analysis framework using wearable inertial sensors to accurately assess all of an athlete's activities in real training environment. We first present a system that automatically classifies a large range of training activities using the discrete wavelet transform (DWT) in conjunction with a random forest classifier. The classifier is capable of successfully classifying various activities with up to 98% accuracy. Second, a computationally efficient gradient descent algorithm is used to estimate the relative orientations of the wearable inertial sensors mounted on the shank, thigh, and pelvis of a subject, from which the flexion-extension knee and hip angles are calculated. These angles, along with sacrum impact accelerations, are automatically extracted for each stride during jogging. Finally, normative data are generated and used to determine if a subject's movement technique differed to the normative data in order to identify potential injury-related factors. For the joint angle data, this is achieved using a curve-shift registration technique. It is envisaged that the proposed framework could be utilized for accurate and automatic sports activity classification and reliable movement technique evaluation in various unconstrained environments for both injury management and performance enhancement.","Motion control,
Medical devices,
Medical services,
Biomedical monitoring,
Intelligent sensors,
Accelerometers,
Discrete wavelet transforms,
Wireless sensor networks,
Wireless communication,
Injuries"
Traceable CP-ABE: How to Trace Decryption Devices Found in the Wild,"In Ciphertext-policy attribute-based encrypt- ion (CP-ABE), ciphertexts are associated with access policies, which do not have to contain the identities of eligible receivers, and attributes are shared by multiple users. CP-ABE is useful for providing fine-grained access control on encrypted data. However, it also has a practicality concern that a malicious user, with his attributes shared with other users, might leak his decryption privilege as a decryption blackbox, for some financial gain or other incentives, as there is little risk of getting caught. There are two types of decryption blackboxes that reflect different practical scenarios. A key-like decryption blackbox is associated with an attribute set SD and can decrypt ciphertexts with access policies satisfied by SD. A policy-specific decryption blackbox is associated with an access policy AD and can decrypt ciphertexts with AD. Policy-specific decryption blackbox has weaker decryption capacity than key-like decryption blackbox, but tracing it is deemed to be more difficult. In the preliminary version (in CCS 2013) of this paper, we proposed a new CP-ABE scheme which is adaptively traceable against key-like decryption blackbox. The scheme has sublinear overhead, which is the most efficient one to date supporting fully collusion-resistant blackbox traceability. The scheme is fully secure in the standard model, and supports any monotonic access structures. In this paper, we further show that the scheme is also selectively traceable against policy-specific decryption blackbox. Furthermore, and more importantly, we prove a general statement that if a CP-ABE scheme is (selectively) traceable against policy-specific decryption blackbox, it is also (selectively) traceable against key-like decryption blackbox, which implies that we now only need to focus on building CP-ABE schemes which are traceable against policy-specific decryption blackbox.","Indexes,
Games,
Encryption,
Receivers,
Law enforcement"
A RISC-V vector processor with tightly-integrated switched-capacitor DC-DC converters in 28nm FDSOI,"This work demonstrates a RISC-V vector microprocessor implemented in 28nm FDSOI with fully-integrated non-interleaved switched-capacitor DCDC (SC-DCDC) converters and adaptive clocking that generates four on-chip voltages between 0.5V and 1V using only 1.0V core and 1.8V IO voltage inputs. The design pushes the capabilities of dynamic voltage scaling by enabling fast transitions (20ns), simple packaging (no off-chip passives), low area overhead (16%), high conversion efficiency (80-86%), and high energy efficiency (26.2 DP GFLOPS/W) for mobile devices.","Clocks,
Voltage measurement,
Adaptive systems,
Random access memory,
Semiconductor device measurement,
Voltage control,
System-on-chip"
Signal Processing With Direct Computations on Compressively Sensed Data,"Sparsity is characteristic of a signal that potentially allows us to represent information efficiently. We present an approach that enables efficient representations based on sparsity to be utilized throughout a signal processing system, with the aim of reducing the energy and/or resources required for computation, communication, and storage. The representation we focus on is compressive sensing. Its benefit is that compression is achieved with minimal computational cost through the use of random projections; however, a key drawback is that reconstruction is expensive. We focus on inference frameworks for signal analysis. We show that reconstruction can be avoided entirely by transforming signal processing operations (e.g., wavelet transforms, finite impulse response filters, etc.) such that they can be applied directly to the compressed representations. We present a methodology and a mathematical framework that achieve this goal and also enable significant computational-energy savings through operations over fewer input samples. This enables explicit energy-versus-accuracy tradeoffs that are under the control of the designer. We demonstrate the approach through two case studies. First, we consider a system for neural prosthesis that extracts wavelet features directly from compressively sensed spikes. Through simulations, we show that spike sorting can be achieved with 54× fewer samples, providing an accuracy of 98.63% in spike count, 98.56% in firing-rate estimation, and 96.51% in determining the coefficient of variation; this compares with a baseline Nyquist-domain detector with corresponding performance of 98.97%, 99.69%, and 97.09%, respectively. Second, we consider a system for detecting epileptic seizures by extracting spectral-energy features directly from compressively sensed electroencephalogram. Through simulations of the end-to-end algorithm, we show that detection can be achieved with 21× fewer samples, providing a sensitivity of 94.43%, false alarm rate of 0.1543/h, and latency of 4.70 s; this compares with a baseline Nyquist-domain detector with corresponding performance of 96.03%, 0.1471/h, and 4.59 s, respectively.","Feature extraction,
Compressed sensing,
Accuracy,
Signal processing,
Sensors,
Measurement,
Vectors"
Dynamics and trajectory optimization for a soft spatial fluidic elastomer manipulator,"The goal of this work is to develop a soft robotic manipulation system that is capable of autonomous, dynamic, and safe interactions with humans and its environment. First, we develop a dynamic model for a multi-body fluidic elastomer manipulator that is composed entirely from soft rubber and subject to the self-loading effects of gravity. Then, we present a strategy for independently identifying all unknown components of the system: the soft manipulator, its distributed fluidic elastomer actuators, as well as drive cylinders that supply fluid energy. Next, using this model and trajectory optimization techniques we find locally optimal open-loop policies that allow the system to perform dynamic maneuvers we call grabs. In 37 experimental trials with a physical prototype, we successfully perform a grab 92% of the time. By studying such an extreme example of a soft robot, we can begin to solve hard problems inhibiting the mainstream use of soft machines.","Manipulator dynamics,
Actuators,
Heuristic algorithms,
Strain,
Dynamics"
Converter topological and solid state protective device trade-offs for future shipboard MVDC systems,"The search for the optimum architecture for Medium Voltage DC (MVDC) Integrated Power Systems must take into account the short circuit protection in addition to overarching goals of efficiency, survivability and cost effectiveness. A comparison study is performed for architectures with a suitable combination of protective devices and power conversion. This leads also to an optimum MVDC bus voltage somewhere between 15kVdc and 20kVdc. Hardware implementation using packaged SiC devices, currently under development, is explored. The inherent speed of operation of Solid state protective devices will also play a role in fault isolation, hence reducing stress level on all system components.","Circuit faults,
Topology,
Power conversion,
Phase change materials,
Marine vehicles,
Fault currents,
Limiting"
A 1.7 ps Equivalent Bin Size and 4.2 ps RMS FPGA TDC Based on Multichain Measurements Averaging Method,"A high precision and high resolution time-to-digital converter (TDC) based on multichain measurements averaging method is implemented in a 40 nm fabrication process Virtex-6 FPGA. The results of the detailed theoretical analysis and the simulation with the MATLAB tool based on a complete TDC module show that the resolution limitation determined by the intrinsic cell delay of plain tapped-delay chain can be overcame, which results in an improvement on both resolution and precision without increasing the dead time. The test results agree with the simulation results quite well. In such a TDC, the input signal is connected to multiple tapped-delay chains simultaneously (the number of the chains is M), and each chain is just a plain TDC and generates a timestamp for a hit signal. Therefore, M timestamps should be obtained in total, which, after averaging, give the final timestamp. A TDC with 1.7 ps equivalent bin size, 1.5 ps averaged bin size and 4.2 ps RMS has been implemented with M being 16, which performs much better than the plain TDC constructed of a single tapped delay chain having 42.3 ps equivalent bin size, 24.0 ps averaged bin size resolution and 13.2 ps RMS precision. The comparisons of equivalent bin size and averaged bin size show that the nonlinearity is improved with a larger M. Due to the real time integral nonlinearity (INL) calibration and averaging calculation, the multichain TDC is almost insensitive to the process voltage and temperature (PVT) variations.","Delays,
Field programmable gate arrays,
Standards,
Clocks,
Computer architecture"
Multitask Gaussian Processes for Multivariate Physiological Time-Series Analysis,"Gaussian process (GP) models are a flexible means of performing nonparametric Bayesian regression. However, GP models in healthcare are often only used to model a single univariate output time series, denoted as single-task GPs (STGP). Due to an increasing prevalence of sensors in healthcare settings, there is an urgent need for robust multivariate time-series tools. Here, we propose a method using multitask GPs (MTGPs) which can model multiple correlated multivariate physiological time series simultaneously. The flexible MTGP framework can learn the correlation between multiple signals even though they might be sampled at different frequencies and have training sets available for different intervals. Furthermore, prior knowledge of any relationship between the time series such as delays and temporal behavior can be easily integrated. A novel normalization is proposed to allow interpretation of the various hyperparameters used in the MTGP. We investigate MTGPs for physiological monitoring with synthetic data sets and two real-world problems from the field of patient monitoring and radiotherapy. The results are compared with standard Gaussian processes and other existing methods in the respective biomedical application areas. In both cases, we show that our framework learned the correlation between physiological time series efficiently, outperforming the existing state of the art.","Correlation,
Biological system modeling,
Training data,
Training,
Covariance matrices,
Gaussian processes,
Indexes"
Trustworthiness in crowd- sensed and sourced georeferenced data,"This paper focuses on the trustworthiness of data gathered from different sources, including crowdsensing and crowdsourcing, in pervasive systems. The specific focus is on mPASS (mobile Pervasive Accessibility Social Sensing), a system devoted to support mobile users with accessibility needs in a smart city context. mPASS is in charge of collecting data about urban and architectural barriers and facilities, with the aim of providing mobile users with personalized paths, during their movement, computed on the basis of their preferences and accessibility needs. A trustworthiness model is presented that combines three sources of information, i.e., crowdsensed data, crowdsourced data and authoritative data. Simulations results witness the feasibility of our approach.","Sensors,
Crowdsourcing,
Data models,
Accuracy,
Urban areas,
Organizations,
Mobile handsets"
I-AUV Mechatronics Integration for the TRIDENT FP7 Project,"Autonomous underwater vehicles (AUVs) are routinely used to survey areas of interest in seas and oceans all over the world. However, those operations requiring intervention capabilities are still reserved to manned submersibles or remotely operated vehicles (ROVs). In the recent years, few research projects have demonstrated the viability of a new type of submersible, the intervention AUV (I-AUV), which can perform underwater missions involving manipulations in a completely autonomous way. The EU FP7 TRIDENT project is one of the most recent examples of such technological concept. This paper describes the different mechatronic components that constitute the I-AUV developed for the TRIDENT project, their hardware and software integration, and the performance of the vehicle during the project trials.","Joints,
Grippers,
Vehicles,
Brushless motors,
Mechatronics,
Underwater vehicles,
Robots"
From single image query to detailed 3D reconstruction,"Structure-from-Motion for unordered image collections has significantly advanced in scale over the last decade. This impressive progress can be in part attributed to the introduction of efficient retrieval methods for those systems. While this boosts scalability, it also limits the amount of detail that the large-scale reconstruction systems are able to produce. In this paper, we propose a joint reconstruction and retrieval system that maintains the scalability of large-scale Structure-from-Motion systems while also recovering the often lost ability of reconstructing fine details of the scene. We demonstrate our proposed method on a large-scale dataset of 7.4 million images downloaded from the Internet.","Image reconstruction,
Three-dimensional displays,
Image resolution,
Image retrieval,
Cameras,
Scalability,
Internet"
Retinal Artery-Vein Classification via Topology Estimation,"We propose a novel, graph-theoretic framework for distinguishing arteries from veins in a fundus image. We make use of the underlying vessel topology to better classify small and midsized vessels. We extend our previously proposed tree topology estimation framework by incorporating expert, domain-specific features to construct a simple, yet powerful global likelihood model. We efficiently maximize this model by iteratively exploring the space of possible solutions consistent with the projected vessels. We tested our method on four retinal datasets and achieved classification accuracies of 91.0%, 93.5%, 91.7%, and 90.9%, outperforming existing methods. Our results show the effectiveness of our approach, which is capable of analyzing the entire vasculature, including peripheral vessels, in wide field-of-view fundus photographs. This topology-based method is a potentially important tool for diagnosing diseases with retinal vascular manifestation.","Veins,
Arteries,
Retina,
Topology,
Labeling,
Image color analysis,
Space exploration"
Adaptive Neural Network Dynamic Surface Control for a Class of Time-Delay Nonlinear Systems With Hysteresis Inputs and Dynamic Uncertainties,"In this paper, an adaptive neural network (NN) dynamic surface control is proposed for a class of time-delay nonlinear systems with dynamic uncertainties and unknown hysteresis. The main advantages of the developed scheme are: 1) NNs are utilized to approximately describe nonlinearities and unknown dynamics of the nonlinear time-delay systems, making it possible to deal with unknown nonlinear uncertain systems and pursue the L∞ performance of the tracking error; 2) using the finite covering lemma together with the NNs approximators, the Krasovskii function is abandoned, which paves the way for obtaining the L∞ performance of the tracking error; 3) by introducing an initializing technique, the L∞ performance of the tracking error can be achieved; 4) using a generalized Prandtl-Ishlinskii (PI) model, the limitation of the traditional PI hysteresis model is overcome; and 5) by applying the Young's inequalities to deal with the weight vector of the NNs, the updated laws are needed only at the last controller design step with only two parameters being estimated, which reduces the computational burden. It is proved that the proposed scheme can guarantee semiglobal stability of the closed-loop system and achieves the L∞ performance of the tracking error. Simulation results for general second-order time-delay nonlinear systems and the tuning metal cutting system are presented to demonstrate the efficiency of the proposed method.","Hysteresis,
Nonlinear systems,
Artificial neural networks,
Adaptive systems,
Delay effects,
Uncertainty,
Vectors"
A Smart Wirelessly Powered Homecage for Long-Term High-Throughput Behavioral Experiments,"A wirelessly powered homecage system, called the EnerCage-HC, that is equipped with multicoil wireless power transfer, closed-loop power control, optical behavioral tracking, and a graphic user interface is presented for longitudinal electrophysiology and behavioral neuroscience experiments. The EnerCage-HC system can wirelessly power a mobile unit attached to a small animal subject and also track its behavior in real-time as it is housed inside a standard homecage. The EnerCage-HC system is equipped with one central and four overlapping slanted wire-wound coils with optimal geometries to form threeand four-coil power transmission links while operating at 13.56 MHz. Utilizing multicoil links increases the power transfer efficiency (PTE) compared with conventional two-coil links and also reduces the number of power amplifiers to only one, which significantly reduces the system complexity, cost, and heat dissipation. A Microsoft Kinect installed 90 cm above the homecage localizes the animal position and orientation with 1.6-cm accuracy. Moreover, a power management ASIC, including a high efficiency active rectifier and automatic coil resonance tuning, was fabricated in a 0.35-μm 4M2P standard CMOS process for the mobile unit. The EnerCage-HC achieves a max/min PTE of 36.3%/16.1% at the nominal height of 7 cm. In vivo experiments were conducted on freely behaving rats by continuously delivering 24 mW to the mobile unit for >7 h inside a standard homecage.","Mobile communication,
Coils,
Animals,
Wires,
Graphical user interfaces,
Real-time systems,
Geometry"
Kernel Association for Classification and Prediction: A Survey,"Kernel association (KA) in statistical pattern recognition used for classification and prediction have recently emerged in a machine learning and signal processing context. This survey outlines the latest trends and innovations of a kernel framework for big data analysis. KA topics include offline learning, distributed database, online learning, and its prediction. The structural presentation and the comprehensive list of references are geared to provide a useful overview of this evolving field for both specialists and relevant scholars.","Kernel,
Support vector machines,
Principal component analysis,
Artificial neural networks,
Optimization,
Feature extraction,
Accuracy"
Collaborative Search Log Sanitization: Toward Differential Privacy and Boosted Utility,"Severe privacy leakage in the AOL search log incident has attracted considerable worldwide attention. However, all the web users' daily search intents and behavior are collected in such data, which can be invaluable for researchers, data analysts and law enforcement personnel to conduct social behavior study [14], criminal investigation [5] and epidemics detection [10]. Thus, an important and challenging research problem is how to sanitize search logs with strong privacy guarantee and sufficiently retained utility. Existing approaches in search log sanitization are capable of only protecting the privacy under a rigorous standard [24] or maintaining good output utility [25] . To the best of our knowledge, there is little work that has perfectly resolved such tradeoff in the context of search logs, meeting a high standard of both requirements. In this paper, we propose a sanitization framework to tackle the above issue in a distributed manner. More specifically, our framework enables different parties to collaboratively generate search logs with boosted utility while satisfying Differential Privacy. In this scenario, two privacy-preserving objectives arise: first, the collaborative sanitization should satisfy differential privacy; second, the collaborative parties cannot learn any private information from each other. We present an efficient protocol -Collaborative sEarch Log Sanitization (CELS) to meet both privacy requirements. Besides security/privacy and cost analysis, we demonstrate the utility and efficiency of our approach with real data sets.",
Rapid prototyping of a wireless sensor network gateway for the internet of things using off-the-shelf components,"More than 50 billion devices are estimated to be connected to the Internet by 2020. Incompatibility of devices and protocols (usually proprietary devices and protocols) are one of the major hurdles to be overcome to realise the Internet of Things (IoT) vision. IoT devices are typically constrained devices and this creates dependencies between the hardware, software and protocols used in the device. Open hardware and software platforms to support emerging IoT trends are required. A wireless sensor network gateway was developed in a three-month period using off-the-shelf components. The gateway was based on the Raspberry PI single-board computer; it implemented 6LoWPAN mesh and wireless access point functionality for mobile and low power sensing and actuation devices. The gateway was tested in the following use-case: integrate a battery-operated 6LoWPAN-enabled smart water meter to an IPv6 building network. Several factors that influence the gateway's performance and reliability were identified and should be considered when deploying gateway devices for future endeavours.",
A Lyapunov Optimization Approach for Green Cellular Networks With Hybrid Energy Supplies,"Powering cellular networks with renewable energy sources via energy harvesting (EH) have recently been proposed as a promising solution for green networking. However, with intermittent and random energy arrivals, it is challenging to provide satisfactory quality of service (QoS) in EH networks. To enjoy the greenness brought by EH while overcoming the instability of the renewable energy sources, hybrid energy supply (HES) networks that are powered by both EH and the electric grid have emerged as a new paradigm for green communications. In this paper, we will propose new design methodologies for HES green cellular networks with the help of Lyapunov optimization techniques. The network service cost, which addresses both the grid energy consumption and achievable QoS, is adopted as the performance metric, and it is optimized via base station assignment and power control (BAPC). Our main contribution is a low-complexity online algorithm to minimize the long-term average network service cost, namely, the Lyapunov optimization-based BAPC (LBAPC) algorithm. One main advantage of this algorithm is that the decisions depend only on the instantaneous side information without requiring distribution information of channels and EH processes. To determine the network operation, we only need to solve a deterministic per-time slot problem, for which an efficient inner-outer optimization algorithm is proposed. Moreover, the proposed algorithm is shown to be asymptotically optimal via rigorous analysis. Finally, sample simulation results are presented to verify the theoretical analysis as well as validate the effectiveness of the proposed algorithm.","Algorithm design and analysis,
Green communications,
Quality of service,
Batteries,
Green products,
Energy consumption,
Cellular networks,
Energy harvesting,
Lyapunov methods"
Multi-Task CNN Model for Attribute Prediction,"This paper proposes a joint multi-task learning algorithm to better predict attributes in images using deep convolutional neural networks (CNN). We consider learning binary semantic attributes through a multi-task CNN model, where each CNN will predict one binary attribute. The multi-task learning allows CNN models to simultaneously share visual knowledge among different attribute categories. Each CNN will generate attribute-specific feature representations, and then we apply multi-task learning on the features to predict their attributes. In our multi-task framework, we propose a method to decompose the overall model's parameters into a latent task matrix and combination matrix. Furthermore, under-sampled classifiers can leverage shared statistics from other classifiers to improve their performance. Natural grouping of attributes is applied such that attributes in the same group are encouraged to share more knowledge. Meanwhile, attributes in different groups will generally compete with each other, and consequently share less knowledge. We show the effectiveness of our method on two popular attribute datasets.","Matrix decomposition,
Visualization,
Training,
Semantics,
Predictive models"
Advanced Methodology for Fast 3-D TCAD Device/Circuit Electrothermal Simulation and Analysis of Power HEMTs,"This paper introduces an advanced methodology for fast 3-D Technology Computer Aided Design (TCAD) electrothermal simulation for the analysis of power devices. The proposed methodology is based on coupling finite element method (FEM) thermal and circuit electrical simulation in a mixed-mode setup. A power InAlN/GaN high-electron mobility transistor (HEMT) is used to perform validation of the designed electrothermal simulation. A new equivalent temperature-dependent nonlinear analytical large signal circuit model of HEMT is proposed. The model is implemented to Synopsys TCAD Sentaurus using compact model interface. The designed electrothermal simulation methodology is developed to shorten the simulation time for complex 3-D devices. This approach combines the speed and accuracy, and couples temperature nonuniformity to the active device electrothermal behavior. The simulation results are compared with the measured data and results of 2-D FEM simulations. The features and limitations of the methods are analyzed and presented.","Integrated circuit modeling,
HEMTs,
MODFETs,
Solid modeling,
Mathematical model,
Logic gates,
Analytical models"
"Low Profile, Broadside Radiating, Electrically Small Huygens Source Antennas","It is demonstrated numerically that a metamaterial-inspired, low profile (height approximately λ/80), electrically small (ka = 0.45) Huygens source antenna can be designed to radiate at 300 MHz in its broadside direction with a high radiation efficiency and a large front-to-back ratio. Two electrically small, near-field resonant parasitic (NFRP) antennas are first designed. Both are based on a coax-fed dipole antenna. An electric dipole response is obtained by combining it with a tunable Egyptian axe dipole (EAD) NFRP element. A magnetic dipole response is obtained by spatially loading the driven dipole with tunable, extruded capacitively loaded loop (CLL) NFRP elements. The driven dipole and the EAD and CLL NFRP elements are combined together and retuned to achieve a broadside radiating Huygens source antenna. Two different designs, one with two CLL elements and one with four, are obtained, and their performance characteristics are compared.","Dipole antennas,
Magnetic resonance,
Copper,
Antenna accessories,
Bandwidth"
Quantize and Encode Relaying Through FSO and Hybrid FSO/RF Links,"A relaying scheme that uses both radio frequency (RF) and free space optical (FSO) links is investigated. In the proposed quantize and encode relaying (QER), a mobile source broadcasts the RF signal using quadrature amplitude modulation (QAM). The relay estimates and quantizes the log-likelihood ratio (LLR) of each received bit in the symbol and transmits the corresponding information to the destination through a high-speed FSO link or through a hybrid FSO/RF link. Relaying of multiple bits through high-speed FSO links improves RF spectrum utilization over systems where both the source and the relay transmit using RF signals. Exploiting the high available unlicensed bandwidth of the FSO links, the relay can even encode the LLRs using a channel code. Multiple encoded bits can then be mapped to FSO or hybrid FSO/RF symbols. The performance of the proposed system is analyzed, and it is shown that optimal symbol mapping can provide improvements of several decibels over conventional FSO transmissions that employ ON and OFF for binary ones and zeros, respectively. The system is found to achieve full diversity in fading FSO and RF channels.","Radio frequency,
Relays,
Signal to noise ratio,
Bandwidth,
Quadrature amplitude modulation,
Optical fiber communication,
RF signals"
Compressed Sensing Matrices From Fourier Matrices,"The class of Fourier matrices is of special importance in compressed sensing (CS). This paper concerns deterministic construction of CS matrices from Fourier matrices. Using Katz' character sum estimation, we are able to design a deterministic procedure to select rows from a Fourier matrix to form a good CS matrix for sparse recovery. The sparsity bound in our construction is similar to that of binary CS matrices constructed by DeVore, which greatly improves previous results for CS matrices from Fourier matrices. Our approach also provides more flexibility in terms of the dimension of CS matrices. This paper also contains a useful improvement to Katz' character sum estimation for quadratic extensions, with an elementary and transparent proof. Based on this improvement, we construct a class of special CS matrices consisting of partial Fourier matrices whose columns are a union of orthonormal bases. As a consequence, our construction yields an approximately mutually unbiased bases from Fourier matrices which is of particular interest to quantum information theory. Some numerical examples are also included.",
Efficient biometric and password based mutual authentication for consumer USB mass storage devices,"A Universal Serial Bus (USB) Mass Storage Device (MSD), often termed a USB flash drive, is ubiquitously used to store important information in unencrypted binary format. This low cost consumer device is incredibly popular due to its size, large storage capacity and relatively high transfer speed. However, if the device is lost or stolen an unauthorized person can easily retrieve all the information. Therefore, it is advantageous in many applications to provide security protection so that only authorized users can access the stored information. In order to provide security protection for a USB MSD, this paper proposes a session key agreement protocol after secure user authentication. The main aim of this protocol is to establish session key negotiation through which all the information retrieved, stored and transferred to the USB MSD is encrypted. This paper not only contributes an efficient protocol, but also does not suffer from the forgery attack and the password guessing attack as compared to other protocols in the literature. This paper analyses the security of the proposed protocol through a formal analysis which proves that the information is stored confidentially and is protected offering strong resilience to relevant security attacks. The computational cost and communication cost of the proposed scheme is analyzed and compared to related work to show that the proposed scheme has an improved tradeoff for computational cost, communication cost and security.","Authentication,
Universal Serial Bus,
Protocols,
Cryptography,
Forgery,
Servers"
Indoor localization system for emergency responders with ultra low-power radio landmarks,"In this paper we present a novel indoor localization approach based on 868MHz radio landmarks and inertial sensor data as a guidance system for emergency responders. For the first time we use low-power wake-up technology to develop real-time capable landmarks that overcome the problem of limited landmark lifetime. While in sleep mode our landmarks have an overall power consumption of 5.6μW making them ready-to-use in case of an emergency for up to 8 years. The landmarks are small and cost-efficient and may be integrated into the building infrastructure, e.g. into smoke detectors. Additionally, we have developed a handheld device for firefighters which communicates with our landmarks by an initial radio wake-up call and subsequent measuring of the received signal strength (RSSI) of the response. The measurements are used as an input to estimate and display the positions of the firefighter and the landmarks using local optimization algorithms. Furthermore, our handheld device communicates with a body-mounted wireless micro-inertial measurement unit (μIMU) to receive the angular rate, acceleration and magnetic field information in all three dimensions improving the accuracy of positioning. With this easy-to-setup guidance system emergency forces can be more effective, and the duration of rescue operations is reduced, hereby improving both the safety of rescue forces and increasing the chances of disaster victims.",
Analyzing Activity Behavior and Movement in a Naturalistic Environment Using Smart Home Techniques,"One of the many services that intelligent systems can provide is the ability to analyze the impact of different medical conditions on daily behavior. In this study, we use smart home and wearable sensors to collect data, while (n = 84) older adults perform complex activities of daily living. We analyze the data using machine learning techniques and reveal that differences between healthy older adults and adults with Parkinson disease not only exist in their activity patterns, but that these differences can be automatically recognized. Our machine learning classifiers reach an accuracy of 0.97 with an area under the ROC curve value of 0.97 in distinguishing these groups. Our permutation-based testing confirms that the sensor-based differences between these groups are statistically significant.","Smart homes,
Machine learning,
Parkinson's disease,
Pervasive computing,
Wearable sensors,
Patient monitoring"
Pervasive self-powered human activity recognition without the accelerometer,"Conventional human activity recognition (HAR) relies on accelerometers to frequently sample human motion (acceleration). Unfortunately, power consumption of accelerometers becomes a bottleneck for realising pervasive self-powering HAR as the amount of power that can be practically harvested from the environment is very small. Instead of using accelerometer, this paper advocates the use of energy harvesting power signal as the source of HAR when motion (kinetic) energy is being harvested to power the device. The proposed use of harvested power for classifying human activities is motivated by the fact that different activities produce kinetic energy in a different way leaving their signatures in the harvested power signal. Using information theoretic analysis of experimental data, we show that many standard statistical features provide significant information gain when the kinetic power signal is used for discriminating between different activities, confirming its potential use for HAR. We have evaluated activity recognition accuracy for kinetic power signal based HAR using 14 different sets of common activities each containing between 2-10 different activities to be classified. HAR accuracies varied between 68% to 100% depending on the set of activities. The average accuracy over all activity sets is 83%, which is within 13% of what could be achieved with an accelerometer without any power constraints.","Accelerometers,
Accuracy,
Kinetic theory,
Acceleration,
Legged locomotion,
Feature extraction,
Conferences"
Bidirectional Active Learning: A Two-Way Exploration Into Unlabeled and Labeled Data Set,"In practical machine learning applications, human instruction is indispensable for model construction. To utilize the precious labeling effort effectively, active learning queries the user with selective sampling in an interactive way. Traditional active learning techniques merely focus on the unlabeled data set under a unidirectional exploration framework and suffer from model deterioration in the presence of noise. To address this problem, this paper proposes a novel bidirectional active learning algorithm that explores into both unlabeled and labeled data sets simultaneously in a two-way process. For the acquisition of new knowledge, forward learning queries the most informative instances from unlabeled data set. For the introspection of learned knowledge, backward learning detects the most suspiciously unreliable instances within the labeled data set. Under the two-way exploration framework, the generalization ability of the learning model can be greatly improved, which is demonstrated by the encouraging experimental results.",
SOM: Semantic obviousness metric for image quality assessment,"Image quality assessment (IQA) tries to estimate human perception based image visual quality in an objective manner. Existing approaches target this problem with or without reference images. For no-reference image quality assessment, there is no given reference image or any knowledge of the distortion type of the image. Previous approaches measure the image quality from signal level rather than semantic analysis. They typically depend on various features to represent local characteristic of an image. In this paper we propose a new no-reference (NR) image quality assessment (IQA) framework based on semantic obviousness. We discover that semantic-level factors affect human perception of image quality. With such observation, we explore semantic obviousness as a metric to perceive objects of an image. We propose to extract two types of features, one to measure the semantic obviousness of the image and the other to discover local characteristic. Then the two kinds of features are combined for image quality estimation. The principles proposed in our approach can also be incorporated with many existing IQA algorithms to boost their performance. We evaluate our approach on the LIVE dataset. Our approach is demonstrated to be superior to the existing NR-IQA algorithms and comparable to the state-of-the-art full-reference IQA (FR-IQA) methods. Cross-dataset experiments show the generalization ability of our approach.",
Toward the Coevolution of Novel Vertical-Axis Wind Turbines,"The production of renewable and sustainable energy is one of the most important challenges currently facing mankind. Wind has made an increasing contribution to the world's energy supply mix, but remains a long way from reaching its full potential. In this paper, we investigate the use of artificial evolution to design vertical-axis wind turbine prototypes that are physically instantiated and evaluated under approximated wind tunnel conditions. Initially, a conventional evolutionary algorithm is used to explore the design space of a single wind turbine and later a cooperative coevolutionary algorithm is used to explore the design space of an array of wind turbines. Artificial neural networks are used throughout as surrogate models to assist learning and found to reduce the number of fabrications required to reach a higher aerodynamic efficiency. Unlike other approaches, such as computational fluid dynamics simulations, no mathematical formulations are used and no model assumptions are made.","Computational modeling,
Blades,
Wind turbines,
Printers,
Prototypes,
Fabrication,
Aerodynamics"
Blurred persistence in transactional persistent memory,"Persistent memory provides data persistence at main memory level and enables memory-level storage systems. To ensure consistency of the storage systems, memory writes need to be transactional and are carefully moved across the boundary between the volatile CPU cache and the persistent memory. Unfortunately, the CPU cache is hardware-controlled, and it incurs high overhead for programs to track and move data blocks from being volatile to persistent. In this paper, we propose a software-based mechanism, Blurred Persistence, to blur the volatility-persistence boundary, so as to reduce the overhead in transaction support. Blurred Persistence consists of two techniques. First, Execution in Log executes a transaction in the log to eliminate duplicated data copies for execution. It allows the persistence of volatile uncommitted data, which can be detected by reorganizing the log structure. Second, Volatile Checkpoint with Bulk Persistence allows the committed data to aggressively stay volatile by leveraging the data durability in the log, as long as the commit order across threads is kept. By doing so, it reduces the frequency of forced persistence and improves cache efficiency. Evaluations show that our mechanism improves system performance by 56.3% to 143.7% for a variety of workloads.",
CogBoost: Boosting for Fast Cost-Sensitive Graph Classification,"Graph classification has drawn great interests in recent years due to the increasing number of applications involving objects with complex structure relationships. To date, all existing graph classification algorithms assume, explicitly or implicitly, that misclassifying instances in different classes incurs an equal amount of cost (or risk), which is often not the case in real-life applications (where misclassifying a certain class of samples, such as diseased patients, is subject to more expensive costs than others). Although cost-sensitive learning has been extensively studied, all methods are based on data with instance-feature representation. Graphs, however, do not have features available for learning and the feature space of graph data is likely infinite and needs to be carefully explored in order to favor classes with a higher cost. In this paper, we propose, CogBoost, a fast cost-sensitive graph classification algorithm, which aims to minimize the misclassification costs (instead of the errors) and achieve fast learning speed for large scale graph data sets. To minimize the misclassification costs, CogBoost iteratively selects the most discriminative subgraph by considering costs of different classes, and then solves a linear programming problem in each iteration by using Bayes decision rule based optimal loss function. In addition, a cutting plane algorithm is derived to speed up the solving of linear programs for fast learning on large scale data sets. Experiments and comparisons on real-world large graph data sets demonstrate the effectiveness and the efficiency of our algorithm.","Training,
Boosting,
Fasteners,
Support vector machines,
Vectors,
Standards,
Linear programming"
Attack of Mechanical Replicas: Liveness Detection With Eye Movements,"This paper investigates liveness detection techniques in the area of eye movement biometrics. We investigate a specific scenario, in which an impostor constructs an artificial replica of the human eye. Two attack scenarios are considered: 1) the impostor does not have access to the biometric templates representing authentic users, and instead utilizes average anatomical values from the relevant literature and 2) the impostor gains access to the complete biometric database, and is able to employ exact anatomical values for each individual. In this paper, liveness detection is performed at the feature and match score levels for several existing forms of eye movement biometric, based on different aspects of the human visual system. The ability of each technique to differentiate between live and artificial recordings is measured by its corresponding false spoof acceptance rate, false live rejection rate, and classification rate. The results suggest that eye movement biometrics are highly resistant to circumvention by artificial recordings when liveness detection is performed at the feature level. Unfortunately, not all techniques provide feature vectors that are suitable for liveness detection at the feature level. At the match score level, the accuracy of liveness detection depends highly on the biometric techniques employed.","Biological system modeling,
Accuracy,
Iris recognition,
Feature extraction,
Vectors,
Mathematical model"
FPGA Implementation of Orthogonal Matching Pursuit for Compressive Sensing Reconstruction,"In this paper, we present a novel architecture based on field-programmable gate arrays (FPGAs) for the reconstruction of compressively sensed signal using the orthogonal matching pursuit (OMP) algorithm. We have analyzed the computational complexities and data dependence between different stages of OMP algorithm to design its architecture that provides higher throughput with less area consumption. Since the solution of least square problem involves a large part of the overall computation time, we have suggested a parallel low-complexity architecture for the solution of the linear system. We have further modeled the proposed design using Simulink and carried out the implementation on FPGA using Xilinx system generator tool. We have presented here a methodology to optimize both area and execution time in Simulink environment. The execution time of the proposed design is reduced by maximizing parallelism by appropriate level of unfolding, while the FPGA resources are reduced by sharing the hardware for matrix-vector multiplication across the data-dependent sections of the algorithm. The hardware implementation on the Virtex6 FPGA provides significantly superior performance in terms of resource utilization measured in the number of occupied slices, and maximum usable frequency compared with the existing implementations. Compared with the existing similar design, the proposed structure involves 328 more DSP48s, but it involves 25802 less slices and 1.85 times less computation time for signal reconstruction with N = 1024, K = 256, and m = 36, where N is the number of samples, K is the size of the measurement vector, and m is the sparsity. It also provides a higher peak signal-to-noise ratio value of 38.9 dB with a reconstruction time of 0.34 μs, which is twice faster than the existing design. In addition, we have presented a performance metric to implement the OMP algorithm in resource constrained FPGA for the better quality of signal reconstruction.","Vectors,
Matrix decomposition,
Algorithm design and analysis,
Matching pursuit algorithms,
Symmetric matrices,
Computer architecture,
Field programmable gate arrays"
An RRAM Biasing Parameter Optimizer,"Research on memory devices is a highly active field, and many new technologies are being constantly developed. However, characterizing them and understanding how to bias for optimal performance are becoming an increasingly tight bottleneck. Here, we propose a novel technique for extracting biasing parameters, conducive to desirable switching behavior in a highly automated manner, thereby shortening the process development cycles. The principle of operation is based on: 1) applying variable amplitude, pulse-mode stimulation on a test device in order to induce switching multiple times; 2) collecting the data on how pulsing parameters affect the device's resistive state; and 3) choosing the most suitable biasing parameters for the application at hand. The utility of the proposed technique is validated on TiOx-based prototypes, where we demonstrate the successful extraction of biasing parameters that allow the operation of our devices both as multistate and binary resistive switches.","Switches,
Programming,
Testing,
Random access memory,
Voltage measurement,
Performance evaluation,
Prototypes"
Efficient RGB-D object categorization using cascaded ensembles of randomized decision trees,"This paper presents an efficient framework for the categorization of objects in real-world scenes (captured with an RGB-D sensor). The proposed framework uses ensembles of randomized decision trees in a hierarchical cascaded architecture to compute consistent object-class inferences of unseen objects. Specifically, the proposed framework computes object-class probabilities at three levels of an image hierarchy (i.e., pixel-, surfel-, and object-levels) using Random Forest classifiers. Next, these probabilities are fused together to compute a cumulative probabilistic output which is used to infer object categories. This fusion results in an improved object categorization performance compared with the state-of-the-art methods.","Feature extraction,
Three-dimensional displays,
Training,
Histograms,
Image color analysis,
Probabilistic logic,
Decision trees"
Supervised Dictionary Learning for Inferring Concurrent Brain Networks,"Task-based fMRI (tfMRI) has been widely used to explore functional brain networks via predefined stimulus paradigm in the fMRI scan. Traditionally, the general linear model (GLM) has been a dominant approach to detect task-evoked networks. However, GLM focuses on task-evoked or event-evoked brain responses and possibly ignores the intrinsic brain functions. In comparison, dictionary learning and sparse coding methods have attracted much attention recently, and these methods have shown the promise of automatically and systematically decomposing fMRI signals into meaningful task-evoked and intrinsic concurrent networks. Nevertheless, two notable limitations of current data-driven dictionary learning method are that the prior knowledge of task paradigm is not sufficiently utilized and that the establishment of correspondences among dictionary atoms in different brains have been challenging. In this paper, we propose a novel supervised dictionary learning and sparse coding method for inferring functional networks from tfMRI data, which takes both of the advantages of model-driven method and data-driven method. The basic idea is to fix the task stimulus curves as predefined model-driven dictionary atoms and only optimize the other portion of data-driven dictionary atoms. Application of this novel methodology on the publicly available human connectome project (HCP) tfMRI datasets has achieved promising results.",
"Feature lifecycles as they spread, migrate, remain, and die in App Stores","We introduce a theoretical characterisation of feature lifecycles in app stores, to help app developers to identify trends and to find undiscovered requirements. To illustrate and motivate app feature lifecycle analysis, we use our theory to empirically analyse the migratory and non-migratory behaviours of 4,053 non-free features from two App Stores (Samsung and BlackBerry). The results reveal that, in both stores, intransitive features (those that neither migrate nor die out) exhibit significantly different behaviours with regard to important properties, such as their price. Further correlation analysis also highlights differences between trends relating price, rating, and popularity. Our results indicate that feature lifecycle analysis can yield insights that may also help developers to understand feature behaviours and attribute relationships.","Feature extraction,
Data mining,
Databases,
Software,
HTML,
Market research,
Natural language processing"
Overview of Measurement Methods for Factors Affecting the Human Visual System in 3D Displays,"Three-dimensional (3D) display systems are widely used nowadays, and their psychophysiological effects on human health have been investigated in detail. However, due to recent advances in 3D display technology, such as (super) multiview display or holography, there is a clear and pressing need to develop a new measurement method for determining optimal viewing parameters. Depending on the display system in question, virtual objects with depth information may present different properties to the human visual system and thus are perceived differently. The methods to measure the factors that affect human health in 3D displays need to be thoroughly reviewed in order to further investigate these characteristics and determine optimal viewing parameters. In this paper, we review various measurement methods that have been proposed to examine the effects of 3D stimuli on the human visual system. We provide an overview of recent advances in 3D techniques by relating them with human factors, primarily focusing on subjective and objective measurement methods, to ensure that human-friendly 3D content and displays will benefit from recent technical advances.","Three-dimensional displays,
Visualization,
Stereo image processing,
Visual systems,
Fatigue,
Observers,
Biomedical measurement"
Neural-Dynamic-Method-Based Dual-Arm CMG Scheme With Time-Varying Constraints Applied to Humanoid Robots,"We propose a dual-arm cyclic-motion-generation (DACMG) scheme by a neural-dynamic method, which can remedy the joint-angle-drift phenomenon of a humanoid robot. In particular, according to a neural-dynamic design method, first, a cyclic-motion performance index is exploited and applied. This cyclic-motion performance index is then integrated into a quadratic programming (QP)-type scheme with time-varying constraints, called the time-varying-constrained DACMG (TVC-DACMG) scheme. The scheme includes the kinematic motion equations of two arms and the time-varying joint limits. The scheme can not only generate the cyclic motion of two arms for a humanoid robot but also control the arms to move to the desired position. In addition, the scheme considers the physical limit avoidance. To solve the QP problem, a recurrent neural network is presented and used to obtain the optimal solutions. Computer simulations and physical experiments demonstrate the effectiveness and the accuracy of such a TVC-DACMG scheme and the neural network solver.",
Occlusion-Based Cooperative Transport with a Swarm of Miniature Mobile Robots,"This paper proposes a strategy for transporting a large object to a goal using a large number of mobile robots that are significantly smaller than the object. The robots only push the object at positions where the direct line of sight to the goal is occluded by the object. This strategy is fully decentralized and requires neither explicit communication nor specific manipulation mechanisms. We prove that it can transport any convex object in a planar environment. We implement this strategy on the e-puck robotic platform and present systematic experiments with a group of 20 e-pucks transporting three objects of different shapes. The objects were successfully transported to the goal in 43 out of 45 trials. When using a mobile goal, teleoperated by a human, the object could be navigated through an environment with obstacles. We also tested the strategy in a 3-D environment using physics-based computer simulation. Due to its simplicity, the transport strategy is particularly suited for implementation on microscale robotic systems.",
Influence of Annealing and Bulk Hydrogenation on Lifetime-Limiting Defects in Nitrogen-Doped Floating Zone Silicon,"A recombination active defect is found in as-grown high-purity floating zone n-type silicon wafers containing grown-in nitrogen. In order to identify the properties of the defect, injection-dependent minority carrier lifetime measurements, secondary ion mass spectroscopy measurements, and photoluminescence lifetime imaging are performed. The lateral recombination center distribution varies greatly in a radially symmetric way, while the nitrogen concentration remains constant. The defect is shown to be deactivated through high temperature annealing and hydrogenation. We suggest that a nitrogen-intrinsic point defect complex may be responsible for the observed recombination.",
In-Body to On-Body Ultrawideband Propagation Model Derived From Measurements in Living Animals,"Ultrawideband (UWB) radio technology for wireless implants has gained significant attention. UWB enables the fabrication of faster and smaller transceivers with ultralow power consumption, which may be integrated into more sophisticated implantable biomedical sensors and actuators. Nevertheless, the large path loss suffered by UWB signals propagating through inhomogeneous layers of biological tissues is a major hindering factor. For the optimal design of implantable transceivers, the accurate characterization of the UWB radio propagation in living biological tissues is indispensable. Channel measurements in phantoms and numerical simulations with digital anatomical models provide good initial insight into the expected path loss in complex propagation media like the human body, but they often fail to capture the effects of blood circulation, respiration, and temperature gradients of a living subject. Therefore, we performed UWB channel measurements within 1-6 GHz on two living porcine subjects because of the anatomical resemblance with an average human torso. We present for the first time, a path loss model derived from these in vivo measurements, which includes the frequency-dependent attenuation. The use of multiple on-body receiving antennas to combat the high propagation losses in implant radio channels was also investigated.",
Relevance Feature Discovery for Text Mining,"It is a big challenge to guarantee the quality of discovered relevance features in text documents for describing user preferences because of large scale terms and data patterns. Most existing popular text mining and classification methods have adopted term-based approaches. However, they have all suffered from the problems of polysemy and synonymy. Over the years, there has been often held the hypothesis that pattern-based methods should perform better than term-based ones in describing user preferences; yet, how to effectively use large scale patterns remains a hard problem in text mining. To make a breakthrough in this challenging issue, this paper presents an innovative model for relevance feature discovery. It discovers both positive and negative patterns in text documents as higher level features and deploys them over low-level features (terms). It also classifies terms into categories and updates term weights based on their specificity and their distributions in patterns. Substantial experiments using this model on RCV1, TREC topics and Reuters-21578 show that the proposed model significantly outperforms both the state-of-the-art term-based methods and the pattern based methods.",
A Unifying Model and Analysis of P2P VoD Replication and Scheduling,"We consider a peer-to-peer (P2P)-assisted video-on-demand (VoD) system where each peer can store a relatively small number of movies to offload the server when these movies are requested. User requests are stochastic based on some movie popularity distribution. The problem is how to replicate (or place) content at peer storage to minimize the server load. Several variations of this replication problem have been studied recently with somewhat different conclusions. In this paper, we first point out and explain that the main difference between these studies is in how they model the scheduling of peers to serve user requests, and show that these different scheduling assumptions will lead to different “optimal” replication strategies. We then propose a unifying request scheduling model, parameterized by the maximum number of peers that can be used to serve a single request. This scheduling is called Fair Sharing with Bounded Degree (FSBD). Based on this unifying model, we can compare the different replication strategies for different degree bounds and see how and why different replication strategies are favored depending on the degree. We also propose a simple (primarily) distributed replication algorithm and show that this algorithm is able to adapt itself to work well for different degrees in scheduling.","Motion pictures,
Servers,
Bandwidth,
Peer-to-peer computing,
Load modeling,
Analytical models,
Sociology"
Distributed Cross-Layer Protocol Design for Magnetic Induction Communication in Wireless Underground Sensor Networks,"Wireless underground sensor networks (WUSNs) enable many applications such as underground pipeline monitoring, power grid maintenance, mine disaster prevention, and oil upstream monitoring among many others. While the classical electromagnetic waves do not work well in WUSNs, the magnetic induction (MI) propagation technique provides constant channel conditions via small size of antenna coils in the underground environments. In this paper, instead of adopting currently layered protocols approach, a distributed cross-layer protocol design is proposed for MI-based WUSNs. First, a detailed overview is given for different communication functionalities from physical to network layers as well as the QoS requirements of applications. Utilizing the interactions of different layer functionalities, a distributed environment-aware protocol, called DEAP, is then developed to satisfy statistical QoS guarantees and achieve both optimal energy savings and throughput gain concurrently. Simulations confirm that the proposed cross-layer protocol achieves significant energy savings, high throughput efficiency and dependable MI communication for WUSNs.","Coils,
Modulation,
Wireless communication,
Protocols,
Wireless sensor networks,
Soil,
Transceivers"
An Energy-Efficient HTTP Adaptive Video Streaming With Networking Cost Constraint Over Heterogeneous Wireless Networks,"This paper presents a seamless high-quality HTTP adaptive streaming algorithm that considers wireless network conditions and the energy consumption of a mobile device with networking cost constraints over heterogeneous wireless networks. In the proposed algorithm, the requested video segments are concurrently delivered through multiple wireless networks to overcome the limitations of a single network. The segment quality level, number of requested segments, network inactive interval, and amount of requested data through each wireless network are determined adaptively in order to provide a seamless high-quality video with low energy consumption and networking cost constraints at the mobile device. The proposed algorithm is fully implemented in an Android-based mobile device and tested in an actual wireless network environment.","Streaming media,
Wireless networks,
Throughput,
Energy consumption,
Algorithm design and analysis,
Energy efficiency,
Adaptive systems"
Reduced-Order Small-Signal Model of Microgrid Systems,"The objective of this study was to develop a reduce-dorder small-signal model of a microgrid system capable of operating in both the grid-tied and the islanded conditions. The nonlinear equations of the proposed system were derived in the dq reference frame and then linearized around stable operating points to construct a small-signal model. The high-order state matrix was then reduced using the singular perturbation technique. The dynamic equations were divided into two groups based on the small-signal model parameters ε. The “slow” states, which dominated the system's dynamics, were preserved, whereas the “fast” states were eliminated. Step responses of the model were compared to the experimental results from a hardware test to assess their accuracy and similarity to the full-order system. The proposed reduced-order model was applied to a modified IEEE-37 bus grid-tied microgrid system to evaluate system's dynamic response in grid-tied mode, islanded mode, and transition from grid-tied to islanded mode.","Microgrids,
Mathematical model,
Phase locked loops,
Inverters,
Computational modeling,
Load modeling,
Reduced order systems"
Robust Serial Nanocommunication With QCA,"We present a serial communication system implemented as quantum-dot cellular automata (QCA). QCA is a promising alternative to the current CMOS technology. It can be implemented at the nanoscale, reaching ultra-low power consumption and high clock rate. Communication systems are important in current computer systems and it is expected to be even more important in near future. Although QCA has been widely studied in the development of logic circuits, there are few studies applying this promising technology to the design of communication systems. In a bottom-up approach, we describe the parallel-to-serial and serial-to-parallel converters, which are essential to the serial communication. We also propose and present components for robust communication, such as QCA circuits for Hamming code and parity checker. We demonstrate the functionality, test and validate the proposed architectures using QCADesigner simulator. Due to the importance of communication systems, this study is central in consolidating QCA as a possible CMOS substitute.","Computer architecture,
Clocks,
Microprocessors,
Wires,
Parity check codes,
Communication systems,
Logic gates"
Unlocking Smart Phone through Handwaving Biometrics,"Screen locking/unlocking is important for modern smart phones to avoid the unintentional operations and secure the personal stuff. Once the phone is locked, the user should take a specific action or provide some secret information to unlock the phone. The existing unlocking approaches can be categorized into four groups: motion, password, pattern, and fingerprint. Existing approaches do not support smart phones well due to the deficiency of security, high cost, and poor usability. We collect 200 users' handwaving actions with their smart phones and discover an appealing observation: the waving pattern of a person is kind of unique, stable and distinguishable. In this paper, we propose OpenSesame, which employs the users' waving patterns for locking/unlocking. The key feature of our system lies in using four fine-grained and statistic features of handwaving to verify users. Moreover, we utilize support vector machine (SVM) for accurate and fast classification. Our technique is robust compatible across different brands of smart phones, without the need of any specialized hardware. Results from comprehensive experiments show that the mean false positive rate of OpenSesame is around 15 percent, while the false negative rate is lower than 8 percent.",
Indoor Terahertz Communications: How Many Antenna Arrays Are Needed?,"Terahertz (THz) communications promise to be the next frontier for wireless networks. Novel solutions should be explored to overcome the hardware constraints and the severe path loss. In this paper, we study a low-complexity indoor THz communication system with antenna subarrays. The Saleh-Valenzuela (S-V) channel model is modified to characterize the THz channel. By exploiting the hybrid beamforming with multiple subarrays, we analyze the ergodic capacity of the system and obtain an upper bound. Furthermore, with the analysis of performance degradation for the uncertainty in THz phase shifters, we provide a guidance on the design of antenna subarray size and number for certain long-term data rate requirements with different distances. Simulation results validate the effectiveness of the ergodic capacity upper bound, and show that the proposed THz system and antenna array structure can efficiently achieve capacity gains and support THz communications.","Array signal processing,
Antenna arrays,
Baseband,
Channel models,
Radio frequency,
Wireless communication"
Unified passivity-based Cartesian force/impedance control for rigid and flexible joint robots via task-energy tanks,"In this paper we propose a novel hybrid Cartesian force/impedance controller that is equipped with energy tanks to preserve passivity. Our approach overcomes the problems of (hybrid) force control, impedance control, and set-point based indirect force control. It allows accurate force tracking, full compliant impedance behavior, and safe contact resemblance simultaneously by introducing a controller shaping function that robustly handles unexpected contact loss and avoids chattering behavior that switching based approaches suffer from. Furthermore, we propose a constructive way of initiating the energy tanks via the concept of task energy. This represents an estimate of the energy consumption of a given force control task prior to execution. The controller can be applied to both rigid body and flexible joint dynamics. To show the validity of our approach, several simulations and experiments with the KUKA/DLR LWR-III are carried out.","Force,
Impedance,
Joints,
Stability analysis,
Robot kinematics,
Force control"
BURSE: A Bursty and Self-Similar Workload Generator for Cloud Computing,"As two of the most important characteristics of workloads, burstiness and self-similarity are gaining more and more attention. Workload generation, which is a key technique for performance analysis and simulations, has also attracted an increasing interest in cloud community in recent years. Though a large number of methods for synthetically generating bursty or self-similar workloads have been proposed in the literature, none of them can deal with workload generation with both of the two characteristics. In this paper, a configurable and intelligible synthetic generator (BURSE) is proposed for bursty and self-similar workloads in cloud computing based on a superposition of two-state Markov Modulated Poisson Processes (MMPP2s). The proposed generator can produce workloads with both specified intension of burstiness and self-similarity. Detailed experimental evaluation demonstrates the accuracy, robustness and good applicability of BURSE.","Markov processes,
Generators,
Cloud computing,
Educational institutions,
Computational modeling,
Accuracy,
Robustness"
Multiagent Reinforcement Learning With Unshared Value Functions,"One important approach of multiagent reinforcement learning (MARL) is equilibrium-based MARL, which is a combination of reinforcement learning and game theory. Most existing algorithms involve computationally expensive calculation of mixed strategy equilibria and require agents to replicate the other agents' value functions for equilibrium computing in each state. This is unrealistic since agents may not be willing to share such information due to privacy or safety concerns. This paper aims to develop novel and efficient MARL algorithms without the need for agents to share value functions. First, we adopt pure strategy equilibrium solution concepts instead of mixed strategy equilibria given that a mixed strategy equilibrium is often computationally expensive. In this paper, three types of pure strategy profiles are utilized as equilibrium solution concepts: pure strategy Nash equilibrium, equilibrium-dominating strategy profile, and nonstrict equilibrium-dominating strategy profile. The latter two solution concepts are strategy profiles from which agents can gain higher payoffs than one or more pure strategy Nash equilibria. Theoretical analysis shows that these strategy profiles are symmetric meta equilibria. Second, we propose a multistep negotiation process for finding pure strategy equilibria since value functions are not shared among agents. By putting these together, we propose a novel MARL algorithm called negotiation-based Q-learning (NegoQ). Experiments are first conducted in grid-world games, which are widely used to evaluate MARL algorithms. In these games, NegoQ learns equilibrium policies and runs significantly faster than existing MARL algorithms (correlated Q-learning and Nash Q-learning). Surprisingly, we find that NegoQ also performs well in team Markov games such as pursuit games, as compared with team-task-oriented MARL algorithms (such as friend Q-learning and distributed Q-learning).",
Distributed Optimization of Dispatch in Sustainable Generation Systems via Dual Decomposition,"Distributed generators (DGs) are being widely deployed in today's power grid. These energy sources are highly variable posing practical challenges for deployment and grid management. In this paper, a novel scalable distributed power dispatch strategy is proposed to effectively manage DGs at the distribution substation level, capitalizing on the recent push to cyber-enable power grid operations. We demonstrate how the inherent separability of the power dispatch problem allows the use of dual decomposition that enables every participating DG to locally compute its dispatch strategy based on simple broadcast data by the utility. Results and comparisons indicate that the DGs are able to rapidly converge to an optimal economical dispatch vector with significantly less concentrated computational effort and communication overhead, promoting security and privacy.","Generators,
Convergence,
Aggregates,
Vectors,
Load modeling,
Cost function"
The Extra Connectivity and Conditional Diagnosability of Alternating Group Networks,"Extra connectivity, diagnosability, and conditional diagnosability are all important measures for a multiprocessor system's ability to diagnose and tolerate faults. In this paper, we analyze the fault tolerance ability for the alternating group graph, a well-known interconnection network proposed for multiprocessor systems, establish the h-extra connectivity, where 1 ≤ h ≤ 3, and prove that the conditional diagnosability of an n-dimensional alternating group graph, denoted by AGn, is 8n - 27 (n ≥ 4) under the PMC model. This is about four times of the AGn's traditional diagnosability. As a byproduct, the strong diagnosability of AGn is also obtained.",
Photo-real talking head with deep bidirectional LSTM,"Long short-term memory (LSTM) is a specific recurrent neural network (RNN) architecture that is designed to model temporal sequences and their long-range dependencies more accurately than conventional RNNs. In this paper, we propose to use deep bidirectional LSTM (BLSTM) for audio/visual modeling in our photo-real talking head system. An audio/visual database of a subject's talking is firstly recorded as our training data. The audio/visual stereo data are converted into two parallel temporal sequences, i.e., contextual label sequences obtained by forced aligning audio against text, and visual feature sequences by applying active-appearance-model (AAM) on the lower face region among all the training image samples. The deep BLSTM is then trained to learn the regression model by minimizing the sum of square error (SSE) of predicting visual sequence from label sequence. After testing different network topologies, we interestingly found the best network is two BLSTM layers sitting on top of one feed-forward layer on our datasets. Compared with our previous HMM-based system, the newly proposed deep BLSTM-based one is better on both objective measurement and subjective A/B test.","Hidden Markov models,
Visualization,
Face,
Active appearance model,
Shape,
Speech"
Mitigation of Turn-to-Turn Faults in Fault Tolerant Permanent Magnet Synchronous Motors,"This study presents a method to mitigate and alleviate the effects produced by a turn-to-turn short in a fault tolerant permanent magnet synchronous motor with single-layer concentrated windings. The rotor magnets are capable of inducing a high voltage across the fault contact point; this voltage has the potential to generate a high circulating current that promotes the rapid propagation of the fault due to the thermal stress created by the increased localized fault power losses. The scope of this study is for applications where postfault operation is desired, even if it means operating at reduced power capacity and lower speeds. Upon quick detection of a fault, the proposed technique can be used to decelerate the propagation of the fault and extend the machine's postfault life span. The technique consists of a magnetic field-weakening strategy at speeds below nominal, to reduce the voltage induced in the faulted portion. The concept is validated through finite element analysis, modeling, and experimental data. It is demonstrated that the proposed technique reduces the fault current magnitude and winding temperature.","Fault currents,
Circuit faults,
Radio frequency,
Fault tolerant systems,
Windings,
Fault tolerance,
Coils"
Multiact Dynamic Game Strategy for Jamming Attack in Electricity Market,"As the current power grid system is upgrading to the smart grid, it becomes more vulnerable to security attacks on its communication subsystem such as the denial-of-service attack. Jamming, as a kind of denial-of service attack, can be applied to interfere the real-time communication in smart grid. In this paper, we analyze the scenario in which the attacker can jam a reduced number of signal channels carrying measurement information in order to manipulate the locational marginal price and create the opportunity for gaining profit, and the defender is able to guarantee a limited number of channels in information delivery. Based on the electricity marketing model, we propose a multiact dynamic game between the attacker and defender, in which the optimal strategies are taken by the two sides to maximize their own profits. We study the gaming process and discuss the prosperities of the outcome. Simulation results present the affect of jamming attack on the electricity prices and the gained profits of the two sides. Moreover, they confirm the optimality of the proposed scheme in pursuing profit.",
Spectrum and Energy Efficiencies for Multiuser Pairs Massive MIMO Systems With Full-Duplex Amplify-and-Forward Relay,"To achieve insights about the impact of amplified loop interference, we consider a dual-hop fullduplex (FD) massive multiple-input multiple-output (MIMO) amplify-and-forward (AF) relaying system in terms of achievable ergodic rates for each user pair as well as spectrum and energy efficiencies. It is assumed that the base station (or relay) is equipped with MRx receive antennas and MTxtransmit antennas, while all sources and destinations have a single antenna. For such FD massive MIMO AF relaying systems, the closedform expressions of the lower bounds of achievable ergodic rates are derived first with a finite number of receive and transmit antennas at base station. Then, the asymptotic performance analysis is performed by considering three different power-scaling schemes: 1) PS = ES/MRx and PR = ER; 2) PS = ES and PR = ER/MTx; and 3) PS = ES/MRx and PR = ER/MTx, where ES and ER are fixed, and PS and PR denote the transmit powers of each source and relay, respectively. Our results show that only when the power-scaling 2) is utilized, do the FD massive MIMO AF relay systems have the ability to restrict the loop interference, so that the system performance is free of loop interference when the number of antennas at the relay is large enough. On the contrary, with the power-scaling cases 1) and 3), the systems have no ability to cancel the loop interference even if MRx or MTx (or both) goes to infinity. The insight is different from the results in the FD massive MIMO decode-and-forward relaying systems where the loop interference can be entirely eliminated for the three power-scaling cases.","MIMO,
Energy efficiency,
Ergodic rates,
Cooperative communication"
A Short-Term Wind Power Forecasting Approach With Adjustment of Numerical Weather Prediction Input by Data Mining,"This paper proposes a novel short-term wind power forecasting approach by mining the bad data of numerical weather prediction (NWP). Today's short-term wind power forecast (WPF) highly depends on the NWP, which contributes the most in the WPF error. This paper first introduces a bad data analyzer to fully study the relationship between the WPF error with several new extracted features from the raw NWP. Second, a hierarchical structure is proposed, which is composed of a K-means clustering-based bad data detection module and a neural network (NN)-based forecasting module. In the NN module, the WPF is fully adjusted based on the output of the bad data analyzer. Simulations are performed comparing with two other different methods. It proves that the proposed approach can improve the short-term wind power forecasting by effectively identifying and adjusting the errors from NWP.",
Fast X-Ray CT Image Reconstruction Using a Linearized Augmented Lagrangian Method With Ordered Subsets,"Augmented Lagrangian (AL) methods for solving convex optimization problems with linear constraints are attractive for imaging applications with composite cost functions due to the empirical fast convergence rate under weak conditions. However, for problems such as X-ray computed tomography (CT) image reconstruction, where the inner least-squares problem is challenging and requires iterations, AL methods can be slow. This paper focuses on solving regularized (weighted) least-squares problems using a linearized variant of AL methods that replaces the quadratic AL penalty term in the scaled augmented Lagrangian with its separable quadratic surrogate function, leading to a simpler ordered-subsets (OS) accelerable splitting-based algorithm, OS-LALM. To further accelerate the proposed algorithm, we use a second-order recursive system analysis to design a deterministic downward continuation approach that avoids tedious parameter tuning and provides fast convergence. Experimental results show that the proposed algorithm significantly accelerates the convergence of X-ray CT image reconstruction with negligible overhead and can reduce OS artifacts when using many subsets.",
Arbitrary-Angle Squint-Free Beamforming in Series-Fed Antenna Arrays Using Non-Foster Elements Synthesized by Negative-Group-Delay Networks,"Beamforming in series-fed antenna arrays can inherently suffer from beam-squinting. To overcome the beam-squinting problem, low-dispersion, fast-wave transmission lines can be employed. Such transmission lines can be designed by loading a regular transmission line with non-Foster reactive elements (e.g., negative capacitors and inductors). As a result of a recent development, these non-Foster reactive elements can be implemented using loss-compensated negative-group-delay (NGD) networks, providing a solution to the stability issues associated with conventional non-Foster networks. In this work, transmission lines augmented by loss-compensated NGD networks, representing the non-Foster reactive-element loading, are employed for designing wideband fast-wave, low-dispersion transmission lines. This work consolidates this non-Foster reactive element loading method with earlier efforts where NGD networks were used to implement zero-degree phase shifters for beamforming at the broadside direction, and generalizes these methods for arbitrary-angle beamforming from backfire to endfire including the broadside direction. Experimental results are presented for a wideband linear four-element transmitting array feed network for beamforming at 30° with respect to the broadside direction in the frequency range 1-1.5 GHz. By connecting this feed network to four wideband tapered-slot antennas, the beamforming performance is experimentally verified inside an anechoic chamber. Moreover, the antenna array is experimentally tested for transmission of a narrow pulse, where low distortion is observed at the beamforming angle over the entire operating bandwidth. The physical length of the feed network is realistic and is 0.96 wavelengths long at the center of this frequency range. In addition, switched-line phase shifters are employed for squint-free beamforming in three other angles: 60°, 0°, and -30^{\circ}.",
Control of Island AC Microgrids Using a Fully Distributed Approach,"A fully distributed control scheme of island ac microgrids that can perform the primary, secondary, and tertiary control locally in distributed generators (DGs) is proposed. In the control scheme, no central controller or external information exchange is needed, while the final frequency can be controlled within the allowable range and the DGs can share loads according to their increment costs. The low-pass filters are designed to decouple the dynamics of the microgrid and to improve the system performance. Simulation studies verify the effectiveness of the control scheme.","Microgrids,
Frequency control,
Steady-state,
Australia,
Frequency measurement,
Decentralized control,
Educational institutions"
Synchronization of Neural Networks With Control Packet Loss and Time-Varying Delay via Stochastic Sampled-Data Controller,"This paper addresses the problem of exponential synchronization of neural networks with time-varying delays. A sampled-data controller with stochastically varying sampling intervals is considered. The novelty of this paper lies in the fact that the control packet loss from the controller to the actuator is considered, which may occur in many real-world situations. Sufficient conditions for the exponential synchronization in the mean square sense are derived in terms of linear matrix inequalities (LMIs) by constructing a proper Lyapunov-Krasovskii functional that involves more information about the delay bounds and by employing some inequality techniques. Moreover, the obtained LMIs can be easily checked for their feasibility through any of the available MATLAB tool boxes. Numerical examples are provided to validate the theoretical results.","Synchronization,
Neural networks,
Packet loss,
Control systems,
Delays,
Symmetric matrices"
Cost-Aware SEcure Routing (CASER) Protocol Design for Wireless Sensor Networks,"Lifetime optimization and security are two conflicting design issues for multi-hop wireless sensor networks (WSNs) with non-replenishable energy resources. In this paper, we first propose a novel secure and efficient Cost-Aware SEcure Routing (CASER) protocol to address these two conflicting issues through two adjustable parameters: energy balance control (EBC) and probabilistic-based random walking. We then discover that the energy consumption is severely disproportional to the uniform energy deployment for the given network topology, which greatly reduces the lifetime of the sensor networks. To solve this problem, we propose an efficient non-uniform energy deployment strategy to optimize the lifetime and message delivery ratio under the same energy resource and security requirement. We also provide a quantitative security analysis on the proposed routing protocol. Our theoretical analysis and OPNET simulation results demonstrate that the proposed CASER protocol can provide an excellent tradeoff between routing efficiency and energy balance, and can significantly extend the lifetime of the sensor networks in all scenarios. For the non-uniform energy deployment, our analysis shows that we can increase the lifetime and the total number of messages that can be delivered by more than four times under the same assumption. We also demonstrate that the proposed CASER protocol can achieve a high message delivery ratio while preventing routing traceback attacks.",
Energy Efficient Clustering Protocol for Large-Scale Sensor Networks,"Due to the energy limit of sensor nodes, prolonging lifetime of wireless sensor networks (WSNs) is a big challenge. This challenge becomes even more critical in large-scale sensor networks, in which more energy is consumed because of more data collections and packet transmissions. It is believed that clustering-based protocols are the best choice for such kind of WSNs. In this paper, we propose a clustering protocol called fan-shaped clustering (FSC) to partition a large-scale network into fan-shaped clusters. Based on this clustering scheme, different energy saving methods are proposed, such as efficient cluster head and relay selection, locality of re-clustering, simple but robust routing and hotspot solution. Performance analysis demonstrates that the proposed FSC can efficiently save energy, which is much better than hybrid, energy-efficient, and distributed clustering in terms of both energy saving and packet collection rate.",
Improving FCM and T2FCM algorithms performance using GPUs for medical images segmentation,"Image segmentation gained popularity recently due to numerous applications in many fields such as computer vision, medical imaging. From its name, segmentation is interested in partitioning the image into separate regions where one of them is of special interest. Such region is called the Region of Interest (RoI) and it is very important for many medical imaging problems. Clustering is one of the segmentation approaches typically used on medical images despite its long running time. In this work, we propose to leverage the power of the Graphics Processing Unit (GPU)to improve the performance of such approaches. Specifically, we focus on the Fuzzy C-Means (FCM) algorithm and its more recent variation, the Type-2 Fuzzy C-Means (T2FCM) algorithm. We propose a hybrid CPU-GPU implementation to speed up the execution time without affecting the algorithm's accuracy. The experiments show that such an approach reduces the execution time by up to 80% for FCM and 74% for T2FCM.","Graphics processing units,
Mathematical model,
Image segmentation,
Biomedical imaging,
Magnetic resonance imaging,
Linear programming,
Instruction sets"
Bayesian Nonparametric Models for Multiway Data Analysis,"Tensor decomposition is a powerful computational tool for multiway data analysis. Many popular tensor decomposition approaches—such as the Tucker decomposition and CANDECOMP/PARAFAC (CP)—amount to multi-linear factorization. They are insufficient to model (i) complex interactions between data entities, (ii) various data types (e.g., missing data and binary data), and (iii) noisy observations and outliers. To address these issues, we propose tensor-variate latent nonparametric Bayesian models for multiway data analysis. We name these models InfTucker. These new models essentially conduct Tucker decomposition in an infinite feature space. Unlike classical tensor decomposition models, our new approaches handle both continuous and binary data in a probabilistic framework. Unlike previous Bayesian models on matrices and tensors, our models are based on latent Gaussian or
t
processes with nonlinear covariance functions. Moreover, on network data, our models reduce to nonparametric stochastic blockmodels and can be used to discover latent groups and predict missing interactions. To learn the models efficiently from data, we develop a variational inference technique and explore properties of the Kronecker product for computational efficiency. Compared with a classical variational implementation, this technique reduces both time and space complexities by several orders of magnitude. On real multiway and network data, our new models achieved significantly higher prediction accuracy than state-of-art tensor decomposition methods and blockmodels.",
Pseudo-Multiple-Exposure-Based Tone Fusion With Local Region Adjustment,"New generations of display technologies provide a significantly improved dynamic range compared to conventional display devices. Inverse tone mapping methods have been proposed to convert low dynamic range (LDR) images to HDR ones, and several of them require multiple exposure LDR images of the same scene as inputs. However, the vast majority of LDR images and videos available have only one single exposure. In this paper, we propose a region-based enhancement of the pseudo-exposures to generate an HDR image. First, we present an exposure dependent curve to convert one LDR image to the pseudo-multiple-exposures. Only certain regions of the pseudo-exposures contain noticeable detail information. We propose a region-based enhancement on the pseudo-exposures to boost details in the most distinct region. Thereby the region-enhanced pseudo-exposures are fused into an HDR image. The fused image thus enhances details in the bright region of the dark image and the dark region of the bright image. Compared with other inverse tone mapped methods, our method generates lower total contrast error measured under the dynamic range independent image quality assessment method in [1].","Dynamic range,
Brightness,
Educational institutions,
Videos,
Piecewise linear approximation,
Detectors"
Obstacle Avoidance Method for Wheeled Mobile Robots Using Interval Type-2 Fuzzy Neural Network,"This paper proposes an obstacle avoidance method in the position stabilization of the wheeled mobile robots using interval type-2 fuzzy neural network (IT2FNN). Previously, we have proposed the unified strategies of obstacle avoidance and shooting method of the robot soccer system using type-1 fuzzy neural network (T1FNN). Even though the previous T1FNN method can achieve the required tasks, the performance of the previous T1FNN method is not satisfactory in the following sense. The previous T1FNN cannot reduce the influence of uncertainties effectively because it uses the crisp set as the membership values. In addition, it can result in the large oscillation behavior during the obstacle avoidance. Accordingly, we should design the IT2FNN method to improve the performance with smoother behavior as well as improved obstacle avoidance. The proposed IT2FNN method has the fuzzy neural network structure different from the T1FNN. Since the IT2FNN uses the fuzzy set instead of the crisp set as the membership values and it is robust against uncertainties, the performance of the robot behavior can be significantly improved especially in the presence of obstacles. Both simulation and experimental results using the actual wheeled mobile robot with the vision information are provided to show the validity and the advantages of the proposed method.",
Shape driven kernel adaptation in Convolutional Neural Network for robust facial trait recognition,"One key challenge of facial trait recognition is the large non-rigid appearance variations due to some irrelevant real world factors, such as viewpoint and expression changes. In this paper, we explore how the shape information, i.e. facial landmark positions, can be explicitly deployed into the popular Convolutional Neural Network (CNN) architecture to disentangle such irrelevant non-rigid appearance variations. First, instead of using fixed kernels, we propose a kernel adaptation method to dynamically determine the convolutional kernels according to the spatial distribution of facial landmarks, which helps learning more robust features. Second, motivated by the intuition that different local facial regions may demand different adaptation functions, we further propose a tree-structured convolutional architecture to hierarchically fuse multiple local adaptive CNN subnetworks. Comprehensive experiments on WebFace, Morph II and MultiPIE databases well validate the effectiveness of the proposed kernel adaptation method and tree-structured convolutional architecture for facial trait recognition tasks, including identity, age and gender recognition. For all the tasks, the proposed architecture consistently achieves the state-of-the-art performances.","Kernel,
Shape,
Face,
Face recognition,
Robustness,
Neural networks,
Computer architecture"
A learning-based approach to direction of arrival estimation in noisy and reverberant environments,"This paper presents a learning-based approach to the task of direction of arrival estimation (DOA) from microphone array input. Traditional signal processing methods such as the classic least square (LS) method rely on strong assumptions on signal models and accurate estimations of time delay of arrival (TDOA) . They only work well in relatively clean conditions, but suffer from noise and reverberation distortions. In this paper, we propose a learning-based approach that can learn from a large amount of simulated noisy and reverberant microphone array inputs for robust DOA estimation. Specifically, we extract features from the generalised cross correlation (GCC) vectors and use a multilayer perceptron neural network to learn the nonlinear mapping from such features to the DOA. One advantage of the learning based method is that as more and more training data becomes available, the DOA estimation will become more and more accurate. Experimental results on simulated data show that the proposed learning based method produces much better results than the state-of-the-art LS method. The testing results on real data recorded in meeting rooms show improved root-mean-square error (RMSE) compared to the LS method.","Direction-of-arrival estimation,
Estimation,
Training data,
Arrays,
Speech,
Robustness,
Training"
Nonparametric Hemodynamic Deconvolution of fMRI Using Homomorphic Filtering,"Functional magnetic resonance imaging (fMRI) is an indirect measure of neural activity which is modeled as a convolution of the latent neuronal response and the hemodynamic response function (HRF). Since the sources of HRF variability can be nonneural in nature, the measured fMRI signal does not faithfully represent underlying neural activity. Therefore, it is advantageous to deconvolve the HRF from the fMRI signal. However, since both latent neural activity and the voxel-specific HRF is unknown, the deconvolution must be blind. Existing blind deconvolution approaches employ highly parameterized models, and it is unclear whether these models have an over fitting problem. In order to address these issues, we 1) present a nonparametric deconvolution method based on homomorphic filtering to obtain the latent neuronal response from the fMRI signal and, 2) compare our approach to the best performing existing parametric model based on the estimation of the biophysical hemodynamic model using the Cubature Kalman Filter/Smoother. We hypothesized that if the results from nonparametric deconvolution closely resembled that obtained from parametric deconvolution, then the problem of over fitting during estimation in highly parameterized deconvolution models of fMRI could possibly be over stated. Both simulations and experimental results demonstrate support for our hypothesis since the estimated latent neural response from both parametric and nonparametric methods were highly correlated in the visual cortex. Further, simulations showed that both methods were effective in recovering the simulated ground truth of the latent neural response.",
Predict Gram-Positive and Gram-Negative Subcellular Localization via Incorporating Evolutionary Information and Physicochemical Features Into Chou's General PseAAC,"In this study, we used structural and evolutionary based features to represent the sequences of gram-positive and gram-negative subcellular localizations. To do this, we proposed a normalization method to construct a normalize Position Specific Scoring Matrix (PSSM) using the information from original PSSM. To investigate the effectiveness of the proposed method we compute feature vectors from normalize PSSM and by applying support vector machine (SVM) and naïve Bayes classifier, respectively, we compared achieved results with the previously reported results. We also computed features from original PSSM and normalized PSSM and compared their results. The archived results show enhancement in gram-positive and gram-negative subcellular localizations. Evaluating localization for each feature, our results indicate that employing SVM and concatenating features (amino acid composition feature, Dubchak feature (physicochemical-based features), normalized PSSM based auto-covariance feature and normalized PSSM based bigram feature) have higher accuracy while employing naïve Bayes classifier with normalized PSSM based auto-covariance feature proves to have high sensitivity for both benchmarks. Our reported results in terms of overall locative accuracy is 84.8% and overall absolute accuracy is 85.16% for gram-positive dataset; and, for gram-negative dataset, overall locative accuracy is 85.4% and overall absolute accuracy is 86.3%.","Proteins,
Feature extraction,
Accuracy,
Amino acids,
Benchmark testing,
Microorganisms,
Support vector machines"
Incentive-Driven and Freshness-Aware Content Dissemination in Selfish Opportunistic Mobile Networks,"Recently, the content-based publish/subscribe (pub/sub) paradigm has been gaining popularity in opportunistic mobile networks (OppNets) for its flexibility and adaptability. Since nodes in OppNets are controlled by humans, they often behave selfishly. Therefore, stimulating nodes in selfish OppNets to collect, store, and share contents efficiently is one of the key challenges. Meanwhile, guaranteeing the freshness of contents is also a big problem for content dissemination in OppNets. In this paper, in order to solve these problems, we propose an incentive-driven and freshness-aware pub/sub Content Dissemination scheme, called ConDis, for selfish OppNets. In ConDis, the Tit-For-Tat (TFT) scheme is employed to deal with selfish behaviors of nodes in OppNets. Moreover, a novel content exchange protocol is proposed when nodes are in contact. Specifically, during each contact, the exchange order is determined by the content utility, which represents the usefulness of a content for a certain node, and the objective of nodes is to maximize the utility of the content inventory stored in their buffer. Extensive realistic trace-driven simulation results show that ConDis is superior to other existing schemes in terms of total freshness value, total delivered contents, and total transmission cost.","Peer-to-peer computing,
Buffer storage,
Incentive schemes,
Thin film transistors,
Educational institutions,
Mobile computing,
Protocols"
Scene Parsing From an MAP Perspective,"Scene parsing is an important problem in the field of computer vision. Though many existing scene parsing approaches have obtained encouraging results, they fail to overcome within-category inconsistency and intercategory similarity of superpixels. To reduce the aforementioned problem, a novel method is proposed in this paper. The proposed approach consists of three main steps: 1) posterior category probability density function (PDF) is learned by an efficient low-rank representation classifier (LRRC); 2) prior contextual constraint PDF on the map of pixel categories is learned by Markov random fields; and 3) final parsing results are yielded up to the maximum a posterior process based on the two learned PDFs. In this case, the nature of being both dense for within-category affinities and almost zeros for intercategory affinities is integrated into our approach by using LRRC to model the posterior category PDF. Meanwhile, the contextual priori generated by modeling the prior contextual constraint PDF helps to promote the performance of scene parsing. Experiments on benchmark datasets show that the proposed approach outperforms the state-of-the-art approaches for scene parsing.",
Stochastic Stability of Delayed Neural Networks With Local Impulsive Effects,"In this paper, the stability problem is studied for a class of stochastic neural networks (NNs) with local impulsive effects. The impulsive effects considered can be not only nonidentical in different dimensions of the system state but also various at distinct impulsive instants. Hence, the impulses here can encompass several typical impulses in NNs. The aim of this paper is to derive stability criteria such that stochastic NNs with local impulsive effects are exponentially stable in mean square. By means of the mathematical induction method, several easy-to-check conditions are obtained to ensure the mean square stability of NNs. Three examples are given to show the effectiveness of the proposed stability criterion.","Artificial neural networks,
Stochastic processes,
Stability criteria,
Mathematical model,
Educational institutions,
Control systems"
NMF-based Target Source Separation Using Deep Neural Network,"Non-negative matrix factorization (NMF) is one of the most well-known techniques that are applied to separate a desired source from mixture data. In the NMF framework, a collection of data is factorized into a basis matrix and an encoding matrix. The basis matrix for mixture data is usually constructed by augmenting the basis matrices for independent sources. However, target source separation with the concatenated basis matrix turns out to be problematic if there exists some overlap between the subspaces that the bases for the individual sources span. In this letter, we propose a novel approach to improve encoding vector estimation for target signal extraction. Estimating encoding vectors from the mixture data is viewed as a regression problem and a deep neural network (DNN) is used to learn the mapping between the mixture data and the corresponding encoding vectors. To demonstrate the performance of the proposed algorithm, experiments were conducted in the speech enhancement task. The experimental results show that the proposed algorithm outperforms the conventional encoding vector estimation scheme.","Vectors,
Speech,
Encoding,
Noise,
Speech enhancement,
Source separation,
Signal processing algorithms"
From Shading to Local Shape,"We develop a framework for extracting a concise representation of the shape information available from diffuse shading in a small image patch. This produces a mid-level scene descriptor, comprised of local shape distributions that are inferred separately at every image patch across multiple scales. The framework is based on a quadratic representation of local shape that, in the absence of noise, has guarantees on recovering accurate local shape and lighting. And when noise is present, the inferred local shape distributions provide useful shape information without over-committing to any particular image explanation. These local shape distributions naturally encode the fact that some smooth diffuse regions are more informative than others, and they enable efficient and robust reconstruction of object-scale shape. Experimental results show that this approach to surface reconstruction compares well against the state-of-art on both synthetic images and captured photographs.","Shape,
Lighting,
Eigenvalues and eigenfunctions,
Transmission line matrix methods,
Image reconstruction,
Surface reconstruction,
Noise"
Crowdsourcing with Tullock contests: A new perspective,"Incentive mechanisms for crowdsourcing have been extensively studied under the framework of all-pay auctions. Along a distinct line, this paper proposes to use Tullock contests as an alternative tool to design incentive mechanisms for crowdsourcing. We are inspired by the conduciveness of Tullock contests to attracting user entry (yet not necessarily a higher revenue) in other domains. In this paper, we explore a new dimension in optimal Tullock contest design, by superseding the contest prize - which is fixed in conventional Tullock contests - with a prize function that is dependent on the (unknown) winner's contribution, in order to maximize the crowdsourcer's utility. We show that this approach leads to attractive practical advantages: (a) it is well-suited for rapid prototyping in fully distributed web agents and smartphone apps; (b) it overcomes the disincentive to participate caused by players' antagonism to an increasing number of rivals. Furthermore, we optimize conventional, fixed-prize Tullock contests to construct the most superior benchmark to compare against our mechanism. Through extensive evaluations, we show that our mechanism significantly outperforms the optimal benchmark, by over three folds on the crowdsourcer's utility cum profit and up to nine folds on the players' social welfare.","Crowdsourcing,
Benchmark testing,
Bayes methods,
Computers,
Cost accounting,
Conferences,
Games"
Nonlinear Discontinuous Dynamics Averaging and PWM-Based Sliding Control of Solenoid-Valve Pneumatic Actuators,"A pneumatic actuator with solenoid valves is a discontinuous-input system because each valve can be either in on or off state. For such an actuator, this paper proposes a sliding-mode control scheme that is based on an averaged continuous-input model of the discontinuous-input open-loop system. The averaged model is obtained from the nonlinear dynamics of the open-loop system undergoing pulse width modulation (PWM) at the input (i.e., valve open/close action). The PWM duty cycle will be regarded as a continuous input to the proposed averaged model, and thus generated by the proposed sliding-mode controller. For the sliding control design, we note that a pneumatic actuator has two chambers with a total of four on/off valves. Thus, there are sixteen possible combinations for the valves' switching. Seven of these sixteen operating “modes” are considered both functional and unique. The proposed sliding control utilizes and switches between these seven modes of the open-loop system in order to select the ones with necessary and sufficient amounts of drive energy. In comparing the new seven-mode controller to previous controllers, we will demonstrate reductions in the position tracking error and the number of switches made by the actuator's on/off valves. The proposed control scheme is used in both position control of a pneumatic cylinder and bilateral control of a one degree of freedom teleoperation system. Experimental results are presented to validate our theoretical findings.","Valves,
Pulse width modulation,
Switches,
Pneumatic actuators,
Solenoids,
Nonlinear dynamical systems"
Describing Trajectory of Surface Patch for Human Action Recognition on RGB and Depth Videos,"This letter proposes a new feature describing the trajectories of surface patches (ToSP) on human bodies for action recognition by a novel scheme of utilizing RGB and depth videos. RGB data contains appearance information by which we track specific patches on body surfaces while depth data contains spatial information by which we describe surface patches. Specifically, we use spatial-temporal interest points as initial points to track in two directions. A ToSP is extracted by keeping the neighborhood in point cloud of each point on the trajectory. By using the temporal pyramid, ToSPs are matched on several levels based on the surface feature extracted from ToSP segments. The proposed feature captures both the shape and position variations of surface patches, thus it has the advantages of trajectories and local spatial-temporal features. The experiment results show that the proposed feature outperforms the existing trajectories based features and depth features.",
Randomized Spatial Context for Object Search,"Searching visual objects in large image or video data sets is a challenging problem, because it requires efficient matching and accurate localization of query objects that often occupy a small part of an image. Although spatial context has been shown to help produce more reliable detection than methods that match local features individually, how to extract appropriate spatial context remains an open problem. Instead of using fixed-scale spatial context, we propose a randomized approach to deriving spatial context, in the form of spatial random partition. The effect of spatial context is achieved by averaging the matching scores over multiple random patches. Our approach offers three benefits: 1) the aggregation of the matching scores over multiple random patches provides robust local matching; 2) the matched objects can be directly identified on the pixelwise confidence map, which results in efficient object localization; and 3) our algorithm lends itself to easy parallelization and also allows a flexible tradeoff between accuracy and speed through adjusting the number of partition times. Both theoretical studies and experimental comparisons with the state-of-the-art methods validate the advantages of our approach.","Context,
Visualization,
Search problems,
Partitioning algorithms,
Feature extraction,
Image segmentation,
Robustness"
An Energy Tank-Based Interactive Control Architecture for Autonomous and Teleoperated Robotic Surgery,"Introducing some form of autonomy in robotic surgery is being considered by the medical community to better exploit the potential of robots in the operating room. However, significant technological steps have to occur before even the smallest autonomous task is ready to be presented to the regulatory authorities. In this paper, we address the initial steps of this process, in particular the development of control concepts satisfying the basic safety requirements of robotic surgery, i.e., providing the robot with the necessary dexterity and a stable and smooth behavior of the surgical tool. Two specific situations are considered: the automatic adaptation to changing tissue stiffness and the transition from autonomous to teleoperated mode. These situations replicate real-life cases when the surgeon adapts the stiffness of her/his arm to penetrate tissues of different consistency and when, due to an unexpected event, the surgeon has to take over the control of the surgical robot. To address the first case, we propose a passivity-based interactive control architecture that allows us to implement stable time-varying interactive behaviors. For the second case, we present a two-layered bilateral control architecture that ensures a stable behavior during the transition between autonomy and teleoperation and, after the switch, limits the effect of initial mismatch between master and slave poses. The proposed solutions are validated in the realistic surgical scenario developed within the EU-funded I-SUR project, using a surgical robot prototype specifically designed for the autonomous execution of surgical tasks like the insertion of needles into the human body.",
Distributed Parameter Estimation for Mobile Wireless Sensor Network Based on Cloud Computing in Battlefield Surveillance System,"The construction of a battlefield surveillance system is very important for monitoring the attack of enemy aircrafts and missiles, which integrates various sensors and mobile devices. Then, multiple battlefield surveillance systems can be connected together to form a battlefield surveillance network. The mobile nodes can be deployed in a certain region to monitor enemy aircrafts and missiles. Thus, some important issues have to be solved efficiently, including the cooperation across the administrative domains of a cloud network, the direction-of-arrival (DOA), and a polarization estimation algorithm for a mobile wireless sensor network (MWSN). In this paper, the architecture of a battlefield surveillance system is constructed based on mobile cloud computing and 5G link. The root multiple signal classification (Root-MUSIC)-like algorithm is proposed for estimating the 1-D DOA and a polarization parameter with a uniform linear array. The Root-MUSIC algorithm is replaced by the Fourier transform, the former algorithm that can be extended to an arbitrary topology structure of a MWSN. Then, the proposed algorithm is extended to the 2-D DOA and a polarization estimation in further. Based on the deployment of different MWSNs, the estimation results of DOA and polarization parameters are fused in order to improve the estimation performance. Finally, the parameter information (DOA and polarization parameter) of enemy aircrafts and missiles can be achieved. The computer simulation verifies the effectiveness of the proposed algorithm. The proposed algorithm ensures the parameter estimation accuracy with a low computational complexity.","Wireless sensor networks,
Mobile communication,
Cloud computing,
Polarization,
Direction-of-arrival estimation,
Surveillance,
Military communication,
Warfare"
Spatial Coordinated Medium Sharing: Optimal Access Control Management in Drive-Thru Internet,"Driven by the ever-growing expectation of ubiquitous connectivity and the widespread adoption of IEEE 802.11 networks, it is not only highly demanded but also entirely possible for in-motion vehicles to establish convenient Internet access to roadside WiFi access points (APs) than ever before, which is referred to as Drive-Thru Internet. The performance of Drive-Thru Internet, however, would suffer from the high vehicle mobility, severe channel contentions, and instinct issues of the IEEE 802.11 MAC as it was originally designed for static scenarios. As an effort to address these problems, in this paper, we develop a unified analytical framework to evaluate the performance of Drive-Thru Internet, which can accommodate various vehicular traffic flow states, and to be compatible with IEEE 802.11a/b/g networks with a distributed coordination function (DCF). We first develop the mathematical analysis to evaluate the mean saturated throughput of vehicles and the transmitted data volume of a vehicle per drive-thru. We show that the throughput performance of Drive-Thru Internet can be enhanced by selecting an optimal transmission region within an AP's coverage for the coordinated medium sharing of all vehicles. We then develop a spatial access control management approach accordingly, which ensures the airtime fairness for medium sharing and boosts the throughput performance of Drive-Thru Internet in a practical, efficient, and distributed manner. Simulation results show that our optimal access control management approach can efficiently work in IEEE 802.11b and 802.11g networks. The maximal transmitted data volume per drive-thru can be enhanced by 113.1% and 59.5% for IEEE 802.11b and IEEE 802.11g networks with a DCF, respectively, compared with the normal IEEE 802.11 medium access with a DCF.",
Arbitrary Category Classification of Websites Based on Image Content,"This paper presents a comprehensive methodology for general large-scale image-based classification tasks. It addresses the Big Data challenge in arbitrary image classification and more specifically, filtering of millions of websites with abstract target classes and high levels of label noise. Our approach uses local image features and their color descriptors to build image representations with the help of a modified k-NN algorithm. Image representations are refined into image and website class predictions by a two-stage classifier method suitable for a very large-scale real dataset. A modification of an Extreme Learning Machine is found to be a suitable classifier technique. The methodology is robust to noise and can learn abstract target categories; website classification accuracy surpasses 97% for the most important categories considered in this study.",
Mechanism and Experiment of Planar Electrode Sensors in Water Pollutant Measurement,"This paper investigates the detecting mechanism of planar electrode sensor in water pollutant detection. A system composed of electrodes, bulk media, and electrode-solution interface is built up, and the corresponding equivalent circuit containing bulk and interfacial impedances is established. The influence of each part is discussed while the impedance at interface is especially focused on. The impedance spectroscopy of the circuit is divided into three parts by the cutoff frequencies caused by interfacial and bulk impedances, and each of the frequency range can be used for the measurement of different physical quantities in water. The effect of electrode, especially the combination of interdigital and coils, is analyzed, and nine different sensors were designed and fabricated. Experiments validate the accuracy and validity of the model, and the sensor with best sensitivity is found. The stability of the planar sensor is proven in the experiment too.",
A Theoretical Approach to Memristor Devices,"Recently, scientific communities in electrical engineering, material science, biophysics and nano-technologies have paid special attention to memristor devices. Several physical and mathematical memristor models have been proposed to describe devices developed for nonvolatile memory applications and neuromorphic systems. The aim of the paper is to provide a theoretical approach to the various classes of memristive devices as nonlinear dynamical systems whose voltage-current curves (i.e., dynamic characteristics) are pinched at the origin when driven by bipolar excitations. Off-origin dynamic characteristics are discussed and mathematical criteria to model such devices are provided as well. Finally, passivity and losslessness properties of memristor are briefly analized.","Memristors,
Nonvolatile memory,
Mathematical model,
Nonlinear dynamical systems,
Hysteresis,
Nanoscale devices,
Integrated circuit modeling"
High-Geometrical-Accuracy Embroidery Process for Textile Antennas With Fine Details,"An embroidery process with high geometrical accuracy is presented for antennas with fine details. Previous embroidery processes employed thicker threads, leading to resolution not better than 1 mm. Therefore, fine details (e.g., sharp corners) could not be realized, and geometrical accuracy was low, viz. > 1 mm. To overcome these limitations, in this letter we: 1) employ much thinner E-fibers to enable the “printing” of sharp corners, and 2) increase embroidery density to boost surface conductivity. Two Liberator E-fibers were tested: 1) 40-strand ( diameter = 0.27 mm), and 2) 20-strand ( diameter = 0.22 mm). Embroidery density was optimized using double-layer stitching of 7 threads/mm. To validate our embroidery approach, we fabricated and tested a dipole antenna with intricate details operating at 2.4 GHz. This design could not be formerly “printed” on textiles. Both E-fiber (40/20-strand) prototypes exhibited excellent performance, comparable to that of copper antennas. The achieved geometrical accuracy was ~ 0.3 mm (viz. 3 times better).","Yarn,
Accuracy,
Dipole antennas,
Copper,
Prototypes,
Conductivity"
Dual Graph Regularized Latent Low-Rank Representation for Subspace Clustering,"Low-rank representation (LRR) has received considerable attention in subspace segmentation due to its effectiveness in exploring low-dimensional subspace structures embedded in data. To preserve the intrinsic geometrical structure of data, a graph regularizer has been introduced into LRR framework for learning the locality and similarity information within data. However, it is often the case that not only the high-dimensional data reside on a non-linear low-dimensional manifold in the ambient space, but also their features lie on a manifold in feature space. In this paper, we propose a dual graph regularized LRR model (DGLRR) by enforcing preservation of geometric information in both the ambient space and the feature space. The proposed method aims for simultaneously considering the geometric structures of the data manifold and the feature manifold. Furthermore, we extend the DGLRR model to include non-negative constraint, leading to a parts-based representation of data. Experiments are conducted on several image data sets to demonstrate that the proposed method outperforms the state-of-the-art approaches in image clustering.","Manifolds,
Data models,
Laplace equations,
Optimization,
Convergence,
Noise,
Australia"
Arc Fault and Flash Signal Analysis in DC Distribution Systems Using Wavelet Transformation,"Arc faults have always been a concern for electrical systems, as they can cause fires, personnel shock hazard, and system failure. Existing commercialized techniques that rely on pattern recognition in the time domain or frequency domain analysis using a Fourier transform do not work well, because the signal-to-noise ratio is low and the arc signal is not periodic. Instead, wavelet transform (WT) provides a time and frequency approach to analyze target signals with multiple resolutions. In this paper, a new approach using WT for arc fault analysis in dc systems is proposed. The process of detecting an arc fault involves signal analysis and then feature identification. The focus of this paper is on the former. Simulation models are synthesized to study the theoretical results of the proposed methodology and traditional fast Fourier transform analysis on arcing faults. Experimental data from the dc system of a photovoltaic array is also shown to validate the approach.",
Compact Image Fingerprint Via Multiple Kernel Hashing,"Image fingerprinting is regarded as an alternative approach to watermarking in terms of near-duplicate detection application. It consists of feature extraction and feature indexing. Generally, the former is mainly related to discrimination, robustness , and security while the latter closely focuses on the efficiency of fingerprints search. To enable fast fingerprints searching over a very large database, we propose a new kernelized multiple feature hashing method to convert the real-value fingerprints into compact binary-value fingerprints. During the process of converting, the proposed hashing method jointly utilizes the kernel trick and multiple feature fusion strategy to map the image represented by multiple features into a compact binary code. With the help of the kernel function, the hashing method can be applied to any format (such as string, graph, set, and so on) as long as there is an associated kernel function available for similarity measurement. In addition, taking multiple features into account aims at improving the discriminability since these multiple evidences are complementary to each other. The extensive experimental results show that the proposed algorithm outperforms state-of-the-art kernelized hashing methods by up to 10 percent.",
RRAM-Based Analog Approximate Computing,"Approximate computing is a promising design paradigm for better performance and power efficiency. In this paper, we propose a power efficient framework for analog approximate computing with the emerging metal-oxide resistive switching random-access memory (RRAM) devices. A programmable RRAM-based approximate computing unit (RRAM-ACU) is introduced first to accelerate approximated computation, and an approximate computing framework with scalability is then proposed on top of the RRAM-ACU. In order to program the RRAM-ACU efficiently, we also present a detailed configuration flow, which includes a customized approximator training scheme, an approximator-parameter-to-RRAM-state mapping algorithm, and an RRAM state tuning scheme. Finally, the proposed RRAM-based computing framework is modeled at system level. A predictive compact model is developed to estimate the configuration overhead of RRAM-ACU and help explore the application scenarios of RRAM-based analog approximate computing. The simulation results on a set of diverse benchmarks demonstrate that, compared with a x86-64 CPU at 2 GHz, the RRAM-ACU is able to achieve 4.06-196.41× speedup and power efficiency of 24.59-567.98 GFLOPS/W with quality loss of 8.72% on average. And the implementation of hierarchical model and X application demonstrates that the proposed RRAM-based approximate computing framework can achieve 12.8× power efficiency than its pure digital implementation counterparts (CPU, graphics processing unit, and field- programmable gate arrays).","Approximation methods,
Resistance,
Training,
Arrays,
Computational modeling,
Hardware,
Approximation algorithms"
"A Surface Acoustic Wave Passive and Wireless Sensor for Magnetic Fields, Temperature, and Humidity","In this paper, we report an integrated single-chip surface acoustic wave sensor with the capability of measuring magnetic field, temperature, and humidity. The sensor is fabricated using a thermally sensitive LiNbO3 substrate, a humidity sensitive hydrogel coating, and a magnetic field sensitive impedance load. The sensor response to individually and simultaneously changing magnetic field, temperature and humidity is characterized by connecting a network analyzer directly to the sensor. Analytical models for each measurand are derived and used to compensate noise due to cross sensitivities. The results show that all three measurands can be monitored in parallel with sensitivities of 75 ppm/°C, 0.13 dB/%R.H. (at 50%R.H.), 0.18 dB/Oe and resolutions of 0.1 °C, 0.4%R.H., 1 Oe for temperature, humidity and magnetic field, respectively. A passive wireless measurement is also conducted on a current line using, which shows the sensors capability to measure both temperature and current signals simultaneously.","Temperature sensors,
Humidity,
Magnetic sensors,
Temperature measurement,
Surface acoustic waves,
Magnetic fields"
Diverse Grouping-Based Aggregation Protocol With Error Detection for Smart Grid Communications,"Smart grid, as the next generation of power grid characterized by “two-way” communications, has been paid great attention to realizing green, reliable, and efficient electricity delivery for our future lives. In order to support the two-way communications in smart grid, a large number of smart meters (SMs) should be deployed to customers to report their near real-time data to control center for monitoring purpose. However, this kind of real-time report could disclose users' privacy, bringing down the users' willingness to participate in smart grid. In order to address the challenge, in this paper, by considering the lifetime of SMs as exponential distribution, we propose a diverse grouping-based aggregation protocol with error detection (DG-APED), which employs differential privacy technique into grouping-based private stream aggregation for secure smart grid communications. DG-APED can not only achieve privacy-preserving aggregation, but also perform error detection efficiently when some SMs are malfunctioning. Detailed security analysis shows that DG-APED can guarantee the security and privacy requirements of smart grid communications. In addition, extensive performance evaluation also verifies the effectiveness and efficiency of the proposed DG-APED.","Protocols,
Privacy,
Smart meters,
Aggregates,
Exponential distribution"
Real-Time Trajectory Generation for Quadrocopters,"This paper presents a trajectory generation algorithm that efficiently computes high-performance flight trajectories that are capable of moving a quadrocopter from a large class of initial states to a given target point that will be reached at rest. The approach consists of planning separate trajectories in each of the three translational degrees of freedom, and ensuring feasibility by deriving decoupled constraints for each degree of freedom through approximations that preserve feasibility. The presented algorithm can compute a feasible trajectory within tens of microseconds on a laptop computer; remaining computation time can be used to iteratively improve the trajectory. By replanning the trajectory at a high rate, the trajectory generator can be used as an implicit feedback law similar to model predictive control. The solutions generated by the algorithm are analyzed by comparing them with time-optimal motions, and experimental results validate the approach.","Trajectory,
Acceleration,
Vehicles,
Vehicle dynamics,
Robots,
Heuristic algorithms,
Real-time systems"
Closed-Form Solution of Time-Varying Model and Its Applications for Output Current Harmonics in Two-Stage PV Inverter,"The single-phase photovoltaic (PV) inverter needs significant capacitance to buffer the double-line frequency power pulsation at ac port. The two-stage inverter allows the designer to choose the dc-link voltage and the capacitor size flexibly. With the reduced capacitance, the lifetime of the dc-link capacitor can be prolonged by replacing the electrolytic capacitors with film capacitors. However, the capacitance deduction results in high double-line frequency voltage ripple on dc-link, which increases a series of odd harmonics in the output current. This paper hence analyzes the harmonics caused by the voltage ripple in an inverter with feedback control. The inverter is modeled as a time-varying system by considering the dc-link voltage ripple. A closed-form solution is derived to calculate the amplitude of the ripple-caused harmonics. This analysis helps the designer to understand the effect of the dc-link voltage ripple on current harmonics, evaluate effectiveness of existing approaches, and stimulate new ideas and solutions. The study also derived the theoretical limit to select dc-link capacitance and sampling rate of current reference without violating the grid-tied regulations in power quality. The analysis is verified both by simulation and experimental evaluation.",
Cognition-Driven Formulation of Space Mapping for Equal-Ripple Optimization of Microwave Filters,"Space mapping is a recognized method for speeding up electromagnetic (EM) optimization. Existing space-mapping approaches belong to the class of surrogate-based optimization methods. This paper proposes a cognition-driven formulation of space mapping that does not require explicit surrogates. The proposed method is applied to EM-based filter optimization. The new technique utilizes two sets of intermediate feature space parameters, including feature frequency parameters and ripple height parameters. The design variables are mapped to the feature frequency parameters, which are further mapped to the ripple height parameters. By formulating the cognition-driven optimization directly in the feature space, our method increases optimization efficiency and the ability to avoid being trapped in local minima. The technique is suitable for design of filters with equal-ripple responses. It is illustrated by two microwave filter examples.",
Terahertz Fiber Bragg Grating for Distributed Sensing,"This letter reports a fiber Bragg grating (FBG) for distributed sensing applications fabricated using single-mode optical fiber and a femtosecond laser and interrogated in the terahertz (THz) range. A theoretical model of device behavior was derived, which agreed well with experimentally observed device behavior. In order to investigate the utility of THZ FBGs (THz FBGs) as a sensing modality, temperature tests were conducted. The results demonstrated a sensitivity of -1.32 GHz/°C and a detection resolution of <;0.0017 °C. A temperature distribution test was also conducted using a THz FBG, demonstrating its potential as a distributed sensing platform with high spatial resolution. The feasibility of interrogating THz FBGs using narrow interrogation bandwidths was also experimentally shown.","Fiber gratings,
Optical fiber sensors,
Optical fibers,
Bandwidth,
Temperature sensors"
The Road Ahead for Architectural Languages,"Despite the huge number of architectural languages that have been proposed in the last two decades, evidence today shows that industry-ready, well-accepted, and recognized languages for producing architecture descriptions are still lacking. This article explores the usability requirements of architectural languages from the perspectives of language definition, language mechanisms, and tool support. With a better understanding of architectural-language requirements, the authors explore the use of model-driven engineering to realize next-generation architectural languages, as well as its limitations.",
Fault Diagnosis and Tolerant Control for Discrete Stochastic Distribution Collaborative Control Systems,"This paper presents a novel fault-tolerant control method for a class of discrete-time and nonGaussian stochastic systems, where two subsystems are connected in series so as to operate in a collaborative way. For such systems, the output probability density function of the second subsystem is taken as the output of the whole system. The proposed method includes the design of a fault diagnosis (FD) algorithm for the first subsystem and the establishment of a fault-tolerant control algorithm for the second subsystem. At first, linear matrix inequality techniques are used to construct the FD algorithm for the first subsystem. Once the fault is diagnosed, a fault-tolerant control algorithm is designed using the well-known optimal norm-based iterative learning control approach. Different from the existing fault tolerant controller methods, the proposed fault-tolerant control is designed not for the faulty subsystem but for the healthy subsystem. As a result, when a fault occurs in the first subsystem, the reconfigured controller for the healthy second subsystem can accommodate the fault and guarantee that the whole system will still exhibit good operational performance. A simulated example is used to demonstrate the collaborative fault-tolerant control effect and desired results have been obtained.","Collaboration,
Control systems,
Algorithm design and analysis,
Splines (mathematics),
Stochastic processes,
Vectors,
Fault tolerance"
Real-time anomaly detection and localization in crowded scenes,"In this paper, we propose a method for real-time anomaly detection and localization in crowded scenes. Each video is defined as a set of non-overlapping cubic patches, and is described using two local and global descriptors. These descriptors capture the video properties from different aspects. By incorporating simple and cost-effective Gaussian classifiers, we can distinguish normal activities and anomalies in videos. The local and global features are based on structure similarity between adjacent patches and the features learned in an unsupervised way, using a sparse auto-encoder. Experimental results show that our algorithm is comparable to a state-of-the-art procedure on UCSD ped2 and UMN benchmarks, but even more time-efficient. The experiments confirm that our system can reliably detect and localize anomalies as soon as they happen in a video.","Streaming media,
Feature extraction,
Training,
Real-time systems,
Gaussian distribution,
Benchmark testing,
Reliability"
Robust NLOS Error Mitigation Method for TOA-Based Localization via Second-Order Cone Relaxation,"The existence of non-line-of-sight (NLOS) errors can significantly degrade the localization performance. In this letter, we address the time-of-arrival (TOA) based localization problem under NLOS conditions. To accurately localize a source, we propose a novel robust second-order cone relaxation (SOCR) method, which is not sensitive to NLOS errors. The proposed method does not require one to know any statistics of the NLOS errors, and instead, it only requires to know the upper bound on the magnitudes of the NLOS errors, which is relatively easy to obtain in practice. Simulation results show that the proposed robust SOCR method has good performance in various NLOS scenarios, and also it has a relatively lower computational complexity than the existing methods.","Robustness,
Sensors,
Noise measurement,
Measurement uncertainty,
Simulation,
Error analysis,
Complexity theory"
Improvement of Stability and Power Factor in PCM Controlled Boost PFC Converter With Hybrid Dynamic Compensation,"Traditional slope compensation (SC) method is an effective way to control fast-scale instabilities present in peak current mode (PCM) controlled boost PFC converters. However, with the SC method, envelope of inductor current deviates from a desired sinusoid especially near the zero crossings, which causes the system power factor to reduce to values lower than what is possible without compensation. To tackle this problem we propose a hybrid dynamic compensation (HDC) scheme, which incorporates a combination of zero-perturbation dynamic compensation (ZPDC) and ripple compensation. The proposed HDC scheme can suppress the fast-scale instabilities and also ensure average inductor current tracks a desired sinusoidal reference which is not possible with the ZPDC scheme alone where only the peak inductor current can track a desired sinusoidal signal. Furthermore, with the proposed HDC scheme the total harmonic distortion (THD) and power factor (PF) are improved in comparison to the SC and ZPDC schemes as well as to the case without compensation. Moreover, operating range of a control parameter is determined analytically subject to some assumptions. Extensive simulation and experimental results are provided to validate the theoretical analysis and the feasibility of the proposed HDC scheme.","Inductors,
Phase change materials,
Switches,
Reactive power,
Voltage control,
Jacobian matrices,
Stability analysis"
Enhancing performance of wireless NoCs with distributed MAC protocols,"Wireless NoC is an emerging paradigm to design high-bandwidth and energy-efficient communication backbones for massive multicore chips. The achievable performance of this type of on-chip interconnect infrastructure depends on the efficiency of the Media Access Control (MAC) protocol that arbitrates between the competing wireless nodes. In this work we propose the design of a distributed MAC protocol suitable for wireless NoC architectures. Compared to the widely used token passing scheme, a distributed MAC protocol improves scalability, provides better performance and lower overall energy dissipation. Depending on the traffic pattern, the proposed distributed MAC provides up to 23% improvement in energy delay product (EDP) when compared to the existing token passing scheme.","Wireless communication,
Media Access Protocol,
Routing,
Switches,
Transceivers,
Ports (Computers)"
"Micromachined Hotplate Platform for the Investigation of Ink-Jet Printed, Functionalized Metal Oxide Nanoparticles","This paper describes a novel micromachined platform serving as an interface between nanosized, gas sensitive metal oxide particles, and the macroscopic world. Through a combination of ink-jet printing and microelectromechanical systems technologies, it thus becomes possible to quickly test and characterize new nanosized metal oxide particles with respect to their gas sensitivity. Within the framework of this report, we describe the design considerations, thermal finite-element method simulations, processing, characterization, and utilization of the platform. Due to the low-power consumption, the hotplate provides an experimental platform to test nanoparticle-based metal oxide gas sensors for mobile systems.",
Analysis of Smart Mobile Applications for Healthcare under Dynamic Context Changes,"Smart mobile medical computing systems (SMDCSes), e.g., mobile medical applications use context information from the environment to provide useful and often critical healthcare services such as continuous monitoring and control of blood glucose levels by infusion of insulin. Given the unsupervised nature of operation of SMDCSes, context changes that are unaccounted for can cause unprecedented faults leading to violation of requirements such as safety, energy sustainability and reliability. Analysis of SMDCSes for testing requirements violations necessitates consideration of context dependent interactions between the SMDCS software, represented by discrete operating modes and its environment, represented by non-linear partial differential equations over space and time. An intractable number of context change sequence and lack of closed form solutions to differential equations makes the requirements analysis of SMDCSes a challenging task. This paper proposes a novel technique to analyze SMDCSes taking into account the dynamic changes in the context and the constant interaction of the computing systems with the physical environment. To show the usage of the technique, Ayushman pervasive health monitoring system is considered as an example SMDCS. Analytical results show that practices considered healthy for a person such as mobility may not be beneficial when an SMDCS is controlling health.","Context,
Analytical models,
Context modeling,
Unified modeling language,
Computational modeling,
Safety,
Software"
Energy efficient green routing protocol for Internet of Multimedia Things,"Internet of Things (IoT) envisions the notion of ubiquitous connectivity of `everything'. However, the current research and development activities have been restricted to scalar sensor data based IoT systems, thus leaving a gap to benefit from services and application enabled by `multimedia things' or Internet of Multimedia Things (IoMT). Moreover, a crucial issue for Information and Communication Technology (ICT) community is the steer increase in CO2 emissions, which mandates green communication to reduce energy consumption and carbon footprint emissions. Recently, IETF ROLL working group standardized an IPv6 Routing Protocol for Low-Power and Lossy Networks (RPL) for resource constrained devices. RPL builds a tree-like network topology based on some network metric optimization using RPL Objective Functions. Previous RPL implementations for scalar sensor data communication are not feasible for IoMT, since multimedia traffic pose distinct network requirements. The goal of this paper is to design an enhanced version of RPL for IoMT in which the sensed information is essentially provided by the multimedia devices. Our proposed RPL implementation minimizes carbon footprint emissions and energy consumption, along with the incorporation of application specific Quality of Service requirements. To evaluate the performance of the proposed scheme a simulation study is carried out in Cooja simulator for Contiki-OS, which suggests significant gains in terms of energy efficiency and delay.","Green products,
Multimedia communication,
Routing protocols,
Air pollution,
Carbon dioxide,
Delays"
Extending Wireless Sensor Network Lifetime With Global Energy Balance,"In this paper, a decentralized routing algorithm, called game theoretic energy balance routing protocol, is proposed to extend the network lifetime by balancing energy consumption in a larger network area using geographical routing protocols. The objective of the proposed protocol is to make sensor nodes deplete their energy at approximately the same time, which is achieved by addressing the load balance problem at both the region and node levels. In the region level, evolutionary game theory (EGT) is used to balance the traffic load to available subregions. At the node level, classical game theory (CGT) is used to select the best node to balance the load in the selected subregion. This two-level approach is shown to be an effective solution for load balancing and extending network lifetime. This paper shows the use of EGT and CGT in designing a robust protocol that offers significant improvement over existing protocols in extending network lifetime.","Games,
Sensors,
Wireless sensor networks,
Routing protocols,
Energy consumption,
Routing"
Proactive Data Migration for Improved Storage Availability in Large-Scale Data Centers,"In face of high partial and complete disk failure rates and untimely system crashes, the executions of low-priority background tasks become increasingly frequent in large-scale data centers. However, the existing algorithms are all reactive optimizations and only exploit the temporal locality of workloads to reduce the user I/O requests during the low-priority background tasks. To address the problem, this paper proposes Intelligent Data Outsourcing (IDO), a zone-based and proactive data migration optimization, to significantly improve the efficiency of the low-priority background tasks. The main idea of IDO is to proactively identify the hot data zones of RAID-structured storage systems in the normal operational state. By leveraging the prediction tools to identify the upcoming events, IDO proactively migrates the data blocks belonging to the hot data zones on the degraded device to a surrogate RAID set in the large-scale data centers. Upon a disk failure or crash reboot, most user I/O requests addressed to the degraded RAID set can be serviced directly by the surrogate RAID set rather than the much slower degraded RAID set. Consequently, the performance of the background tasks and user I/O performance during the background tasks are improved simultaneously. Our lightweight prototype implementation of IDO and extensive trace-driven experiments on two case studies demonstrate that, compared with the existing state-of-the-art approaches, IDO effectively improves the performance of the low-priority background tasks. Moreover, IDO is portable and can be easily incorporated into any existing algorithms for RAID-structured storage systems.","Optimization,
Availability,
Computer crashes,
Software,
Maintenance engineering,
Performance evaluation,
System performance"
A Benchmark and Comparative Study of Video-Based Face Recognition on COX Face Database,"Face recognition with still face images has been widely studied, while the research on video-based face recognition is inadequate relatively, especially in terms of benchmark datasets and comparisons. Real-world video-based face recognition applications require techniques for three distinct scenarios: 1) Videoto-Still (V2S); 2) Still-to-Video (S2V); and 3) Video-to-Video (V2V), respectively, taking video or still image as query or target. To the best of our knowledge, few datasets and evaluation protocols have benchmarked for all the three scenarios. In order to facilitate the study of this specific topic, this paper contributes a benchmarking and comparative study based on a newly collected still/video face database, named COX1 Face DB. Specifically, we make three contributions. First, we collect and release a largescale still/video face database to simulate video surveillance with three different video-based face recognition scenarios (i.e., V2S, S2V, and V2V). Second, for benchmarking the three scenarios designed on our database, we review and experimentally compare a number of existing set-based methods. Third, we further propose a novel Point-to-Set Correlation Learning (PSCL) method, and experimentally show that it can be used as a promising baseline method for V2S/S2V face recognition on COX Face DB. Extensive experimental results clearly demonstrate that video-based face recognition needs more efforts, and our COX Face DB is a good benchmark database for evaluation.","Face,
Face recognition,
Databases,
Testing,
Protocols,
Video equipment,
Video sequences"
A Partial Selection Methodology for Efficient QoS-Aware Service Composition,"As web service has become a popular way for engineering software on the Internet, quality of service (QoS) which describes non-functional characteristics of web services is often employed in service composition. Since QoS is an aggregated concept consisting of several attributes, service composition on enormous candidate sets is a challenging multi-objective optimization problem. In this paper, we study the problem from a general Pareto optimal angle, seeking to reduce search space in service composition. Pareto set model for QoS-aware service composition is introduced, and its relationship with the widely used utility function model is theoretically studied, which proves the applicability of our model. QoS attributes are systematically studied according to their different types of aggregation patterns in service composition, and QoS-based dominance relationships between candidates and between workflows are defined. Taking advantage of pruning candidates by dominance relationships and constraint validations at candidate level, a service composition algorithm using partial selection techniques is proposed. Furthermore, a parallel approach is designed, which is able to significantly reduce search space and achieve great performance gains. A careful analysis of the optimality of our approach is provided, and its efficacy is further validated by both simulation experiments and real-world data based evaluations.","Quality of service,
Web services,
Aggregates,
Pareto optimization,
Vectors,
Time factors"
A Fully Parallel Nonbinary LDPC Decoder With Fine-Grained Dynamic Clock Gating,"Nonbinary LDPC (NB-LDPC) codes, defined over Galois field, offer better coding gain and a lower error floor than binary LDPC codes. However, the complex decoding and large memory requirement have prevented any practical chip implementations. We present a 1.22 Gb/s fully parallel decoder of a GF(64) (160, 80) regular-(2, 4) NB-LDPC code in 65 nm CMOS. The reduced number of edges in NB-LDPC code's factor graph permits a low wiring overhead in the fully parallel architecture. The throughput is further improved by a one-step look-ahead check node design that increases the clock frequency to 700 MHz, and the interleaving of variable node and check node operations that shortens one decoding iteration to 47 clock cycles. We allow each processing node to detect its own convergence and apply dynamic clock gating to save power. When all processing nodes have been clock gated, the decoder terminates and continues with the next input to increase the throughput to 1.22 Gb/s. The dynamic clock gating and decoder termination improve the energy efficiency to 3.03 nJ/b, or 259 pJ/b/iteration, at 1.0 V and 700 MHz. Voltage scaling to 675 mV improves the energy efficiency to 89 pJ/b/iteration for a throughput of 698 Mb/s at 400 MHz.","Decoding,
Parity check codes,
Complexity theory,
Clocks,
Indexes,
Algorithm design and analysis,
Throughput"
Identification of Protein Complexes Using Weighted PageRank-Nibble Algorithm and Core-Attachment Structure,"Protein complexes play a significant role in understanding the underlying mechanism of most cellular functions. Recently, many researchers have explored computational methods to identify protein complexes from protein-protein interaction (PPI) networks. One group of researchers focus on detecting local dense subgraphs which correspond to protein complexes by considering local neighbors. The drawback of this kind of approach is that the global information of the networks is ignored. Some methods such as Markov Clustering algorithm (MCL), PageRank-Nibble are proposed to find protein complexes based on random walk technique which can exploit the global structure of networks. However, these methods ignore the inherent core-attachment structure of protein complexes and treat adjacent node equally. In this paper, we design a weighted PageRank-Nibble algorithm which assigns each adjacent node with different probability, and propose a novel method named WPNCA to detect protein complex from PPI networks by using weighted PageRank-Nibble algorithm and core-attachment structure. Firstly, WPNCA partitions the PPI networks into multiple dense clusters by using weighted PageRank-Nibble algorithm. Then the cores of these clusters are detected and the rest of proteins in the clusters will be selected as attachments to form the final predicted protein complexes. The experiments on yeast data show that WPNCA outperforms the existing methods in terms of both accuracy and p-value.The software for WPNCA is available at “http://netlab.csu.edu.cn/bioinfomatics/weipeng/WPNCA/download.html”.","Proteins,
Clustering algorithms,
Computational biology,
Bioinformatics,
Partitioning algorithms"
Quantitative Susceptibility Mapping by Inversion of a Perturbation Field Model: Correlation With Brain Iron in Normal Aging,"There is increasing evidence that iron deposition occurs in specific regions of the brain in normal aging and neurodegenerative disorders such as Parkinson's, Huntington's, and Alzheimer's disease. Iron deposition changes the magnetic susceptibility of tissue, which alters the MR signal phase, and allows estimation of susceptibility differences using quantitative susceptibility mapping (QSM). We present a method for quantifying susceptibility by inversion of a perturbation model, or “QSIP.” The perturbation model relates phase to susceptibility using a kernel calculated in the spatial domain, in contrast to previous Fourier-based techniques. A tissue/air susceptibility atlas is used to estimate B0 inhomogeneity. QSIP estimates in young and elderly subjects are compared to postmortem iron estimates, maps of the Field-Dependent Relaxation Rate Increase, and the L1-QSM method. Results for both groups showed excellent agreement with published postmortem data and in vivo FDRI: statistically significant Spearman correlations ranging from Rho=0.905 to Rho=1.00 were obtained. QSIP also showed improvement over FDRI and L1-QSM: reduced variance in susceptibility estimates and statistically significant group differences were detected in striatal and brainstem nuclei, consistent with age-dependent iron accumulation in these regions.",
Representing Uncertainty in Graph Edges: An Evaluation of Paired Visual Variables,"When visualizing data with uncertainty, a common approach is to treat uncertainty as an additional dimension and encode it using a visual variable. The effectiveness of this approach depends on how the visual variables chosen for representing uncertainty and other attributes interact to influence the user's perception of each variable. We report a user study on the perception of graph edge attributes when uncertainty associated with each edge and the main edge attribute are visualized simultaneously using two separate visual variables. The study covers four visual variables that are commonly used for visualizing uncertainty on line graphical primitives: lightness, grain, fuzziness, and transparency. We select width, hue, and saturation for visualizing the main edge attribute and hypothesize that we can observe interference between the visual variable chosen to encode the main edge attribute and that to encode uncertainty, as suggested by the concept of dimensional integrality. Grouping the seven visual variables as color-based, focus-based, or geometry-based, we further hypothesize that the degree of interference is affected by the groups to which the two visual variables belong. We consider two further factors in the study: discriminability level for each visual variable as a factor intrinsic to the visual variables and graph-task type (visual search versus comparison) as a factor extrinsic to the visual variables. Our results show that the effectiveness of a visual variable in depicting uncertainty is strongly mediated by all the factors examined here. Focus-based visual variables (fuzziness, grain, and transparency) are robust to the choice of visual variables for encoding the main edge attribute, though fuzziness has stronger negative impact on the perception of width and transparency has stronger negative impact on the perception of hue than the other uncertainty visual variables. We found that interference between hue and lightness is much greater than that between saturation and lightness, though all three are color-based visual variables. We also found a compound relationship between discriminability level and the degree of dimensional integrality. We discuss the generalizability and limitation of the results and conclude with design considerations for visualizing graph uncertainty derived from these results, including recommended choices of visual variables when the relative importance of data attributes and graph tasks is known.",
Enhancing the quality level support for real-time multimedia applications in software-defined networks,"Nowadays, the explosive growth of real-time applications that need stringent Quality of Service (QoS) and Quality of Experience (QoE) support, forces network programmers to design network protocols that deliver specified performance guarantees. This paper exploits the use of Software-Defined Networking (SDN) in conjunction with the OpenFlow protocol to differentiate network services with quality level assurance and to respect agreed Service Level Agreements. Initially, we define a Management and Orchestration architecture that allows us to manage the network in a modular way. Then, we provide a seamless integration of the proposed architecture and the SDN standard following the separation between the control and data planes. Finally, we give an Integer Linear Programming formulation of the problem of enhancing QoS and QoE in SDNs in terms of packet loss and delay, taking into account the network constraints and the requirements of real-time applications, i.e., maximum acceptable packet loss and delay rates. Given the optimal solution of the problem, we evaluate the impact and benefits of the proposed scheme by means of the Mininet network emulator.",
Human-Like Behavior Generation Based on Head-Arms Model for Robot Tracking External Targets and Body Parts,"Facing and pointing toward moving targets is a usual and natural behavior in daily life. Social robots should be able to display such coordinated behaviors in order to interact naturally with people. For instance, a robot should be able to point and look at specific objects. This is why, a scheme to generate coordinated head-arm motion for a humanoid robot with two degrees-of-freedom for the head and seven for each arm is proposed in this paper. Specifically, a virtual plane approach is employed to generate the analytical solution of the head motion. A quadratic program (QP)-based method is exploited to formulate the coordinated dual-arm motion. To obtain the optimal solution, a simplified recurrent neural network is used to solve the QP problem. The effectiveness of the proposed scheme is demonstrated using both computer simulation and physical experiments.","Robot kinematics,
Face,
Humanoid robots,
Neck,
Joints,
Target tracking"
Energy Consumption Analysis and Minimization in Multi-Layer Heterogeneous Wireless Systems,"Cellular network technologies have traditionally evolved to meet the ever-increasing need for capacity and coverage. Particularly, there has been a significant focus on exploiting the use of small cells and heterogeneous networks (HetNets). In the latter, the economic and environmental impact of the energy consumption is a key concern. Although much research has been done to address the energy consumption in HetNets, existing approaches have failed to capture the key factors affecting it. In this paper, the energy consumption in HetNets is analyzed with a focus on their multi-layer nature and the dependence of the energy consumption on the spatio-temporal traffic demands and the internal base station hardware components. The problem of minimizing the energy consumption is then studied and characterized in terms of a 0-1 Knapsack-like problem. Due to the differences with the classical 0-1 Knapsack problem, an efficient algorithm is introduced to minimize the energy consumption by adjusting the cell-association and the base stations on-off policies. Such algorithm is shown to be applicable to the twoand m-layer HetNet cases. Performance evaluation is provided to identify the achievable energy savings of our algorithm and its effect on the energy consumption, activity, and load across multiple layers.",
The Secrecy Capacity of Compound Gaussian MIMO Wiretap Channels,"Strong secrecy capacity of compound wiretap channels is studied. The known lower bounds for the secrecy capacity of compound finite-state memoryless channels under discrete alphabets are extended to arbitrary uncertainty sets and continuous alphabets under the strong secrecy criterion. The conditions under which these bounds are tight are given. Under the saddle-point condition, the compound secrecy capacity is shown to be equal to that of the worst-case channel. Based on this, the compound Gaussian multiple-input multiple-output wiretap channel is studied under the spectral norm constraint and without the degradedness assumption. First, it is assumed that only the eavesdropper channel is unknown, but is known to have a bounded spectral norm (maximum channel gain). The compound secrecy capacity is established in a closed form and the optimal signaling is identified. The compound capacity equals the worst-case channel capacity and thus establishing the saddlepoint property; the optimal signaling is Gaussian and on the eigenvectors of the legitimate channel and the worst-case eavesdropper is isotropic. The eigenmode power allocation somewhat resembles the standard water-filling but is not identical to it. More general uncertainty sets are considered and the existence of a maximum element is shown to be sufficient for a saddle-point to exist, so that signaling on the worst-case channel achieves the compound capacity of the whole class of channels. The case of rank-constrained eavesdropper is considered and the respective compound secrecy capacity is established. Subsequently, the case of additive uncertainty in the legitimate channel, in addition to the unknown eavesdropper channel, is studied. Its compound secrecy capacity and the optimal signaling are established in a closed form as well, revealing the same saddle-point property. When a saddle-point exists under strong secrecy, strong and weak secrecy compound capacities are equal.","Compounds,
Uncertainty,
MIMO,
Transmitters,
Receivers,
Wireless communication,
Security"
Sub-60mV-swing negative-capacitance FinFET without hysteresis,"In this work, we report the first Negative-Capacitance FinFET. ALD Hf042Zr058O2 is added on top of the FinFET's gate stack. The test devices have a floating internal gate that can be electrically probed. Direct measurement found the small-signal voltage amplified by 1.6X maximum at the internal gate in agreement with the improvement of the subthreshold swing (from 87 to 55mV/decade). ION increased by >25% for the IOFF. For the first time, we demonstrate that raising HfZrO2 ferroelectricity, by annealing at higher temperature, reduces and eliminates IV hysteresis and increases the voltage gain. These discoveries will guide future theoretical and experimental work.",
Urban Resolution: New Metric for Measuring the Quality of Urban Sensing,"The rising popularity of smartphones and vehicles equipped with onboard sensors sheds lights on building a city-scale sensing system for urban surveillance. This paper proposes a novel metric, urban resolution, to measure the quality of urban sensing. Urban resolution describes how sensitivity the urban sensing system could achieve for environment monitoring applications. Then, we study the relationship between resolution r and number of sensing nodes s, and reveal the linear growth relationship between √r and √s . Furthermore, by employing a commonly used human/vehicle mobility model, SLAW, we find that the distribution model of urban sensing nodes is able to be described by a truncated Pareto distribution, and derive the complementary cumulative distribution function (CCDF) of urban resolution. The CCDF reveals the radio of the sub-regions which satisfy the required sensing quality to the whole region. Our findings provide valuable insights to infer the urban sensing quality according to the scale of urban sensing system or determine how many smartphone/vehicles needed for participating in urban sensing applications. Finally, based on five real datasets-three human/vehicle trajectory datasets and two environment monitoring datasets, we examine the metric of urban resolution and evaluate the main results in this paper.","Smart phones,
Urban areas,
Image resolution,
Environmental factors,
Cameras,
Intelligent vehicles,
Sensor systems"
Parallel Implementation of Sparse Representation Classifiers for Hyperspectral Imagery on GPUs,"Classification is one of the most important analysis techniques for hyperspectral image analysis. Sparse representation is an extremely powerful tool for this purpose, but the high computational complexity of sparse representation-based classification techniques limits their application in time-critical scenarios. To improve the efficiency and performance of sparse representation classification techniques for hyperspectral image analysis, this paper develops a new parallel implementation on graphics processing units (GPUs). First, an optimized sparse representation model based on spatial correlation regularization and a spectral fidelity term is introduced. Then, we use this approach as a case study to illustrate the advantages and potential challenges of applying GPU parallel optimization principles to the considered problem. The first GPU optimization algorithm for sparse representation classification (SRCSC_P) of hyperspectral images is proposed in this paper, and a parallel implementation of the proposed method is developed using compute unified device architecture (CUDA) on GPUs. The GPU parallel implementation is compared with the serial and multicore implementations on CPUs. Experimental results based on real hyperspectral datasets show that the average speedup of SRCSC_P is more than 130×, and the proposed approach is able to provide results accurately and fast, which is appealing for computationally efficient hyperspectral data processing.","Hyperspectral imaging,
Training,
Graphics processing units,
Correlation,
Optimization,
Kernel"
All-Optical Relaying FSO Systems Using EDFA Combined With Optical Hard-Limiter Over Atmospheric Turbulence Channels,"In this paper, a novel relaying technique is proposed to improve the bit-error rate (BER) performance and distance coverage of high-speed all-optical free-space optical (FSO) communication systems. Particularly, an optical amplify-and-forward (OAF) relaying technique using erbium-doped fiber amplifier (EDFA) combined with optical hard-limiter (OHL) is introduced. The use of OHL enables EDFA-based OAF relaying FSO systems to prevent the accumulation of amplified background noise, which significantly degrades the system performance, when deploying multiple relays. For performance evaluation, we theoretically analyze the proposed system over atmospheric turbulence channels modeled by Gamma-Gamma distribution. A closed-form expression for the end-to-end BER bounds is, therefore, analytically formulated, taking into account other impacts of atmospheric channels, including atmospheric attenuation and geometric spreading of the optical beam, as well as noises caused by the background light and receiver. The numerical results, which are validated by Monte-Carlo simulations, confirm the superiority of the proposed system in comparison with the conventional ones.","Erbium-doped fiber amplifiers,
Relays,
Optical receivers,
Gain,
Noise,
Optical attenuators,
Stimulated emission"
Thermometry of Filamentary RRAM Devices,"Since thermal effects play a major role in filamentary RRAM devices, we compare the two localized thermometry methods developed for such devices. One method is based on short-pulsed measurements and the other on the measurement of minority-carrier injection from the filament into a semiconductor electrode by thermionic emission. We carried out and compared the measurements on the same functional oxide layer. Both methods indicate that the filament temperature is at least ~550 K during device operation. Furthermore, comparison between the measured thermal resistance and the thermal simulations of both techniques shows that under the conditions of low forming current compliance (~10 μA), the filament dimensions are below ~5 nm. We show that the thermionic emission method is useful for high-resistance (>100 kQ) devices operating at low-power conditions (<;10 μW), whereas the pulsed thermometry is more suitable for lower resistance devices (<;500 kQ) operated above 1 μW. The average thermal resistance measured by the pulse technique decreases with applied power. Our simulations indicate that the expansion of the heated zone surrounding the filament can explain the observed reduction in thermal resistance with applied power. The underlying physics of the two methods is discussed.",
A closed-form solution for real-time ZMP gait generation and feedback stabilization,"Here we present a closed-form solution to the continuous time-varying linear-quadratic regulator problem for zero-moment point (ZMP) tracking. This generalizes previous analytical solutions for gait generation by allowing ""soft"" tracking (with a quadratic cost) of the desired ZMP, and by providing the feedback gains for the resulting time-varying optimal controller. This enables very fast O(n) computation, with n the number of piecewise polynomial segments in the desired ZMP trajectory. Results are presented using the Atlas humanoid robot where dynamic walking is achieved by recomputing the optimal controller online.",
Optimal Task Placement with QoS Constraints in Geo-Distributed Data Centers Using DVFS,"With the rising demands on cloud services, the electricity consumption has been increasing drastically as the main operational expenditure (OPEX) to data center providers. The geographical heterogeneity of electricity prices motivates us to study the task placement problem over geo-distributed data centers. We exploit the dynamic frequency scaling technique and formulate an optimization problem that minimizes OPEX while guaranteeing the quality-of-service, i.e, the expected response time of tasks. Furthermore, an optimal solution is discovered for this formulated problem. The experimental results show that our proposal achieves much higher cost-efficiency than the traditional resizing scheme, i.e, by activating/deactivating certain servers in data centers.","Servers,
Electricity,
Power demand,
Quality of service,
Portals,
Silicon,
Minimization"
A High-Efficiency PFM Half-Bridge Converter Utilizing a Half-Bridge LLC Converter Under Light Load Conditions,"Recently, the various types of the half-bridge (HB) converters with the output inductor have been developed, and they exhibit a good performance in medium power applications such as the server power supplies and personal computer power supplies requiring high output current. However, they have common problems such as the primary and secondary switch turn-off losses and snubber loss in the secondary side caused by the output inductor, which degrades light load efficiency. To relieve these limitations of the conventional HB converters, a new HB converter, which employs one additional switch and capacitor in the secondary side, is proposed for a high efficiency under light load conditions in this paper. Since the proposed converter operates like the HB LLC converter with below operation by turning on additional switch under light load conditions, the switch turn-off losses and snubber loss can be minimized, and the zero-voltage switching (ZVS) capability can be improved. Consequently, the proposed converter can achieve a high efficiency under light load conditions. To confirm the operation, features, and validity of the proposed converter, a 330-400 V input and 12 V/300 W output laboratory prototype is built and tested.","Switches,
Inductors,
Snubbers,
Zero voltage switching,
Voltage control,
Power supplies,
Capacitors"
A call to action: Securing IEEE 1687 and the need for an IEEE test Security Standard,"Today's chips often contain a wealth of embedded instruments, including sensors, hardware monitors, built-in self-test (BIST) engines, etc. They may process sensitive data that requires encryption or obfuscation and may contain encryption keys and ChipIDs. Unfortunately, unauthorized access to internal registers or instruments through test and debug circuitry can turn design for testability (DFT) logic into a backdoor for data theft, reverse engineering, counterfeiting, and denial-of-service attacks. A compromised chip also poses a security threat to any board or system that includes that chip, and boards have their own security issues. We will provide an overview of some chip and board security concerns as they relate to DFT hardware and will briefly review several ways in which the new IEEE 1687 standard can be made more secure. We will then discuss the need for an IEEE Security Standard that can provide solutions and metrics for providing appropriate security matched to the needs of a real world environment.","Instruments,
Registers,
Encryption,
Ports (Computers),
Standards,
Microprogramming"
"A Promise of Realizable, Ultra-Scalable Communications at Nano-Scale:A Multi-Modal Nano-Machine Architecture","Wireless networks of nano-nodes will play a critical role in future medical, quality control, environmental monitoring and military applications. Nano-nodes are invisible/marginally visible to the human eye, ranging in size from approximately 100 μm to few nanometers. Nano-networking poses unique challenges, requiring ground-breaking solutions. First, the nano-scale imposes severe restrictions to the computational and communication capabilities of the nodes. Second, nano-nodes are not accessible for programming, configuration and debugging in the classical sense. Thus, a nano-network should be self-configuring, resilient and adaptive to environmental changes. Finally, all nano-networking protocols should be ultra-scalable, since a typical nano-network may comprise billions of nodes. The study contributes a novel paradigm for data dissemination in networking nano-machines, addressing these unique challenges. Relying on innovative analytical results on lattice algebra and nature-inspired processes, a novel data dissemination method is proposed. The nano-nodes exploit their environmental feedback and mature adaptively into network backbone or remain single network users. Such a process can be implemented as an ultra-scalable, low complexity, multi-modal nano-node architecture (physical layer), providing efficient networking and application services at the same time. Requiring existing manufacturing technology, the proposed architecture constitutes the first candidate solution for realizable nano-networking.",
Physical Processes and Applications of the Monte Carlo Radiative Energy Deposition (MRED) Code,"MRED is a Python-language scriptable computer application that simulates radiation transport. It is the computational engine for the on-line tool CRÈME-MC. MRED is based on c++ code from Geant4 with additional Fortran components to simulate electron transport and nuclear reactions with high precision. We provide a detailed description of the structure of MRED and the implementation of the simulation of physical processes used to simulate radiation effects in electronic devices and circuits. Extensive discussion and references are provided that illustrate the validation of models used to implement specific simulations of relevant physical processes. Several applications of MRED are summarized that demonstrate its ability to predict and describe basic physical phenomena associated with irradiation of electronic circuits and devices. These include effects from single particle radiation (including both direct ionization and indirect ionization effects), dose enhancement effects, and displacement damage effects. MRED simulations have also helped to identify new single event upset mechanisms not previously observed by experiment, but since confirmed, including upsets due to muons and energetic electrons.","Physics,
Single event upsets,
Radiation effects,
Production,
Monte Carlo methods,
Integrated circuit modeling"
Wearable soft artificial skin for hand motion detection with embedded microfluidic strain sensing,"This paper describes the design and manufacturing of soft artificial skin with an array of embedded soft strain sensors for detecting various hand gestures by measuring joint motions of five fingers. The proposed skin was made of a hyperelastic elastomer material with embedded microchannels filled with two different liquid conductors, an ionic liquid and a liquid metal. The ionic liquid microchannels were used to detect the mechanical strain changes of the sensing material, and the liquid metal microchannels were used as flexible and stretchable electrical wires for connecting the sensors to an external control circuit. The two heterogeneous liquid conductors were electrically interfaced through flexible conductive threads to prevent the two liquid from being intermixed. The skin device was connected to a computer through a microcontroller instrumentation circuit for reconstructing the 3-D hand motions graphically. The paper also presents preliminary calibration and experimental results.","Sensors,
Skin,
Liquids,
Joints,
Microchannels,
Strain,
Metals"
On a Modified DeGroot-Friedkin model of opinion dynamics,"This paper studies the opinion dynamics that result when individuals consecutively discuss a sequence of issues. Specifically, we study how individuals' self-confidence levels evolve via a reflected appraisal mechanism. Motivated by the DeGroot-Friedkin model, we propose a Modified DeGroot-Friedkin model which allows individuals to update their self-confidence levels by only interacting with their neighbors and in particular, the modified model allows the update of self-confidence levels to take place in finite time without waiting for the opinion process to reach a consensus on any particular issue. We study properties of this Modified DeGroot-Friedkin model and compare the associated equilibria and stability with those of the original DeGroot-Friedkin model. Specifically, for the case when the interaction matrix is doubly stochastic, we show that for the modified model, the vector of individuals' self-confidence levels converges to a unique nontrivial equilibrium which for each individual is equal to 1 over n, where n is the number of individuals. This implies that eventually individuals reach a democratic state.","Stochastic processes,
Appraisal,
Frequency modulation,
Stability analysis,
Matrix decomposition,
Social network services,
Atmospheric modeling"
Prioritized Planning Algorithms for Trajectory Coordination of Multiple Mobile Robots,"In autonomous multirobot systems one of the concerns is how to prevent collisions between the individual robots. One approach to this problem involves finding coordinated trajectories from start to destination for all the robots and then letting the robots follow the preplanned coordinated trajectories. A widely used practical method for finding such coordinated trajectories is “classical” prioritized planning, where robots plan sequentially one after another. This method has been shown to be effective in practice, but it is incomplete (i.e., there are solvable problem instances that the algorithm fails to solve) and it has not yet been formally analyzed under what circumstances is the method guaranteed to succeed. Further, prioritized planning is a centralized algorithm, which makes the method unsuitable for decentralized multirobot systems. The contributions of this paper are: a) an adapted version of classical prioritized planning called revised prioritized planning with a formal characterization of a class of instances that are provably solvable by this algorithm and b) an asynchronous decentralized variant of both classical and revised prioritized planning together with a formal analysis showing that the algorithm terminates and inherits completeness properties from its centralized counterpart. The experimental evaluation performed in simulation on realworld indoor maps shows that: a) the revised version of prioritized planning reliably solves a wide class of instances on which both classical prioritized planning and popular reactive technique ORCA fail and b) the asynchronous decentralized implementation of classical and revised prioritized planning finds solution in large multirobot teams up to 2x-faster than the previously proposed synchronized decentralized approach. Note to Practitioners-Consider a large warehouse in which the goods are stored and retrieved by autonomous mobile robots. One way to deal with possible collisions between the robots is to ignore interactions between the vehicles during the route planning for each robot and handle the conflicts only during the route execution. However, such an approach is prone to deadlocks, i.e., to situations during which some of the robots mutually block each other, cannot proceed and fail to complete their transportation task. An alternative approach would involve planning collision-free routes for each robot before the robots start executing them. However, the current methods that guarantee ability to find a solution to any such coordination problem are not applicable in practice due to their high computational complexity. Instead, a simple and computationally efficient approach in which robots plan their routes sequentially one after another (classical prioritized planning) is often used for finding coordinated trajectories even though the algorithm is known to fail on many dense problem instances. In this paper, we show that a simple adaptation of this classical algorithm called revised prioritized planning is guaranteed to find collision-free trajectories for a well-defined class of practical problems. In particular, if the system resembles human-made transport infrastructures by requiring that the start and destination position of each vehicle must never obstruct other vehicles from moving, then the proposed approach is guaranteed to provide a solution. For instance, in our warehouse multirobot system example, the collision-free routes can be efficiently computed by the revised prioritized planning approach. This paper formally characterizes the problem instances for which the method is guaranteed to succeed. Further, we propose a new asynchronous decentralized adaptation of both classical and revised prioritized algorithm that can be used in multirobot systems without a central solver. This technique can be used to find coordinated trajectories just by running a simple asynchronous negotiation protocol between the individual robots. This paper provides an analysis showing that the asynchronous decentralized implementations of classical and revised prioritized planning exhibit desirable theoretical properties and an experimental comparison of performance of different variations of centralized and decentralized prioritized planning algorithms.","Robot kinematics,
Trajectory,
Planning,
Collision avoidance,
Mobile robots,
Multi-robot systems"
Using Binocular Feature Combination for Blind Quality Assessment of Stereoscopic Images,"The quality assessment of 3D images is more challenging than its 2D counterparts, and little investigation has been dedicated to blind quality assessment of stereoscopic images. In this letter, we propose a novel blind quality assessment for stereoscopic images based on binocular feature combination. The prominent contribution of this work is that we simplify the process of binocular quality prediction as monocular feature encoding and binocular feature combination. Experimental results on two publicly available 3D image quality assessment databases demonstrate the promising performance of the proposed method.",
SimTrack: A simulation-based framework for scalable real-time object pose detection and tracking,"We propose a novel approach for real-time object pose detection and tracking that is highly scalable in terms of the number of objects tracked and the number of cameras observing the scene. Key to this scalability is a high degree of parallelism in the algorithms employed. The method maintains a single 3D simulated model of the scene consisting of multiple objects together with a robot operating on them. This allows for rapid synthesis of appearance, depth, and occlusion information from each camera viewpoint. This information is used both for updating the pose estimates and for extracting the low-level visual cues. The visual cues obtained from each camera are efficiently fused back into the single consistent scene representation using a constrained optimization method. The centralized scene representation, together with the reliability measures it enables, simplify the interaction between pose tracking and pose detection across multiple cameras. We demonstrate the robustness of our approach in a realistic manipulation scenario. We publicly release this work as a part of a general ROS software framework for real-time pose estimation, SimTrack, that can be integrated easily for different robotic applications.","Cameras,
Robot vision systems,
Visualization,
Robot kinematics,
Real-time systems"
Maximally Permissive Distributed Control of Large Scale Automated Manufacturing Systems Modeled With Petri Nets,"Ensuring nonblockingness remains challenging for automated manufacturing systems (AMSs) owing to their discrete event dynamics. Both scalability and maximal permissiveness are essential for the synthesis and implementation of their centralized supervisors. Inspired by the divide and conquer philosophy, this brief proposes a partition methodology and distributed control technique for large-scale AMSs. They are represented as interconnected and overlapping subsystems sharing some common components in terms of buffers. For each subsystem, a local supervisor is designed based on its local behavior and neighboring information only. Generalizing the existing results, we develop a condition under which the control law via decomposition promises the maximal permissiveness. Buffer capacities are well designed for the sake of their decomposition into multiple overlapping subsystems. Theoretical results are developed to characterize the behavior compatibility among local controllers. An experimental study illustrates the effectiveness of the proposed method.","Decentralized control,
Vectors,
Educational institutions,
Computer architecture,
Barium,
Resource management,
Monitoring"
Average-Value Modeling of Synchronous-Machine-Fed Thyristor-Controlled-Rectifier Systems,"Due to the repeated switching, the detailed switch-level models of electrical machines coupled with power-electronic converters are computationally expensive and hard to linearize for small-signal frequency-domain analysis. Average-value modeling (AVM) has become an effective tool for small-signal analysis of power electronic systems and time-domain transient studies where the details of switching are not important and can be neglected. Recently, a parametric AVM (PAVM) approach has been developed for machine/diode rectifier systems. This paper extends the parametric approach to the machine/thyristor-controlled-rectifier systems, where the thyristor firing may be referenced to either the line voltages or the rotor position. An analytical average model for this system is also developed based on the recently proposed constant-parameter voltage-behind-reactance synchronous machine model. The new PAVM is compared against the original switching system, as well as the analytical AVM. It is shown that the PAVM can accurately predict both small-signal characteristics and large-signal transients of the original switching system in light and heavy modes, which represents an advantage over the analytical models which are typically implicit.","Thyristors,
Analytical models,
Rotors,
Computational modeling,
Switches,
Integrated circuit modeling,
Transient analysis"
Posterior Linearization Filter: Principles and Implementation Using Sigma Points,"This paper is concerned with Gaussian approximations to the posterior probability density function (PDF) in the update step of Bayesian filtering with nonlinear measurements. In this setting, sigma-point approximations to the Kalman filter (KF) recursion are widely used due to their ease of implementation and relatively good performance. In the update step, these sigma-point KFs are equivalent to linearizing the nonlinear measurement function by statistical linear regression (SLR) with respect to the prior PDF. In this paper, we argue that the measurement function should be linearized using SLR with respect to the posterior rather than the prior to take into account the information provided by the measurement. The resulting filter is referred to as the posterior linearization filter (PLF). In practice, the exact PLF update is intractable but can be approximated by the iterated PLF (IPLF), which carries out iterated SLRs with respect to the best available approximation to the posterior. The IPLF can be seen as an approximate recursive Kullback-Leibler divergence minimization procedure. We demonstrate the high performance of the IPLF in relation to other Gaussian filters in two numerical examples.","Noise measurement,
Probability density function,
Approximation algorithms,
Kalman filters,
Covariance matrices,
Linear approximation"
Impedance control network resonant step-down DC-DC converter architecture,"In this paper, we introduce a step-down resonant dc-dc converter architecture based on the newly-proposed concept of an Impedance Control Network (ICN). The ICN architecture is designed to provide zero-voltage and near-zero-current switching of the power devices, and the proposed approach further uses inverter stacking techniques to reduce the voltages of individual devices. The proposed architecture is suitable for large-step-down, wide-input-range applications such as dc-dc converters for dc distribution in data centers. We demonstrate a first-generation prototype ICN resonant dc-dc converter that can deliver 330 W from a wide input voltage range of 260 V-410 V to an output voltage of 12 V.","Inverters,
Power generation,
Bridge circuits,
Rectifiers,
Impedance,
Zero voltage switching,
Windings"
A Novel Multiple-Instance Learning-Based Approach to Computer-Aided Detection of Tuberculosis on Chest X-Rays,"To reach performance levels comparable to human experts, computer-aided detection (CAD) systems are typically optimized following a supervised learning approach that relies on large training databases comprising manually annotated lesions. However, manually outlining those lesions constitutes a difficult and time-consuming process that renders detailedly annotated data difficult to obtain. In this paper, we investigate an alternative approach, namely multiple-instance learning (MIL), that does not require detailed information for optimization. We have applied MIL to a CAD system for tuberculosis detection. Only the case condition (normal or abnormal) was required during training. Based upon the well-known miSVM technique, we propose an improved algorithm that overcomes miSVM's drawbacks related to positive instance underestimation and costly iteration. To show the advantages of our MIL-based approach as compared with a traditional supervised one, experiments with three X-ray databases were conducted. The area under the receiver operating characteristic curve was utilized as a performance measure. With the first database, for which training lesion annotations were available, our MIL-based method was comparable to the supervised system (0.86 versus 0.88). When evaluating the remaining databases, given their large difference with the previous image set, the most appealing strategy was to retrain the CAD systems. However, since only the case condition was available, only the MIL-based system could be retrained. This scenario, which is common in real-world applications, demonstrates the better adaptation capabilities of the proposed approach. After retraining, our MIL-based system significantly outperformed the supervised one (0.86 versus 0.79 and 0.91 versus 0.85, p<;0.0001 and p=0.0002, respectively).","Design automation,
Training,
Lesions,
Support vector machines,
Lungs,
Vectors,
Databases"
Improving Multi-Objective Test Case Selection by Injecting Diversity in Genetic Algorithms,"A way to reduce the cost of regression testing consists of selecting or prioritizing subsets of test cases from a test suite according to some criteria. Besides greedy algorithms, cost cognizant additional greedy algorithms, multi-objective optimization algorithms, and multi-objective genetic algorithms (MOGAs), have also been proposed to tackle this problem. However, previous studies have shown that there is no clear winner between greedy and MOGAs, and that their combination does not necessarily produce better results. In this paper we show that the optimality of MOGAs can be significantly improved by diversifying the solutions (sub-sets of the test suite) generated during the search process. Specifically, we introduce a new MOGA, coined as DIversity based Genetic Algorithm (DIV-GA), based on the mechanisms of orthogonal design and orthogonal evolution that increase diversity by injecting new orthogonal individuals during the search process. Results of an empirical study conducted on eleven programs show that DIV-GA outperforms both greedy algorithms and the traditional MOGAs from the optimality point of view. Moreover, the solutions (sub-sets of the test suite) provided by DIV-GA are able to detect more faults than the other algorithms, while keeping the same test execution cost.","Optimization,
Greedy algorithms,
Testing,
Linear programming,
Genetic algorithms,
Genetics,
Sociology"
Efficient Scheduling for Video Transmissions in Maritime Wireless Communication Networks,"This paper develops a framework for vessel surveillance video uploading via maritime wideband communication networks. A broadband wireless network utilizing a time-division-multiple-access (TDMA)-based media access control protocol is employed to establish a shore-side network infrastructure, and a packet store-carry-forward routing mechanism is adopted to achieve intermittent network connectivity in maritime communications. To provide high-quality videos to the administrative authority, a resource allocation problem is formulated to maximize the throughput priority-based video transmission problem, subject to the intermittent network connections and the time indexes such as the release time and deadline of each video packet. To reduce computational complexity, time-capacity mapping is applied to transform the original resource allocation problem into a two-machine nonpreemptive scheduling problem. Three offline scheduling algorithms are proposed, namely, a time-capacity-mapping-based two-phase (TMTP) algorithm for a single machine, a TMTP algorithm for two machines, and an interval graph-theory-based job relay selection (IGTJRS) algorithm. It is mathematically proved that the IGTJRS algorithm has an approximation ratio (i.e., the ratio of the throughput of an optimal schedule to that of the IGTJRS algorithm) of 2 and time complexity of O(n2). Simulations results validate the performance of the proposed algorithms, based on real ship route traces obtained from navigation software BLM-Shipping.","Optimal scheduling,
Approximation algorithms,
Marine vehicles,
Ports (Computers),
Wideband,
Throughput,
Wireless communication"
Non-backtracking Spectrum of Random Graphs: Community Detection and Non-regular Ramanujan Graphs,"A non-backtracking walk on a graph is a directed path such that no edge is the inverse of its preceding edge. The non-backtracking matrix of a graph is indexed by its directed edges and can be used to count on-backtracking walks of a given length. It has been used recently in the context of community detection and has appeared previously in connection with the Ihara zeta function and in some generalizations of Ramanujan graphs. In this work, we study the largest eigen valus of the non-backtracking matrix of the Erdos-Renyi random graph and of the Stochastic Block Model in the regime where the number of edges is proportional to the number of vertices. Our results confirm the ""spectral redemption conjecture"" that community detection can be made on the basis of the leading eigenvectors above the feasibility threshold.","Eigenvalues and eigenfunctions,
Stochastic processes,
Symmetric matrices,
Image edge detection,
Electronic mail,
Context,
Belief propagation"
A Stochastic Model for Estimating the Power Consumption of a Processor,"Quantitatively estimating the relationship between the workload and the corresponding power consumption of a multicore processor is an essential step towards achieving energy proportional computing. Most existing and proposed approaches use Performance Monitoring Counters (Hardware Monitoring Counters) for this task. In this paper we propose a complementary approach that employs the statistics of CPU utilization (workload) only. Hence, we model the workload and the power consumption of a multicore processor as random variables and exploit the monotonicity property of their distribution functions to establish a quantitative relationship between the random variables. We will show that for a single-core processor the relationship is best approximated by a quadratic function whereas for a dualcore processor, the relationship is best approximated by a linear function. We will demonstrate the plausibility of our approach by estimating the power consumption of both custom-made and standard benchmarks (namely, the SPEC power benchmark and the Apache benchmarking tool) for an Intel and AMD processors.","Power demand,
Radiation detectors,
Central Processing Unit,
Multicore processing,
Monitoring,
Stochastic processes,
Computational modeling"
Towards Maximizing Timely Content Delivery in Delay Tolerant Networks,"Many applications, such as product promotion advertisement and traffic congestion notification, benefit from opportunistic content exchange in Delay Tolerant Networks (DTNs). An important requirement of such applications is timely delivery. However, the intermittent connectivity of DTNs may significantly delay content exchange, and cannot guarantee timely delivery. The state-of-the-arts capture mobility patterns or social properties of mobile devices. Such solutions do not capture patterns of delivered content in order to optimize content delivery. Without such optimization, the content demanded by a large number of subscribers could follow the same forwarding path as the content by only one subscriber, leading to traffic congestion and packet drop. To address the challenge, in this paper, we develop a solution framework, namely Ameba, for timely delivery. In detail, we first leverage content properties to derive an optimal routing hop count of each content to maximize the number of needed nodes. Next, we develop node utilities to capture interests, capacity and locations of mobile devices. Finally, the distributed forwarding scheme leverages the optimal routing hop count and node utilities to deliver content towards the needed nodes in a timely manner. Illustrative results verify that Ameba achieves comparable delivery ratio as Epidemic but with much lower overhead.","Nickel,
Mobile handsets,
Relays,
Histograms,
Equations,
Delays,
Educational institutions"
Big Heart Data: Advancing Health Informatics Through Data Sharing in Cardiovascular Imaging,"The burden of heart disease is rapidly worsening due to the increasing prevalence of obesity and diabetes. Data sharing and open database resources for heart health informatics are important for advancing our understanding of cardiovascular function, disease progression and therapeutics. Data sharing enables valuable information, often obtained at considerable expense and effort, to be reused beyond the specific objectives of the original study. Many government funding agencies and journal publishers are requiring data reuse, and are providing mechanisms for data curation and archival. Tools and infrastructure are available to archive anonymous data from a wide range of studies, from descriptive epidemiological data to gigabytes of imaging data. Meta-analyses can be performed to combine raw data from disparate studies to obtain unique comparisons or to enhance statistical power. Open benchmark datasets are invaluable for validating data analysis algorithms and objectively comparing results. This review provides a rationale for increased data sharing and surveys recent progress in the cardiovascular domain. We also highlight the potential of recent large cardiovascular epidemiological studies enabling collaborative efforts to facilitate data sharing, algorithms benchmarking, disease modeling and statistical atlases.",
PWDGR: Pair-Wise Directional Geographical Routing Based on Wireless Sensor Network,"Multipath routing in wireless multimedia sensor network makes it possible to transfer data simultaneously so as to reduce delay and congestion and it is worth researching. However, the current multipath routing strategy may cause problem that the node energy near sink becomes obviously higher than other nodes which makes the network invalid and dead. It also has serious impact on the performance of wireless multimedia sensor network (WMSN). In this paper, we propose a pair-wise directional geographical routing (PWDGR) strategy to solve the energy bottleneck problem. First, the source node can send the data to the pair-wise node around the sink node in accordance with certain algorithm and then it will send the data to the sink node. These pair-wise nodes are equally selected in 360° scope around sink according to a certain algorithm. Therefore, it can effectively relieve the serious energy burden around Sink and also make a balance between energy consumption and end-to-end delay. Theoretical analysis and a lot of simulation experiments on PWDGR have been done and the results indicate that PWDGR is superior to the proposed strategies of the similar strategies both in the view of the theory and the results of those simulation experiments. With respect to the strategies of the same kind, PWDGR is able to prolong 70% network life. The delay time is also measured and it is only increased by 8.1% compared with the similar strategies.","Routing,
Energy consumption,
Quality of service,
Routing protocols,
Internet of Things,
Intelligent sensors,
Wireless sensor networks,
Geography,
Biomedical monitoring,
Medical services,
Medical devices"
Crosstalk Noise in WDM-Based Optical Networks-on-Chip: A Formal Study and Comparison,"Optical networks-on-chip (ONoCs) using wavelength-division multiplexing (WDM) technology have progressively attracted more and more attention for their use in tackling the high-power consumption and low bandwidth issues in growing metallic interconnection networks in multiprocessor systems-on-chip. However, the basic optical devices employed to construct WDM-based ONoCs are imperfect and suffer from inevitable power loss and crosstalk noise. Furthermore, when employing WDM, optical signals of various wavelengths can interfere with each other through different optical switching elements within the network, creating crosstalk noise. As a result, the crosstalk noise in large-scale WDM-based ONoCs accumulates and causes severe performance degradation, restricts the network scalability, and considerably attenuates the signal-to-noise ratio (SNR). In this paper, we systematically study and compare the worst case as well as the average crosstalk noise and SNR in three well-known optical interconnect architectures, mesh-based, folded-torus-based, and fat-tree-based ONoCs using WDM. The analytical models for the worst case and the average crosstalk noise and SNR in the different architectures are presented. Furthermore, the proposed analytical models are integrated into a newly developed crosstalk noise and loss analysis platform (CLAP) to analyze the crosstalk noise and SNR in WDM-based ONoCs of any network size using an arbitrary optical router. Utilizing CLAP, we compare the worst case as well as the average crosstalk noise and SNR in different WDM-based ONoC architectures. Furthermore, we indicate how the SNR changes in respect to variations in the number of optical wavelengths in use, the free-spectral range, and the microresonators Q factor. The analyses' results demonstrate that the crosstalk noise is of critical concern to WDM-based ONoCs: in the worst case, the crosstalk noise power exceeds the signal power in all three WDM-based ONoC architectures, even when the number of processor cores is small, e.g., 64.","Optical crosstalk,
Optical noise,
Crosstalk,
Optical waveguides,
Signal to noise ratio,
Optical modulation,
Optical losses"
Rule Extraction From Support Vector Machines Using Ensemble Learning Approach: An Application for Diagnosis of Diabetes,"Diabetes mellitus is a chronic disease and a worldwide public health challenge. It has been shown that 50-80% proportion of T2DM is undiagnosed. In this paper, support vector machines are utilized to screen diabetes, and an ensemble learning module is added, which turns the “black box” of SVM decisions into comprehensible and transparent rules, and it is also useful for solving imbalance problem. Results on China Health and Nutrition Survey data show that the proposed ensemble learning method generates rule sets with weighted average precision 94.2% and weighted average recall 93.9% for all classes. Furthermore, the hybrid system can provide a tool for diagnosis of diabetes, and it supports a second opinion for lay users.","Support vector machines,
Diabetes,
Radio frequency,
Data models,
Predictive models,
Accuracy,
Decision trees"
Real-Time Load Elasticity Tracking and Pricing for Electric Vehicle Charging,"While electric vehicles (EVs) are expected to provide environmental and economical benefit, judicious coordination of EV charging is necessary to prevent overloading of the distribution grid. Leveraging the smart grid infrastructure, the utility company can adjust the electricity price intelligently for individual customers to elicit desirable load curves. In this context, this paper addresses the problem of predicting the EV charging behavior of the consumers at different prices, which is a prerequisite for optimal price adjustment. The dependencies on price responsiveness among consumers are captured by a conditional random field (CRF) model. To account for temporal dynamics potentially in a strategic setting, the framework of online convex optimization is adopted to develop an efficient online algorithm for tracking the CRF parameters. The proposed model is then used as an input to a stochastic profit maximization module for real-time price setting. Numerical tests using simulated and semi-real data verify the effectiveness of the proposed approach.","Real-time systems,
Elasticity,
Load modeling,
Heuristic algorithms,
Pricing,
Stochastic processes,
Electricity"
Transport-based single frame super resolution of very low resolution face images,"Extracting high-resolution information from highly degraded facial images is an important problem with several applications in science and technology. Here we describe a single frame super resolution technique that uses a transport-based formulation of the problem. The method consists of a training and a testing phase. In the training phase, a nonlinear Lagrangian model of high-resolution facial appearance is constructed fully automatically. In the testing phase, the resolution of a degraded image is enhanced by finding the model parameters that best fit the given low resolution data. We test the approach on two face datasets, namely the extended Yale Face Database B and the AR face datasets, and compare it to state of the art methods. The proposed method outperforms existing solutions in problems related to enhancing images of very low resolution.","Face,
Training,
Image reconstruction,
Mathematical model,
Image resolution,
Jacobian matrices,
Computational modeling"
Design and Implementation of a Journaling File System for Phase-Change Memory,"Journaling file systems are widely used in modern computer systems as they provide high reliability at reasonable cost. However, existing journaling file systems are not efficient for emerging PCM (phase-change memory) storage because they are optimized for hard disks. Specifically, the large amount of data that they write during journaling degrades the performance of PCM storage seriously as it has a long write latency. In this paper, we present a new journaling file system for PCM, called Shortcut-JFS, that reduces write traffic to PCM by more than half of existing journaling file systems running on block I/O interfaces. To do this, we devise two novel schemes that can be used under byte-addressable I/O interfaces: 1) differential logging that journals only the modified part of a block and 2) in-place checkpointing that eliminates the overhead of block copying. We implement Shortcut-JFS on Linux 2.6.32 and measure the performance of Shortcut-JFS compared to those of existing journaling and log-structured file systems. The results show that the performance improvement of Shortcut-JFS against Ext4 and LFS is 54 and 96 percent, respectively, on average.","File systems,
Checkpointing,
Phase change materials,
Computer crashes,
Phase change memory,
Reliability,
Hard disks"
On Studying the Impact of Uncertainty on Behavior Diffusion in Social Networks,"Unlike traditional epidemic virus spreading, behavior diffusion in social networks is conducted by rational users, who would make strategic choices instead of being randomly infected with some probability. Specifically, individuals always try to maximize their utilities through rationally selecting specific behaviors (adopting a new product, or spreading a rumor, etc.). However, utility obtained by an individual, naturally contains uncertainty, and it may stem from two sources: users' imperfect and incomplete knowledge about others, and the inherently stochastic property in human behavior. Thus, it is imperative to model and analyze the diffusion pattern under the resulting uncertainty in social networks, which, however, has not yet been deeply examined by the existing works. This paper deeply explores the pattern of gossip diffusion in social networks when uncertainty exists in users' decision making. In detail, the innovative results provided in this paper are: first, inspired by random utility theory, we formulate the diffusion model based on mixed logit model that allows for user's uncertainty in determining whether to adopt a specific strategy; second, the formal analysis framework characterizing the diffusion process is derived through the approximation method of mean field theory; finally, we explore the extensive applicability of our proposed analysis framework through modeling rumor diffusion in social networks as a coordination game. Our findings are, for various structural characteristics, small uncertainty can significantly speed up the diffusion of gossip; furthermore, social networks with scale-free property can facilitate the gossip diffusion in the easiest way, but, the range of uncertainty factor that can maximize gossip diffusion is the smallest. The obtained results perfectly comply with the philosophical saying about rumor diffusion in real social life: easy come, easy go.",
An Energy-Efficient Adaptive Sensing Framework for Gait Monitoring Using Smart Insole,"Gait analysis is an important process to gauge human motion. Recently, longitudinal gait analysis received much attention from the medical and healthcare domains. The challenge in studies over extended time periods is the battery life. Due to the continuous sensing and computing, wearable gait devices cannot fulfill a full-day work schedule. In this paper, we present an energy-efficient adaptive sensing framework to address this problem. Through presampling for content understanding, a selective sensing and sparsity-based signal reconstruction method is proposed. In particular, we develop and implement the new sensing scheme in a smart insole system to reduce the number of samples, while still preserving the information integrity of gait parameters. Experimental results show the effectiveness of our method in data point reduction. Our proposed method improves the battery life to 10.47 h, while normalized mean square error is within 10%.",
Intensity-Based Visual Servoing for Instrument and Tissue Tracking in 3D Ultrasound Volumes,"This paper presents a three dimensional ultrasound (3DUS)-based visual servoing technique for intraoperative tracking of the motion of both surgical instruments and tissue targets. In the proposed approach, visual servoing techniques are used to control the position of a virtual ultrasound probe so as to keep a target centered within the virtual probe's field-of-view. Multiple virtual probes can be servoed in parallel to provide simultaneous tracking of instruments and tissue. The technique is developed in the context of robotic beating-heart intracardiac surgery in which the goal of tracking is to both provide guidance to the operator as well as to provide the means to automate the surgical procedure. To deal with the low signal-to-noise ratio (SNR) of the 3DUS volumes, an intensity-based method is proposed that requires no primitive extraction or image segmentation since it directly utilizes the image intensity information as a visual feature. This approach is computationally efficient and can be applied to a wide range of tissue types and medical instruments. This paper presents the first validation of these techniques through offline robot and tissue tracking using actual in vivo cardiac volume sequences from a robotic beating-heart surgery.","Three-dimensional displays,
Probes,
Target tracking,
Visualization,
Visual servoing"
RSTFC: A Novel Algorithm for Spatio-Temporal Filtering and Classification of Single-Trial EEG,"Learning optimal spatio-temporal filters is a key to feature extraction for single-trial electroencephalogram (EEG) classification. The challenges are controlling the complexity of the learning algorithm so as to alleviate the curse of dimensionality and attaining computational efficiency to facilitate online applications, e.g., brain-computer interfaces (BCIs). To tackle these barriers, this paper presents a novel algorithm, termed regularized spatio-temporal filtering and classification (RSTFC), for single-trial EEG classification. RSTFC consists of two modules. In the feature extraction module, an l2-regularized algorithm is developed for supervised spatio-temporal filtering of the EEG signals. Unlike the existing supervised spatio-temporal filter optimization algorithms, the developed algorithm can simultaneously optimize spatial and high-order temporal filters in an eigenvalue decomposition framework and thus be implemented highly efficiently. In the classification module, a convex optimization algorithm for sparse Fisher linear discriminant analysis is proposed for simultaneous feature selection and classification of the typically high-dimensional spatio-temporally filtered signals. The effectiveness of RSTFC is demonstrated by comparing it with several state-of-the-arts methods on three brain-computer interface (BCI) competition data sets collected from 17 subjects. Results indicate that RSTFC yields significantly higher classification accuracies than the competing methods. This paper also discusses the advantage of optimizing channel-specific temporal filters over optimizing a temporal filter common to all channels.","Electroencephalography,
Feature extraction,
Optimization,
Algorithm design and analysis,
Eigenvalues and eigenfunctions,
Covariance matrices,
Linear programming"
Service Operator-Aware Trust Scheme for Resource Matchmaking across Multiple Clouds,"This paper proposes a service operator-aware trust scheme (SOTS) for resource matchmaking across multiple clouds. Through analyzing the built-in relationship between the users, the broker, and the service resources, this paper proposes a middleware framework of trust management that can effectively reduces user burden and improve system dependability. Based on multidimensional resource service operators, we model the problem of trust evaluation as a process of multi-attribute decision-making, and develop an adaptive trust evaluation approach based on information entropy theory. This adaptive approach can overcome the limitations of traditional trust schemes, whereby the trusted operators are weighted manually or subjectively. As a result, using SOTS, the broker can efficiently and accurately prepare the most trusted resources in advance, and thus provide more dependable resources to users. Our experiments yield interesting and meaningful observations that can facilitate the effective utilization of SOTS in a large-scale multi-cloud environment.",
Exploiting Partially-Forgetful Memories for Approximate Computing,"While the memory subsystem is already a major contributor to energy consumption of embedded systems, the guard-banding required for masking the effects of ever increasing manufacturing variations in memories imposes even more energy overhead. In this letter, we explore how partially-forgetful memories can be used by exploiting the intrinsic tolerance of a vast class of applications to some level of error for relaxing this guard-banding in memories. We discuss the challenges to be addressed and introduce relaxed cache as an exemplar to address these challenges for partially-forgetful SRAM caches. Preliminary results show how adapting guard-bands to application characteristics can help the system save significant amount of cache leakage energy (up to 74%) while still generating acceptable quality results.","Hardware,
Software,
PSNR,
Random access memory,
Reliability,
Benchmark testing,
Data structures"
Theory and Design of Multizone Soundfield Reproduction Using Sparse Methods,"Multizone soundfield reproduction over an extended spatial region is a challenging problem in acoustic signal processing. We introduce a method of reproducing a multizone soundfield within a desired region in reverberant environments. It is based on the identification of the acoustic transfer function (ATF) from the loudspeaker over the desired reproduction region using a limited number of microphone measurements. We assume that the soundfield is sparse in the domain of planewave decomposition and identify the ATF using sparse methods. The estimates of the ATFs are then used to derive the optimal least-squares solution for the loudspeaker filters that minimize the reproduction error over the entire reproduction region. Simulations confirm that the method leads to a significantly reduced number of required microphones for accurate multizone sound reproduction, while it also facilitates the reproduction over a wide frequency range. Practical experiments are used to verify the sparse planewave representation of the reverberant soundfield in a real-world listening environment.","Loudspeakers,
Microphones,
Speech processing,
Harmonic analysis,
Approximation methods,
Acoustic noise,
Sparse matrices"
Tejas: A java based versatile micro-architectural simulator,"In this paper, we present the design of a new Java based, cycle-accurate, heterogeneous architectural simulator, Tejas. Tejas is a trace driven simulator, which is platform-independent. It can simulate binaries in any ISA and corresponding to virtually any operating system. It can itself run on virtually any machine. It is one of the fastest cycle accurate simulators available in academia. This is achieved through employing optimized data structures, improving the simulator's cache locality, and reducing the amount of wasteful work done. Tejas offers a rich library of architectural features that are modular and highly configurable. Tejas has been validated against real hardware (Dell PowerEdge R620 server) and has been shown to be more accurate than some of the most popular architectural simulators.","Chlorine,
Sockets,
Weaving,
Analytical models"
Synchrophasor-Based Auxiliary Controller to Enhance the Voltage Stability of a Distribution System With High Renewable Energy Penetration,"Wind energy is highly location-dependent. Many desirable wind resources in North America are located in rural areas without direct access to the transmission grid. By connecting megawatt-scale wind turbines to the distribution system, the cost of building transmission facilities can be avoided and wind power supplied to consumers can be greatly increased; however, integrating megawatt-scale wind turbines on distribution feeders will impact the distribution feeder stability, especially voltage stability. Distributed wind turbine generators (WTGs) have the capability to aid in grid stability if equipped with appropriate controllers, but few investigations are focusing on this. This paper investigates the potential of using real-time measurements from distribution phasor measurement units for a new WTG control algorithm to stabilize the voltage deviation of a distribution feeder. This paper proposes a novel auxiliary coordinated-control approach based on a support vector machine (SVM) predictor and a multiple-input and multiple-output model predictive control on linear time-invariant and linear time-variant systems. The voltage condition of the distribution system is predicted by the SVM classifier using synchrophasor measurement data. The controllers equipped on WTGs are triggered by the prediction results. The IEEE 13-bus distribution system with WTGs is used to validate and evaluate the proposed auxiliary control approach.","Power system stability,
Support vector machines,
Stability analysis,
Voltage control,
Phasor measurement units,
Vectors,
Voltage measurement"
Quantitative Evaluation of Model-Driven Performance Analysis and Simulation of Component-Based Architectures,"During the last decade, researchers have proposed a number of model transformations enabling performance predictions. These transformations map performance-annotated software architecture models into stochastic models solved by analytical means or by simulation. However, so far, a detailed quantitative evaluation of the accuracy and efficiency of different transformations is missing, making it hard to select an adequate transformation for a given context. This paper provides an in-depth comparison and quantitative evaluation of representative model transformations to, e.g., queueing petri nets and layered queueing networks. The semantic gaps between typical source model abstractions and the different analysis techniques are revealed. The accuracy and efficiency of each transformation are evaluated by considering four case studies representing systems of different size and complexity. The presented results and insights gained from the evaluation help software architects and performance engineers to select the appropriate transformation for a given context, thus significantly improving the usability of model transformations for performance prediction.",
Sequential and adaptive sampling for matrix completion in network monitoring systems,"End-to-end network monitoring is essential to ensure transmission quality for Internet applications. However, in large-scale networks, full-mesh measurement of network performance between all transmission pairs is infeasible. As a newly emerging sparsity representation technique, matrix completion allows the recovery of a low-rank matrix using only a small number of random samples. Existing schemes often fix the number of samples assuming the rank of the matrix is known, while the data features thus the matrix rank vary over time. In this paper, we propose to exploit the matrix completion techniques to derive the end-to-end network performance among all node pairs by only measuring a small subset of end-to-end paths. To address the challenge of rank change in the practical system, we propose a sequential and information-based adaptive sampling scheme, along with a novel sampling stopping condition. Our scheme is based only on the data observed without relying on the reconstruction method or the knowledge on the sparsity of unknown data. We have performed extensive simulations based on real-world trace data, and the results demonstrate that our scheme can significantly reduce the measurement cost while ensuring high accuracy in obtaining the whole network performance data.","Monitoring,
Sparse matrices,
Matrix decomposition,
Computers,
Accuracy,
Conferences,
Internet"
Multi-Valued Decision Diagram-Based Reliability Analysis of k -out-of-n Cold Standby Systems Subject to Scheduled Backups,"To improve the system reliability while conserving the limited system resources, cold standby sparing is often used. In computing tasks, because active components fail randomly, and the standby component has to pick up the mission task whenever required, scheduled backups are often implemented to save the completed portions of the task. The backups can facilitate an effective system recovery where the standby component can take over the mission task from the last backup point instead of resuming the mission task from the very beginning. This paper considers a k-out-of- n cold standby system subject to scheduled backups, where k components are online and operating, with the remaining components waiting in the unpowered, cold standby mode. Whenever an online component fails, a cold standby component is activated to take over the mission task from the last backup point. The backup intervals are deterministic, but can be even or uneven. As the component may fail due to an imperfect switching from the standby state to the fully powered up state, the switching failure is also considered in the system model. A multi-valued decision diagram (MDD)-based analytical approach is proposed to evaluate the reliability of the considered system, and its complexity is analyzed. The proposed method is applicable to systems with non-identical components following arbitrary lifetime distributions. Examples are given to illustrate the MDD-based method. The correctness and efficiency of the proposed method are verified using Monte Carlo simulations.","Switches,
Redundancy,
Analytical models,
Mathematical model,
Educational institutions,
Equations"
Iterative Convex Refinement for Sparse Recovery,"In this letter, we address sparse signal recovery in a Bayesian framework where sparsity is enforced on reconstruction coefficients via probabilistic priors. In particular, we focus on the setup of Yen who employ a variant of spike and slab prior to encourage sparsity. The optimization problem resulting from this model has broad applicability in recovery and regression problems and is known to be a hard non-convex problem whose existing solutions involve simplifying assumptions and/or relaxations. We propose an approach called Iterative Convex Refinement (ICR) that aims to solve the aforementioned optimization problem directly allowing for greater generality in the sparse structure. Essentially, ICR solves a sequence of convex optimization problems such that sequence of solutions converges to a sub-optimal solution of the original hard optimization problem. We propose two versions of our algorithm: a.) an unconstrained version, and b.) with a non-negativity constraint on sparse coefficients, which may be required in some real-world problems. Experimental validation is performed on both synthetic data and for a real-world image recovery problem, which illustrates merits of ICR over state of the art alternatives.","Optimization,
Bayes methods,
Slabs,
Signal processing algorithms,
Approximation methods,
Image reconstruction,
Dictionaries"
Detecting Surgical Tools by Modelling Local Appearance and Global Shape,"Detecting tools in surgical videos is an important ingredient for context-aware computer-assisted surgical systems. To this end, we present a new surgical tool detection dataset and a method for joint tool detection and pose estimation in 2d images. Our two-stage pipeline is data-driven and relaxes strong assumptions made by previous works regarding the geometry, number, and position of tools in the image. The first stage classifies each pixel based on local appearance only, while the second stage evaluates a tool-specific shape template to enforce global shape. Both local appearance and global shape are learned from training data. Our method is validated on a new surgical tool dataset of 2 476 images from neurosurgical microscopes, which is made freely available. It improves over existing datasets in size, diversity and detail of annotation. We show that our method significantly improves over competitive baselines from the computer vision field. We achieve 15% detection miss-rate at 10^{-1}
false positives per image (for the suction tube) over our surgical tool dataset. Results indicate that performing semantic labelling as an intermediate task is key for high quality detection.","Surgery,
Shape,
Semantics,
Videos,
Instruments,
Labeling,
Support vector machines"
Finding top-k local users in geo-tagged social media data,"Social network platforms and location-based services are increasingly popular in people's daily lives. The combination of them results in location-based social media where people are connected not only through the friendship in the social network but also by their geographical locations in reality. This duality makes it possible to query and make use of social media data in novel ways. In this work, we formulate a novel and useful problem called top-k local user search (TkLUS for short) from tweets with geo-tags. Given a location q, a distance r, and a set of keywords W, the TkLUS query finds the top-k users who have posted tweets relevant to the desired keywords in W at a place within the distance r from q. TkLUS queries are useful in many application scenarios such as friend recommendation, spatial decision, etc. We design a set of techniques to answer such queries efficiently. First, we propose two local user ranking methods that integrate text relevance and location proximity in a TkLUS query. Second, we construct a hybrid index under a scalable framework, which is aware of keywords as well as locations, to organize high volume geo-tagged tweets. Furthermore, we devise two algorithms for processing TkLUS queries. Finally, we conduct an experimental study using real tweet data sets to evaluate the proposed techniques. The experimental results demonstrate the efficiency, effectiveness and scalability of our proposals.","Media,
Twitter,
Instruction sets,
Indexing"
Noncontact Multiple Heartbeats Detection and Subject Localization Using UWB Impulse Doppler Radar,"In this letter, a phase-based algorithm based on a logarithmic method, applicable to UWB radars and suitable to real-time monitoring, is proposed to detect the phase variations of reflected pulses caused by the tiny cardiac motions. Compared with conventional FFT vital signs detection method, this algorithm demonstrates advantage in respiration harmonics suppression and avoidance of intermodulation between respiration and heartbeat signals. Furthermore, it is experimentally shown that UWB Doppler radar is capable of multiple heartbeats detection and subject identification/localization.","Ultra wideband radar,
Heart beat,
Doppler radar,
Harmonic analysis,
Heart rate detection"
Three Dimensional Data-Driven Multi Scale Atomic Representation of Optical Coherence Tomography,"In this paper, we discuss about applications of different methods for decomposing a signal over elementary waveforms chosen in a family called a dictionary (atomic representations) in optical coherence tomography (OCT). If the representation is learned from the data, a nonparametric dictionary is defined with three fundamental properties of being data-driven, applicability on 3D, and working in multi-scale, which make it appropriate for processing of OCT images. We discuss about application of such representations including complex wavelet based K-SVD, and diffusion wavelets on OCT data. We introduce complex wavelet based K-SVD to take advantage of adaptability in dictionary learning methods to improve the performance of simple dual tree complex wavelets in speckle reduction of OCT datasets in 2D and 3D. The algorithm is evaluated on 144 randomly selected slices from twelve 3D OCTs taken by Topcon 3D OCT-1000 and Cirrus Zeiss Meditec. Improvement of contrast to noise ratio (CNR) (from 0.9 to 11.91 and from 3.09 to 88.9, respectively) is achieved. Furthermore, two approaches are proposed for image segmentation using diffusion. The first method is designing a competition between extended basis functions at each level and the second approach is defining a new distance for each level and clustering based on such distances. A combined algorithm, based on these two methods is then proposed for segmentation of retinal OCTs, which is able to localize 12 boundaries with unsigned border positioning error of 9.22 ±3.05 μm, on a test set of 20 slices selected from 13 3D OCTs.","Three-dimensional displays,
Dictionaries,
Wavelet transforms,
Noise reduction,
Image segmentation,
Adaptive optics"
Robust and Computationally Lightweight Autonomous Tracking of Vehicle Taillights and Signal Detection by Embedded Smart Cameras,"An important aspect of collision avoidance and driver assistance systems, as well as autonomous vehicles, is the tracking of vehicle taillights and the detection of alert signals (turns and brakes). In this paper, we present the design and implementation of a robust and computationally lightweight algorithm for a real-time vision system, capable of detecting and tracking vehicle taillights, recognizing common alert signals using a vehicle-mounted embedded smart camera, and counting the cars passing on both sides of the vehicle. The system is low-power and processes scenes entirely on the microprocessor of an embedded smart camera. In contrast to most existing work that addresses either daytime or nighttime detection, the presented system provides the ability to track vehicle taillights and detect alert signals regardless of lighting conditions. The mobile vision system has been tested in actual traffic scenes and the results obtained demonstrate the performance and the lightweight nature of the algorithm.",
A Transaction and QoS-Aware Service Selection Approach Based on Genetic Algorithm,"As there are various risks of failure in its execution, a composite web service (CWS) requires a transactional mechanism to guarantee its reliable execution. Though the existing service selection methods have considered that its transactional properties may affect its quality of service (QoS) such as its execution time, some of these methods can just give the locally optimal transactional CWS while others can give globally optimal CWS only under a given fixed transactional workflow. This paper addresses the issue of selecting and composing web services via a genetic algorithm (GA) and gives a transaction and QoS-aware selection approach. First, it introduces transactional properties of a single web service and CWS and the transactional rules used to compose them. Next, it conducts the performance analysis of basic workflow patterns such as sequential, parallel, selectable, and loop patterns and develops an algorithm to compute the execution time of a complex CWS. Then, it presents a GA-based approach, which takes into account the execution time, price, transactional property, stability, and penalty-factor, to achieve globally optimal service selection. Finally, this paper reports experimental results that compare the proposed approach with the exhaustive search algorithm, transactional-QoS-driven selection algorithm, and transactional service selection algorithm. The experimental results show that the proposed algorithm is efficient and effective and can give a globally optimal transactional CWS.","Quality of service,
Optimization,
Genetic algorithms,
Performance evaluation,
Web services,
Performance analysis,
Automata"
An Efficient Framework for Generating Storyline Visualizations from Streaming Data,"This paper presents a novel framework for applying storyline visualizations to streaming data. The framework includes three components: a new data management scheme for processing and storing the incoming data, a layout construction algorithm specifically designed for incrementally generating storylines from streaming data, and a layout refinement algorithm for improving the legibility of the visualization. By dividing the layout computation to two separate components, one for constructing and another for refining, our framework effectively provides the users with the ability to follow and reason dynamic data. The evaluation studies of our storyline visualization framework demonstrate its efficacy to present streaming data as well as its superior performance over existing methods in terms of both computational efficiency and visual clarity.","Data visualization,
Layout,
Algorithm design and analysis,
Visualization,
Feeds,
Optimization,
Social network services"
Maximizing Constrained Capacity of Power-Imbalanced Optical Wireless MIMO Communications Using Spatial Modulation,"In this paper, we present a constellation optimization technique that can be invoked for optical spatial modulation (OSM) multiple-input multiple-output (MIMO) systems within the context of optical wireless (OW) systems that is designed to negate the high channel correlation imposed on conventional OSM schemes. More specifically, the proposed unified OSM architecture relies on power-imbalanced (PI) multiple transmit light sources. Furthermore, we formulate the constrained capacity of the proposed PI-OSM scheme, and then provide the design guidelines of our OSM scheme's PI constellation, in which the parameters have been optimized to ensure the associated constrained capacity is maximized. Our simulation results demonstrate that our proposed scheme is capable of outperforming conventional OSM and OW-MIMO schemes over a wide range of signal-to-noise ratios.","Light sources,
Signal to noise ratio,
Optical transmitters,
Receivers,
Photodetectors,
Modulation"
Boolean Satisfiability Solvers and Their Applications in Model Checking,"Boolean satisfiability (SAT)-the problem of determining whether there exists an assignment satisfying a given Boolean formula-is a fundamental intractable problem in computer science. SAT has many applications in electronic design automation (EDA), notably in synthesis and verification. Consequently, SAT has received much attention from the EDA community, who developed algorithms that have had a significant impact on the performance of SAT solvers. EDA researchers introduced techniques such as conflict-driven clause learning, novel branching heuristics, and efficient unit propagation. These techniques form the basis of all modern SAT solvers. Using these ideas, contemporary SAT solvers can often handle practical instances with millions of variables and constraints. The continuing advances of SAT solvers are the driving force of modern model checking tools, which are used to check the correctness of hardware designs. Contemporary automated verification techniques such as bounded model checking, proof-based abstraction, interpolation-based model checking, and IC3 have in common that they are all based on SAT solvers and their extensions. In this paper, we trace the most important contributions made to modern SAT solvers by the EDA community, and discuss applications of SAT in hardware model checking.","Model checking,
Boolean functions,
Data structures,
Context modeling,
Algorithm design and analysis,
Automatic test pattern generation,
Computer science"
A Trust-Based Privacy-Preserving Friend Recommendation Scheme for Online Social Networks,"Online social networks (OSNs), which attract thousands of million people to use everyday, greatly extend OSN users' social circles by friend recommendations. OSN users' existing social relationship can be characterized as 1-hop trust relationship, and further establish a multi-hop trust chain during the recommendation process. As the same as what people usually experience in the daily life, the social relationship in cyberspaces are potentially formed by OSN users' shared attributes, e.g., colleagues, family members, or classmates, which indicates the attribute-based recommendation process would lead to more fine-grained social relationships between strangers. Unfortunately, privacy concerns raised in the recommendation process impede the expansion of OSN users' friend circle. Some OSN users refuse to disclose their identities and their friends' information to the public domain. In this paper, we propose a trust-based privacy-preserving friend recommendation scheme for OSNs, where OSN users apply their attributes to find matched friends, and establish social relationships with strangers via a multi-hop trust chain. Based on trace-driven experimental results and security analysis, we have shown the feasibility and privacy preservation of our proposed scheme.","Privacy,
Social network services,
Vectors,
Cryptography,
Educational institutions,
Electronic mail"
Compiler-Assisted Refresh Minimization for Volatile STT-RAM Cache,"Spin-transfer torque RAM (STT-RAM) has been proposed to build on-chip caches because of its attractive features such as high storage density and ultra low leakage power. However, long write latency and high write energy are the two challenges for STT-RAM. Recently, researchers propose to improve the write performance of STT-RAM by relaxing its non-volatility property. To avoid data losses resulting from volatility, refresh schemes have been proposed. However, refresh operations consume additional overhead. In this paper, we propose to significantly reduce the number of refresh operations through re-arranging program data layout at compilation time. An N-refresh scheme is also proposed to further reduce the number of refreshes. Experimental results show that, on average, the proposed methods can reduce the number of refresh operations by 84.2 percent, and reduce the dynamic energy consumption by 38.0 percent for volatile STT-RAM caches while incurring only 4.1 percent performance degradation.","Equations,
Layout,
Random access memory,
Educational institutions,
Resource management,
Mathematical model,
Silicon"
Emerging Trends in Design and Applications of Memory-Based Computing and Content-Addressable Memories,"Content-addressable memory (CAM) and associative memory (AM) are types of storage structures that allow searching by content as opposed to searching by address. Such memory structures are used in diverse applications ranging from branch prediction in a processor to complex pattern recognition. In this paper, we review the emerging challenges and opportunities in implementing different varieties of CAM/AM structures. Beyond-CMOS silicon and nonsilicon memory technologies hold significant promise in implementing dense, fast, and energy-efficient CAM/AM structures. We describe circuit/architecture level implementations of CAM/AM using these technologies, as well as novel applications in different domains, including informatics, text analytics, data mining, and reconfigurable computing platforms.","Computer aided manufacturing,
Random access memory,
Transistors,
Computer architecture,
Market research,
Information processing,
Memory management,
Content management"
StructSLAM: Visual SLAM With Building Structure Lines,"We propose a novel 6-degree-of-freedom (DoF) visual simultaneous localization and mapping (SLAM) method based on the structural regularity of man-made building environments. The idea is that we use the building structure lines as features for localization and mapping. Unlike other line features, the building structure lines encode the global orientation information that constrains the heading of the camera over time, eliminating the accumulated orientation errors and reducing the position drift in consequence. We extend the standard extended Kalman filter visual SLAM method to adopt the building structure lines with a novel parameterization method that represents the structure lines in dominant directions. Experiments have been conducted in both synthetic and real-world scenes. The results show that our method performs remarkably better than the existing methods in terms of position error and orientation error. In the test of indoor scenes of the public RAWSEEDS data sets, with the aid of a wheel odometer, our method produces bounded position errors about 0.79 m along a 967-m path although no loop-closing algorithm is applied.",
Joint Optimization of Rule Placement and Traffic Engineering for QoS Provisioning in Software Defined Network,"Software-Defined Network (SDN) is a promising network paradigm that separates the control plane and data plane in the network. It has shown great advantages in simplifying network management such that new functions can be easily supported without physical access to the network switches. However, Ternary Content Addressable Memory (TCAM), as a critical hardware storing rules for high-speed packet processing in SDN-enabled devices, can be supplied to each device with very limited quantity because it is expensive and energy-consuming. To efficiently use TCAM resources, we propose a rule multiplexing scheme, in which the same set of rules deployed on each node apply to the whole flow of a session going through but towards different paths. Based on this scheme, we study the rule placement problem with the objective of minimizing rule space occupation for multiple unicast sessions under QoS constraints. We formulate the optimization problem jointly considering routing engineering and rule placement under both existing and our rule multiplexing schemes. Via an extensive review of the state-of-the-art work, to the best of our knowledge, we are the first to study the non-routing-rule placement problem. Finally, extensive simulations are conducted to show that our proposals significantly outperform existing solutions.",
Capacitive-Piezoelectric Transducers for High- Q Micromechanical AlN Resonators,"A capacitive-piezoelectric (also known as, capacitive-piezo) transducer that combines the strengths of capacitive and piezoelectric mechanisms to achieve a combination of electromechanical coupling and Q higher than otherwise attainable by either mechanism separately, has allowed demonstration of a 1.2-GHz contour-mode aluminum nitride (AlN) ring resonator with Q > 3000 on par with the highest measured d31-transduced AlN-only piezoelectric resonators past 1 GHz, and a 50-MHz disk array with an even higher Q > 12 000. Here, the key innovation is to separate the piezoelectric resonator from its metal electrodes by tiny gaps to eliminate metal material and metal-to-piezoelectric interface losses thought to limit thin-film piezoelectric resonator Q, while also maintaining high electric field strength to preserve a strong piezoelectric effect. While Q increases, electromechanical coupling decreases, but the keff2 · Q product can still increase overall. More importantly, use of the capacitive-piezo transducer allows a designer to trade electromechanical coupling for Q, providing a very useful method to tailor Q and coupling for narrowband radio frequency (RF) channel-selecting filters for which Q trumps coupling. This capacitive-piezo transducer concept does not require dc-bias voltages and allows for much thicker electrodes that reduce series resistance without mass loading the resonant structure. The latter is especially important as resonators and their supports continue to scale toward even higher frequencies. [2013-0395].",
Hybrid Method for 3-D Gaze Tracking Using Glint and Contour Features,"Glint features have important roles in gaze-tracking systems. However, when the operation range of a gaze-tracking system is enlarged, the performance of glint-feature-based (GFB) approaches will be degraded mainly due to the curvature variation problem at around the edge of the cornea. Although the pupil contour feature may provide complementary information to help estimating the eye gaze, existing methods do not properly handle the cornea refraction problem, leading to inaccurate results. This paper describes a contour-feature-based (CFB) 3-D gaze-tracking method that is compatible to cornea refraction. We also show that both the GFB and CFB approaches can be formulated in a unified framework and, thus, they can be easily integrated. Furthermore, it is shown that the proposed CFB method and the GFB method should be integrated because the two methods provide complementary information that helps to leverage the strength of both features, providing robustness and flexibility to the system. Computer simulations and real experiments show the effectiveness of the proposed approach for gaze tracking.","Cornea,
Cameras,
Vectors,
Light sources,
Estimation,
Tracking,
Optical refraction"
Preventing Occupancy Detection From Smart Meters,"Utilities are rapidly deploying smart meters that measure electricity usage in real-time. Unfortunately, smart meters indirectly leak sensitive information about a home's occupancy, which is easy to detect because it highly correlates with simple statistical metrics, such as power's mean, variance, and range. To prevent occupancy detection, we propose using the thermal energy storage of electric water heaters already present in many homes. In essence, our approach, which we call combined heat and privacy (CHPr), modulates a water heater's power usage to make it look like someone is always home. We design a CHPr-enabled water heater that regulates its energy usage to thwart a variety of occupancy detection attacks without violating its objective-to provide hot water on demand-and evaluate it in simulation using real data. Our results show that a standard 50-gal CHPr-enabled water heater prevents a wide range of state-of-the-art occupancy detection attacks.","Water heating,
Batteries,
Smart meters,
Cogeneration,
Thermal energy,
Home appliances"
Unified performance analysis of mixed line of sight RF-FSO fixed gain dual-hop transmission systems,"In this work, we carry out a unified performance analysis of a dual-hop amplify-and-forward fixed gain relay system over asymmetric links composed of both radio-frequency (RF) and unified free-space optics (FSO) under the effect of pointing errors. The RF link is modeled by the Nakagami-m fading channel and the FSO link by the Gamma-Gamma fading channel subject to both types of detection techniques (i.e. heterodyne detection and intensity modulation with direct detection (IM/DD)). In particular, we derive new unified closed-form expressions for the cumulative distribution function, the probability density function, the moment generating function, and the moments of the end-to-end signal-to-noise ratio of these systems in terms of the Meijer's G function. Based on these formulas, we offer exact closed-form expressions for the outage probability, the higher-order amount of fading, and the average bit-error rate of a variety of binary modulations in terms of the Meijer's G function. Further, an exact closed-form expression for the end-to-end ergodic capacity for the Nakagami-m-unified FSO relay links is derived in terms of the extended generalized bivariate Meijer's G function. All the given results are verified via computer-based Monte-Carlo simulations.",
Drone-assisted public safety wireless broadband network,"A nationwide interoperable public safety wireless broadband network is being planned by the First Responder Network Authority (FirstNet) under the auspices of the United States government. The public safety network shall provide the needed wireless coverage in the wake of an incident or a disaster. This paper proposes a drone-assisted multi-hop device-to-device (D2D) communication scheme as a means to extend the network coverage over regions where it is difficult to deploy a landbased relay. The resource are shared using either time division or frequency division scheme. Efficient algorithms are developed to compute the optimal position of the drone for maximizing the data rate, which are shown to be highly effective via simulations.","Base stations,
Frequency conversion,
Safety,
Conferences,
Signal to noise ratio,
Optimization,
Relays"
Triple-Mode Dielectric Resonator Diplexer for Base-Station Applications,"This paper proposes a novel diplexer based on triple-mode dielectric-loaded cylindrical cavities. Such two metal cavities are designed to achieve two different frequency bands, while three resonant modes of a single cavity are classified as a TM mode and a pair of hybrid (HE) degeneration modes. An off-centered dielectric resonator instead of a traditional corner cuts perturbation or screws perturbation properly perturbs the two degenerate modes in the same cavity. Extensive study is then conducted to design this proposed diplexer. Finally, a diplexer prototype is fabricated using a brass cavity and it is tested for experimental verification of the predicted results. Good agreement between measurement and simulation is achieved.","Couplings,
Cavity resonators,
Filtering theory,
Resonator filters,
Magnetic resonance,
Microwave filters"
Learning force-based manipulation of deformable objects from multiple demonstrations,"Manipulation of deformable objects often requires a robot to apply specific forces to bring the object into the desired configuration. For instance, tightening a knot requires pulling on the ends, flattening an article of clothing requires smoothing out wrinkles, and erasing a whiteboard requires applying downward pressure. We present a method for learning force-based manipulation skills from demonstrations. Our approach uses non-rigid registration to compute a warping function that transforms both the end-effector poses and forces in each demonstration into the current scene, based on the configuration of the object. Our method then uses the variation between the demonstrations to extract a single trajectory, along with time-varying feedback gains that determine how much to match poses or forces. This results in a learned variable-impedance control strategy that trades off force and position errors, providing for the right level of compliance that applies the necessary forces at each stage of the motion. We evaluate our approach by tying knots in rope, flattening towels, and erasing a whiteboard.","Trajectory,
Force,
Robots,
Three-dimensional displays,
Joints,
Impedance,
Kinematics"
Layered Transmission of Space-Time Coded Signals for Image-Sensor-Based Visible Light Communications,"This paper demonstrates the feasibility of layered space-time coding (STC) in an outdoor image-sensor-based (ISbased) visible light communication (VLC) system. We examined that for low-resolution IS-based VLC channel where intensity-modulated signals from two different light emitting diodes (LEDs) are detected by one pixel of an IS, STC allows us to decouple them; thus, succeeding to receive them with no errors. Consequently, STC offers extended transmission distance to pixel-resolution-limited IS-based VLC links. In the layered STC presented in this paper, additional bit streams are laid on the 2n × 2n LED array for increasing the transmission rate per symbol duration for the case where the pixel resolution is improved. A prototype of a threelayered STC is built with an 8 × 8 LED array, where each of the LEDs is modulated at 1 kb/s and a high-speed camera with IS operating at 1000 fps. Our experimental results validate that the two additional bit streams (layer-2 and -3), aligned in the layer-1 STC matrix pair, are extracted with no errors when the receiver comes within 155 and 55 m, respectively, from the LED array, without decreasing 210 m of the transmission distance of layer-1 bit stream.",
Topological Modeling and Classification of Mammographic Microcalcification Clusters,"Goal: The presence of microcalcification clusters is a primary sign of breast cancer; however, it is difficult and time consuming for radiologists to classify microcalcifications as malignant or benign. In this paper, a novel method for the classification of microcalcification clusters in mammograms is proposed. Methods: The topology/connectivity of individual microcalcifications is analyzed within a cluster using multiscale morphology. This is distinct from existing approaches that tend to concentrate on the morphology of individual microcalcifications and/or global (statistical) cluster features. A set of microcalcification graphs are generated to represent the topological structure of microcalcification clusters at different scales. Subsequently, graph theoretical features are extracted, which constitute the topological feature space for modeling and classifying microcalcification clusters. k-nearest-neighbors-based classifiers are employed for classifying microcalcification clusters. Results: The validity of the proposed method is evaluated using two well-known digitized datasets (MIAS and DDSM) and a full-field digital dataset. High classification accuracies (up to 96%) and good ROC results (area under the ROC curve up to 0.96) are achieved. A full comparison with related publications is provided, which includes a direct comparison. Conclusion: The results indicate that the proposed approach is able to outperform the current state-of-the-art methods. Significance: This study shows that topology modeling is an important tool for microcalcification analysis not only because of the improved classification accuracy but also because the topological measures can be linked to clinical understanding.","Cancer,
Feature extraction,
Topology,
Databases,
Educational institutions,
Electronic mail,
Shape"
Efficient metric indexing for similarity search,"The goal in similarity search is to find objects similar to a specified query object given a certain similarity criterion. Although useful in many areas, such as multimedia retrieval, pattern recognition, and computational biology, to name but a few, similarity search is not yet supported well by commercial DBMS. This may be due to the complex data types involved and the needs for flexible similarity criteria seen in real applications. We propose an efficient disk-based metric access method, the Space-filling curve and Pivot-based B+-tree (SPB-tree), to support a wide range of data types and similarity metrics. The SPB-tree uses a small set of so-called pivots to reduce significantly the number of distance computations, uses a space-filling curve to cluster the data into compact regions, thus improving storage efficiency, and utilizes a B+-tree with minimum bounding box information as the underlying index. The SPB-tree also employs a separate random access file to efficiently manage a large and complex data. By design, it is easy to integrate the SPB-tree into an existing DBMS. We present efficient similarity search algorithms and corresponding cost models based on the SPB-tree. Extensive experiments using real and synthetic data show that the SPB-tree has much lower construction cost, smaller storage size, and can support more efficient similarity queries with high accuracy cost models than is the case for competing techniques. Moreover, the SPB-tree scales sublinearly with growing dataset size.",
"Bottom-up learning of object categories, action effects and logical rules: From continuous manipulative exploration to symbolic planning","This work aims for bottom-up and autonomous development of symbolic planning operators from continuous interaction experience of a manipulator robot that explores the environment using its action repertoire. Development of the symbolic knowledge is achieved in two stages. In the first stage, the robot explores the environment by executing actions on single objects, forms effect and object categories, and gains the ability to predict the object/effect categories from the visual properties of the objects by learning the nonlinear and complex relations among them. In the next stage, with further interactions that involve stacking actions on pairs of objects, the system learns logical high-level rules that return a stacking-effect category given the categories of the involved objects and the discrete relations between them. Finally, these categories and rules are encoded in Planning Domain Definition Language (PDDL), enabling symbolic planning. We realized our method by learning the categories and rules in a physics-based simulator. The learned symbols and operators are verified by generating and executing non-trivial symbolic plans on the real robot in a tower building task.","Planning,
Robot sensing systems,
Solids,
Grippers,
Decision trees,
Stacking"
Continuous humanoid locomotion over uneven terrain using stereo fusion,"For humanoid robots to fulfill their mobility potential they must demonstrate reliable and efficient locomotion over rugged and irregular terrain. In this paper we present the perception and planning algorithms which have allowed a humanoid robot to use only passive stereo imagery (as opposed to actuating a laser range sensor) to safely plan footsteps to continuously walk over rough and uneven surfaces without stopping. The perception system continuously integrates stereo imagery to build a consistent 3D model of the terrain which is then used by our footstep planner which reasons about obstacle avoidance, kinematic reachability and foot rotation through mixed-integer quadratic optimization to plan the required step positions. We illustrate that our stereo imagery fusion approach can measure the walking terrain with sufficient accuracy that it matches the quality of terrain estimates from LIDAR. To our knowledge this is the first such demonstration of the use of computer vision to carry out general purpose terrain estimation on a locomoting robot - and additionally to do so in continuous motion. A particular integration challenge was ensuring that these two computationally intensive systems operate with minimal latency (below 1 second) to allow re-planning while walking. The results of extensive experimentation and quantitative analysis are also presented. Our results indicate that a laser range sensor is not necessary to achieve locomotion in these challenging situations.","Legged locomotion,
Robot sensing systems,
Planning,
Three-dimensional displays,
Laser radar,
Robot kinematics"
Robust Subspace Clustering via Smoothed Rank Approximation,"Matrix rank minimizing subject to affine constraints arises in many application areas, ranging from signal processing to machine learning. Nuclear norm is a convex relaxation for this problem which can recover the rank exactly under some restricted and theoretically interesting conditions. However, for many real-world applications, nuclear norm approximation to the rank function can only produce a result far from the optimum. To seek a solution of higher accuracy than the nuclear norm, in this letter, we propose a rank approximation based on Logarithm-Determinant. We consider using this rank approximation for subspace clustering application. Our framework can model different kinds of errors and noise. Effective optimization strategy is developed with theoretical guarantee to converge to a stationary point. The proposed method gives promising results on face clustering and motion segmentation tasks compared to the state-of-the-art subspace clustering algorithms.","Approximation methods,
Approximation algorithms,
Clustering algorithms,
Signal processing algorithms,
Optimization,
Minimization,
Linear programming"
Target Detection Based on Random Forest Metric Learning,"Target detection is aimed at detecting and identifying target pixels based on specific spectral signatures, and is of great interest in hyperspectral image (HSI) processing. Target detection can be considered as essentially a binary classification. Random forests have been effectively applied to the classification of HSI data. However, random forests need a huge amount of labeled data to achieve a good performance, which can be difficult to obtain in target detection. In this paper, we propose an efficient metric learning detector based on random forests, named the random forest metric learning (RFML) algorithm, which combines semimultiple metrics with random forests to better separate the desired targets and background. The experimental results demonstrate that the proposed method outperforms both the state-of-the-art target detection algorithms and the other classical metric learning methods.","Measurement,
Object detection,
Vegetation,
Hyperspectral imaging,
Detectors,
Learning systems"
Bioinspired Nanonetworks for Targeted Cancer Drug Delivery,"A biomimicry approach to nanonetworks is proposed here for targeted cancer drug delivery (TDD). The swarm of bioinspired nanomachines utilizes the blood distribution network and chemotaxis to carry drug through the vascular system to the cancer site, recognized by a high concentration of vascular endothelial growth factor (VEGF). Our approach is multi-scale and includes processes that occur both within cells and with their neighbors. The proposed bionanonetwork takes advantage of several organic processes, some of which already occur within the human body, such as a plate-like structure similar to those of red blood cells for more environmental contact; a berry fruit architecture for its internal multi-foams architecture; the penetrable structure of cancer cells, tissue, as well as the porous structure of the capillaries for drug penetration; state of glycocalyx for ligand-receptor adhesion; as well as changes in pH state of blood and O 2 release for nanomachine communication. For a more appropriate evaluation, we compare our work with a conventional chemotherapy approach using a mathematical model of cancer under actual experimental parameter settings. Simulation results show the merits of the proposed method in targeted cancer therapy by improving the densities of the relevant cancer cell types and VEGF concentration, while following more organic and natural processes.",
Empirical Non-Parametric Estimation of the Fisher Information,"The Fisher information matrix (FIM) is a foundational concept in statistical signal processing. The FIM depends on the probability distribution, assumed to belong to a smooth parametric family. Traditional approaches to estimating the FIM require estimating the probability distribution function (PDF), or its parameters, along with its gradient or Hessian. However, in many practical situations the PDF of the data is not known but the statistician has access to an observation sample for any parameter value. Here we propose a method of estimating the FIM directly from sampled data that does not require knowledge of the underlying PDF. The method is based on non-parametric estimation of an f-divergence over a local neighborhood of the parameter space and a relation between curvature of the f-divergence and the FIM. Thus we obtain an empirical estimator of the FIM that does not require density estimation and is asymptotically consistent. We empirically evaluate the validity of our approach using two experiments.","Estimation,
Probability density function,
Educational institutions,
Density measurement,
Least squares approximations,
Vectors,
Signal processing"
Polyp Detection via Imbalanced Learning and Discriminative Feature Learning,"Recent achievement of the learning-based classification leads to the noticeable performance improvement in automatic polyp detection. Here, building large good datasets is very crucial for learning a reliable detector. However, it is practically challenging due to the diversity of polyp types, expensive inspection, and labor-intensive labeling tasks. For this reason, the polyp datasets usually tend to be imbalanced, i.e., the number of non-polyp samples is much larger than that of polyp samples, and learning with those imbalanced datasets results in a detector biased toward a non-polyp class. In this paper, we propose a data sampling-based boosting framework to learn an unbiased polyp detector from the imbalanced datasets. In our learning scheme, we learn multiple weak classifiers with the datasets rebalanced by up/down sampling, and generate a polyp detector by combining them. In addition, for enhancing discriminability between polyps and non-polyps that have similar appearances, we propose an effective feature learning method using partial least square analysis, and use it for learning compact and discriminative features. Experimental results using challenging datasets show obvious performance improvement over other detectors. We further prove effectiveness and usefulness of the proposed methods with extensive evaluation.",
Microwave Interrogated Sapphire Fiber Michelson Interferometer for High Temperature Sensing,"We present, for the first time to our knowledge, a microwave interrogated sapphire fiber Michelson interferometer for high temperature sensing. By sending a microwave-modulated optical wave to a sapphire fiber Michelson interferometer, a high quality interference spectrum was reconstructed in the microwave domain with a fringe visibility exceeding 40 dB. The sensor showed good sensitivity, reversibility and stability in the temperature range of 100 °C-1400 °C. The proposed sensing configuration has a number of unique advantages including low dependence to the multimodal influences, high signal quality, relieved fabrication precision, and insensitivity to the background blackbody radiation when used in high temperature.","Optical fiber sensors,
Optical interferometry,
Temperature sensors,
Optical fiber couplers,
Microwave photonics"
Lexicographic Multiobjective Integer Programming for Optimal and Structurally Minimal Petri Net Supervisors of Automated Manufacturing Systems,"Based on Petri net (PN) models of automated manufacturing systems, this paper proposes a deadlock prevention method to obtain a maximally permissive (optimal) supervisor while minimizing its structure. The optimal supervisor can be achieved by forbidding all first-met bad markings (FBMs) and permitting all legal markings in a PN model. An FBM obtained via a single transition's firing at a legal marking is a deadlock or marking that inevitably evolves into a deadlock. A lexicographic multiobjective integer programming problem with multiple objectives to be achieved sequentially is formulated to design such an optimal and structurally minimal supervisor. As a nonlinear function, the quantity of its directed arcs is minimized. A conversion method is proposed to convert the nonlinear model into a linear one. With the premise that each place in the supervisor is associated with a nonnegative place invariant, the controlled net holds all legal markings of the net model, and the supervisor has the minimal structure. Finally, some examples are used to illustrate the application of the proposed approach.",
A Molecular Communications Model for Drug Delivery,"This paper considers the scenario of a targeted drug delivery system, which consists of deploying a number of biological nanomachines close to a biological target (e.g., a tumor), able to deliver drug molecules in the diseased area. Suitably located transmitters are designed to release a continuous flow of drug molecules in the surrounding environment, where they diffuse and reach the target. These molecules are received when they chemically react with compliant receptors deployed on the receiver surface. In these conditions, if the release rate is relatively high and the drug absorption time is significant, congestion may happen, essentially at the receiver site. This phenomenon limits the drug absorption rate and makes the signal transmission ineffective, with an undesired diffusion of drug molecules elsewhere in the body. The original contribution of this paper consists of a theoretical analysis of the causes of congestion in diffusion-based molecular communications. For this purpose, it is proposed a reception model consisting of a set of pure loss queuing systems. The proposed model exhibits an excellent agreement with the results of a simulation campaign made by using the Biological and Nano-Scale communication simulator version 2 (BiNS2), a well-known simulator for molecular communications, whose reliability has been assessed through in vitro experiments. The obtained results can be used in rate control algorithms to optimally determine the optimal release rate of molecules in drug delivery applications.","Receivers,
Drugs,
Molecular communication,
Drug delivery,
Biological system modeling,
Nanobioscience,
Protocols"
Large Tanker Motion Model Identification Using Generalized Ellipsoidal Basis Function-Based Fuzzy Neural Networks,"In this paper, the motion dynamics of a large tanker is modeled by the generalized ellipsoidal function-based fuzzy neural network (GEBF-FNN). The reference model of tanker motion dynamics in the form of nonlinear difference equations is established to generate training data samples for the GEBF-FNN algorithm which begins with no hidden neuron. In the sequel, fuzzy rules associated with the GEBF-FNN-based model can be online self-constructed by generation criteria and parameter estimation, and can dynamically capture essential motion dynamics of the large tanker with high prediction accuracy. Simulation studies and comprehensive comparisons are conducted on typical zig-zag maneuvers with moderate and extreme steering, and demonstrate that the GEBF-FNN-based model of tanker motion dynamics achieves superior performance in terms of both approximation and prediction.","Dynamics,
Mathematical model,
Fuzzy neural networks,
Vectors,
Neurons,
Input variables,
Data models"
Mining Attribute-Based Access Control Policies,"Attribute-based access control (ABAC) provides a high level of flexibility that promotes security and information sharing. ABAC policy mining algorithms have potential to significantly reduce the cost of migration to ABAC, by partially automating the development of an ABAC policy from an access control list (ACL) policy or role-based access control (RBAC) policy with accompanying attribute data. This paper presents an ABAC policy mining algorithm. To the best of our knowledge, it is the first ABAC policy mining algorithm. Our algorithm iterates over tuples in the given user-permission relation, uses selected tuples as seeds for constructing candidate rules, and attempts to generalize each candidate rule to cover additional tuples in the user-permission relation by replacing conjuncts in attribute expressions with constraints. Our algorithm attempts to improve the policy by merging and simplifying candidate rules, and then it selects the highest-quality candidate rules for inclusion in the generated policy.","Access control,
Data mining,
Measurement,
Gold,
Merging,
Materials"
Critical database size for effective caching,"Replicating or caching popular content in memories distributed across the network is a technique to reduce peak network loads. Conventionally, the performance gain of caching was thought to result from making part of the requested data available closer to end users. Recently, it has been shown that by using a carefully designed technique to store the contents in the cache and coding across data streams a much more significant gain can be achieved in reducing the network load. Inner and outer bounds on the network load v/s cache memory tradeoff were obtained in [1]. We give an improved outer bound on the network load v/s cache memory tradeoff. We also address the question of to what extent caching is effective in reducing the server load when the number of files becomes large as compared to the number of users. We show that the effectiveness of caching become small when the number of files becomes comparable to the square of the number of users.","Servers,
Databases,
Cache memory,
Upper bound,
Encoding,
Entropy,
Mutual information"
Designing Truthful Spectrum Auctions for Multi-hop Secondary Networks,"Opportunistic wireless channel access granted to non-licensed users through auctions represents a promising approach for effectively distributing and utilizing the scarce wireless spectrum. A limitation of existing spectrum auction designs lies in the over-simplifying assumption that every non-licensed secondary user is a single node or single-hop network. For the first time in the literature, we propose to model non-licensed users as secondary networks (SNs), each of which comprises of a multihop network with end-to-end routing demands. We use simple examples to show that such auctions among SNs differ drastically from simple auctions among single-hop users, and previous solutions suffer from local, per-hop decision making. We first design a simple, heuristic auction that takes inter-SN interference into consideration and is truthful. We then design a randomized auction framework based on primal-dual linear optimization, which is automatically truthful and achieves a social welfare approximation ratio that matches one achieved by cooperative optimization assuming truthful bids for free. The framework relieves a spectrum auction designer from worrying about truthfulness of the auction, so that he or she can focus on social welfare maximization while assuming truthful bids for free.","Wireless networks,
Spread spectrum management,
Radio spectrum management,
Linear programming"
Semi-supervised Domain Adaptation with Subspace Learning for visual recognition,"In many real-world applications, we are often facing the problem of cross domain learning, i.e., to borrow the labeled data or transfer the already learnt knowledge from a source domain to a target domain. However, simply applying existing source data or knowledge may even hurt the performance, especially when the data distribution in the source and target domain is quite different, or there are very few labeled data available in the target domain. This paper proposes a novel domain adaptation framework, named Semi-supervised Domain Adaptation with Subspace Learning (SDASL), which jointly explores invariant low-dimensional structures across domains to correct data distribution mismatch and leverages available unlabeled target examples to exploit the underlying intrinsic information in the target domain. Specifically, SDASL conducts the learning by simultaneously minimizing the classification error, preserving the structure within and across domains, and restricting similarity defined on unlabeled target examples. Encouraging results are reported for two challenging domain transfer tasks (including image-to-image and image-to-video transfers) on several standard datasets in the context of both image object recognition and video concept detection.","Manifolds,
Support vector machines,
Linear programming,
Visualization,
Training,
Measurement,
Optimization"
A Time-Domain Microwave System for Breast Cancer Detection Using a Flexible Circuit Board,"We present the design of a flexible multilayer circuit board for use in a custom-built microwave system for breast health monitoring. The flexible circuit features both an integrated solid-state switching network and 16 wideband antennas, which transmit short-duration pulses into the breast tissues and receive the backscattered responses. By integrating the switching matrix and the antenna array on the same substrate, we reduce the overall cost and size of the system in comparison with previously demonstrated systems in the literature. We characterize the performance of the flexible circuit board using our clinically tested experimental system and demonstrate its functionality through successful imaging of dielectrically realistic breast phantoms that simulate the presence of a tumor. This represents a step toward a more patient-friendly, compact, cost-effective, and wearable design in contrast to previous systems in the literature that required a clinical table or used bulky rigid antenna housings and electromechanical switching networks.","Switches,
Antennas,
Breast,
Microwave circuits,
Microwave imaging,
Printed circuits,
Transmission line matrix methods"
Super Fast Event Recognition in Internet Videos,"Techniques for recognizing high-level events in consumer videos on the Internet have many applications. Systems that produced state-of-the-art recognition performance usually contain modules requiring extensive computation, such as the extraction of the temporal motion trajectories, which cannot be deployed on large-scale datasets. In this paper, we provide a comprehensive study on efficient methods in this area and identify technical options for super fast event recognition in Internet videos. We start from analyzing a multimodal baseline that has produced good performance on popular benchmarks, by systematically evaluating each component in terms of both computational cost and contribution to recognition accuracy. After that, we identify alternative features, classifiers, and fusion strategies that can all be efficiently computed. In addition, we also provide a study on the following interesting question: for event recognition in Internet videos, what is the minimum number of visual and audio frames needed to obtain a comparable accuracy to that of using all the frames? Results on two rigorously designed datasets indicate that similar results can be maintained by using only a small portion of the visual frames. We also find that, different from the visual frames, the soundtracks contain little redundant information and thus sampling is always harmful. Integrating all the findings, our suggested recognition system is 2,350-fold faster than a baseline approach with even higher recognition accuracies. It recognizes 20 classes on a 120-second video sequence in just 1.78 seconds, using a regular desktop computer.","Videos,
Feature extraction,
Visualization,
Kernel,
Support vector machines,
Trajectory,
Quantization (signal)"
Graph-based framework for flexible baseband function splitting and placement in C-RAN,"The baseband-up centralization architecture of radio access networks (C-RAN) has recently been proposed to support efficient cooperative communications and reduce deployment and operational costs. However, the massive fronthaul bandwidth required to aggregate baseband samples from remote radio heads (RRHs) to the central office incurs huge fronthauling cost, and existing baseband compression algorithms can hardly solve this issue. In this paper, we propose a graph-based framework to effectively reduce fronthauling cost through properly splitting and placing baseband processing functions in the network. Baseband transceiver structures are represented with directed graphs, in which nodes correspond to baseband functions, and edges to the information flows between functions. By mapping graph weighs to computational and fronthauling costs, we transform the problem of finding the optimum location to place some baseband functions into the problem of finding the optimum clustering scheme for graph nodes. We then solve this problem using a genetic algorithm with customized fitness function and mutation module. Simulation results show that proper splitting and placement schemes can significantly reduce fronthauling cost at the expense of increased computational cost. We also find that cooperative processing structures and stringent delay requirements will increase the possibility of centralized placement.","Baseband,
Delays,
Bandwidth,
Genetic algorithms,
Computational efficiency,
Wireless communication,
Computer architecture"
Object-based RGBD image co-segmentation with mutex constraint,"We present an object-based co-segmentation method that takes advantage of depth data and is able to correctly handle noisy images in which the common foreground object is missing. With RGBD images, our method utilizes the depth channel to enhance identification of similar foreground objects via a proposed RGBD co-saliency map, as well as to improve detection of object-like regions and provide depth-based local features for region comparison. To accurately deal with noisy images where the common object appears more than or less than once, we formulate co-segmentation in a fully-connected graph structure together with mutual exclusion (mutex) constraints that prevent improper solutions. Experiments show that this object-based RGBD co-segmentation with mutex constraints outperforms related techniques on an RGBD co-segmentation dataset, while effectively processing noisy images. Moreover, we show that this method also provides performance comparable to state-of-the-art RGB co-segmentation techniques on regular RGB images with depth maps estimated from them.","Image segmentation,
Image color analysis,
Noise measurement,
Histograms,
Lighting,
Proposals,
Videos"
Towards NFV-based multimedia delivery,"The popularity of multimedia services offered over the Internet have increased tremendously during the last decade. The technologies that are used to deliver these services are evolving at a rapidly increasing pace. However, new technologies often demand updating the dedicated hardware (e.g., transcoders) that is required to deliver the services. Currently, these updates require installing the physical building blocks at different locations across the network. These manual interventions are time-consuming and extend the Time to Market of new and improved services, reducing their monetary benefits. To alleviate the aforementioned issues, Network Function Virtualization (NFV) was introduced by decoupling the network functions from the physical hardware and by leveraging IT virtualization technology to allow running Virtual Network Functions (VNFs) on commodity hardware at datacenters across the network. In this paper, we investigate how existing service chains can be mapped onto NFV-based Service Function Chains (SFCs). Furthermore, the different alternative SFCs are explored and their impact on network and datacenter resources (e.g., bandwidth, storage) are quantified. We propose to use these findings to cost-optimally distribute datacenters across an Internet Service Provider (ISP) network.","Delays,
Servers,
Streaming media,
Hardware,
Multimedia communication,
Bandwidth,
Mathematical model"
Quantum Dash Mode-Locked Lasers for Data Centre Applications,"The authors demonstrate single-polarisation WDM transmission with capacities higher than 400 Gb/s and 1 Tb/s, and show the possibility of obtaining capacity in excess of 4 Tb/s for interconnect applications within and between data centres, based on a single laser source. Quantum Dash (Q-Dash) passively mode-locked lasers (PMLLs), with free spectral ranges of 82.8, 44.7, and 10.2 GHz, were used for the generation of a large number of carriers, enabling high data rate transmission. The terabit per second transmission using Q-Dash MLLs was demonstrated in this paper, and was enabled using intensity modulated and directly detected (IM/DD) single-side band orthogonal frequency-division multiplexed signals. The system performance was investigated for a propagation distance of 3 and 50 km of standard single mode fibre indicating the potential for interconnect applications within and between data centres. The relative intensity noise (RIN) of all Q-Dash devices was characterised, and the effect of RIN on the system performance was investigated by examining the error-vector magnitude of OFDM subcarriers over the desired frequency range.","Optical filters,
Optical transmitters,
OFDM,
Optical fibers,
Optical variables measurement,
Optical amplifiers,
Receivers"
Variable-state latent conditional random fields for facial expression recognition and action unit detection,"Automatic recognition of facial expressions of emotions, and detection of facial action units (AUs), from videos depends critically on modeling of their dynamics. These dynamics are characterized by changes in temporal phases (onset-apex-offset) and intensity of emotion/AUs, the appearance of which vary considerably among subjects, making the recognition/detection task very challenging. While state-of-the-art Latent Conditional Random Fields (LCRF) allow one to efficiently encode these dynamics via modeling of structural information (e.g., temporal consistency and ordinal constraints), their latent states are restricted to either unordered (nominal) or fully ordered (ordinal). However, such an approach is often too restrictive since, for instance, in the case of AU detection, the sequences of an active AU may better be described using ordinal latent states (corresponding to the AU intensity levels), while the sequences of this AU not being active may better be described using unordered (nominal) latent states. To this end, we propose the Variable-state LCRF model that automatically selects the optimal latent states (nominal or ordinal) for each sequence from each target class. This unsupervised adaptation of the model to individual sequence or subject contexts opens the possibility for improved model fitting and, subsequently, enhanced predictive performance. Our experiments on four public expression databases (CK+, AFEW, MMI and GEMEP-FERA) show that the proposed model consistently outperforms the state-of-the-art methods for both facial expression recognition and action unit detection from image sequences.","Hidden Markov models,
Gold,
Face recognition,
Standards,
Computational modeling,
Data models,
Videos"
A Parametric Classification Rule Based on the Exponentially Embedded Family,"In this paper, we extend the exponentially embedded family (EEF), a new approach to model order estimation and probability density function construction originally proposed by Kay in 2005, to multivariate pattern recognition. Specifically, a parametric classifier rule based on the EEF is developed, in which we construct a distribution for each class based on a reference distribution. The proposed method can address different types of classification problems in either a data-driven manner or a model-driven manner. In this paper, we demonstrate its effectiveness with examples of synthetic data classification and real-life data classification in a data-driven manner and the example of power quality disturbance classification in a model-driven manner. To evaluate the classification performance of our approach, the Monte-Carlo method is used in our experiments. The promising experimental results indicate many potential applications of the proposed method.","Training data,
Vectors,
Data models,
Estimation,
Neural networks,
Statistics,
Testing"
Time-Aware Service Recommendation for Mashup Creation,"Web service recommendation has become a critical problem as services become increasingly prevalent on the Internet. Some existing methods focus on content matching techniques, while others are based on QoS measurement. However, service ecosystem is evolving over time with services publishing, prospering and perishing. Few existing methods consider or exploit the evolution of service ecosystem on service recommendation. This paper employs a probabilistic approach to predict the popularity of services to enhance the recommendation performance. A method is presented that extracts service evolution patterns by exploiting latent dirichlet allocation (LDA) and time series prediction. A time-aware service recommendation framework is established for mashup creation that conducts joint analysis of temporal information, content description and historical mashup-service usage in an evolving service ecosystem. Experiments on a real-world service repository, ProgrammableWeb.com, show that the proposed approach leads to a higher precision than traditional collaborative filtering and content matching methods, by taking into account temporal information.","Mashups,
Mathematical model,
Ecosystems,
Filtering,
Equations,
Collaboration,
Computational modeling"
S-Aframe: Agent-Based Multilayer Framework With Context-Aware Semantic Service for Vehicular Social Networks,"This paper presents S-Aframe, an agent-based multilayer framework with context-aware semantic service (CSS) to support the development and deployment of context-aware applications for vehicular social networks (VSNs) formed by in-vehicle or mobile devices used by drivers, passengers, and pedestrians. The programming model of the framework incorporates features that support collaborations between mobile agents to provide communication services on behalf of owner applications, and service (or resident) agents to provide application services on mobile devices. Using this model, different self-adaptive applications and services for VSNs can be effectively developed and deployed. Built on top of the mobile devices' operating systems, the framework architecture consists of framework service layer, software agent layer and owner application layer. Integrated with the proposed novel CSS, applications developed on the framework can autonomously and intelligently self-adapt to rapidly changing network connectivity and dynamic contexts of VSN users. A practical implementation and experimental evaluations of S-Aframe are presented to demonstrate its reliability and efficiency in terms of computation and communication performance on popular mobile devices. In addition, a VSN-based smart ride application is developed to demonstrate the functionality and practical usefulness of S-Aframe.","Mobile agents,
Context,
Mobile handsets,
Mobile communication,
Vehicles,
Programming,
Cascading style sheets"
Security as a CoAP resource: An optimized DTLS implementation for the IoT,"The growing number of applications based on Internet of Things (IoT) technologies is pushing towards standardized protocol stacks for machine-to-machine (M2M) communication and the adoption of standard-based security solutions, such as the Datagram Transport Layer Security (DTLS). Despite the huge diffusion of DTLS, there is a lack of optimized implementations tailored to resource constrained devices. High energy consumption and long delays of current implementations limit their effective usage in real-life deployments. The aim of this paper is to explain how to integrate the DTLS protocol inside the Constrained Application Protocol (CoAP), exploiting Elliptic Curve Cryptography (ECC) optimizations and minimizing ROM occupancy. We have implemented our solution on an off-the-shelf mote platform and evaluated its performance. Results show that our ECC optimizations outperform priors scalar multiplication in state of the art for class 1 mote platforms, and improve network lifetime by a factor of up to 6.5 with respect to a standard-based not optimized implementation.","Protocols,
Optimization,
Servers,
Read only memory,
Ciphers,
Elliptic curves"
Performance assessment of lower VHF band for short-range communication and geolocation applications,"The focus of this paper is to characterize near-ground wave propagation in the lower very high frequency (VHF) band and to assess advantages that this frequency band offers for reliable short-range low-data rate communications and geolocation applications in highly cluttered environments as compared to conventional systems in the microwave range. With the advent of palm-sized miniaturized VHF antennas, interest in low-power and low-frequency communication links is increasing because (1) channel complexity is far less in this frequency band compared to higher frequencies and (2) significant signal penetration through/over obstacles is possible at this frequency. In this paper, we quantify the excess path loss and small-scale fading at the lower VHF and the 2.4 GHz bands based on short-range measurements in various environments. We consider indoor-to-indoor, outdoor-to-indoor, and non-line-of-sight outdoor measurements and compare the results with measurements at higher frequencies which are used in conventional systems (i.e., 2.4 GHz). Propagation measurements at the lower VHF band are carried out by using an electrically small antenna to assess the possibility of achieving a miniaturized, mobile system for near-ground communication. For each measurement scenario considered, path loss and small-scale fading are characterized after calibrating the differences in the systems used for measurements at different frequencies, including variations in antenna performance.","Antenna measurements,
Dipole antennas,
Frequency measurement,
Loss measurement,
Mobile antennas,
Receiving antennas"
Modeling and Health Monitoring of DC Side of Photovoltaic Array,"In this paper, a health monitoring method for photovoltaic (PV) systems based on probabilistic neural network (PNN) is proposed that detects and classifies short- and open-circuit faults in real time. To implement and validate the proposed method in computer programs, a new approach for modeling PV systems is proposed that only requires information from manufacturers datasheet reported under normal-operating cell temperature (NOCT) conditions and standard-operating test conditions (STCs). The proposed model precisely represents characteristics of PV systems at different temperatures, as the temperature dependency of parameters such as ideality factor, series resistance, and thermal voltage is considered in the proposed model. Although this model can be applied to a variety of applications, it is specifically used to test and validate the performance of the proposed fault detection and classification method.","Mathematical model,
Prognostics and health management,
Fault detection,
Photovoltaic systems,
Monitoring,
Probabilistic logic,
Neural networks"
"On the Delay Performance in a Large-Scale Wireless Sensor Network: Measurement, Analysis, and Implications","We present a comprehensive delay performance measurement and analysis in a large-scale wireless sensor network. We build a lightweight delay measurement system and present a robust method to calculate the per-packet delay. We show that the method can identify incorrect delays and recover them with a bounded error. Through analysis of delay and other system metrics, we seek to answer the following fundamental questions: What are the spatial and temporal characteristics of delay performance in a real network? What are the most important impacting factors, and is there any practical model to capture those factors? What are the implications to protocol designs? In this paper, we identify important factors from the data trace and show that the important factors are not necessarily the same with those in the Internet. Furthermore, we propose a delay model to capture those factors. We revisit several prevalent protocol designs such as Collection Tree Protocol, opportunistic routing, and Dynamic Switching-based Forwarding and show that our model and analysis are useful to practical protocol designs.","Delays,
Clocks,
Wireless sensor networks,
Protocols,
Synchronization"
"Antenna Array Developments: A Perspective on the Past, Present and Future","This paper presents a historical development of phased-array antennas as viewed by the authors. Arrays are another approach to high-gain antennas as contrasted with reflector antennas. They originated a little over 100 years ago and received little attention at first. WWII elevated their importance through use in air defense. Since then, the development of computers and solid-state devices has made arrays a very valuable tool in radio-frequency systems. Radio astronomy and defense applications will continue to push the state of the art for many years.","Phased arrays,
Reflector antennas,
Radar antennas,
Antenna arrays,
Radio frequency"
"BIST Methodology, Architecture and Circuits for Pre-Bond TSV Testing in 3D Stacking IC Systems","This paper presents a built-in self test (BIST) methodology, architecture and circuits for testing Through Silicon Vias (TSVs) in 3D-IC systems prior to stacking in order to improve 3D-IC yield and reduce overall test cost. A scan switch network (SSN) architecture is proposed to perform pre-bond TSV scan testing in test mode, and operate as functional circuit in functional mode, respectively. In the SSN, novel test structures and circuits are proposed to address pre-bond TSV test accessibility issue and perform stuck-at-fault tests and TSV tests. By exploiting the inherent RC delay characteristics of TSV, a novel delay-based TSV test method is also proposed to map the variation of TSV-to-substrate resistance due to TSV defects to a test path delay change. Compared with state-of-art methods, the proposed BIST methodology addresses pre-bond TSV testing with a low-overhead integrated test solution which is compatible to existing 2D-IC testing method. The proposed BIST architecture and method can be implemented by standard DFT design flow and integrated into a unified pre-bond TSV test flow. Experiment results and robustness analysis are presented to verify the effectiveness of the proposed self-test methodology, architecture, and circuits.","Through-silicon vias,
Built-in self-test,
Delays,
Resistance,
Capacitance,
Computer architecture"
A New Cellular-Automata-Based Fractional Frequency Reuse Scheme,"A fundamental challenge in orthogonal-frequency-division-multiple-access (OFDMA)-based cellular networks is intercell interference coordination, and to meet this challenge, various solutions using fractional frequency reuse (FFR) have been proposed in the literature. However, most of these schemes are either static in nature, dynamic on a large time scale, or require frequent reconfiguration for event-driven changes in the environment. The significant operational cost involved can be minimized with the added functionality that self-organizing networks bring. In this paper, we propose a solution based on the center of gravity of users in each sector. This enables us to have a distributed and adaptive solution for interference coordination. We further enhance our adaptive distributed FFR scheme by employing cellular automata as a step toward achieving an emergent self-organized solution. Our proposed scheme achieves a close performance with strict FFR and better performance than SFR in terms of the edge user's sum rate.","OFDM,
Interference,
Resource management,
Computer architecture,
Automata,
Microprocessors,
Dynamic scheduling"
Distributed Self Localization for Relative Position Sensing Networks in 2D Space,"This paper studies the 2D localization problem of a sensor network given anchor node positions in a common global coordinate frame and relative position measurements in local coordinate frames between node pairs. It is assumed that the local coordinate frames of different sensors have different orientations and the orientation difference with respect to the global coordinate frame are not known. In terms of graph connectivity, a necessary and sufficient condition is obtained for self-localizability that leads to a fully distributed localization algorithm. Moreover, a distributed verification algorithm is developed to check the graph connectivity condition, which can terminate successfully when the sensor network is self-localizable. Finally, a fully distributed, linear, and iterative algorithm based on the complex-valued Laplacian associated with the sensor network is proposed, which converges globally and gives the correct localization result.","Position measurement,
Signal processing algorithms,
Laplace equations,
Nickel,
Sensors,
Distance measurement,
Graph theory"
Fast Mode Decision Using Inter-View and Inter-Component Correlations for Multiview Depth Video Coding,"With the development of three-dimensional (3-D) display technologies, 3-D video has attracted more and more interest. Multiview video plus depth (MVD) is one of the most popular representation formats of 3-D video. In MVD coding system, multiview depth video needs to be coded and transmitted in addition to the texture video. This paper presents a novel fast mode decision (FMD) method for odd views in multiview depth video coding. First, the inter-view and inter-component coding correlations are analyzed to provide efficient reference information. Then, with a view to the characteristics of different types of frames, different early termination strategies are proposed. For the nonanchor frame, the early termination criterion is based on the rate-distortion cost information of the even views and the coded block pattern information. For the anchor frame, the criterion is set stricter to maintain the coding accuracy. Experimental results show that the proposed method can reduce 78.07% coding time on average, without significant loss of video quality.","Encoding,
Video coding,
Correlation,
Informatics,
Three-dimensional displays,
Rate-distortion,
Joints"
"Spinal Navigation and Imaging: History, Trends, and Future","The clinical practice of spine navigation has rapidly grown with the development of image-based guidance. In this paper, a brief history of spinal navigation is presented and a review of clinical outcomes for pedicle screws placed using the latest technology in the sacral, lumbar and thoracic regions. The clinical evidence demonstrate that intraoperative 3D image guided surgery has a 96.8% success rate. A concluding section detailing existing barriers that limit more widespread adoption and future development efforts is presented.","Fasteners,
Navigation,
Three-dimensional displays,
Surgery,
Computed tomography,
Accuracy"
3D Palmprint Identification Using Block-Wise Features and Collaborative Representation,"Developing 3D palmprint recognition systems has recently begun to draw attention of researchers. Compared with its 2D counterpart, 3D palmprint has several unique merits. However, most of the existing 3D palmprint matching methods are designed for one-to-one verification and they are not efficient to cope with the one-to-many identification case. In this paper, we fill this gap by proposing a collaborative representation (CR) based framework with l1-norm or l2-norm regularizations for 3D palmprint identification. The effects of different regularization terms have been evaluated in experiments. To use the CR-based classification framework, one key issue is how to extract feature vectors. To this end, we propose a block-wise statistics based feature extraction scheme. We divide a 3D palmprint ROI into uniform blocks and extract a histogram of surface types from each block; histograms from all blocks are then concatenated to form a feature vector. Such feature vectors are highly discriminative and are robust to mere misalignment. Experiments demonstrate that the proposed CR-based framework with an l2-norm regularization term can achieve much better recognition accuracy than the other methods. More importantly, its computational complexity is extremely low, making it quite suitable for the large-scale identification application. Source codes are available at http://sse.tongji.edu.cn/linzhang/cr3dpalm/cr3dpalm.htm.","Three-dimensional displays,
Feature extraction,
Vectors,
Collaboration,
Educational institutions,
Training,
Support vector machine classification"
A Lightweight Secure Scheme for Detecting Provenance Forgery and Packet DropAttacks in Wireless Sensor Networks,"Large-scale sensor networks are deployed in numerous application domains, and the data they collect are used in decision-making for critical infrastructures. Data are streamed from multiple sources through intermediate processing nodes that aggregate information. A malicious adversary may introduce additional nodes in the network or compromise existing ones. Therefore, assuring high data trustworthiness is crucial for correct decision-making. Data provenance represents a key factor in evaluating the trustworthiness of sensor data. Provenance management for sensor networks introduces several challenging requirements, such as low energy and bandwidth consumption, efficient storage and secure transmission. In this paper, we propose a novel lightweight scheme to securely transmit provenance for sensor data. The proposed technique relies on in-packet Bloom filters to encode provenance. We introduce efficient mechanisms for provenance verification and reconstruction at the base station. In addition, we extend the secure provenance scheme with functionality to detect packet drop attacks staged by malicious data forwarding nodes. We evaluate the proposed technique both analytically and empirically, and the results prove the effectiveness and efficiency of the lightweight secure provenance scheme in detecting packet forgery and loss attacks.","Encoding,
Security,
Data models,
Aggregates,
Base stations,
Educational institutions,
Electronic mail"
A Platform for Smart Object Virtualization and Composition,"One of the most challenging objectives of the Internet of Things (IoT) domain is the identification of interaction paradigms and communication standards to integrate smart objects (SOs), i.e., physical objects able to interact with the network. Such interaction paradigms and communication protocols belong to what can be called the IoT application layer, on which this paper focuses. This paper presents app execution platform (AEP), a platform that supports the design, deployment, execution, and management of IoT applications in the domain of smart home, smart car, and smart city. AEP was designed to coherently fulfill a set of requirements covered only partially or in a fragmented way by other IoT application platforms. AEP focuses on SO virtualization and on composite application (CA) orchestration and supports dynamic object availability.","Internet of things,
Software,
Semantics,
Context,
Java,
Virtualization,
Protocols"
Associating neural word embeddings with deep image representations using Fisher Vectors,"In recent years, the problem of associating a sentence with an image has gained a lot of attention. This work continues to push the envelope and makes further progress in the performance of image annotation and image search by a sentence tasks. In this work, we are using the Fisher Vector as a sentence representation by pooling the word2vec embedding of each word in the sentence. The Fisher Vector is typically taken as the gradients of the log-likelihood of descriptors, with respect to the parameters of a Gaussian Mixture Model (GMM). In this work we present two other Mixture Models and derive their Expectation-Maximization and Fisher Vector expressions. The first is a Laplacian Mixture Model (LMM), which is based on the Laplacian distribution. The second Mixture Model presented is a Hybrid Gaussian-Laplacian Mixture Model (HGLMM) which is based on a weighted geometric mean of the Gaussian and Laplacian distribution. Finally, by using the new Fisher Vectors derived from HGLMMs to represent sentences, we achieve state-of-the-art results for both the image annotation and the image search by a sentence tasks on four benchmarks: Pascal1K, Flickr8K, Flickr30K, and COCO.","Laplace equations,
Mixture models,
Mathematical model,
Neural networks,
Gaussian distribution,
Covariance matrices,
Pipelines"
Frequency-Modulated Lorentz Force Magnetometer With Enhanced Sensitivity via Mechanical Amplification,"This letter presents a micromachined silicon Lorentz force magnetometer, which consists of a flexural beam resonator coupled to current-carrying silicon beams via a microleverage mechanism. The flexural beam resonator is a force sensor, which measures the magnetic field through resonant frequency shift induced by the Lorentz force, which acts as an axial load. Previous frequency-modulated Lorentz force magnetometers suffer from low sensitivity, limited by both fabrication restrictions and lack of a force amplification mechanism. In this letter, the microleverage mechanism amplifies the Lorentz force, thereby enhancing the sensitivity of the magnetometer by a factor of 42. The device has a measured sensitivity of 6687 ppm/(mA · T), which is two orders of magnitude larger than the prior state-of-the-art. The measured results agree with an analytical model and finite-element analysis. The frequency stability of the sensor is limited by the quality factor (Q) of 540, which can be increased through improved vacuum packaging.","Magnetometers,
Lorentz covariance,
Sensitivity,
Magnetic resonance,
Frequency measurement,
Frequency modulation"
Software Implementation of an Attribute-Based Encryption Scheme,"A ciphertext-policy attribute-based encryption protocol uses bilinear pairings to provide control access mechanisms, where the set of user's attributes is specified by means of a linear secret sharing scheme. In this paper we present the design of a software cryptographic library that achieves record timings for the computation of a 126-bit security level attribute-based encryption scheme. We developed all the required auxiliary building blocks and compared the computational weight that each of them adds to the overall performance of this protocol. In particular, our single pairing and multi-pairing implementations achieve state-of-the-art time performance at the 126-bit security level.","Protocols,
Elliptic curves,
Encryption,
Software,
Hospitals"
Non-Rigid Graph Registration Using Active Testing Search,"We present a new approach for matching sets of branching curvilinear structures that form graphs embedded in {\mathbb {R}}^2 or {\mathbb {R}}^3 and may be subject to deformations. Unlike earlier methods, ours does not rely on local appearance similarity nor does require a good initial alignment. Furthermore, it can cope with non-linear deformations, topological differences, and partial graphs. To handle arbitrary non-linear deformations, we use Gaussian process regressions to represent the geometrical mapping relating the two graphs. In the absence of appearance information, we iteratively establish correspondences between points, update the mapping accordingly, and use it to estimate where to find the most likely correspondences that will be used in the next step. To make the computation tractable for large graphs, the set of new potential matches considered at each iteration is not selected at random as with many RANSAC-based algorithms. Instead, we introduce a so-called Active Testing Search strategy that performs a priority search to favor the most likely matches and speed-up the process. We demonstrate the effectiveness of our approach first on synthetic cases and then on angiography data, retinal fundus images, and microscopy image stacks acquired at very different resolutions.","Image resolution,
Gaussian processes,
Testing,
Microscopy,
Noise,
Search problems,
Retina"
Analysis and Design Guide of Active EMI Filter in a Compact Package for Reduction of Common-Mode Conducted Emissions,"A common-mode (CM) active filter was designed in a compact package to suppress CM conducted emissions at a switching mode power supply (SMPS). Based on the analytical expressions considering both stability and performance, the design and optimization rules for the proposed active filter have been presented. After verifying its performance by measurements using vector network analysis, the proposed filter was installed in a 200-W SMPS board with 64 and 110 kHz switching frequencies, demonstrating its usefulness by experiments. The performance degradation due to the magnetic saturation and the AEF grounding impedance was also analyzed and investigated.","Noise,
Impedance,
Capacitors,
Inductors,
Electromagnetic interference,
Switched-mode power supply,
Stability analysis"
A Compact Variable Stiffness and Damping Shock Absorber for Vehicle Suspension,A shock absorber is an important device for vehicle suspension. The semi-active suspension requires the damping or stiffness of the shock absorber to be controllable. This paper proposed a novel compact shock absorber with both damping and stiffness variable characteristics. The shock absorber is developed based on MR fluid through an innovative design. A prototype is tested by MTS to characterize the variable damping and stiffness properties. A mathematical model that incorporated the Bingham model is established and an optimization method is adopted to identify the parameters. The coherence of experiments and the proposed model verified the control ability of dual damping and stiffness of the shock absorber.,"Damping,
Shock absorbers,
Springs,
Force,
Vehicles,
Vibrations"
Estimating the Aboveground Dry Biomass of Grass by Assimilation of Retrieved LAI Into a Crop Growth Model,"This study presents a method to assimilate leaf area index (LAI) retrieved from MODIS data using a physically based method into a soil-water-atmosphere-plant (SWAP) model to estimate the aboveground dry biomass of grass in the Ruoergai grassland, China. The assimilation method consists of reinitializing the model with optimal input parameters that allow a better temporal agreement between the LAI simulated by the SWAP model and the LA! retrieved from MODIS data. The minimization is performed by a four-dimensional variational data assimilation (4D-VAR) algorithm but which is challenged by the development of the adjoint model. The automatic differentiation (AD) technique is thus used to provide the adjoint model at the level of computer language codes. After the re-initialization, the simulated aboveground dry biomass value is compared with ground measurements taken in early August2013. The results show that the biomass can be estimated with highly satisfactory accuracy level through the assimilation method with R2(the deterministic coefficient) = 0.73 and RMSE(root-mean-square error) = 617.94 kg ha-1. The accuracy is further improved when the newly derived RMSELAI values are used as observation errors in the assimilation process, with R2 = 0.76 and RMSE = 542.52 kgha-1. Both assimilation strategies yield a significant improvement in SWAP model accuracy with respect to no significant correlation obtained when the SWAP model is run alone with constant values of the input parameters employed for the whole area. The validity of the 4D-VAR method for biomass estimation is well demonstrated.","Biological system modeling,
Agriculture,
Biomass,
Computational modeling,
Table lookup,
Data models,
MODIS"
Geographic Routing in Clustered Wireless Sensor Networks Among Obstacles,"An important issue of research in wireless sensor networks (WSNs) is to dynamically organize the sensors into a wireless network and route the sensory data from sensors to a sink. Clustering in WSNs is an effective technique for prolonging the network lifetime. In most of the traditional routing in clustered WSNs assumes that there is no obstacle in a field of interest. Although it is not a realistic assumption, it eliminates the effects of obstacles in routing the sensory data. In this paper, we first propose a clustering technique in WSNs named energy-efficient homogeneous clustering that periodically selects the cluster heads according to a hybrid of their residual energy and a secondary parameter, such as the utility of the sensor to its neighbors. In this way, the selected cluster heads have equal number of neighbors and residual energy. We then present a route optimization technique in clustered WSNs among obstacles using Dijkstra's shortest path algorithm. We demonstrate that our work reduces the average hop count, packet delay, and energy-consumption of WSNs.","Sensors,
Wireless sensor networks,
Routing,
Energy consumption,
Delays,
Time complexity,
Optimization"
Semi-Local Structure Patterns for Robust Face Detection,"In many image processing and computer vision problems, including face detection, local structure patterns such as local binary patterns (LBP) and modified census transform (MCT) have been adopted in widespread applications due to their robustness against illumination changes. However, being reliant on the local differences between neighboring pixels, they are inevitably sensitive to noise. To overcome the problem of noise-vulnerability of the conventional local structure patterns, we propose semi-local structure patterns (SLSP), a novel feature extraction method based on local region-based differences. The SLSP is robust to illumination variations, distortion, and sparse noise because it encodes the relative sizes of the central region with locally neighboring regions into a binary code. The principle of SLSP leads noise-robust expansions of LBP and MCT feature extraction frameworks. In a statistical analysis, we find that the proposed methods transform a substantial amount of random noise patterns in face images into more meaningful uniform patterns. The empirical results on the MIT + CMU dataset and FDDB (face detection dataset and benchmark) show that the proposed semi-local patterns applied to LBP and MCT feature extraction frameworks outperform the conventional LBP and MCT features in AdaBoost-based face detectors, with much higher detection rates.","Noise,
Face detection,
Lighting,
Face,
Transforms,
Feature extraction,
Robustness"
Efficient Motif Discovery for Large-Scale Time Series in Healthcare,"Analyzing time series data can reveal the temporal behavior of the underlying mechanism producing the data. Time series motifs, which are similar subsequences or frequently occurring patterns, have significant meanings for researchers especially in medical domain. With the fast growth of time series data, traditional methods for motif discovery are inefficient and not applicable to large-scale data. This work proposes an efficient Motif Discovery method for Large-scale time series (MDLats). By computing standard motifs, MDLats eliminates a majority of redundant computation in the related arts and reuses existing information to the maximum. All the motif types and subsequences are generated for subsequent analysis and classification. Our system is implemented on a Hadoop platform and deployed in a hospital for clinical electrocardiography classification. The experiments on real-world healthcare data show that MDLats outperform the state-of-the-art methods even in large time series.","Time series analysis,
Standards,
Approximation algorithms,
Algorithm design and analysis,
Euclidean distance,
Electrocardiography,
Electronic mail"
Robotic Fish: Design and Characterization of an Interactive iDevice-Controlled Robotic Fish for Informal Science Education,"In this article, we present the design, development, and characterization of a biomimetic robotic fish remotely controlled by an iDevice application (app) for use in informal science education. By leveraging robots, biomimicry, and iDevices, we seek to establish an engaging and unique experience for free-choice learners visiting aquariums, zoos, museums, and other public venues. The robotic fish incorporates a three-degree-of-freedom tail along with a combined pitch and buoyancy control system, allowing for high maneuverability in an underwater three-dimensional (3-D) space. The iDevice app implements three modes of control that offer a vividly colored, intuitive, and user-friendly theme to enhance the user experience when controlling the biomimetic robotic fish. In particular, the implemented modes vary in the degree of autonomy of the robotic fish, from fully autonomous to remotely controlled. A series of tests are conducted to assess the performance of the robotic fish and the interactive control modes. Finally, a usability study on elementary school students is performed to learn about students' perception of the platform and the various control modes.","Marine animals,
Robot sensing systems,
Fish,
Servomotors,
Mobile robots,
Marine technology"
Compact and Discriminative Descriptor Inference Using Multi-Cues,"Feature descriptors around local interest points are widely used in human action recognition both for images and videos. However, each kind of descriptors describes the local characteristics around the reference point only from one cue. To enhance the descriptive and discriminative ability from multiple cues, this paper proposes a descriptor learning framework to optimize the descriptors at the source by learning a projection from multiple descriptors' spaces to a new Euclidean space. In this space, multiple cues and characteristics of different descriptors are fused and complemented for each other. In order to make the new descriptor more discriminative, we learn the multi-cue projection by the minimization of the ratio of within-class scatter to between-class scatter, and therefore, the discriminative ability of the projected descriptor is enhanced. In the experiment, we evaluate our framework on the tasks of action recognition from still images and videos. Experimental results on two benchmark image and two benchmark video data sets demonstrate the effectiveness and better performance of our method.","Videos,
Shape,
Image recognition,
Context,
Optimization,
Image color analysis,
Linear programming"
Area-Efficient 128- to 2048/1536-Point Pipeline FFT Processor for LTE and Mobile WiMAX Systems,"Fast Fourier transform (FFT) is widely used in digital signal processing and telecommunications, particularly in orthogonal frequency division multiplexing systems, to overcome the problems associated with orthogonal subcarriers. This paper presents a novel 128/256/512/1024/1536/2048-point single-path delay feedback (SDF) pipeline FFT processor for long-term evolution and mobile worldwide interoperability for microwave access systems. The proposed design employs a low-cost computation scheme to enable 1536-point FFT, which significantly reduces hardware costs as well as power consumption. In conjunction with the aforementioned 1536-point FFT computation scheme, the proposed design included an efficient three-stage SDF pipeline architecture on which to implement a radix-3 FFT. The new radix-3 SDF pipeline FFT processor simplifies its data flow and is easy to control, and the complexity of the resulting hardware is lower than that of existing structures. This paper also formulated a hardware-sharing mechanism to reduce the memory space requirements of the proposed 1536-point FFT computation scheme. The proposed design was implemented using 90 nm CMOS technology. Postlayout simulation results revealed a die area of approximately 1.44×1.44 mm2 with power consumption of only 9.3 mW at 40 MHz.","Pipelines,
Hardware,
WiMAX,
Signal to noise ratio,
Mobile communication,
Memory management"
Massive uncoordinated multiway relay networks with simultaneous detections,"In this paper, we consider multiway relay networks with massive number of users. In this situation a fixed transmission scheduling is difficult to apply. We propose uncoordinated communications using the concept of coded slotted ALOHA (CSA), where simultaneous transmitted signals are detected using iterative demapping (IDM) algorithm to improve the success rate probability. We allow each user to transmit the information via any random time slots (during the contention period) to the network. We show the bound of the proposed system and confirm an achievable point using practical coding. We also evaluate the bit-error-rate (BER) performance of the proposed technique via computer simulations. The results indicate that even though with the offered traffic of 1.11 packets/slot, reliable communications is achievable. It is also validated that the proposed system works very well even in relatively low signal-to-noise ratio (SNR) environments. Moreover, the packet-loss-rate (PLR) evaluation shows that the proposed technique outperforms the conventional CSA without simultaneous detection algorithm.","Relay networks (telecommunications),
Decoding,
Iterative decoding,
Upper bound,
Conferences,
Wireless networks"
Phase Transitions in Spectral Community Detection,"Consider a network consisting of two subnetworks (communities) connected by some external edges. Given the network topology, the community detection problem can be cast as a graph partitioning problem that aims to identify the external edges as the graph cut that separates these two subnetworks. In this paper, we consider a general model where two arbitrarily connected subnetworks are connected by random external edges. Using random matrix theory and concentration inequalities, we show that when one performs community detection via spectral clustering there exists an abrupt phase transition as a function of the random external edge connection probability. Specifically, the community detection performance transitions from almost perfect detectability to low detectability near some critical value of the random external edge connection probability. We derive upper and lower bounds on the critical value and show that the bounds are equal to each other when two subnetwork sizes are identical. Using simulated and experimental data we show how these bounds can be empirically estimated to validate the detection reliability of any discovered communities.","Communities,
Image edge detection,
Stochastic processes,
Laplace equations,
Network topology,
Signal processing,
Reliability"
Multilevel Fast Adaptive Cross-Approximation Algorithm With Characteristic Basis Functions,"This paper presents a multilevel fast adaptive crossapproximation (MLFACA) algorithm for accelerated iterative solution of the method of moments (MoM) matrix equation for electrically large targets. The MLFACA compresses the impedance submatrices between well-separated blocks into products of sparse matrices, constructed with the aid of the fast adaptive cross-sampling (FACS) scheme and the butterfly algorithm. As a result, the MLFACA can reduce both the computational time and the storage of the MoM to O(N log2N), where N is the number of the Rao-Wilton-Glisson (RWG) basis functions in the analyzed target. Meanwhile, the MLFACA maintains the adaptive and kernel-independent properties. Furthermore, the characteristic basis function method (CBFM) is employed to decrease the size of the outer matrices of the MLFACA to further reduce the storage and iteration time. Numerical results are presented to demonstrate the advantages of the proposed method, including a successful solution of a scattering problem involving 10 861 668 RWG basis functions.","Complexity theory,
Impedance,
Matrix decomposition,
Method of moments,
Approximation algorithms,
Approximation methods"
A Step Counting Algorithm for Smartphone Users: Design and Implementation,"The step count is an important information for developing services for smartphone users. Most existing step counting solutions restrict that: the phone has to be fixed to the user and the user cannot use the phone naturally while walking. We can see that these restrictions are inconvenient for users. In this paper, we propose a step calculation algorithm, which can relieve the above restrictions and can count users' steps precisely. The proposed algorithm is composed of two phases. The first phase collects linear acceleration and gravity values from the smartphone's accelerometer. Then, this phase derives the horizontal components of the perceived linear acceleration values and identifies possible start points of periodical regular fluctuations (of linear acceleration measurements). The second phase adopts the concept of correlation coefficients to identify whether the collected sensing measurements exhibit similar tendencies and calculates step counts. In this paper, we implement the proposed method on the android platform. The experiment results indicate that the proposed scheme can analyze gaits accurately and count steps effectively.","Acceleration,
Sensors,
Legged locomotion,
Accelerometers,
Correlation,
Gravity,
Data collection"
PPS: Privacy-Preserving Strategyproof Social-Efficient Spectrum Auction Mechanisms,"Many spectrum auction mechanisms have been proposed for spectrum allocation problem, and unfortunately, few of them protect the bid privacy of bidders and achieve good social efficiency. In this paper, we propose PPS, a Privacy Preserving Strategyproof spectrum auction framework. We design two schemes based on PPS separately for 1) the single-unit auction model (SUA), where only single channel will be sold in the spectrum market; and 2) the multi-unit auction model (MUA), where the primary user subleases multi-unit channels to the secondary users and each of the secondary users wants to access multi-unit channels either. Since the social efficiency maximization problem is NP-hard in both auction models, we present allocation mechanisms with approximation factors of (1 + ε) and 32 separately for SUA and MUA, and further judiciously design strategyproof auction mechanisms with privacy preserving based on them. Our extensive evaluations show that our mechanisms achieve good social efficiency and with low computation and communication overhead.","Privacy,
Resource management,
Encryption,
Approximation methods,
Public key,
Educational institutions"
Alternating Optimization of Sensing Matrix and Sparsifying Dictionary for Compressed Sensing,"This paper deals with alternating optimization of sensing matrix and sparsifying dictionary for compressed sensing systems. Under the same framework proposed by J. M. Duarte-Carvajalino and G. Sapiro, a novel algorithm for optimal sparsifying dictionary design is derived with an optimized sensing matrix embedded. A closed-form solution to the optimal dictionary design problem is obtained. A new measure is proposed for optimizing sensing matrix and an algorithm is developed for solving the corresponding optimization problem. Experiments are carried out with synthetic data and real images, which demonstrate promising performance of the proposed algorithms and superiority of the CS system designed with the optimized sensing matrix and dictionary to existing ones in terms of signal reconstruction accuracy. Particularly, the proposed CS system yields in general a much improved performance than those designed using previous methods in terms of peak signal-to-noise ratio for the application to image compression.","Dictionaries,
Sensors,
Signal processing algorithms,
Vectors,
Sparse matrices,
Signal reconstruction"
Indoor Positioning of a Robotic Walking Assistant for Large Public Environments,"Indoor localization and position tracking are essential to support applications and services for ambient-assisted living. While the problem of indoor localization is still open and already quite complex per se, in large public places, additional issues of cost, accuracy, and scalability arise. In this paper, the position estimation and tracking technique developed within the project devices for assisted living (DALi) is described, analyzed through simulations, and finally validated by means of a variety of experiments on the field. The goal of the DALi project is to design a robotic wheeled walker guiding people with psychomotor problems. Indeed, people with motor or cognitive impairments are often afraid of moving in large and crowded environments (e.g., because they could lose the sense of direction). In order to mitigate this problem, the position tracking approach described in this paper is based on multisensor data fusion and it is conceived to assure a good tradeoff between target accuracy, level of confidence, and deployment costs. Quite interestingly, the same approach could be used for indoor automated guided vehicles and robotics.","Radiofrequency identification,
Accuracy,
Cameras,
Robot sensing systems,
Wheels,
Uncertainty"
Robust Discriminative Tracking via Landmark-Based Label Propagation,"The appearance of an object could be continuously changing during tracking, thereby being not independent identically distributed. A good discriminative tracker often needs a large number of training samples to fit the underlying data distribution, which is impractical for visual tracking. In this paper, we present a new discriminative tracker via landmark-based label propagation (LLP) that is nonparametric and makes no specific assumption about the sample distribution. With an undirected graph representation of samples, the LLP locally approximates the soft label of each sample by a linear combination of labels on its nearby landmarks. It is able to effectively propagate a limited amount of initial labels to a large amount of unlabeled samples. To this end, we introduce a local landmarks approximation method to compute the cross-similarity matrix between the whole data and landmarks. Moreover, a soft label prediction function incorporating the graph Laplacian regularizer is used to diffuse the known labels to all the unlabeled vertices in the graph, which explicitly considers the local geometrical structure of all samples. Tracking is then carried out within a Bayesian inference framework, where the soft label prediction value is used to construct the observation model. Both qualitative and quantitative evaluations on the benchmark data set containing 51 challenging image sequences demonstrate that the proposed algorithm outperforms the state-of-the-art methods.",
A Distributed Deployment Strategy for a Network of Cooperative Autonomous Vehicles,"This brief presents a distributed deployment algorithm for a network of heterogeneous mobile agents to minimize a prescribed cost function. This function is concerned with the cost of serving the entire field by all agents, where the so called operation cost of different agents are not necessarily the same. The problem is investigated for the case where agents have different types of dynamics. Using a multiplicatively-weighted Voronoi diagram, the field is partitioned to smaller regions (one for each agent). A distributed coverage control law is then provided that guarantees the convergence of agents to the optimal configuration with respect to the above-mentioned cost function. The effectiveness of the proposed algorithm is demonstrated by simulations and experiments on a testbed with two types of unmanned vehicles (aerial and ground).","Vehicle dynamics,
Mobile robots,
Mobile agents,
Cost function,
Robot sensing systems,
Trajectory"
Selective restore: An energy efficient read disturbance mitigation scheme for future STT-MRAM,"STT-MRAM (Spin-Transfer Torque Magnetic RAM) has recently emerged as one of the most promising memory technologies for constructing large capacity last level cache (LLC) of low power mobile processors. With fast technology scaling, STT-MRAM read operations will become destructive such that post-read restores are inevitable to ensure data reliability. However, frequent restores introduce large energy overheads. In this paper, we propose Selective Restore (SR), an energy efficient scheme to mitigate the restore overheads. Given a L2 cacheline disturbed from a read operation, SR postpones its restore till the cacheline being evicted from the upper level cache L1. Based on the status of the line at the eviction time, SR selectively restores the disturbed cells to achieve energy efficiency. Our experimental results show that SR improves system performance by 5% and reduces dynamic energy consumption by 62%.","Random access memory,
Magnetic tunneling,
Energy consumption,
Program processors,
Energy efficiency,
Mobile communication,
Writing"
3-D Model-Based Multi-Camera Deployment: A Recursive Convex Optimization Approach,"Based on a convex optimization approach, we propose a new method of multi-camera deployment for visual coverage of a 3-D object surface. In particular, the optimal placement of a single camera is first formulated as translation and rotation convex optimization problems, respectively, over a set of covered triangle pieces on the target object. The convex optimization is recursively applied to expand the covered area of the single camera, with the initially covered triangle pieces being chosen along the object boundary for the first trial through a selection criterion. Then, the same optimization procedures are applied to place the next camera and thereafter. It is pointed out that our optimization approach guarantees that each camera is placed at the optimal pose in some sense for a group of triangles instead of a single piece. This feature, together with the selection criterion for initially covered triangles, reduces the number of operating cameras while still satisfying various constraint requirements such as resolution, field of view, blur, and occlusion. Both simulation and experimental results are presented to show superior performance of the proposed approach, comparing with the results from other existing methods.","Cameras,
Solid modeling,
Convex functions,
Visualization,
Optimization,
Inspection,
Design automation"
BRAINIAC: Bringing reliable accuracy into neurally-implemented approximate computing,"Applications with large amounts of data, real-time constraints, ultra-low power requirements, and heavy computational complexity present significant challenges for modern computing systems, and often fall within the category of high performance computing (HPC). As such, computer architects have looked to high performance single instruction multiple data (SIMD) architectures, such as accelerator-rich platforms, for handling these workloads. However, since the results of these applications do not always require exact precision, approximate computing may also be leveraged. In this work, we introduce BRAINIAC, a heterogeneous platform that combines precise accelerators with neural-network-based approximate accelerators. These reconfigurable accelerators are leveraged in a multi-stage flow that begins with simple approximations and resorts to more complex ones as needed. We employ high-level, application-specific light-weight checks (LWCs) to throttle this multi-stage acceleration flow and reliably ensure user-specified accuracy at runtime. Evaluation of the performance and energy of our heterogeneous platform for error tolerance thresholds of 5%-25% demonstrates an average of 3× gain over computation that only includes precise acceleration, and 15×-35× gain over software-based computation.","Approximation methods,
Acceleration,
Artificial neural networks,
Hardware,
RNA,
Benchmark testing,
Software"
Energy-Efficient Approximate Multiplication for Digital Signal Processing and Classification Applications,"The need to support various digital signal processing (DSP) and classification applications on energy-constrained devices has steadily grown. Such applications often extensively perform matrix multiplications using fixed-point arithmetic while exhibiting tolerance for some computational errors. Hence, improving the energy efficiency of multiplications is critical. In this brief, we propose multiplier architectures that can tradeoff computational accuracy with energy consumption at design time. Compared with a precise multiplier, the proposed multiplier can consume 58% less energy/op with average computational error of
∼1
%. Finally, we demonstrate that such a small computational error does not notably impact the quality of DSP and the accuracy of classification applications.","Accuracy,
Digital signal processing,
Energy consumption,
Multiplexing,
Very large scale integration,
Image recognition,
Algorithm design and analysis"
Decentralized control of Partially Observable Markov Decision Processes using belief space macro-actions,"The focus of this paper is on solving multi-robot planning problems in continuous spaces with partial observability. Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) are general models for multi-robot coordination problems, but representing and solving Dec-POMDPs is often intractable for large problems. To allow for a high-level representation that is natural for multi-robot problems and scalable to large discrete and continuous problems, this paper extends the Dec-POMDP model to the Decentralized Partially Observable Semi-Markov Decision Process (Dec-POSMDP). The Dec-POSMDP formulation allows asynchronous decision-making by the robots, which is crucial in multi-robot domains. We also present an algorithm for solving this Dec-POSMDP which is much more scalable than previous methods since it can incorporate closed-loop belief space macro-actions in planning. These macro-actions are automatically constructed to produce robust solutions. The proposed method's performance is evaluated on a complex multi-robot package delivery problem under uncertainty, showing that our approach can naturally represent multi-robot problems and provide high-quality solutions for large-scale problems.","Joints,
Bismuth,
Robot kinematics,
History,
Planning,
Decision making"
Transfer Zero-Entropy and Its Application for Capturing Cause and Effect Relationship Between Variables,"Detection of causality is an important and challenging problem in root cause and hazard propagation analysis. It has been shown that the transfer entropy approach is a very useful tool in quantifying directional causal influence for both linear and nonlinear relationships. A key assumption for this method is that the sampled data should follow a well-defined probability distribution; yet this assumption may not hold for some industrial process data. In this paper, a new information theory-based measure, transfer 0-entropy (T0E), is proposed for causality analysis on the basis of the definitions of 0-entropy and 0-information without assuming a probability space. For the cases of more than two variables, a direct T0E (DT0E) concept is presented to detect whether there is a direct information and/or material flow pathway from one variable to another. Estimation methods for the T0E and the DT0E are addressed. The effectiveness of the proposed method is illustrated by two data sets, one based on data from a pilot scale process and a second evaluation based on data from a benchmark industrial case study.","Random variables,
Joints,
Entropy,
Estimation,
Uncertainty,
Materials,
Probability distribution"
Terahertz Conductivity of Copper Surfaces,"Terahertz (THz) radiation holds great promise for applications in communications, molecular detection, and imaging. Effective THz system design requires accurate models for the frequency-dependent conductivity of metals and the effect of surface roughness on conduction loss. However, predictive methods are currently unverified in the region between 0.3 and 0.9 THz because few experimental data exist in this regime. In order to address this problem, we have measured the conductivity of copper, of various surface roughnesses, using a semi-confocal open resonator system. This paper describes our measurements of the THz conductivity, dc conductivity, roughness, and microstructure of copper. We show that the classical Drude theory is sufficient for predicting the THz conductivity of copper at room temperature and that dissipation loss enhancement caused by surface roughness is modeled better by the Hammerstad-Bekkadal formula than second-order small perturbation theory.","Rough surfaces,
Surface roughness,
Conductivity,
Copper,
Surface topography,
Surface waves,
Optical surface waves"
Utility Functions and Resource Management in an Oversubscribed Heterogeneous Computing Environment,"We model an oversubscribed heterogeneous computing system where tasks arrive dynamically and a scheduler maps the tasks to machines for execution. The environment and workloads are based on those being investigated by the Extreme Scale Systems Center at Oak Ridge National Laboratory. Utility functions that are designed based on specifications from the system owner and users are used to create a metric for the performance of resource allocation heuristics. Each task has a time-varying utility (importance) that the enterprise will earn based on when the task successfully completes execution. We design multiple heuristics, which include a technique to drop low utility-earning tasks, to maximize the total utility that can be earned by completing tasks. The heuristics are evaluated using simulation experiments with two levels of oversubscription. The results show the benefit of having fast heuristics that account for the importance of a task and the heterogeneity of the environment when making allocation decisions in an oversubscribed environment. The ability to drop low utility-earning tasks allow the heuristics to tolerate the high oversubscription as well as earn significant utility.","Computational modeling,
Resource management,
Electronic mail,
US Department of Defense,
Measurement,
Collaboration,
Shape"
Experimental Demonstration of Real-Time High-Level QAM-Encoded Direct-Detection Optical OFDM Systems,"In this paper, high-level quadrature amplitude modulation (QAM)-encoded real-time orthogonal frequency division multiplexing (OFDM) transceivers are implemented with two field programmable gate arrays and high-resolution digital-to-analog converter (DAC) and analog-to-digital converter (ADC). Some key digital signal processing (DSP) algorithms for real-time direct-detection optical OFDM (DDO-OFDM) system are presented and described in detail. To improve the effective number of bits of ADC and reduce quantization noise, the DAC operates at 5 GS/s with an oversampling factor of 2. Meanwhile, the optimal digital clipping ratio at the transmitter is also investigated by numerical simulation to optimize the performance of the real-time transmitter. The results show that the real-time measured BERs after 10-km SSMF are below the hard-decision forward error correction threshold of
3.8×
10
−3
. For comparison, the off-line BER performance is also analyzed using off-line DSP approaches. It shows that there is a negligible power penalty between the offline and real-time processing results. To the best of our knowledge, we have achieved the highest modulation format (1024-QAM) for real-time optical OFDM systems.","OFDM,
Synchronization,
Real-time systems,
Optical transmitters,
Quadrature amplitude modulation,
Digital signal processing"
Automatic Detection and Resolution of Lexical Ambiguity in Process Models,"System-related engineering tasks are often conducted using process models. In this context, it is essential that these models do not contain structural or terminological inconsistencies. To this end, several automatic analysis techniques have been proposed to support quality assurance. While formal properties of control flow can be checked in an automated fashion, there is a lack of techniques addressing textual quality. More specifically, there is currently no technique available for handling the issue of lexical ambiguity caused by homonyms and synonyms. In this paper, we address this research gap and propose a technique that detects and resolves lexical ambiguities in process models. We evaluate the technique using three process model collections from practice varying in size, domain, and degree of standardization. The evaluation demonstrates that the technique significantly reduces the level of lexical ambiguity and that meaningful candidates are proposed for resolving ambiguity.","Unified modeling language,
Object oriented modeling,
Context,
Business,
Natural languages,
Manuals,
Vectors"
Objective Evaluation Criteria for Stereo Camera Shooting Quality Under Different Shooting Parameters and Shooting Distances,"The vigorous development of 3D technology has improved the photography technology of stereo cameras constantly. However, there are no widely recognized objective evaluation criteria for stereo camera shooting quality under different shooting parameters and shooting distances. At the same time, no shooting guideline can be used for reference when people take stereoscopic images. To solve this problem, we propose the objective evaluation criteria of shooting quality of two types of stereo cameras (parallel and toed-in camera configurations) under three shooting conditions (macro shooting, short, and long distance shooting). In our work, several prominent evaluation factors are built by analyzing the characteristics of each shooting condition. Based on the effective five-point scale used in our subjective experiments, the relationships between shooting factors and shooting quality are obtained and then effectively integrated together to build the overall evaluation criteria. Finally, extensive experiments have been conducted, and the results demonstrate that the proposed approach can effectively evaluate the shooting quality of stereo cameras.","Cameras,
Visualization,
Three-dimensional displays,
Sensors,
Stereo image processing,
Convergence,
Indexes"
Query-Dependent Aesthetic Model With Deep Learning for Photo Quality Assessment,"The automatic assessment of photo quality from an aesthetic perspective is a very challenging problem. Most existing research has predominantly focused on the learning of a universal aesthetic model based on hand-crafted visual descriptors . However, this research paradigm can achieve only limited success because (1) such hand-crafted descriptors cannot well preserve abstract aesthetic properties , and (2) such a universal model cannot always capture the full diversity of visual content. To address these challenges, we propose in this paper a novel query-dependent aesthetic model with deep learning for photo quality assessment. In our method, deep aesthetic abstractions are discovered from massive images , whereas the aesthetic assessment model is learned in a query- dependent manner. Our work addresses the first problem by learning mid-level aesthetic feature abstractions via powerful deep convolutional neural networks to automatically capture the underlying aesthetic characteristics of the massive training images . Regarding the second problem, because photographers tend to employ different rules of photography for capturing different images , the aesthetic model should also be query- dependent . Specifically, given an image to be assessed, we first identify which aesthetic model should be applied for this particular image. Then, we build a unique aesthetic model of this type to assess its aesthetic quality. We conducted extensive experiments on two large-scale datasets and demonstrated that the proposed query-dependent model equipped with learned deep aesthetic abstractions significantly and consistently outperforms state-of-the-art hand-crafted feature -based and universal model-based methods.","Training,
Kernel,
Visualization,
Quality assessment,
Feature extraction,
Adaptation models,
Image color analysis"
A stigmergic approach to indoor localization using Bluetooth Low Energy beacons,"Localization of people and devices is one of the main building blocks of context aware systems since the user position represents the core information for detecting user's activities, devices activations, proximity to points of interest, etc. While for outdoor scenarios Global Positioning System (GPS) constitutes a reliable and easily available technology, for indoor scenarios GPS is largely unavailable. In this paper we present a range-based indoor localization system that exploits the Received Signal Strength (RSS) of Bluetooth Low Energy (BLE) beacon packets broadcast by anchor nodes and received by a BLE-enabled device. The method used to infer the user's position is based on stigmergy. We exploit the stigmergic marking process to create an on-line probability map identifying the user's position in the indoor environment.","Bluetooth,
Mobile nodes,
Wireless sensor networks,
IEEE 802.11 Standard,
Global Positioning System,
Hardware"
Extracting Development Tasks to Navigate Software Documentation,"Knowledge management plays a central role in many software development organizations. While much of the important technical knowledge can be captured in documentation, there often exists a gap between the information needs of software developers and the documentation structure. To help developers navigate documentation, we developed a technique for automatically extracting tasks from software documentation by conceptualizing tasks as specific programming actions that have been described in the documentation. More than 70 percent of the tasks we extracted from the documentation of two projects were judged meaningful by at least one of two developers. We present TaskNavigator, a user interface for search queries that suggests tasks extracted with our technique in an auto-complete list along with concepts, code elements, and section headers. We conducted a field study in which six professional developers used TaskNavigator for two weeks as part of their ongoing work. We found search results identified through extracted tasks to be more helpful to developers than those found through concepts, code elements, and section headers. The results indicate that task descriptions can be effectively extracted from software documentation, and that they help bridge the gap between documentation structure and the information needs of software developers.","Documentation,
Software,
Navigation,
Data mining,
Programming,
Natural language processing,
Subscriptions"
Reduced Reference Stereoscopic Image Quality Assessment Based on Binocular Perceptual Information,"In this paper, we propose a novel reduced reference stereoscopic image quality assessment (RR-SIQA) metric by using binocular perceptual information (BPI). BPI is represented by the distribution statistics of visual primitives in left and right views' images, which are extracted by sparse coding and representation . Specifically, entropy of the left view's image and entropy of the right view's image are used to represent monocular cue. Their mutual information is used to represent binocular cue. Constructively, we represent BPI as three numerical indicators . The difference of the original and distorted images' BPIs is taken as perceptual loss vector. The perceptual loss vector is used to compute the quality score for a stereoscopic image by a prediction function which is trained using support vector regression (SVR). Experimental results show that the proposed metric achieves significantly higher prediction accuracy than the state-of-the-art reduced reference SIQA methods and better than several state-of-the-art full reference SIQA methods on the LIVE phase II asymmetric databases.","Visual perception,
Quality assessment,
Stereo image processing,
Nonlinear distortion,
Entropy,
Mutual information"
Tactile Feedback of Object Slip Facilitates Virtual Object Manipulation,"Recent advances in myoelectric prosthetic technology have enabled more complex movements and interactions with objects, but the lack of natural haptic feedback makes object manipulation difficult to perform. Our research effort aims to develop haptic feedback systems for improving user performance in object manipulation. Specifically, in this work, we explore the effectiveness of vibratory tactile feedback of slip information for grasping objects without slipping. A user interacts with a virtual environment to complete a virtual grasp and hold task using a Sensable Phantom. Force feedback simulates contact with objects, and vibratory tactile feedback alerts the user when a virtual object is slipping from the grasp. Using this task, we found that tactile feedback significantly improved a user's ability to detect and respond to slip and to recover the slipping object when visual feedback was not available. This advantage of tactile feedback is especially important in conjunction with force feedback, which tends to reduce a subject's grasping forces and therefore encourage more slips. Our results demonstrate the potential of slip feedback to improve a prosthesis user's ability to interact with objects with less visual attention, aiding in performance of everyday manipulation tasks.","Object manipulation,
Visualization,
Prosthetics,
Tactile sensors,
Phantoms,
Force feedback"
Polar Codes: Speed of Polarization and Polynomial Gap to Capacity,"We prove that, for all binary-input symmetric memoryless channels, polar codes enable reliable communication at rates within an additive gap ε > 0 to the Shannon capacity with a block length, construction complexity, and decoding complexity, all bounded by a polynomial in 1/ε. Polar coding gives the first known explicit construction with rigorous proofs of all these properties; previous constructions were not known to achieve capacity with less than exp(1/ε) decoding complexity except for erasure channels. We establish the capacity-achieving property of polar codes via a direct analysis of the underlying martingale of conditional entropies, without relying on the martingale convergence theorem. This step gives rough polarization (noise levels ≈ ε for the good channels), which can then be adequately amplified by tracking the decay of the channel Bhattacharyya parameters. Our effective bounds imply that polar codes can have block length (and encoding/decoding complexity) bounded by a polynomial in 1/ε. The generator matrix of such polar codes can be constructed in polynomial time by algorithmically computing an adequate approximation of the polarization process.",
Active Data Selection for Motor Imagery EEG Classification,"Rejecting or selecting data from multiple trials of electroencephalography (EEG) recordings is crucial. We propose a sparsity-aware method to data selection from a set of multiple EEG recordings during motor-imagery tasks, aiming at brain machine interfaces (BMIs). Instead of empirical averaging over sample covariance matrices for multiple trials including low-quality data, which can lead to poor performance in BMI classification, we introduce weighted averaging with weight coefficients that can reject such trials. The weight coefficients are determined by the ℓ1-minimization problem that lead to sparse weights such that almost zero-values are allocated to low-quality trials. The proposed method was successfully applied for estimating covariance matrices for the so-called common spatial pattern (CSP) method, which is widely used for feature extraction from EEG in the two-class classification. Classification of EEG signals during motor imagery was examined to support the proposed method. It should be noted that the proposed data selection method can be applied to a number of variants of the original CSP method.","Electroencephalography,
Covariance matrices,
Joints,
Foot,
Optimization,
Passband,
Visualization"
Learning Representative Deep Features for Image Set Analysis,"This paper proposes to learn features from sets of labeled raw images. With this method, the problem of over-fitting can be effectively suppressed, so that deep CNNs can be trained from scratch with a small number of training data, i.e., 420 labeled albums with about 30 000 photos. This method can effectively deal with sets of images, no matter if the sets bear temporal structures. A typical approach to sequential image analysis usually leverages motions between adjacent frames, while the proposed method focuses on capturing the co-occurrences and frequencies of features. Nevertheless, our method outperforms previous best performers in terms of album classification, and achieves comparable or even better performances in terms of gait based human identification. These results demonstrate its effectiveness and good adaptivity to different kinds of set data.","Feature extraction,
Hidden Markov models,
Convolution,
Training data,
Videos,
Training,
Data models"
Scalable Elliptic Curve Cryptosystem FPGA Processor for NIST Prime Curves,"The architecture and the implementation of a high-performance scalable elliptic curve cryptography processor (ECP) are presented. The proposed ECP is able to support all five prime field elliptic curves recommended by the National Institute of Standards and Technology (NIST). The design takes advantage of the high-performance capabilities of the DSP48E slices available in Xilinx field-programmable gate arrays (FPGAs) to achieve high speed and low hardware resource utilization. The proposed design parallelizes the underlying prime field operations to reduce the latency of the elliptic curve point multiplication (ECPM) operation. Prime field inversion is performed efficiently using the same arithmetic blocks as the ones used for prime field multiplication and addition/subtraction. To the best of the authors' knowledge, the proposed scalable ECP is the fastest and smallest ECP that can support all five NIST recommended prime curves without the need to reconfigure the hardware. It can compute the ECPM between 1.709 and 28.04 ms using a Xilinx Virtex-5 FPGA.","Elliptic curve cryptography,
NIST,
Hardware,
Field programmable gate arrays,
Elliptic curves,
Random access memory"
Diversified Sensitivity-Based Undersampling for Imbalance Classification Problems,"Undersampling is a widely adopted method to deal with imbalance pattern classification problems. Current methods mainly depend on either random resampling on the majority class or resampling at the decision boundary. Random-based undersampling fails to take into consideration informative samples in the data while resampling at the decision boundary is sensitive to class overlapping. Both techniques ignore the distribution information of the training dataset. In this paper, we propose a diversified sensitivity-based undersampling method. Samples of the majority class are clustered to capture the distribution information and enhance the diversity of the resampling. A stochastic sensitivity measure is applied to select samples from both clusters of the majority class and the minority class. By iteratively clustering and sampling, a balanced set of samples yielding high classifier sensitivity is selected. The proposed method yields a good generalization capability for 14 UCI datasets.",
Robust visual SLAM across seasons,"In this paper, we present an appearance-based visual SLAM approach that focuses on detecting loop closures across seasons. Given two image sequences, our method first extracts one descriptor per image for both sequences using a deep convolutional neural network. Then, we compute a similarity matrix by comparing each image of a query sequence with a database. Finally, based on the similarity matrix, we formulate a flow network problem and compute matching hypotheses between sequences. In this way, our approach can handle partially matching routes, loops in the trajectory and different speeds of the robot. With a matching hypothesis as loop closure information and the odometry information of the robot, we formulate a graph based SLAM problem and compute a joint maximum likelihood trajectory.","Trajectory,
Robustness,
Simultaneous localization and mapping,
Visualization,
Databases,
Feature extraction"
NVMain 2.0: A User-Friendly Memory Simulator to Model (Non-)Volatile Memory Systems,"In this letter, a flexible memory simulator - NVMain 2.0, is introduced to help the community for modeling not only commodity DRAMs but also emerging memory technologies, such as die-stacked DRAM caches, non-volatile memories (e.g., STT-RAM, PCRAM, and ReRAM) including multi-level cells (MLC), and hybrid non-volatile plus DRAM memory systems. Compared to existing memory simulators, NVMain 2.0 features a flexible user interface with compelling simulation speed and the capability of providing sub-array-level parallelism, fine-grained refresh, MLC and data encoder modeling, and distributed energy profiling.","Nonvolatile memory,
Memory management,
Computational modeling,
Phase change random access memory,
Computer architecture"
A Multilevel Energy Buffer and Voltage Modulator for Grid-Interfaced Microinverters,"Microinverters operating into the single-phase grid from solar photovoltaic (PV) panels or other low-voltage sources must buffer the twice-line-frequency variations between the energy sourced by the PV panel and that required for the grid. Moreover, in addition to operating over wide average power ranges, they inherently operate over a wide range of voltage conversion ratios as the line voltage traverses a cycle. These factors make the design of microinverters challenging. This paper presents a multilevel energy buffer and voltage modulator (MEB) that significantly reduces the range of voltage conversion ratios that the dc-ac converter portion of the microinverter must operate over by stepping its effective input voltage in pace with the line voltage. The MEB partially replaces the original bulk input capacitor, and functions as an active energy buffer to reduce the total size of the twice-line-frequency energy buffering capacitance. The small additional loss of the MEB can be compensated by the improved efficiency of the dc-ac converter stage, leading to a higher overall system efficiency. The MEB architecture can be implemented in a variety of manners, allowing different design tradeoffs to be made. A prototype microinverter incorporating an MEB, designed for 27 to 38 V dc input voltage, 230-V rms ac output voltage, and rated for a line cycle average power of 70 W, has been built and tested in a grid-connected mode. It is shown that the MEB can successfully enhance the performance of a single-phase grid-interfaced microinverter by increasing its efficiency and reducing the total size of the twice-line-frequency energy buffering capacitance.","Capacitors,
Resonant frequency,
Inverters,
Frequency control,
Computer architecture,
Switching frequency,
Voltage control"
Learning coarse-to-fine sparselets for efficient object detection and scene classification,"Part model-based methods have been successfully applied to object detection and scene classification and have achieved state-of-the-art results. More recently the “sparselets” work [1-3] were introduced to serve as a universal set of shared basis learned from a large number of part detectors, resulting in notable speedup. Inspired by this framework, in this paper, we propose a novel scheme to train more effective sparselets with a coarse-to-fine framework. Specifically, we first train coarse sparselets to exploit the redundancy existing among part detectors by using an unsupervised single-hidden-layer auto-encoder. Then, we simultaneously train fine sparselets and activation vectors using a supervised single-hidden-layer neural network, in which sparselets training and discriminative activation vectors learning are jointly embedded into a unified framework. In order to adequately explore the discriminative information hidden in the part detectors and to achieve sparsity, we propose to optimize a new discriminative objective function by imposing L0-norm sparsity constraint on the activation vectors. By using the proposed framework, promising results for multi-class object detection and scene classification are achieved on PASCAL VOC 2007, MIT Scene-67, and UC Merced Land Use datasets, compared with the existing sparselets baseline methods.","Detectors,
Training,
Object detection,
Linear programming,
Visualization,
Artificial neural networks,
Computational modeling"
Multi-Modality Vertebra Recognition in Arbitrary Views Using 3D Deformable Hierarchical Model,"Computer-aided diagnosis of spine problems relies on the automatic identification of spine structures in images. The task of automatic vertebra recognition is to identify the global spine and local vertebra structural information such as spine shape, vertebra location and pose. Vertebra recognition is challenging due to the large appearance variations in different image modalities/views and the high geometric distortions in spine shape. Existing vertebra recognitions are usually simplified as vertebrae detections, which mainly focuses on the identification of vertebra locations and labels but cannot support further spine quantitative assessment. In this paper, we propose a vertebra recognition method using 3D deformable hierarchical model (DHM) to achieve cross-modality local vertebra location+pose identification with accurate vertebra labeling, and global 3D spine shape recovery. We recast vertebra recognition as deformable model matching, fitting the input spine images with the 3D DHM via deformations. The 3D model-matching mechanism provides a more comprehensive vertebra location+pose+label simultaneous identification than traditional vertebra location+label detection, and also provides an articulated 3D mesh model for the input spine section. Moreover, DHM can conduct versatile recognition on volume and multi-slice data, even on single slice. Experiments show our method can successfully extract vertebra locations, labels, and poses from multi-slice T1/T2 MR and volume CT, and can reconstruct 3D spine model on different image views such as lumbar, cervical, even whole spine. The resulting vertebra information and the recovered shape can be used for quantitative diagnosis of spine problems and can be easily digitalized and integrated in modern medical PACS systems.","Computed tomography,
Three-dimensional displays,
Solid modeling,
Shape,
Feature extraction,
Deformable models,
Training"
Bimorph pMUT with dual electrodes,"The concept of “bimorph” piezoelectric micromachined ultrasonic transducers (pMUTs) has been demonstrated by utilizing a two active AlN layers structure constructed in a CMOS-compatible process. The prototype device has two 0.95μm-thick AlN layers sandwiched by three 0.15μm-thick Mo electrodes. In a prototype, both an inner circular and an outer annular electrode are designed on a 230 μm in radius, circular-shape diaphragm. When actuated with the inner electrode of 160μm in radius, the pMUT has a resonant frequency of 198.8 kHz and central displacement of 407.4 nm/V. Under the differential drive scheme using the dual-electrodes for large acoustic outputs at a low frequency, the measured central displacement is 13.0 nm/V, which is about 400% higher than that of a unimorph AlN-pMUT under similar actuation conditions. As such, the dual-electrode bimorph pMUT presents the improved operation as compared with the state-of-the-art flat pMUT design to achieve enhanced acoustic outputs.",
Multiple Clone Row DRAM: A low latency and area optimized DRAM,"Several previous works have changed DRAM bank structure to reduce memory access latency and have shown performance improvement. However, changes in the area-optimized DRAM bank can incur large area-overhead. To solve this problem, we propose Multiple Clone Row DRAM (MCR-DRAM), which uses existing DRAM bank structure without any modification.",DRAM chips
Fault Ride-Through Capability Improvement of DFIG-Based Wind Turbine by Employing a Voltage-Compensation-Type Active SFCL,"Based on the considerations in creating a smart grid roadmap, an integrated application of renewable energy sources and superconducting power devices may bring more positive effects. This paper suggests a voltage-compensation-type active superconducting fault current limiter (SFCL) to enhance the fault ride-through capability of doubly fed induction generator (DFIG) for wind power generation. Since the active SFCL has higher controllability and flexibility than a common resistive- or inductive-type SFCL, its application may give better results. Related theory derivation, cost evaluation, and simulation analysis are conducted, and a comparison between the active SFCL and an inductive SFCL is performed. From the results, the active SFCL can limit the faulty currents flowing through the DFIG's stator and rotor windings and compensate the generator terminal voltage. The inductive SFCL may not evacuate the surplus active power during the grid fault; however, the active SFCL can smooth the DFIG's power fluctuation, and the stability of the wind power system can be well strengthened.","Circuit faults,
Superconducting transmission lines,
Rotors,
Voltage control,
Stator windings,
Windings"
Overcoming Computational Errors in Sensing Platforms Through Embedded Machine-Learning Kernels,"We present an approach for overcoming computational errors at run time that originate from static hardware faults in digital processors. The approach is based on embedded machine-learning stages that learn and model the statistics of the computational outputs in the presence of errors, resulting in an error-aware model for embedded analysis. We demonstrate, in hardware, two systems for analyzing sensor data: 1) an EEG-based seizure detector and 2) an ECG-based cardiac arrhythmia detector. The systems use a small kernel of fault-free hardware (constituting <;7.0% and <;31% of the total areas respectively) to construct and apply the error-aware model. The systems construct their own error-aware models with minimal overhead through the use of an embedded active-learning framework. Via an field-programmable gate array implementation for hardware experiments, stuck-at faults are injected at controllable rates within synthesized gate-level netlists to permit characterization. The seizure detector demonstrates restored performance despite faults on 0.018% of the circuit nodes [causing bit error rates (BERs) up to 45%], and the arrhythmia detector demonstrates restored performance despite faults on 2.7% of the circuit nodes (causing BERs up to 50%).","Circuit faults,
Training,
Hardware,
Kernel,
Brain modeling,
Data models,
Support vector machines"
Face Spoofing Detection Through Visual Codebooks of Spectral Temporal Cubes,"Despite important recent advances, the vulnerability of biometric systems to spoofing attacks is still an open problem. Spoof attacks occur when impostor users present synthetic biometric samples of a valid user to the biometric system seeking to deceive it. Considering the case of face biometrics, a spoofing attack consists in presenting a fake sample (e.g., photograph, digital video, or even a 3D mask) to the acquisition sensor with the facial information of a valid user. In this paper, we introduce a low cost and software-based method for detecting spoofing attempts in face recognition systems. Our hypothesis is that during acquisition, there will be inevitable artifacts left behind in the recaptured biometric samples allowing us to create a discriminative signature of the video generated by the biometric sensor. To characterize these artifacts, we extract time-spectral feature descriptors from the video, which can be understood as a low-level feature descriptor that gathers temporal and spectral information across the biometric sample and use the visual codebook concept to find mid-level feature descriptors computed from the low-level ones. Such descriptors are more robust for detecting several kinds of attacks than the low-level ones. The experimental results show the effectiveness of the proposed method for detecting different types of attacks in a variety of scenarios and data sets, including photos, videos, and 3D masks.","Visualization,
Noise,
Face,
Feature extraction,
Three-dimensional displays,
Face recognition"
A Rewarding Framework for Network Resource Sharing in Co-Channel Hybrid Access Femtocell Networks,"With the explosive growth in mobile data traffic, femtocell technology is regarded as the most effective way to enhance the mobile service quality and system capacity of cellular networks. However, the major problem with femtocell deployment is finding an appropriate access control mode that mobile operators and users are willing to adopt. Among the various kinds of access control modes, the hybrid access mode is considered the most promising because it allows femtocells to give preferential access to femtocell owners, while other public users can only access femtocells with certain restrictions. Because all femtocell owners are selfish, how to provide sufficient incentives so that they will share their femtocell resources is a challenging issue. To address the problem, we propose an economic framework for mobile operator and femtocell users based on game theoretical analysis. We also exploit the concept of revenue sharing, which provides a positive cycle to sustain the femtocell service. In the framework, a femtocell game is formulated where the femtocell owners determine the proportion of femtocell resources they will share with public users, while the operator maximizes its benefit by setting the ratio of the revenue distributed to femtocell owners. We analyze the existence and uniqueness of the Nash Equilibrium of the game. The results of extensive simulations show that the proposed framework maximizes the operator's benefit and satisfies the users' service requirements.",
Reconstructing the world* in six days,"We propose a novel, large-scale, structure-from-motion framework that advances the state of the art in data scalability from city-scale modeling (millions of images) to world-scale modeling (several tens of millions of images) using just a single computer. The main enabling technology is the use of a streaming-based framework for connected component discovery. Moreover, our system employs an adaptive, online, iconic image clustering approach based on an augmented bag-of-words representation, in order to balance the goals of registration, comprehensiveness, and data compactness. We demonstrate our proposal by operating on a recent publicly available 100 million image crowd-sourced photo collection containing images geographically distributed throughout the entire world. Results illustrate that our streaming-based approach does not compromise model completeness, but achieves unprecedented levels of efficiency and scalability.","Solid modeling,
Streaming media,
Visualization,
Computational modeling,
Registers,
Image reconstruction,
Scalability"
Evaluation of Contrast Enhancement by Carbon Nanotubes for Microwave-Induced Thermoacoustic Tomography,"Microwave-induced thermoacoustic tomography (MITAT) is a hybrid method which constructs images with ultrasound spatial resolution while exploiting dielectric contrast at microwave frequency. It has great potential in biomedical imaging especially in early breast cancer detection. The detection of early stage breast tumor in MITAT is challenged by the moderate endogenous dielectric contrast between malignant and healthy glandular tissues. In order to overcome this limitation, the performance of using carbon nanotubes (CNTs) as an imaging contrast enhancement agent is evaluated. First, the influences in dielectric and acoustic properties caused by CNTs are measured. Second, based on the measurements and the published data, numerical breast phantom is created and then used to explore the contrast enhancing effect of CNTs for MITAT, by an integrated simulation approach in both electromagnetic and acoustic field. With an experimental MITAT system, the thermoacoustic responses of tissue mimicking materials with different CNTs concentrations are also quantitatively investigated. Finally, the effectiveness of the contrast agent is also validated experimentally by using a MITAT system. The results show that the using of the dielectric contrast agent can effectively enhance the contrast of the MITAT image.","Acoustics,
Microwave imaging,
Dielectrics,
Tumors,
Conductivity,
Breast"
GPU Parallel Implementation of Support Vector Machines for Hyperspectral Image Classification,"Support vector machine (SVM) is considered as one of the most powerful classifiers for hyperspectral remote sensing images. However, it has high computational cost. In this paper, we propose a novel two-level parallel computing framework to accelerate the SVM-based classification by utilizing CUDA and OpenMP. For a binary SVM classifier, the kernel function is optimized on GPU, and then a second-order working set selection (WSS) procedure is employed and optimized especially for GPU to reduce the cost of communication between GPU and host. In addition to the parallel binary SVM classifier on GPU as dataprocessing level parallelization, a multiclass SVM is addressed by a “one-against-one” approach in OpenMP, and several binary SVM classifiers are run simultaneously to conduct task-level parallelization. The experimental results show that the solver in this framework offered a speedup of 18.5× over the popular LIBSVM software in the training process for data with 200 bands, 13 classes, and 95 597 training samples, and 81.9× in the testing process for data with 103 bands, 9 classes, 1892 support vectors (SVs), and 42 776 testing samples.","Support vector machines,
Graphics processing units,
Hyperspectral imaging,
Multicore processing,
Image classification"
GPU Parallel Implementation of Support Vector Machines for Hyperspectral Image Classification,,
Multimodal Manifold Analysis by Simultaneous Diagonalization of Laplacians,"We construct an extension of spectral and diffusion geometry to multiple modalities through simultaneous diagonalization of Laplacian matrices. This naturally extends classical data analysis tools based on spectral geometry, such as diffusion maps and spectral clustering. We provide several synthetic and real examples of manifold learning, object classification, and clustering, showing that the joint spectral geometry better captures the inherent structure of multi-modal data. We also show the relation of many previous approaches for multimodal manifold analysis to our framework.",
Dictionary Design for Distributed Compressive Sensing,"Conventional dictionary learning frameworks attempt to find a set of atoms that promote both signal representation and signal sparsity fora class of signals. In distributed compressive sensing (DCS), in addition to intra-signal correlation, inter-signal correlation is also exploited in the joint signal reconstruction, which goes beyond the aim of the conventional dictionary learning framework. In this letter, we propose a new dictionary learning framework in order to improve signal reconstruction performance in DCS applications. By capitalizing on the sparse common component and innovations (SCCI) model , which captures both intra- and inter-signal correlation, the proposed method iteratively finds a dictionary design that promotes various goals: i) signal representation; ii) intra-signal correlation; and iii) inter-signal correlation. Simulation results showthat our dictionary design leads to an improved DCS reconstruction performance in comparison to other designs.","Dictionaries,
Correlation,
Joints,
Technological innovation,
Electrocardiography,
Educational institutions,
Silicon"
Event-Based Robust Sampled-Data Model Predictive Control: A Non-Monotonic Lyapunov Function Approach,"In this paper, two event-based robust sampled-data model predictive control (MPC) strategies are proposed based on the non-monotonic Lyapunov function approach for continuous-time systems with disturbances. Each event-triggering mechanism consists of the event-based MPC law and the triggering conditions. We show that although the proposed event-triggering conditions are only checked at the sampling instants and the control law is piecewise constant, the feasibility of the event-based sampled-data MPC algorithm and the stability of the closed-loop system are guaranteed in continuous time. Besides, the implementation issue is discussed, and we show that the proposed triggering conditions can be checked rapidly without obviously increasing the computational burden. Finally, an application to a nonholonomic robot system is provided to illustrate the effectiveness of the proposed results.",
Single target tracking using adaptive clustered decision trees and dynamic multi-level appearance models,"This paper presents a method for single target tracking of arbitrary objects in challenging video sequences. Targets are modeled at three different levels of granularity (pixel level, parts-based level and bounding box level), which are cross-constrained to enable robust model relearning. The main contribution is an adaptive clustered decision tree method which dynamically selects the minimum combination of features necessary to sufficiently represent each target part at each frame, thereby providing robustness with computational efficiency. The adaptive clustered decision tree is implemented in two separate parts of the tracking algorithm: firstly to enable robust matching at the parts-based level between successive frames; and secondly to select the best superpixels for learning new parts of the target. We have tested the tracker using two different tracking benchmarks (VOT2013-2014 and CVPR2013 tracking challenges), based on two different test methodologies, and show it to be significantly more robust than the best state-of-the-art methods from both of those tracking challenges, while also offering competitive tracking precision.",
Cross conduction analysis for enhancement-mode 650-V GaN HFETs in a phase-leg topology,"Cross conduction is a well-known issue in buck converters and phase-leg topologies, in which fast switching transients cause spurious gate voltages in the synchronous device and a subsequent increase in switching loss. Cross conduction can typically be mitigated with a well-designed gate drive, but this is challenging with WBG devices. Phase legs using SiC and GaN devices can experience heavy cross conduction loss due to their exceptionally fast switching transients. Enhancement-mode GaN heterojunction field-effect transistors (HFETs) in the 600-V class are now commercially available, with switching transients as fast as 200 kV/μs. A double pulse test setup was used to measure the switching loss of one such GaN HFET, with several gate drive circuits and resistances. The results were analyzed and compared to characterize the effects of cross conduction in the active and synchronous devices of a phase-leg topology with enhancementmode GaN HFETs.","Logic gates,
Switches,
Gallium nitride,
Transient analysis,
Resistance,
Switching loss,
Inductance"
A Generalized Common-Mode Current Cancelation Approach for Power Converters,"The interwinding parasitic capacitance of transformers and the parasitic capacitance between semiconductor switches and the ground are two major contributors to the common-mode (CM) noise currents in switched mode power converters. In this paper, a generalized CM current cancelation approach is proposed for the reduction of CM noise in isolated power converters. The approach is demonstrated in a forward converter. In this approach, the total effect of the two parasitic capacitances on CM noise is represented with an equivalent parasitic capacitance (EPC) at low frequencies. With this EPC, different CM current cancelation techniques can be efficiently organized to simultaneously cancel the low-frequency CM noise caused by these two parasitic capacitances. Furthermore, the EPC can be used to evaluate and quantify the performance of CM noise reduction techniques. Both theoretical analysis and experimental results show that the proposed approach is easy to implement and can significantly attenuate low frequency CM noise and therefore greatly reduce CM filter size and cost.","Windings,
Low-frequency noise,
Parasitic capacitance,
Hafnium,
Semiconductor diodes"
Free-Breathing Diffusion Tensor Imaging and Tractography of the Human Heart in Healthy Volunteers Using Wavelet-Based Image Fusion,"Free-breathing cardiac diffusion tensor imaging (DTI) is a promising but challenging technique for the study of fiber structures of the human heart in vivo. This work proposes a clinically compatible and robust technique to provide three-dimensional (3-D) fiber architecture properties of the human heart. To this end, 10 short-axis slices were acquired across the entire heart using a multiple shifted trigger delay (TD) strategy under free breathing conditions. Interscan motion was first corrected automatically using a nonrigid registration method. Then, two post-processing schemes were optimized and compared: an algorithm based on principal component analysis (PCA) filtering and temporal maximum intensity projection (TMIP), and an algorithm that uses the wavelet-based image fusion (WIF) method. The two methods were applied to the registered diffusion-weighted (DW) images to cope with intrascan motion-induced signal loss. The tensor fields were finally calculated, from which fractional anisotropy (FA), mean diffusivity (MD), and 3-D fiber tracts were derived and compared. The results show that the comparison of the FA values (FAPCATMIP = 0.45 ±0.10, FAWIF = 0.42 ±0.05, P=0.06) showed no significant difference, while the MD values ( MDPCATMIP=0.83 ±0.12×10-3 mm2/s, MDWIF=0.74±0.05×10-3 mm2/s, P=0.028) were significantly different. Improved helix angle variations through the myocardium wall reflecting the rotation characteristic of cardiac fibers were observed with WIF. This study demonstrates that the combination of multiple shifted TD acquisitions and dedicated post-processing makes it feasible to retrieve in vivo cardiac tractographies from free-breathing DTI acquisitions. The substantial improvements were observed using the WIF method instead of the previously published PCATMIP technique.","Heart,
Diffusion tensor imaging,
Tensile stress,
In vivo,
Three-dimensional displays,
Wavelet coefficients,
Noise"
A Computationally Efficient Motion Primitive for Quadrocopter Trajectory Generation,"A method is presented for the rapid generation and feasibility verification of motion primitives for quadrocopters and similar multirotor vehicles. The motion primitives are defined by the quadrocopter's initial state, the desired motion duration, and any combination of components of the quadrocopter's position, velocity, and acceleration at the motion's end. Closed-form solutions for the primitives are given, which minimize a cost function related to input aggressiveness. Computationally efficient tests are presented to allow for rapid feasibility verification. Conditions are given under which the existence of feasible primitives can be guaranteed a priori . The algorithm may be incorporated in a high-level trajectory generator, which can then rapidly search over a large number of motion primitives which would achieve some given high-level goal. It is shown that a million motion primitives may be evaluated and compared per second on a standard laptop computer. The motion primitive generation algorithm is experimentally demonstrated by tasking a quadrocopter with an attached net to catch a thrown ball, evaluating thousands of different possible motions to catch the ball.","Algorithm design and analysis,
Acceleration,
Vehicle dynamics,
Motion control,
Trajectory"
Bayesian Nonparametric Adaptive Control Using Gaussian Processes,"Most current model reference adaptive control (MRAC) methods rely on parametric adaptive elements, in which the number of parameters of the adaptive element are fixed a priori, often through expert judgment. An example of such an adaptive element is radial basis function networks (RBFNs), with RBF centers preallocated based on the expected operating domain. If the system operates outside of the expected operating domain, this adaptive element can become noneffective in capturing and canceling the uncertainty, thus rendering the adaptive controller only semiglobal in nature. This paper investigates a Gaussian process-based Bayesian MRAC architecture (GP-MRAC), which leverages the power and flexibility of GP Bayesian nonparametric models of uncertainty. The GP-MRAC does not require the centers to be preallocated, can inherently handle measurement noise, and enables MRAC to handle a broader set of uncertainties, including those that are defined as distributions over functions. We use stochastic stability arguments to show that GP-MRAC guarantees good closed-loop performance with no prior domain knowledge of the uncertainty. Online implementable GP inference methods are compared in numerical simulations against RBFN-MRAC with preallocated centers and are shown to provide better tracking and improved long-term learning.",
Hybrid 3-D Localization for Visible Light Communication Systems,"In this study, we investigate the hybrid utilization of angle-of-arrival (AOA) and received signal strength (RSS) information in visible light communication (VLC) systems for 3-D localization. We show that AOA-based localization method allows the receiver to locate itself via a least squares estimator by exploiting the directionality of light-emitting diodes (LEDs). We then prove that when the RSS information is taken into account, the positioning accuracy of AOA-based localization can be improved further using a weighted least squares solution. On the other hand, when the radiation patterns of LEDs are explicitly considered in the estimation, RSS-based localization yields highly accurate results. In order to deal with the system of non-linear equations for RSS-based localization, we develop an analytical learning rule based on the Newton-Raphson method. The non-convex structure is addressed by initializing the learning rule based on 1) location estimates, and 2) a newly developed method, which we refer as a random report and cluster algorithm. As a benchmark, we also derive the analytical expression of the Cramér-Rao lower bound for RSS-based localization, which captures any deployment scenario positioning in 3-D geometry. Finally, we demonstrate the effectiveness of the proposed solutions for a wide range of LED characteristics and orientations through extensive computer simulations.","Light emitting diodes,
Receivers,
Transmitters,
Three-dimensional displays,
Accuracy,
Clustering algorithms,
Estimation"
Focal-Test-Based Spatial Decision Tree Learning,"Given learning samples from a raster data set, spatial decision tree learning aims to find a decision tree classifier that minimizes classification errors as well as salt-and-pepper noise. The problem has important societal applications such as land cover classification for natural resource management. However, the problem is challenging due to the fact that learning samples show spatial autocorrelation in class labels, instead of being independently identically distributed. Related work relies on local tests (i.e., testing feature information of a location) and cannot adequately model the spatial autocorrelation effect, resulting in salt-and-pepper noise. In contrast, we recently proposed a focal-test-based spatial decision tree (FTSDT), in which the tree traversal direction of a sample is based on both local and focal (neighborhood) information. Preliminary results showed that FTSDT reduces classification errors and salt-and-pepper noise. This paper extends our recent work by introducing a new focal test approach with adaptive neighborhoods that avoids over-smoothing in wedge-shaped areas. We also conduct computational refinement on the FTSDT training algorithm by reusing focal values across candidate thresholds. Theoretical analysis shows that the refined training algorithm is correct and more scalable. Experiment results on real world data sets show that new FTSDT with adaptive neighborhoods improves classification accuracy, and that our computational refinement significantly reduces training time.","Decision trees,
Noise,
Training,
Correlation,
Algorithm design and analysis,
Prediction algorithms,
Indexes"
Classification of Parkinson's Disease Gait Using Spatial-Temporal Gait Features,"Quantitative gait assessment is important in diagnosis and management of Parkinson's disease (PD); however, gait characteristics of a cohort are dispersed by patient physical properties including age, height, body mass, and gender, as well as walking speed, which may limit capacity to discern some pathological features. The aim of this study was twofold. First, to use a multiple regression normalization strategy that accounts for subject age, height, body mass, gender, and self-selected walking speed to identify differences in spatial-temporal gait features between PD patients and controls; and second, to evaluate the effectiveness of machine learning strategies in classifying PD gait after gait normalization. Spatial-temporal gait data during self-selected walking were obtained from 23 PD patients and 26 aged-matched controls. Data were normalized using standard dimensionless equations and multiple regression normalization. Machine learning strategies were then employed to classify PD gait using the raw gait data, data normalized using dimensionless equations, and data normalized using the multiple regression approach. After normalizing data using the dimensionless equations, only stride length, step length, and double support time were significantly different between PD patients and controls (p <; 0.05); however, normalizing data using the multiple regression method revealed significant differences in stride length, cadence, stance time, and double support time. Random Forest resulted in a PD classification accuracy of 92.6% after normalizing gait data using the multiple regression approach, compared to 80.4% (support vector machine) and 86.2% (kernel Fisher discriminant) using raw data and data normalized using dimensionless equations, respectively. Our multiple regression normalization approach will assist in diagnosis and treatment of PD using spatial-temporal gait data.",
Secure and Distributed Data Discovery and Dissemination in Wireless Sensor Networks,"A data discovery and dissemination protocol for wireless sensor networks (WSNs) is responsible for updating configuration parameters of, and distributing management commands to, the sensor nodes. All existing data discovery and dissemination protocols suffer from two drawbacks. First, they are based on the centralized approach; only the base station can distribute data items. Such an approach is not suitable for emergent multi-owner-multi-user WSNs. Second, those protocols were not designed with security in mind and hence adversaries can easily launch attacks to harm the network. This paper proposes the first secure and distributed data discovery and dissemination protocol named DiDrip. It allows the network owners to authorize multiple network users with different privileges to simultaneously and directly disseminate data items to the sensor nodes. Moreover, as demonstrated by our theoretical analysis, it addresses a number of possible security vulnerabilities that we have identified. Extensive security analysis show DiDrip is provably secure. We also implement DiDrip in an experimental network of resource-limited sensor nodes to show its high efficiency in practice.","Protocols,
Distributed databases,
Wireless sensor networks,
Base stations,
Public key,
Educational institutions"
Toward Green Power Allocation in Relay-Assisted Multiuser Networks: A Pricing-Based Approach,"Green communications have emerged as a demanding concept for improving the network energy efficiency (EE). In this paper, a pricing-based approach is investigated to achieve energy-efficient power allocation in relay-assisted multiuser networks. We introduce a network price to the power consumption as a penalty for the achievable sum rate, and study its impact on the tradeoff between the EE and the spectral efficiency (SE). It is hard to directly solve the problem as it is non-convex, and thus a concave lower bound on the pricing-based utility is applied to transform the problem into a convex one. Through dual decomposition, a q-price algorithm is proposed for iteratively tightening the lower bound and finding the optimal solution. In addition, an optimal price that enables green power allocation is defined and found from the viewpoint of maximizing EE. We further analyze the optimal power allocation strategies of the pricing-based approach in a two-user case under different noise operating regimes, yielding on-off, water-filling, and channel-reversal approaches, etc. Finally, the performance of the proposed approach is evaluated by computer simulations, and we characterize the interaction between the EE and SE for various network parameters when the network is designed from the energy-efficient perspective.",
Single Image Superresolution Based on Gradient Profile Sharpness,"Single image superresolution is a classic and active image processing problem, which aims to generate a high-resolution (HR) image from a low-resolution input image. Due to the severely under-determined nature of this problem, an effective image prior is necessary to make the problem solvable, and to improve the quality of generated images. In this paper, a novel image superresolution algorithm is proposed based on gradient profile sharpness (GPS). GPS is an edge sharpness metric, which is extracted from two gradient description models, i.e., a triangle model and a Gaussian mixture model for the description of different kinds of gradient profiles. Then, the transformation relationship of GPSs in different image resolutions is studied statistically, and the parameter of the relationship is estimated automatically. Based on the estimated GPS transformation relationship, two gradient profile transformation models are proposed for two profile description models, which can keep profile shape and profile gradient magnitude sum consistent during profile transformation. Finally, the target gradient field of HR image is generated from the transformed gradient profiles, which is added as the image prior in HR image reconstruction model. Extensive experiments are conducted to evaluate the proposed algorithm in subjective visual effect, objective quality, and computation time. The experimental results demonstrate that the proposed approach can generate superior HR images with better visual quality, lower reconstruction error, and acceptable computation efficiency as compared with state-of-the-art works.","Global Positioning System,
Image resolution,
Image edge detection,
Shape,
Histograms,
Image reconstruction,
Image color analysis"
A Stochastic Approach to Analysis of Energy-Aware DVS-Enabled Cloud Datacenters,"With the increasing call for green cloud, reducing energy consumption has been an important requirement for cloud resource providers not only to reduce operating costs, but also to improve system reliability. Dynamic voltage scaling (DVS) has been a key technique in exploiting the hardware characteristics of cloud datacenters to save energy by lowering the supply voltage and operating frequency. This paper presents a novel stochastic framework for energy efficiency and performance analysis of DVS-enabled cloud. This framework uses virtual machine request arrival rate, failure rate, repair rate, and service rate of datacenter servers as model inputs. Based on a queuing-network-based analysis, this paper gives analytic solutions of three metrics. The proposed framework can be used to help the design and optimization of energy-aware high performance cloud systems.","Voltage control,
Energy consumption,
Maintenance engineering,
Computers,
Analytical models,
Markov processes"
Characterization of Corroded Reinforced Steel Bars by Active Microwave Thermography,"Detection and characterization of corrosion on steel is important in the transportation and infrastructure industries. Many nondestructive testing (NDT) methods have been applied to this inspection need. To overcome the existing limitations of traditional NDT methods, integrated NDT techniques have also been developed. To this end, the integration of microwave and thermography, referred to as active microwave thermography (AMT), is proposed as a potential NDT tool for detection and characterization of corrosion on steel bars. This method utilizes microwave energy to provide heat excitation. Subsequently, a thermal camera is used to monitor the thermal surface profile. This paper presents preliminary simulations and measurements of AMT as a potential method for corrosion detection and characterization.","Corrosion,
Electromagnetic heating,
Microwave theory and techniques,
Temperature measurement,
Microwave imaging,
Steel"
Full-duplex MIMO relaying powered by wireless energy transfer,"We consider a full-duplex decode-and-forward system, where the wirelessly powered relay employs the time-switching protocol to receive power from the source and then transmit information to the destination. It is assumed that the relay node is equipped with two sets of antennas to enable full-duplex communications. Three different interference mitigation schemes are studied, namely, 1) optimal 2) zero-forcing and 3) maximum ratio combining/maximum ratio transmission. We develop new outage probability expressions to investigate delay-constrained transmission throughput of these schemes. Our analysis show interesting performance comparisons of the considered precoding schemes for different system and link parameters.","Relays,
Signal to noise ratio,
Wireless communication,
High definition video,
Throughput,
Antennas,
Interference"
Evaluating clone detection tools with BigCloneBench,"Many clone detection tools have been proposed in the literature. However, our knowledge of their performance in real software systems is limited, particularly their recall. In this paper, we use our big data clone benchmark, BigCloneBench, to evaluate the recall of ten clone detection tools. BigCloneBench is a collection of eight million validated clones within IJaDataset-2.0, a big data software repository containing 25,000 open-source Java systems. BigCloneBench contains both intra-project and inter-project clones of the four primary clone types. We use this benchmark to evaluate the recall of the tools per clone type and across the entire range of clone syntactical similarity. We evaluate the tools for both single-system and cross-project detection scenarios. Using multiple clone-matching metrics, we evaluate the quality of the tools' reporting of the benchmark clones with respect to refactoring and automatic clone analysis use-cases. We compare these real-world results against our Mutation and Injection Framework, a synthetic benchmark, to reveal deeper understanding of the tools. We found that the tools have strong recall for Type-1 and Type-2 clones, as well as Type-3 clones with high syntactical similarity. The tools have weaker detection of clones with lower syntactical similarity.","Cloning,
Benchmark testing,
Software systems,
Big data,
Java,
Data mining"
An 18.7-Gb/s 60-GHz OOK Demodulator in 65-nm CMOS for Wireless Network-on-Chip,"This paper presents a high-efficiency 60-GHz on-off keying (OOK) demodulator for high-speed short-range wireless communications such as wireless network-on-chip (WiNoC) applications. Targeting at data rates of beyond 16 Gb/s, the OOK demodulator consists of a wideband envelope detector (ED) and a single-stage baseband (BB) peaking amplifier. Novel dual gain-boosting techniques improve the gain, bandwidth, and out-of-band rejection of the ED. In addition, an actively-enhanced tunable inductor (AETI) load in the BB amplifier not only significantly reduces its area overhead, but also provides a tunable peaking level. Fabricated in a 65-nm bulk CMOS process, the OOK demodulator consumes only 4.6 mW from a 1-V supply, and occupies an active area of 0.043 mm2. A maximum data rate of 18.7 Gb/s with a bit-error rate less than 10-12 is demonstrated through measurements, which translates to a bit-energy efficiency of 0.25 pJ/bit.","Gain,
Demodulation,
Bandwidth,
Inductors,
Wireless communication,
Bit error rate,
Envelope detectors"
A Two-Stage Approach for the Estimation of Doubly Spread Acoustic Channels,"In this paper, the estimation of doubly spread acoustic channels is investigated. By parameterizing the amplitude variation and delay variation of each path with polynomial approximation, this paper derives a mathematical model for the discrete-time channel input-output relationship tailored to single-carrier block transmissions. Based on the mathematical model, the channel estimation problem is transformed into estimation of the low-dimensional parameter sets (amplitude, delay, Doppler scale) that characterize the channel. A two-stage sparse channel estimation technique is then developed, which estimates the delay and Doppler scale sequentially. Compared to the one-stage joint estimation, the two-stage estimation approach greatly reduces the number of candidates on the delay-Doppler scale grid searched by the orthogonal matching pursuit (OMP) algorithm, that is, the dictionary size is reduced dramatically. As a result, the computational complexity is much lower. Further, the two-stage approach demonstrated higher levels of accuracy in computer simulations and led to better detection performance when applied to experimental data.","Channel estimation,
Delays,
Doppler effect,
Estimation,
Mathematical model,
Dictionaries,
Polynomials"
Denial-of-service attacks in OpenFlow SDN networks,"Software-Defined Networking (SDN) has recently gained significant momentum. However, before any large scale deployments, it is important to understand security issues arising from this new technology. This paper discusses two types of Denial-of-Service (DoS) attacks specific to OpenFlow SDN networks. We emulate them on Mininet and provide an analysis on the effect of these attacks. We find that the timeout value of a flow rule, and the control plane bandwidth have a significant impact on the switch's capability. If not configured appropriately, they may allow successful DoS attacks. Finally, we highlight possible mitigation strategies to address such attacks.",
Incorporating Dynamics in a Mesh-Based Magnetic Equivalent Circuit Model of Synchronous Machines,"A mesh-based magnetic equivalent circuit has been derived to model the dynamics of wound rotor synchronous machines (WRSMs). A particular focus has been placed on the derivation of flux tubes to model machines with an arbitrary number of damper bars placed at an arbitrary depth in the rotor pole tip. Faraday's Law is applied to establish a state model in which winding and damper bar flux linkages are selected as state variables. The resulting coupled magnetic equivalent circuit/state model is solved to predict machine dynamics. An important attribute of the model is that saturation is represented without the need for a relaxation factor, which enables its use as a practical tool in machine design. Data obtained from hardware experiment and a finite-element model are used to validate the proposed methods.","Shock absorbers,
Rotors,
Integrated circuit modeling,
Windings,
Bars,
Mathematical model,
Stators"
GPU-Accelerated Parallel Coevolutionary Algorithm for Parameters Identification and Temperature Monitoring in Permanent Magnet Synchronous Machines,"A hierarchical fast parallel co-evolutionary immune particle swarm optimization (PSO) algorithm, accelerated by graphics processing unit (GPU) technique (G-PCIPSO), is proposed for multiparameter identification and temperature monitoring of permanent magnet synchronous machines (PMSM). It is composed of two levels and is developed based on compute unified device architecture (CUDA). In G-PCIPSO, the antibodies (Abs) of higher level memory are selected from the lower level swarms and improved by immune clonal-selection operator. The search information exchanges between swarms using the memory-based sharing mechanism. Moreover, an immune vaccine-enhanced operator is proposed to lead the Pbests particles to unexplored areas. Optimized parallel implementations of G-PCIPSO algorithm is developed on GPU using CUDA, which significantly speeds up the search process. Finally, the proposed algorithm is applied to multiple parameters identification and temperature monitoring of PMSM. It can track parameter variation and achieve temperature monitoring online effectively. Compared with a CPU-based serial execution, the computational efficiency is greatly enhanced by GPU-accelerated parallel computing technique.","Graphics processing units,
Sociology,
Parameter estimation,
Monitoring,
Temperature measurement,
Temperature sensors"
A First Step Toward Network Security Virtualization: From Concept To Prototype,"Network security management is becoming more and more complicated in recent years, considering the need of deploying more and more network security devices/middle-boxes at various locations inside the already complicated networks. A grand challenge in this situation is that current management is inflexible and the security resource utilization is not efficient. The flexible deployment and utilization of proper security devices at reasonable places at needed time with low management cost is extremely difficult. In this paper, we present a new concept of network security virtualization, which virtualizes security resources/functions to network administrators/users, and thus maximally utilizing existing security devices/middle-boxes. In addition, it enables security protection to desirable networks with minimal management cost. To verify this concept, we further design and implement a prototype system, NETSECVISOR, which can utilize existing pre-installed (fixed-location) security devices and leverage software-defined networking technology to virtualize network security functions. At its core, NETSECVISOR contains: 1) a simple script language to register security services and policies; 2) a set of routing algorithms to determine optimal routing paths for different security policies based on different needs; and 3) a set of security response functions/strategies to handle security incidents. We deploy NETSECVISOR in both virtual test networks and a commercial switch environment to evaluate its performance and feasibility. The evaluation results show that our prototype only adds a very small overhead while providing desired network security virtualization to network users/administrators.","Security,
Communication networks,
Routing,
Virtualization,
Prototypes,
Monitoring,
Switches"
Online Fountain Codes With Low Overhead,"An online fountain code is defined as a fountain code for which an optimal encoding strategy can be found efficiently given any instantaneous decoding state. This property is important for data distribution in practical networks. In this paper, we formalize the problem of online fountain code construction, and propose new online fountain codes that outperform known ones in having factor 3-5 lower redundancy overhead. The bounding of the code overhead is carried out using the analysis of the dynamics of random-graph processes.","Decoding,
Encoding,
Receivers,
Polynomials,
Redundancy,
Propagation losses,
Complexity theory"
Design and analysis of novel SRAM PUFs with embedded latch for robustness,"Physical Unclonable Function (PUF) is a cost-effective security primitive to address hardware attacks such as cloning, impersonation and Intellectual Property (IP) violation. Static Random-Access Memory (SRAM) PUF has been proposed; however, it suffers from challenges, some of which are environmental fluctuations such as voltage, temperature, and noise. Ensuring the robustness of SRAM PUF under such conditions is challenging. In this paper, we propose 8T SRAM PUF with a back-to-back PMOS latch to improve robustness by 4X. We also propose a low-power 7T SRAM with embedded Magnetic Tunnel Junction (MTJ) devices to enhance the robustness (2.3X to 20X) while lowering the leakage power and area overhead.","Random access memory,
Noise,
Latches,
Robustness,
Fluctuations,
Magnetic tunneling,
Transistors"
Park Here! a smart parking system based on smartphones' embedded sensors and short range Communication Technologies,"Nowadays, the convergence of Internet of Things (IoT) networking and mobile applications is favoring the deployment of novel and advanced smart parking systems through which users can be informed in real-time about the presence of vacant parking spots close to their destinations. In this paper, we provide an example of such opportunity, by describing Park Here!, a novel mobile application that aims at mitigating the overhead caused by parking spot seeking operations in urban areas. Our solution targets common city environments, where no per-spot sensors are available, and there is no remote service allowing the reservation in-advance of a parking spot. For this scenario, we propose a novel algorithm for the automatic detection of parking actions performed by the user, through the analysis of smartphone embedded sensors' (accelerometer/gyroscope), and of the Bluetooth connectivity. Once a parking event has been detected, an adaptive strategy allows disseminating the information over the target scenario, using a combination of Internet connection to a remote server, and Device-to-Device (D2D) connections over WiFi Direct links. Preliminary experiments demonstrate the accuracy of the proposed algorithm in correctly identifying parking events in an automatic way, and hence in notifying information to other potentially interested users.",
Design and Analysis of Sliding Mode Controller Under Approximate Hysteresis Compensation,"A sliding mode controller (SMC) is proposed for a class of systems comprising a hysteresis operator preceding a linear system with an all-pole transfer function. The hysteresis operator is modeled with uncertain piecewise linear characteristics, and a nominal inverse operator is included to mitigate the hysteresis effect. A classical SMC design typically uses a constant coefficient in the switching component, which is tuned via trial-and-error. In this paper, a state- and time-dependent coefficient is proposed based on the derived inversion error, which eliminates the need for parameter tuning and ensures the convergence of the sliding surface to the boundary layer without compactness assumptions. In addition, singular perturbation is used to analyze the system behavior within the sliding-surface boundary layer for the case of a constant coefficient in the classical SMC design. In particular, analytical insight is gained on the frequency-scaling behavior of the tracking error under a periodic reference. Simulation and experimental results based on a piezoelectric actuator-based nanopositioner are presented to illustrate the design and analysis, where the hysteresis nonlinearity is represented by a Prandtal-Ishlinskii operator.",
A repetitive microsecond pulse generator for atmospheric pressure plasma jets,"Compared with other non-thermal plasma sources, the atmospheric-pressure plasma jet (APPJ) has advantages on simple structure, low temperatures, strong chemical activities, and convenient handling, all of which have attracted much attention. The power sources play an important role on the characteristics and the applications of the APPJ. In this article, a compact repetitive microsecond-pulse generator is designed for exciting the APPJ in helium and argon. The microsecond-pulse generator can produce repetitive pulses with output voltages of up to 20 kV, pulse width of ~8 μs, and pulse repetition frequencies (PRFs) of 1 Hz ~2 kHz. Using the designed repetitive microsecond-pulse generator, the characteristics of the APPJ are investigated by measuring the voltages and currents and obtaining images of the discharges. Experimental results show that the microsecond-pulse generator has been successfully used to sustain stable APPJs both in helium and argon. The shape of the output voltage pulses may change as the applied voltage increases. Nevertheless, the output voltages are stable at all PRFs when the applied voltage is fixed. Furthermore, the effects of flow rate, the applied voltage, and the PRF on the He/Ar APPJ are investigated. Results show that it is more likely to generate a He APPJ rather than an Ar APPJ under microsecond-pulse excitation. The length of the plasma plume is slightly affected by the PRF both in the He APPJ and the Ar APPJ.","Generators,
Pulse transformers,
Discharges (electric),
Plasmas,
Helium,
Voltage measurement,
Transformer cores"
"Fast, Automated, Scalable Generation of Textured 3D Models of Indoor Environments","3D modeling of building architecture from mobile scanning is a rapidly advancing field. These models are used in virtual reality, gaming, navigation, and simulation applications. State-of-the-art scanning produces accurate point-clouds of building interiors containing hundreds of millions of points. This paper presents several scalable surface reconstruction techniques to generate watertight meshes that preserve sharp features in the geometry common to buildings. Our techniques can automatically produce high-resolution meshes that preserve the fine detail of the environment by performing a ray-carving volumetric approach to surface reconstruction. We present methods to automatically generate 2D floor plans of scanned building environments by detecting walls and room separations. These floor plans can be used to generate simplified 3D meshes that remove furniture and other temporary objects. We propose a method to texture-map these models from captured camera imagery to produce photo-realistic models. We apply these techniques to several data sets of building interiors, including multi-story datasets.","Buildings,
Three-dimensional displays,
Solid modeling,
Computational modeling,
Surface reconstruction,
Face,
Geometry"
Heterogeneous Cloud Computing: The Way Forward,"Cloud computing developers face multiple challenges in adapting systems and applications for increasingly heterogeneous datacenter architectures. A major appeal of cloud computing is that it abstracts hardware architecture from both end users and programmers. This abstraction allows underlying infrastructure to be scaled up or improved-for example, by adding datacenter servers or upgrading to newer hardware-without forcing changes in applications. The long-dominant x86 processor architecture, along with high-level, portable languages such as Java, PHP, Python, and SQL, has helped assure the continued viability of such abstraction. Meanwhile, exponential growth in microprocessor capability, mirroring Moore's law, has helped to improve performance for most applications that execute on general-purpose processors, including those deployed on clouds.",
Discovery of Ranking Fraud for Mobile Apps,"Ranking fraud in the mobile App market refers to fraudulent or deceptive activities which have a purpose of bumping up the Apps in the popularity list. Indeed, it becomes more and more frequent for App developers to use shady means, such as inflating their Apps' sales or posting phony App ratings, to commit ranking fraud. While the importance of preventing ranking fraud has been widely recognized, there is limited understanding and research in this area. To this end, in this paper, we provide a holistic view of ranking fraud and propose a ranking fraud detection system for mobile Apps. Specifically, we first propose to accurately locate the ranking fraud by mining the active periods, namely leading sessions, of mobile Apps. Such leading sessions can be leveraged for detecting the local anomaly instead of globalanomaly of App rankings. Furthermore, we investigate three types of evidences, i.e., ranking based evidences, rating based evidences and review based evidences, by modeling Apps' ranking, rating and review behaviors through statistical hypotheses tests. In addition, we propose an optimization based aggregation method to integrate all the evidences for fraud detection. Finally, we evaluate the proposed system with real-world App data collected from the iOS App Store for a long time period. In the experiments, we validate the effectiveness of the proposed system, and show the scalability of the detection algorithm as well as some regularity of ranking fraud activities.","Mobile communication,
Lead,
Maximum likelihood estimation,
Educational institutions,
Electronic mail,
Probability,
Scalability"
Goal-Based Holonic Multiagent System for Operation of Power Distribution Systems,"Large-scale integration of rooftop solar power generation is transforming traditionally passive power distribution systems into active ones. High penetration of such devices creates new dynamics for which the current power distribution systems are inadequate. The changing paradigm of power distribution system requires it to be operated as cyber-physical system. A goal-based holonic multiagent system (HMAS) is presented in this paper to achieve this objective. This paper provides details on design of the HMAS for operation of power distribution systems. Various operating modes and associated goals are discussed. Finally, the role of HMAS is demonstrated for two applications in distribution systems. The first one is associated with control of reactive power at solar photovoltaic installations at individual homes for optimal operation of the system. The second deals with the state estimation of the system leveraging different measurements available from smart meters at homes.","Power distribution,
Organizations,
Substations,
Reactive power,
Artificial neural networks,
Optimization,
Control systems"
A Cloud-Based Smart-Parking System Based on Internet-of-Things Technologies,This paper introduces a novel algorithm that increases the efficiency of the current cloud-based smart-parking system and develops a network architecture based on the Internet-of-Things technology. This paper proposed a system that helps users automatically find a free parking space at the least cost based on new performance metrics to calculate the user parking cost by considering the distance and the total number of free places in each car park. This cost will be used to offer a solution of finding an available parking space upon a request by the user and a solution of suggesting a new car park if the current car park is full. The simulation results show that the algorithm helps improve the probability of successful parking and minimizes the user waiting time. We also successfully implemented the proposed system in the real world.,"Smart systems,
Performance evaluation,
Algorithm design and analysis,
Cloud computing,
Internet of things"
Attack-resilient state estimation in the presence of noise,"We consider the problem of attack-resilient state estimation in the presence of noise. We focus on the most general model for sensor attacks where any signal can be injected via the compromised sensors. An l0-based state estimator that can be formulated as a mixed-integer linear program and its convex relaxation based on the l1 norm are presented. For both l0 and l1-based state estimators, we derive rigorous analytic bounds on the state-estimation errors. We show that the worst-case error is linear with the size of the noise, meaning that the attacker cannot exploit noise and modeling errors to introduce unbounded state-estimation errors. Finally, we show how the presented attack-resilient state estimators can be used for sound attack detection and identification, and provide conditions on the size of attack vectors that will ensure correct identification of compromised sensors.","State estimation,
Noise measurement,
Symmetric matrices,
Optimization,
Linear systems,
Size measurement,
Security"
A Parking Occupancy Detection Algorithm Based on AMR Sensor,"Recently, with the explosive increase of automobiles in cities, parking problems are serious and even worsen in many cities. This paper proposes a new algorithm for parking occupancy detection based on the use of anisotropic magnetoresistive sensors. Parking occupancy detection is abstracted as binary pattern recognition problem. According to the status of the parking space, the recognition result contains two categories: vacant and occupied. The feature extraction method of the parking magnetic signal is proposed. In addition, the classification criteria are derived based on the distance discriminate analysis method. Eighty-two sensor nodes are deployed on the roadside parking spaces. By running the system for six months, we observed that the accuracy rate of the proposed parking occupancy detection algorithm is better than 98%.","Vehicles,
Magnetic sensors,
Fluctuations,
Interference,
Vehicle detection,
Arrays"
Decentralized Energy Allocation for Wireless Networks With Renewable Energy Powered Base Stations,"In this paper, a green wireless communication system in which base stations are powered by renewable energy sources is considered. This system consists of a capacity-constrained renewable power supplier (RPS) and a base station (BS) that faces a predictable random connection demand from mobile user equipments (UEs). In this model, the BS, which is powered via a combination of a renewable power source and the conventional electric grid, seeks to specify the renewable power inventory policy, i.e., the power storage level. On the other hand, the RPS must strategically choose the energy amount that is supplied to the BS. An M/M/1 make-to-stock queuing model is proposed to investigate the decentralized decisions when the two parties optimize their individual costs in a noncooperative manner. The problem is formulated as a noncooperative game whose Nash equilibrium (NE) strategies are characterized to identify the causes of inefficiency in the decentralized operation. A set of simple linear contracts are introduced to coordinate the system so as to achieve an optimal system performance. The proposed approach is then extended to a setting with one monopolistic RPS and N BSs that are privately informed of their optimal energy inventory levels. In this scenario, we show that the widely used proportional allocation mechanism is no longer socially optimal. To make the BSs truthfully report their energy demand, an incentive compatible (IC) mechanism is proposed for our model. Simulation results show that using the green energy can present significant traditional energy savings for the BS when the connection demand is not heavy. Moreover, the proposed scheme provides valuable energy cost savings by allowing the BSs to smartly use a combination of renewable and traditional energy, even when the BS has a heavy traffic of connections. Also, the results show that performance of the proposed IC mechanism will be close to the social optimal when the green energy production capacity increases.",
Reliably scalable name prefix lookup,"Name prefix lookup is a core building block of information-centric networking (ICN). In ICN hierarchical naming schemes, each packet has a name that consists of multiple variable-length name components, and packets are forwarded based on longest name prefix matching (LNPM). LNPM is challenging because names are longer than IP addresses and the namespace is unbounded. Recently proposed solutions have shown encouraging performance, however, most are optimized for or evaluated with a limited number of URL datasets that may not fully characterize the forwarding information base (FIB).What's more, the worst-case scenarios of several schemes require O(k) string lookups, where k is the number of components in each prefix. Thus, the sustained performance of existing solutions is not guaranteed. In this paper, we present a LNPM design based on the binary search of hash tables, which was originally proposed for IP lookup. With this design, the worst-case number of string lookups is O(log(k)) for prefixes with up to k components, regardless of the characteristics of the FIB. We implemented the design in software and demonstrated 10 Gbps throughput with one billion synthetic longest name prefix matching rules, each containing up to seven components. We also propose level pulling to optimize the average LNPM performance based on the observation that some prefixes have large numbers of next-level suffixes in the available URL datasets.","IP networks,
Uniform resource locators,
Memory management,
Software,
Internet,
Multicore processing,
Random access memory"
Homology-Based Distributed Coverage Hole Detection in Wireless Sensor Networks,"Homology theory provides new and powerful solutions to address the coverage problems in wireless sensor networks (WSNs). They are based on algebraic objects, such as Čech complex and Rips complex. Čech complex gives accurate information about coverage quality, but requires a precise knowledge of the relative locations of nodes. This assumption is rather strong and hard to implement in practical deployments. Rips complex provides an approximation of Čech complex. It is easier to build and does not require any knowledge of nodes location. This simplicity is at the expense of accuracy. Rips complex cannot always detect all coverage holes. It is then necessary to evaluate its accuracy. This work proposes to use the proportion of the area of undiscovered coverage holes as performance criteria. Investigations show that it depends on the ratio between communication and sensing radii of a sensor. Closed-form expressions for lower and upper bounds of the accuracy are also derived. For those coverage holes that can be discovered by Rips complex, a homology-based distributed algorithm is proposed to detect them. Simulation results are consistent with the proposed analytical lower bound, with a maximum difference of 0.5%. Upper-bound performance depends on the ratio of communication and sensing radii. Simulations also show that the algorithm can localize about 99% coverage holes in about 99% cases.","Wireless sensor networks,
Sensors,
Distributed algorithms,
IEEE transactions,
Accuracy,
Telecommunications,
Complexity theory"
When hybrid cloud meets flash crowd: Towards cost-effective service provisioning,"With rapid development in online shopping, e-commerce websites are facing intensive user requests from an increasing number of customers. Especially in promotion seasons, these websites may encounter flash crowds which pull heavy pressure o private infrastructure and even make he website unavailable. Such severe flash crowds can be addressed by leveraging hybrid cloud solution, which relieves workloads of the private cloud by offloading the excessive user requests to the IaaS public cloud. However, the bursty and fluctuation of flash crowds bring challenges to distributing user requests with targest of delay-minimizing and cost-saving. In his paper, we apply the queueing theory to evaluate the average response time and explore the tradeoff between performance and cost in the hybrid cloud. By taking advantage of Lyapunov optimization techniques, we design an online decision algorithm for request distribution which achieves the average response time arbitrarily close to the theoretically optimum and controls he outsourcing cost based on a given budge. The simulation results demonstrate ha in a hybrid cloud, our solution can reduce he cost of e-commerce services as well as guarantee performance when encountering flash crowds.","Conferences,
Computers,
Cloud computing"
A matrix model for redefining and testing NoC interconnect shorts,"Network-on-chip (NoC) has currently considered as a holistic solution over traditional and global bus-based system-on-chip (SoC) interconnections. However, NoC interconnects experience a subset of manufacturing faults- shorts, opens, and stuck-ats. A limitation of prior works on testing shorts on interconnects of a NoC is that interconnects are tested without coexistent open faults. The works then fail to detect all shorts if a relaxation is made on this assumption. A fast matrix based test strategy that tests and diagnoses shorts with and without coexistent opens on NoC interconnects is proposed. Proposed strategy is scalable irrespective of NoCs and evaluated in terms of test time, test criteria, and performance metrics. Both 100% and near 100% fault coverages are achieved on explicit and implicit testing of shorts respectively. However, 100% test coverage is achieved in either of the cases.","Silicon,
Routing,
Generators,
Payloads,
Clocks,
Scalability"
Effects of Proton-Induced Displacement Damage on Gallium Nitride HEMTs in RF Power Amplifier Applications,"The effects of proton-induced displacement damage in GaN HEMTs on circuit-level RF power amplifier parameters such as circuit gain, stability, and RF output power are presented. The results are explained based on the device-level degradation. Commercial-off-the-shelf GaN HEMTs from two manufacturers were compared. Differences are observed in both device and circuit level responses. Suggestions to mitigate the negative effects of displacement damage on GaN based amplifiers are also provided.",
A Parallel and Incremental Approach for Data-Intensive Learning of Bayesian Networks,"Bayesian network (BN) has been adopted as the underlying model for representing and inferring uncertain knowledge. As the basis of realistic applications centered on probabilistic inferences, learning a BN from data is a critical subject of machine learning, artificial intelligence, and big data paradigms. Currently, it is necessary to extend the classical methods for learning BNs with respect to data-intensive computing or in cloud environments. In this paper, we propose a parallel and incremental approach for data-intensive learning of BNs from massive, distributed, and dynamically changing data by extending the classical scoring and search algorithm and using MapReduce. First, we adopt the minimum description length as the scoring metric and give the two-pass MapReduce-based algorithms for computing the required marginal probabilities and scoring the candidate graphical model from sample data. Then, we give the corresponding strategy for extending the classical hill-climbing algorithm to obtain the optimal structure, as well as that for storing a BN by <;key, value> pairs. Further, in view of the dynamic characteristics of the changing data, we give the concept of influence degree to measure the coincidence of the current BN with new data, and then propose the corresponding two-pass MapReduce-based algorithms for BNs incremental learning. Experimental results show the efficiency, scalability, and effectiveness of our methods.",
Group Key Establishment for Enabling Secure Multicast Communication in Wireless Sensor Networks Deployed for IoT Applications,"Wireless sensor networks (WSNs) are a prominent fundamental technology of the Internet of Things (IoTs). Rather than device-to-device communications, group communications in the form of broadcasting and multicasting incur efficient message deliveries among resource-constrained sensor nodes in the IoT-enabled WSNs. Secure and efficient key management is in many cases used to protect the authenticity, integrity, and confidentiality of multicast messages. This paper develops two group key establishment protocols for secure multicast communications among the resource-constrained devices in IoT. Major deployment conditions and requirements of each protocol are described in terms of the specific IoT application scenarios. Furthermore, the applicability of the two protocols is analyzed and justified by a comprehensive analysis of the performance, scalability, and security of the protocols proposed.","Protocols,
Wireless sensor networks,
Multicast communication,
Digital signatures,
Public key,
Scalability"
Non-Divergence of Stochastic Discrete Time Algorithms for PCA Neural Networks,"Learning algorithms play an important role in the practical application of neural networks based on principal component analysis, often determining the success, or otherwise, of these applications. These algorithms cannot be divergent, but it is very difficult to directly study their convergence properties, because they are described by stochastic discrete time (SDT) algorithms. This brief analyzes the original SDT algorithms directly, and derives some invariant sets that guarantee the nondivergence of these algorithms in a stochastic environment by selecting proper learning parameters. Our theoretical results are verified by a series of simulation examples.","Principal component analysis,
Algorithm design and analysis,
Convergence,
Signal processing algorithms,
Neural networks,
Approximation algorithms,
Heuristic algorithms"
Sensor fusion for semantic segmentation of urban scenes,"Semantic understanding of environments is an important problem in robotics in general and intelligent autonomous systems in particular. In this paper, we propose a semantic segmentation algorithm which effectively fuses information from images and 3D point clouds. The proposed method incorporates information from multiple scales in an intuitive and effective manner. A late-fusion architecture is proposed to maximally leverage the training data in each modality. Finally, a pairwise Conditional Random Field (CRF) is used as a post-processing step to enforce spatial consistency in the structured prediction. The proposed algorithm is evaluated on the publicly available KITTI dataset [1] [2], augmented with additional pixel and point-wise semantic labels for building, sky, road, vegetation, sidewalk, car, pedestrian, cyclist, sign/pole, and fence regions. A per-pixel accuracy of 89.3% and average class accuracy of 65.4% is achieved, well above current state-of-the-art [3].","Image segmentation,
Three-dimensional displays,
Feature extraction,
Semantics,
Training,
Training data,
Labeling"
Dynamic Routing for Data Integrity and Delay Differentiated Services in Wireless Sensor Networks,"Applications running on the same Wireless Sensor Network (WSN) platform usually have different Quality of Service (QoS) requirements. Two basic requirements are low delay and high data integrity. However, in most situations, these two requirements cannot be satisfied simultaneously. In this paper, based on the concept of potential in physics, we propose IDDR, a multi-path dynamic routing algorithm, to resolve this conflict. By constructing a virtual hybrid potential field, IDDR separates packets of applications with different QoS requirements according to the weight assigned to each packet, and routes them towards the sink through different paths to improve the data fidelity for integrity-sensitive applications as well as reduce the end-to-end delay for delay-sensitive ones. Using the Lyapunov drift technique, we prove that IDDR is stable. Simulation results demonstrate that IDDR provides data integrity and delay differentiated services.","Delays,
Wireless sensor networks,
Routing,
Reliability,
Quality of service,
Heuristic algorithms,
Force"
Mammoth: Gearing Hadoop Towards Memory-Intensive MapReduce Applications,"The MapReduce platform has been widely used for large-scale data processing and analysis recently. It works well if the hardware of a cluster is well configured. However, our survey has indicated that common hardware configurations in small-and medium-size enterprises may not be suitable for such tasks. This situation is more challenging for memory-constrained systems, in which the memory is a bottleneck resource compared with the CPU power and thus does not meet the needs of large-scale data processing. The traditional high performance computing (HPC) system is an example of the memory-constrained system according to our survey. In this paper, we have developed Mammoth, a new MapReduce system, which aims to improve MapReduce performance using global memory management. In Mammoth, we design a novel rule-based heuristic to prioritize memory allocation and revocation among execution units (mapper, shuffler, reducer, etc.), to maximize the holistic benefits of the Map/Reduce job when scheduling each memory unit. We have also developed a multi-threaded execution engine, which is based on Hadoop but runs in a single JVM on a node. In the execution engine, we have implemented the algorithm of memory scheduling to realize global memory management, based on which we further developed the techniques such as sequential disk accessing, multi-cache and shuffling from memory, and solved the problem of full garbage collection in the JVM. We have conducted extensive experiments to compare Mammoth against the native Hadoop platform. The results show that the Mammoth system can reduce the job execution time by more than 40 percent in typical cases, without requiring any modifications of the Hadoop programs. When a system is short of memory, Mammoth can improve the performance by up to 5.19 times, as observed for I/O intensive applications, such as PageRank. We also compared Mammoth with Spark. Although Spark can achieve better performance than Mammoth for interactive and iterative applications when the memory is sufficient, our experimental results show that for batch processing applications, Mammoth can adapt better to various memory environments and outperform Spark when the memory is insufficient, and can obtain similar performance as Spark when the memory is sufficient. Given the growing importance of supporting large-scale data processing and analysis and the proven success of the MapReduce platform, the Mammoth system can have a promising potential and impact.","Memory management,
Engines,
Data structures,
Receivers,
Data processing,
Runtime,
Educational institutions"
The Effect of GoF Design Patterns on Stability: A Case Study,"Stability refers to a software system's resistance to the “ripple effect”, i.e., propagation of changes. In this paper, we investigate the stability of classes that participate in instances/occurrences of GoF design patterns. We examine whether the stability of such classes is affected by (a) the pattern type, (b) the role that the class plays in the pattern, (c) the number of pattern occurrences in which the class participates, and (d) the application domain. To this end, we conducted a case study on about 65.000 Java open-source classes, where we performed change impact analysis on classes that participate in zero, one (single pattern), or more than one (coupled) pattern occurrences. The results suggest that, the application of design patterns can provide the expected “shielding” of certain pattern-participating classes against changes, depending on their role in the pattern. Moreover, classes that participate in coupled pattern occurrences appear to be the least stable. The results can be used for assessing the benefits and liabilities of the use of patterns and for testing and refactoring prioritization, because less stable classes are expected to require more effort while testing, and urge for refactoring activities that would make them more resistant to change propagation.","Stability analysis,
Couplings,
Abstracts,
Measurement,
Production facilities,
Open source software"
Exploiting mobile social behaviors for Sybil detection,"In this paper, we propose a Social-based Mobile Sybil Detection (SMSD) scheme to detect Sybil attackers from their abnormal contacts and pseudonym changing behaviors. Specifically, we first define four levels of Sybil attackers in mobile environments according to their attacking capabilities. We then exploit mobile users' contacts and their pseudonym changing behaviors to distinguish Sybil attackers from normal users. To alleviate the storage and computation burden of mobile users, the cloud server is introduced to store mobile user's contact information and to perform the Sybil detection. Furthermore, we utilize a ring structure associated with mobile user's contact signatures to resist the contact forgery by mobile users and cloud servers. In addition, investigating mobile user's contact distribution and social proximity, we propose a semi-supervised learning with Hidden Markov Model to detect the colluded mobile users. Security analysis demonstrates that the SMSD can resist the Sybil attackers from the defined four levels, and the extensive trace-driven simulation shows that the SMSD can detect these Sybil attackers with high accuracy.","Mobile communication,
Servers,
Mobile computing,
Hidden Markov models,
Aggregates,
Computers,
Resists"
Active Hypothesis Testing for Anomaly Detection,"The problem of detecting a single anomalous process among a finite number M of processes is considered. At each time, a subset of the processes can be observed, and the observations from each chosen process follow two different distributions, depending on whether the process is normal or abnormal. The objective is a sequential search strategy that minimizes the expected detection time subject to an error probability constraint. This problem can be considered as a special case of active hypothesis testing first considered by Chernoff where a randomized strategy, referred to as the Chernoff test, was proposed and shown to be asymptotically (as the error probability approaches zero) optimal. For the special case considered in this paper, we show that a simple deterministic test achieves asymptotic optimality and offers better performance in the finite regime. We further extend the problem to the case where multiple anomalous processes are present. In particular, we examine the case where only an upper bound on the number of anomalous processes is known.","Testing,
Search problems,
Error probability,
Upper bound,
Sensors,
Vectors,
Indexes"
Clock-Tree Aware Multibit Flip-Flop Generation During Placement for Power Optimization,"Utilizing multibit flip-flops (MBFFs) is one of the most effective power optimization techniques in modern nanometer integrated circuit design. Most of the previous works apply MBFFs without doing placement refinement of combinational logic cells. Such problem formulation may result in less power reduction due to tight timing constraints with fixed combinational logic cells. This paper introduces a novel placement flow with clock-tree aware flip-flop (FF) merging and MBFF generation, and proposes the corresponding algorithms to simultaneously minimize FF power and clock latency when applying MBFFs during placement. Experimental results based on the IWLS-2005 benchmark show that our approach is very effective in not only FF power but also clock latency minimization without degrading circuit performance. To our best knowledge, this is also the first work in the literature which considers clock trees when generating MBFFs during placement.","Clocks,
Merging,
Timing,
Power demand,
Optimization,
Minimization,
Mathematical model"
Probabilistic Rank Score Coding: A Robust Rank-Order Based Classifier for Electronic Nose Applications,"Motivated by the recent experimental findings about odor identification with the unique spiking patterns of neurons in the biological olfactory system, rank-order-based classifiers have been proposed for gas identification in electronic nose applications. These classifiers rely on one-to-one mapping between the target gas and the temporal sequence of spiking sensors in an electronic nose. However, shuffled spike sequences, due to low repeatability of the response patterns from the sensors, limit the performance of these classifiers. We propose a robust probabilistic rank score coding scheme that tabulates the probability of each spiking sensor at each rank, or temporal position, by exploiting all the spike sequences of the sensors for each target gas, and we analyze a new test vector with this tabular information for its identification. A new quantification metric is proposed in order to estimate the confidence of the classifier's output. Overall, our coding scheme provides an analytical solution that spots the most probable gas for any new test spike sequence with the quantitative feedback. In order to evaluate the robustness of our coding scheme, we target the identification of commonly found health-endangering indoor gases, such as C6H6, CH2O, CO, NO2, and SO2, as a case study. Data of these gases are acquired using our in-house fabricated gas sensor array under different operating conditions, as well as an array of commercially available gas sensors under uniform operational settings. An accuracy rate of 100% has been achieved in both cases with our probabilistic rank score coding scheme.",
"Small Cluster in Cyber Physical Systems: Network Topology, Interdependence and Cascading Failures","In cyber physical system (CPS), computational resources and physical resources are strongly correlated and mutually dependent. Cascading failures occur between coupled networks, cause the system more fragile than single network. Besides widely used metric giant component, we study small cluster (small component) in interdependent networks after cascading failures occur. We first introduce an overview on how small clusters distribute in various single networks. Then we propose a percolation theory based mathematical method to study how small clusters be affected by the interdependence between two coupled networks. We prove that the upper bounds exist for both the fraction and the number of operating small clusters. Without loss of generality, we apply both synthetic network and real network data in simulation to study small clusters under different interdependence models and network topologies. The extensive simulations highlight our findings: except the giant component, considerable proportion of small clusters exists, with the remaining part fragmenting to very tiny pieces or even massive isolated single vertex; no matter how the two networks are tightly coupled, an upper bound exists for the size of small clusters. We also discover that the interdependent small-world networks generally have the highest fractions of operating small clusters. Three attack strategies are compared: Inter Degree Priority Attack, Intra Degree Priority Attack and Random Attack. We observe that the fraction of functioning small clusters keeps stable and is independent from the attack strategies.","Power system faults,
Power system protection,
Power grids,
Data models,
Communication networks,
Actuators,
Sensors"
Mixed Spectral-Element Method for 3-D Maxwell's Eigenvalue Problem,"A high-order 3-D mixed spectral-element method (SEM) based on Gauss-Lobatto-Legendre polynomials in the mixed finite-element framework is proposed to remove the spurious eigenmodes in the numerical solution of the vector Maxwell eigenvalue problem with inhomogeneous, lossy isotropic, and anisotropic media. In order to suppress all zero and nonzero spurious modes that exist in the conventional finite-element and higher order SEMs, the proposed method not only employs the mixed-order curl-conforming vector basis functions for the electric field intensity, but also includes the divergence-free condition given by Gauss' law in a weak form. Several numerical examples are given to verify that the mixed SEM is free of any spurious eigenmodes and has spectral accuracy with analytic eigenvectors.","Eigenvalues and eigenfunctions,
Numerical analysis,
Vectors,
Cavity resonators,
Accuracy,
Media,
Equations"
Cyber-physical systems: A security perspective,"A cyber-physical system (CPS) is a composition of independently interacting components, including computational elements, communications and control systems. Applications of CPS institute at different levels of integration, ranging from nation-wide power grids, to medium scale, such as the smart home, and small scale, e.g. ubiquitous health care systems including implantable medical devices. Cyber-physical systems primarily transmute how we interact with the physical world, with each system requiring different levels of security based on the sensitivity of the control system and the information it carries. Considering the remarkable progress in CPS technologies during recent years, advancement in security and trust measures is much needed to counter the security violations and privacy leakage of integration elements. This paper focuses on security and privacy concerns at different levels of the composition and presents system level solutions for ensuring the security and trust of modern cyber-physical systems.","Smart grids,
Smart homes,
Computer crime,
Medical services,
Guidelines"
Modeling virtualized downlink cellular networks with ultra-dense small cells,"The unrelenting increase in the mobile users' populations and traffic demand drive cellular network operators to densify their infrastructure. Network densification increases the spatial frequency reuse efficiency while maintaining the signal-to-interference-plus-noise-ratio (SINR) performance, hence, increases the spatial spectral efficiency and improves the overall network performance. However, control signaling in such dense networks consumes considerable bandwidth and limits the densification gain. Radio access network (RAN) virtualization via control plane (C-plane) and user plane (U-plane) splitting has been recently proposed to lighten the control signaling burden and improve the network throughput. In this paper, we present a tractable analytical model for virtualized downlink cellular networks, using tools from stochastic geometry. We then apply the developed modeling framework to obtain design insights for virtualized RANs and quantify associated performance improvement.",
A General Scalable and Elastic Content-Based Publish/Subscribe Service,"The big data era is characterized by the emergence of live content with increasing complexities of data dimensionality and data sizes, which poses a new challenge to emergency applications: how to timely disseminate large-scale live content to users who are interested in. The publish/subscribe (pub/sub) model is widely used to disseminate data because of its possibility of expanding the system to Internet-scale size. However, existing pub/sub systems are inadequate to meet the requirement of disseminating live content in the big data era, since their multi-hop routing techniques and coarse-grained partitioning techniques lead to a low matching throughput, and their upload capacities do not scale well. In this paper, we propose a general scalable and elastic pub/sub service based on the cloud computing environment, called GSEC. For generality, we propose a two-layer pub/sub framework to support the dissemination with diverse data sizes and data dimensionality. For scalability, a hybrid space partitioningtechnique is proposed to achieve high matching throughput, which divides subscriptions into multiple clusters in a hierarchical manner. Moreover, a helper-based content distribution technique is proposed to achieve high upload bandwidth, where servers act as both providers and coordinators to fully explore the upload capacity of the system. For elasticity, we propose a performance-aware provisioningtechnique to adjust the scale of servers to adapt to the churn workloads. To evaluate the performance of GSEC, about 1,000 servers are deployed and hundreds of thousands of live content items are tested in our CloudStack-based testbed. Extensive experiments confirm that GSEC can linearly increase the capacities of event matching and content distribution with the growth of servers, adaptively adjust these capacities in tens of seconds according to the churn workloads, and significantly outperforms the state-of-the-art approaches under various parameter settings.",
The MGB challenge: Evaluating multi-genre broadcast media recognition,"This paper describes the Multi-Genre Broadcast (MGB) Challenge at ASRU 2015, an evaluation focused on speech recognition, speaker diarization, and ""lightly supervised"" alignment of BBC TV recordings. The challenge training data covered the whole range of seven weeks BBC TV output across four channels, resulting in about 1,600 hours of broadcast audio. In addition several hundred million words of BBC subtitle text was provided for language modelling. A novel aspect of the evaluation was the exploration of speech recognition and speaker diarization in a longitudinal setting - i.e. recognition of several episodes of the same show, and speaker diarization across these episodes, linking speakers. The longitudinal tasks also offered the opportunity for systems to make use of supplied metadata including show title, genre tag, and date/time of transmission. This paper describes the task data and evaluation process used in the MGB challenge, and summarises the results obtained.",
Interactions with recognized patients using smart glasses,"Recently, different smart glasses solutions have been proposed on the market. The rapid development of this wearable technology has led to several research projects related to applications of smart glasses in healthcare. In this paper we propose a general architecture of the system enabling data integration for the recognized person. In the proposed system smart glasses integrates data obtained for the recognized patient from health care information systems, from devices connected to the patient and from the patient himself. The data integration is possible, if proper patient recognition procedure is used. Therefore, we evaluated three identification methods based on face recognition and using the recognition of graphical markers (i.e. QR-codes and proposed color-based codes). The results show that it is possible to obtain reliable and fast recognition results during the video acquisition by the smart glasses camera.","Glass,
Face recognition,
Image color analysis,
Cameras,
Face,
Medical services,
Training"
Sequential Estimation of Mixtures in Diffusion Networks,"The letter studies the problem of sequential estimation of mixtures in diffusion networks whose nodes communicate only with their adjacent neighbors. The adopted quasi-Bayesian approach yields a probabilistically consistent and computationally non-intensive and fast method, applicable to a wide class of mixture models with unknown component parameters and weights. Moreover, if conjugate priors are used for inferring the component parameters, the solution attains a closed analytic form.",
A Dual-Band High-Gain Resonant Cavity Antenna with a Single Layer Superstrate,"In this communication, we present a novel design of a dual-band high-gain resonant cavity antenna (RCA) with single polarization. First of all, the theory of dual-frequency operation of conventional RCA with single superstrate is discussed. Next, we designed a feed system, for dual-band operation with single polarization and directional patterns, two T-shape slots in nonradiating edges of the microstrip patch are introduced, which serves as the feed system of the designed dual-band high-gain RCA. Then, a full-wave analysis is performed to extract the impedance matching and radiation patterns of feed system and the complete RCA. At the last, measurement results are provided to compare with the modeling and simulations results which agree reasonably well.","Frequency selective surfaces,
Resonant frequency,
Dual band,
Feeds,
Reflection coefficient,
Antenna measurements,
Microstrip antennas"
Now or later? Predicting and maximising success of navigation actions from long-term experience,"In planning for deliberation or navigation in real-world robotic systems, one of the big challenges is to cope with change. It lies in the nature of planning that it has to make assumptions about the future state of the world, and the robot's chances of successively accomplishing actions in this future. Hence, a robot's plan can only be as good as its predictions about the world. In this paper, we present a novel approach to specifically represent changes that stem from periodic events in the environment (e.g. a door being opened or closed), which impact on the success probability of planned actions. We show that our approach to model the probability of action success as a set of superimposed periodic processes allows the robot to predict action outcomes in a long-term data obtained in two real-life offices better than a static model. We furthermore discuss and showcase how this knowledge gathered can be successfully employed in a probabilistic planning framework to devise better navigation plans. The key contributions of this paper are (i) the formation of the spectral model of action outcomes from non-uniform sampling, the (ii) analysis of its predictive power using two long-term datasets, and (iii) the application of the predicted outcomes in an MDP-based planning framework.","Navigation,
Planning,
Predictive models,
Data models,
Analytical models,
Mobile robots"
Dynamic machine learning based matching of nonvolatile processor microarchitecture to harvested energy profile,"Energy harvesting systems without an energy storage device have to efficiently harness the fluctuating and weak power sources to ensure the maximum computational progress. While a simpler processor enables a higher turn-on potential with a weak source, a more powerful processor can utilize more energy that is harvested. Earlier work shows that different complexity levels of nonvolatile microarchitectures provide best fit for different power sources, and even different trails within same power source. In this work, we propose a dynamic nonvolatile microarchitecture by integrating all non-pipelined (NP), N-stage-pipeline (NSP), and Out of Order (OoO) cores together. Neural network machine learning algorithms are also integrated to dynamically adjust the microarchitecture to achieve the maximum forward progress. This integrated solution can achieve forward progress equal to 2.4× of the baseline NP architecture (1.82× of an OoO core).","Microarchitecture,
Computer architecture,
Registers,
Energy storage,
Switches,
Nonvolatile memory"
Help your mobile applications with fog computing,"Cloud computing has paved a way for resource-constrained mobile devices to speed up their computing tasks and to expand their storage capacity. However, cloud computing is not necessary a panacea for all mobile applications. The high network latency to cloud data centers may not be ideal for delay-sensitive applications while storing everything on public clouds risks users' security and privacy. In this paper, we discuss two preliminary ideas, one for mobile application offloading and the other for mobile storage expansion, by leveraging the edge intelligence offered by fog computing to help mobile applications. Preliminary experiments conducted based on implemented prototypes show that fog computing can provide an effective and sometimes better alternative to help mobile applications.",
Self-Aligned Double Patterning Aware Pin Access and Standard Cell Layout Co-Optimization,"Self-aligned double patterning (SADP) is being considered for use at the 10-nm technology node and below for routing layers with pitches down to ~50 nm because it has better line edge roughness and overlay control compared to other multiple patterning candidates. To date, most of the SADP-related literature has focused on enabling SADP-legal routing in physical design tools while few attempts have been made to address the impact SADP routing has on local, standard cell (SC) I/O pin access. At the same time, via layers are used to connect the local SADP routing layers to the I/O pins on lower metal layers. Due to the high via density on the Via-1 layer, the litho-etch-litho-etch (LELE)-aware Via-1 design becomes a necessity to achieve legal pin access at the SC level. In this paper, we present the first study on SADP-aware pin access and layout optimization at the SC level. Accounting for SADP-specific and Via-1 design rules, we propose a coherent framework that uses depth first search, mixed integer linear programming, and backtracking method to enable LELE friendly Via-1 design and simultaneously optimize SADP-based local pin access and within-cell connections. Our experimental results show that, compared with the conventional approach, our framework effectively improves pin access of the SCs and maximizes the pin access flexibility for routing.","Layout,
Wires,
Routing,
Optimization,
Standards,
Pins,
Arrays"
Swadloon: Direction Finding and Indoor Localization Using Acoustic Signal by Shaking Smartphones,"We propose an accurate acoustic direction finding scheme, Swadloon, according to the arbitrary pattern of phone shaking in a rough horizontal plane. Swadloon leverages sensors of the smartphone without the requirement of any specialized devices. Our Swadloon design exploits a key observation: the relative displacement and velocity of the phone-shaking movement corresponds to the subtle phase and frequency shift of the Doppler effects experienced in the received acoustic signal by the phone. Swadloon tracks the displacement of smartphone relative to the acoustic direction with the resolution less than 1 millimeter. The direction is then obtained by combining the velocity from the displacement with the one from the inertial sensors. Major challenges in implementing Swadloon are to measure the displacement precisely and to estimate the shaking velocity accurately when the speed of phone-shaking is low and changes arbitrarily. We propose rigorous methods to address these challenges, and apply Swadloon to several case studies: Phone-to-Phone direction finding, indoor localization and tracking. Our extensive experiments show that the mean error of direction finding is around 2.1 degree within the range of 32 m. For indoor localization, the 90-percentile errors are under 0.92 m. For real-time tracking, the errors are within 0.4 m for walks of 51 m.",
Multisource Data Ensemble Modeling for Clinker Free Lime Content Estimate in Rotary Kiln Sintering Processes,"Clinker free lime (f-CaO) content plays a crucial role in determining the quality of cement. However, the existing methods are mainly based on laboratory analysis and with significant time delays, which makes the closed-loop control of f-CaO content impossible. In this paper, a multisource data ensemble learning-based soft sensor model is developed for online estimation of clinker f-CaO content. To build such a soft sensor model, input flame images, process variables, and the corresponding output f-CaO content data for a rotary cement kiln were collected from No. 2 rotary kiln at Jiuganghongda Cement Plant which produces 2000 tonnes of clinker per day. The raw data were preprocessed to distinguish the flame image regions of interest (ROI) and remove process variable outliers. Three types of flame image ROI features, i.e., color, global configuration, and local configuration features, were then extracted without segmentation. Further, a kernel partial least square technique was applied for extracting the compressed score matrix features from the concatenated flame image features and filtered process variables to avoid high-dimensional, nonlinear, and correlated problems. Feed-forward neural networks with random weights were employed as base learners in our proposed ensemble modeling framework, which aims to enhance the model's reliability and prediction performance. A total of 157 flame images, the associated process variable data, and the experimentally measured f-CaO content data were used in our experiments. A comparative study on the f-CaO content estimator built by various feature compressed techniques and learner models and robustness analysis were carried out. The results indicate that the proposed multisource data ensemble soft sensor model performs favorably and has good potential in real world applications.","Feature extraction,
Kilns,
Data models,
Image color analysis,
Data preprocessing,
Predictive models,
Training"
"Depth Reconstruction From Sparse Samples: Representation, Algorithm, and Sampling","The rapid development of 3D technology and computer vision applications has motivated a thrust of methodologies for depth acquisition and estimation. However, existing hardware and software acquisition methods have limited performance due to poor depth precision, low resolution, and high computational cost. In this paper, we present a computationally efficient method to estimate dense depth maps from sparse measurements. There are three main contributions. First, we provide empirical evidence that depth maps can be encoded much more sparsely than natural images using common dictionaries, such as wavelets and contourlets. We also show that a combined wavelet-contourlet dictionary achieves better performance than using either dictionary alone. Second, we propose an alternating direction method of multipliers (ADMM) for depth map reconstruction. A multiscale warm start procedure is proposed to speed up the convergence. Third, we propose a two-stage randomized sampling scheme to optimally choose the sampling locations, thus maximizing the reconstruction performance for a given sampling budget. Experimental results show that the proposed method produces high-quality dense depth estimates, and is robust to noisy measurements. Applications to real data in stereo matching are demonstrated.","Dictionaries,
Image reconstruction,
Standards,
Optimization,
Three-dimensional displays,
Estimation,
Hardware"
Robust One-Bit Bayesian Compressed Sensing with Sign-Flip Errors,"We consider the problem of sparse signal recovery from one-bit measurements. Due to the noise present in the acquisition and transmission process, some quantized bits may be flipped to their opposite states. These bit-flip errors, also referred to as the sign-flip errors, may result in severe performance degradation. To address this issue, we introduce a robust Bayesian compressed sensing framework to account for sign flip errors. Specifically, sign-flip errors are considered as a result of a sparse noise-corrupted model in which original (unquantized) observations are corrupted by sparse (impulse) noise. A Gaussian-inverse Gamma hierarchical prior is assigned to the noise vector to promote sparsity. Based on the modified hierarchical model, we develop a variational expectation-maximization (EM) algorithm to identify the sign-flip errors and recover the sparse signal simultaneously. Numerical results are provided to illustrate the effectiveness and superiority of the proposed method.","Noise,
Bayes methods,
Compressed sensing,
Vectors,
Signal processing algorithms,
Robustness,
Electronic mail"
Empirical Results for Application Landscape Complexity,"The complexity of application landscapes (AL) has been identified as one of the major challenges in enterprise architecture (EA) management for quite some time. Since there is no agreed upon definition of the term complexity in general or in the context of EA management in particular, literature offers a broad variety of concepts and measurements. Therefore, the main purpose of this paper is to (1) provide an overview about metrics to quantify the complexity of ALs proposed in literature, (2) identify metrics currently used in practice to measure AL complexity, and (3) compare empirical results and assess the metrics' applicability with industry experts. By the assessment of four different ALs from the financial sector, we are able to derive various strengths and weaknesses for the different metrics as well as open issues for future research on quantitative EA models.","Measurement,
Complexity theory,
Companies,
Industries,
Computer architecture,
Cybernetics"
Zero-Bending Piezoelectric Micromachined Ultrasonic Transducer (pMUT) With Enhanced Transmitting Performance,"A piezoelectric micromachined ultrasonic transducer (pMUT) has enabled numerous exciting ultrasonic applications. However, residual stress and initial buckling may worsen the transmitting sensitivity of a pMUT, and also limit its application and commercialization. In this paper, we report a new innovative pMUT with a perfectly flat membrane, i.e., zero-bending membrane. Leveraging on the stress-free AlN thin film, framelike top electrode layout, and integrated vacuum cavity, the initial deflection of suspended membrane is significantly suppressed to only 0.005%. The transmitting sensitivity of the zero-bending pMUT is measured as 123 nm/V at a resonant frequency of 2.21 MHz, which is 450% higher than that of the reference pMUT with slightly non-zero initial deflection. Compared with the simulation results, the measured data of zero-bending pMUT achieve 94.5% of its ideal transmitting sensitivity. It is solid evidence that our approach is an effective and reliable way to overcome the residual stress and the initial buckling issue.","Aluminum nitride,
III-V semiconductor materials,
Sensitivity,
Residual stresses,
Electrodes,
Cavity resonators"
Semi-direct EKF-based monocular visual-inertial odometry,"We propose a novel monocular visual inertial odometry algorithm that combines the advantages of EKF-based approaches with those of direct photometric error minimization methods. The method is based on sparse, very small patches and incorporates the minimization of photometric error directly into the EKF measurement model so that inertial data and vision-based surface measurements are used simultaneously during camera pose estimation. We fuse vision-based and inertial measurements almost at the raw-sensor level, allowing the estimated system state to constrain and guide image-space measurements. Our formulation allows for an efficient implementation that runs in real-time on a standard CPU and has several appealing and unique characteristics such as being robust to fast camera motion, in particular rotation, and not depending on the presence of corner-like features in the scene. We experimentally demonstrate robust and accurate performance compared to ground truth and show that our method works on scenes containing only non-intersecting lines.","Cameras,
Three-dimensional displays,
Standards,
Feature extraction,
Robustness,
Visualization"
A Novel Adaptive Wide Area PSS Based on Output-Only Modal Analysis,"Usage of wide area PSSs (WAPSS) in actual power systems is limited because of their restricted adaptability to different operating conditions. Numerous adaptive control methods have been proposed to solve this problem, but they are limited due to strict prerequisites, such as the necessity of consistent excitations or large disturbances. This paper, therefore, presents a novel adaptive wide area PSS (AWAPSS), which has the ability of tracking system operating condition without the need for meeting the above prerequisites. The inherent dead-band structure of a WAPSS enables a steady system to perform like in an open loop, thus allowing the parameters of a WAPSS to be tuned adaptively through output-only modal analysis. The effectiveness of the novel AWAPSS has been validated in a two-area four-machine system as well as in a large complex system, China Southern Grid.",
"Optimal Backup Distribution in 1-out-of-
N
Cold Standby Systems","This paper considers nonrepairable 1-out-of-N: G cold standby (CS) systems subject to uneven backup actions as well as dynamic backup and retrieval times. In such systems, only one element is online and operates with the rest of the elements waiting in the unpowered CS mode. The operating element performs data backup actions when certain fractions of the mission task are accomplished. The backup actions facilitate data recovery in case of an operating element failure, which allows an activated standby element to take over the task through data retrieval. Backup distribution can have a nonmonotonic effect on mission reliability, time, and cost, leading to the optimal backup distribution problem. In this paper, we first suggest a numerical method to model and evaluate mission reliability, expected time, and cost simultaneously for the considered CS systems with uneven backup actions and dynamic backup and retrieval times. Based on the suggested evaluation method and genetic algorithm, the optimal backup distribution problem is then formulated and solved with the objective to minimize the expected mission cost subject to meeting certain levels of mission reliability and expected mission time. Examples show that the proposed methodology can facilitate a tradeoff study between mission reliability, and time and cost, which assists in the optimal decisionmaking for the backup policy used in the practical design of CS systems.","Genetic algorithms,
Switches,
Optimization,
Redundancy,
Cybernetics,
Educational institutions"
Convex Discriminative Multitask Clustering,"Multitask clustering tries to improve the clustering performance of multiple tasks simultaneously by taking their relationship into account. Most existing multitask clustering algorithms fall into the type of generative clustering, and none are formulated as convex optimization problems. In this paper, we propose two convex Discriminative Multitask Clustering (DMTC) objectives to address the problems. The first one aims to learn a shared feature representation, which can be seen as a technical combination of the convex multitask feature learning and the convex Multiclass Maximum Margin Clustering (M3C). The second one aims to learn the task relationship, which can be seen as a combination of the convex multitask relationship learning and M3C. The objectives of the two algorithms are solved in a uniform procedure by the efficient cutting-plane algorithm and further unified in the Bayesian framework. Experimental results on a toy problem and two benchmark data sets demonstrate the effectiveness of the proposed algorithms.","Clustering algorithms,
Optimization,
Convex functions,
Covariance matrices,
Support vector machines,
Linear programming"
FEATS: Framework for Explorative Analog Topology Synthesis,"This paper proposes a new methodology for automated analog circuit synthesis, aiming to address the challenges known from other analog synthesis approaches: unsatisfactory time predictability due to stochastic-driven circuit generation methods, the dereliction of the creative part during the design process, and the inflexibility leading to synthesis tools, which mostly only handle just one circuit class. This contribution presents the underlying concepts and ideas to provide the predictability, flexibility, and creative freedom in order to elevate analog circuit design to the next step. A circuit generation algorithm is presented, which allows a full design-space exploration. Furthermore, an isomorphism algorithm is developed, which reduces a given set of circuits to its unique being one of the first methodologies addressing this issue. Thus, the algorithm handles vast amounts of circuits in a very efficient manner. The results demonstrate the claimed feasibility and applicability of the synthesis framework in general and in the context of system design.","Topology,
Abstracts,
Libraries,
Algorithm design and analysis,
Ports (Computers),
Analog circuits,
Engines"
Home-Based Zero-Knowledge Multi-Copy Routing in Mobile Social Networks,"A mobile social network (MSN) is a special kind of delay tolerant network (DTN) composed of mobile nodes that move around and share information with each other through their carried short-distance wireless communication devices. A main characteristic of MSNs is that mobile nodes in the networks generally visit some locations (namely, community homes) frequently, while visiting other locations less frequently. In this paper, we propose a novel zero-knowledge multi-copy routing algorithm, homing spread (HS), for homogeneous MSNs, in which all mobile nodes share all community homes. HS is a distributed and localized algorithm. It mainly lets community homes spread messages with a higher priority. Theoretical analysis shows that HS can spread a given number of message copies in an optimal way when the inter-meeting time between any two nodes and between a node and a community home follows independent and identical exponential distributions, respectively. We also extend HS to the heterogeneous MSNs, where mobile nodes have different community homes. In addition, we calculate the expected delivery delay of HS, and conduct extensive simulations. Results show that community homes are important factors in message spreading. By using homes to spread messages faster, HS achieves a better performance than existing zero-knowledge MSN routing algorithms, including Epidemic (with a given number of copies), and Spray&Wait.","Delays,
Mobile nodes,
Routing,
Communities,
Mobile computing"
Optimal Pricing and Energy Scheduling for Hybrid Energy Trading Market in Future Smart Grid,"Future smart grid (SG) has been considered a complex and advanced power system, where energy consumers are connected not only to the traditional energy retailers (e.g., the utility companies), but also to some local energy networks for bidirectional energy trading opportunities. This paper aims to investigate a hybrid energy trading market that is comprised of an external utility company and a local trading market managed by a local trading center (LTC). The existence of local energy market provides new opportunities for the energy consumers and the distributed energy sellers to perform the local energy trading in a cooperative manner such that they all can benefit. This paper first quantifies the respective benefits of the energy consumers and the sellers from the local trading and then investigates how they can optimize their benefits by controlling their energy scheduling in response to the LTC's pricing. Two different types of the LTC are considered: 1) the nonprofit-oriented LTC, which solely aims at benefiting the energy consumers and the sellers; and 2) the profit-oriented LTC, which aims at maximizing its own profit while guaranteeing the required benefit for each consumer and seller. For each type of the LTC, the optimal trading problem is formulated and the associated algorithm is further proposed to efficiently find the LTC's optimal price, as well as the optimal energy scheduling for each consumer and seller. Numerical results are provided to validate the benefits of the hybrid energy trading market and the performance of the proposed algorithms.",
"A Novel In Situ Efficiency Estimation Algorithm for Three-Phase IM Using GA, IEEE Method F1 Calculations, and Pretested Motor Data","The precise estimation of efficiency of induction motors is crucial in industries for energy savings, auditing, and management. This paper presents a novel method for in situ induction motors efficiency estimation by applying the genetic algorithm and utilizing IEEE Form F2-Method F1 calculations with pretested motor data. The method requires a dc test, full-load operating point rms voltages, currents, input power, and speed measurements. The proposed algorithm uses a sensorless technique to determine motor speed. The algorithm is not only an in situ tool; it can also be used as an on-site efficiency estimation tool that might replace the expensive dynamometer procedure. The method was validated by testing 30 induction motors.","Induction motors,
Loss measurement,
Temperature measurement,
Genetic algorithms,
Estimation,
Voltage measurement,
Rotors"
A novel cloud computing based smart farming system for early detection of borer insects in tomatoes,"Every year farmers experience huge losses due to pest infestation in crops & this inturn impacts his livelihood. In this paper we discuss a novel approach to solve this problem by constantly monitoring crops using video processing, cloud computing and robotics. The paper concentrates in methodologies to detect pests in one of the most popular fruits in the world - the tomato. An insight into how the idea of the Internet of Things can also be conceptualized in this project has been elaborated.",
New Analytic Model of Coupling and Substrate Capacitance in Nanometer Technologies,"In this paper, we propose a new modeling method for computing coupling capacitance between interconnects on the same or different layers and substrate capacitance in the nanometer very large-scale integration circuits. The model has been developed based on a template, which is obtained on the basis of electric field approximation and followed by a curve-fitting technique to reach promising accuracy. To verify our proposed model, we develop scripts to generate thousands of layout samples which cover all possible geometric situations for CMOS 180-, 90-, and 65-nm technologies. The proposed model is compared with previously published works with reference to the extracted results from commercial tools. The experimental results show that the estimation errors of our method are much lower than 10% (2%-4% or less for most of the cases) but with significantly reduced computation effort. The proposed model is a general methodology that can be used for any nanometer technologies with different geometric parameters.","Capacitance,
Mathematical model,
Equations,
Metals,
Substrates,
Computational modeling,
Couplings"
Modeling and Estimation of Tip Contact Force for Steerable Ablation Catheters,"Objective: The efficacy of catheter-based cardiac ablation procedures can be significantly improved if real-time information is available concerning contact forces between the catheter tip and cardiac tissue. However, the widely used ablation catheters are not equipped for force sensing. This paper proposes a technique for estimating the contact forces without direct force measurements by studying the changes in the shape of the deflectable distal section of a conventional 7-Fr catheter (henceforth called the “deflectable distal shaft,” the “deflectable shaft,” or the “shaft” of the catheter) in different loading situations. Method: First, the shaft curvature when the tip is moving in free space is studied and based on that, a kinematic model for the deflectable shaft in free space is proposed. In the next step, the shaft shape is analyzed in the case where the tip is in contact with the environment, and it is shown that the curvature of the deflectable shaft provides useful information about the loading status of the catheter and can be used to define an index for determining the range of contact forces exerted by the ablation tip. Results: Experiments with two different steerable ablation catheters show that the defined index can detect the range of applied contact forces correctly in more than 80% of the cases. Based on the proposed technique, a framework for obtaining contact force information by using the shaft curvature at a limited number of points along the deflectable shaft is constructed. Conclusion: The proposed kinematic model and the force estimation technique can be implemented together to describe the catheter's behavior before contact, detect tip/tissue contact, and determine the range of contact forces. Significance: This study proves that the flexibility of the catheter's distal shaft provides a means of estimating the force exerted on tissue by the ablation tip.","Catheters,
Shafts,
Force,
Shape,
Kinematics,
Force sensors,
Robot sensing systems"
Low-Cost Compact Circularly Polarized Directional Antenna for Universal UHF RFID Handheld Reader Applications,"A low-cost compact circularly polarized (CP) directional antenna is proposed for universal ultra-high frequency (UHF) RF identification (RFID) handheld reader applications. The antenna consists of four sequentially rotated inverted-F antennas (IFAs) fed by a compact four-feed network with closed-form design formulas. A prototype is implemented by FR-4 substrates and a thick air layer for the reduction of cost. For return loss (RL) > 13 dB, 3-dB gain variation, and axial ratio (AR) , the prototype achieves the measured bandwidth of 14.9% and exhibits stable symmetrical directional radiation patterns with wide half-power beamwidth. Compared with the reported UHF RFID directional reader antennas, the proposed structure not only exhibits the largest CP bandwidth for easily covering the entire UHF RFID band but also achieves compact size of 95 ×100 ×13.6 mm3.","Radiofrequency identification,
Bandwidth,
Antenna measurements,
Substrates,
UHF antennas,
Couplers"
Solving Uncompromising Problems With Lexicase Selection,"We describe a broad class of problems, called “uncompromising problems,” which are characterized by the requirement that solutions must perform optimally on each of many test cases. Many of the problems that have long motivated genetic programming research, including the automation of many traditional programming tasks, are uncompromising. We describe and analyze the recently proposed “lexicase” parent selection algorithm and show that it can facilitate the solution of uncompromising problems by genetic programming. Unlike most traditional parent selection techniques, lexicase selection does not base selection on a fitness value that is aggregated over all test cases; rather, it considers test cases one at a time in random order. We present results comparing lexicase selection to more traditional parent selection methods, including standard tournament selection and implicit fitness sharing, on four uncompromising problems: 1) finding terms in finite algebras; 2) designing digital multipliers; 3) counting words in files; and 4) performing symbolic regression of the factorial function. We provide evidence that lexicase selection maintains higher levels of population diversity than other selection methods, which may partially explain its utility as a parent selection algorithm in the context of uncompromising problems.","Genetic programming,
Sociology,
Statistics,
Algebra,
Standards,
Programming,
Algorithm design and analysis"
Novel Self-Body-Biasing and Statistical Design for Near-Threshold Circuits With Ultra Energy-Efficient AES as Case Study,"Near-threshold operation enables high energy efficiency, but requires proper design techniques to deal with performance loss and increased sensitivity to process variations. In this paper, we address both issues with two synergistic approaches. First, we introduce a novel body-biasing technique to mitigate the performance loss at near-threshold voltages while not requiring any additional circuitry for the body-bias control, thereby minimizing the design effort and simplifying the systems-on-chip integration. Second, we introduce a novel statistical design methodology to efficiently and accurately evaluate the design guardband strictly needed in the worst case, thereby keeping the area cost of variations at its very minimum. A 65-nm advanced encryption standard testchip demonstrates 1.65× throughput improvement over a baseline design without body biasing, and enables reliable operation over a wide voltage range (0.5-1.2 V) as opposed to traditional body-biasing schemes. In addition, our testchip achieves 1.63× area efficiency improvement compared with a design based on corner analysis. Accordingly, the proposed techniques are well suited for the design of near-threshold specialized hardware with improved performance, reduced silicon area, and design effort.",
Reliability lessons learned from GPU experience with the Titan supercomputer at Oak Ridge leadership computing facility,"The high computational capability of graphics processing units (GPUs) is enabling and driving the scientific discovery process at large-scale. The world's second fastest supercomputer for open science, Titan, has more than 18,000 GPUs that computational scientists use to perform scientific simulations and data analysis. Understanding of GPU reliability characteristics, however, is still in its nascent stage since GPUs have only recently been deployed at large-scale. This paper presents a detailed study of GPU errors and their impact on system operations and applications, describing experiences with the 18,688 GPUs on the Titan supercomputer as well as lessons learned in the process of efficient operation of GPUs at scale. These experiences are helpful to HPC sites which already have large-scale GPU clusters or plan to deploy GPUs in the future.",
Second-Order Cyclostationarity-Based Detection of LTE SC-FDMA Signals for Cognitive Radio Systems,"In this paper, we investigate the detection of long-term evolution (LTE) single carrier-frequency division multiple access (SC-FDMA) signals, with application to cognitive radio systems. We explore the second-order cyclostationarity of the LTE SC-FDMA signals and apply results obtained for the cyclic autocorrelation function to signal detection. The proposed detection algorithm provides a very good performance under various channel conditions, with a short observation time and at low signal-to-noise ratios, with reduced complexity. The validity of the proposed algorithm is verified using signals generated and acquired by laboratory instrumentation, and the experimental results show a good match with computer simulation results.",
Multiscale Tikhonov-Total Variation Image Restoration Using Spatially Varying Edge Coherence Exponent,"Edge preserving regularization using partial differential equation (PDE)-based methods although extensively studied and widely used for image restoration, still have limitations in adapting to local structures. We propose a spatially adaptive multiscale variable exponent-based anisotropic variational PDE method that overcomes current shortcomings, such as over smoothing and staircasing artifacts, while still retaining and enhancing edge structures across scale. Our innovative model automatically balances between Tikhonov and total variation (TV) regularization effects using scene content information by incorporating a spatially varying edge coherence exponent map constructed using the eigenvalues of the filtered structure tensor. The multiscale exponent model we develop leads to a novel restoration method that preserves edges better and provides selective denoising without generating artifacts for both additive and multiplicative noise models. Mathematical analysis of our proposed method in variable exponent space establishes the existence of a minimizer and its properties. The discretization method we use satisfies the maximum-minimum principle which guarantees that artificial edge regions are not created. Extensive experimental results using synthetic, and natural images indicate that the proposed multiscale Tikhonov-TV (MTTV) and dynamical MTTV methods perform better than many contemporary denoising algorithms in terms of several metrics, including signal-to-noise ratio improvement and structure preservation. Promising extensions to handle multiplicative noise models and multichannel imagery are also discussed.",
High RF Performance Enhancement-Mode Al2O3/AlGaN/GaN MIS-HEMTs Fabricated With High-Temperature Gate-Recess Technique,"In this letter, we report high-performance enhancement-mode (E-mode) Al2O3/AlGaN/GaN metal-insulator-semiconductor high-electron-mobility transistors (MIS-HEMTs) fabricated with high-temperature low-damage gate recess technique. The high-temperature gate recess is implemented by increasing the substrate temperature to 180 °C to enhance the desorption of chlorine-based etching residues during the dry etching of AlGaN barrier. High-crystal-quality Al2O3 gate dielectric was grown by atomic-layer deposition using O3 as the oxygen source to suppress hydrogen-induced weak bonds. The fabricated E-mode MIS-HEMTs exhibit a threshold voltage of 1.6 V, a pulsed drive current of 1.13 A/mm, and very low OFF-state standby power of $6.8 \times 10-8 W/mm at VGS = 0 V and VDS = 30 V. At 4 GHz and in pulse-mode operation, the output power density and power-added efficiency were measured to be 5.76 W/mm and 57%, both of which are the highest for GaN-based E-mode MIS-HEMTs reported to date.","Logic gates,
Aluminum gallium nitride,
Wide band gap semiconductors,
Gallium nitride,
HEMTs,
Aluminum oxide,
MODFETs"
A location-aware publish/subscribe framework for parameterized spatio-textual subscriptions,"With the rapid progress of mobile Internet and the growing popularity of smartphones, location-aware publish/subscribe systems have recently attracted significant attention. Different from traditional content-based publish/subscribe, subscriptions registered by subscribers and messages published by publishers include both spatial information and textual descriptions, and messages should be delivered to relevant subscribers whose subscriptions have high relevancy to the messages. To evaluate the relevancy between spatio-textual messages and subscriptions, we should combine the spatial proximity and textual relevancy. Since subscribers have different preferences - some subscribers prefer messages with high spatial proximity and some subscribers pay more attention to messages with high textual relevancy, it calls for new location-aware publish/subscribe techniques to meet various needs from different subscribers. In this paper, we allow subscribers to parameterize their subscriptions and study the location-aware publish/subscribe problem on parameterized spatio-textual subscriptions. One big challenge is to achieve high performance. To meet this requirement, we propose a filter-verification framework to efficiently deliver messages to relevant subscribers. In the filter step, we devise effective filters to prune large numbers of irreverent results and obtain some candidates. In the verification step, we verify the candidates to generate the answers. We propose three effective filters by integrating prefix filtering and spatial pruning techniques. Experimental results show our method achieves higher performance and better quality than baseline approaches.","Subscriptions,
Spatial indexes,
Complexity theory,
Footwear,
Filtering algorithms,
Mobile communication"
Reactive Resource Provisioning Heuristics for Dynamic Dataflows on Cloud Infrastructure,"The need for low latency analysis over high-velocity data streams motivates the need for distributed continuous dataflow systems. Contemporary stream processing systems use simple techniques to scale on elastic cloud resources to handle variable data rates. However, application QoS is also impacted by variability in resource performance exhibited by clouds and hence necessitates autonomic methods of provisioning elastic resources to support such applications on cloud infrastructure. We develop the concept of “dynamic dataflows” which utilize alternate tasks as additional control over the dataflow's cost and QoS. Further, we formalize an optimization problem to represent deployment and runtime resource provisioning that allows us to balance the application's QoS, value, and the resource cost. We propose two greedy heuristics, centralized and sharded, based on the variable-sized bin packing algorithm and compare against a Genetic Algorithm (GA) based heuristic that gives a near-optimal solution. A large-scale simulation study, using the linear road benchmark and VM performance traces from the AWS public cloud, shows that while GA-based heuristic provides a better quality schedule, the greedy heuristics are more practical, and can intelligently utilize cloud elasticity to mitigate the effect of variability, both in input data rates and cloud resource performance, to meet the QoS of fast data applications.","Cloud computing,
Throughput,
Quality of service,
Optimization,
Runtime,
Ports (Computers),
Bandwidth"
Non-Dominated Quantum Iterative Routing Optimization for Wireless Multihop Networks,"Routing in wireless multihop networks (WMHNs) relies on a delicate balance of diverse and often conflicting parameters, when aiming for maximizing the WMHN performance. Classified as a non-deterministic polynomial-time hard problem, routing in WMHNs requires sophisticated methods. As a benefit of observing numerous variables in parallel, quantum computing offers a promising range of algorithms for complexity reduction by exploiting the principle of quantum parallelism (QP), while achieving the optimum full-search-based performance. In fact, the so-called non-dominated quantum optimization (NDQO) algorithm has been proposed for addressing the multiobjective routing problem with the goal of achieving a near-optimal performance, while imposing a complexity of the order of O(N) and O(N√N) in the best and worst case scenarios, respectively. However, as the number of nodes in the WMHN increases, the total number of routes increases exponentially, making its employment infeasible despite the complexity reduction offered. Therefore, we propose a novel optimal quantum-assisted algorithm, namely, the non-dominated quantum iterative optimization (NDQIO) algorithm, which exploits the synergy between the hardware and the QP for the sake of achieving a further complexity reduction, which is on the order of O(√N) and O(N√N) in the best and worst case scenarios, respectively. In addition, we provide simulation results for demonstrating that our NDQIO algorithm achieves an average complexity reduction of almost an order of magnitude compared with the near-optimal NDQO algorithm, while having the same order of power consumption.",
Convex Hull-Based Multiobjective Genetic Programming for Maximizing Receiver Operating Characteristic Performance,"The receiver operating characteristic (ROC) is commonly used to analyze the performance of classifiers in data mining. An important topic in ROC analysis is the ROC convex hull (ROCCH), which is the least convex majorant (LCM) of the empirical ROC curve and covers potential optima for a given set of classifiers. ROCCH maximization problems have been taken as multiobjective optimization problem (MOPs) in some previous work. However, the special characteristics of ROCCH maximization problem makes it different from traditional MOPs. In this paper, the difference will be discussed in detail and a new convex hull-based multiobjective genetic programming (CH-MOGP) is proposed to solve ROCCH maximization problems. Specifically, convex hull-based without redundancy sorting (CWR-sorting) is introduced, which is an indicator-based selection scheme that aims to maximize the area under the convex hull. A novel selection procedure is also proposed based on the proposed sorting scheme. It is hypothesized that by using a tailored indicator-based selection, CH-MOGP becomes more efficient for ROC convex hull approximation than algorithms that compute all Pareto optimal points. Empirical studies are conducted to compare CH-MOGP to both existing machine learning approaches and multiobjective genetic programming (MOGP) methods with classical selection schemes. Experimental results show that CH-MOGP outperforms the other approaches significantly.","Optimization,
Sorting,
Sociology,
Statistics,
Vectors,
Genetic programming,
Approximation methods"
Need for speed: CORA scheduler for optimizing completion-times in the cloud,"There is an increasing need for cloud service performance that can be tailored to customer requirements. In the context of jobs submitted to cloud computing clusters, a crucial requirement is the specification of job completion-times. A natural way to model this specification, is through client/job utility functions that are dependent on job completion-times. We present a method to allocate and schedule heterogeneous resources to jointly optimize the utilities of jobs in a cloud. Specifically: (i) we formulate a completion-time optimal resource allocation (CORA) problem to apportion cluster resources across the jobs that enforces max-min fairness among job utilities, and (ii) starting with an integer programming problem, we perform a series of steps to transform it into an equivalent linear programming problem, and (iii) we implement the proposed framework as a utility-aware resource scheduler in the widely used Hadoop data processing framework, and finally (iv) through extensive experiments with real-world datasets, we show that our prototype achieves significant performance improvement over existing resource-allocation policies.","Linear programming,
Resource management,
Convex functions,
Transforms,
Containers,
Sensitivity,
Conferences"
An Accurate de novo Algorithm for Glycan Topology Determination from Mass Spectra,"Determining the glycan topology automatically from mass spectra represents a great challenge. Existing methods fall into approximate and exact ones. The former including greedy and heuristic ones can reduce the computational complexity, but suffer from information lost in the procedure of glycan interpretation. The latter including dynamic programming and exhaustive enumeration are much slower than the former. In the past years, nearly all emerging methods adopted a tree structure to represent a glycan. They share such problems as repetitive peak counting in reconstructing a candidate structure. Besides, tree-based glycan representation methods often have to give different computational formulas for binary and ternary glycans. We propose a new directed acyclic graph structure for glycan representation. Based on it, this work develops a de novo algorithm to accurately reconstruct the tree structure iteratively from mass spectra with logical constraints and some known biosynthesis rules, by a single computational formula. The experiments on multiple complex glycans extracted from human serum show that the proposed algorithm can achieve higher accuracy to determine a glycan topology than prior methods without increasing computational burden.","Couplings,
Proteins,
Databases,
Computational biology"
Cross-Camera Knowledge Transfer for Multiview People Counting,"We present a novel two-pass framework for counting the number of people in an environment, where multiple cameras provide different views of the subjects. By exploiting the complementary information captured by the cameras, we can transfer knowledge between the cameras to address the difficulties of people counting and improve the performance. The contribution of this paper is threefold. First, normalizing the perspective of visual features and estimating the size of a crowd are highly correlated tasks. Hence, we treat them as a joint learning problem. The derived counting model is scalable and it provides more accurate results than existing approaches. Second, we introduce an algorithm that matches groups of pedestrians in images captured by different cameras. The results provide a common domain for knowledge transfer, so we can work with multiple cameras without worrying about their differences. Third, the proposed counting system is comprised of a pair of collaborative regressors. The first one determines the people count based on features extracted from intracamera visual information, whereas the second calculates the residual by considering the conflicts between intercamera predictions. The two regressors are elegantly coupled and provide an accurate people counting system. The results of experiments in various settings show that, overall, our approach outperforms comparable baseline methods. The significant performance improvement demonstrates the effectiveness of our two-pass regression framework.","Cameras,
Feature extraction,
Visualization,
Estimation,
Training,
Equations,
Knowledge transfer"
Design and Development of a Smart Control Strategy for Plug-In Hybrid Vehicles Including Vehicle-to-Home Functionality,"Plug-in hybrid electric vehicles (PHEVs) are seen to be a step forward in transportation electrification, to replace internal combustion engine (ICE)-based conventional vehicles. However, to consider the vehicle-to-home (V2H) and home-tovehicle (H2V) capabilities, new energy control strategy has to be developed to avoid new peaks consumption. This paper presents a novel controller based on fuzzy logic, which integrates an objective state-of-charge (SoC) for V2H application. The V2H capability is used when the PHEV is connected to the home to help the grid to meet the household loads during peak period. The SoC objective is the minimum SoC that the PHEV has to have when the driver connects the PHEV to the home. The proposed controller is applied on fourth different scenario.","Batteries,
Electric vehicles,
Fuzzy logic,
Plug-in hybrid electric vehicles,
Power generation"
Massive MIMO as a Big Data System: Random Matrix Models and Testbed,"This paper has two parts. The first one deals with how to use large random matrices as building blocks to model the massive data arising from the massive (or large-scale) multiple-input, multiple-output (MIMO) system. As a result, we apply this model for distributed spectrum sensing and network monitoring. The part boils down to the streaming, distributed massive data, for which a new algorithm is obtained and its performance is derived using the central limit theorem that is recently obtained in the literature. The second part deals with the large-scale testbed using software-defined radios (particularly, universal software radio peripheral) that takes us more than four years to develop this 70-node network testbed. To demonstrate the power of the software-defined radio, we reconfigure our testbed quickly into a testbed for massive MIMO. The massive data of this testbed are of central interest in this paper. For the first time, we have modeled the experimental data arising from this testbed. To our best knowledge, there is no other similar work.","MIMO,
Big data,
5G mobile communication,
Random matrices"
Scatter Balance: An Angle-Based Supervised Dimensionality Reduction,"Subspace selection is widely applied in data classification, clustering, and visualization. The samples projected into subspace can be processed efficiently. In this paper, we research the linear discriminant analysis (LDA) and maximum margin criterion (MMC) algorithms intensively and analyze the effects of scatters to subspace selection. Meanwhile, we point out the boundaries of scatters in LDA and MMC algorithms to illustrate the differences and similarities of subspace selection in different circumstances. Besides, the effects of outlier classes on subspace selection are also analyzed. According to the above analysis, we propose a new subspace selection method called angle linear discriminant embedding (ALDE) on the basis of angle measurement. ALDE utilizes the cosine of the angle to get new within-class and between-class scatter matrices and avoids the small sample size problem simultaneously. To deal with high-dimensional data, we extend ALDE to a two-stage ALDE (TS-ALDE). The synthetic data experiments indicate that ALDE can balance the within-class and between-class scatters and be robust to outlier classes. The experimental results based on UCI machine-learning repository and image databases show that TS-ALDE has a lower time complexity than ALDE while processing high-dimensional data.","Optimized production technology,
Principal component analysis,
Algorithm design and analysis,
Eigenvalues and eigenfunctions,
Null space,
Matrix decomposition"
Read Performance: The Newest Barrier in Scaled STT-RAM,"Spin-torque transfer RAM (STT-RAM), a promising alternative to static RAM (SRAM) for reducing leakage power consumption, has been widely studied to mitigate the impact of its asymmetrically long write latency. However, physical effects of technology scaling down to 45 nm and below, in particular, process variation, introduce the previously unreported and alarming trends in read performance and reliability due to reduced sensing margins and increasing error rates. In this brief, we study the scaling trends of STT-RAM from 65 down to 22 nm as they pertain to read performance, including a 50% increase in sensing versus peripheral circuit delay ratio and a more than 80% increase in uncorrectable read error rates. Through differential sensing, we show how 22 nm can return to sense delay ratio levels at 65 nm and uncorrectable read errors can be reduced by an order of magnitude. Through a case study of a multilevel STT-RAM cache, we show how a reconfigurable cache cell can create an extreme access mode (X-mode) based on differential sensing improve to outperform the state-of-the-art STT-RAM caching techniques in both raw performance and performance per watt by more than 10% while still reducing energy consumption over SRAM caches by more than 1/3.","Sensors,
Random access memory,
Computer architecture,
Delays,
Market research,
Error analysis,
Microprocessors"
Secure Massive MIMO transmission in the presence of an active eavesdropper,"In this paper, we investigate secure and reliable transmission strategies for multi-cell multi-user massive multipleinput multiple-output (MIMO) systems in the presence of an active eavesdropper. We consider a time-division duplex system where uplink training is required and an active eavesdropper can attack the training phase to cause pilot contamination at the transmitter. This forces the precoder used in the subsequent downlink transmission phase to implicitly beamform towards the eavesdropper, thus increasing its received signal power. We derive an asymptotic achievable secrecy rate for matched filter precoding and artificial noise (AN) generation at the transmitter when the number of transmit antennas goes to infinity. For the achievability scheme at hand, we obtain the optimal power allocation policy for the transmit signal and the AN in closed form. For the case of correlated fading channels, we show that the impact of the active eavesdropper can be completely removed if the transmit correlation matrices of the users and the eavesdropper are orthogonal. Inspired by this result, we propose a precoder null space design exploiting the low rank property of the transmit correlation matrices of massive MIMO channels, which can significantly degrade the eavesdropping capabilities of the active eavesdropper.",
MyHealthAssistant: An Event-driven Middleware for Multiple Medical Applications on a Smartphone-Mediated Body Sensor Network,"An ever-growing range of wireless sensors for medical monitoring has shown that there is significant interest in monitoring patients in their everyday surroundings. It however remains a challenge to merge information from several wireless sensors and applications are commonly built from scratch. This paper presents a middleware targeted for medical applications on smartphone-like platforms that relies on an event-based design to enable flexible coupling with changing sets of wireless sensor units, while posing only a minor overhead on the resources and battery capacity of the interconnected devices. We illustrate the requirements for such middleware with three different healthcare applications that were deployed with our middleware solution, and characterize the performance with energy consumption, overhead caused for the smartphone, and processing time under real-world circumstances. Results show that with sensing-intensive applications, our solution only minimally impacts the phone's resources, with an added CPU utilization of 3% and a memory usage under 7 MB. Furthermore, for a minimum message delivery ratio of 99.9%, up to 12 sensor readings per second are guaranteed to be handled, regardless of the number of applications using our middleware.","Monitoring,
Middleware,
Smart phones,
Biomedical monitoring,
Medical services,
Sensor systems"
Deep learning for automatic cell detection in wide-field microscopy zebrafish images,"The zebrafish has become a popular experimental model organism for biomedical research. In this paper, a unique framework is proposed for automatically detecting Tyrosine Hydroxylase-containing (TH-labeled) cells in larval zebrafish brain z-stack images recorded through the wide-field microscope. In this framework, a supervised max-pooling Convolutional Neural Network (CNN) is trained to detect cell pixels in regions that are preselected by a Support Vector Machine (SVM) classifier. The results show that the proposed deep-learned method outperforms hand-crafted techniques and demonstrate its potential for automatic cell detection in wide-field microscopy z-stack zebrafish images.","Computer architecture,
Microprocessors,
Training,
Microscopy,
Three-dimensional displays,
Neurons,
Histograms"
Multiperson Tracking With a Network of Ultrawideband Radar Sensors Based on Gaussian Mixture PHD Filters,"In this paper, we investigate the use of Gaussian mixture probability hypothesis density filters for multiple person tracking using ultrawideband (UWB) radar sensors in an indoor environment. An experimental setup consisting of a network of UWB radar sensors and a computer is designed, and a new detection algorithm is proposed. The results of this experimental proof-of-concept study show that it is possible to accurately track multiple targets using a UWB radar sensor network in indoor environments based on the proposed approach.",
Energy Harvesting for Two-Way OFDM Communications under Hostile Jamming,"Hostile jamming can cause significant performance degradation in wireless communications, but it also provides an unexplored source of additional signal power. In this letter, we propose an energy-harvesting receiver for two-way orthogonal frequency division multiplexing (OFDM) systems under hostile jamming. More specifically, in the downlink, the receiver is designed to simultaneously process information and harvest energy from the received desired signal as well as the jamming interference through a power splitter. The harvested energy can then be used as an additional source of power to enhance the uplink transmission. We investigate the optimal power allocation and power splitting ratio to maximize the sum-rate of the uplink and downlink transmissions. To reduce the complexity, a suboptimal energy harvesting scheme with closed-form solution is proposed. We also obtain a lower bound on the sum-rate of the proposed scheme under strong full-band jamming.","Jamming,
OFDM,
Downlink,
Energy harvesting,
Receivers,
Uplink,
Resource management"
Incorporating PV Inverter Control Schemes for Planning Active Distribution Networks,"The distribution network planning under active network management (ANM) schemes is becoming of interest due to substantial benefits in facilitating the increasing integration of renewable energy sources. This paper presents various potential ANM schemes based on the photovoltaic inverter control (PVIC) considering enhanced utilization of the inverter reactive power capability. Depending on the active power generation of PV arrays, inverter size and desired reactive power settings, several PVIC schemes are proposed. The PVIC schemes are incorporated in the optimal power flow (OPF) and formulated as a nonlinear programming (NLP) problem. In this study, the PVIC schemes are applied to maximize the total wind-distributed generation (DG) penetration on a typical U.K. distribution system. Various case studies are presented and compared to evaluate the performance. The results show that the proposed schemes can significantly increase the wind penetration levels by 45.4% and up to 92.3%.","Reactive power,
Power system planning,
Distributed power generation,
Load flow"
End-to-End Delay Minimization for Scientific Workflows in Clouds under Budget Constraint,"Next-generation e-Science features large-scale, compute-intensive workflows of many computing modules that are typically executed in a distributed manner. With the recent emergence of cloud computing and the rapid deployment of cloud infrastructures, an increasing number of scientific workflows have been shifted or are in active transition to cloud environments. As cloud computing makes computing a utility, scientists across different application domains are facing the same challenge of reducing financial cost in addition to meeting the traditional goal of performance optimization. We develop a prototype generic workflow system by leveraging existing technologies for a quick evaluation of scientific workflow optimization strategies. We construct analytical models to quantify the network performance of scientific workflows using cloud-based computing resources, and formulate a task scheduling problem to minimize the workflow end-to-end delay under a user-specified financial constraint. We rigorously prove that the proposed problem is not only NP-complete but also non-approximable. We design a heuristic solution to this problem, and illustrate its performance superiority over existing methods through extensive simulations and real-life workflow experiments based on proof-of-concept implementation and deployment in a local cloud testbed.","Cloud computing,
Delays,
Data transfer,
Prototypes,
Schedules,
Processor scheduling,
Virtual machining"
Biologically Inspired Visual Model With Preliminary Cognition and Active Attention Adjustment,"Recently, many computational models have been proposed to simulate visual cognition process. For example, the hierarchical Max-Pooling (HMAX) model was proposed according to the hierarchical and bottom-up structure of V1 to V4 in the ventral pathway of primate visual cortex, which could achieve position- and scale-tolerant recognition. In our previous work, we have introduced memory and association into the HMAX model to simulate visual cognition process. In this paper, we improve our theoretical framework by mimicking a more elaborate structure and function of the primate visual cortex. We will mainly focus on the new formation of memory and association in visual processing under different circumstances as well as preliminary cognition and active adjustment in the inferior temporal cortex, which are absent in the HMAX model. The main contributions of this paper are: 1) in the memory and association part, we apply deep convolutional neural networks to extract various episodic features of the objects since people use different features for object recognition. Moreover, to achieve a fast and robust recognition in the retrieval and association process, different types of features are stored in separated clusters and the feature binding of the same object is stimulated in a loop discharge manner and 2) in the preliminary cognition and active adjustment part, we introduce preliminary cognition to classify different types of objects since distinct neural circuits in a human brain are used for identification of various types of objects. Furthermore, active cognition adjustment of occlusion and orientation is implemented to the model to mimic the top-down effect in human cognition process. Finally, our model is evaluated on two face databases CAS-PEAL-R1 and AR. The results demonstrate that our model exhibits its efficiency on visual recognition process with much lower memory storage requirement and a better performance compared with the traditional purely computational methods.","Visualization,
Cognition,
Biological system modeling,
Computational modeling,
Brain modeling,
Feature extraction"
Learning Spatial and Temporal Extents of Human Actions for Action Detection,"For the problem of action detection, most existing methods require that relevant portions of the action of interest in training videos have been manually annotated with bounding boxes. Some recent works tried to avoid tedious manual annotation , and proposed to automatically identify the relevant portions in training videos. However, these methods only concerned the identification in either spatial or temporal domain, and may get irrelevant contents from another domain. These irrelevant contents are usually undesirable in the training phase, which will lead to a degradation of the detection performance. This paper advances prior work by proposing a joint learning framework to simultaneously identify the spatial and temporal extents of the action of interest in training videos. To get pixel-level localization results, our method uses dense trajectories extracted from videos as local features to represent actions. We first present a trajectory split-and-merge algorithm to segment a video into the background and several separated foreground moving objects. In this algorithm, the inherent temporal smoothness of human actions is exploited to facilitate segmentation. Then, with the latent SVM framework on segmentation results, spatial and temporal extents of the action of interest are treated as latent variables that are inferred simultaneously with action recognition. Experiments on two challenging datasets show that action detection with our learned spatial and temporal extents is superior than state-of-the-art methods.","Trajectory,
Videos,
Training,
Feature extraction,
Support vector machines,
Discrete cosine transforms,
Partitioning algorithms"
The Bose and Minimum Distance of a Class of BCH Codes,"Cyclic codes are an interesting class of linear codes due to their efficient encoding and decoding algorithms. Bose-Ray-Chaudhuri-Hocquenghem (BCH) codes form a subclass of cyclic codes and are very important in both theory and practice as they have good error-correcting capability and are widely used in communication systems, storage devices, and consumer electronics. However, the dimension and minimum distance of BCH codes are not known in general. The objective of this paper is to determine the Bose and minimum distances of a class of narrow-sense primitive BCH codes.","Polynomials,
Generators,
Educational institutions,
Linear codes,
Reed-Solomon codes,
Electronic mail"
On-Chip Compensated Wide Output Range Boost Converter with Fixed-Frequency Adaptive Off-Time Control for LED Driver Applications,"An on-chip compensated wide output range boost converter with fixed-frequency adaptive off-time current-mode control is presented. The small signal characteristic of the boost converter with current-mode control is reviewed, and an adaptive current sensing technique is proposed to reduce the variation of phase margin at different output voltages. On-chip compensation is achieved with a Type II compensator. Adaptive off-time control is adopted for its fast response and no need for slope compensation, while its disadvantage of varying switching frequency is eliminated by the proposed off-time generator. The IC controller was fabricated in a 0.5 μm 2P3M BCD 40 V process. Measurement results confirm that an output range of 5.5 V ~ 36 V with an input voltage of 5 V is achieved. The switching frequency is fixed at 1 MHz with a variation of ±1%. The measured peak efficiency and maximum output power are 92.9% and 8.6 W, respectively. For a load step of 200 mA using a 3.3-μH inductor and a 20-μF output capacitor, overshoot and undershoot of the load transient responses are smaller than 1% of the output voltage.","Control systems,
Switching frequency,
Inductors,
Voltage control,
Poles and zeros,
System-on-chip,
Pulse width modulation"
Customized Certificate Revocation Lists for IEEE 802.11s-Based Smart Grid AMI Networks,"Public-key cryptography (PKC) is widely used in smart grid (SG) communications to reduce the overhead of key management. However, PKC comes with its own problems in terms of certificate management. Specifically, certificate revocation lists (CRLs) need to be maintained and distributed to the smart meters (SMs) in order to ensure security of the communications. The size of CRLs may grow over time and eventually may introduce additional delay, bandwidth, and storage overhead when various applications are run on SG. In this paper, we propose novel algorithms for creating customized CRLs with reduced size for IEEE 802.11s-based advanced metering infrastructure (AMI) networks. Rather than maintaining a huge-size single CRL that introduces unnecessary search time and storage, the idea is to cluster/group SMs within the AMI network and create CRLs based on these groups. The grouping is mainly done in such a way that they bring together the SMs that will be very likely to communicate so that the CRLs will be kept local to that group. To this end, we propose two novel grouping algorithms. The first algorithm is a bottom-up approach, which is based on the existing routes from the SMs to the gateway. Since the SMs will be sending their data to the gateway through the nodes on the route, this forms a natural grouping. The second approach is a top-down recursive approach, which considers the minimum spanning tree of the network and then divides it into smaller subtrees. Via grouping, the length of the CRL for each SM and the corresponding distribution overhead can be reduced significantly. Simulation results have shown that our approach can maintain a balance between the size of the CRL and the number of signatures generated by CAs while guaranteeing security of the communications.","Logic gates,
Security,
IEEE 802.11 Standards,
Wireless communication,
Relays,
Smart grids"
Large-Scale Weakly Supervised Object Localization via Latent Category Learning,"Localizing objects in cluttered backgrounds is challenging under large-scale weakly supervised conditions. Due to the cluttered image condition, objects usually have large ambiguity with backgrounds. Besides, there is also a lack of effective algorithm for large-scale weakly supervised localization in cluttered backgrounds. However, backgrounds contain useful latent information, e.g., the sky in the aeroplane class. If this latent information can be learned, object-background ambiguity can be largely reduced and background can be suppressed effectively. In this paper, we propose the latent category learning (LCL) in large-scale cluttered conditions. LCL is an unsupervised learning method which requires only image-level class labels. First, we use the latent semantic analysis with semantic object representation to learn the latent categories, which represent objects, object parts or backgrounds. Second, to determine which category contains the target object, we propose a category selection strategy by evaluating each category's discrimination. Finally, we propose the online LCL for use in large-scale conditions. Evaluation on the challenging PASCAL Visual Object Class (VOC) 2007 and the large-scale imagenet large-scale visual recognition challenge 2013 detection data sets shows that the method can improve the annotation precision by 10% over previous methods. More importantly, we achieve the detection precision which outperforms previous results by a large margin and can be competitive to the supervised deformable part model 5.0 baseline on both data sets.","Semantics,
Visualization,
Training,
Proposals,
Search problems,
Feature extraction,
Histograms"
Evaluation and Acceleration of High-Throughput Fixed-Point Object Detection on FPGAs,"Reliance on object or people detection is rapidly growing beyond surveillance to industrial and social applications. The histogram of oriented gradients (HOG), one of the most popular object detection algorithms, achieves high detection accuracy but delivers just under 1 frame/s on a high-end CPU. Field-programmable gate array (FPGA) accelerations of this algorithm are limited by the intensive floating-point computations. All current fixed-point HOG implementations use large bit width to maintain detection accuracy, or perform poorly at reduced data precision. In this paper, we introduce the full-image evaluation methodology to explore the FPGA implementation of HOG using reduced bit width. This approach lessens the required area resources on the FPGA, and increases the clock frequency and hence the throughput per device through increased parallelism. We evaluate the detection accuracy of the fixed-point HOG by applying state-of-the-art computer vision pedestrian detection evaluation metrics and show it performs as well as the original floating-point code from OpenCV. We then show our single FPGA implementation achieves a 68.7 × higher throughput than a highend CPU, 5.1 × higher than a high-end graphics processing unit (GPU), and 7.8 × higher than the same implementation using floating-point on the same FPGA. A power consumption comparison for different platforms shows our fixed-point FPGA implementation uses 130 × less power than CPU, and 31 × less energy than GPU to process one image.","Field programmable gate arrays,
Histograms,
Accuracy,
Throughput,
Vectors,
Graphics processing units,
Equations"
Throughput-Optimal Cross-Layer Design for Cognitive Radio Ad Hoc Networks,"We present a distributed, integrated medium access control, scheduling, routing and congestion/rate control protocol stack for cognitive radio ad hoc networks (CRAHNs) that dynamically exploits the available spectrum resources left unused by primary licensed users, maximizing the throughput of a set of multi-hop flows between peer nodes. Using a network utility maximization (NUM) formulation, we devise a distributed solution consisting of a set of sub-algorithms for the different layers of the protocol stack (MAC, flow scheduling and routing), which result from a natural decomposition of the problem into sub-problems. Specifically, we show that: 1) The NUM optimization problem can be solved via duality theory in a distributed way, and 2) the resulting algorithms can be regarded as the CRAHN protocols. These protocols combine back-pressure scheduling with a CSMA-based random access with exponential backoffs. Our theoretical findings are exploited to provide a practical implementation of our algorithms using a common control channel for node coordination and a wireless spectrum sensor network for spectrum sensing. We evaluate our solutions through ns-2 MIRACLE-based simulations. Our results show that the proposed protocol stack effectively enables multiple flows among cognitive radio nodes to coexist with primary communications. The CRAHN achieves high utilization of the spectrum left unused by the licensed users, while the impact on their communications is limited to an increase of their packet error rate that is below 1 percent.","Interference,
Availability,
Peer-to-peer computing,
Cognitive radio,
Media Access Protocol,
Routing"
Profit Improvement in Wireless Video Broadcasting System: A Marginal Principle Approach,"In this paper, we address the problem of how to make the wireless service provider have better profits with consideration of user experience provision in wireless video broadcasting systems. We propose a marginal-based pricing and a resource-allocation framework to achieve better resource utilization and profit improvement. The marginal principle includes 1) marginal user principle, in which a pricing mechanism is established on the basis of marginal users, such that the WSP can seek its own maximum profit of each content with a QoE guarantee; 2) marginal profit principle, in which a WSP can earn the maximum profit through multicontent-service provision by regulating rate allocation in limited available bandwidth. Furthermore, we present a two-tier framework consisting of the inner and outer loops. The inner loop focuses on pricing-based service provision based on the notion of marginal user principle. The outer loop concentrates on allocating bandwidth among multiple video contents according to marginal profit principle. For the solution, we model the profit regions of WSPs and end-users as the polymatroid structures and model the corresponding allocated rate regions as the contra-polymatroid structures. Through exploiting the properties of polymatroid and contra-polymatroid structures, the broadcasting profit problem is solved by finding the optimal rate vector on the sum-rate facet which satisfies the maximal achievable profit. Extensive performance comparison and analysis are presented to demonstrate efficiency of the proposed solution.","Broadcasting,
Multimedia communication,
Wireless communication,
Pricing,
Resource management,
Bandwidth,
Quality of service"
Compact 0.92/2.45-GH Dual-Band Directional Circularly Polarized Microstrip Antenna for Handheld RFID Reader Applications,"This paper presents a compact 0.92/2.45-GHz dual-band directional circularly polarized (CP) microstrip antenna for handheld radio-frequency identification (RFID) reader applications. The proposed antenna comprises a wideband dual-feed network and two stacked concentric patches assembled by two orthogonally placed vertical probes. The dual-feed network feeds quadrature signals across the RFID bands between 0.92 and 2.45 GHz. The two stacked concentric patches provide resonance frequencies in fundamental mode for lower band and higher band, respectively. Additionally, the antenna features only one connection port and same sense CP radiation at two bands, beneficial to cost and complexity reductions of the dual-band front end of RFID readers. The measurement results show the performances of return loss (RL) >10 dB, 3-dB gain variation, and axial ratio (AR) <;3 dB are achieved on the bands 0.911-0.933 GHz and 2.40- 2.57 GHz. The measured peak gains are 3.8 dBic at 0.926 GHz and 8.9 dBic at 2.48 GHz. In addition, the antenna provides symmetrical patterns with wide-angle half-power beamwidths and wide-angle 3-dB AR beamwidths. The size of the antenna 110 × 110 × 6.6 mm3 is much smaller than reported dual-band one port RFID directional CP reader antennas. The antenna appropriates to both ultra-high frequency (UHF) and industrial scientific and medical (ISM) bands in handheld RFID reader applications.","Radiofrequency identification,
Dual band,
Ports (Computers),
Substrates,
Microstrip antennas,
Directive antennas"
Differentially private and strategy-proof spectrum auction with approximate revenue maximization,"The rapid growth of wireless mobile users and applications has led to high demand of spectrum. Auction is a powerful tool to improve the utilization of spectrum resource, and many auction mechanisms have been proposed thus far. However, none of them has considered both the privacy of bidders and the revenue gain of the auctioneer together. In this paper, we study the design of privacy-preserving auction mechanisms. We first propose a differentially private auction mechanism which can achieve strategy-proofness and a near optimal expected revenue based on the concept of virtual valuation. Assuming the knowledge of the bidders' valuation distributions, the near optimal differentially private and strategy-proof auction mechanism uses the generalized Vickrey-Clarke-Groves auction payment scheme to achieve high revenue with a high probability. To tackle its high computational complexity, we also propose an approximate differentially PrivAte, Strategy-proof, and polynomially tractable Spectrum (PASS) auction mechanism that can achieve a suboptimal revenue. PASS uses a monotone allocation algorithm and the critical payment scheme to achieve strategy-proofness. We also evaluate PASS extensively via simulation, showing that it can generate more revenue than existing mechanisms in the spectrum auction markets.","Privacy,
Cost accounting,
Resource management,
Wireless communication,
Computational complexity,
Conferences,
Computers"
Railway Fastener Inspection by Real-Time Machine Vision,"In this paper, a real-time railway fastener detection system using a high-speed laser range finder camera is presented. First, an extensive analysis of various methods based on pixel-wise and histogram similarities are conducted on a specific railway route. Then, a fusing stage is introduced which combines least correlated approaches also considering the performance upgrade after fusing. Then, the resulting method is tested on a larger database collected from a different railway route. After observing repeated successes, the method is implemented on NI LabVIEW and run real-time with a high-speed 3-D camera placed under a railway carriage designed for railway quality inspection.","Fasteners,
Rail transportation,
Inspection,
Training,
Principal component analysis,
Rails,
Histograms"
A Compact Kapton-Based Inkjet-Printed Multiband Antenna for Flexible Wireless Devices,"A low-cost inkjet-printed multiband antenna envisioned for integration into flexible and conformal mobile devices is presented. The antenna structure contains a novel triangular iterative design with coplanar waveguide (CPW) feed, printed on a Kapton polyimide-based flexible substrate with dimensions of 70×70×0.11 mm3. The antenna covers four wide frequency bands with measured impedance bandwidths of 54.4%, 14%, 23.5% and 17.2%, centered at 1.2, 2.0, 2.6 and 3.4 GHz, respectively, thus, enabling it to cover GSM 900, GPS, UMTS, WLAN, ISM, Bluetooth, LTE 2300/2500 and WiMAX standards. The antenna has omnidirectional radiation pattern with a maximum gain of 2.1 dBi. To characterize the flexibility of the antenna, the fabricated prototype is tested in convex and concave bent configurations for radii of 78 mm and 59 mm. The overall performance remains unaffected, except a minor shift of 20 MHz and 60 MHz in S11, for concave bending at both radii. The compact, lightweight and conformal design as well as multiband performance in bent configurations, proves the suitability of the antenna for future electronic devices.","Antenna measurements,
Substrates,
Antenna radiation patterns,
Flexible electronics"
Object-Based Multiple Foreground Video Co-Segmentation via Multi-State Selection Graph,"We present a technique for multiple foreground video co-segmentation in a set of videos. This technique is based on category-independent object proposals. To identify the foreground objects in each frame, we examine the properties of the various regions that reflect the characteristics of foregrounds, considering the intra-video coherence of the foreground as well as the foreground consistency among the different videos in the set. Multiple foregrounds are handled via a multi-state selection graph in which a node representing a video frame can take multiple labels that correspond to different objects. In addition, our method incorporates an indicator matrix that for the first time allows accurate handling of cases with common foreground objects missing in some videos, thus preventing irrelevant regions from being misclassified as foreground objects. An iterative procedure is proposed to optimize our new objective function. As demonstrated through comprehensive experiments, this object-based multiple foreground video co-segmentation method compares well with related techniques that co-segment multiple foregrounds.","Image segmentation,
Proposals,
Feature extraction,
TV,
Electronic mail,
Learning systems,
Training"
Ambient RF Energy Harvesting From a Two-Way Talk Radio for Flexible Wearable Wireless Sensor Devices Utilizing Inkjet Printing Technologies,"A complete design and additive fabrication process of flexible wearable radio-frequency (RF) energy harvesters for off-the-shelf 2 W two-way talk radios utilizing inkjet printing technology is discussed in this paper. As a result of numerous output dc power measurements of fabricated proof-of-concept prototypes, a maximum output power of 146.9 mW and 43.2 mW was achieved with an H-field and E-field harvester, respectively. Also, the effect of misalignment between receiver and hand-held radio on harvesting performance is discussed in detail. To verify their potential in real-world wearable autonomous RF modules, the operation of E- and H-field energy harvesters was verified by utilizing an LED and a microcontroller communication module under on-body and on-bottle conditions, and the effect of the energy harvesters on the performance of the harvested communication systems was inspected through received power measurements in an anechoic chamber.","Printing,
Radio frequency,
Energy harvesting,
Fabrication,
Power measurement,
Ink,
Substrates"
A New Railway Power Flow Control System Coupled With Asymmetric Double LC Branches,"Facing the challenges of power quality problems and excessive neutral sections of conventional two-phase electric railway supply system, the way of adopting railway static power conditioner (RPC)-based single-phase supply system is a feasible solution. To enhance the cost-efficiency and reliability of RPC, a novel compensating system named asymmetric double LC-coupled railway power flow conditioner (ALC-RPFC) is proposed in this paper. The study indicates that compared with the conventional RPC, the proposed ALC-RPFC has an effective heavy-load compensating ability with lower power rating, which is benefit to enhance converter's operating efficiency and reliability. Besides, a design method for LC coupling branches mentioned in this paper is suitable for fluctuated railway loads, and is useful for designers of industrial applications as well. Finally, the good heavy-load compensating performance and power capacity decreasing ability of the ALC-RPFC are validated based on simulation and experiment results.",
Ribosome Flow Model on a Ring,"The asymmetric simple exclusion process (ASEP) is an important model from statistical physics describing particles that hop randomly from one site to the next along an ordered lattice of sites, but only if the next site is empty. ASEP has been used to model and analyze numerous multiagent systems with local interactions including the flow of ribosomes along the mRNA strand. In ASEP with periodic boundary conditions a particle that hops from the last site returns to the first one. The mean field approximation of this model is referred to as the ribosome flow model on a ring (RFMR). The RFMR may be used to model both synthetic and endogenous gene expression regimes. We analyze the RFMR using the theory of monotone dynamical systems. We show that it admits a continuum of equilibrium points and that every trajectory converges to an equilibrium point. Furthermore, we show that it entrains to periodic transition rates between the sites. We describe the implications of the analysis results to understanding and engineering cyclic mRNA translation in-vitro and in-vivo.",
ARIMA-based demand forecasting method considering probabilistic model of electric vehicles' parking lots,"Electric transportation is one of the key elements of the future power systems since conventional power networks are rapidly evolving towards smart grids. This transition creates the need for systematic utilization of electric vehicles (EV) in order to avoid unpredictable effects on the power systems. An accurate and efficient method for demand forecasting of EVs is needed to perform a feasible scheduling of resources in order to supply the predicted load sufficiently. This paper presents a method for electricity demand forecasting considering EV parking lots' charging demand using historical load data. The method is based on auto-regressive integrated moving average (ARIMA) model for medium-term demand forecasting. The proposed approach improves the forecasting accuracy. Probabilistic hierarchical EVs' parking lot demand modeling is used to estimate the expected load for each parking lots' daily charging demand. In order to evaluate the effectiveness of the proposed approach, it is implemented on PJM historical load data. The simulation results show the high accuracy of the proposed method for electricity demand forecasting.","Load modeling,
Predictive models,
Mathematical model,
Smart grids,
Probabilistic logic,
Demand forecasting"
Evolution of the Internet Economic Ecosystem,"The evolution of the Internet has manifested itself in many ways: the traffic characteristics, the interconnection topologies, and the business relationships among the autonomous components. It is important to understand why (and how) this evolution came about, and how the interplay of these dynamics may affect future evolution and services. We propose a network-aware, macroscopic model that captures the characteristics and interactions of the application and network providers, and show how it leads to a market equilibrium of the ecosystem. By analyzing the driving forces and the dynamics of the market equilibrium, we obtain some fundamental understandings of the cause and effect of the Internet evolution, which explain why some historical and recent evolutions have happened. Furthermore, by projecting the likely future evolutions, our model can help application and network providers to make informed business decisions so as to succeed in this competitive ecosystem.","Throughput,
Internet,
Ecosystems,
Pricing,
Economics,
Sensitivity"
A Probabilistic Method for Image Enhancement With Simultaneous Illumination and Reflectance Estimation,"In this paper, a new probabilistic method for image enhancement is presented based on a simultaneous estimation of illumination and reflectance in the linear domain. We show that the linear domain model can better represent prior information for better estimation of reflectance and illumination than the logarithmic domain. A maximum a posteriori (MAP) formulation is employed with priors of both illumination and reflectance. To estimate illumination and reflectance effectively, an alternating direction method of multipliers is adopted to solve the MAP problem. The experimental results show the satisfactory performance of the proposed method to obtain reflectance and illumination with visually pleasing enhanced results and a promising convergence rate. Compared with other testing methods, the proposed method yields comparable or better results on both subjective and objective assessments.","Lighting,
Probabilistic logic,
Estimation,
Image enhancement,
Image color analysis,
Mathematical model,
Computational modeling"
SAR: A sentiment-aspect-region model for user preference analysis in geo-tagged reviews,"Many location based services, such as FourSquare, Yelp, TripAdvisor, Google Places, etc., allow users to compose reviews or tips on points of interest (POIs), each having a geographical coordinates. These services have accumulated a large amount of such geo-tagged review data, which allows deep analysis of user preferences in POIs. This paper studies two types of user preferences to POIs: topical-region preference and category aware topical-aspect preference. We propose a unified probabilistic model to capture these two preferences simultaneously. In addition, our model is capable of capturing the interaction of different factors, including topical aspect, sentiment, and spatial information. The model can be used in a number of applications, such as POI recommendation and user recommendation, among others. In addition, the model enables us to investigate whether people like an aspect of a POI or whether people like a topical aspect of some type of POIs (e.g., bars) in a region, which offer explanation for recommendations. Experiments on real world datasets show that the model achieves significant improvement in POI recommendation and user recommendation in comparison to the state-of-the-art methods. We also propose an efficient online recommendation algorithm based on our model, which saves up to 90% computation time.","Analytical models,
Computational modeling,
Proposals,
Mathematical model,
Inference algorithms,
Data mining,
Gaussian distribution"
On the role of astroglial syncytia in self-repairing spiking neural networks,"It has been shown that brain-like self-repair can arise from the interactions between neurons and astrocytes where endocannabinoids are synthesized and released from active neurons. This retrograde messenger feeds back to local synapses directly and indirectly to distant synapses via astrocytes. This direct/indirect feedback of the endocannabinoid retrograde messenger results in the modulation of the probability of release (PR) at synaptic sites. When synapses fail, there is a corresponding falloff in the firing activity of the associated neurons, and hence the strength of the direct feedback messenger diminishes. This triggers an increase in PR of healthy synapses, due to the indirect messenger from other active neurons, which is the catalyst for the repair process. In this paper, the repair process is implemented by developing a new learning rule that captures the spike-timing-dependent plasticity and Bienenstock, Cooper, and Munro learning rules. The rule is activated by the increase in PR and results in a potentiation of the weight values, which reestablishes the firing activity of neurons. In addition, this self-repairing mechanism is extended to network-level repair where astrocyte to astrocyte communications are implemented using a linear gap junction model. This facilitates the implementation of an astroglial syncytium involving multiple astrocytes, which relays the indirect feedback messenger to distant neurons: each astrocyte is bidirectionally coupled to neurons. A detailed and comprehensive set of results with analysis is presented demonstrating repair at both cellular and network levels.","Neurons,
Maintenance engineering,
Junctions,
Neurotransmitters,
Calcium,
Biological neural networks,
Mathematical model"
Glove-Based Continuous Arabic Sign Language Recognition in User-Dependent Mode,"In this paper, we propose a glove-based Arabic sign language recognition system using a novel technique for sequential data classification. We compile a sensor-based dataset of 40 sentences using an 80-word lexicon. In the dataset, hand movements are captured using two DG5-VHand data gloves. Data labeling is performed using a camera to synchronize hand movements with their corresponding sign language words. Low-complexity preprocessing and feature extraction techniques are applied to capture and emphasize the temporal dependence of the data. Subsequently, a Modified k-Nearest Neighbor (MKNN) approach is used for classification. The proposed MKNN makes use of the context of feature vectors for the purpose of accurate classification. The proposed solution achieved a sentence recognition rate of 98.9%. The results are compared against an existing vision-based approach that uses the same set of sentences. The proposed solution is superior in terms of classification rates while eliminating restrictions of vision-based systems.","Assistive technology,
Gesture recognition,
Vectors,
Feature extraction,
Accuracy,
Training,
Man machine systems"
Tri-Subject Kinship Verification: Understanding the Core of A Family,"One major challenge in computer vision is to go beyond the modeling of individual objects and to investigate the bi- (one-versus-one) or tri- (one-versus-two) relationship among multiple visual entities, answering such questions as whether a child in a photo belongs to the given parents. The child-parents relationship plays a core role in a family, and understanding such kin relationship would have a fundamental impact on the behavior of an artificial intelligent agent working in the human world. In this work, we tackle the problem of one-versus-two (tri-subject) kinship verification and our contributions are threefold: 1) a novel relative symmetric bilinear model (RSBM) is introduced to model the similarity between the child and the parents, by incorporating the prior knowledge that a child may resemble one particular parent more than the other; 2) a spatially voted method for feature selection, which jointly selects the most discriminative features for the child-parents pair, while taking local spatial information into account; and 3) a large-scale tri-subject kinship database characterized by over 1,000 child-parents families. Extensive experiments on KinFaceW, Family101, and our newly released kinship database show that the proposed method outperforms several previous state of the art methods, while could also be used to significantly boost the performance of one-versus-one kinship verification when the information about both parents are available.","Face,
Databases,
Feature extraction,
Visualization,
Logistics,
Computer vision,
Measurement"
Improvement of Resistive Switching Characteristic in Silicon Oxide-Based RRAM Through Hydride- Oxidation on Indium Tin Oxide Electrode by Supercritical CO2 Fluid,"Supercritical carbon dioxide (SCCO2) fluid technology was applied to indium-tin-oxide (ITO) electrode to improve the resistive switching characteristic of silicon oxide RRAM through hydride oxidation for the first time. We found device power consumption can be effectively reduced so that side effects can be also restricted under device operation. By applying SCCO2 fluid, more oxygen ions will be introduced into the ITO electrode and thus the participation of net oxygen ions in the RRAM redox reaction will increase. Fourier transform spectroscopy and X-ray photoelectron spectroscopy were used to confirm hydride oxidation on ITO electrode. Combined with the current fitting results, we proposed a reaction model to explain the improvement of resistive switching in RRAM by SCCO2 fluids.","Indium tin oxide,
Electrodes,
Switches,
Silicon,
Films,
Ions,
Fluids"
RF energy harvesting two-way cognitive DF relaying with transceiver impairments,"This paper analyzes the impact of transceiver impairments on outage probability (OP) and throughput of decode-and-forward two-way cognitive relay (TWCR) networks, where the relay is self-powered by harvesting energy from the transmitted signals. We consider two bidirectional relaying protocols namely, multiple access broadcast (MABC) protocol and time division broadcast (TDBC) protocol, as well as, two power transfer policies namely, dual-source (DS) energy transfer and single-fixed-source (SFS) energy transfer. Closed-form expressions for OP and throughput of the network are derived in the context of delay-limited transmission. Numerical results corroborate our analysis, thereby we can quantify the degradation of OP and throughput of TWCR networks due to transceiver hardware impairments. Under the specific parameters, our results indicate that the MABC protocol achieves asymptotically a higher throughput by 0.65 [bits/s/Hz] than the TDBC protocol, while the DS energy transfer scheme offers better performance than the SFS policy for both relaying protocols.","Protocols,
IP networks,
Relays,
Throughput,
Transceivers,
Energy exchange,
Hardware"
Efficient Location Identification of Multiple Line Outages With Limited PMUs in Smart Grids,"The efficient location identification of multiple line outages is critical to not only cascading failure elimination but also repair cost reduction. Most of existing methods, however, fail to handle location identification well. This failure typically occurs because the methods cannot overcome two challenges: the very limited number of phasor measurement units (PMUs) and the high computational complexity. This paper presents an efficient algorithm inspired by the ambiguity group theory to identify the locations of line outages with limited PMUs. Using 14-, 57-, 118-, 300-, and 2383-bus systems, our experimental study demonstrates that the proposed technique successfully identifies the most likely multiple line outages while attaining a 500 × speedup when compared to the method of exhaustive search.","Phasor measurement units,
Transmission line matrix methods,
Vectors,
Smart grids,
Equations,
Matrix decomposition,
Transmission line measurements"
Model-Free Primitive-Based Iterative Learning Control Approach to Trajectory Tracking of MIMO Systems With Experimental Validation,"This paper proposes a novel model-free trajectory tracking of multiple-input multiple-output (MIMO) systems by the combination of iterative learning control (ILC) and primitives. The optimal trajectory tracking solution is obtained in terms of previously learned solutions to simple tasks called primitives. The library of primitives that are stored in memory consists of pairs of reference input/controlled output signals. The reference input primitives are optimized in a model-free ILC framework without using knowledge of the controlled process. The guaranteed convergence of the learning scheme is built upon a model-free virtual reference feedback tuning design of the feedback decoupling controller. Each new complex trajectory to be tracked is decomposed into the output primitives regarded as basis functions. The optimal reference input for the control system to track the desired trajectory is next recomposed from the reference input primitives. This is advantageous because the optimal reference input is computed straightforward without the need to learn from repeated executions of the tracking task. In addition, the optimization problem specific to trajectory tracking of square MIMO systems is decomposed in a set of optimization problems assigned to each separate single-input single-output control channel that ensures a convenient model-free decoupling. The new model-free primitive-based ILC approach is capable of planning, reasoning, and learning. A case study dealing with the model-free control tuning for a nonlinear aerodynamic system is included to validate the new approach. The experimental results are given.",
An intrusion detection system against malicious attacks on the communication network of driverless cars,"Vehicular ad hoc networking (VANET) have become a significant technology in the current years because of the emerging generation of self-driving cars such as Google driverless cars. VANET have more vulnerabilities compared to other networks such as wired networks, because these networks are an autonomous collection of mobile vehicles and there is no fixed security infrastructure, no high dynamic topology and the open wireless medium makes them more vulnerable to attacks. It is important to design new approaches and mechanisms to rise the security these networks and protect them from attacks. In this paper, we design an intrusion detection mechanism for the VANETs using Artificial Neural Networks (ANNs) to detect Denial of Service (DoS) attacks. The main role of IDS is to detect the attack using a data generated from the network behavior such as a trace file. The IDSs use the features extracted from the trace file as auditable data. In this paper, we propose anomaly and misuse detection to detect the malicious attack.","Vehicles,
Security,
Artificial neural networks,
Feature extraction,
Training,
Accuracy,
Ad hoc networks"
"LabPET II, an APD-based Detector Module with PET and Counting CT Imaging Capabilities","Computed tomography (CT) is currently the standard modality to provide anatomical reference for positron emission tomography (PET) in molecular imaging applications. Since both PET and CT rely on detecting radiation to generate images, using the same detection system for data acquisition is a compelling idea even though merging PET and CT hardware imposes stringent requirements on detectors. These requirements include large signal dynamic range with high signal-to-noise ratio for good energy resolution in PET and energy-resolved photon-counting CT, high pixelization for suitable spatial resolution in CT, and high count rate capability for reasonable CT acquisition time. To meet these criteria, the avalanche photodiode (APD)-based LabPET II module is proposed as the building block for a truly combined PET/CT scanner. The module is made of two monolithic 4×8 APD pixel arrays mounted side-by-side on a custom ceramic holder. Individual APD pixels have an active area of 1.1×1.1 mm2 at a 1.2 mm pitch. The APD arrays are coupled to a 12-mm high, 8 ×8 LYSO scintillator array made of 1.12 ×1.12 mm2 pixels also at a pitch of 1.2 mm to ensure direct one-to-one coupling to individual APD pixels. The scintillator array was designed with unbound specular reflective material between pixels to maximize the difference between refractive indices and enhance total internal reflection at the crystal side surfaces for better light collection, and the APD quantum efficiency was improved to ~ 60% at 420 nm to optimize intrinsic detector performance. Mean energy resolution was 20 ±1% at 511 keV and 41±4% at 60 keV. The measured intrinsic spatial and time resolution for PET were respectively 0.81 ±0.04 mm FWHM/1.57 ±0.04 mm FWTM and 3.6±0.3 ns FWHM with an energy threshold of 400 keV. Initial phantom images obtained using a CT test bench demonstrated excellent contrast linearity as a function of material density. With a magnification factor of 2, a CT spatial resolution of 0.66 mm FWHM/1.2 mm FWTM, corresponding to 1.18 lp/mm at MTF10%/0.67 lp/mm at MTF50%, was measured, allowing 0.75 mm air holes in an Ultra-Micro Hot Spot resolution phantom to be clearly distinguished.","Computed tomography,
Positron emission tomography,
Detectors,
Energy resolution,
Spatial resolution,
Crystals"
Support vector machines and Word2vec for text classification with semantic features,"With the rapid expansion of new available information presented to us online on a daily basis, text classification becomes imperative in order to classify and maintain it. Word2vec offers a unique perspective to the text mining community. By converting words and phrases into a vector representation, word2vec takes an entirely new approach on text classification. Based on the assumption that word2vec brings extra semantic features that helps in text classification, our work demonstrates the effectiveness of word2vec by showing that tf-idf and word2vec combined can outperform tf-idf because word2vec provides complementary features (e.g. semantics that tf-idf can't capture) to tf-idf. Our results show that the combination of word2vec weighted by tf-idf and tf-idf does not outperform tf-idf consistently. It is consistent enough to say the combination of the two can outperform either individually.","Probabilistic logic,
Semantics"
Analysis of symbol-design strategies for intrapulse radar-embedded communications,"The design of communication symbols that may be embedded on an intrapulse basis into the backscatter generated by a high-power, pulsed radar is considered. This framework requires the asynchronous detection of transmitted symbols in a high-interference environment that degrades the capabilities of conventional intercept receivers. The impact of symbol design and filter structure upon the successful detection of covert symbols by the intended receiver and a hypothetical partially clairvoyant intercept receiver is examined.",
Exploiting Rateless Codes in Cloud Storage Systems,"Block-level cloud storage (BLCS) offers to users and applications the access to persistent block storage devices (virtual disks) that can be directly accessed and used as if they were raw physical disks. In this paper we devise ENIGMA, an architecture for the back-end of BLCS systems able to provide adequate levels of access and transfer performance, availability, integrity, and confidentiality, for the data it stores. ENIGMA exploits LT rateless codes to store fragments of sectors on storage nodes organized in clusters. We quantitatively evaluate how the various ENIGMA system parameters affect the performance, availability, integrity, and confidentiality of virtual disks. These evaluations are carried out by using both analytical modeling (for availability, integrity, and confidentiality) and discrete event simulation (for performance), and by considering a set of realistic operational scenarios. Our results indicate that it is possible to simultaneously achieve all the objectives set forth for BLCS systems by using ENIGMA, and that a careful choice of the various system parameters is crucial to achieve a good compromise among them. Moreover, they also show that LT coding-based BLCS systems outperform traditional BLCS systems in all the aspects mentioned before.","Decoding,
Encoding,
Availability,
Cloud computing,
Analytical models,
Computer architecture,
Protocols"
"A Novel Slow-Wave Structure for High-Power
K
a
-Band Backward Wave Oscillators With Mode Control","We present a novel slow-wave structure (SWS) to significantly enhance the performance of high-power backward wave oscillators (BWOs). The design features a periodic metallic ring insertion and a deeply corrugated cylindrical waveguide. Both serving to improve interaction impedance and flexibility in dispersion curve engineering. A new technique for mode control in waveguides is also introduced. In addition to demonstrating mode control in SWSs, the key aspects of the presented design are mode dominance reversal and a 100% improvement in interaction impedance that can be exploited to achieve greater power conversion efficiency and output mode purity. Performance comparisons on group velocity, phase velocity and interaction impedance of the new SWS versus the conventional corrugated waveguide are provided. We extend the concept of inhomogeneous SWSs by designing a three-section inhomogeneous SWS. Further simulations using a Particle in Cell code of a highly efficient three-section inhomogeneous Ka-band BWO generates a peak output power of a 5.92 MW at 27 GHz with a 58% peak efficiency.","Impedance,
Dispersion,
Cavity resonators,
Nonhomogeneous media,
Cutoff frequency,
Passband"
Sparse Dissimilarity-Constrained Coding for Glaucoma Screening,"Objective: Glaucoma is an irreversible chronic eye disease that leads to vision loss. As it can be slowed down through treatment, detecting the disease in time is important. However, many patients are unaware of the disease because it progresses slowly without easily noticeable symptoms. Currently, there is no effective method for low-cost population-based glaucoma detection or screening. Recent studies have shown that automated optic nerve head assessment from 2-D retinal fundus images is promising for low-cost glaucoma screening. In this paper, we propose a method for cup to disc ratio (CDR) assessment using 2-D retinal fundus images. Methods: In the proposed method, the optic disc is first segmented and reconstructed using a novel sparse dissimilarity-constrained coding (SDC) approach which considers both the dissimilarity constraint and the sparsity constraint from a set of reference discs with known CDRs. Subsequently, the reconstruction coefficients from the SDC are used to compute the CDR for the testing disc. Results: The proposed method has been tested for CDR assessment in a database of 650 images with CDRs manually measured by trained professionals previously. Experimental results show an average CDR error of 0.064 and correlation coefficient of 0.67 compared with the manual CDRs, better than the state-of-the-art methods. Our proposed method has also been tested for glaucoma screening. The method achieves areas under curve of 0.83 and 0.88 on datasets of 650 and 1676 images, respectively, outperforming other methods. Conclusion: The proposed method achieves good accuracy for glaucoma detection. Significance: The method has a great potential to be used for large-scale population-based glaucoma screening.","Image reconstruction,
Optical imaging,
Image segmentation,
Blood vessels,
Adaptive optics,
Biomedical optical imaging"
Impact of Wind-Based Distributed Generation on Electric Energy in Distribution Systems Embedded With Electric Vehicles,"In this paper, the synergy between wind-based distributed generation (DG) and plug-in electric vehicles (PEVs) is studied. MonteCarlo is used to address the uncertainties associated with wind speed variations and charging of PEVs hence simulating their impact at the distribution system (DS) level considering different DG penetration (up to 35%) and different PEV penetration (up to 50%). The excess in active/reactive power, energy exceeding normal (EEN), unserved energy (UE), and energy losses are investigated in this study. Forty-eight penetration scenarios involving DGs and PEVs are studied in this work and simulated in the IEEE 123-bus radial power distribution test system after modeling its secondary circuit in OpenDSS. The results of the simulation show that 30% wind-based DG penetration may be adequate to supply the active energy needed to charge PEVs. However, this might result in a reverse reactive power flow back to the substation.","Wind speed,
Indexes,
Batteries,
Reactive power,
Clustering algorithms,
Electric vehicles"
Hand-Dorsa Vein Recognition by Matching Local Features of Multisource Keypoints,"As an emerging biometric for people identification, the dorsal hand vein has received increasing attention in recent years due to the properties of being universal, unique, permanent, and contactless, and especially its simplicity of liveness detection and difficulty of forging. However, the dorsal hand vein is usually captured by near-infrared (NIR) sensors and the resulting image is of low contrast and shows a very sparse subcutaneous vascular network. Therefore, it does not offer sufficient distinctiveness in recognition particularly in the presence of large population. This paper proposes a novel approach to hand-dorsa vein recognition through matching local features of multiple sources. In contrast to current studies only concentrating on the hand vein network, we also make use of person dependent optical characteristics of the skin and subcutaneous tissue revealed by NIR hand-dorsa images and encode geometrical attributes of their landscapes, e.g., ridges, valleys, etc., through different quantities, such as cornerness and blobness, closely related to differential geometry. Specifically, the proposed method adopts an effective keypoint detection strategy to localize features on dorsal hand images, where the speciality of absorption and scattering of the entire dorsal hand is modeled as a combination of multiple (first-, second-, and third-) order gradients. These features comprehensively describe the discriminative clues of each dorsal hand. This method further robustly associates the corresponding keypoints between gallery and probe samples, and finally predicts the identity. Evaluated by extensive experiments, the proposed method achieves the best performance so far known on the North China University of Technology (NCUT) Part A dataset, showing its effectiveness. Additional results on NCUT Part B illustrate its generalization ability and robustness to low quality data.","Veins,
Optical imaging,
Detectors,
Biomedical optical imaging,
Feature extraction,
Optical scattering,
Skin"
Segmentation of Overlapping Elliptical Objects in Silhouette Images,"Segmentation of partially overlapping objects with a known shape is needed in an increasing amount of various machine vision applications. This paper presents a method for segmentation of clustered partially overlapping objects with a shape that can be approximated using an ellipse. The method utilizes silhouette images, which means that it requires only that the foreground (objects) and background can be distinguished from each other. The method starts with seedpoint extraction using bounded erosion and fast radial symmetry transform. Extracted seedpoints are then utilized to associate edge points to objects in order to create contour evidence. Finally, contours of the objects are estimated by fitting ellipses to the contour evidence. The experiments on one synthetic and two different real data sets showed that the proposed method outperforms two current state-of-art approaches in overlapping objects segmentation.","Image edge detection,
Object segmentation,
Image segmentation,
Shape,
Transforms,
Estimation"
Sparse composite quantization,"The quantization techniques have shown competitive performance in approximate nearest neighbor search. The state-of-the-art algorithm, composite quantization, takes advantage of the compositionabity, i.e., the vector approximation accuracy, as opposed to product quantization and Cartesian k-means. However, we have observed that the runtime cost of computing the distance table in composite quantization, which is used as a lookup table for fast distance computation, becomes nonnegligible in real applications, e.g., reordering the candidates retrieved from the inverted index when handling very large scale databases. To address this problem, we develop a novel approach, called sparse composite quantization, which constructs sparse dictionaries. The benefit is that the distance evaluation between the query and the dictionary element (a sparse vector) is accelerated using the efficient sparse vector operation, and thus the cost of distance table computation is reduced a lot. Experiment results on large scale ANN retrieval tasks (1M SIFTs and 1B SIFTs) and applications to object retrieval show that the proposed approach yields competitive performance: superior search accuracy to product quantization and Cartesian k-means with almost the same computing cost, and much faster ANN search than composite quantization with the same level of accuracy.","Quantization (signal),
Approximation methods,
Databases,
Dictionaries,
Accuracy,
Acceleration,
Artificial neural networks"
Impact of Variation in Nanoscale Silicon and Non-Silicon FinFETs and Tunnel FETs on Device and SRAM Performance,"One of the key challenges in scaling beyond 10-nm technology node is device-to-device variation. Variation in device performance, mainly threshold voltage, VT, inhibits VCC scaling. In this paper, we present a comprehensive study of process variations and sidewall roughness (SWR) effects in silicon (Si) bulk n-/p-FinFETs, In0.53Ga0.47As bulk n-FinFETs, germanium (Ge) bulk p-FinFETs, and gallium antimonide-indium arsenide (GaSb-InAs) staggered-gap heterojunction n-/p-tunnel FETs (HTFETs) using 3-D Technology Computer Aided Design numerical simulations. According to the sensitivity study, FinFET and tunnel FET (TFET) device parameters are highly susceptible to fin width, WFIN, and ultrathin body thickness, Tb, variations, respectively. TFETs show higher variation in device performance than FinFETs. A Monte Carlo study of SWR variation on nand p-FinFETs shows higher 3σ(VT Lin) of In0.53Ga0.47As bulk nand Ge bulk p-FinFETs than their Si counterparts. Furthermore, to study the variation impact on memory circuits, we simulate 6T and 10T static random access memory (SRAM) cells with FinFETs and HTFETs, respectively. The probability distribution of read failure in SRAM cells at different supply voltages, VCC, shows that HTFETs require 10T SRAM cell architecture and less than 4% variation in Tb for their VCCmin to approach 200 mV.","FinFETs,
Silicon,
Performance evaluation,
SRAM cells,
Logic gates"
Adaptive Fuzzy Consensus Clustering Framework for Clustering Analysis of Cancer Data,"Performing clustering analysis is one of the important research topics in cancer discovery using gene expression profiles, which is crucial in facilitating the successful diagnosis and treatment of cancer. While there are quite a number of research works which perform tumor clustering, few of them considers how to incorporate fuzzy theory together with an optimization process into a consensus clustering framework to improve the performance of clustering analysis. In this paper, we first propose a random double clustering based cluster ensemble framework (RDCCE) to perform tumor clustering based on gene expression data. Specifically, RDCCE generates a set of representative features using a randomly selected clustering algorithm in the ensemble, and then assigns samples to their corresponding clusters based on the grouping results. In addition, we also introduce the random double clustering based fuzzy cluster ensemble framework (RDCFCE), which is designed to improve the performance of RDCCE by integrating the newly proposed fuzzy extension model into the ensemble framework. RDCFCE adopts the normalized cut algorithm as the consensus function to summarize the fuzzy matrices generated by the fuzzy extension models, partition the consensus matrix, and obtain the final result. Finally, adaptive RDCFCE (A-RDCFCE) is proposed to optimize RDCFCE and improve the performance of RDCFCE further by adopting a self-evolutionary process (SEPP) for the parameter set. Experiments on real cancer gene expression profiles indicate that RDCFCE and A-RDCFCE works well on these data sets, and outperform most of the state-of-the-art tumor clustering algorithms.","Clustering algorithms,
Cancer,
Algorithm design and analysis,
Bioinformatics,
Computational biology"
PRGA: Privacy-Preserving Recording & Gateway-Assisted Authentication of Power Usage Information for Smart Grid,"Smart grid network facilitates reliable and efficient power generation and transmission. The power system can adjust the amount of electricity generated based on power usage information submitted by end users. Sender authentication and user privacy preservation are two important security issues on this information flow. In this paper, we propose a scheme such that even the control center (power operator) does not know which user makes the requests of using more power or agreements of using less power until the power is actually used. At the end of each billing period (i.e., after electricity usage), the end user can prove to the power operator that it has really requested to use more power or agreed to use less power earlier. To reduce the total traffic volume in the communications network, our scheme allows gateway smart meters to help aggregate power usage information, and the power generators to determine the total amount of power that needs to be generated at different times. To reduce the impact of attacking traffic, our scheme allows gateway smart meters to help filter messages before they reach the control center. Through analysis and experiments, we show that our scheme is both effective and efficient.","Logic gates,
Smart grids,
Electricity supply industry,
Encryption,
Substations,
Power generation,
Power transmission"
Quantitative Evaluation of a Low-Cost Noninvasive Hybrid Interface Based on EEG and Eye Movement,"This paper describes a low-cost noninvasive brain-computer interface (BCI) hybridized with eye tracking. It also discusses its feasibility through a Fitts' law-based quantitative evaluation method. Noninvasive BCI has recently received a lot of attention. To bring the BCI applications into real life, user-friendly and easily portable devices need to be provided. In this work, as an approach to realize a real-world BCI, electroencephalograph (EEG)-based BCI combined with eye tracking is investigated. The two interfaces can be complementary to attain improved performance. Especially to consider public availability, a low-cost interface device is intentionally used for test. A low-cost commercial EEG recording device is integrated with an inexpensive custom-built eye tracker. The developed hybrid interface is evaluated through target pointing and selection experiments. Eye movement is interpreted as cursor movement and noninvasive BCI selects a cursor point with two selection confirmation schemes. Using Fitts' law, the proposed interface scheme is compared with other interface schemes such as mouse, eye tracking with dwell time, and eye tracking with keyboard. In addition, the proposed hybrid BCI system is discussed with respect to a practical interface scheme. Although further advancement is required, the proposed hybrid BCI system has the potential to be practically useful in a natural and intuitive manner.","Electroencephalography,
Protocols,
Target tracking,
Mice,
Human computer interaction,
Feature extraction"
Spread Spectrum-Based High Embedding Capacity Watermarking Method for Audio Signals,"Audio watermarking is a promising technology for copyright protection of audio data. Built upon the concept of spread spectrum (SS), many SS-based audio watermarking methods have been developed, where a pseudonoise (PN) sequence is usually used to introduce security. A major drawback of the existing SS-based audio watermarking methods is their low embedding capacity. In this paper, we propose a new SS-based audio watermarking method which possesses much higher embedding capacity while ensuring satisfactory imperceptibility and robustness. The high embedding capacity is achieved through a set of mechanisms: embedding multiple watermark bits in one audio segment, reducing host signal interference on watermark extraction, and adaptively adjusting PN sequence amplitude in watermark embedding based on the property of audio segments. The effectiveness of the proposed audio watermarking method is demonstrated by simulation examples.","Watermarking,
Audio watermarking,
Interference,
Discrete cosine transforms,
Speech processing,
Copyright protection,
Spread spectrum management"
Maximum Likelihood Passive and Active Sensing of Wideband Power Spectra From Few Bits,"Wideband power spectrum sensing is essential for cognitive radio and many other applications. Aiming to crowdsource spectrum sensing operations, a novel frugal sensing framework was recently proposed, employing a network of low duty-cycle sensors (e.g., running in background mode on consumer devices) reporting randomly filtered broadband power measurement bits to a fusion center, which in turn estimates the ambient power spectrum. Frugal sensing is revisited here from a statistical estimation point of view. Taking into account fading and insufficient sample averaging considerations, maximum likelihood (ML) formulations are developed which outperform the original minimum power and interior point solutions when the soft power estimates prior to thresholding are noisy. Assuming availability of a downlink channel that the fusion center can use to send threshold information, active sensing strategies are developed that quickly narrow down and track the power spectrum estimate, using ideas borrowed from cutting plane methods to develop active ML solutions. Simulations show that satisfactory wideband power spectrum estimates can be obtained with passive ML sensing from few bits, and much better performance can be attained using active sensing. Various other aspects, such as known emitter spectral shapes and different types of non-negativity constraints, are also considered.","Sensors,
Correlation,
Fading,
Maximum likelihood estimation,
Power measurement,
Gaussian distribution"
Sensitivity of the Distorted Born Iterative Method to the Initial Guess in Microwave Breast Imaging,"The distorted Born iterative method (DBIM) has been explored recently for microwave breast imaging. DBIM is an iterative method; thus, it requires an initial guess of the dielectric properties of the breast. In this paper, we study the sensitivity of DBIM imaging accuracy and convergence speed to the properties of a homogeneous initial guess. We conduct this investigation for a multifrequency formulation of DBIM, wherein the dispersive breast tissue properties are described with a Debye model. The parameters of the Debye model for the initial guess are linearly linked to reflect typical breast tissue dielectric properties. The static permittivity characterizing the properties is swept over an appropriate range of initial guesses and DBIM is used to obtain imaging results for each guess. Image quality and the number of iterations required for convergence is evaluated using three-dimensional (3-D) anatomically realistic numerical breast phantoms. This investigation not only vividly illustrates the sensitivity of DBIM to the initial guess but also definitively demonstrates that the use of initial values close to the average properties of the breast yields near-optimal performance. Finally, we present and evaluate a practical algorithm for estimating the average properties to be used as the initial guess.","Breast,
Phantoms,
Dielectrics,
Image reconstruction,
Antenna measurements,
Arrays"
Efficiency-Risk Tradeoffs in Electricity Markets with Dynamic Demand Response,"In order to study the impact of dynamic demand response in the future smart grid, we examine in an abstract framework how a tradeoff between efficiency and risk arises under different market architectures. We first examine the system performance under noncooperative and cooperative market architectures. The statistics of the stationary aggregate demand processes show that, although the noncooperative load scheduling scheme leads to an efficiency loss, the stationary distribution of the corresponding aggregate demand process has a smaller tail, resulting in less frequent aggregate demand spikes. Cooperative dynamic demand response, on the other hand, makes the market place more efficient at the cost of increased risk of aggregate demand spikes. The market architecture determines the locus of the system performance with respect to the tradeoff curve. We also investigate how a properly designed real-time electricity pricing mechanism can help the system operator achieve a target tradeoff between efficiency and risk in a noncooperative market. We further provide a convex characterization of the Pareto front of system performance measures, which serves as a benchmark of the tradeoffs for the system operator to evaluate the pricing rules.","Aggregates,
Electricity,
Load modeling,
Pricing,
Electricity supply industry,
Load management,
Real-time systems"
Matrix Variate Distribution-Induced Sparse Representation for Robust Image Classification,"Sparse representation learning has been successfully applied into image classification, which represents a given image as a linear combination of an over-complete dictionary. The classification result depends on the reconstruction residuals. Normally, the images are stretched into vectors for convenience, and the representation residuals are characterized by I2-norm, which actually assumes that the elements in the residuals are independent and identically distributed variables. However, it is hard to satisfy the hypothesis when it comes to some structural errors, such as illuminations, occlusions, and so on. In this paper, we represent the image data in their intrinsic matrix form rather than concatenated vectors. The representation residual is considered as a matrix variate following the matrix elliptically contoured distribution, which is robust to dependent errors and has long tail regions to fit outliers. Then, we seek the maximum a posteriori probability estimation solution of the matrix-based optimization problem under sparse regularization. An alternating direction method of multipliers (ADMMs) is derived to solve the resulted optimization problem. The convergence of the ADMM is proven theoretically. Experimental results demonstrate that the proposed method is more effective than the state-of-the-art methods when dealing with the structural errors.","Sparse matrices,
Dictionaries,
Robustness,
Convergence,
Vectors,
Image representation,
Optimization"
Two-Dimensional Route Switching in Cognitive Radio Networks: A Game-Theoretical Framework,"In cognitive radio networks (CRNs), secondary users (SUs) can flexibly access primary users' (PUs') idle spectrum bands, but such spectrum opportunities are dynamic due to PUs' uncertain activity patterns. In a multihop CRN consisting of SUs as relays, such spectrum dynamics will further cause the invalidity of predetermined routes. In this paper, we investigate spectrum-mobility-incurred route-switching problems in both spatial and frequency domains for CRNs, where spatial switching determines which relays and links should be reselected and frequency switching decides which channels ought to be reassigned to the spatial routes. The proposed route-switching scheme not only avoids conflicts with PUs but also mitigates spectrum congestion. Meanwhile, tradeoffs between routing costs and channel switching costs are achieved. We further formulate the route-switching problem as the Route-Switching Game, which is shown to be a potential game and has a pure Nash equilibrium (NE). Accordingly, efficient algorithms for finding the NE and the ε-NE are proposed. Then, we extend the proposed game to the incomplete-information scenario and provide a method to compute the Bayesian NE. Finally, we prove that the price of anarchy of the proposed game has a deterministic upper bound.",
Control barrier function based quadratic programs with application to bipedal robotic walking,"This paper presents a methodology for the development of control barrier functions (CBFs) through a backstepping inspired approach. Given a set defined as the superlevel set of a function, h, the main result is a constructive means for generating control barrier functions that guarantee forward invariance of this set. In particular, if the function defining the set has relative degree n, an iterative methodology utilizing higher order derivatives of h provably results in a control barrier function that can be explicitly derived. To demonstrate these formal results, they are applied in the context of bipedal robotic walking. Physical constraints, e.g., joint limits, are represented by control barrier functions and unified with control objectives expressed through control Lyapunov functions (CLFs) via quadratic program (QP) based controllers. The end result is the generation of stable walking satisfying physical realizability constraints for a model of the bipedal robot AMBER2.","Legged locomotion,
Lyapunov methods,
Backstepping,
Context,
Mathematical model,
Foot"
Body Node Coordinator Placement Algorithms for Wireless Body Area Networks,"Wireless body area networks (WBANs) are intelligent wireless monitoring systems, consisting of wearable, and implantable computing devices on or in the human body. They are used to support a variety of personalized, advanced, and integrated applications in the field of medical, fitness, sports, military, and consumer electronics. In a WBAN, network longevity is a major challenge due to the limitation of the availability of energy supply in body nodes. Therefore, routing protocols can play a key role towards making such networks energy efficient. In this work, we exhibit that a routing protocol together with an effective body node coordinator (BNC) deployment strategy can influence the network lifetime eminently. Our initial work shows that the variation in the placement of a BNC within a WBAN could significantly vary the overall network lifetime. This motivated us to work on an effective node placement strategy for a BNC, within a WBAN; and thus we propose three different BNC placement algorithms considering different features of available energy efficient routing protocols in a WBAN. Our simulation results show that these algorithms along with an appropriate routing protocol can prolong the network lifetime by up to 47.45%.","Routing protocols,
Algorithm design and analysis,
Wireless sensor networks,
Energy efficiency,
Wireless communication,
Body area networks,
Internet of Things"
Discovery of Path Nearby Clusters in Spatial Networks,"The discovery of regions of interest in large cities is an important challenge. We propose and investigate a novel query called the path nearby cluster (PNC) query that finds regions of potential interest (e.g., sightseeing places and commercial districts) with respect to a user-specified travel route. Given a set of spatial objects O (e.g., POIs, geo-tagged photos, or geo-tagged tweets) and a query route q, if a cluster c has high spatial-object density and is spatially close to q, it is returned by the query (a cluster is a circular region defined by a center and a radius). This query aims to bring important benefits to users in popular applications such as trip planning and location recommendation. Efficient computation of the PNC query faces two challenges: how to prune the search space during query processing, and how to identify clusters with high density effectively. To address these challenges, a novel collective search algorithm is developed. Conceptually, the search process is conducted in the spatial and density domains concurrently. In the spatial domain, network expansion is adopted, and a set of vertices are selected from the query route as expansion centers. In the density domain, clusters are sorted according to their density distributions and they are scanned from the maximum to the minimum. A pair of upper and lower bounds are defined to prune the search space in the two domains globally. The performance of the PNC query is studied in extensive experiments based on real and synthetic spatial data.","Equations,
Query processing,
Clustering algorithms,
Roads,
Educational institutions,
Upper bound,
Planning"
Cognition-Based Networks: A New Perspective on Network Optimization Using Learning and Distributed Intelligence,"In response to the new challenges in the design and operation of communication networks, and taking inspiration from how living beings deal with complexity and scalability, in this paper we introduce an innovative system concept called COgnition-BAsed NETworkS (COBANETS). The proposed approach develops around the systematic application of advanced machine learning techniques and, in particular, unsupervised deep learning and probabilistic generative models for system-wide learning, modeling, optimization, and data representation. Moreover, in COBANETS, we propose to combine this learning architecture with the emerging network virtualization paradigms, which make it possible to actuate automatic optimization and reconfiguration strategies at the system level, thus fully unleashing the potential of the learning approach. Compared with the past and current research efforts in this area, the technical approach outlined in this paper is deeply interdisciplinary and more comprehensive, calling for the synergic combination of expertise of computer scientists, communications and networking engineers, and cognitive scientists, with the ultimate aim of breaking new ground through a profound rethinking of how the modern understanding of cognition can be used in the management and optimization of telecommunication networks.","Communication networks,
Cognitive networks,
Hierarchical networks,
Optimization,
Deep learning"
Bag-of-Frequencies: A Descriptor of Pulmonary Nodules in Computed Tomography Images,"We present a novel descriptor for the characterization of pulmonary nodules in computed tomography (CT) images. The descriptor encodes information on nodule morphology and has scale-invariant and rotation-invariant properties. Information on nodule morphology is captured by sampling intensity profiles along circular patterns on spherical surfaces centered on the nodule, in a multi-scale fashion. Each intensity profile is interpreted as a periodic signal, where the Fourier transform is applied, obtaining a spectrum. A library of spectra is created and labeled via unsupervised clustering, obtaining a Bag-of-Frequencies, which is used to assign each spectra a label. The descriptor is obtained as the histogram of labels along all the spheres. Additional contributions are a technique to estimate the nodule size, based on the sampling strategy, as well as a technique to choose the most informative plane to cut a 2-D view of the nodule in the 3-D image. We evaluate the descriptor on several nodule morphology classification problems, namely discrimination of nodules versus vascular structures and characterization of spiculation. We validate the descriptor on data from European screening trials NELSON and DLCST and we compare it with state-of-the-art approaches for 3-D shape description in medical imaging and computer vision, namely SPHARM and 3-D SIFT, outperforming them in all the considered experiments.","Morphology,
Computed tomography,
Lungs,
Biomedical imaging,
Cancer,
Design automation,
Radiology"
GALE: Geometric Active Learning for Search-Based Software Engineering,"Multi-objective evolutionary algorithms (MOEAs) help software engineers find novel solutions to complex problems. When automatic tools explore too many options, they are slow to use and hard to comprehend. GALE is a near-linear time MOEA that builds a piecewise approximation to the surface of best solutions along the Pareto frontier. For each piece, GALE mutates solutions towards the better end. In numerous case studies, GALE finds comparable solutions to standard methods (NSGA-II, SPEA2) using far fewer evaluations (e.g. 20 evaluations, not 1,000). GALE is recommended when a model is expensive to evaluate, or when some audience needs to browse and understand how an MOEA has made its conclusions.","Optimization,
Software,
Computational modeling,
Approximation methods,
Standards,
Biological system modeling,
Sociology"
Scientific benchmarking of parallel computing systems: twelve ways to tell the masses when reporting performance results,"Measuring and reporting performance of parallel computers constitutes the basis for scientific advancement of high-performance computing (HPC). Most scientific reports show performance improvements of new techniques and are thus obliged to ensure reproducibility or at least interpretability. Our investigation of a stratified sample of 120 papers across three top conferences in the field shows that the state of the practice is lacking. For example, it is often unclear if reported improvements are deterministic or observed by chance. In addition to distilling best practices from existing work, we propose statistically sound analysis and reporting techniques and simple guidelines for experimental design in parallel computing and codify them in a portable benchmarking library. We aim to improve the standards of reporting research results and initiate a discussion in the HPC field. A wide adoption of our minimal set of rules will lead to better interpretability of performance results and improve the scientific culture in HPC.","Software,
Benchmark testing,
Parallel processing,
Time measurement,
Computer science,
Guidelines,
Standards"
Lattices Over Eisenstein Integers for Compute-and-Forward,"In this paper, we consider the use of lattice codes over Eisenstein integers for implementing a compute and-forward protocol in wireless networks when channel state information is not available at the transmitter. We extend the compute-and-forward paradigm of Nazer and Gastpar to decoding Eisenstein integer combinations of transmitted messages at relays by proving the existence of a sequence of pairs of nested lattices over Eisenstein integers in which the coarse lattice is good for covering and the fine lattice can achieve the Poltyrev limit. Using this result, we show that both the outage performance and error-correcting performance of the nested lattice codebooks over Eisenstein integers surpass those of lattice codebooks over integers considered by Nazer and Gastpar with no additional computational complexity.",
Collocated Z-Axis Control of a High-Speed Nanopositioner for Video-Rate Atomic Force Microscopy,"A key hurdle to achieve video-rate atomic force microscopy (AFM) in constant-force contact mode is the inadequate bandwidth of the vertical feedback control loop. This paper describes techniques used to increase the vertical tracking bandwidth of a nanopositioner to a level that is sufficient for video-rate AFM. These techniques involve the combination of: a high-speed XYZ nanopositioner; a passive damping technique that cancels the inertial forces of the Z actuator which in turns eliminates the low 20-kHz vertical resonant mode of the nanopositioner; an active control technique that is used to augment damping to high vertical resonant modes at 60 kHz and above. The implementation of these techniques allows a tenfold increase in the vertical tracking bandwidth, from 2.3 (without damping) to 28.1 kHz. This allows high-quality, video-rate AFM images to be captured at 10 frames/s without noticeable artifacts associated with vibrations and insufficient vertical tracking bandwidth.","Nanopositioning,
Damping,
Actuators,
Gain,
Bandwidth,
Resonant frequency,
Vibrations"
Graph Ensemble Boosting for Imbalanced Noisy Graph Stream Classification,"Many applications involve stream data with structural dependency, graph representations, and continuously increasing volumes. For these applications, it is very common that their class distributions are imbalanced with minority (or positive) samples being only a small portion of the population, which imposes significant challenges for learning models to accurately identify minority samples. This problem is further complicated with the presence of noise, because they are similar to minority samples and any treatment for the class imbalance may falsely focus on the noise and result in deterioration of accuracy. In this paper, we propose a classification model to tackle imbalanced graph streams with noise. Our method, graph ensemble boosting, employs an ensemble-based framework to partition graph stream into chunks each containing a number of noisy graphs with imbalanced class distributions. For each individual chunk, we propose a boosting algorithm to combine discriminative subgraph pattern selection and model learning as a unified framework for graph classification. To tackle concept drifting in graph streams, an instance level weighting mechanism is used to dynamically adjust the instance weight, through which the boosting framework can emphasize on difficult graph samples. The classifiers built from different graph chunks form an ensemble for graph stream classification. Experiments on real-life imbalanced graph streams demonstrate clear benefits of our boosting design for handling imbalanced noisy graph stream.","Boosting,
Noise measurement,
Noise,
Vectors,
Linear programming,
Support vector machines,
Accuracy"
Surface fluorinated epoxy resin for high voltage DC application,"Charge accumulation under high voltage DC is a major concern in the transmission system as its presence distorts the local electric field. By performing chemical treatment on polymeric insulation via fluorination process, the charge transport characteristics of the material can be modified. In doing so, excellent surface properties of fluoropolymers can be attained without compromising the bulk properties of the original polymeric insulation. The change in chemical components at the surface of polymeric insulation should lead to a corresponding change in electrical properties at the surface and so suppress charge accumulation. In this paper, epoxy resin samples were formulated and treated with various surface fluorinating conditions. The samples then were characterised by scanning electron microscope (SEM), Raman spectroscopy and DC surface conductivity measurements. The surface potential decay measurement was performed and the result shows that there is a significant change in surface potential decay measurement with the introduction of surface fluorinated layer. The pulsed electroacoustic (PEA) measurement was used to further explain the decay mechanisms responsible for the observed phenomena. Surface DC flashover test using a pair of finger electrodes had also been conducted. It has been found that the introduction of fluorinated surface layer on epoxy resins plays an important role in improving the surface dielectric properties as apparent from the experimental results.","Surface treatment,
Epoxy resins,
Electric potential,
Surface charging,
Chemicals,
Dielectric measurement,
Electrodes"
"Text visualization techniques: Taxonomy, visual survey, and community insights","Text visualization has become a growing and increasingly important subfield of information visualization. Thus, it is getting harder for researchers to look for related work with specific tasks or visual metaphors in mind. In this paper, we present an interactive visual survey of text visualization techniques that can be used for the purposes of search for related work, introduction to the subfield and gaining insight into research trends. We describe the taxonomy used for categorization of text visualization techniques and compare it to approaches employed in several other surveys. Finally, we present results of analyses performed on the entries data.","Data visualization,
Visualization,
Taxonomy,
Browsers,
Market research,
Media"
TMC: Exploiting Trajectories for Multicast in Sparse Vehicular Networks,"Multicast is a crucial routine operation for vehicular networks, which underpins important functions such as message dissemination and group coordination. As vehicles may distribute over a vast area, the number of vehicles in a given region can be limited which results in sparse node distribution in part of the vehicular network. This poses several great challenges for efficient multicast, such as network disconnection, scarce communication opportunities and mobility uncertainty. Existing multicast schemes proposed for vehicular networks typically maintain a forwarding structure assuming the vehicles have a high density and move at low speed while these assumptions are often invalid in a practical vehicular network. As more and more vehicles are equipped with GPS enabled navigation systems, the trajectories of vehicles are becoming increasingly available. In this work, we propose an approach called TMC to exploit vehicle trajectories for efficient multicast in vehicular networks. The novelty of TMC includes a message forwarding metric that characterizes the capability of a vehicle to forward a given message to destination nodes, and a method of predicting the chance of inter-vehicle encounter between two vehicles based only on their trajectories without accurate timing information. TMC is designed to be a distributed approach. Vehicles make message forwarding decisions based on vehicle trajectories shared through inter-vehicle exchanges without the need of central information management. We have performed extensive simulations based on real vehicular GPS traces and compared our proposed TMC scheme with other existing approaches. The performance results demonstrate that our approach can achieve a delivery ratio close to that of the flooding-based approach while the cost is reduced by over 80 percent.","Vehicles,
Trajectory,
Relays,
Measurement,
Roads,
Global Positioning System,
Vectors"
Walking gait optimization for accommodation of unknown terrain height variations,"We investigate the design of periodic gaits that will also function well in the presence of modestly uneven terrain. We use parameter optimization and, inspired by recent work of Dai and Tedrake, augment a cost function with terms that account for perturbations arising from a finite set of terrain height changes. Trajectory and control deviations are related to a nominal periodic orbit via a mechanical phase variable, which is more natural than comparing solutions on the basis of time. The mechanical phase variable is also used to penalize more heavily deviations that persist “late” into the gait. The method is illustrated both in simulation and in experiments on a planar bipedal robot.","Legged locomotion,
Cost function,
Trajectory,
Orbits,
Foot"
Ensemble centralities based adaptive Artificial Bee algorithm,"An adaptive Artificial Bee Colony algorithm based on centralities is presented in this paper. As complex networks are generated in evolutionary algorithms during iterations, it becomes possible to obtain meaningful information regarding population dynamics during evaluations. The three centralities of Degree, Closeness and Betweenness are used for adaptive population control of the algorithm, where population interaction is measured and least performing solutions are replaced. Two adaptive variants of the algorithm are presented, one based on a single population and the other on an ensemble population approach. The experimentation is conducted on various standard test functions, showing that the adaptive approaches offer an improvement upon the canonical algorithm.","Sociology,
Statistics,
Complex networks,
Algorithm design and analysis,
Heuristic algorithms,
Standards,
Adaptive systems"
Bits and coins: Supporting collaborative consumption of mobile internet,"The recent mobile data explosion has increased the interest for mobile user-provided networks (MUPNs), where users share their Internet access by exploiting the diversity in their needs and resource availability. Although promising, MUPNs raise unique challenges. Namely, the success of such services relies on user participation which in turn can be achieved on the basis of a fair and efficient resource (i.e., Internet access and battery energy) exchange policy. The latter should be devised and imposed in a very fast time scale, based on near real-time feedback from mobile users regarding their needs, resources, and network conditions that are rapidly changing. To address these challenges we design and implement a novel cloud-controlled MUPN system, that employs software defined networking support on mobile terminals, to dynamically apply data forwarding policies with adaptive flow-control. We devise these policies by solving a coalitional game that is played among the users. We prove that the game has a non-empty core and hence the solution, which determines the servicing policy, incentivizes the users to participate. Finally, we evaluate the performance of the service in a prototype, where we investigate its performance limits, quantify the implementation overheads, and justify our architecture design choices.","Internet,
Mobile communication,
Games,
IEEE 802.11 Standard,
Mobile computing,
Logic gates,
Batteries"
Bandwidth Improvement Methods of Transmitarray Antennas,"Despite several advantages of planar transmitarray antennas compared to conventional lens antennas, they have a narrow bandwidth. The goal of this paper is to improve the bandwidth of transmitarray antennas through the control of the transmission phase range and the optimization of the phase distribution on the transmitarray aperture. To validate the proposed approaches, two quad-layer transmitarrays using double square loop elements have been designed, fabricated, and tested at Ku-band. The transmission phase distribution is optimized for both antennas, while they differ only in the transmission phase ranges. It is shown that the transmitarray antennas designed using the proposed techniques achieve 1-dB gain bandwidth of 9.8% and 11.7%, respectively. The measured gains at 13.5 GHz are 30.22 and 29.95 dB, respectively, leading to aperture efficiencies of 50% and 47%, respectively.","Gain,
Bandwidth,
Transmitting antennas,
Aperture antennas,
Arrays,
Feeds"
Predistribution Scheme for Establishing Group Keys in Wireless Sensor Networks,"wireless sensor networks (WSNs). This is because sensor nodes are limited in memory storage and computational power. In 1992, Blundo et al. proposed a noninteractive group key establishment scheme using a multivariate polynomial. Their scheme can establish a group key of m sensors. Since each share is a polynomial involving m - 1 variables and having degree k, each sensor needs to store (k + 1)m-1 coefficients from GF(p), which is exponentially proportional to the size of group. This makes their scheme only practical when m = 2 for peer-to-peer communication. So far, most existing predistribution schemes in WSNs establish pairwise keys for sensor nodes. In this paper, we propose a novel design to propose a predistribution scheme for establishing group keys in WSNs. Our design uses a special-type multivariate polynomial in ZN, where N is a RSA modulus. The advantage of using this type of multivariate polynomial can limit the storage space of each sensor to be m(k + 1), which is linearly proportional to the size of group communication. In addition, we prove the security of the proposed scheme and show that the computational complexity of the proposed scheme is efficient.",
Outsourcing coordination and management of home wireless access points through an open API,"In dense wireless deployments at homes, such as apartment buildings, neighboring home WLANs share the same unlicensed spectrum by deploying consumer-grade access points in their individual homes. In such environments, WiFi networks can suffer from intermittent performance issues such as wireless packet losses, interference from WiFi and non-WiFi sources due to the rapid growth and increasing diversity of devices that share the spectrum. In this paper, we propose a vendor-neutral cloud-based centralized framework called COAP to configure, coordinate and manage individual home APs using an open API implemented by these commodity APs. The framework, implemented using OpenFlow extensions, allows the APs to share various types of information with a centralized controller - interference and traffic phenomenon and various flow contexts, and in turn receive instructions - configuration parameters (e.g., channel) and transmission parameters (through coarse-grained schedules and throttling parameters). This paper describes the framework and associated techniques, applications to motivate its potential benefits, such as, upto 47% reduction in channel congestion and our experiences from having deployed it in actual home environments.",
Making cars a main ICT resource in smart cities,"As cars are ubiquitous in today's and tomorrow's cities they could play a major role in the communication of the future. In the last years the development of Inter-Vehicle Communication (IVC) took huge steps forward and therefore gives us exactly the tools needed to accomplish this task. We propose an architecture, named Car4ICT, that puts cars into the middle of future ICT systems. In this system users are able to offer and request services; at the same time, members are in charge of discovering the services and routing the data between users. Members are always cars, therefore they are the central part of our architecture. A user can be a human using a smartphone, a machine offering sensor readings, or even a car which offers storage, processing power, or its own sensor readings. We outline the architecture of our system and the different concepts to connect the users and the members. As such services cannot easily be described with known concepts, we outline our way of identifying the services. Additionally, we present some initial proof of concept simulation results that show the immense potential of the system.","Smart cities,
Protocols,
Vehicles,
Routing,
Conferences,
Informatics,
Cities and towns"
Layered Soft Video Broadcast for Heterogeneous Receivers,"Wireless video broadcast poses a challenge to the conventional visual communication in providing simultaneously each receiver the best video quality under its channel condition. Soft video broadcast, as a newly emerged wireless video broadcast scheme, is able to accommodate multiple receivers of different channel SNRs. However, the current soft video broadcast frameworks such as SoftCast require the bandwidth of the wireless channel to match the number of video coefficients per second. When the channel bandwidth is larger, the existing frameworks become not very efficient in bandwidth expansion. More importantly, it is possible that the users in broadcast applications have different bandwidths. However, none of the existing soft video broadcast frameworks considers bandwidth heterogeneity. In this paper, we propose a soft video broadcast framework, called LayerCast, which can simultaneously accommodate heterogeneous users with diverse SNRs and diverse bandwidths. The bandwidth expansion problem is solved by applying layered coset coding. More importantly, we derive a globally optimal power allocation between layers and, within each layer, between each DCT chunk. In simulations, the proposed framework outperforms SoftCast of up to 4 dB in video PSNR, and outperforms H.264-based framework up to 8 dB in broadcast.","Bandwidth,
Discrete cosine transforms,
Encoding,
Decoding,
Resource management,
Quantization (signal),
Wireless communication"
Cybermatics: A Holistic Field for Systematic Study of Cyber-Enabled New Worlds,"Following the two trends of computerization and informatization, another emerging trend is cyberization in which numerous and various cyber entities in cyberspace will exist in cyber-enabled worlds, including the cyber world and cyber-conjugated physical, social, and mental worlds. Computer science and information science, as holistic fields, have, respectively, played important roles in computerization and informatization. Similarly, it is necessary for there to be a corresponding field for cyberization. Cybermatics is proposed as such a holistic field for the systematic study of cyber entities in cyberspace and cyber world, and their properties, functions, and conjugations with entities in conventional spaces/worlds. This paper sets out to explain the necessity and rationale for, and significance of, the proposed field of Cybermatics, what it is and what it encompasses, and how it is related to other fields and areas.","Cyberspace,
Computers,
Market research,
Systematics,
History,
Computer science,
Electronic mail"
Privacy-Preserving Indoor Localization on Smartphones,"Indoor Positioning Systems (IPS) have recently received considerable attention, mainly because GPS is unavailable in indoor spaces and consumes considerable energy. On the other hand, predominant Smartphone OS localization subsystems currently rely on server-side localization processes, allowing the service provider to know the location of a user at all times. In this paper, we propose an innovative algorithm for protecting users from location tracking by the localization service, without hindering the provisioning of fine-grained location updates on a continuous basis. Our proposed Temporal Vector Map (TVM) algorithm, allows a user to accurately localize by exploiting a k-Anonymity Bloom (kAB) filter and a bestNeighbors generator of camouflaged localization requests, both of which are shown to be resilient to a variety of privacy attacks. We have evaluated our framework using a real prototype developed in Android and Hadoop HBase as well as realistic Wi-Fi traces scaling-up to several GBs. Our analytical evaluation and experimental study reveal that TVM is not vulnerable to attacks that traditionally compromise k-anonymity protection and indicate that TVM can offer fine-grained localization in approximately four orders of magnitude less energy and number of messages than competitive approaches.","IEEE 802.11 Standards,
Privacy,
Smart phones,
Servers,
Global Positioning System,
Databases,
Buildings"
Toward Practical MAC Design for Underwater Acoustic Networks,"Recently, various medium access control (MAC) protocols have been proposed for underwater acoustic networks (UANs). These protocols have significantly improved the performance of MAC layer in theory. However, two critical characteristics, low transmission rates and long preambles, found in the commercial modem-based real systems, severely degrade the performance of existing MAC protocols in the real world. Thus, a new practical MAC design is demanded. Toward an efficient approach, this paper analyzes the impact of these two modem characteristics on the random access-based MAC and handshake-based MAC, which are two major categories of MAC protocols for UANs. We further develop the nodal throughput and collision probability models for representative solutions of these two MAC protocol categories. Based on the analyses, we believe time sharing-based MAC is very promising. Along this line, we propose a time sharing-based MAC and analyze its nodal throughput. Both analytical and simulation results show that the time sharing-based solution can achieve significantly better performance.","Media Access Protocol,
Modems,
Throughput,
Delays,
Propagation delay,
Underwater acoustics"
Indian Buffet Game With Negative Network Externality and Non-Bayesian Social Learning,"In a dynamic system, how to perform learning and make decisions are becoming more and more important for users. Although there are some works in social learning-related literature regarding how to construct belief for an uncertain system state, few studies have been conducted on incorporating social learning with decision making. Moreover, users may have multiple concurrent options on different objects/resources and their decisions usually negatively influence each other's utility, which makes the problem even more challenging. In this paper, we propose an Indian Buffet Game to study how users in a dynamic system learn about the uncertain system state and make multiple concurrent decisions by not only considering the current myopic utility, but also the influence of subsequent users' decisions. We analyze the proposed Indian Buffet Game under two different scenarios: 1) on customers requesting multiple dishes without budget constraint and 2) with budget constraint. For both cases, we design recursive best response algorithms to find the subgame perfect Nash equilibrium (NE) for customers and characterize special properties of the NE profile under homogeneous setting. Moreover, we introduce a non-Bayesian social learning algorithm for customers to learn the system state, and theoretically prove its convergence. Finally, we conduct simulations to validate the effectiveness and efficiency of the proposed algorithms.","Games,
Decision making,
Algorithm design and analysis,
Convergence,
Indexes,
Uncertain systems,
Prediction algorithms"
Energy-Efficient Randomized Switching for Maximizing Lifetime in Tree-Based Wireless Sensor Networks,"In most wireless sensor network (WSN) applications, data are typically gathered by sensor nodes and reported to a data collection point called sink. To support such a data collection pattern, a tree structure rooted at the sink is defined. Depending on various factors, including the WSN topology and the availability of resources, the energy consumption of nodes in different paths of the data collection tree may vary largely, thus affecting the overall network lifetime. This paper addresses the problem of lifetime maximization of WSNs based on data collection trees. Specifically, we propose a novel and efficient algorithm, called Randomized Switching for Maximizing Lifetime (RaSMaLai), that aims at extending the lifetime of WSNs through load balancing. Given an initial data collection tree, RaSMaLai randomly switches some sensor nodes from their original paths to other paths with lower load. We prove that, under appropriate settings of the operating parameters, RaSMaLai converges with a low time complexity. We further design a distributed version of our algorithm. Through an extensive performance evaluation study that includes simulation of large-scale scenarios and real experiments on a WSN testbed, we show that the proposed RaSMaLai algorithm and its distributed version achieve a longer network lifetime than the state-of-the-art solutions.","Data collection,
Switches,
Wireless sensor networks,
Load management,
Algorithm design and analysis,
Routing,
IEEE transactions"
Adaptively Secure Identity-Based Broadcast Encryption With a Constant-Sized Ciphertext,"In this paper, we present an adaptively secure identity-based broadcast encryption system featuring constant sized ciphertext in the standard model. The size of the public key and the private keys of our system are both linear in the maximum number of receivers. In addition, our system is fully collusion-resistant and has stateless receivers. Compared with the state-of-the-art, our scheme is well optimized for the broadcast encryption. The computational complexity of decryption of our scheme depends only on the number of receivers, not the maximum number of receivers of the system. Technically, we employ dual system encryption technique and our proposal offers adaptive security under the general subgroup decisional assumption. Our scheme demonstrates that the adaptive security of the schemes utilizing a composite order group can be proven under the general subgroup decisional assumption, while many existing systems working in a composite order group are secure under multiple subgroup decision assumptions. We note that this finding is of an independent interest, which may be useful in other scenarios.",
Network-Lifetime Maximization of Wireless Sensor Networks,"Network lifetime (NL) maximization techniques have attracted a lot of research attention owing to their importance for extending the duration of the operations in the battery-constrained wireless sensor networks (WSNs). In this paper, we consider a two-stage NL maximization technique conceived for a fully-connected WSN, where the NL is strictly dependent on the source node's (SN) battery level, since we can transmit information generated at the SN to the destination node (DN) via alternative routes, each having a specific route lifetime (RL) value. During the first stage, the RL of the alternative routes spanning from the SN to the DN is evaluated, where the RL is defined as the earliest time, at which a sensor node lying in the route fully drains its battery charge. The second stage involves the summation of these RL values, until the SN's battery is fully depleted, which constitutes the lifetime of the WSN considered. Each alternative route is evaluated using cross-layer optimization of the power allocation, scheduling and routing operations for the sake of NL maximization for a predetermined per-link target signal-to-interference-plus-noise ratio values. Therefore, we propose the optimal but excessive-complexity algorithm, namely, the exhaustive search algorithm (ESA) and a near-optimal single objective genetic algorithm (SOGA) exhibiting a reduced complexity in a fully connected WSN. We demonstrate that in a high-complexity WSN, the SOGA is capable of approaching the ESA's NL within a tiny margin of 3.02% at a 2.56 times reduced complexity. We also show that our NL maximization approach is powerful in terms of prolonging the NL while striking a tradeoff between the NL and the quality of service requirements.","Telecommunication network management,
Wireless sensor networks,
Maximation techniques,
Batteries,
Complexity theory,
Resource management,
Routing protocols,
Search problems"
Multilayer Joint Gait-Pose Manifolds for Human Gait Motion Modeling,"We present new multilayer joint gait-pose manifolds (multilayer JGPMs) for complex human gait motion modeling, where three latent variables are defined jointly in a low-dimensional manifold to represent a variety of body configurations. Specifically, the pose variable (along the pose manifold) denotes a specific stage in a walking cycle; the gait variable (along the gait manifold) represents different walking styles; and the linear scale variable characterizes the maximum stride in a walking cycle. We discuss two kinds of topological priors for coupling the pose and gait manifolds, i.e., cylindrical and toroidal, to examine their effectiveness and suitability for motion modeling. We resort to a topologically-constrained Gaussian process (GP) latent variable model to learn the multilayer JGPMs where two new techniques are introduced to facilitate model learning under limited training data. First is training data diversification that creates a set of simulated motion data with different strides. Second is the topology-aware local learning to speed up model learning by taking advantage of the local topological structure. The experimental results on the Carnegie Mellon University motion capture data demonstrate the advantages of our proposed multilayer models over several existing GP-based motion models in terms of the overall performance of human gait motion modeling.",
Perception-Based Evaluation of Projection Methods for Multidimensional Data Visualization,"Similarity-based layouts generated by multidimensional projections or other dimension reduction techniques are commonly used to visualize high-dimensional data. Many projection techniques have been recently proposed addressing different objectives and application domains. Nonetheless, very little is known about the effectiveness of the generated layouts from a user's perspective, how distinct layouts from the same data compare regarding the typical visualization tasks they support, or how domain-specific issues affect the outcome of the techniques. Learning more about projection usage is an important step towards both consolidating their role in high-dimensional data analysis and taking informed decisions when choosing techniques. This work provides a contribution towards this goal. We describe the results of an investigation on the performance of layouts generated by projection techniques as perceived by their users. We conducted a controlled user study to test against the following hypotheses: (1) projection performance is task-dependent; (2) certain projections perform better on certain types of tasks; (3) projection performance depends on the nature of the data; and (4) subjects prefer projections with good segregation capability. We generated layouts of high-dimensional data with five techniques representative of different projection approaches. As application domains we investigated image and document data. We identified eight typical tasks, three of them related to segregation capability of the projection, three related to projection precision, and two related to incurred visual cluttering. Answers to questions were compared for correctness against `ground truth' computed directly from the data. We also looked at subject confidence and task completion times. Statistical analysis of the collected data resulted in Hypotheses 1 and 3 being confirmed, Hypothesis 2 being confirmed partially and Hypotheses 4 could not be confirmed. We discuss our findings in comparison with some numerical measures of projection layout quality. Our results offer interesting insight on the use of projection layouts in data visualization tasks and provide a departing point for further systematic investigations.",
Energy harvesting study on single and multilayer ferroelectret foams under compressive force,"Cellular polypropylene (PP) ferro electret is a thin and flexible cellular polymer foam that generates electrical power under mechanical force. This work investigates single and multilayer ferro electret PP foams and their potential to supply energy for human-body-worn sensors. Human foot-fall is emulated using an electrodynamic instrument, allowing applied compressive force and momentum to be correlated with energy output. Peak power, output pulse duration, and energy per strike is derived experimentally as a function of force and momentum, and shown to be a strong function of external load resistance, thus providing a clear maximum energy point. The possibility of increasing pulse time and reducing voltage to CMOS compatible levels at some expense of peak power is shown. To further increase the output power, multilayer ferro electret is presented. The synchronized power generation of each layer is studied and illustrated using simulation, and results are supported by experiments. Finally, the energy output of single-layer and multi-layer ferro electrets are compared by charging a capacitor via a rectifier. A ten-layer ferro electret is shown to have charging ability 29.1 times better than that of the single-layer ferro electret. It demonstrates energy output that is capable of powering the start-up and transmission of a typical low-power wireless sensor chipset.","Legged locomotion,
Force,
Nonhomogeneous media,
Energy harvesting,
Voltage measurement,
Immune system,
Instruments"
4D Blood Flow Reconstruction Over the Entire Ventricle From Wall Motion and Blood Velocity Derived From Ultrasound Data,"We demonstrate a new method to recover 4D blood flow over the entire ventricle from partial blood velocity measurements using multiple 3D+t colour Doppler images and ventricular wall motion estimated using 3D+t BMode images. We apply our approach to realistic simulated data to ascertain the ability of the method to deal with incomplete data, as typically happens in clinical practice. Experiments using synthetic data show that the use of wall motion improves velocity reconstruction, shows more accurate flow patterns and improves mean accuracy particularly when coverage of the ventricle is poor. The method was applied to patient data from 6 congenital cases, producing results consistent with the simulations. The use of wall motion produced more plausible flow patterns and reduced the reconstruction error in all patients.","Doppler effect,
Blood,
Three-dimensional displays,
Image color analysis,
Image reconstruction,
Splines (mathematics),
Velocity measurement"
A Faster Cutting Plane Method and its Implications for Combinatorial and Convex Optimization,"In this paper we improve upon the running time for finding a point in a convex set given a separation oracle. In particular, given a separation oracle for a convex set K ⊂ Rn that is contained in a box of radius R we show how to either compute a point in K or prove that K does not contain a ball of radius ϵ using an expected O(n log(nR/ϵ)) evaluations of the oracle and additional time O(n3 logO(1)(nR/ϵ)). This matches the oracle complexity and improves upon the O(nω+1 log(nR/ϵ)) additional time of the previous fastest algorithm achieved over 25 years ago by Vaidya [91] for the current value of the matrix multiplication constant w <; 2.373 [98], [36] when R/ϵ = O(poly(n)). Using a mix of standard reductions and new techniques we show how our algorithm can be used to improve the running time for solving classic problems in continuous and combinatorial optimization. In particular we provide the following running time improvements: · Submodular Function Minimization: n is the size of the ground set, M is the maximum absolute value of function values and EO is the time for function evaluation. Our weakly and strongly polynomial time algorithms have a running time of O(n2 log nM · EO + n3 logO(1) nM) and O(n3 log2 n · EO + n4 logO(1) n), improving upon the previous best of O((n4 · EO + n5)logM) and O(n5 · EO + n6) respectively. · Submodular Flow: n = |V|, m = |E|, C is the maximum edge cost in absolute value and U is maximum edge capacity in absolute value. We obtain a faster weakly polynomial running time of O(n2 log nCU · EO + n3 logO(1) nCU), improving upon the previous best of O(mn5 log nU · EO) and O (n4h min {log C, log U}) from 15 years ago by a factor of Õ(n4). We also achieve faster strongly polynomial time algorithms as a consequence of our result on submodular minimization. · Matroid Intersection: n is the size of the ground set, r is the maximum size of independent sets, M is the maximum absolute value of element weight, Trank and Tind are the time for each rank and independence oracle query. We obtain a running time of O((nr log2 nTrank+n3 logO(1) n) log nM) and O((n2 log nTind+n3 logO(1) n) log nM), achieving the first quadratic bound on the query complexity for the independence and rank oracles. In the unweighted case, this is the first improvement since 1986 for independence oracle. · Semidefinite Programming: n is the number of constraints, m is the number of dimensions and S is the total number of non-zeros in the constraint matrices. We obtain a running time of O(n(n2 + mω + S)), improving upon the previous best of Õ(n(nω + mω + S)) for the regime S is small.","Ellipsoids,
Optimization,
Algorithm design and analysis,
Complexity theory,
Polynomials,
Convex functions,
Minimization"
Multi-view Subspace Clustering,"For many computer vision applications, the data sets distribute on certain low-dimensional subspaces. Subspace clustering is to find such underlying subspaces and cluster the data points correctly. In this paper, we propose a novel multi-view subspace clustering method. The proposed method performs clustering on the subspace representation of each view simultaneously. Meanwhile, we propose to use a common cluster structure to guarantee the consistence among different views. In addition, an efficient algorithm is proposed to solve the problem. Experiments on four benchmark data sets have been performed to validate our proposed method. The promising results demonstrate the effectiveness of our method.","Clustering methods,
Optimization,
Computer vision,
Clustering algorithms,
Computer science,
Image color analysis,
Benchmark testing"
An Image-Based Endmember Bundle Extraction Algorithm Using Both Spatial and Spectral Information,"With the development of imaging technology, remote sensing images with a high spatial and spectral resolution have become available and have been used in various applications such as the identification of materials and the estimation of physical parameters. Although many endmember extraction algorithms have been proposed for hyperspectral data sets which extract/select the standard endmember spectrum for each existing endmember class or scene component, there are still some problems in endmember extraction which blur the discrimination between the different types of ground objects and lead to inaccurate endmember extraction. One problem is that the definition of pure materials (or endmembers) can be subjective and application dependent. The other problem is that spectral variability is inevitable due to the different imaging conditions, especially in a hyperspectral image with a higher spatial resolution. In this paper, to account for the spectral variability, each endmember of a material is represented with a set or “bundle” of spectra, and an image-based endmember bundle extraction algorithm using both spatial and spectral information is proposed. There are four steps in the proposed method of extracting endmember bundles: 1) pixel purity index preprocessing; 2) homogeneity index calculation; 3) region-based candidate endmember selection; and 4) spectral clustering. Experiments with both synthetic and real hyperspectral data sets indicate that, by considering the endmember variability in the original hyperspectral data, the proposed method shows a significant improvement over the current state-of-the-art endmember bundle extraction methods.","Hyperspectral imaging,
Indexes,
Materials,
Vectors,
Clustering algorithms,
Algorithm design and analysis,
Data mining"
A Visual-Aided Wireless Monitoring System Design for Total Hip Replacement Surgery,"To improve the positioning accuracy of implants in Total Hip Replacement (THR) surgeries, a visual-aided wireless monitoring system for THR surgery is proposed in this paper. This system aims to measure and display the contact distribution and relative pose between femoral head and acetabulum prosthesis during the surgery to help surgeons obtain accurate position of implants. The system consists of two parts: the Sensors Array Measuring System (SAMS) and the display part. The SAMS is composed of a sensors array (including contact sensors and an image sensor), signal conditioning circuits, a low power microcontroller (MCU), and a low-power transceiver. The SAMS is designed to estimate the relative pose of femoral head component to acetabular component. The display part processes the data from sensors and demonstrates the contact distribution and the pose of the prothesis during the surgery in 3-D graphics. The two parts of the system communicate with each other on an RF link at the band of 400 MHz. The signal conditioning circuits have been designed and fabricated in 0.18 μm CMOS process. Testing results show that the resolution of the signal conditioning circuits is 60.1 μ Vpp (1.35g) with ±100 mVpp input. The chip can operate under 1.2-to-3.6 V supply voltage for single battery applications with 116-160 μ A current consumption. The system has been verified by the simulation with rotation quaternion and translation vector. The experimental results show that the contact distribution and relative pose of the two components could be measured and demonstrated in real time. The relative error of rotation is less than 8% and the actual relative error of translation is less than 10%.","Sensors,
Head,
Surgery,
Cameras,
Hip,
Prosthetics,
Biomedical measurement"
PVMirror: A New Concept for Tandem Solar Cells and Hybrid Solar Converters,"As the solar electricity market has matured, energy conversion efficiency and storage have joined installed system cost as significant market drivers. In response, manufacturers of flat-plate silicon photovoltaic (PV) cells have pushed cell efficiencies above 25%-nearing the 29.4% detailed-balance efficiency limit-and both solar thermal and battery storage technologies have been deployed at utility scale. This paper introduces a new tandem solar collector employing a “PVMirror” that has the potential to both increase energy conversion efficiency and provide thermal storage. A PVMirror is a concentrating mirror, spectrum splitter, and light-to-electricity converter all in one: It consists of a curved arrangement of PV cells that absorb part of the solar spectrum and reflect the remainder to their shared focus, at which a second solar converter is placed. A strength of the design is that the solar converter at the focus can be of a radically different technology than the PV cells in the PVMirror; another is that the PVMirror converts a portion of the diffuse light to electricity in addition to the direct light. We consider two case studies-a PV cell located at the focus of the PVMirror to form a four-terminal PV-PV tandem, and a thermal receiver located at the focus to form a PV-CSP (concentrating solar thermal power) tandem-and compare the outdoor energy outputs to those of competing technologies. PVMirrors can outperform (idealized) monolithic PV-PV tandems that are under concentration, and they can also generate nearly as much energy as silicon flat-plate PV while simultaneously providing the full energy storage benefit of CSP.","Silicon,
Mirrors,
Photonic band gap,
Heterojunctions,
Glass,
Photovoltaic cells"
Global Network Alignment in the Context of Aging,"Analogous to sequence alignment, network alignment (NA) can be used to transfer biological knowledge across species between conserved network regions. NA faces two algorithmic challenges: 1) Which cost function to use to capture “similarities” between nodes in different networks? 2) Which alignment strategy to use to rapidly identify “high-scoring” alignments from all possible alignments? We “break down” existing state-of-the-art methods that use both different cost functions and different alignment strategies to evaluate each combination of their cost functions and alignment strategies. We find that a combination of the cost function of one method and the alignment strategy of another method beats the existing methods. Hence, we propose this combination as a novel superior NA method. Then, since human aging is hard to study experimentally due to long lifespan, we use NA to transfer aging-related knowledge from well annotated model species to poorly annotated human. By doing so, we produce novel human aging-related knowledge, which complements currently available knowledge about aging that has been obtained mainly by sequence alignment. We demonstrate significant similarity between topological and functional properties of our novel predictions and those of known aging-related genes. We are the first to use NA to learn more about aging.","Cost function,
Proteins,
Bioinformatics,
Aging,
Computational biology"
Multi-View Concept Learning for Data Representation,"Real-world datasets often involve multiple views of data items, e.g., a Web page can be described by both its content and anchor texts of hyperlinks leading to it; photos in Flickr could be characterized by visual features, as well as user contributed tags. Different views provide information complementary to each other. Synthesizing multi-view features can lead to a comprehensive description of the data items, which could benefit many data analytic applications. Unfortunately, the simple idea of concatenating different feature vectors ignores statistical properties of each view and usually incurs the “curse of dimensionality” problem. We propose Multi-view Concept Learning (MCL), a novel nonnegative latent representation learning algorithm for capturing conceptual factors from multi-view data. MCL exploits both multi-view information and label information. The key idea is to learn a common latent space across different views which (1) captures the semantic relationships between data items through graph embedding regularization on labeled items, and (2) allows each latent factor to be associated with a subset of views via sparseness constraints. In this way, MCL could capture flexible conceptual patterns hidden in multi-view features. Experiments on a toy problem and three real-world datasets show that MCL performs well and outperforms baseline methods.","Encoding,
Semantics,
Optimization methods,
Linear programming,
Visualization,
Electronic mail"
Analysis of Structural Similarity in Mammograms for Detection of Bilateral Asymmetry,"We hypothesize that quantification of structural similarity or dissimilarity between paired mammographic regions can be effective in detecting asymmetric signs of breast cancer. Bilateral masking procedures are applied for this purpose by using automatically detected anatomical landmarks. Changes in structural information of the extracted regions are investigated using spherical semivariogram descriptors and correlation-based structural similarity indices in the spatial and complex wavelet domains. The spatial distribution of grayscale values as well as of the magnitude and phase responses of multidirectional Gabor filters are used to represent the structure of mammographic density and of the directional components of breast tissue patterns, respectively. A total of 188 mammograms from the DDSM and mini-MIAS databases, consisting of 47 asymmetric cases and 47 normal cases, were analyzed. For the combined dataset of mammograms, areas under the receiver operating characteristic curves of 0.83, 0.77, and 0.87 were obtained, respectively, with linear discriminant analysis, the Bayesian classifier, and an artificial neural network with radial basis functions, using the features selected by stepwise logistic regression and leave-one-patient-out cross-validation. Two-view analysis provided accuracy up to 0.94, with sensitivity and specificity of 1 and 0.88, respectively.","Strips,
Breast cancer,
Delta-sigma modulation,
Accuracy,
Indexes"
Recursive Approximation of the Bilateral Filter,"This paper presents a complete proof that the bilateral filter can be implemented recursively, as long as: 1) the spatial filter can be implemented recursively and 2) the range filter can be decomposed into a recursive product. As a result, an O(ND) solution can be obtained for bilateral filtering, where N is the image size and D is the dimensionality.","Kernel,
Filtering,
Gray-scale,
Approximation methods,
Computational complexity,
Equations"
Analysis Model for Magnetic Energy Harvesters,"Energy harvesting offers an important design option for creating sensing and control elements without a requirement for custom wiring or batteries. An exciting possibility creates a “self-powered” sensor node with an integrated energy harvester that can extract power from the magnetic fields around a power line to a load, in the manner of a current transformer. However, this “current transformer” provides not just current sensing, but also power for a sensor package, all without ohmic contact. This paper provides a technique for design optimization for maximizing power harvest, revealing a critical result: For any given core in any particular application, power harvest is maximized when the core is permitted to saturate at an opportune time in the line cycle. Circuits for optimizing this power transfer window and experimental results supporting the analysis are presented in this paper.",
Secure Distributed Deduplication Systems with Improved Reliability,"Data deduplication is a technique for eliminating duplicate copies of data, and has been widely used in cloud storage to reduce storage space and upload bandwidth. However, there is only one copy for each file stored in cloud even if such a file is owned by a huge number of users. As a result, deduplication system improves storage utilization while reducing reliability. Furthermore, the challenge of privacy for sensitive data also arises when they are outsourced by users to cloud. Aiming to address the above security challenges, this paper makes the first attempt to formalize the notion of distributed reliable deduplication system. We propose new distributed deduplication systems with higher reliability in which the data chunks are distributed across multiple cloud servers. The security requirements of data confidentiality and tag consistency are also achieved by introducing a deterministic secret sharing scheme in distributed storage systems, instead of using convergent encryption as in previous deduplication systems. Security analysis demonstrates that our deduplication systems are secure in terms of the definitions specified in the proposed security model. As a proof of concept, we implement the proposed systems and demonstrate that the incurred overhead is very limited in realistic environments.",
Video Deraining and Desnowing Using Temporal Correlation and Low-Rank Matrix Completion,"A novel algorithm to remove rain or snow streaks from a video sequence using temporal correlation and low-rank matrix completion is proposed in this paper. Based on the observation that rain streaks are too small and move too fast to affect the optical flow estimation between consecutive frames, we obtain an initial rain map by subtracting temporally warped frames from a current frame. Then, we decompose the initial rain map into basis vectors based on the sparse representation, and classify those basis vectors into rain streak ones and outliers with a support vector machine. We then refine the rain map by excluding the outliers. Finally, we remove the detected rain streaks by employing a low-rank matrix completion technique. Furthermore, we extend the proposed algorithm to stereo video deraining. Experimental results demonstrate that the proposed algorithm detects and removes rain or snow streaks efficiently, outperforming conventional algorithms.","Rain,
Optical imaging,
Support vector machines,
Heuristic algorithms,
Dictionaries,
Image color analysis,
Image reconstruction"
Topic Model for Graph Mining,"Graph mining has been a popular research area because of its numerous application scenarios. Many unstructured and structured data can be represented as graphs, such as, documents, chemical molecular structures, and images. However, an issue in relation to current research on graphs is that they cannot adequately discover the topics hidden in graph-structured data which can be beneficial for both the unsupervised learning and supervised learning of the graphs. Although topic models have proved to be very successful in discovering latent topics, the standard topic models cannot be directly applied to graph-structured data due to the “bag-of-word” assumption. In this paper, an innovative graph topic model (GTM) is proposed to address this issue, which uses Bernoulli distributions to model the edges between nodes in a graph. It can, therefore, make the edges in a graph contribute to latent topic discovery and further improve the accuracy of the supervised and unsupervised learning of graphs. The experimental results on two different types of graph datasets show that the proposed GTM outperforms the latent Dirichlet allocation on classification by using the unveiled topics of these two models to represent graphs.","Data mining,
Chemicals,
Hidden Markov models,
Inference algorithms,
Data models,
Vectors,
Chemical elements"
Design and Performance Evaluation of a Dielectric Flat Lens Antenna for Millimeter-Wave Applications,"In this letter, a practical fabrication of a novel inhomogeneous gradient-index dielectric flat lens for millimeter-wave applications is presented. A previous theoretical design of a dielectric flat lens composed of different permittivity materials is now modeled and analyzed for a practical prototype fabrication and performance evaluation at 60 and 77 GHz. The measurement results at 60 GHz show that with the novel gradient-index dielectric flat lens antenna prototype, we can achieve up to 18.3 dB of broadside gain, beam-steering capabilities in both planes from -30° to +30° with around 15 dB of gain, and up to ±45° with around 14 dB of gain, with low sidelobe levels. At 77 GHz, the performance evaluation shows that we can obtain up to 18.9 dB of broadside gain, beam-steering capabilities in both planes from -30° to +30° with around 17 dB of gain and low sidelobe levels, and up to ±45° with around 15 dB of gain. This novel design leads to a low-cost, low-profile, and lightweight antenna solution, easy to integrate in a compact millimeter-wave wireless communication system.",
Message in a Sealed Bottle: Privacy Preserving Friending in Mobile Social Networks,"Many proximity-based mobile social networks are developed to facilitate connections between any two people, or to help a user to find people with a matched profile within a certain distance. A challenging task in these applications is to protect the privacy of the participants' profiles and communications. In this paper, we design novel mechanisms, when given a preference-profile submitted by a user, that search persons with matching-profile in decentralized mobile social networks. Meanwhile, our mechanisms establish a secure communication channel between the initiator and matching users at the time when a matching user is found. These techniques can also be applied to conduct privacy preserving keywords based search without any secure communication channel. Our analysis shows that our mechanism is privacy-preserving (no participants' profile and the submitted preference-profile are exposed), verifiable (both the initiator and any unmatched user cannot cheat each other to pretend to be matched), and efficient in both communication and computation. Extensive evaluations using real social network data, and actual system implementation on smart phones show that our mechanisms are significantly more efficient than existing solutions.","Vectors,
Privacy,
Social network services,
Cryptography,
Relays,
Mobile computing,
Mobile communication"
New VHP-Female v. 2.0 full-body computational phantom and its performance metrics using FEM simulator ANSYS HFSS,"Simulation of the electromagnetic response of the human body relies heavily upon efficient computational models or phantoms. The first objective of this paper is to present a new platform-independent full-body electromagnetic computational model (computational phantom), the Visible Human Project® (VHP)-Female v. 2.0 and to describe its distinct features. The second objective is to report phantom simulation performance metrics using the commercial FEM electromagnetic solver ANSYS HFSS.","Finite element analysis,
Phantoms,
Computational modeling,
Electromagnetics,
Brain models,
Biological system modeling"
Gaussian Process Regression-Based Video Anomaly Detection and Localization With Hierarchical Feature Representation,"This paper presents a hierarchical framework for detecting local and global anomalies via hierarchical feature representation and Gaussian process regression (GPR) which is fully non-parametric and robust to the noisy training data, and supports sparse features. While most research on anomaly detection has focused more on detecting local anomalies, we are more interested in global anomalies that involve multiple normal events interacting in an unusual manner, such as car accidents. To simultaneously detect local and global anomalies, we cast the extraction of normal interactions from the training videos as a problem of finding the frequent geometric relations of the nearby sparse spatio-temporal interest points (STIPs). A codebook of interaction templates is then constructed and modeled using the GPR, based on which a novel inference method for computing the likelihood of an observed interaction is also developed. Thereafter, these local likelihood scores are integrated into globally consistent anomaly masks, from which anomalies can be succinctly identified. To the best of our knowledge, it is the first time GPR is employed to model the relationship of the nearby STIPs for anomaly detection. Simulations based on four widespread datasets show that the new method outperforms the main state-of-the-art methods with lower computational burden.","Ground penetrating radar,
Hidden Markov models,
Three-dimensional displays,
Training,
Feature extraction,
Detectors,
Computational modeling"
Performance Enhancement of Plasmonic Sub-Terahertz Detector Based on Antenna Integrated Low-Impedance Silicon MOSFET,"We demonstrate the performance enhancement of field-effect transistor (FET)-based plasmonic terahertz (THz) detector with monolithic integrated antenna in low-impedance regime and report the experimental results of Si MOSFET impedance in THz regime using 0.2-THz measurement system. By designing FET with low-impedance ranges (<;1 kΩ) and integrating antennas with impedances of 50 and 100 Ω, we found that our low-impedance MOSFETs have the input impedance criterion of 50 Ω at 0.2 THz and the MOSFETs with thinner gate oxide show the highly enhanced plasmonic photoresponses at 50-Ω antenna by 325 times from the result of the detector without antenna.","MOSFET,
Detectors,
Impedance,
Plasmons,
Antennas,
Silicon"
Ultra-dense small cell planning using cognitive radio network toward 5G,"Mobile communication is facing new challenges to the soaring traffic demand of numerous user devices; thus, the notion of the small cell has been proposed and realized in recent years. However, licensed spectrum has been occupied by various underlying access technologies, so the deployment of small cells needs a sophisticated planning algorithm. In this article, we provide an overview of reconfigurable radio and small cell technologies, then introduce the tentative network architecture for 5G. Two planning approaches (i.e., genetic-based and graphbased) are proposed that accommodate cognitive radio technology to improve user throughput by eliminating communication interference. Since cognitive radio networking provides frequency allocation with cognition cycle for better spectral efficiency, we tackle the deployment of ultradense small cells and consider the coordination of unlicensed spectrum at the same time. Results show that the proposed algorithms with spectrum cognition improve network performance in terms of throughput and signal-to-interference- plus-noise ratio. Specifically, the genetic- based algorithm increases 232 percent in throughput and 150 percent in signal-to-interference- plus-noise ratio compared to the graphbased algorithm. Finally, we conclude this article by discussing potential challenges and opportunities.",
Cloud-assisted GPS-driven dynamic spectrum access in cognitive radio vehicular networks for transportation cyber physical systems,"Transportation Cyber Physical Systems (CPS) are expected to rely on robust wireless communication networks for real-time feedback for controlling these systems. The IEEE 802.11p based Dedicated Short Range Communication (DSRC) standard has been proposed for vehicular communications that has 7 channels. However, these channels could be easily congested resulting in delay and unreliable communications when vehicle density is high. In this paper, we present a cloud-assisted global positioning system (GPS)-driven dynamic spectrum access framework for transportation CPS. To provide reliable communications, we assume that each vehicle is equipped with two transceivers: one transceiver (always connected to the internet using e.g., 4G link) queries spectrum database and/or can serve as a GPS through an application (app), and the other transceiver/radio switches channels and adapts to suitable transmit parameters for vehicular communications to avoid any harmful interference to primary users (PUs). Each vehicle calculates the best route to its destination using GPS and finds the set of idle channels along the route. Furthermore, each vehicle periodically checks the spectrum database throughout the route to get most updated spectrum opportunities. We present performance evaluation of the proposed approach with the help numerical results obtained from simulations.","Databases,
Vehicles,
IEEE 802.11 Standards,
Global Positioning System,
Cloud computing,
Cognitive radio,
Real-time systems"
Spectral CT Modeling and Reconstruction With Hybrid Detectors in Dynamic-Threshold-Based Counting and Integrating Modes,"Spectral CT with photon counting detectors can significantly improve CT performance by reducing image noise and dose, increasing contrast resolution and material specificity, as well as enabling functional and molecular imaging with existing and emerging probes. However, the current photon counting detector architecture is difficult to balance the number of energy bins and the statistical noise in each energy bin. Moreover, the hardware support for multi-energy bins demands a complex circuit which is expensive. In this paper, we promote a new scheme known as hybrid detectors that combine the dynamic-threshold-based counting and integrating modes. In this scheme, an energy threshold can be dynamically changed during a spectral CT scan, which can be considered as compressive sensing along the spectral dimension. By doing so, the number of energy bins can be retrospectively specified, even in a spatially varying fashion. To establish the feasibility and merits of such hybrid detectors, we develop a tensor-based PRISM algorithm to reconstruct a spectral CT image from dynamic dual-energy data, and perform experiments with simulated and real data, producing very promising results.","Detectors,
Computed tomography,
Photonics,
Tensile stress,
Image reconstruction,
Attenuation,
Energy resolution"
Computation Sharing in Distributed Robotic Systems: A Case Study on SLAM,"Aiming at increasing team efficiency, mobile robots may act as a node of a Robotic Cluster to assist their teammates in computationally demanding tasks. Having this in mind, we propose two distributed architectures for the Simultaneous Localization And Mapping (SLAM) problem, our main case study. The analysis focuses especially on the efficiency gain that can be obtained. It is shown that the proposed architectures enable us to raise the workload up to values that would not be possible in a single robot solution, thus gaining in localization precision and map accuracy. Furthermore, we assess the impact of network bandwidth. All the results are extracted from frequently used SLAM datasets available in the robotics community and a real world testbed is described to show the potential of using the proposed philosophy.",
Reliability analysis of healthcare information systems: State of the art and future directions,"Testing and verification of healthcare information systems is a challenging and important issue since faults in these critical systems may lead to loss of lives, and in the best cases, loss of money and reputations. However, due to the complexity of these systems, and the increasing demand for new products and new technologies in this domain, there are several methods and technologies being used for testing these systems. In this paper, we review the state of the art on testing and verification of healthcare information systems, and then we identify several open issues and challenges in the area. We divide the exiting methods into three categories: simulation based methods, formal methods, and other techniques such as semi-formal methods. Then, we discuss challenging and open issues in the domain.","Medical services,
Electrocardiography,
Testing,
MATLAB,
Security,
Sensors"
Bioinformatics-Inspired Quantized Hard Combination-Based Abnormality Detection for Cooperative Spectrum Sensing in Cognitive Radio Networks,"String matching algorithms used in bioinformatics can be applied to scenarios in cognitive radios, where reports of cooperative spectrum sensing nodes need to be compared with each other. Cooperative spectrum sensing is susceptible to security risks, where malicious users who participate in the process falsify the spectrum sensing data, thus affecting cognitive radio network performance. In this paper, an efficient spectrum sensing system is developed where each cognitive radio (CR) user senses the spectrum multiple times within an allocated sensing period. Each CR user quantizes its decision to predefined levels so as to achieve a tradeoff between bandwidth utilization and decision reporting accuracy. The reports for all the CR users are compared at the fusion center using Smith-Waterman algorithm, an optimal algorithm for aligning biological sequences used in bioinformatics, and similarity indices are computed. Robust mean and robust deviation of the similarity indices are calculated and a threshold is determined by these values. The CR users who have similarity indices below the given threshold are declared malicious and their reports are discarded. The local decisions of the remaining CR users are combined using the modified rules of decision combination to take a global decision. Simulation results show that our proposed scheme performs better than conventional schemes with and without malicious users.","Sensors,
Bioinformatics,
Robustness,
Indexes,
Measurement,
Signal to noise ratio,
Cognitive radio"
Resolution recommendation for event tickets in service management,"In recent years, IT Service Providers have been rapidly transforming to an automated service delivery model. This is due to advances in technology and driven by the unrelenting market pressure to reduce cost and maintain quality. Tremendous progress has been made to date towards attainment of truly automated service delivery; that is, the ability to deliver the same service automatically using the same process with the same quality. However, automating Incident and Problem Management continuous to be a difficult problem, particularly due to the growing complexity of IT environments. Software monitoring systems are designed to actively collect and signal event occurrances and, when necessary, automatically generate incident tickets. Repeating events generate similar tickets, which in turn have a vast number of repeated problem resolutions likely to be found in earlier tickets. In this paper we find an appropriate resolution by making use of similarities between the events and previous resolutions of similar events. Traditional KNN (K Nearest Neighbor) algorithm has been used to recommend resolutions for incoming tickets. However, the effectiveness of recommendation heavily relies on the underlying similarity measure in KNN. In this paper, we significantly improve the similarity measure used in KNN by utilizing both the event and resolution information in historical tickets via a topic-level feature extraction using the LDA (Latent Dirichlet Allocation) model. In addition, when resolution categories are available, we propose to learn a more effective similarity measure using metric learning. Extensive empirical evaluations on three ticket data sets demonstrate the effectiveness and efficiency of our proposed methods.","Monitoring,
Measurement,
Feature extraction,
Computational modeling,
Software,
Nearest neighbor searches,
Servers"
Thwarting Intelligent Malicious Behaviors in Cooperative Spectrum Sensing,"Sensing falsification is a key security threat in cooperative spectrum sensing in cognitive radio networks. Intelligent malicious users (IMUs) adjust their malicious behaviors according to their objectives and the network's defense schemes. Without long-term collection of information on users' reputation, the existing schemes fail to thwart such malicious behaviors. In this paper, we construct a joint spectrum sensing and access framework to thwart the malicious behaviors of both rational and irrational IMUs. Lack of reputation information makes the malicious behavior resistance degrade performance since the honest users may be misjudged as IMUs. Based on the moral hazard principal-agent model, we design an incentive compatible mechanism to provide a moderate punishment to IMUs. Our findings show that neither spectrum sensing nor spectrum access alone can prevent malicious behaviors without any information on users' reputation. According to the different properties of malicious behavior resistance by spectrum sensing and spectrum access, we employ joint spectrum sensing and access to optimally prevent the IMUs sensing falsification. The proposed malicious behavior resistance mechanism is shown to achieve almost the same performance as the ideal case with truthful sensing.","Sensors,
Resistance,
Joints,
Ethics,
Hazards,
Mobile computing,
Probability"
P-Q and P-V Control of Photovoltaic Generators in Distribution Systems,"In this paper, simultaneous control of active power and volt/var is explored with photovoltaic (PV) generators in distribution systems. The PV active power output can be controlled in the load-following mode when sufficient solar power is available to supply a local load, or the maximum power point tracking (MPPT) mode when a local load is large or injection to the system is allowed. Two selected control approaches, P-Q control in the load-following mode and P-V control in the MPPT mode, are investigated in this paper. The P-Q control is implemented with a relatively simple approach, while the P-V control demands an extra MPPT logic, which is solved based on a power balance between the dc and ac sides in a two-stage PV configuration. The control algorithms are tested with the IEEE 13-bus distribution feeder with various system conditions like the presence of multiple PV generators, imbalance, harmonics, and faults. The MATLAB and SimPowerSystems simulation results clearly demonstrate the capability of the proposed control in maintaining the P/V bus as either a P-Q or P-V bus depending on different applications.","Voltage control,
Solar panels,
Generators,
Photovoltaic systems,
Microgrids,
Maximum power point trackers,
Solar power generation"
Energy-Efficient Location and Activity-Aware On-Demand Mobile Distributed Sensing Platform for Sensing as a Service in IoT Clouds,"The Internet of Things (IoT) envisions billions of sensors deployed around us and connected to the Internet, where the mobile crowd sensing technologies are widely used to collect data in different contexts of the IoT paradigm. Due to the popularity of Big Data technologies, processing and storing large volumes of data have become easier than ever. However, large-scale data management tasks still require significant amounts of resources that can be expensive regardless of whether they are purchased or rented (e.g., pay-as-you-go infrastructure). Further, not everyone is interested in such large-scale data collection and analysis. More importantly, not everyone has the financial and computational resources to deal with such large volumes of data. Therefore, a timely need exists for a cloud-integrated mobile crowd sensing platform that is capable of capturing sensors data, on-demand, based on conditions enforced by the data consumers. In this paper, we propose a context-aware, specifically, location and activity-aware mobile sensing platform called context-aware mobile sensor data engine (C-MOSDEN) for the IoT domain. We evaluated the proposed platform using three real-world scenarios that highlight the importance of selective sensing. The computational effectiveness and efficiency of the proposed platform are investigated and are used to highlight the advantages of context-aware selective sensing.","Sensors,
Cloud computing,
Mobile communication,
Data collection,
Context awareness,
Internet of things,
Middleware"
Joint Search by Social and Spatial Proximity,"The diffusion of social networks introduces new challenges and opportunities for advanced services, especially so with their ongoing addition of location-based features. We show how applications like company and friend recommendation could significantly benefit from incorporating social and spatial proximity, and study a query type that captures these two-fold semantics. We develop highly scalable algorithms for its processing, and enhance them with elaborate optimizations. Finally, we use real social network data to empirically verify the efficiency and efficacy of our solutions.","Tin,
Social network services,
Distributed databases,
Euclidean distance,
Educational institutions,
Data structures,
Indexes"
An Opportunistic Relay Protocol With Dynamic Scheduling in Wireless Body Area Sensor Network,"Due to varying on-body channel conditions, transmission between a sensor node and a body-worn coordinator is vulnerable to poor channel conditions caused by body shadowing. One possible solution to this is the use of relays where direct transmission to the hub is not possible. The two-hop relay mechanism proposed in IEEE 802.15.6 standard can be divided into channel assessment, relaying node election, and data relaying processes. However, as these three processes are initiated at different time intervals, simulations suggest that channel conditions actually vary between processes, which leads to data relaying failure. In order to reduce the possibility of data relaying failure, a relay mechanism with predefined relaying nodes are introduced and evaluated against the relay mechanism proposed in IEEE 802.15.6 standard. A predefined relaying node will be active during the data relaying process even if it is not elected. Simulations show that the proposed relay mechanism is able to achieve 50% reduction in data relaying failure rate, which in turn improves the packet delivery rate (PDR). The proposed relay mechanism is evaluated in a superframe structure. Simulation shows that with the presence of the predefined relaying node, the network lifetime is extended by 8%. To further improve the PDR, direct transmission in the relaying process is supported, and a dynamic scheduling algorithm is proposed to optimize slot allocation in the superframe for all nodes. The proposed relay protocol achieves 21% improvements in network lifetime and 14% improvements in PDR with decreasing transmission powers from -10 to -15 dBm.","Relays,
IEEE 802.15 Standards,
Delays,
Sensors,
Wireless sensor networks,
Protocols,
Nominations and elections"
A survey of experimental evaluation in indoor localization research,"During the last decade, research in indoor localization and navigation has focused on techniques, protocols, and algorithms. The first International Conference on Indoor Positioning and Indoor Navigation (IPIN) was held in 2010. Since then, this annual conference showed the progress of research and technology. The variations of evaluation methods are significant in this field: they range from none, to extensive simulations, and real-world experiments under non-lab conditions. We look at the articles published in the proceedings of IPIN by IEEE Xplore from 2010 to 2014, and analyze the development of evaluation methods. We categorized 183 randomly selected papers, in respect to five different aspects. Namely: (1) the underlying system/technology in use, (2) the evaluation method for the proposed technique, (3) the method of ground truth data gathering, (4) the applied metrics, and (5) whether the authors establish a baseline for their work.",
Weighted Tanimoto Extreme Learning Machine with Case Study in Drug Discovery,"Machine learning methods are becoming more and more popular in the field of computer-aided drug design. The specific data characteristic, including sparse, binary representation as well as noisy, imbalanced datasets, presents a challenging binary classification problem. Currently, two of the most successful models in such tasks are the Support Vector Machine (SVM) and Random Forest (RF). In this paper, we introduce a Weighted Tanimoto Extreme Learning Machine (T-WELM), an extremely simple and fast method for predicting chemical compound biological activity and possibly other data with discrete, binary representation. We show some theoretical properties of the proposed model including the ability to learn arbitrary sets of examples. Further analysis shows numerous advantages of T-WELM over SVMs, RFs and traditional Extreme Learning Machines (ELM) in this particular task. Experiments performed on 40 large datasets of thousands of chemical compounds show that T-WELMs achieve much better classification results and are at the same time faster in terms of both training time and further classification than both ELM models and other state-of-the-art methods in the field.","Machine learning,
Compounds,
Design automation,
Fingerprint recognition,
Drugs,
Biological system modeling,
Computational modeling"
IoT-based occupancy monitoring techniques for energy-efficient smart buildings,"With the proliferation of Internet of Things (IoT) devices such as smartphones, sensors, cameras, and RFIDs, it is possible to collect massive amount of data for localization and tracking of people within commercial buildings. Enabled by such occupancy monitoring capabilities, there are extensive opportunities for improving the energy consumption of buildings via smart HVAC control. In this respect, the major challenges we envision are 1) to achieve occupancy monitoring in a minimally intrusive way, e.g., using the existing infrastructure in the buildings and not requiring installation of any apps in the users' smart devices, and 2) to develop effective data fusion techniques for improving occupancy monitoring accuracy using a multitude of sources. This paper surveys the existing works on occupancy monitoring and multi-modal data fusion techniques for smart commercial buildings. The goal is to lay down a framework for future research to exploit the spatio-temporal data obtained from one or more of various IoT devices such as temperature sensors, surveillance cameras, and RFID tags that may be already in use in the buildings. A comparative analysis of existing approaches and future predictions for research challenges are also provided.","Buildings,
Monitoring,
Sensors,
IEEE 802.11 Standards,
Accuracy,
Data integration,
Cameras"
Wavelet-Based Classification of Hyperspectral Images Using Extended Morphological Profiles on Graphics Processing Units,"The availability of graphics processing units (GPUs) provides a low-cost solution to real-time processing, which may benefit many remote sensing applications. In this paper, a spectral-spatial classification scheme for hyperspectral images is specifically adapted for computing on GPUs. It is based on wavelets, extended morphological profiles (EMPs), and support vector machine (SVM). Additionally, a preprocessing stage is used to remove noise in the original hyperspectral image. The local computation of the techniques used in the proposed scheme makes them particularly suitable for parallel processing by blocks of threads in the GPU. Moreover, a block-asynchronous updating process is applied to the EMP to speedup the morphological reconstruction. The results over different hyperspectral images show that the execution can be speeded up to 8.2× compared to an efficient OpenMP parallel implementation, achieving real-time hyperspectral image classification while maintaining the high classification accuracy values of the original classification scheme.","Graphics processing units,
Instruction sets,
Kernel,
Support vector machines,
Hyperspectral imaging,
Image reconstruction,
Vectors"
Revenue Maximization with Optimal Capacity Control in Infrastructure as a Service Cloud Markets,"Infrastructure-as-a-Service cloud providers offer diverse purchasing options and pricing plans, namely on-demand, reservation, and spot market plans. This allows them to efficiently target a variety of customer groups with distinct preferences and to generate more revenue accordingly. An important consequence of this diversification however, is that it introduces a non-trivial optimization problem related to the allocation of the provider's available data center capacity to each pricing plan. The complexity of the problem follows from the different levels of revenue generated per unit of capacity sold, and the different commitments consumers and providers make when resources are allocated under a given plan. In this work, we address a novel problem of maximizing revenue through an optimization of capacity allocation to each pricing plan by means of admission control for reservation contracts, in a setting where aforementioned plans are jointly offered to customers. We devise both an optimal algorithm based on a stochastic dynamic programming formulation and two heuristics that trade-off optimality and computational complexity. Our evaluation, which relies on an adaptation of a large-scale real-world workload trace of Google, shows that our algorithms can significantly increase revenue compared to an allocation without capacity control given that sufficient resource contention is present in the system. In addition, we show that our heuristics effectively allow for online decision making and quantify the revenue loss caused by the assumptions made to render the optimization problem tractable.","Pricing,
Cloud computing,
Capacity planning,
Contracts,
Heuristic algorithms,
Stochastic processes,
Dynamic programming"
"Synthesis of Monitor-Based Liveness-Enforcing Supervisors for \rm{S}^{3}
PR With {\boldsymbol{\xi }}
-Resources","Deadlocks are a rather undesirable phenomenon in flexible manufacturing systems (FMSs). This work, by adding monitors, develops a deadlock prevention policy for FMSs that can be modeled by a class of Petri nets called α-S3PR with i-resources. First, an algorithm is presented to reduce an S3PR via a i-resource. Based on the algorithm, i-resources in α-S3PRs are classified into two types: 1) A-ξ-resources and 2) B-ξ-resources. Next, for an α-S3PR with only B-ξ-resources, it is proved that a maximally permissive liveness-enforcing supervisor can be designed by controlling all emptied strict minimal siphons. For an α-S3PR containing A-ξ-resources, a liveness-enforcing supervisor can be designed by iteratively reducing the net via A-ξ-resources and adding the corresponding monitors. Finally, a deadlock prevention algorithm for α-S3PRs is presented. Two FMS examples are used to illustrate its application. Its comparison results with other state-of-the-art deadlock prevention policies validate its overall advantages in terms of computational complexity, structural complexity, and behavior permissiveness.","System recovery,
Monitoring,
Control systems,
Algorithm design and analysis,
Petri nets,
Complexity theory,
Cybernetics"
Towards a model of privacy and security for smart homes,"The domain of smart home environments is viewed as a key element of the future Internet, and many homes are becoming “smarter” by using Internet of Things (IoT) technology to improve home security, energy efficiency and comfort. At the same time, enforcing privacy in IoT environments has been identified as one of the main barriers for realizing the vision of the smart home. Based on the results of a risk analysis of a smart home automation system developed in collaboration with leading industrial actors, we outline the first steps towards a general model of privacy and security for smart homes. As such, it is envisioned as support for enforcing system security and enhancing user privacy, and it can thus help to further realize the potential in smart home environments.","Security,
Smart homes,
Privacy,
Risk analysis,
Software,
Logic gates,
Automation"
Learning Fingerprint Reconstruction: From Minutiae to Image,"The set of minutia points is considered to be the most distinctive feature for fingerprint representation and is widely used in fingerprint matching. It was believed that the minutiae set does not contain sufficient information to reconstruct the original fingerprint image from which minutiae were extracted. However, recent studies have shown that it is indeed possible to reconstruct fingerprint images from their minutiae representations. Reconstruction techniques demonstrate the need for securing fingerprint templates, improving the template interoperability, and improving fingerprint synthesis. But, there is still a large gap between the matching performance obtained from original fingerprint images and their corresponding reconstructed fingerprint images. In this paper, the prior knowledge about fingerprint ridge structures is encoded in terms of orientation patch and continuous phase patch dictionaries to improve the fingerprint reconstruction. The orientation patch dictionary is used to reconstruct the orientation field from minutiae, while the continuous phase patch dictionary is used to reconstruct the ridge pattern. Experimental results on three public domain databases (FVC2002 DB1_A, FVC2002 DB2_A, and NIST SD4) demonstrate that the proposed reconstruction algorithm outperforms the state-of-the-art reconstruction algorithms in terms of both: 1) spurious minutiae and 2) matching performance with respect to type-I attack (matching the reconstructed fingerprint against the same impression from which minutiae set was extracted) and type-II attack (matching the reconstructed fingerprint against a different impression of the same finger).","Image reconstruction,
NIST,
Reconstruction algorithms,
Gray-scale,
Fingerprint recognition"
A 240 GHz Fully Integrated Wideband QPSK Transmitter in 65 nm CMOS,"In this paper, a 240 GHz 16 Gbps QPSK transmitter is demonstrated in 65 nm bulk CMOS process. The transmitter chain employs an 80 GHz local oscillator and a modulator to generate the data that is amplified by a class-E switching power amplifier. The amplified signal then drives the 240 GHz tripler to generate the required modulated data. By using on-chip slotted loop antennas, the transmitter achieves an EIRP of 1 dBm. A maximum data rate of 16 Gbps is achieved with a transmitter efficiency of 14 pJ/bit.","Transmitters,
Frequency modulation,
Binary phase shift keying,
Phase noise"
Comb-Push Ultrasound Shear Elastography (CUSE) for Evaluation of Thyroid Nodules: Preliminary In Vivo Results,"In clinical practice, an overwhelming majority of biopsied thyroid nodules are benign. Therefore, there is a need for a complementary and noninvasive imaging tool to provide clinically relevant diagnostic information about thyroid nodules to reduce the rate of unnecessary biopsies. The goal of this study was to evaluate the feasibility of utilizing comb-push ultrasound shear elastography (CUSE) to measure the mechanical properties (i.e., stiffness) of thyroid nodules and use this information to help classify nodules as benign or malignant. CUSE is a fast and robust 2-D shear elastography technique in which multiple laterally distributed acoustic radiation force beams are utilized simultaneously to produce shear waves. Unlike other shear elasticity imaging modalities, CUSE does not suffer from limited field of view (FOV) due to shear wave attenuation and can provide a large FOV at high frame rates. To evaluate the utility of CUSE in thyroid imaging, a preliminary study was performed on a group of five healthy volunteers and 10 patients with ultrasound-detected thyroid nodules prior to fine needle aspiration biopsy. The measured shear wave speeds in normal thyroid tissue and thyroid nodules were converted to Young's modulus (E), indicating a measure of tissue stiffness. Our results indicate an increase in E for thyroid nodules compared to normal thyroid tissue. This increase was significantly higher in malignant nodules compared to benign. The Young's modulus in normal thyroid tissue, benign and malignant nodules were found to be 23.2 ±8.29 kPa, 91.2±34.8 kPa, and 173.0±17.1 kPa, respectively. Results of this study suggest the utility of CUSE in differentiating between benign and malignant thyroid nodules.","Phantoms,
Cancer,
Ultrasonic imaging,
Elasticity,
In vivo"
Screening in Ultrashort (5 nm) Channel MoS2 Transistors: A Full-Band Quantum Transport Study,Full-band ballistic quantum transport calculations were used to study the screening effects in ultrashort-channel few-layer MoS2 transistors. A large density of states resulted in small screening lengths while inhibiting direct source-to-drain tunneling. Short-channel effects were observed even for the structurally confined 2-D transistors resulting in degraded electrostatic control. Electron confinement effects were also observed in the OFF-state in multilayered devices.,"Transistors,
Logic gates,
Photonic band gap,
Electric potential,
Electrostatics,
Performance evaluation,
Doping"
A Model for Wind Turbines Placement Within a Distribution Network Acquisition Market,"This paper proposes an innovative exhaustive search method for the optimal placement of wind turbines (WTs) in electrical distribution systems taking into account wind speed and load demand uncertainty, and the variability of electrical energy prices within a distribution network operator (DNO) acquisition market environment. The method combines Monte Carlo simulation (MCS) and market-based optimal power flow (OPF) to maximize the net present value (NPV) related to the investment made by WTs' developers over a planning horizon. In particular, the MCS data feed the market-based OPF problem with inter-temporal constraints in order to find the most convenient WTs allocation and priority on the network, based on distribution-locational marginal prices (D-LMPs) in a competitive electricity market. The effectiveness of the proposed method is demonstrated with an 84-bus 11.4-kV radial distribution system.","Wind speed,
Planning,
Investment,
Resource management,
Generators,
Load modeling,
Stochastic processes"
Utilizing Image Scales Towards Totally Training Free Blind Image Quality Assessment,"A new approach to blind image quality assessment (BIQA), requiring no training, is proposed in this paper. The approach is named as blind image quality evaluator based on scales and works by evaluating the global difference of the query image analyzed at different scales with the query image at original resolution. The approach is based on the ability of the natural images to exhibit redundant information over various scales. A distorted image is considered as a deviation from the natural image and bereft of the redundancy present in the original image. The similarity of the original resolution image with its down-scaled version will decrease more when the image is distorted more. Therefore, the dissimilarities of an image with its low-resolution versions are cumulated in the proposed method. We dissolve the query image into its scale-space and measure the global dissimilarity with the co-occurrence histograms of the original and its scaled images. These scaled images are the low pass versions of the original image. The dissimilarity, called low pass error, is calculated by comparing the low pass versions across scales with the original image. The high pass versions of the image in different scales are obtained by Wavelet decomposition and their dissimilarity from the original image is also calculated. This dissimilarity, called high pass error, is computed with the variance and gradient histograms and weighted by the contrast sensitivity function to make it perceptually effective. These two kinds of dissimilarities are combined together to derive the quality score of the query image. This method requires absolutely no training with the distorted image, pristine images, or subjective human scores to predict the perceptual quality but uses the intrinsic global change of the query image across scales. The performance of the proposed method is evaluated across six publicly available databases and found to be competitive with the state-of-the-art techniques.",
Multiple-Inputs and Multiple-Outputs Wireless Power Combining and Delivering Systems,"In this paper, we investigated the effect of power combining and delivering in multiinput and multioutput wireless energy transmission systems, which consist of more than one transmitter antennas as sources and more than one receiver antennas as loads and repeaters. Theoretical expressions were developed to model the system operation that can be in a large-scale wireless energy network architecture. System characteristics, such as power transfer between antennas, power losses induced in each antenna, wireless efficiency, coil misalignment, and power fluctuation due to the loss of frequency synchronization were examined by theory and verified with experiments. Measurement results matched well with the theory demonstrating the feasibility of combining and delivering power with high efficiencies in large-scale wireless energy transmission systems.","Wireless communication,
Inductance,
Transmitters,
Receivers,
MIMO,
Resistance,
Resonant frequency"
Speech emotion recognition with acoustic and lexical features,"In this paper we explore one of the key aspects in building an emotion recognition system: generating suitable feature representations. We generate feature representations from both acoustic and lexical levels. At the acoustic level, we first extract low-level features such as intensity, F0, jitter, shimmer and spectral contours etc. We then generate different acoustic feature representations based on these low-level features, including statistics over these features, a new representation derived from a set of low-level acoustic codewords, and a new representation from Gaussian Supervectors. At the lexical level, we propose a new feature representation named emotion vector (eVector). We also use the traditional Bag-of-Words (BoW) feature. We apply these feature representations for emotion recognition and compare their performance on the USC-IEMOCAP database. We also combine these different feature representations via early fusion and late fusion. Our experimental results show that late fusion of both acoustic and lexical features achieves four-class emotion recognition accuracy of 69.2%.",
An Improved Direct Adaptive Fuzzy Controller of an Uncertain PMSM for Web-Based E-Service Systems,"Web-based systems have enjoyed tremendous growth in both theory and applications. They are highly visible and influential realizations of user-oriented technology supporting numerous human pursuits realized across the e-service. In this paper, we focus on web-based e-service systems for the permanent magnet synchronous motor (PMSM) remote control. These systems can provide web services for updating factors and the fuzzy law of Takagi-Sugeno fuzzy, when the PMSM devices are required. This paper designs the controller of the PMSM with uncertain inertia and friction factors working under load noise in Web-based e-service systems. This controller is based on rotor field-oriented control (RFOC) structures, internal model control (IMC), and improved direct adaptive fuzzy (IDAF). In order to enhance the transient quality for the case of uncertain inertia and friction factors, we use the IDAF algorithm for the outer loop (speed loop). The IDAF is designed based on the direct adaptive fuzzy algorithm combined with the G-Fuzzy system for adjusting online updating adaption factors. The essence of IDAF is a self-learning and self-adaption system with enhanced adaptive ability through the G-Fuzzy system. For the inner loop (current loop), an improved IMC (IIMC) structure is proposed to reduce the effect of load noise. The IIMC combines the tradition IMC and a speed feedback loop to enhance the antiload noise ability of the system. The difference between our control structure and the traditional control structure is that the system could automatically realize antiload noise in the inner loop before adjusting the speed in the outer loop. This will create really high performances for PMSM control systems. We also demonstrate the effect of this control algorithm on PMSM-RFOC system control. The extensive simulation results demonstrate that the current response satisfies the condition of ability and settling time. Especially, the antiload noise ability and transient quality of the system are controlled independently. Thus, it is a solid foundation upon which to develop a high-quality PMSM electric drive in the e-service.","Noise,
Mathematical model,
Torque,
Adaptive systems,
Control systems,
Transient analysis,
Transfer functions"
On Summarization and Timeline Generation for Evolutionary Tweet Streams,"Short-text messages such as tweets are being created and shared at an unprecedented rate. Tweets, in their raw form, while being informative, can also be overwhelming. For both end-users and data analysts, it is a nightmare to plow through millions of tweets which contain enormous amount of noise and redundancy. In this paper, we propose a novel continuous summarization framework called Sumblr to alleviate the problem. In contrast to the traditional document summarization methods which focus on static and small-scale data set, Sumblr is designed to deal with dynamic, fast arriving, and large-scale tweet streams. Our proposed framework consists of three major components. First, we propose an online tweet stream clustering algorithm to cluster tweets and maintain distilled statistics in a data structure called tweet cluster vector (TCV). Second, we develop a TCV-Rank summarization technique for generating online summaries and historical summaries of arbitrary time durations. Third, we design an effective topic evolution detection method, which monitors summary-based/volume-based variations to produce timelines automatically from tweet streams. Our experiments on large-scale real tweets demonstrate the efficiency and effectiveness of our framework.","Clustering algorithms,
Vectors,
Algorithm design and analysis,
Data structures,
Monitoring,
Twitter,
Context"
Location-based channel estimation and pilot assignment for massive MIMO systems,"In this paper, a location-based channel estimation algorithm is proposed for massive multi-input multi-output (MIMO) systems. By utilizing the property of the steering vector, a fast Fourier transform (FFT)-based post-processing is introduced after the conventional pilot-aided channel estimation. Under the condition that different users with the same pilot sequence have non-overlapping angle-of-arrivals (AOAs), the proposed channel estimation algorithm is capable of distinguishing these users effectively. To cooperate with the location-based channel estimation, a pilot assignment algorithm is also proposed to ensure that the users in different cells using the same pilot sequence have different AOAs at base station. The simulation results demonstrate that the proposed scheme can reduce the inter-cell interference caused by the reuse of the pilot sequence and thus improves the overall system performance significantly.","Channel estimation,
MIMO,
Interference,
Antennas,
Signal processing algorithms,
Partial transmit sequences,
Contamination"
Design of a Wideband Dual-Polarization Full-Corporate Waveguide Feed Antenna Array,"A wideband and dual-polarization antenna array with high efficiency and high isolation is proposed. In order to achieve the desired performance, a wideband radiating element and a full-corporate waveguide feed network are employed in the design. In particular, E-plane waveguides are utilized for the feed-network configuration so as to suppress wave leakage between adjacent layers when the antenna is fabricated via conventional machining techniques. The operational mechanism is presented and a 16 × 16 antenna array is tested for verification. Experimental results show that the bandwidths of VSWR <; 2.0 for both of the polarizations are about 17.1% (12.45-14.78 GHz) and the isolation between the two polarization ports is better than 39.5 dB. In addition, more than 70% antenna efficiency with higher than 29.4 dBi gain is achieved over the operational bandwidth.",
A New Compact High-Power Microwave Phase Shifter,"A new compact low-loss fast phase-shift high-power microwave (HPM) phase shifter (PS) is proposed, designed, and cold and high-power tested. Firstly, based on solving the scattering matrix and eigenvectors, we design a novel HPM dual circular polarizer, and then a dumbbell-like metal plug driven by a high-speed servomotor is used to slide a short circuit along the dual circular polarized port to adjust the output RF phase, which varies 180° by moving the plug with a quarter of the guided wavelength. The X-band PS has a total length of 9.5 cm and a power capacity achieved 300 MW at 30-ns HPM pulse. A fast phase shift of 310° was achieved within 0.1 s in test, a high precision of phase shift 1° can be realized, and the tested insertion loss was <; 0.15 dB.","Ports (Computers),
Plugs,
Scattering,
Rectangular waveguides,
Microwave circuits,
Microwave communication,
Microwave FET integrated circuits"
A Novel Scheduling Algorithm for Supporting Periodic Queries in Broadcast Environments,"Being a proven efficient approach to answering queries that have common data needs, data broadcast has received much attention in the past decade, especially for dynamic and large-scale data dissemination. An important class of emerging data broadcast applications must monitor multiple data items continuously in order to enable data-driven decision making. For such applications, an important problem that must be addressed is how to disseminate data to periodic continuous queries so that all the requests can be satisfied while the bandwidth utilization is minimized. To our best knowledge, the only known work on this topic is the RM-UO algorithm proposed in the work of Huang et al. (2012). However, the RM-UO algorithm simply utilizes the Sr algorithm introduced in the work of Han et al. (1996) to transform the original queries into 2-harmonic tasks, which would lead to a considerable waste of available bandwidth. In this paper, based on the observation that some queries can be merged to save bandwidth consumption, we propose two merging polices namely Multiple Query Merging (MQM) and Redundant Query Merging (RQM), and show that both can lead to notable bandwidth savings. Further, to disseminate data to periodic continuous queries, we implement a unified scheduling algorithm called UM, which combines both MQM and RQM. Extensive experiments have been conducted to compare our UM algorithm with RM-UO, and the results show that UM outperforms RM-UO considerably in terms of wireless bandwidth consumption and query service ratio.",
Genetic Algorithm Aided Proportional Fair Resource Allocation in Multicast OFDM Systems,"The next-generation wireless communication networks are envisioned to offer many multimedia services such as audio/video clips, mobile TV, web browsing, video conference, etc., with diverse quality of service (QoS) requirements. Multicasting/broadcasting has been recognized as an emerging and enabling technique for such multimedia transmissions over wireless networks. By employing multicast transmission, a base station can transmit the same data content to several groups of users requiring flexible QoS. In this paper, we investigate subchannel and power allocation problems in an OFDM-based wireless multicast system. With the goal of maximizing the total system capacity, a low complexity, novel genetic algorithm aided efficient subchannel allocation scheme taking into account the constraints of total available bandwidth, proportional data rate fairness and total transmit power budget at the base station is proposed. The subchannel allocation is then followed by optimal power allocation. Unlike previous work where either no fairness or fairness based on number of subchannels allocated to the different groups was considered, we incorporate a set of system parameters in the problem formulation such that the ratio of the group data rates strictly follow the set of system parameters after resource allocation. Simulation results show that the proposed method obtains higher sum capacities while maintaining proportional data rate fairness among different multicast groups, without being awfully complex.","Resource management,
Genetic algorithms,
Biological cells,
Wireless communication,
Optimization,
Sociology,
Statistics"
Reconstruction of Ultrasound RF Echoes Modeled as Stable Random Variables,"This paper introduces a new technique for reconstruction of biomedical ultrasound images from simulated compressive measurements, based on modeling data with stable distributions. The proposed algorithm exploits two types of prior information: on one hand, our proposed approach is based on the observation that ultrasound RF echoes are best characterized statistically by alpha-stable distributions. On the other hand, through knowledge of the acquisition process, the support of the RF echoes in the Fourier domain can be easily inferred. Together, these two facts form the basis of an ℓp minimization approach that employs the iteratively reweighted least squares (IRLS) algorithm, but in which the parameter p is judiciously chosen, by relating it to the characteristic exponent of the underlying alpha-stable distributed data. We demonstrate, through Monte Carlo simulations, that the optimal value of the parameter p is just below that of the characteristic exponent α, which we estimate from the data. Our reconstruction results show that the proposed algorithm outperforms previously proposed reconstruction techniques, both visually and in terms of two objective evaluation measures.","Ultrasonic imaging,
Radio frequency,
Image reconstruction,
Imaging,
Minimization,
Frequency-domain analysis,
Image coding"
Lowering HAMR Near-Field Transducer Temperature via Inverse Electromagnetic Design,"Heat-assisted magnetic recording (HAMR) allows for data writing in hard disks beyond 1 Tb/in2 areal density, by temporarily heating the area of a single bit to its Curie temperature. The metallic optical antenna or near-field transducer (NFT), used to apply the nanoscale heating to the media, may self-heat by several hundreds of degrees. With the NFT reaching such extreme temperatures, demonstrations of HAMR technology experience write-head lifetimes that are orders of magnitude less than that required for a commercial product. Hence, heating of the NFT is of upmost importance. In this paper, we first derive fundamental limits on the temperature ratio NFT/Media to drive NFT design choices for low-temperature operation. Next, we employ inverse electromagnetic design software, which solves for unexpected geometries of the NFT and waveguide. We present computationally generated designs for the waveguide feeding the NFT that offer a 50% reduction in NFT self-heating (~220 °C) compared with typical industry designs.","Media,
Heat-assisted magnetic recording,
Electromagnetics,
Optical waveguides,
Optimization,
Heating"
"Semantic description, discovery and integration for the Internet of Things","To share and publish the domain knowledge of IoT objects, the development of a semantic IoT model based directory system that manages meta-data and relationships of IoT objects is required. Many researches focus on static relationships between IoT objects. However, because complex relationships between various resources change with time in an IoT environment, an efficient method for updating the meta-data is required. Thus, we propose an IoT-DS as the IoT directory that supports semantic description, discovery, and integration of IoT objects. Firstly, we introduce a semantic IoT component model to establish a shared conceptualization. Secondly, we present general cases of relationships to efficiently interact between IoT-DS and IoT objects. Thirdly, we construct IoT-DS as a Web portal. Finally, we verify in our evaluation study that the query processing time and communication workload imposed by the proposed approach are reduced.",Gold
EcoSky: Reducing vehicular environmental impact through eco-routing,"Reduction in greenhouse gas emissions from transportation attracts increasing interest from governments, fleet managers, and individual drivers. Eco-routing, which enables drivers to use eco-friendly routes, is a simple and effective approach to reducing emissions from transportation. We present EcoSky, a system that annotates edges of a road network with time dependent and uncertain eco-weights using GPS data and that supports different types of eco-routing. Basic eco-routing returns the most eco-friendly routes; skyline eco-routing takes into account not only fuel consumption but also travel time and distance when computing eco-routes; and personalized eco-routing considers each driver's past behavior and accordingly suggests different routes to different drivers.","Fuels,
Roads,
Global Positioning System,
Vehicles,
Routing,
Random variables,
Three-dimensional displays"
Inverse depth for accurate photometric and geometric error minimisation in RGB-D dense visual odometry,"In this paper we present a dense visual odometry system for RGB-D cameras performing both photometric and geometric error minimisation to estimate the camera motion between frames. Contrary to most works in the literature, we parametrise the geometric error by the inverse depth instead of the depth, which translates into a better fit of the distribution of the geometric error to the used robust cost functions. We also provide a unified evaluation under the same framework of different estimators and ways of computing the scale of the residuals which can be found spread along the related literature. For the comparison of our approach with state-of-the-art approaches we use the popular dataset from the TUM for RGB-D benchmarking. Our approach shows to be competitive with state-of-the-art methods in terms of drift in meters per second, even compared to methods performing loop closure too. When comparing to approaches performing pure odometry like ours, our method outperforms them in the majority of the tested datasets. Additionally we show that our approach is able to work in real time and we provide a qualitative evaluation on our own sequences showing a low drift in the 3D reconstructions.","Cameras,
Visualization,
Maximum likelihood estimation,
Cost function,
Three-dimensional displays"
Learning the spatial semantics of manipulation actions through preposition grounding,"In this paper, we introduce an abstract representation for manipulation actions that is based on the evolution of the spatial relations between involved objects. Object tracking in RGBD streams enables straightforward and intuitive ways to model spatial relations in 3D space. Reasoning in 3D overcomes many of the limitations of similar previous approaches, while providing significant flexibility in the desired level of abstraction. At each frame of a manipulation video, we evaluate a number of spatial predicates for all object pairs and treat the resulting set of sequences (Predicate Vector Sequences, PVS) as an action descriptor. As part of our representation, we introduce a symmetric, time-normalized pairwise distance measure that relies on finding an optimal object correspondence between two actions. We experimentally evaluate the method on the classification of various manipulation actions in video, performed at different speeds and timings and involving different objects. The results demonstrate that the proposed representation is remarkably descriptive of the high-level manipulation semantics.","Three-dimensional displays,
Semantics,
Cognition,
Robot sensing systems,
Radio frequency,
Grounding"
ENF-Based Region-of-Recording Identification for Media Signals,"The electric network frequency (ENF) is a signature of power distribution networks that can be captured by multimedia signals recorded near electrical activities. This has led to the emergence of multiple forensic applications based on the use of ENF signals. Examples of such applications include validating the time-of-recording of an ENF-containing multimedia signal or estimating its recording location based on concurrent reference signals from power grids. In this paper, we examine a novel ENF-based application that infers the power grid in which the ENF-containing multimedia signal was recorded without relying on the availability of concurrent power references. We investigate features based on the statistical differences in ENF variations between different power grids to serve as signatures for the region-of-recording of the media signal. We use these features in a multiclass machine learning implementation that is able to identify the grid-of-recording of a signal with high accuracy. In addition, we explore techniques for building multiconditional learning systems that can adapt to changes in the noise environment between the training and testing data.","Feature extraction,
Testing,
Power grids,
Training,
Support vector machines,
Multimedia communication,
Forensics"
Boundary Detection Using Double-Opponency and Spatial Sparseness Constraint,"Brightness and color are two basic visual features integrated by the human visual system (HVS) to gain a better understanding of color natural scenes. Aiming to combine these two cues to maximize the reliability of boundary detection in natural scenes, we propose a new framework based on the color-opponent mechanisms of a certain type of color-sensitive double-opponent (DO) cells in the primary visual cortex (V1) of HVS. This type of DO cells has oriented receptive field with both chromatically and spatially opponent structure. The proposed framework is a feedforward hierarchical model, which has direct counterpart to the color-opponent mechanisms involved in from the retina to V1. In addition, we employ the spatial sparseness constraint (SSC) of neural responses to further suppress the unwanted edges of texture elements. Experimental results show that the DO cells we modeled can flexibly capture both the structured chromatic and achromatic boundaries of salient objects in complex scenes when the cone inputs to DO cells are unbalanced. Meanwhile, the SSC operator further improves the performance by suppressing redundant texture edges. With competitive contour detection accuracy, the proposed model has the additional advantage of quite simple implementation with low computational cost.",
Planar Hexagonal Meshing for Architecture,"Mesh surfaces with planar hexagonal faces, what we refer to as PH meshes, offer an elegant way of paneling freeform architectural surfaces due to their node simplicity (i.e., valence-3 nodes) and naturally appealing layout. We investigate PH meshes to understand how the shape, size, and pattern of PH faces are constrained by surface geometry. This understanding enables us to develop an effective method for paneling freeform architectural surfaces with PH meshes. Our method first constructs an ideal triangulation of a given smooth surface, guided by surface geometry. We show that such an ideal triangulation leads to a Dupin-regular PH mesh via tangent duality on the surface. We have developed several novel and effective techniques for improving undesirable mesh layouts caused by singular behaviors of surface curvature. We compute support structures associated with PH meshes, including exact vertex offsets and approximate edge offsets, as demanded in panel manufacturing. The efficacy of our method is validated by a number of architectural examples.","Shape,
Geometry,
Approximation methods,
Optimization,
Layout,
Indexes,
Fabrication"
Quality-Aware Target Coverage in Energy Harvesting Sensor Networks,"Sensing coverage is a fundamental problem in wireless sensor networks for event detection, environment monitoring, and surveillance purposes. In this paper, we study the sensing coverage problem in an energy harvesting sensor network deployed for monitoring a set of targets for a given monitoring period, where sensors are powered by renewable energy sources and operate in duty-cycle mode, for which we first introduce a new coverage quality metric to measure the coverage quality within two different time scales. We then formulate a novel coverage quality maximization problem that considers both sensing coverage quality and network connectivity that consists of active sensors and the base station. Due to the NP-hardness of the problem, we instead devise efficient centralized and distributed algorithms for the problem, assuming that the harvesting energy prediction at each sensor is accurate during the entire monitoring period. Otherwise, we propose an adaptive framework to deal with energy prediction fluctuations, under which we show that the proposed centralized and distributed algorithms are still applicable. We finally evaluate the performance of the proposed algorithms through experimental simulations. Experimental results demonstrate that the proposed solutions are promising.","Monitoring,
Base stations,
Sensors,
Energy harvesting,
Measurement,
Vegetation,
Renewable energy sources"
Windowed DMD as a microtexture descriptor for finger vein counter-spoofing in biometrics,"Recent studies have shown that it is possible to attack a finger vein (FV) based biometric system using printed materials. In this study, we propose a novel method to detect spoofing of static finger vein images using Windowed Dynamic mode decomposition (W-DMD). This is an atemporal variant of the recently proposed Dynamic Mode Decomposition for image sequences. The proposed method achieves better results when compared to established methods such as local binary patterns (LBP), discrete wavelet transforms (DWT), histogram of gradients (HoG), and filter methods such as range-filters, standard deviation filters (STD) and entropy filters, when using SVM with a minimum intersection kernel. The overall pipeline which consists ofW-DMD and SVM, proves to be efficient, and convenient to use, given the absence of additional parameter tuning requirements. The effectiveness of our methodology is demonstrated using FV-Spoofing-Attack database which is publicly available. Our test results show that W-DMD can successfully detect printed finger vein images because they contain micro-level artefacts that not only differ in quality but also in light reflection properties compared to valid/live finger vein images.","Veins,
Biometrics (access control),
Discrete wavelet transforms,
Feature extraction,
Discrete cosine transforms,
Pipelines,
Authentication"
A Fast Algorithm to Compute Precise Type-2 Centroids for Real-Time Control Applications,"An interval type-2 fuzzy set (IT2 FS) is characterized by its upper and lower membership functions containing all possible embedded fuzzy sets, which together is referred to as the footprint of uncertainty (FOU). The FOU results in a span of uncertainty measured in the defuzzified space and is determined by the positional difference of the centroids of all the embedded fuzzy sets taken together. This paper provides a closed-form formula to evaluate the span of uncertainty of an IT2 FS. The closed-form formula offers a precise measurement of the degree of uncertainty in an IT2 FS with a runtime complexity less than that of the classical iterative Karnik-Mendel algorithm and other formulations employing the iterative Newton-Raphson algorithm. This paper also demonstrates a real-time control application using the proposed closed-form formula of centroids with reduced root mean square error and computational overhead than those of the existing methods. Computer simulations for this real-time control application indicate that parallel realization of the IT2 defuzzification outperforms its competitors with respect to maximum overshoot even at high sampling rates. Furthermore, in the presence of measurement noise in system (plant) states, the proposed IT2 FS based scheme outperforms its type-1 counterpart with respect to peak overshoot and root mean square error in plant response.","Equations,
Uncertainty,
Real-time systems,
Fuzzy sets,
Measurement uncertainty,
Pragmatics,
Cybernetics"
A cost based approach for a Crane Assignment and Scheduling Problem,"Different methods are used to address Quay Crane Assignment and Scheduling Problems (QCASP). In current literature often the unloading time is used to optimize QCASPs. However, this approach neglects the value of the vessel's freight. This paper therefore uses a cost based approach to optimize container terminal operations, which allows the model to focus on two objectives. The first objective is to show the impact of varying freight lead time costs on the priority of vessels and consequently the Quay Crane (QC) assignment and scheduling. The second objective is to implement adjustable QC operation costs and working rate and show the impact of particular adjustments. The model results show vessel prioritization based on the value of the vessel's freight. The variation in crane operation cost only impacts the assignment and scheduling in the occurrence of high crane operating costs relative to the value of the vessel's freight.","Cranes,
Resource management,
Ports (Computers),
Containers,
Linear programming,
Mathematical model,
Transportation"
A High-Sensitivity Fully Passive Neurosensing System for Wireless Brain Signal Monitoring,"A high-sensitivity, fully passive neurosensing system is presented for wireless brain signal monitoring. The proposed system is able to detect very low-power brain-like signals, viz. as low as -82 dBm (50 μVpp) at fneuro > 1 kHz. It is also able to read emulated neural signals as low as -70 dBm (200 μVpp) at fneuro > 100 Hz. This is an improvement of up to 22 dB in sensitivity as compared with previously reported neural signals. The system is comprised of an implanted neurosensor and an exterior interrogator. The neurosensor receives an external carrier signal and mixes it with the neural signals prior to retransmitting to the interrogator. Of importance is that the implanted neurosensor is fully passive and does not require a battery nor rectifier/regulator but is concurrently wireless for unobtrusive neurosensing with minimal impact to the individual's activity. To achieve this remarkable high sensitivity, the sensing system employed: 1) a subharmonic mixer using an anti-parallel diode pair; 2) a pair of implanted/interrogator antennas with high transmission coefficient |S21|;and 3) a matching circuit between the implanted antenna and the mixer. This neurosensing system brings forward a new possibility of wireless neural signal detection using passive brain implants.","Mixers,
Antennas,
Wireless communication,
Wireless sensor networks,
Implants,
Harmonic analysis,
Antenna measurements"
User Verification Leveraging Gait Recognition for Smartphone Enabled Mobile Healthcare Systems,"The rapid deployment of sensing technology in smartphones and the explosion of their usage in people's daily lives provide users with the ability to collectively sense the world. This leads to a growing trend of mobile healthcare systems utilizing sensing data collected from smartphones with/without additional external sensors to analyze and understand people's physical and mental states. However, such healthcare systems are vulnerable to user spoofing, in which an adversary distributes his registered device to other users such that data collected from these users can be claimed as his own to obtain more healthcare benefits and undermine the successful operation of mobile healthcare systems. Existing mitigation approaches either only rely on a secret PIN number (which can not deal with colluded attacks) or require an explicit user action for verification. In this paper, we propose a user verification system leveraging unique gait patterns derived from acceleration readings to detect possible user spoofing in mobile healthcare systems. Our framework exploits the readily available accelerometers embedded within smartphones for user verification. Specifically, our user spoofing mitigation framework (which consists of three components, namely Step Cycle Identification, Step Cycle Interpolation, and Similarity Comparison) is used to extract gait patterns from run-time accelerometer measurements to perform robust user verification under various walking speeds. We show that our framework can be implemented in two ways: user-centric and server-centric, and it is robust to not only random but also mimic attacks. Our extensive experiments using over 3,000 smartphone-based traces with mobile phones placed on different body positions confirm the effectiveness of the proposed framework with users walking at various speeds. This strongly indicates the feasibility of using smartphone based low grade accelerometer to conduct gait recognition and facilitate effective user verification without active user cooperation.","Medical services,
Accelerometers,
Legged locomotion,
Sensors,
Mobile communication,
Feature extraction,
Robustness"
Aging Adaption in Integrated Circuits Using a Novel Built-In Sensor,"As process technology further scales, aging, noise and variations in integrated circuits (ICs) and systems become a major challenge to both the semiconductor and electronic design automation (EDA) industries, which may cause significantly increased mismatch between modeled and actual silicon behavior, and even IC failure in field. Therefore, the addition of accurate and low-cost on-chip sensors is of great value to reduce the mismatch and perform in-field measurements. This paper presents a novel standard-cell-based sensor for reliability analysis of digital ICs (called Radic), in order to better understand the characteristics of gate, functional path aging and process variations' impact on timing performance, and perform in-field aging measurements. The Radic sensor has been fabricated on two floating gate Freescale SoCs in very advanced technology. The measurement results demonstrate that the resolution can be better than 0.1 ps, and the accuracy is kept throughout aging/process variation. Additionally, a built-in aging adaption system based on Radic sensor is proposed to perform in-field aging adaption. Simulation results verify that, comparing with designs with fixed aging guardband, the proposed aging adaption system releases 80% of aging timing margin, saves silicon area by 1.02%-3.16% at most targeting frequencies, and prevents aging induced failure.","Aging,
Clocks,
Accuracy,
Semiconductor device measurement,
System-on-chip,
Logic gates,
Frequency measurement"
"Domain Wall Memory-Layout, Circuit and Synergistic Systems","Domain wall memory (DWM) is gaining significant attention for embedded cache application due to low standby power, excellent retention, and ability to store multiple bits per cell. Additionally, it provides fast access time, good endurance, and good retention. However, it suffers from poor write latency, shift latency, shift power, and write power. DWM is sequential in nature and latency of read/write operations depends on the offset of the bit from the read/write head. This paper investigates the circuit design challenges such as bitcell layout, head positioning, utilization factor of the nanowire, shift power, shift latency, and provides solutions to deal with these issues. A synergistic system is proposed by combining circuit techniques such as merged read/write heads (for compact layout), flipped-bitcell and shift gating (for shift power optimization), wordline strapping (for access latency), shift circuit design with two micro-architectural techniques: 1) segmented cache and 2) workload-aware dynamic shift and write current boosting to realize energy-efficient and robust DWM cache. Simulations show 3-33% performance and 1.2-14.4X power consumption improvement for cache segregation and 2.5-31% performance and 1.3-14.9X power enhancement for dynamic current boosting over a wide range of PARSEC benchmarks.","Transistors,
Metals,
Layout,
Random access memory,
Magnetic heads,
Boosting,
Routing"
Fine-grained recognition of abnormal behaviors for early detection of mild cognitive impairment,"According to the World Health Organization, the rate of people aged 60 or more is growing faster than any other age group in almost every country, and this trend is not going to change in a near future. Since senior citizens are at high risk of non communicable diseases requiring long-term care, this trend will challenge the sustainability of the entire health system. Pervasive computing can provide innovative methods and tools for early detecting the onset of health issues. In this paper we propose a novel method relying on medical models, provided by cognitive neuroscience researchers, describing abnormal activity routines that may indicate the onset of early symptoms of mild cognitive impairment. A non-intrusive sensor-based infrastructure acquires low-level data about the interaction of the individual with home appliances and furniture, as well as data from environmental sensors. Based on those data, a novel hybrid statistical-symbolical technique is used to detect first the activities being performed and then the abnormal aspects in carrying out those activities, which are communicated to the medical center. Differently from related works, our method can detect abnormal behaviors at a fine-grained level, thus providing an important tool to support the medical diagnosis. In order to evaluate our method we have developed a prototype of the system and acquired a large dataset of abnormal behaviors carried out in an instrumented smart home. Experimental results show that our technique has a high precision while generating a small number of false positives.","Sensors,
Medical diagnostic imaging,
Pervasive computing,
Senior citizens,
Computational modeling,
Instruments,
Monitoring"
Gateway Placement and Packet Routing for Multihop In-Vehicle Internet Access,"In-vehicle Internet access is one of the main applications of vehicular ad hoc networks (VANETs), which aims at providing the vehicle passengers with a low-cost access to the Internet via on-road gateways. This paper introduces a new strategy for deploying Internet gateways on the roads, together with a novel scheme for data packet routing, in order to allow a vehicle to access the Internet via multihop communications in a VANET. The gateway placement strategy is to minimize the total cost of gateway deployment, while ensuring that a vehicle can connect to an Internet gateway (using multihop communications) with a probability greater than a specified threshold. This cost-minimization problem is formulated using binary integer programming, and applied to a realistic city scenario, consisting of the roads around the University of Waterloo, Waterloo, ON, Canada. To the best of our knowledge, the proposed deployment strategy is the first study to address the probability of multihop connectivity among the vehicles and the deployed gateways. On the other hand, the developed packet routing scheme is based on a multichannel medium access control protocol, known as VeMAC, using time division multiple access. The performance of this cross-layer design is evaluated for a multichannel VANET in a highway scenario, mainly in terms of the end-to-end packet delivery delay. The end-to-end delay is calculated by modeling each relay vehicle as a queuing system, in which the packets are served in batches of no more than a specified maximum batch size. The proposed gateway placement and packet routing schemes represent a step toward providing reliable and ubiquitous in-vehicle Internet connectivity.","Vehicles,
Logic gates,
Economic indicators,
Relays,
Routing,
Delays,
Internet"
Parallel Marching-on-in-Degree Solver of Time-Domain Combined Field Integral Equation for Bodies of Revolution Accelerated by MLACA,"Time-domain combined field integral equation (TD-CFIE) for bodies of revolution (BORs) is solved by marching-on-in-degree (MOD) method. A multilevel partitioning is adopted to group the spatial basis functions along the longitudinal dimension. The interactions of the adjacent groups are calculated directly in the traditional manner, while the impedance matrices associated with the well-separated groups at each level are computed by the multilevel adaptive cross approximation (MLACA) algorithm. The hybrid MPI and OpenMP parallel programming technique is utilized to further accelerate the solving process on a shared-memory computer system. Two numerical results demonstrate that the proposed method can greatly reduce the memory requirement and CPU time, thus enhance the capability of MOD method.","Instruction sets,
Memory management,
Mathematical model,
Approximation algorithms,
Integral equations,
Time-domain analysis,
Parallel programming"
Pattern-based Topics for Document Modelling in Information Filtering,"Many mature term-based or pattern-based approaches have been used in the field of information filtering to generate users' information needs from a collection of documents. A fundamental assumption for these approaches is that the documents in the collection are all about one topic. However, in reality users' interests can be diverse and the documents in the collection often involve multiple topics. Topic modelling, such as Latent Dirichlet Allocation (LDA), was proposed to generate statistical models to represent multiple topics in a collection of documents, and this has been widely utilized in the fields of machine learning and information retrieval, etc. But its effectiveness in information filtering has not been so well explored. Patterns are always thought to be more discriminative than single terms for describing documents. However, the enormous amount of discovered patterns hinder them from being effectively and efficiently used in real applications, therefore, selection of the most discriminative and representative patterns from the huge amount of discovered patterns becomes crucial. To deal with the above mentioned limitations and problems, in this paper, a novel information filtering model, Maximum matched Pattern-based Topic Model (MPBTM), is proposed. The main distinctive features of the proposed model include: (1) user information needs are generated in terms of multiple topics; (2) each topic is represented by patterns; (3) patterns are generated from topic models and are organized in terms of their statistical and taxonomic features; and (4) the most discriminative and representative patterns, called Maximum Matched Patterns, are proposed to estimate the document relevance to the user's information needs in order to filter out irrelevant documents. Extensive experiments are conducted to evaluate the effectiveness of the proposed model by using the TREC data collection Reuters Corpus Volume 1. The results show that the proposed model significantly outperforms both state-of-the-art term-based models and pattern-based models.","Itemsets,
Semantics,
Pattern matching,
Data models,
Data mining,
Probabilistic logic,
Resource management"
"A 0.8-V, 1-MS/s, 10-bit SAR ADC for Multi-Channel Neural Recording","This paper presents a 10-bit single-ended SAR ADC suitable for multi-channel neural recording. The proposed ADC introduces several power saving techniques to boost the energy efficiency. The ADC is built with on-chip common-mode buffer for input tracking, which is reused as the pre-amplifier of a current-mode comparator during conversion. A small capacitor is inserted between the amplifier and the capacitive DAC array in order to reduce the capacitive load on the amplifier. A split capacitor array with dual thermometer decoders is proposed to reduce the switching energy. Implemented in 0.13-μm CMOS technology, the ADC achieved a maximum differential nonlinearity (DNL) of -0.33/+0.56 LSB, maximum integral nonlinearity (INL) of -0.61/+0.55 LSB, effective number-of-bits (ENOB) of 8.8, and a power consumption of 9-μW.",
Direction of Arrival Estimation of Reflections from Room Impulse Responses Using a Spherical Microphone Array,"This paper studies the direction of arrival estimation of reflections in short time windows of room impulse responses measured with a spherical microphone array. Spectral-based methods, such as multiple signal classification (MUSIC) and beamforming, are commonly used in the analysis of spatial room impulse responses. However, the room acoustic reflections are highly correlated or even coherent in a single analysis window and this imposes limitations on the use of spectral-based methods. Here, we apply maximum likelihood (ML) methods, which are suitable for direction of arrival estimation of coherent reflections. These methods have been earlier developed in the linear space domain and here we present the ML methods in the context of spherical microphone array processing and room impulse responses. Experiments are conducted with simulated and real data using the em32 Eigenmike. The results show that direction estimation with ML methods is more robust against noise and less biased than MUSIC or beamforming.","Arrays,
Microphones,
Acoustics,
Direction-of-arrival estimation,
Estimation,
Smoothing methods,
Covariance matrices"
Sparse Malicious False Data Injection Attacks and Defense Mechanisms in Smart Grids,"This paper discusses malicious false data injection attacks on the wide area measurement and monitoring system in smart grids. First, methods of constructing sparse stealth attacks are developed for two typical scenarios: 1) random attacks in which arbitrary measurements can be compromised; and 2) targeted attacks in which specified state variables are modified. It is already demonstrated that stealth attacks can always exist if the number of compromised measurements exceeds a certain value. In this paper, it is found that random undetectable attacks can be accomplished by modifying only a much smaller number of measurements than this value. It is well known that protecting the system from malicious attacks can be achieved by making a certain subset of measurements immune to attacks. An efficient greedy search algorithm is then proposed to quickly find this subset of measurements to be protected to defend against stealth attacks. It is shown that this greedy algorithm has almost the same performance as the brute-force method, but without the combinatorial complexity. Third, a robust attack detection method is discussed. The detection method is designed based on the robust principal component analysis problem by introducing element-wise constraints. This method is shown to be able to identify the real measurements, as well as attacks even when only partial observations are collected. The simulations are conducted based on IEEE test systems.",
RC-Based Temperature Prediction Scheme for Proactive Dynamic Thermal Management in Throttle-Based 3D NoCs,"The three-dimensional Network-on-Chip (3D NoC) has been proposed to solve the complex on-chip communication issues in multicore systems using die stacking in recent days. Because of the larger power density and the heterogeneous thermal conductance in different silicon layers of 3D NoC, the thermal problems of 3D NoC become more exacerbated than that of 2D NoC and become a major design constraint for a high-performance system. To control the system temperature under a certain thermal limit, many Dynamic Thermal Managements (DTMs) have been proposed. Recently, for emergent cooling, the full throttling scheme is usually employed as the system temperature reaches the alarming level. Hence, the conventional reactive DTM suffers from significant performance impact because of the pessimistic reaction. In this paper, we propose a throttle-based proactive DTM(T-PDTM) scheme to predict the future temperature through a new Thermal RC-based temperature prediction (RCTP) model. The RCTP model can precisely predict the temperature with heterogeneous workload assignment with low constant computational complexity. Based on the predictive temperature, the proposed T-PDTM scheme will assign the suitable clock frequency for each node of the NoC system to perform early temperature control through power budget distribution. Based on the experimental results, compared with the conventional reactive throttled-based DTMs, the T-PDTM scheme can help to reduce 11.4~80.3 percent fully throttled nodes and improves the network throughput by around 1.5~211.8 percent.","Temperature sensors,
Three-dimensional displays,
Temperature control,
Thermal management,
Predictive models,
Temperature measurement,
Thermal conductivity"
Co-Extracting Opinion Targets and Opinion Words from Online Reviews Based on the Word Alignment Model,"Mining opinion targets and opinion words from online reviews are important tasks for fine-grained opinion mining, the key component of which involves detecting opinion relations among words. To this end, this paper proposes a novel approach based on the partially-supervised alignment model, which regards identifying opinion relations as an alignment process. Then, a graph-based co-ranking algorithm is exploited to estimate the confidence of each candidate. Finally, candidates with higher confidence are extracted as opinion targets or opinion words. Compared to previous methods based on the nearest-neighbor rules, our model captures opinion relations more precisely, especially for long-span relations. Compared to syntax-based methods, our word alignment model effectively alleviates the negative effects of parsing errors when dealing with informal online texts. In particular, compared to the traditional unsupervised alignment model, the proposed model obtains better precision because of the usage of partial supervision. In addition, when estimating candidate confidence, we penalize higher-degree vertices in our graph-based co-ranking algorithm to decrease the probability of error generation. Our experimental results on three corpora with different sizes and languages show that our approach effectively outperforms state-of-the-art methods.","Hidden Markov models,
Syntactics,
Feature extraction,
Data mining,
Data models,
Standards,
Training"
Design of Mixed Synchronous/Asynchronous Systems with Multiple Clocks,"Today's distributed systems are commonly equipped with both synchronous and asynchronous components controlled with multiple clocks. The key challenges in designing such systems are (1) how to model multi-clocked local synchronous component, local asynchronous component, and asynchronous communication among components in a single framework. (2) how to ensure the correctness of model, and keep consistency between the model and the implementation of real system. In this paper, we propose a novel computation model named GalsBlock for the design of multi-clocked embedded system with both synchronous and asynchronous components. The computation model consists of several hierarchical compound and atom blocks communicating with data port connections. Each atom block can be refined as parallel mealy automata. The synchronous component can be captured in an atom block with the corresponding local control clock while the asynchronous component in an atom block without clock, and the asynchronous communications can be captured in the data port connections among blocks. The unified operational semantics and formal semantics are defined, which can be used for simulation and verification, respectively. Then, we can generate efficient VHDL code from the validated model, which can be synthesized into the FPGA processor for execution directly. We have developed the graphical modeling, simulation, verification, and code generation toolkit to support the computation model, and applied it in the design of a sub-system used in the real train communication control.","Ports (Computers),
Computational modeling,
Atomic clocks,
Automata,
Semantics,
Compounds"
Conformal Electromagnetic Particle in Cell: A Review,"Conformal (or body-fitted) electromagnetic particle-in-cell (EM-PIC) numerical solution schemes are reviewed. Included is a chronological history of relevant particle physics algorithms often employed in these conformal simulations. Brief mathematical descriptions of particle-tracking algorithms and current weighting schemes are provided, along with a brief summary of major time-dependent electromagnetic solution methods. Several research areas are also highlighted for recommended future development of new conformal EM-PIC methods.","Time-domain analysis,
Finite difference methods,
Finite element analysis,
Interpolation,
Accuracy,
Force"
Fabrication Process Yielding Saturated Nanowire Single-Photon Detectors With 24-ps Jitter,"We present an optimized fabrication process for superconducting nanowire single-photon detectors that allowed us to obtain a yield of ~70% for detectors based on 80-nm-wide niobium nitride nanowires. We fabricated detectors that showed 24-ps timing jitter and saturated detection efficiency without the need for cryogenic amplifiers, allowing for operation in a low-bias low-dark-count-rate regime while operating at maximum detection efficiency.","Detectors,
Timing jitter,
Films,
Photonics,
Resists,
Fabrication,
Gold"
A Novel Range Grating Lobe Suppression Method Based on the Stepped-Frequency SAR Image,"The magnitude error and phase error (MEPE) in the transfer function of a stepped-frequency synthetic aperture radar (SAR) system results in a periodic MEPE in the synthesized wideband waveform, which induces the grating lobes in the high-resolution range profile. In this letter, a novel grating lobe suppression method based on the SAR image is proposed. In the paired-echo theory, a single sinusoidal term of the periodic MEPE in the frequency domain induces a pair of grating lobes in the time domain. Based on the magnitudes and phases of a strong scatterer and its grating lobes in the SAR image, the sinusoidal terms in the periodic MEPE can be estimated using the proposed method. By compensating for the estimated sinusoidal terms in the spectrum reconstruction, the corresponding grating lobes can be suppressed to the background level of the SAR image. The validity of the proposed method has been demonstrated using computer simulations and experiments based on real data.","Gratings,
Synthetic aperture radar,
Noise measurement,
Transfer functions,
Wideband,
Image reconstruction"
Optimal Mass Transport for Shape Matching and Comparison,"Surface based 3D shape analysis plays a fundamental role in computer vision and medical imaging. This work proposes to use optimal mass transport map for shape matching and comparison, focusing on two important applications including surface registration and shape space. The computation of the optimal mass transport map is based on Monge-Brenier theory, in comparison to the conventional method based on Monge-Kantorovich theory, this method significantly improves the efficiency by reducing computational complexity from O(n2) to O(n). For surface registration problem, one commonly used approach is to use conformal map to convert the shapes into some canonical space. Although conformal mappings have small angle distortions, they may introduce large area distortions which are likely to cause numerical instability thus resulting failures of shape analysis. This work proposes to compose the conformal map with the optimal mass transport map to get the unique area-preserving map, which is intrinsic to the Riemannian metric, unique, and diffeomorphic. For shape space study, this work introduces a novel Riemannian framework, Conformal Wasserstein Shape Space, by combing conformal geometry and optimal mass transport theory. In our work, all metric surfaces with the disk topology are mapped to the unit planar disk by a conformal mapping, which pushes the area element on the surface to a probability measure on the disk. The optimal mass transport provides a map from the shape space of all topological disks with metrics to the Wasserstein space of the disk and the pullback Wasserstein metric equips the shape space with a Riemannian metric. We validate our work by numerous experiments and comparisons with prior approaches and the experimental results demonstrate the efficiency and efficacy of our proposed approach.","Shape,
Extraterrestrial measurements,
Three-dimensional displays,
Conformal mapping,
Surface morphology,
Space vehicles"
Spline-Like Wavelet Filterbanks for Multiresolution Analysis of Graph-Structured Data,"Multiresolution analysis is important for understanding graph signals, which represent graph-structured data. Wavelet filterbanks permit multiscale analysis and processing of graph signals-particularly, useful for harvesting large-scale data. Inspired by first-order spline wavelets in classical signal processing, we introduce two-channel (low-pass and high-pass) wavelet filterbanks for graph signals. This class of filterbanks boasts several useful properties, such as critical sampling, perfect reconstruction, and graph invariance. We consider an application in graph semi-supervised learning and propose a wavelet-regularized semi-supervised learning algorithm that is competitive for certain synthetic and real-world data.","Information processing,
Splines (mathematics),
Matrix decomposition,
Semisupervised learning,
Symmetric matrices,
Wavelet analysis,
Signal processing"
Towards generating arcade game rules with VGDL,"We describe an attempt to generate complete arcade games using the Video Game Description Language (VGDL) and the General Video Game Playing environment (GVG-AI). Games are generated by an evolutionary algorithm working on genotypes represented as VGDL descriptions. In order to direct evolution towards good games, we need an evaluation function that accurately estimates game quality. The evaluation function used here is based on the differential performance of several game-playing algorithms, or Relative Algorithm Performance Profiles (RAPP): it is assumed that good games allow good players to play better than bad players. For the purpose of such evaluations, we introduce two new game tree search algorithms, DeepSearch and Explorer; these perform very well on benchmark games and constitute a substantial subsidiary contribution of the paper. In the end, the attempt to generate arcade games is only partially successful, as some of the games have interesting design features but are barely playable as generated. An analysis of these shortcomings yields several suggestions to guide future attempts at arcade game generation.","Games,
Sprites (computer),
Algorithm design and analysis,
Clocks,
Entropy,
Computers,
Testing"
"Scalable energy-efficient, low-latency implementations of trained spiking Deep Belief Networks on SpiNNaker","Deep neural networks have become the state-of-the-art approach for classification in machine learning, and Deep Belief Networks (DBNs) are one of its most successful representatives. DBNs consist of many neuron-like units, which are connected only to neurons in neighboring layers. Larger DBNs have been shown to perform better, but scaling-up poses problems for conventional CPUs, which calls for efficient implementations on parallel computing architectures, in particular reducing the communication overhead. In this context we introduce a realization of a spike-based variation of previously trained DBNs on the biologically-inspired parallel SpiNNaker platform. The DBN on SpiNNaker runs in real-time and achieves a classification performance of 95% on the MNIST handwritten digit dataset, which is only 0.06% less than that of a pure software implementation. Importantly, using a neurally-inspired architecture yields additional benefits: during network run-time on this task, the platform consumes only 0.3 W with classification latencies in the order of tens of milliseconds, making it suitable for implementing such networks on a mobile platform. The results in this paper also show how the power dissipation of the SpiNNaker platform and the classification latency of a network scales with the number of neurons and layers in the network and the overall spike activity rate.","Neurons,
Topology,
MATLAB,
Clocks"
Enabling Adaptive Cloud Gaming in an Open-Source Cloud Gaming Platform,"We study the problem of optimally adapting ongoing cloud gaming sessions to maximize the gamer experience in dynamic environments. The considered problem is quite challenging because: 1) gamer experience is subjective and hard to quantify; 2) the existing open-source cloud gaming platform does not support dynamic reconfigurations of video codecs; and 3) the resource allocation among concurrent gamers leaves a huge room to optimize. We rigorously address these three challenges by: 1) conducting a crowdsourced user study over the live Internet for an empirical gaming experience model; 2) enhancing the cloud gaming platform to support frame rate and bitrate adaptation on-the-fly; and 3) proposing optimal yet efficient algorithms to maximize the overall gaming experience or ensure the fairness among gamers. We conduct extensive trace-driven simulations to demonstrate the merits of our algorithms and implementation. Our simulation results show that the proposed efficient algorithms: 1) outperform the baseline algorithms by up to 46% and 30%; 2) run fast and scale to large (≤8000 gamers) problems; and 3) achieve the user-specified optimization criteria, such as maximizing average gamer experience or maximizing the minimum gamer experience. The resulting cloud gaming platform can be leveraged by many researchers, developers, and gamers.","Games,
Servers,
Resource management,
Optimization,
Cloud computing,
Graphics,
Streaming media"
IFROWANN: Imbalanced Fuzzy-Rough Ordered Weighted Average Nearest Neighbor Classification,"Imbalanced classification deals with learning from data with a disproportional number of samples in its classes. Traditional classifiers exhibit poor behavior when facing this kind of data because they do not take into account the imbalanced class distribution. Four main kinds of solutions exist to solve this problem: modifying the data distribution, modifying the learning algorithm for considering the imbalance representation, including the use of costs for data samples, and ensemble methods. In this paper, we adopt the second type of solution and introduce a classification algorithm for imbalanced data that uses fuzzy rough set theory and ordered weighted average aggregation. The proposal considers different strategies to build a weight vector to take into account data imbalance. Our methods are validated by an extensive experimental study, showing statistically better results than 13 other state-of-the-art methods.","Vectors,
Approximation methods,
Open wireless architecture,
Approximation algorithms,
Decision trees,
Prediction algorithms,
Educational institutions"
A Strategy-Proof Combinatorial Heterogeneous Channel Auction Framework in Noncooperative Wireless Networks,"Auction is believed to be an effective way to solve or relieve the problem of radio spectrum shortage, by dynamically redistributing idle wireless channels of primary users to secondary users. However, to design a practical channel auction mechanism, we have to consider five challenges, including strategy-proofness, channel spatial reusability, channel heterogeneity, bid diversity, and social welfare maximization. Unfortunately, none of the existing works fully considered the five design challenges. In this paper, we present the first in-depth study on the problem of dynamic channel redistribution jointly considering the five design challenges, and present SMASHER, which is a family of Strategy-proof coMbinatorial Auction mechaniSms for HEterogeneous channel Redistribution. SMASHER contains two strategy-proof auction mechanisms, namely SMASHER-AP and SMASHER-GR. SMASHER-AP is a strategy-proof, approximately efficient combinatorial auction mechanism for indivisible channel redistribution. We further consider the case, in which channels can be shared by the users in a paradigm of time-division multiplexing and propose SMASHER-GR, which is a strategy-proof channel allocation and scheduling mechanism. We have extensively evaluated our designs. The evaluation results show that our designs achieve much better performance than existing works.","Wireless communication,
Vectors,
Cost accounting,
Channel allocation,
Interference,
Quality of service,
Mobile computing"
Simple and Accurate Circuit Simulation Model for SiC Power MOSFETs,"Simple and accurate circuit simulation models for high-voltage silicon carbide power MOSFETs and Schottky barrier diodes are presented and validated. The models are physics-based and consist of minimal number of model parameters that can be easily extracted from simple static I-V and C-V measurements. The models are used in a buck-boost bidirectional dc-dc converter, with and without an antiparallel Schottky diode. The efficiency of the converter was analyzed for synchronous and nonsynchronous operation of the switches. An optimal selection of the antiparallel Schottky diode is proposed to minimize the cost of the converter without compromising its efficiency.","Semiconductor device modeling,
Schottky diodes,
Integrated circuit modeling,
MOSFET,
Silicon carbide,
Mathematical model,
Insulated gate bipolar transistors"
Risk-Sensitive Control Under Markov Modulated Denial-of-Service (DoS) Attack Strategies,"We consider the problem of risk-sensitive stochastic control under a Markov modulated denial-of-service (DoS) attack strategy in which the attacker, using a hidden Markov model, stochastically jams the control packets in the system. For a discrete-time partially observed stochastic system with an exponential running cost, we provide a solution in terms of the finite-dimensional dynamics of the system through a chain of measure transformation techniques. We also prove a separation principle under which a recursive optimal control policy together with a newly defined information-state constitutes an equivalent completely observable stochastic control problem. Remarkably, on the transformed measure space, the solution to the optimal control problem appears as if it depends only on the sample-path (or path-estimation) of the DoS attack sequences in the system.",
IIPS: Infrastructure IP for Secure SoC Design,"Security is becoming an increasingly important parameter in current system-on-chip (SoC) design due to diverse hardware security attacks that can affect manufacturers, system designers or end users. To effectively address the security issues, design-time considerations, e.g. incorporation of design-for-security (DfS) features, are becoming essential. However, DfS measures for diverse security threats require specific design modifications to achieve target security level, which significantly increases design effort thus time-to-market, and usually incurs considerable design overhead. In addition, the general heterogeneous architecture of current SoCs makes many core-level DfS mechanisms unusable at SoC level. In this paper, we propose a centralized on-chip infrastructure IP for SoC security (IIPS), which alleviates the SoC designers from separately addressing different security issues through design modifications in multiple cores. It also provides ease of integration and functional scalability. We consider a specific implementation of IIPS that provides protection against: (1) scan-based attack for information leakage through low-overhead authentication; (2) counterfeiting attacks through integration of a Physical Unclonable Function (PUF); and (3) hardware Trojan attacks through a test infrastructure fortrust validation. To make the IP amenable for plug-and-play during SoC design, working protocols of the security functions are designed to comply with IEEE 1500 Standard for Embedded Core Test (SECT). Since IIPS resides outside the functional modules, it does not incur functional performance or power overhead. Simulations and experiments on example SoC designs validate the effectiveness of IIPS in providing protections against diverse attacks at a low hardware overhead.","System-on-chip,
Trojan horses,
Hardware,
IP networks,
Testing,
Delays"
On Energy Harvesting Gain and Diversity Analysis in Cooperative Communications,"The use of energy harvesting cooperative relays is a promising solution to battery-limited wireless networks. In this paper, we consider a cooperative system in which one source node transmits data to one destination with the assistance of an energy harvesting decode-and-forward (DF) relay node. Our objective is to minimize the long-term average symbol error rate (SER) performance through a Markov decision process (MDP) framework. By doing so, we find the optimal stochastic power control at the relay that adapts the transmission power to the changes of energy harvesting, battery, channel, and decoding states. We derive a finite-integral expression for the exact average SER of the cooperative system. Further insights are gained by analyzing the asymptotic average SER and its lower and upper bounds at high signal-to-noise ratio (SNR), and the performance is eventually characterized by the occurrence probability of the relay's actions at the worst channel states in the MDP. We also show that the optimal cooperative policy at asymptotically high SNR follows a threshold-type structure, i.e., the relay spends the harvested energy only when the signal is successfully decoded and the source is faced with the worst channel condition in its direct link. Using these observations to quantify the diversity gain and the energy harvesting gain, we reveal that full diversity is guaranteed if and only if the probability of harvesting zero energy quantum is zero, which can be achieved by reducing the energy quantum size or increasing the energy harvesting capability. Finally, we present several numerical examples to validate the analytical findings.","Energy harvesting,
Relays,
Batteries,
Decoding,
Cooperative communication,
Signal to noise ratio,
Green communications"
Architecture Support for Task Out-of-Order Execution in MPSoCs,"Multi-processor system on chip (MPSoC) has been widely applied in embedded systems in the past decades. However, it has posed great challenges to efficiently design and implement a rapid prototype for diverse applications due to heterogeneous instruction set architectures (ISA), programming interfaces and software tool chains. In order to solve the problem, this paper proposes a novel high level architecture support for automatic out-of-order (OoO) task execution on FPGA based heterogeneous MPSoCs. The architecture support is composed of a hierarchical middleware with an automatic task level OoO parallel execution engine. Incorporated with a hierarchical OoO layer model, the middleware is able to identify the parallel regions and generate the sources codes automatically. Besides, a runtime middleware Task-Scoreboarding analyzes the inter-task data dependencies and automatically schedules and dispatches the tasks with parameter renaming techniques. The middleware has been verified by the prototype built on FPGA platform. Examples and a JPEG case study demonstrate that our model can largely ease the burden of programmers as well as uncover the task level parallelism.","Computer architecture,
Program processors,
Field programmable gate arrays,
Hardware,
IP networks,
Middleware,
Computational modeling"
"The Puck Antenna: A Compact Design With Wideband, High-Gain Operation","We develop a high-gain antenna with wideband operation and compact size by placing a small dielectric superstrate (puck) in front of the feeding antenna. The antenna performance is a combination of the leaky-wave effect, naturally existing in this type of antennas, and the edge diffraction effect occurring at the puck perimeter. Compared to the typical resonant cavity antenna utilizing a large superstrate, the proposed puck antenna has nearly four times enhanced performance (gain-bandwidth combination) while using a square puck of side slightly smaller than two wavelengths (at the design frequency). Further enhancement is achieved by making the puck circular in shape in order to add the diffracted fields in phase. The study is conducted through full-wave simulations and validated through measurements in the Ku band. The effect of puck misalignment is then discussed as a potential practical issue. Last, the ground plane is optimized for maximum antenna performance and relatively acceptable values of aperture efficiency (up to 51%).",
Semi-Continuity of Skeletons in Two-Manifold and Discrete Voronoi Approximation,"The skeleton of a 2D shape is an important geometric structure in pattern analysis and computer vision. In this paper we study the skeleton of a 2D shape in a two-manifold \mathcal {M} , based on a geodesic metric. We present a formal definition of the skeleton S(\Omega ) for a shape \Omega in \mathcal {M} and show several properties that make S(\Omega ) distinct from its Euclidean counterpart in \mathbb {R}^2 . We further prove that for a shape sequence \lbrace \Omega _i\rbrace that converge to a shape \Omega in \mathcal {M} , the mapping \Omega \rightarrow \overline{S}(\Omega ) is lower semi-continuous. A direct application of this result is that we can use a set P of sample points to approximate the boundary of a 2D shape \Omega in \mathcal {M} , and the Voronoi diagram of P inside \Omega \subset \mathcal {M} gives a good approximation to the skeleton S(\Omega ) . Examples of skeleton computation in topography and brain morphometry are illustrated.","Skeleton,
Shape,
Approximation methods,
Measurement,
Manifolds,
Pattern analysis,
Computer vision"
"Tilted Beam Piezoresistive Displacement Sensor: Design, Modeling, and Characterization","We present a comprehensive study of the design, modeling, and characterization of an on-chip piezoresistive displacement sensor. The design is based on the bulk piezoresistivity of tilted clamped-guided beams without the need for additional steps to generate doped regions. The sensor is implemented in a one-degree-of-freedom microelectromechanical system (MEMS) nanopositioner, where the beams also function as the suspension system. A standard MEMS fabrication process is used to realize the device on single-crystalline silicon as the structural material. The beams are oppositely tilted to develop tensile and compressive axial forces during stage movement, creating a differential sensing feature. An analytical approach is proposed for modeling and design of the tilted clamped-guided beams. The linearity of the sensor in the differential configuration is investigated analytically. The static, dynamic, and noise characteristics of the sensor are presented, followed by a model-based investigation of the measured dynamic feedthrough.",
Pattern-Aided Regression Modeling and Prediction Model Analysis,"This paper first introduces pattern aided regression (PXR) models, a new type of regression models designed to represent accurate and interpretable prediction models. This was motivated by two observations: (1) Regression modeling applications often involve complex diverse predictor-response relationships, which occur when the optimal regression models (of given regression model type) fitting two or more distinct logical groups of data are highly different. (2) State-of-the-art regression methods are often unable to adequately model such relationships. This paper defines PXR models using several patterns and local regression models, which respectively serve as logical and behavioral characterizations of distinct predictor-response relationships. The paper also introduces a contrast pattern aided regression (CPXR) method, to build accurate PXR models. In experiments, the PXR models built by CPXR are very accurate in general, often outperforming state-of-the-art regression methods by big margins. Usually using (a) around seven simple patterns and (b) linear local regression models, those PXR models are easy to interpret; in fact, their complexity is just a bit higher than that of (piecewise) linear regression models and is significantly lower than that of traditional ensemble based regression models. CPXR is especially effective for high-dimensional data. The paper also discusses how to use CPXR methodology for analyzing prediction models and correcting their prediction errors.","Predictive models,
Data models,
Biological system modeling,
Computational modeling,
Analytical models,
Regression tree analysis,
Linear regression"
Impact of AlN Interfacial Dipole on Effective Work Function of Ni and Band Alignment of Ni/HfO2/In0.53Ga0.47As Gate-Stack,"AlN has successfully been applied to passivate the oxide/III-V interface; however, it changes both the metal work function (WF) and band alignment of the gate-stack and, thus, affects the power consumption of the devices. We found that the AlN layer induces a dipole δ = 0.18 eV between HfO2 and substrate. The dipole value obtained from capacitance- voltage characteristics performs good agreement with the results of X-ray photoelectron spectroscopic measurements. The effective WF of Ni is found to be 5.55 eV, which is larger than its WF in vacuum. The valance band offset and the conduction band offset of HfO2 with AlN/In0.53Ga0.47As are found to be 2.82 and 2.06 eV, respectively.",
Fairness-Aware Energy-Efficient Resource Allocation for AF Co-Operative OFDMA Networks,"In this paper, we adopt an energy-efficiency (EE) metric, named worst-EE, that is suitable for EE fairness optimization in the uplink transmission of amplify-and-forward (AF) cooperative orthogonal frequency division multiple access (OFDMA) networks. More specifically, we assign subcarriers and allocate powers for mobile and relay stations in order to maximize the worst-EE, i.e., to maximize the EE of the mobile station (MS) with the lowest EE value, subject to MSs transmit power, relay station (RS) transmit power, and MSs quality-of-service (QoS) constraints. The formulated primal max-min optimization problem is nonconvex fractional mixed integer nonlinear program, i.e., NP-hard to solve. We provide a novel optimization framework that studies the structure of the primal problem and prove that the dual min-max optimization problem attains the same optimal solution of the primal problem. Additionally, we propose a modified Dinkelbach algorithm, named dual Dinkelbach, to achieve the optimal solution of the dual problem in a polynomial time complexity. We further exploit the structure of the obtained optimal solution and develop a low complexity suboptimal heuristic. Numerical results show the effectiveness of the proposed algorithm to improve the network performance in terms of fairness between MSs, worst-EE, and average network transmission rate when compared to traditional schemes that maximize the EE of the whole network. Presented results also show that the suboptimal heuristic balances the achieved performance and the computational complexity.","Green communications,
Resource management,
Uplink,
Energy efficiency,
Signal to noise ratio,
Cooperative communication,
Mobile communication,
OFDM"
Supply Voltage Dependence of Heavy Ion Induced SEEs on 65 nm CMOS Bulk SRAMs,"Soft Error Rates (SER) of hardened and unhardened SRAM cells need to be experimentally characterized to determine their appropriate applications in radiation environments. This characterization is especially important when low supply voltage is preferred. In this paper, we developed an SRAM test chip with four cell arrays including two types of unhardened cells (standard 6T and subthreshold 10T) and two types of hardened cells (Quatro and DICE). This test chip was fabricated in a 65 nm bulk technology and irradiated by heavy ions at different supply voltages. Experimental results show that the SERs of 6T and 10T cells present significant sensitivities to supply voltages when the particle linear energy transfers (LETs) are relatively low. For Quatro and DICE cells, one does not consistently show superior hardening performance over the other. It is also noted that Quatro cells show significant advantage in single event resilience over 10T cells although they consume similar areas. TCAD simulations were carried out to validate the experimental data. In addition, the error amount distributions follow a Poisson distribution very well for each type of cell array.","Arrays,
SRAM cells,
Ions,
Alpha particles,
Testing,
Neutrons"
Demonstration of OpenFlow-Controlled Network Orchestration for Adaptive SVC Video Manycast,"Software defined networking (SDN) makes networks programmable and application-aware by decoupling network control and management (NC&M) from data forwarding and leveraging centralized NC&M to facilitate user-customized routing and switching. Inspired by these, this paper investigates how to realize the OpenFlow-controlled (OF-controlled) network orchestration that can facilitate efficient scalable video coding (SVC) streaming to heterogeneous clients. Specifically, we consider real-time SVC streaming and address the situation in which video sources reside in geographically- distributed servers and clients can join and leave the streaming services dynamically. We formulate this as a multi-source multi-destination manycast problem and realize the networking system with an OF-controlled SDN architecture. We first design the OF controller to enable efficient network operations. Then, we focus on solving the multi-source multi-destination SVC video manycast problem and design several algorithms. Initially, an integer linear programming (ILP) model is formulated to obtain the optimal solutions for small-scale problems. Next, we try to make the manycast algorithm suitable for practical implementation, and design two time-efficient heuristics. Simulation results indicate that the heuristics can provide close-to-optimal solutions. Finally, we build an OF network testbed that consists of OF switches, SVC video servers and clients, and perform SVC streaming experiments to demonstrate our design. Experimental results verify that the proposed scheme can allocate bandwidth intelligently and ensure high-quality video streaming. To the best of our knowledge, this is the first work that accomplishes experimental demonstration of OF-controlled network orchestration for adaptive SVC video manycast.","Streaming media,
Static VAr compensators,
Servers,
Bandwidth,
Control systems,
Quality of service,
Delays"
A personalized two-tier cloaking scheme for privacy-aware location-based services,"The ubiquity of modern mobile devices with GPS modules and Internet connectivity such as 3G/4G techniques have resulted in rapid development of Location-Based Services (LBSs). However, users enjoy the convenience provided by the untrusted LBS server at the cost of their privacy. To protect user's sensitive information against adversaries with side information, we design a personalized spatial cloaking scheme, termed TTcloak, which provides k-anonymity for user's location privacy, 1-diversity for query privacy and desired size of cloaking region for mobile users in LBSs, simultaneously. TTcloak uses Dummy Query Determining (DQD) algorithm and Dummy Location Determining (DLD) algorithm to find out a set of realistic cells as candidates, and employs a CR-refinement Module (CRM) to guarantee that dummy users are assigned into the cloaking region with desired size. Finally, thorough security analysis and empirical evaluation results verify our proposed TTcloak.","Privacy,
Servers,
Mobile radio mobility management,
Algorithm design and analysis,
Complexity theory,
Entropy"
Power Optimization of Ultrasonic Friction-Modulation Tactile Interfaces,"Ultrasonic friction-modulation devices provide rich tactile sensation on flat surfaces and have the potential to restore tangibility to touchscreen. To date, their adoption into consumer electronics has been in part limited by relatively high power consumption, incompatible with the requirements of battery-powered devices. This paper introduces a method that optimizes the energy efficiency and performance of this class of devices. It considers optimal energy transfer to the impedance provided by the finger interacting with the surface. Constitutive equations are determined from the mode shape of the interface and the piezoelectric coupling of the actuator. The optimization procedure employs a lumped parameter model to simplify the treatment of the problem. Examples and an experimental study show the evolution of the optimal design as a function of the impedance of the finger.",
Assessing the Refactorability of Software Clones,"The presence of duplicated code in software systems is significant and several studies have shown that clones can be potentially harmful with respect to the maintainability and evolution of the source code. Despite the significance of the problem, there is still limited support for eliminating software clones through refactoring, because the unification and merging of duplicated code is a very challenging problem, especially when software clones have gone through several modifications after their initial introduction. In this work, we propose an approach for automatically assessing whether a pair of clones can be safely refactored without changing the behavior of the program. In particular, our approach examines if the differences present between the clones can be safely parameterized without causing any side-effects. The evaluation results have shown that the clones assessed as refactorable by our approach can be indeed refactored without causing any compile errors or test failures. Additionally, the computational cost of the proposed approach is negligible (less than a second) in the vast majority of the examined cases. Finally, we perform a large-scale empirical study on over a million clone pairs detected by four different clone detection tools in nine open-source projects to investigate how refactorability is affected by different clone properties and tool configuration options. Among the highlights of our conclusions, we found that (a) clones in production code tend to be more refactorable than clones in test code, (b) clones with a close relative location (i.e., same method, type, or file) tend to be more refactorable than clones in distant locations (i.e., same hierarchy, or unrelated types), (c) Type-1 clones tend to be more refactorable than the other clone types, and (d) clones with a small size tend to be more refactorable than clones with a larger size.","Cloning,
Arrays,
Java,
Software systems,
Production,
Space exploration"
Novel Sampling Scheme on the Sphere for Head-Related Transfer Function Measurements,"This paper presents a novel sampling scheme on the sphere for obtaining head-related transfer function (HRTF) measurements and accurately computing the spherical harmonic transform (SHT). The scheme requires an optimal number of samples, given by the degrees of freedom in the spectral domain, for the accurate representation of the HRTF that is band-limited in the spherical harmonic domain. The proposed scheme allows for the samples to be easily taken over the sphere due to its iso-latitude structure and non-dense sampling near the poles. In addition, the scheme can be used when samples are not taken from the south polar cap region of the sphere as the HRTF measurements are not reliable in south polar cap region due to reflections from the ground. Furthermore, the scheme has a hierarchical structure, which enables the HRTF to be analyzed at different audible frequencies using the same sampling configuration. In comparison to the proposed scheme, none of the other sampling schemes on the sphere simultaneously possess all these properties. We conduct several numerical experiments to determine the accuracy of the SHT associated with the proposed sampling scheme. We show that the SHT attains accuracy on the order of numerical precision (10-14) when samples are taken over the whole sphere, both in the optimal sample placement and hierarchical configurations, and achieves an acceptable level of accuracy (10-5) when samples are not taken over the south polar cap region of the sphere for the band-limits of interest. Simulations are used to show the accurate reconstruction of the HRTF over the whole sphere, including unmeasured locations.","Harmonic analysis,
Spectral analysis,
Accuracy,
Transforms,
Microphones,
IEEE transactions,
Speech"
Melanoma detection algorithm based on feature fusion,"A Computer Aided-Diagnosis (CAD) System for melanoma diagnosis usually makes use of different types of features to characterize the lesions. The features are often combined into a single vector that can belong to a high dimensional space (early fusion). However, it is not clear if this is the optimal strategy and works on other fields have shown that early fusion has some limitations. In this work, we address this issue and investigate which is the best approach to combine different features comparing early and late fusion. Experiments carried on the datasets PH2 (single source) and EDRA (multi source) show that late fusion performs better, leading to classification scores of Sensitivity = 98% and Specificity = 90% (PH2) and Sensitivity = 83% and Specificity = 76% (EDRA).","Lesions,
Feature extraction,
Malignant tumors,
Image color analysis,
Design automation,
Training,
Histograms"
Scalable Constrained Spectral Clustering,"Constrained spectral clustering (CSC) algorithms have shown great promise in significantly improving clustering accuracy by encoding side information into spectral clustering algorithms. However, existing CSC algorithms are inefficient in handling moderate and large datasets. In this paper, we aim to develop a scalable and efficient CSC algorithm by integrating sparse coding based graph construction into a framework called constrained normalized cuts. To this end, we formulate a scalable constrained normalized-cuts problem and solve it based on a closed-form mathematical analysis. We demonstrate that this problem can be reduced to a generalized eigenvalue problem that can be solved very efficiently. We also describe a principled k-way CSC algorithm for handling moderate and large datasets. Experimental results over benchmark datasets demonstrate that the proposed algorithm is greatly cost-effective, in the sense that (1) with less side information, it can obtain significant improvements in accuracy compared to the unsupervised baseline; (2) with less computational time, it can achieve high clustering accuracies close to those of the state-of-the-art.","Clustering algorithms,
Vectors,
Accuracy,
Encoding,
Algorithm design and analysis,
Eigenvalues and eigenfunctions,
Sparse matrices"
Individualization for Education at Scale: MIIC Design and Preliminary Evaluation,"We present the design, implementation, and preliminary evaluation of our Adaptive Educational System (AES): the Mobile Integrated and Individualized Course (MIIC). MIIC is a platform for personalized course delivery which integrates lecture videos, text, assessments, and social learning into a mobile native app, and collects clickstream-level behavioral measurements about each student as they interact with the material. These measurements can subsequently be used to update the student's user model, which can in turn be used to determine the content adaptation. Recruiting students from one of our Massive Open Online Courses (MOOCs), we have conducted two preliminary trials with MIIC, in which we found (i) that the majority of students (70 percent) preferred MIIC overall to a one-size-fits-all (OSFA) presentation of the same material, (ii) that the mean level of engagement, when quantified as the number of pages viewed, was statistically higher (by 72 percent) among students using MIIC than among OSFA, and (iii) that the integrated multimedia learning features were generally favorable among the students (e.g., 87 percent found the videos helpful).",
Reflectance Photoplethysmography as Noninvasive Monitoring of Tissue Blood Perfusion,"In the last decades, photoplethysmography (PPG) has been used as a noninvasive technique for monitoring arterial oxygen saturation by pulse oximetry (PO), whereas near-infrared spectroscopy (NIRS) has been employed for monitoring tissue blood perfusion. While NIRS offers more parameters to evaluate oxygen delivery and consumption in deep tissues, PO only assesses the state of oxygen delivery. For a broader assessment of blood perfusion, this paper explores the utilization of dual-wavelength PPG by using the pulsatile (ac) and continuous (dc) PPG for the estimation of arterial oxygen saturation (SpO2) by conventional PO. Additionally, the Beer-Lambert law is applied to the dc components only for the estimation of changes in deoxyhemoglobin (HHb), oxyhemoglobin (HbO2), and total hemoglobin (tHb) as in NIRS. The system was evaluated on the forearm of 21 healthy volunteers during induction of venous occlusion (VO) and total occlusion (TO). A reflectance PPG probe and NIRS sensor were applied above the brachioradialis, PO sensors were applied on the fingers, and all the signals were acquired simultaneously. While NIRS and forearm SpO2 indicated VO, SpO2 from the finger did not exhibit any significant drop from baseline. During TO, all the indexes indicated the change in blood perfusion. HHb, HbO2, and tHb changes estimated by PPG presented high correlation with the same parameters obtained by NIRS during VO (r2 = 0.960, r2 = 0.821, and r2 = 0.974, respectively) and during TO (r2 = 0.988, r2 = 0.940, and r2 = 0.938, respectively). The system demonstrated the ability to extract valuable information from PPG signals for a broader assessment of tissue blood perfusion.","Probes,
Blood,
Reflectivity,
Estimation,
Fingers,
Light emitting diodes,
Biomedical measurement"
Parallelizing Epistasis Detection in GWAS on FPGA and GPU-Accelerated Computing Systems,"High-throughput genotyping technologies (such as SNP-arrays) allow the rapid collection of up to a few million genetic markers of an individual. Detecting epistasis (based on 2-SNP interactions) in Genome-Wide Association Studies is an important but time consuming operation since statistical computations have to be performed for each pair of measured markers. Computational methods to detect epistasis therefore suffer from prohibitively long runtimes; e.g., processing a moderately-sized dataset consisting of about 500,000 SNPs and 5,000 samples requires several days using state-of-the-art tools on a standard 3 GHz CPU. In this paper, we demonstrate how this task can be accelerated using a combination of fine-grained and coarse-grained parallelism on two different computing systems. The first architecture is based on reconfigurable hardware (FPGAs) while the second architecture uses multiple GPUs connected to the same host. We show that both systems can achieve speedups of around four orders-of-magnitude compared to the sequential implementation. This significantly reduces the runtimes for detecting epistasis to only a few minutes for moderatelysized datasets and to a few hours for large-scale datasets.","Field programmable gate arrays,
Graphics processing units,
Bioinformatics,
Random access memory,
Computer architecture,
Computational biology"
Low Overhead Software Wear Leveling for Hybrid PCM + DRAM Main Memory on Embedded Systems,"Phase change memory (PCM) is a promising DRAM replacement in embedded systems due to its attractive characteristics, such as low-cost, shock-resistivity, nonvolatility, high density, and low leakage power. However, relatively low endurance has limited its practical applications. In this paper, in addition to existing hardware level optimizations, we propose software enabled wear-leveling techniques to further extend PCMs lifetime when it is adopted in embedded systems. Most existing software optimization techniques focus on reducing the total number of writes to PCM, but none of them consider wear leveling, in which the writes are distributed more evenly over the PCM. An integer linear programming formulation and a polynomial-time algorithm, the software wear-leveling algorithm, are proposed in this paper to achieve wear leveling without hardware overhead. According to the experimental results, the proposed techniques can reduce the number of writes on the most-written addresses by more than 80% when compared with a greedy algorithm, and by more than 60% when compared with the existing optimal data allocation algorithm with under 6% memory access overhead.",
Nanostructured Thermionics for Conversion of Light to Electricity: Simultaneous Extraction of Device Parameters,"Thermionic conversion involves the direct conversion of heat, including light-induced heat, from a heat source, e.g., solar energy, to electricity. Although the concept is almost a hundred years old, the progress of thermionic convertors has been limited by issues such as the space-charge effect and availability of materials with desirable mechanical and electrical properties, while maintaining a low work function. Nanotechnology could help address some of the main challenges that thermionic convertors face. However, existing models, which were developed for macroscopic convertors, are not capable of describing all aspects of nanostructured devices. We present a method to evaluate the output characteristics of thermionic convertors with a higher precision than the existing models and the ability to simulate a broader range of parameters, including temperatures, active surface areas, interelectrode distances, and work functions. These features are crucial for the characterization of emergent devices due to the unknowns involved in their internal parameters; the model's high numerical precision and flexibility allows one to solve the reverse problem and to evaluate the internal parameters of the device from a set of simple experimental data. As an experimental case, a carbon nanotube forest was used as the emitter and locally heated to thermionic emission temperatures using a 50-mW-focused laser beam. The current-voltage characteristics were measured and used to solve the reverse problem to obtain the internal parameters of the device, which were shown to be consistent with the values obtained using other methods.","Mathematical model,
Thermionic emission,
Converters,
Heating,
Temperature,
Electrodes,
Electric fields"
Subwavelength Graphene-Based Plasmonic THz Switches and Logic Gates,"In this paper, we report on the design procedure for developing subwavelength graphene-based plasmonic waveguide, performing as a THz switch or an AND/OR logic gate. The propagation length of the surface plasmons (SPs), stimulated by a 6 THz TM polarized incident wave along this waveguide with a top graphene layer whose chemical potential is held at μC=300 meV (ON state) is more than 35 times larger than that in the waveguide with μC = 0 eV (OFF state). Numerical results, obtained from full wave simulations using a finite element method, also show that the modulation depth density obtained for the straight plasmonic switching waveguide, whose length is just about 20% of the incident wavelength, is larger than those reported to date. Moreover, we also designed a logic AND gate composed of a straight waveguide, a Y-branch switch, and a logic OR gate composed of two face to face Y-branches, whose total lengths are ~ 37%, ~ 45%, and ~ 53% of the incident wavelength, respectively. Simulations show that the maximum ON/OFF ratios for these subwavelength plasmonic waveguides that occur between their `1 1' and `0 0' logical states are ~ 41.37, ~ 39.87, and ~ 40.76 dB, respectively. These numerical data also show that the modulation depth densities obtained for these devices are also greater than those reported to date. The proposed graphene-based plasmonic switches and gates offer potential building blocks for the future digital plasmonic circuits operating around 6 THz.",
Supporting Serendipitous Social Interaction Using Human Mobility Prediction,"Leveraging the regularities of people's trajectories, mobility prediction can help forecast social interaction opportunities. In this paper, in order to facilitate real-world social interaction, we aim to predict “serendipitous” social interactions, which are defined as unplanned encounters and interaction opportunities and regarded as emerging social interactions. We collected GPS trajectory data from people' daily life on campus and use it as empirical mobility traces to generate decision trees and model trees to predict next venues, arrival times, and user encounter. Mobility regularities are mainly considered in these prediction models, and mobility contexts (e.g., time, location, and speed) act as decision nodes in the classification trees. Experimental results using collected GPS data showed that our system achieves 90% accuracy for predicting a user's next venue using a decision tree algorithm, with minute-level (around 5 min) prediction error for arrival time using the model tree algorithm. Two prototype applications were developed to support serendipitous social interaction on campus, and the feedback from a user study with 25 users demonstrated the usability of these two applications.","Global Positioning System,
Trajectory,
Accuracy,
Predictive models,
Inference mechanisms,
Social implications of technology"
Contention Aware Energy Efficient Scheduling on Heterogeneous Multiprocessors,"Energy efficiency along with enhanced performance are two important goals of scheduling on multiprocessors. This paper proposes a Contention-aware, Energy Efficient, Duplication based Mixed Integer Programming (CEEDMIP) formulation for scheduling task graphs on heterogeneous multiprocessors, interconnected in a distributed system or a network on chip architecture. The effect of duplication is studied with respect to minimizing: the makespan, the total energy for processing tasks and messages on processors and network resources respectively and the tardiness of tasks with respect to their deadlines. Optimizing the use of duplication with MIP provides both energy efficiency and performance by reducing the communication energy consumption and the communication latency. The contention awareness gives a more accurate estimation of the energy consumption. We also propose a corner case that allows the scheduling of a parent task copy after a copy of the child task which may lead to efficient schedules. It has been observed that the proposed MIP with a clustering based heuristic provides scalability and gives 10-30 percent improvement in energy with improved makespan and accuracy when compared with other duplication based energy aware algorithms.",
Training for Planning Tumour Resection: Augmented Reality and Human Factors,"Planning surgical interventions is a complex task, demanding a high degree of perceptual, cognitive, and sensorimotor skills to reduce intra- and post-operative complications. This process requires spatial reasoning to coordinate between the preoperatively acquired medical images and patient reference frames. In the case of neurosurgical interventions, traditional approaches to planning tend to focus on providing a means for visualizing medical images, but rarely support transformation between different spatial reference frames. Thus, surgeons often rely on their previous experience and intuition as their sole guide is to perform mental transformation. In case of junior residents, this may lead to longer operation times or increased chance of error under additional cognitive demands. In this paper, we introduce a mixed augmented-/virtual-reality system to facilitate training for planning a common neurosurgical procedure, brain tumour resection. The proposed system is designed and evaluated with human factors explicitly in mind, alleviating the difficulty of mental transformation. Our results indicate that, compared to conventional planning environments, the proposed system greatly improves the nonclinicians' performance, independent of the sensorimotor tasks performed (p <; 0.01). Furthermore, the use of the proposed system by clinicians resulted in a significant reduction in time to perform clinically relevant tasks (p <; 0.05). These results demonstrate the role of mixed-reality systems in assisting residents to develop necessary spatial reasoning skills needed for planning brain tumour resection, improving patient outcomes.","Planning,
Surgery,
Tumors,
Rendering (computer graphics),
Visualization,
Phantoms,
Head"
Sectorized Antenna-based DoA Estimation and Localization: Advanced Algorithms and Measurements,"Sectorized antennas are a promising class of antennas for enabling direction-of-arrival (DoA) estimation and successive transmitter localization. In contrast to antenna arrays, sectorized antennas do not require multiple transceiver branches and can be implemented using a single RF front-end only, thus reducing the overall size and cost of the devices. However, for good localization performance the underlying DoA estimator is of uttermost importance. In this paper, we therefore propose a novel high performance DoA estimator for sectorized antennas that does not require cooperation between the transmitter and the localizing network. The proposed DoA estimator is broadly applicable with different sectorized antenna types and signal waveforms, and has low computational complexity. Using computer simulations, we show that our algorithm approaches the respective Cramer-Rao lower bound for DoA estimation variance if the signal-to-noise ratio (SNR) is moderate to large and also outperforms the existing estimators. Moreover, we also derive analytical error models for the underlying DoA estimation principle considering both free space as well as multipath propagation scenarios. Furthermore, we also address the fusion of the individual DoA estimates into a location estimate using the Stansfield algorithm and study the corresponding localization performance in detail. Finally, we show how to implement the localization in practical systems and demonstrate the achievable performance using indoor RF measurements obtained with practical sectorized antenna units.","Direction-of-arrival estimation,
Estimation,
Antenna measurements,
Antenna arrays,
Signal to noise ratio,
Computational modeling"
3D Modeling of Spatio-temporal Heat-transport in III-V Gate-all-around Transistors Allows Accurate Estimation and Optimization of Nanowire Temperature,"Excellent electrostatic control offered by gate-all-around (GAA) geometry makes multinanowire (multi-NW) MOSFET a promising candidate for sub-10-nm technology nodes. Unfortunately, the GAA geometry is susceptible to the increased self-heating due to poor heat dissipation from the nanowires (NWs) to the substrate. Therefore, an understanding of spatio-temporal temperature rise, AT(x, y, z; t), at the NW level is important for predicting activity-induced variability within an IC, as well as characterization of various reliability issues, such as, NBTI, PBTI, HCI, and TDDB that depend sensitively on self-heating. In this paper, a 3-D electrothermal simulation model is developed to explore and interpret self-heating and heat dissipation in GAA devices. Our results identify complex heat dissipation pathways characterized by multiple time constants. First, the nanowires heat up quickly (τGAA-NW ~ nSec), then heat spreads all over the gate contact pad (τG-pad ~ 100 nSec), and finally, the heat exits through the heat sink at the bottom of the substrate (τsub ~ mSec). A systematic thermoreflectance measurement of temperature helps us to identify the time constants, and validates the model. Our results have implications for the design, characterization, circuit-operation, and reliability of high-performance GAA devices.","Heating,
Logic gates,
Transistors,
Temperature measurement,
Substrates,
Geometry,
Heat sinks"
A Unifying Framework of Mining Trajectory Patterns of Various Temporal Tightness,"Discovering trajectory patterns is shown to be very useful in learning interactions between moving objects. Many types of trajectory patterns have been proposed in the literature, but previous methods were developed for only a specific type of trajectory patterns. This limitation could make pattern discovery tedious and inefficient since users typically do not know which types of trajectory patterns are hidden in their data sets. Our main observation is that many trajectory patterns can be arranged according to the strength of temporal constraints. In this paper, we propose a unifying framework of mining trajectory patterns of various temporal tightness, which we call unifying trajectory patterns (UT-patterns). This framework consists of two phases: initial pattern discovery and granularity adjustment. A set of initial patterns are discovered in the first phase, and their granularities (i.e., levels of detail) are adjusted by split and merge to detect other types in the second phase. As a result, the structure called a pattern forest is constructed to show various patterns. Both phases are guided by an information-theoretic formula without user intervention. Experimental results demonstrate that our framework facilitates easy discovery of various patterns from real-world trajectory data.","Trajectory,
Data mining,
Clustering algorithms,
Partitioning algorithms,
Animals,
Electronic mail,
Vectors"
Energy Delay Tradeoff in Cloud Offloading for Multi-Core Mobile Devices,"Cloud offloading is considered a promising approach for both energy conservation and storage/computation enhancement for resource-limited mobile devices. In this paper, we present a Lyapunov optimization-based scheme for cloud offloading scheduling, as well as download scheduling for cloud execution output, for multiple applications running in a mobile device with a multi-core CPU. We derive an online algorithm and prove performance bounds for the proposed algorithm with respect to average power consumption and average queue length, which is indicative of delay, and reveal the fundamental tradeoff between the two optimization goals. The performance of the proposed online scheduling scheme is validated with trace-driven simulations.","Cloud computing,
Energy efficiency,
Job shop scheduling,
Lyapunov optimization,
Load management,
Energy conservation,
Storage management"
Robust and Energy-Efficient Trajectory Tracking for Mobile Devices,"Many mobile location-aware applications require the sampling of trajectory data accurately over an extended period of time. However, continuous trajectory tracking poses new challenges to the overall battery life of the device, and thus novel energy-efficient sensor management strategies are necessary for improving the lifetime of such applications. Additionally, such sensor management strategies are required to provide a high and application-adjustable level of robustness regardless of the user's transportation mode. In this article, we extend and further analyze the sensor management strategies of the EnTrackedT system that intelligently determines when to sample different on-device sensors (e.g., accelerometer, compass and GPS) for trajectory tracking. Specifically, we propose the concept of situational bounding to improve and parameterize the robustness of sensor management strategies for trajectory tracking. We demonstrate the effectiveness of our proposed approach by performing a series of emulation experiments on real world data sets collected from different modes of transportation (including walking, running, biking and commuting by car) on mobile devices from two different platforms. Thorough experimental analyses indicate that our system can save significant amounts of battery power compared to the state-of-the-art position tracking systems, while simultaneously maintaining robustness and accuracy bounds as required by diverse location-aware applications.","Trajectory,
Robustness,
Global Positioning System,
Accuracy,
Power demand,
Target tracking"
Face video retrieval with image query via hashing across Euclidean space and Riemannian manifold,"Retrieving videos of a specific person given his/her face image as query becomes more and more appealing for applications like smart movie fast-forwards and suspect searching. It also forms an interesting but challenging computer vision task, as the visual data to match, i.e., still image and video clip are usually represented quite differently. Typically, face image is represented as point (i.e., vector) in Euclidean space, while video clip is seemingly modeled as a point (e.g., covariance matrix) on some particular Riemannian manifold in the light of its recent promising success. It thus incurs a new hashing-based retrieval problem of matching two heterogeneous representations, respectively in Euclidean space and Riemannian manifold. This work makes the first attempt to embed the two heterogeneous spaces into a common discriminant Hamming space. Specifically, we propose Hashing across Euclidean space and Riemannian manifold (HER) by deriving a unified framework to firstly embed the two spaces into corresponding reproducing kernel Hilbert spaces, and then iteratively optimize the intra- and inter-space Hamming distances in a max-margin framework to learn the hash functions for the two spaces. Extensive experiments demonstrate the impressive superiority of our method over the state-of-the-art competitive hash learning methods.","Manifolds,
Kernel,
Face,
Covariance matrices,
Training,
Hilbert space,
Learning systems"
Where Do Configuration Constraints Stem From? An Extraction Approach and an Empirical Study,"Highly configurable systems allow users to tailor software to specific needs. Valid combinations of configuration options are often restricted by intricate constraints. Describing options and constraints in a variability model allows reasoning about the supported configurations. To automate creating and verifying such models, we need to identify the origin of such constraints. We propose a static analysis approach, based on two rules, to extract configuration constraints from code. We apply it on four highly configurable systems to evaluate the accuracy of our approach and to determine which constraints are recoverable from the code. We find that our approach is highly accurate (93% and 77% respectively) and that we can recover 28% of existing constraints. We complement our approach with a qualitative study to identify constraint sources, triangulating results from our automatic extraction, manual inspections, and interviews with 27 developers. We find that, apart from low-level implementation dependencies, configuration constraints enforce correct runtime behavior, improve users' configuration experience, and prevent corner cases. While the majority of constraints is extractable from code, our results indicate that creating a complete model requires further substantial domain knowledge and testing. Our results aim at supporting researchers and practitioners working on variability model engineering, evolution, and verification techniques.","Feature extraction,
Kernel,
Accuracy,
Linux,
Manuals,
Interviews"
Automatic Feature Learning to Grade Nuclear Cataracts Based on Deep Learning,"Goal: Cataracts are a clouding of the lens and the leading cause of blindness worldwide. Assessing the presence and severity of cataracts is essential for diagnosis and progression monitoring, as well as to facilitate clinical research and management of the disease. Methods: Existing automatic methods for cataract grading utilize a predefined set of image features that may provide an incomplete, redundant, or even noisy representation. In this study, we propose a system to automatically learn features for grading the severity of nuclear cataracts from slit-lamp images. Local filters are first acquired through clustering of image patches from lenses within the same grading class. The learned filters are fed into a convolutional neural network, followed by a set of recursive neural networks, to further extract higher order features. With these features, support vector regression is applied to determine the cataract grade. Results: The proposed system is validated on a large population-based dataset of 5378 images, where it outperforms the state of the art by yielding with respect to clinical grading a mean absolute error (ε) of 0.304, a 70.7% exact integral agreement ratio (R0), an 88.4% decimal grading error ≤0.5 (Re0.5), and a 99.0% decimal grading error ≤1.0 (Re1.0). Significance: The proposed method is useful for assisting and improving clinical management of the disease in the context of large-population screening and has the potential to be applied to other eye diseases.","Lenses,
Feature extraction,
Neural networks,
Visualization,
Image color analysis,
Training,
Standards"
Exploring Spin Transfer Torque Devices for Unconventional Computing,"This paper reviews the potential of spin-transfer torque devices as an alternative to complementary metal-oxide-semiconductor for non-von Neumann and non-Boolean computing. Recent experiments on spin-transfer torque devices have demonstrated high-speed magnetization switching of nanoscale magnets with small current densities. Coupled with other properties, such as nonvolatility, zero leakage current, high integration density, we discuss that the spin-transfer torque devices can be inherently suitable for some unconventional computing models for information processing. We review several spintronic devices in which magnetization can be manipulated by current induced spin transfer torque and explore their applications in neuromorphic computing and reconfigurable memory-based computing.","Magnetic tunneling,
Magnetic domain walls,
Magnetic domains,
Torque,
Neurons,
Magnetization"
Discrete Rate Scheduling for Packets With Individual Deadlines in Energy Harvesting Systems,"This paper presents an optimal rate scheduling algorithm called Truncation for an energy-harvesting enabled wireless transmitter to transmit a set of dynamically arrived packets with minimum transmission energy. Distinct from existing works, we allow packets to have individual delay constraints, which is the most general model ever assumed but is very much desired to guarantee per-application quality-of-service (QoS). Moreover, we restrict the allowable rates to a set of discrete values, which is more practical and required in many real applications. As the first achievement, we obtain an optimal offline algorithm, which assumes the rate is continuously adjustable. Then, we propose a general framework that transforms any algorithm using the continuous-rate model into an algorithm using only discrete-rates, while preserving the optimality as long as the optimality holds for convex rate-power functions. It is possible that the harvested energy is insufficient to guarantee all packets to meet their deadlines. Should this occur, maximizing throughput with the limited available energy becomes the goal to achieve. Our Truncation algorithm is able to identify this case and produces a schedule that guarantees maximum throughput, if packets share a common deadline. Furthermore, based on the optimal offline algorithms, an efficient online algorithm is designed which has been shown by simulations to produce near optimal results.","Schedules,
Throughput,
Energy consumption,
Delays,
Scheduling,
Energy harvesting,
Transmitters"
Model Predictive Control of a Nonlinear 2-Body Point Absorber Wave Energy Converter With Estimated State Feedback,"Ocean wave energy has the potential to significantly contribute to sustainable power generation in coastal regions. Much of the research effort has gone into developing time domain state space models of point absorber wave energy converters (WECs) and subsequently into model-based optimal control to efficiently harvest the maximum possible amount of energy. The resulting controllers require knowledge of the states of the WEC in order to achieve the design goals. The purpose of this paper is to design and apply an extended Kalman filter-based estimation algorithm to a nonlinear two-body WEC model and to evaluate its performance in conjunction with a model predictive controller (MPC), which maximizes energy yield while satisfying operational constraints.",
Endurance-Aware Allocation of Data Variables on NVM-Based Scratchpad Memory in Real-Time Embedded Systems,"Nonvolatile memory (NVM) has many benefits compared to the traditional static RAM, such as improved reliability and reduced power consumption, but it has long write latency and limited write endurance. Scratchpad memory (SPM) is software-managed small on-chip memory for improving system performance and predicability. We consider SPM based on spin-transfer torque RAM, a type of NVM with high performance and good endurance. We present algorithms for allocating data variables to SPM and distribute write activity evenly in the SPM address space, in order to achieve wear-leveling and prolong the lifetime of NVM. We present two optimization algorithms for minimizing system CPU utilization subject to NVM lifetime constraints: 1) an optimal algorithm based on ILP and 2) an efficient heuristic algorithm that can obtain close-to-optimal solutions.","Resource management,
Nonvolatile memory,
Random access memory,
Heuristic algorithms,
Runtime,
Embedded systems,
Optimization"
The STOne Transform: Multi-Resolution Image Enhancement and Compressive Video,"Compressive sensing enables the reconstruction of high-resolution signals from under-sampled data. While the compressive methods simplify data acquisition, they require the solution of difficult recovery problems to make use of the resulting measurements. This paper presents a new sensing framework that combines the advantages of both the conventional and the compressive sensing. Using the proposed sum-to-one transform, the measurements can be reconstructed instantly at the Nyquist rates at any power-of-two resolution. The same data can then be enhanced to higher resolutions using the compressive methods that leverage sparsity to beat the Nyquist limit. The availability of a fast direct reconstruction enables the compressive measurements to be processed on small embedded devices. We demonstrate this by constructing a real-time compressive video camera.","Image reconstruction,
Transforms,
Image coding,
Sensors,
Image resolution,
Cameras,
Streaming media"
Reliable multicast routing for software-defined networks,"Current traffic engineering in SDN mostly focuses on unicast. By contrast, compared with individual unicast, multicast can effectively reduce network resources consumption to serve multiple clients jointly. Since many important applications require reliable transmissions, it is envisaged that reliable multicast plays a crucial role when an SDN operator plans to provide multicast services. However, the shortest-path tree (SPT) adopted in current Internet is not bandwidth-efficient, while the Steiner tree (ST) in Graph Theory is not designed to support reliable transmissions since the selection of recovery nodes is not examined. In this paper, therefore, we propose a new reliable multicast tree for SDN, named Recover-aware Steiner Tree (RST). The goal of RST is to minimize both tree and recovery costs, while finding an RST is very challenging. We prove that the RST problem is NP-Hard and inapproximable within k, which is the number of destination nodes. Thus, we design an approximate algorithm, called Recover Aware Edge Reduction Algorithm (RAERA), to solve the problem. The simulation results on real networks and large synthetic networks, together with the experiment on our SDN testbed with real YouTube traffic, all manifest that RST outperforms both SPT and ST. Also, the implementation of RAERA in SDN controllers shows that an RST can be returned within a few seconds and thereby is practical for SDN networks.","Routing,
Reliability,
Computer network reliability,
Approximation algorithms,
Approximation methods,
TV,
Algorithm design and analysis"
"Fast Parallel MR Image Reconstruction via B1-Based, Adaptive Restart, Iterative Soft Thresholding Algorithms (BARISTA)","Sparsity-promoting regularization is useful for combining compressed sensing assumptions with parallel MRI for reducing scan time while preserving image quality. Variable splitting algorithms are the current state-of-the-art algorithms for SENSE-type MR image reconstruction with sparsity-promoting regularization. These methods are very general and have been observed to work with almost any regularizer; however, the tuning of associated convergence parameters is a commonly-cited hindrance in their adoption. Conversely, majorize-minimize algorithms based on a single Lipschitz constant have been observed to be slow in shift-variant applications such as SENSE-type MR image reconstruction since the associated Lipschitz constants are loose bounds for the shift-variant behavior. This paper bridges the gap between the Lipschitz constant and the shift-variant aspects of SENSE-type MR imaging by introducing majorizing matrices in the range of the regularizer matrix. The proposed majorize-minimize methods (called BARISTA) converge faster than state-of-the-art variable splitting algorithms when combined with momentum acceleration and adaptive momentum restarting. Furthermore, the tuning parameters associated with the proposed methods are unitless convergence tolerances that are easier to choose than the constraint penalty parameters required by variable splitting algorithms.",
Face Sketch Synthesis via Sparse Representation-Based Greedy Search,"Face sketch synthesis has wide applications in digital entertainment and law enforcement. Although there is much research on face sketch synthesis, most existing algorithms cannot handle some nonfacial factors, such as hair style, hairpins, and glasses if these factors are excluded in the training set. In addition, previous methods only work on well controlled conditions and fail on images with different backgrounds and sizes as the training set. To this end, this paper presents a novel method that combines both the similarity between different image patches and prior knowledge to synthesize face sketches. Given training photo-sketch pairs, the proposed method learns a photo patch feature dictionary from the training photo patches and replaces the photo patches with their sparse coefficients during the searching process. For a test photo patch, we first obtain its sparse coefficient via the learnt dictionary and then search its nearest neighbors (candidate patches) in the whole training photo patches with sparse coefficients. After purifying the nearest neighbors with prior knowledge, the final sketch corresponding to the test photo can be obtained by Bayesian inference. The contributions of this paper are as follows: 1) we relax the nearest neighbor search area from local region to the whole image without too much time consuming and 2) our method can produce nonfacial factors that are not contained in the training set and is robust against image backgrounds and can even ignore the alignment and image size aspects of test photos. Our experimental results show that the proposed method outperforms several state-of-the-arts in terms of perceptual and objective metrics.",
The Potential Energy of an Autoencoder,"Autoencoders are popular feature learning models, that are conceptually simple, easy to train and allow for efficient inference. Recent work has shown how certain autoencoders can be associated with an energy landscape, akin to negative log-probability in a probabilistic model, which measures how well the autoencoder can represent regions in the input space. The energy landscape has been commonly inferred heuristically, by using a training criterion that relates the autoencoder to a probabilistic model such as a Restricted Boltzmann Machine (RBM). In this paper we show how most common autoencoders are naturally associated with an energy function, independent of the training procedure, and that the energy landscape can be inferred analytically by integrating the reconstruction function of the autoencoder. For autoencoders with sigmoid hidden units, the energy function is identical to the free energy of an RBM, which helps shed light onto the relationship between these two types of model. We also show that the autoencoder energy function allows us to explain common regularization procedures, such as contractive training, from the perspective of dynamical systems. As a practical application of the energy function, a generative classifier based on class-specific autoencoders is presented.",
Data Partitioning on Multicore and Multi-GPU Platforms Using Functional Performance Models,"Heterogeneous multiprocessor systems, which are composed of a mix of processing elements, such as commodity multicore processors, graphics processing units (GPUs), and others, have been widely used in scientific computing community. Software applications incorporate the code designed and optimized for different types of processing elements in order to exploit the computing power of such heterogeneous computing systems. In this paper, we consider the problem of optimal distribution of the workload of data-parallel scientific applications between processing elements of such heterogeneous computing systems. We present a solution that uses functional performance models (FPMs) of processing elements and FPM-based data partitioning algorithms. Efficiency of this approach is demonstrated by experiments with parallel matrix multiplication and numerical simulation of lid-driven cavity flow on hybrid servers and clusters.","Kernel,
Central Processing Unit,
Multicore processing,
Computational modeling,
Data models,
Graphics processing units"
On the Accuracy of Phasor Angle Measurements in Power Networks,"As known, phasor measurement units (PMUs) greatly enhance smart grid monitoring capabilities with advantageous impacts on power network management. Generally, PMUs accuracy is expressed in terms of total vector error, which comprises the joint effect of both angle and magnitude errors, thus possibly concealing the algorithm ability to measure phase. Some recent research works emphasize the importance of measuring current or voltage phasor angle with high accuracy (in the order of a few milliradians) at the distribution level. Because this issue is seldom considered in the literature, in this paper the phase measurement accuracy of three algorithms, namely the basic DFT, the windowed Taylor-Fourier filter, and the interpolated dynamic DFT (IpD2 FT) estimator, is extensively analyzed by means of simulations performed in various conditions described in the Standards IEEE C37.118.1:2011 and EN 50160:2010. In addition, some meaningful considerations about the uncertainty contributions due to imperfect synchronization are reported.",
Ultrasound Volume Projection Imaging for Assessment of Scoliosis,"The standing radiograph is used as a gold standard to diagnose spinal deformity including scoliosis, a medical condition defined as lateral spine curvature . However, the health concern of X-ray and large inter-observer variation of measurements on X-ray images have significantly restricted its application, particularly for scoliosis screening and close follow-up for adolescent patients. In this study, a radiation-free freehand 3-D ultrasound system was developed for scoliosis assessment using a volume projection imaging method. Based on the obtained coronal view images, two measurement methods were proposed using transverse process and spinous profile as landmarks, respectively. As a reliability study, 36 subjects (age: 30.1 ±14.5; male: 12; female: 24) with different degrees of scoliosis were scanned using the system to test the inter- and intra-observer repeatability. The intra- and inter-observer tests indicated that the new assessment methods were repeatable, with ICC larger than 0.92. Small intra- and inter-observer variations of measuring spine curvature were observed for the two measurement methods (intra-: 1.4 ±1.0° and 1.4 ±1.1°; inter-: 2.2 ±1.6° and 2.5 ±1.6°). The results also showed that the spinal curvature obtained by the new method had good linear correlations with X-ray Cobb's method ( , 29 subjects). These results suggested that the ultrasound volume projection imaging method can be a promising approach for the assessment of scoliosis, and further research should be followed up to demonstrate its potential clinical applications for mass screening and curve progression and treatment outcome monitoring of scoliosis patients.","Ultrasonic imaging,
Three-dimensional displays,
Imaging,
Rendering (computer graphics),
Ultrasonic variables measurement,
Surface treatment,
Image reconstruction"
Automated Detection of Activity Transitions for Prompting,"Individuals with cognitive impairment can benefit from intervention strategies like recording important information in a memory notebook. However, training individuals to use the notebook on a regular basis requires a constant delivery of reminders. In this study, we design and evaluate machine-learning-based methods for providing automated reminders using a digital memory notebook interface. Specifically, we identify transition periods between activities as times to issue prompts. We consider the problem of detecting activity transitions using supervised and unsupervised machine-learning techniques and find that both techniques show promising results for detecting transition periods. We test the techniques in a scripted setting with 15 individuals. Motion sensors data are recorded and annotated as participants perform a fixed set of activities. We also test the techniques in an unscripted setting with eight individuals. Motion sensor data are recorded as participants go about their normal daily routine. In both the scripted and unscripted settings, a true positive rate of greater than 80% can be achieved while maintaining a false positive rate of less than 15%. On average, this leads to transitions being detected within 1 min of a true transition for the scripted data and within 2 min of a true transition on the unscripted data.","Intelligent sensors,
Sensor phenomena and characterization,
Smart homes,
Temperature sensors,
Supervised learning,
TV"
An Electrothermally Actuated VO2-Based MEMS Using Self-Sensing Feedback Control,"A self-sensing approach is used to accurately control the large displacements observed in VO2-based microelectromechanical systems actuators. The device is operated electrothermally using integrated resistive heaters. The coupling of the abrupt electrical and mechanical changes in VO2 films across its phase transition allow for the estimation of the device's deflection by monitoring the film's resistance. Furthermore, the typical hysteretic behavior observed in VO2 films is significantly reduced in the present device and the need for optical testing equipment is eliminated. The displacement-resistance relationship is modeled by a memoryless Boltzmann function consisting of four parameters, which are optimized to fit the experimental data with an average error of 1.1 μm throughout the complete actuation range of 95 μm. The estimated deflection is used as feedback to achieve closed-loop micropositioning control of the device, which is designed from the system dynamics obtained experimentally. Closed-loop sinusoidal and step reference response experiments are performed in order to show the effectiveness of the self-sensing feedback technique used. In the closed-loop sinusoidal frequency response, a cutoff frequency of 43 Hz is observed with a maximum actual deflection error of 0.19 dB up to the phase margin frequency of 30 Hz. In the step response, an average actual displacement steady-state error of ±1.15 μm is obtained with response times ranging from 5 to 12 ms.",
Distributed Data Fusion for Multirobot Search,"This paper presents novel data fusion methods that enable teams of vehicles to perform target search tasks without guaranteed communication. Techniques are introduced for merging estimates of a target's position from vehicles that regain contact after long periods of time, and a fully distributed team-planning algorithm is proposed, which utilizes limited shared information as it becomes available. The proposed data fusion techniques are shown to avoid overcounting information, which ensures that combining data from different vehicles will not decrease the performance of the search. Motivated by the underwater search domain, a realistic underwater acoustic communication channel is used to determine the probability of successful data transfer between two locations. The channel model is integrated into a simulation of multiple autonomous vehicles in both open water and harbor environments. The results demonstrate that the proposed distributed coordination techniques provide performance competitive with full communication.",
A Framework for Simultaneous Message Broadcasting Using CDMA-Based Visible Light Communications,"Internet of Things applications are fast growing recently. One of the things that has a lot of potential is the lighting equipment since it is widely used in our daily life. Recently, the technology of visible light communication (VLC) has been widely discussed. VLC has several advantages, such as freedom of license, line-of-sight security, and less health concern compared with radio-based systems. In addition, the rapid progress of light emitting diode (LED) technology by solid-state lighting allows VLC to be easily deployed and integrated with the existing lighting infrastructure at low costs. However, VLC, when integrated with lighting infrastructure, is usually for one-way communication and is highly sensitive to external interfering light. Thus, transmitting or broadcasting multiple messages simultaneously over a visible light channel without any preprocessing may result in serious collisions. In this paper, we propose a framework to tackle these problems by optical code division multiple access (CDMA) for VLC. With our approach, a VLC receiver can enter an environment without any prior configuration and can be designed with simple hardware. Even a mobile device with a high-resolution photodiode sensor can be used as a receiver. We demonstrate an application of indoor positioning by querying the location service provider on the Internet with the IDs decoded from the received light signals. The prototyping results reveal some communication properties of CDMA-based VLC and its potential for indoor positioning applications.",
Energy-efficient acceleration of big data analytics applications using FPGAs,"A recent trend for big data analytics is to provide heterogeneous architectures to allow support for hardware specialization. Considering the time dedicated to create such hardware implementations, an analysis that estimates how much benefit we gain in terms of speed and energy efficiency, through offloading various functions to hardware would be necessary. This work analyzes data mining and machine learning algorithms, which are utilized extensively in big data applications in a heterogeneous CPU+FPGA platform. We select and offload the computational intensive kernels to the hardware accelerator to achieve the highest speed-up and best energy-efficiency. We use the latest Xilinx Zynq boards for implementation and result analysis. We also perform a first order comprehensive analysis of communication and computation overheads to understand how the speedup of each application contributes to its overall execution in an end-to-end Hadoop MapReduce environment. Moreover, we study how other system parameters such as the choice of CPU (big vs little) and the number of mapper slots affect the performance and power-efficiency benefits of hardware acceleration. The results show that a kernel speedup of upto χ 321.5 with hardware+software co-design can be achieved. This results in χ2.72 speedup, 2.13χ power reduction, and 15.21χ energy efficiency improvement (EDP) in an end-to-end Hadoop MapReduce environment.","Big data,
Servers,
Field programmable gate arrays,
Hardware,
Acceleration,
Kernel,
Support vector machines"
Polar Coding for Secret-Key Generation,"Practical implementations of secret-key generation are often based on sequential strategies, which handle reliability and secrecy in two successive steps, called reconciliation and privacy amplification. In this paper, we propose an alternative approach based on polar codes that jointly deals with reliability and secrecy. Specifically, we propose secret-key capacity-achieving polar coding schemes for the following models: (i) the degraded binary memoryless source (DBMS) model with rate-unlimited public communication, (ii) the DBMS model with one-way rate-limited public communication, (iii) the 1-to-m broadcast model and (iv) the Markov tree model with uniform marginals. For models (i) and (ii) our coding schemes remain valid for non-degraded sources, although they may not achieve the secret-key capacity. For models (i), (ii) and (iii), our schemes rely on pre-shared secret seed of negligible rate; however, we provide special cases of these models for which no seed is required. Finally, we show an application of our results to secrecy and privacy for biometric systems. We thus provide the first examples of low-complexity secret-key capacity-achieving schemes that are able to handle vector quantization for model (ii), or multiterminal communication for models (iii) and (iv).","Encoding,
Reliability,
Privacy,
Biological system modeling,
Decoding,
Protocols,
Markov processes"
Real-time embedded age and gender classification in unconstrained video,"In this paper, we present a complete framework for video-based age and gender classification which performs accurately on embedded systems in real-time and under unconstrained conditions. We propose a segmental dimensionality reduction technique using Enhanced Discriminant Analysis (EDA) to reduce the memory requirements up to 99.5%. A non-linear Support Vector Machine (SVM) along with a discriminative demographics classification strategy is exploited to improve both accuracy and performance. Also, we introduce novel improvements for face alignment and illumination normalization in unconstrained environments. Our cross-database evaluations demonstrate competitive recognition rates compared to the resource-demanding state-of-the-art approaches.","Face,
Support vector machines,
Noise,
Lighting,
Training,
Feature extraction,
Histograms"
Data-driven analytics for automated cell outage detection in Self-Organizing Networks,"In this paper, we address the challenge of autonomous cell outage detection (COD) in Self-Organizing Networks (SON). COD is a pre-requisite to trigger fully automated self-healing recovery actions following cell outages or network failures. A special case of cell outage, referred to as Sleeping Cell (SC) remains particularly challenging to detect in state-of-the-art SON, since it triggers no alarms for Operation and Maintenance (O&M) entity. Consequently, no SON compensation function can be launched unless site visits or drive tests are performed, or complaints are received by affected customers. To address this issue, we present and evaluates a COD framework, which is based on minimization of drive test (MDT) reports, a functionality recently specified in third generation partnership project (3GPP) Release 10, for LTE Networks. Our proposed framework aims to detect cell outages in an autonomous fashion by first pre-processing the MDT measurements using multidimensional scaling method and further employing it together with machine learning algorithms to detect and localize anomalous network behaviour. We validate and demonstrate the effectiveness of our proposed solution using the data obtained from simulating the network under various operational settings.","Computer architecture,
Microprocessors,
Data models,
Databases,
Mathematical model,
Support vector machines,
Phase measurement"
Examination of incentive based demand response in western connection reduced model,"In this paper, an incentive base demand response (DR) program is proposed that has advantages for smaller residential consumers. In this model, a Load Serving Entity (LSE) needs to determine desired load reduction and an adequate incentive payment for their customers through the DR program. The program should be simple to implement for both the customer and LSE while achieving savings. Two different thresholds above market variable price aredered as the trigger for the proposed DR program: constant and a variable optimum threshold that is found by the optimization proposed in this paper. In this optimization framework, the savings for the LSE and customer is considered as well as the client convenience based on the number of requests for load change in each day and season under the DR program. Results show a constant threshold has more impact on locational marginal price (LMP) average and volatility in the high load season but a variable threshold can achieve benefits throughout the year.",
Adaptive cruise control: Experimental validation of advanced controllers on scale-model cars,"Recent advances in automotive technology, such as, sensing and onboard computation, have resulted in the development of adaptive cruise control (ACC) algorithms that improve both comfort and safety. With a view towards developing advanced controllers for ACC, this paper presents an experimental platform for validation and demonstration of an online optimization based controller. Going beyond traditional PID based controllers for ACC that lack proof of safety, we construct a control framework that gives formal guarantees of correctness. In particular, safety constraints-maintaining a valid following distance from a lead car-are represented by control barrier functions (CBFs), and control objectives- achieving a desired speed-are encoded through control Lyapunov functions (CLFs). These different objectives can be unified through a quadtraic program (QP), with constraints dictated by CBFs and CLFs, that balances safety and the control objectives in an optimal fashion. This methodology is demonstrated on scale-model cars, for which the CBF-CLF based controller is implemented online, with the end result being the experimental validation of an advanced adaptive cruise controller.","Vehicles,
Safety,
Lead,
Mathematical model,
Wheels,
Cruise control,
Boards"
Stability conditions for a digital discrete-time non-Foster circuit element,"Digital discrete-time implementations of non-Foster circuit elements offer an alternative to conventional analog circuit approaches. In particular, the design of a discrete-time negative capacitor is investigated, since such non-Foster circuit elements offer significant potential in wideband antenna, metamaterial, and artificial magnetic conductor applications. As with analog non-Foster circuits, stability is an important design consideration for digital non-Foster elements. Therefore, stability conditions and simulation results are presented for a discrete-time negative capacitor, and the onset of instability is shown near the predicted stability boundary.","Stability analysis,
Capacitors,
Circuit stability,
Impedance,
Simulation,
Transfer functions,
Welding"
Patient Infusion Pattern based Access Control Schemes for Wireless Insulin Pump System,"Wireless insulin pumps have been widely deployed in hospitals and home healthcare systems. Most of them have limited security mechanisms embedded to protect them from malicious attacks. In this paper, two attacks against insulin pump systems via wireless links are investigated: a single acute overdose with a significant amount of medication and a chronic overdose with a small amount of extra medication over a long time period. They can be launched unobtrusively and may jeopardize patients' lives. It is very urgent to protect patients from these attacks. We propose a novel personalized patient infusion pattern based access control scheme (PIPAC) for wireless insulin pumps. This scheme employs supervised learning approaches to learn normal patient infusion patterns in terms of the dosage amount, rate, and time of infusion, which are automatically recorded in insulin pump logs. The generated regression models are used to dynamically configure a safe infusion range for abnormal infusion identification. This model includes two sub models for bolus (one type of insulin) abnormal dosage detection and basal abnormal rate detection. The proposed algorithms are evaluated with real insulin pump. The evaluation results demonstrate that our scheme is able to detect the two attacks with a very high success rate.","Insulin,
Wireless communication,
Communication system security,
Wireless sensor networks,
Diabetes,
Access control,
Universal Serial Bus"
Algorithms for advance bandwidth reservation in media production networks,"Media production generally requires many geographically distributed actors (e.g., production houses, broadcasters, advertisers) to exchange huge amounts of raw video and audio data. Traditional distribution techniques, such as dedicated point-to-point optical links, are highly inefficient in terms of installation time and cost. To improve efficiency, shared media production networks that connect all involved actors over a large geographical area, are currently being deployed. The traffic in such networks is often predictable, as the timing and bandwidth requirements of data transfers are generally known hours or even days in advance. As such, the use of advance bandwidth reservation (AR) can greatly increase resource utilization and cost efficiency. In this paper, we propose an Integer Linear Programming formulation of the bandwidth scheduling problem, which takes into account the specific characteristics of media production networks, is presented. Two novel optimization algorithms based on this model are thoroughly evaluated and compared by means of in-depth simulation results.","Bandwidth,
Production,
Media,
Heuristic algorithms,
Streaming media,
Schedules,
Linear programming"
Optimal Charging of Electric Vehicles With Uncertain Departure Times: A Closed-Form Solution,"In this paper, we show that an uncertain departure time significantly changes the analysis in optimizing the charging schedule of electric vehicles (EVs). We also obtain a closed-form solution for the stochastic optimization problem that is formulated to schedule charging of EVs with uncertain departure times in presence of hourly time-of-use pricing tariffs.","Electricity,
Charging stations,
Electric vehicles,
Schedules,
Smart grids,
Closed-form solutions,
Optimization"
Advanced controller design for a series-series compensated inductive power transfer charging infrastructure using asymmetrical clamped mode control,"Wireless charging of electric vehicles require a significant air gap between the primary and secondary winding of an inductive power transfer (IPT) system. Due to the existence of the air gap, power flow regulation to keep the output voltage constant becomes a non-trivial task. Hence, the bandwidth, phase margin, and gain margin of the voltage control loops should be appropriately designed, in order to guarantee a robust system. In this paper, a generalized small-signal modelling of series-series compensated (SS topology) IPT system using extended describing function concept has been presented. Using this small-signal model, a controller has been designed for fixed frequency and variable duty cycle, to control the output voltage. Since an asymmetrical clamped mode control (ACM) requires a lower switching frequency compared to the popular fixed frequency control strategies, viz. symmetrical clamed mode control (SCM) and asymmetrical duty cycle control (ADC), it has been used to control the output voltage.","Topology,
Frequency control,
Voltage control,
Resonant frequency,
Integrated circuit modeling,
Switching frequency,
Mathematical model"
Optimization Integrator for Large Time Steps,"Practical time steps in today's state-of-the-art simulators typically rely on Newton's method to solve large systems of nonlinear equations. In practice, this works well for small time steps but is unreliable at large time steps at or near the frame rate, particularly for difficult or stiff simulations. We show that recasting backward Euler as a minimization problem allows Newton's method to be stabilized by standard optimization techniques with some novel improvements of our own. The resulting solver is capable of solving even the toughest simulations at the 24Hz frame rate and beyond. We show how simple collisions can be incorporated directly into the solver through constrained minimization without sacrificing efficiency. We also present novel penalty collision formulations for self collisions and collisions against scripted bodies designed for the unique demands of this solver. Finally, we show that these techniques improve the behavior of Material Point Method (MPM) simulations by recasting it as an optimization problem.","Newton method,
Minimization,
Optimization,
Robustness,
Mathematical model,
Digital TV,
Nonlinear systems"
A Novel LS-SVM Modeling Method for a Hydraulic Press Forging Process With Multiple Localized Solutions,"An effective model of the forging process is crucial for the optimal operation and health management of a hydraulic press machine (HPM). Modeling this forging process is difficult, because multiple localized nonlinear solutions and modeling of unknown complex interactions between localized regions are required. In this paper, a novel least squares support vector machine (LS-SVM) method is developed for modeling the forging process. The proposed method integrates the advantages of local LS-SVM modeling and global regularization. Local LS-SVM modeling is performed to capture the local dynamics for each local working region. Global regularization is performed to minimize the global error and improve the global generalization of the local models. These features guarantee continuity and smoothness between the local LS-SVM models and avoid over-fitting of each local LS-SVM model. The algorithm developed here is simple and may easily be added into existing HPM systems. Experiment data from a practical HPM demonstrate the effectiveness of the proposed method.","Force,
Load modeling,
Friction,
Kernel,
Dynamics,
Mathematical model,
Support vector machines"
Analysis of LEACH protocol(s) using formal verification,"WSN nodes operate in an unattended environment and thus have irreplaceable batteries. Thus an important concern is the network lifetime; we need to utilize their energy for a longer time otherwise nodes run out of power. For this purpose various protocols have been established and the subject of our matter is the LEACH protocol. The LEACH protocol is self-organizing and is characterized as an adaptive clustering protocol which uses randomly distributes energy load among nodes. By using cluster heads and data aggregation excessive energy consumption is avoided. In this paper we analyzed LEACH and its extensions like LEACH-C and LEACH-F using Formal modeling techniques. Formal modeling is often used by researchers these days to verify a variety of routing protocols. By using formal verification one can precisely confirm the authenticity of results and worst case scenarios, a solution not possible using computer simulations and hardware implementation. In this paper, we have applied formal verification to compare how efficient LEACH is as compared to its extensions in various WSN topologies. The paper is not about design improvement of LEACH but to formally verify its correctness, efficiency and performance as already stated. This work is novel as LEACH and its extensions according to our knowledge have not been analyzed using formal verification techniques.","Wireless sensor networks,
Formal verification,
Routing protocols,
IP networks"
Chime-home: A dataset for sound source recognition in a domestic environment,"For the task of sound source recognition, we introduce a novel data set based on 6.8 hours of domestic environment audio recordings. We describe our approach of obtaining annotations for the recordings. Further, we quantify agreement between obtained annotations. Finally, we report baseline results for sound source recognition using the obtained dataset. Our annotation approach associates each 4-second excerpt from the audio recordings with multiple labels, based on a set of 7 labels associated with sound sources in the acoustic environment. With the aid of 3 human annotators, we obtain 3 sets of multi-label annotations, for 4378 4-second audio excerpts. We evaluate agreement between annotators by computing Jaccard indices between sets of label assignments. Observing varying levels of agreement across labels, with a view to obtaining a representation of ‘ground truth’ in annotations, we refine our dataset to obtain a set of multi-label annotations for 1946 audio excerpts. For the set of 1946 annotated audio excerpts, we predict binary label assignments using Gaussian mixture models estimated on MFCCs. Evaluated using the area under receiver operating characteristic curves, across considered labels we observe performance scores in the range 0.76 to 0.98. Dataset URL: http://archive.org/details/chime-home","Acoustics,
Speech,
Speech processing,
Audio recording,
Conferences,
Speech recognition"
A Novel Nondestructive Read/Write Circuit for Memristor-Based Memory Arrays,"Emerging nonvolatile universal memory technology is vital for providing the huge storage capabilities, which is needed for nanocomputing facilities. Memristor, which is recently discovered and known as the missing fourth circuit element, is a potential candidate for the next-generation memory. Memristor has received extra attention in the last few years. To support this effort, this paper presents a novel read/write circuit that facilitates the reading and writing operation of the Memristor device as a memory element. The advantages of the proposed read/write circuit are threefold. First, the proposed circuit has a nondestructive successive reading cycle capability. Second, it occupies less die area. Finally, the proposed read/write circuit offers a significant improvement in power consumption and delay time compared with other read/write circuits.","Memristors,
Writing,
Computational modeling,
Resistance,
Integrated circuit modeling,
Power demand"
Triple- and Quadruple-Mode Wideband Bandpass Filter Using Simple Perturbation in Single Metal Cavity,"This paper proposes a novel class of wideband metal cavity multiple-mode bandpass filters (BPFs), consisting of a triple-mode filter and a quadruple-mode filter. Two TE11 degeneration modes in a single metal cavity are excited by using an off-centered approach instead of a traditional corner-cut approach. They work together with the TM10 mode to constitute a three-pole wide passband with a fractional bandwidth of 30% at the central frequency of 3.2 GHz. Moreover, an off-centered metal cylinder can properly excite an extra TM11 mode in the passband. As such, this TM11 mode, TM10 mode, and a pair of degeneration TE11 modes can be simultaneously utilized to form a quadruple-mode BPF. Compared with the triple-mode BPF, the quadruple-mode BPF has better performance in term of the steepness of rejection skirt. The fractional bandwidth of this BPF can achieve up to 31%. In final, the two proposed BPFs are fabricated by using the silver plated aluminum technology. Measured S-parameter frequency response and group delay have satisfactorily matched with the simulated results.","Metals,
Cavity resonators,
Wideband,
Band-pass filters,
Couplings,
Probes"
"The t/k
-Diagnosability of Star Graph Networks","The t/k-diagnosis is a diagnostic strategy at system level that can significantly enhance the system's self-diagnosing capability. It can detect up to t faulty processors (or nodes, units) which might include at most k misdiagnosed processors, where k is typically a small number. Somani and Peleg ([26], 1996) claimed that an n-dimensional Star Graph (denoted Sn), a well-studied interconnection model for multiprocessor systems, is ((k + 1)n - 3k - 2)/k-diagnosable. Recently, Chen and Liu ([5], 2012) found counterexamples for the diagnosability obtained in [26], without further pursuing the cause of the flawed result. In this paper, we provide a new, complete proof that an n-dimensional Star Graph is actually ((k + 1)n - 3k - 1)/k-diagnosable, where 1 ≤ k ≤ 3, and investigate the reason that caused the flawed result in [26]. Based on our newly obtained fault-tolerance properties, we will also outline an O(N log N) diagnostic algorithm ( N = n! is the number of nodes in Sn) to locate all (up to (k + 1)n - 3k - 1) faulty processors, among which at most k (1 ≤ k ≤ 3) fault-free processors might be wrongly diagnosed as faulty.","Tin,
Program processors,
Silicon,
Fault tolerance,
Fault tolerant systems,
Fault diagnosis,
Multiprocessing systems"
Optimal Fractional Repetition Codes Based on Graphs and Designs,"Fractional repetition (FR) codes is a family of codes for distributed storage systems (DSSs) that allow for uncoded exact repairs having the minimum repair bandwidth. However, in contrast to minimum bandwidth regenerating (MBR) codes, where an arbitrary set of a certain size of available nodes is used for a node repair, the repairs with FR codes are table based. This usually allows to store more data compared with MBR codes. In this paper, we consider bounds on the FR capacity, which is the maximum amount of data that can be stored using an FR code. Optimal FR codes which attain these bounds are presented. The constructions of these FR codes are based on combinatorial designs and on families of regular and biregular graphs. These constructions of FR codes for given parameters raise some interesting questions in graph theory. These questions and some of their solutions are discussed in this paper. In addition, based on a connection between FR codes and batch codes, we propose a new family of codes for DSS, namely, FR batch codes, which have the properties of batch codes and FR codes simultaneously. These are the first codes for DSS which allow for uncoded efficient exact repairs and load balancing which can be performed by several users in parallel. Other concepts related to FR codes are also discussed.","Maintenance engineering,
Bandwidth,
Decision support systems,
Bipartite graph,
Encoding"
Equivalent-Sparse Unmixing Through Spatial and Spectral Constrained Endmember Selection From an Image-Derived Spectral Library,"Spectral variation, which is inevitably present in hyperspectral data due to nonuniformity and inconsistency of illumination, may result in considerable difficulty in spectral unmixing. In this paper, a field endmember library is constructed to accommodate spectral variation by representing each endmember class by a batch of image-derived spectra. In order to perform unmixing by such a field endmember library, a novel spatial and spectral endmember selection (SSES) algorithm is designed to search for a spatial and spectral constrained endmember subset per pixel for abundance estimation (AE). The net effect is to achieve sparse unmixing equivalently, considering the fact that only a few endmembers in the large library have nonzero abundances. Thus, the resulting algorithm is called spatial and spectral constrained sparse unmixing (SSCSU). Experimental results using both synthetic and real hyperspectral images demonstrate that the proposed SSCSU algorithm not only improves the performance of traditional AE algorithms by considering spectral variation, but also outperforms the existing sparse unmixing approaches.","Libraries,
Algorithm design and analysis,
Hyperspectral imaging,
Indexes,
Materials,
Bayes methods,
Vectors"
Harnessing encrypted data in cloud for secure and efficient image sharing from mobile devices,"In storage outsourcing, highly correlated datasets can occur commonly, where the rich information buried in correlated data can be useful for many cloud data generation/dissemination services. In light of this, we propose to enable a secure and efficient cloud-assisted image sharing architecture for mobile devices, by leveraging outsourced encrypted image datasets with privacy assurance. Different from traditional image sharing, the proposed design aims to save the transmission cost from mobile clients, by directly utilizing outsourced correlated images to reproduce the image of interest inside the cloud for immediate dissemination. While the benefits are obvious, how to leverage the encrypted image datasets makes the problem particular challenging. To tackle the problem, we first propose a secure and efficient index design that allows the mobile client to securely find from the encrypted image datasets the candidate selection pertaining to the image of interest for sharing. We then design two specialized encryption mechanisms that support the secure image reproduction inside the cloud directly from the encrypted candidate selection. We formally analyze the security strength of the design. Our experiments show that up to 90% of the transmission cost at the mobile client can be saved, while achieving all service requirements and security guarantees.","Mobile communication,
Encryption,
Servers,
Feature extraction,
Indexes"
Software defined network traffic measurement: Current trends and challenges,"Next generation networks such as Software Defined Networks (SDN) must support the integration of new paradigms of service offerings such as virtual cloud computing, big data applications, data centers services, and rich multimedia content. Operators of next generation SDNs are responsible for configuring policies that employ traffic monitoring tools and measurement mechanisms to detect and react to a wide range of network events and applications. In this article, we take a look at traffic measurement methods in SDNs, cover their strengths and weaknesses, point to open issues, and remaining future challenges.","Software radio,
Current measurement,
Monitoring,
Real-time systems,
Next generation networking,
Quality of service,
Telecommunication traffic"
Design and Analysis of Multimodel-Based Anomaly Intrusion Detection Systems in Industrial Process Automation,"Industrial process automation is undergoing an increased use of information communication technologies due to high flexibility interoperability and easy administration. But it also induces new security risks to existing and future systems. Intrusion detection is a key technology for security protection. However, traditional intrusion detection systems for the IT domain are not entirely suitable for industrial process automation. In this paper, multiple models are constructed by comprehensively analyzing the multidomain knowledge of field control layers in industrial process automation, with consideration of two aspects: physics and information. And then, a novel multimodel-based anomaly intrusion detection system with embedded intelligence and resilient coordination for the field control system in industrial process automation is designed. In the system, an anomaly detection based on multimodel is proposed, and the corresponding intelligent detection algorithms are designed. Furthermore, to overcome the disadvantages of anomaly detection, a classifier based on an intelligent hidden Markov model, is designed to differentiate the actual attacks from faults. Finally, based on a combination simulation platform using optimized performance network engineering tool, the detection accuracy and the real-time performance of the proposed intrusion detection system are analyzed in detail. Experimental results clearly demonstrate that the proposed system has good performance in terms of high precision and good real-time capability.","Intrusion detection,
Process control,
Automation,
Hidden Markov models,
Protocols,
Control systems"
Deep learning helicopter dynamics models,"We consider the problem of system identification of helicopter dynamics. Helicopters are complex systems, coupling rigid body dynamics with aerodynamics, engine dynamics, vibration, and other phenomena. Resultantly, they pose a challenging system identification problem, especially when considering non-stationary flight regimes. We pose the dynamics modeling problem as direct high-dimensional regression, and take inspiration from recent results in Deep Learning to represent the helicopter dynamics with a Rectified Linear Unit (ReLU) Network Model, a hierarchical neural network model. We provide a simple method for initializing the parameters of the model, and optimization details for training. We describe three baseline models and show that they are significantly outperformed by the ReLU Network Model in experiments on real data, indicating the power of the model to capture useful structure in system dynamics across a rich array of aerobatic maneuvers. Specifically, the ReLU Network Model improves 58% overall in RMS acceleration prediction over state-of-the-art methods. Predicting acceleration along the helicopter's up-down axis is empirically found to be the most difficult, and the ReLU Network Model improves by 60% over the prior state-of-the-art. We discuss explanations of these performance gains, and also investigate the impact of hyperparameters in the novel model.","Helicopters,
Mathematical model,
Trajectory,
Aerodynamics,
Acceleration,
Data models,
Training"
Design and Development of Software Defined Metamaterials for Nanonetworks,"This paper introduces a class of programmable metamaterials, whose electromagnetic properties can be controlled via software. These software defined metamaterials (SDMs) stem from utilizing metamaterials in combination with nanonetworks. Metamaterials are artificial structures with properties that may not be found in nature. Since their initial advent, they have inspired ground-breaking applications to a range of research topics, such as electromagnetic invisibility of objects (cloaking), radiation absorption, filtering of light and sound as well as efficient antennas for sensors and implantable communication devices in recent years. However, existing metamaterial structures are ""rigid"", i.e. they cannot be restructured once constructed. This trait limits their fabrication to some well-equipped laboratories worldwide, slows down innovation, and, most importantly, restricts their applicability to static structures only. The proposed SDMs act as ""plastic"" (reconfigurable) metamaterials, whose attributes can be changed programmatically via a computer interface. This control is achieved by a network of nanomachines, incorporated into the structure of the metamaterial. The nanomachines may receive commands from the user and perform simple, yet geometrically-altering, actions on the metamaterial profile and tuning of its electromagnetic behavior. Architectural aspects, expected features and implementation issues are covered in this paper, while a suitable nanonetworking model is presented along with simulation results on its anticipated performance. The paper concludes by outlining the research challenges pertaining to the analysis, design, prototyping, manufacturing, and initial application scenarios of the proposed SDMs.","Metamaterials,
Electromagnetics,
Sensors,
Nanonetworks,
Radiation absorption,
Design methodology,
Cloaking,
Reconfigurable architectures"
Power-Efficient Provisioning for Online Virtual Network Requests in Cloud-Based Data Centers,"A cloud computing paradigm enables users to access services, applications, and infrastructure resources by using thin clients anywhere and at any time. In this paradigm, multiple users can share cloud infrastructure resources. The application or service requests from a user can be abstracted as a virtual network (VN) request and can be submitted to the cloud-based data centers. How to map a VN onto the cloud infrastructure network is a challenging issue in cloud resource provisioning. Thus, efficient mapping techniques that intelligently use the resources of cloud infrastructure are important and necessary. Current research on VN mapping and design focuses on resource-efficient VN mapping or cost-efficient VN mapping. However, there is another important issue in cloud-based data centers that we must pay attention to, i.e., the amount of power or energy that is consumed by a data center. The power consumption in data centers can be a significant percentage of the total power consumption, and it not only leads to a higher data center operating cost but also contributes to carbon emissions and the greenhouse effect. In this paper, we propose a power-efficient resource provisioning technique in cloud-based data centers while complying with service level agreements. We first model a power-efficient VN provisioning problem as a mathematical optimization problem, with the objective of minimizing the power consumption by employing mixed-integer programming. We then propose a heuristic algorithm to efficiently solve this model since this optimization problem is NP-hard. We validate and evaluate our framework and algorithm by conducting extensive simulations on different cloud infrastructure networks under various scenarios. The simulation results show that our approach performs well.","Power demand,
Servers,
Cloud computing,
Educational institutions,
WDM networks,
Mathematical model"
Missile Guidance Law Based on Robust Model Predictive Control Using Neural-Network Optimization,"In this brief, the utilization of robust model-based predictive control is investigated for the problem of missile interception. Treating the target acceleration as a bounded disturbance, novel guidance law using model predictive control is developed by incorporating missile inside constraints. The combined model predictive approach could be transformed as a constrained quadratic programming (QP) problem, which may be solved using a linear variational inequality-based primal-dual neural network over a finite receding horizon. Online solutions to multiple parametric QP problems are used so that constrained optimal control decisions can be made in real time. Simulation studies are conducted to illustrate the effectiveness and performance of the proposed guidance control law for missile interception.","Missiles,
Optimization,
Vectors,
Acceleration,
Predictive control,
Educational institutions,
Neural networks"
Millimeter-Wave Vector Signal Generation Based on a Bi-Directional Use of a Polarization Modulator in a Sagnac Loop,A novel technique to generate a frequency-doubled millimeter-wave (mm-W) vector signal that is immune to fiber chromatic-dispersion-induced power fading and free from interband beating interferences (IBBIs) based on a bi-directional use of a polarization modulator (PolM) in a Sagnac loop is proposed and experimentally demonstrated. The fundamental concept of the proposed approach is to use a PolM that is incorporated in a Sagnac loop at which a light wave is modulated by an intermediate-frequency vector signal along one direction and with no modulation along the opposite direction due to the traveling-wave nature of the PolM. The combination of the modulated and un-modulated signals at a photodetector will generate an mm-W signal that is immune to the fiber chromatic-dispersion-induced power fading and free from the IBBIs. The generation of a 100 and a 500 MSym/s 16-QAM signal at 31.5 GHz and the transmission of the signals over a 25-km single-mode fiber are evaluated. An error-free transmission of the 100 MSym/s signal and the transmission of the 500 MSym/s signal with a bit-error-rate below the forward error correction threshold of 3.8 × 10-3 are achieved.,"Optical fibers,
Optical polarization,
Optical filters,
Optical modulation,
Optical amplifiers"
Particle swam optimization based reliability-redundancy allocation in a type-2 fuzzy environment,"In this paper, we have addressed the reliability-redundancy allocation problem with a particle swam optimization based technique. The parameters of the system components are actually imprecise or uncertain quantity since those are generally guessed by the designers during the design-time. Thus, important features of the designed system, viz. reliability, costs, weight etc very suitably qualifies to be considered as fuzzy quantity. Our problem formulation considers these parameters as type-2 fuzzy quantity. There are few reports where the problem has been studied under type-1 fuzzy uncertainty. As far as we know, no research has been reported where the problem has been addressed with a particle swam optimization based approach in a type-2 fuzzy environment. Suitable examples are included to demonstrate our approach. Results are compared showing that the type-2 fuzzy uncertainty based approach outperforms other recently reported results.","Resource management,
Redundancy,
Optimization,
Uncertainty,
Particle swarm optimization,
Mathematical model"
On Reliability of Smart Grid Neighborhood Area Networks,"With the integration of the advanced computing and communication technologies, smart grid system is dedicated to enhance the efficiency and the reliability of future power systems greatly through renewable energy resources, as well as distributed communication intelligence and demand response. Along with advanced features of smart grid, the reliability of smart grid communication system emerges to be a critical issue, since millions of smart devices are interconnected through communication networks throughout critical power facilities, which has an immediate and direct impact on the reliability of the entire power infrastructure. In this paper, we present a comprehensive survey of reliability issues posted by the smart grid with a focus on communications in support of neighborhood area networks (NAN). Specifically, we focus on network architecture, reliability requirements and challenges of both communication networks and systems, secure countermeasures, and case studies in smart grid NAN. We aim to provide a deep understanding of reliability challenges and effective solutions toward reliability issues in smart grid NAN.","Smart grids,
Reliability,
Power system reliability,
IEEE 802.11 Standard,
Wide area networks,
Communication networks,
Computer network reliability"
Application of Fuzzy Cognitive Maps to water demand prediction,"This article is focused on the issue of learning of Fuzzy Cognitive Maps designed to model and predict time series. The multi-step supervised-learning based-on-gradient methods as well as population-based learning, with the use of real coded genetic algorithms, are described. In this study, a new structure optimization genetic algorithm for fuzzy cognitive maps learning is proposed for automatic construction of FCM applied to time series prediction. The proposed learning methodologies are based on an FCM reconstruction procedure using historical time series. The main contribution of this study is the analysis of the use of FCMs with their learning algorithms based on the multi-step gradient method (MGM) and other population-based methods to predict water demand. The performance of learning algorithms is presented through the analysis of real data of daily water demand and the corresponding prediction. The multivariate analysis of historical water demand data is held for five variables, mean and high temperature, precipitation, wind speed and touristic activity. Simulation results were obtained with the ISEMK (Intelligent Expert System based on Cognitive Maps) software tool. Through the experimental analysis, we demonstrate the usefulness of the new proposed FCM learning algorithm in water demand prediction, by calculating the known prediction errors. The advantage of the optimization genetic algorithm structure is its ability to select the most significant relations between concepts for prediction.","Genetic algorithms,
Time series analysis,
Prediction algorithms,
Sociology,
Algorithm design and analysis,
Fuzzy cognitive maps"
On the optimality of threshold policies in event triggered estimation with packet drops,"We consider a remote state estimation problem, where a sensor transmits local state estimates over an independent and identically distributed (i.i.d.) packet dropping link to a remote estimator. At each discrete time instant, the sensor can decide whether to transmit, with each transmission incurring a fixed energy cost. Performance is quantified via an optimization problem that minimizes a convex combination of the expected error covariance at the remote estimator and expected energy usage. For transmission schedules dependent only on the error covariance at the remote estimator, this work establishes that a threshold policy (i.e. transmit if the error covariance exceeds a certain threshold and don't transmit otherwise) is optimal. This provides a rigorous justification for the use of such threshold policies in event triggered estimation. An extension of the result to Markovian packet drops is also outlined.","Estimation,
Yttrium,
Optimization,
Lattices,
Numerical models,
Kalman filters,
Steady-state"
Mining Temporal Patterns in Time Interval-Based Data,"Sequential pattern mining is an important subfield in data mining. Recently, applications using time interval-based event data have attracted considerable efforts in discovering patterns from events that persist for some duration. Since the relationship between two intervals is intrinsically complex, how to effectively and efficiently mine interval-based sequences is a challenging issue. In this paper, two novel representations, endpoint representation and endtime representation, are proposed to simplify the processing of complex relationships among event intervals. Based on the proposed representations, three types of interval-based patterns: temporal pattern, occurrence-probabilistic temporal pattern, and duration-probabilistic temporal pattern, are defined. In addition, we develop two novel algorithms, Temporal Pattern Miner (TPMiner) and Probabilistic Temporal Pattern Miner (P-TPMiner), to discover three types of interval-based sequential patterns. We also propose three pruning techniques to further reduce the search space of the mining process. Experimental studies show that both algorithms are able to find three types of patterns efficiently. Furthermore, we apply proposed algorithms to real datasets to demonstrate the effectiveness and validate the practicability of proposed patterns.","Databases,
Data mining,
Home appliances,
Probabilistic logic,
Algorithm design and analysis,
Pattern recognition,
Distribution functions,
Sequential analysis"
A New Technique for Multi-Oriented Scene Text Line Detection and Tracking in Video,"Text detection and tracking in video is challenging due to contrast, resolution and background variations, and different orientations and text movements. In addition, the presence of both caption and scene texts in video aggravates the problem because these two text types differ in characteristics significantly . This paper proposes a new technique for detecting and tracking video texts of any orientation by using spatial and temporal information, respectively. The technique explores gradient directional symmetry at component level for smoothing edge components before text detection. Spatial information is preserved by forming Delaunay triangulation in a novel way at this level, which results in text candidates. Text characteristics are then proposed in a different way for eliminating false text candidates , which results in potential text candidates. Then grouping is proposed for combining potential text candidates regardless of orientation based on the nearest neighbor criterion. To tackle the problems of multi-font and multi-sized texts, we propose multi-scale integration by a pyramid structure, which helps in extracting full text lines. Then, the detected text lines are tracked in video by matching the subgraphs of triangulation. Experimental results for text detection and tracking on our video dataset, the benchmark video datasets, and the natural scene image benchmark datasets show that the proposed method is superior to the state-of-the-art methods in terms of recall, precision , and F-measure.","Image edge detection,
Tracking,
Feature extraction,
Shape,
Image color analysis,
Histograms,
Smoothing methods"
RANWAR: Rank-Based Weighted Association Rule Mining From Gene Expression and Methylation Data,"Ranking of association rules is currently an interesting topic in data mining and bioinformatics. The huge number of evolved rules of items (or, genes) by association rule mining (ARM) algorithms makes confusion to the decision maker. In this article, we propose a weighted rule-mining technique (say, RANWAR or rank-based weighted association rule-mining) to rank the rules using two novel rule-interestingness measures, viz., rank-based weighted condensed support (wcs) and weighted condensed confidence (wcc) measures to bypass the problem. These measures are basically depended on the rank of items (genes). Using the rank, we assign weight to each item. RANWAR generates much less number of frequent itemsets than the state-of-the-art association rule mining algorithms. Thus, it saves time of execution of the algorithm. We run RANWAR on gene expression and methylation datasets. The genes of the top rules are biologically validated by Gene Ontologies (GOs) and KEGG pathway analyses. Many top ranked rules extracted from RANWAR that hold poor ranks in traditional Apriori, are highly biologically significant to the related diseases. Finally, the top rules evolved from RANWAR, that are not in Apriori, are reported.","Itemsets,
Radio access networks,
Association rules,
Gene expression,
Image color analysis"
Parallel and High-Speed Computations of Elliptic Curve Cryptography Using Hybrid-Double Multipliers,"High-performance and fast implementation of point multiplication is crucial for elliptic curve cryptographic systems. Recently, considerable research has investigated the implementation of point multiplication on different curves over binary extension fields. In this paper, we propose efficient and high speed architectures to implement point multiplication on binary Edwards and generalized Hessian curves. We perform a data-flow analysis and investigate maximum number of parallel multipliers to be employed to reduce the latency of point multiplication on these curves. Then, we modify the addition and doubling formulations and employ a newly proposed digit-level hybrid-double Gaussian normal basis multiplier to remove the data dependencies and hence reduce the latency of point multiplication. To the best of our knowledge, this is the first time that one employs hybrid-double multiplication technique to reduce the computation time of point multiplication. Moreover, we have implemented our proposed architectures for point multiplication on FPGA and obtained the results of timing and area. Our results indicate that the proposed scheme is one step forward to improve the performance of point multiplication on binary Edward and generalized Hessian curves.",
A Practical Supercapacitor Model for Power Management in Wireless Sensor Nodes,"In this paper, a new practical method is presented to estimate supercapacitor state for wireless sensor nodes. The self-discharge process of supercapacitor, as an energy storage device in sensor nodes, is usually considered as the main factor that needs to be taken into account for power management. Recent studies have demonstrated that a supercapacitor charge-redistribution process may also have significant impact on power management. To consider charge redistribution in power management of a real-time system, a practical method is presented to estimate the state of a supercapacitor. The accuracy of the method is validated by experiments. The impact of time step on the proposed model is also investigated. The results indicate that the proposed model can achieve good accuracy with relatively large time step. Moreover, the model is easy to implement, and has low memory usage and computational cost for practical applications in a real-time system. Based on the practical model, estimations of charge and energy transferred during the redistribution process are presented, which provide important information toward developing energy aware algorithms in wireless sensor networks.",
Force estimation and slip detection/classification for grip control using a biomimetic tactile sensor,"We introduce and evaluate contact-based techniques to estimate tactile properties and detect manipulation events using a biomimetic tactile sensor. In particular, we estimate finger forces, and detect and classify slip events. In addition, we present a grip force controller that uses the estimation results to gently pick up objects of various weights and texture. The estimation techniques and the grip controller are experimentally evaluated on a robotic system consisting of Barrett arms and hands. Our results indicate that we are able to accurately estimate forces acting in all directions, detect the incipient slip, and classify slip with over 80% success rate.",
Heavy-Ion-Induced Charge Sharing Measurement With a Novel Uniform Vertical Inverter Chains (UniVIC) SEMT Test Structure,"In this paper, a novel uniform vertical inverter chains (UniVIC) single event multiple transient (SEMT) test structure is proposed for the first time. Charge sharing between standard inverters is measured for the first time experimentally. The heavy-ion experiment results in 65 nm bulk CMOS process indicate that charge sharing can impact three transistors at most. At the same time, the occurring probability of charge sharing is attained for the first time experimentally. 3D TCAD simulations have also verified them. In total, the conclusions are helpful for researchers to have a direct knowledge of charge sharing in concrete circuits, and then to improve the precise of soft error evaluation.","Inverters,
Charge measurement,
MOSFET,
Transient analysis"
Constrained Multi-View Video Face Clustering,"In this paper, we focus on face clustering in videos. To promote the performance of video clustering by multiple intrinsic cues, i.e., pairwise constraints and multiple views, we propose a constrained multi-view video face clustering method under a unified graph-based model. First, unlike most existing video face clustering methods which only employ these constraints in the clustering step, we strengthen the pairwise constraints through the whole video face clustering framework, both in sparse subspace representation and spectral clustering. In the constrained sparse subspace representation, the sparse representation is forced to explore unknown relationships. In the constrained spectral clustering, the constraints are used to guide for learning more reasonable new representations. Second, our method considers both the video face pairwise constraints as well as the multi-view consistence simultaneously. In particular, the graph regularization enforces the pairwise constraints to be respected and the co-regularization penalizes the disagreement among different graphs of multiple views. Experiments on three real-world video benchmark data sets demonstrate the significant improvements of our method over the state-of-the-art methods.",
Toward k -Connectivity of the Random Graph Induced by a Pairwise Key Predistribution Scheme With Unreliable Links,"We study the secure and reliable connectivity of wireless sensor networks. Security is assumed to be ensured by the random pairwise key predistribution scheme of Chan, Perrig, and Song, and unreliable wireless links are represented by independent ON/OFF channels. Modeling the network by an intersection of a random K-out graph and an Erdos-Rényi graph, we present scaling conditions (on the number of nodes n, the scheme parameter K, and the probability p of a wireless channel being on), such that the resulting graph contains no nodes with a degree less than k with high probability. Results are given in the form of zero-one laws with n getting large, and are shown to improve the previous results by Yagan and Makowski on the absence of isolated nodes (i.e., absence of nodes with degree zero) in the same model. Through simulations, the established zero-one laws are also shown to hold for the property of k-connectivity, i.e., the property that graph remains connected despite the deletion of any k - 1 nodes or edges.","Wireless sensor networks,
Erbium,
Wireless communication,
Cryptography,
Communication system security,
Standards"
Extracting aspects and mining opinions in product reviews using supervised learning algorithm,"Social media is emerging rapidly on the internet. This media knowledge helps people, company and organizations to analyze information for important decision making. Opinion mining is also called as sentiment analysis which involves in building a system to gather and examine opinions about the product made in reviews or tweets, comments, blog posts on the web. Sentiment is classified automatically for important applications such as opinion mining and summarization. To make valuable decisions in marketing analysis where implement sentiment classification efficiently. Reviews contain sentiment which is expressed in a different way in different domains and it is costly to annotate data for each new domain. The analysis of online customer reviews in which firms cannot discover what exactly people liked and did not like in document-level and sentence-level opinion mining. So, now opinion mining ongoing research is in phrase-level opinion mining. It performs finer-grained analysis and directly looks at the opinion in online reviews. The proposed system is based on phrase-level to examine customer reviews. Phrase-level opinion mining is also well-known as aspect based opinion mining. It is used to extract most important aspects of an item and to predict the orientation of each aspect from the item reviews. The projected system implements aspect extraction using frequent itemset mining in customer product reviews and mining opinions whether it is positive or negative opinion. It identifies sentiment orientation of each aspect by supervised learning algorithms in customer reviews.","Data mining,
Tagging,
Media,
Itemsets,
Algorithm design and analysis,
Sentiment analysis,
Accuracy"
Reduced-Order Load Models for Large Populations of Flexible Appliances,"To respond to volatility and congestion in the power grid, demand response (DR) mechanisms allow for shaping the load compared to a base load profile. When tapping on a large population of heterogeneous appliances as a DR resource, the challenge is in modeling the dimensions available for control. Such models need to strike the right balance between accuracy of the model and tractability. The goal of this paper is to provide a medium-grained stochastic hybrid model to represent a population of appliances that belong to two classes: deferrable or thermostatically controlled loads. We preserve quantized information regarding individual load constraints, while discarding information about the identity of appliance owners. The advantages of our proposed population model are 1) it allows us to model and control load in a scalable fashion, useful for ex-ante planning by an aggregator or for real-time load control; 2) it allows for the preservation of the privacy of end-use customers that own submetered or directly controlled appliances.",
Solar Power Shaping: An Analytical Approach,"The focus of our work is the use of an energy storage system (ESS) to integrate solar energy generators into the electrical grid. Although, in theory, an ESS allows intermittent solar power to be shaped to meet any desired load profile, in practice, parsimonious ESS dimensioning is challenging due to the stochastic nature of generation and load and the diversity and high cost of storage technologies. Existing methods for ESS sizing are based either on simulation or on analysis, both of which have shortcomings. Simulation methods are computationally expensive and depend on the availability of extensive data traces. Existing analytical methods tend to be conservative, overestimating expensive storage requirements. Our key insight is that solar power fluctuations arise at a few distinct time scales. We separately model fluctuations in each time scale, which allows us to accurately estimate ESS performance and efficiently size an ESS. Numerical examples with real data traces show that our model and analysis are tight.",
Free-Form Region Description with Second-Order Pooling,"Semantic segmentation and object detection are nowadays dominated by methods operating on regions obtained as a result of a bottom-up grouping process (segmentation) but use feature extractors developed for recognition on fixed-form (e.g. rectangular) patches, with full images as a special case. This is most likely suboptimal. In this paper we focus on feature extraction and description over free-form regions and study the relationship with their fixed-form counterparts. Our main contributions are novel pooling techniques that capture the second-order statistics of local descriptors inside such free-form regions. We introduce second-order generalizations of average and max-pooling that together with appropriate non-linearities, derived from the mathematical structure of their embedding space, lead to state-of-the-art recognition performance in semantic segmentation experiments without any type of local feature coding. In contrast, we show that codebook-based local feature coding is more important when feature extraction is constrained to operate over regions that include both foreground and large portions of the background, as typical in image classification settings, whereas for high-accuracy localization setups, second-order pooling over free-form regions produces results superior to those of the winning systems in the contemporary semantic segmentation challenges, with models that are much faster in both training and testing.","Feature extraction,
Symmetric matrices,
Image segmentation,
Image color analysis,
Encoding,
Shape,
Manifolds"
Decentralized dynamic spectrum access in full-duplex cognitive radio networks,"In the dynamic spectrum access (DSA) paradigm for cognitive radio networks (CRNs), one of the commonly used Medium Access Control (MAC) schemes is designed on basis of the popular carrier sensing multiple access with collision avoidance. However, this proposal suffers from two major problems that may significantly decrease the system performance: (1) collision among the secondary users (SUs) can hardly be detected, thus leading to the secondary transmission failures, and (2) SUs cannot abort transmission when collision occurs, making the long collision duration possible. In this paper, we propose a new cognitive MAC protocol for efficient DSA based on full-duplex CRNs (FD-CRNs), where SUs are able to perform simultaneous spectrum sensing and data transmission owing to full-duplex techniques. Specifically, SUs can detect the collision during transmission, so as to reduce the collision time and improve secondary network performance. Analytical results include the derivations of key design parameters such as the collision ratio with the PU, spectrum usage ratio, optimal contention window size, and the performance comparisons with the conventional DSA in half-duplex CRNs (HD-CRNs), which are further confirmed by simulation results.","Sensors,
Cognitive radio,
Media Access Protocol,
Simulation,
Dynamic spectrum access,
High definition video"
Learning Social Relation Traits from Face Images,"Social relation defines the association, e.g., warm, friendliness, and dominance, between two or more people. Motivated by psychological studies, we investigate if such fine grained and high-level relation traits can be characterised and quantified from face images in the wild. To address this challenging problem we propose a deep model that learns a rich face representation to capture gender, expression, head pose, and age-related attributes, and then performs pairwise-face reasoning for relation prediction. To learn from heterogeneous attribute sources, we formulate a new network architecture with a bridging layer to leverage the inherent correspondences among these datasets. It can also cope with missing target attribute labels. Extensive experiments show that our approach is effective for fine-grained social relation learning in images and videos.","Face,
Psychology,
Computer vision,
Face recognition,
Cognition,
Videos"
Investigating the Discriminative Power of Keystroke Sound,"The goal of this paper is to determine whether keystroke sound can be used to recognize a user. In this regard, we analyze the discriminative power of keystroke sound in the context of a continuous user authentication application. Motivated by the concept of digraphs used in modeling keystroke dynamics, a virtual alphabet is first learned from keystroke sound segments. Next, the digraph latency within the pairs of virtual letters, along with other statistical features, is used to generate match scores. The resultant scores are indicative of the similarities between two sound streams, and are fused to make a final authentication decision. Experiments on both static text-based and free text-based authentications on a database of 50 subjects demonstrate the potential as well as the limitations of keystroke sound.","Acoustics,
Presses,
Authentication,
Feature extraction,
Keyboards,
Training,
Histograms"
"Accelerating compressive sensing reconstruction OMP algorithm with CPU, GPU, FPGA and domain specific many-core","Compressive Sensing (CS) signal reconstruction can be implemented using convex relaxation, non-convex, or local optimization algorithms. Though the reconstruction using convex optimization, such as the Iterative Hard Thresholding algorithm, is more accurate than matching pursuit algorithms, most researchers focus on matching pursuit algorithms because they are less computationally complex. Orthogonal Matching Pursuit (OMP) is a greedy algorithm, which solves the problem by choosing the most significant variable to reduce the least square error. In this paper, we propose an efficient parallel architecture for OMP CS reconstruction. For architecture implementation, we perform measurement and sparsity analysis to reduce the complexity. The proposed architecture is platform independent and is implemented on 7 different platforms including general purpose CPUs, GPUs, a Virtex-7 FPGA and a domain specific many-core. The implementation results indicate that reconstruction time on FPGA is improved by 3× compared to previous FPGA implementation, whereas GPU implementation is 4× faster than the previously proposed GPU-based OMP architecture. The CPU implementation is 6× faster, compared with previous CPU-based implementation. The domain specific many-core acheives 24 times faster reconstruction time when compared to both GPU and CPU implementations.","Image reconstruction,
Matching pursuit algorithms,
Field programmable gate arrays,
Computer architecture,
Hardware,
Kernel,
Graphics processing units"
Impedance control network resonant dc-dc converter for wide-range high-efficiency operation,"This paper introduces a new resonant converter architecture that utilizes multiple inverters and a lossless impedance control network (ICN) to maintain zero voltage switching (ZVS) and near zero current switching (ZCS) across wide operating ranges. Hence, the ICN converter is able to operate at fixed frequency and maintain high efficiency across wide ranges in input and output voltages and output power. The ICN converter architecture enables increase in switching frequency (hence reducing size and mass) while achieving very high efficiency. A prototype 200 W, 500 kHz ICN resonant converter designed to operate over an input voltage range of 25 V to 40 V and output voltage range of 250 V to 400 V is built and tested. The prototype ICN converter achieves a peak efficiency of 97.2%, maintains greater than 96.2% full power efficiency at 250 V output voltage across the nearly 2:1 input voltage range, and maintains full power efficiency above 94.6% across its full input and output voltage range. It also maintains efficiency above 93.4% over a 10:1 output power range across its full input and output voltage range owing to the use of burst-mode control.","Inverters,
Voltage control,
Power generation,
Zero voltage switching,
Switching frequency,
Impedance,
Control systems"
A Uniplanar Triple-Band Dipole Antenna Using Complementary Capacitively Loaded Loop,"A uniplanar compact metamaterial-inspired triple-band dipole antenna is designed and proposed for wireless local area network (WLAN) and Worldwide Interoperability for Microwave Access (WiMAX) applications. By introducing two pairs of complementary capacitively loaded loop (CCLL) slots into a uniplanar bow-tie antenna, two notched bands can be generated to form a triple-band operation. The antenna is directly fed by a 50- Ω microstrip line and a microstrip-to-coplanar-stripline (CPS) transition as a wideband balun. Antenna parameters, including voltage standing-wave ratio (VSWR), radiation patterns, and gain, are obtained by numerical simulations and experimental measurements. The results show that the proposed antenna can provide triple-band operation at 2.21-2.77, 3.33-3.95, and 5.04-6 GHz with the VSWR less than 2 to achieve 2.4/5.2/5.8-GHz WLAN and 2.5/3.5/5.5-GHz WiMAX applications.","Dipole antennas,
Antenna measurements,
Antenna radiation patterns,
Wireless communication,
Slot antennas,
Frequency measurement"
Comments on a Public Auditing Mechanism for Shared Cloud Data Service,"Recently, a public auditing protocol for shared data called Panda (IEEE Transactions on Services Computing, doi: 10.1109/TSC.2013.2295611) was proposed to ensure the correctness of the outsourced data. A distinctive feature of Panda is the support of data sharing and user revocation. Unfortunately, in this letter, we show that Panda is insecure in the sense that a cloud server can hide data loss without being detected. Specifically, we show that even some stored file blocks have been lost, the server is able to generate a valid proof by replacing a pair of lost data block and its signature with another block and signature pair. We also provide a solution to the problem while preserving all the desirable features of the original protocol.","Servers,
Computer security,
Auditing,
Cloud computing"
MIMO Passive Radar Tracking Under a Single Frequency Network,"In conventional MIMO radars, transmitting waveforms are usually assumed to be mutually orthogonal. This is also the case for MIMO passive radar when the transmitters occupy non-overlapping frequency channels, such as the FM-based MIMO passive radar. For the single frequency network (SFN)-based MIMO passive radar (SMPR), all illuminators transmit the same content at the same frequency simultaneously, that makes the signal indistinguishable. Therefore, one has to solve the measurement-to-transmitter association herein in addition to the standard measurement-to-target association in conventional MIMO radars. This paper investigates the non-standard target tracking for SMPR. A novel approach is proposed to achieve real-time operation as well as nearly optimal performance. Simulation results show comparable performance to the case with known association. Moreover, the feasibility of the proposed approach is demonstrated using field experimental data.","Radar tracking,
MIMO radar,
Passive radar,
Transmitters,
Signal processing algorithms,
Algorithm design and analysis"
Efficient visual exploration and coverage with a micro aerial vehicle in unknown environments,"In this paper, we propose a novel and computationally efficient algorithm for simultaneous exploration and coverage with a vision-guided micro aerial vehicle (MAV) in unknown environments. This algorithm continually plans a path that allows the MAV to fulfil two objectives at the same time while avoiding obstacles: observe as much unexplored space as possible, and observe as much of the surface of the environment as possible given viewing angle and distance constraints. The former and latter objectives are known as the exploration and coverage problems respectively. Our algorithm is particularly useful for automated 3D reconstruction at the street level and in indoor environments where obstacles are omnipresent. By solving the exploration problem, we maximize the size of the reconstructed model. By solving the coverage problem, we maximize the completeness of the model. Our algorithm leverages the state lattice concept such that the planned path adheres to specified motion constraints. Furthermore, our algorithm is computationally efficient and able to run on-board the MAV in real-time. We assume that the MAV is equipped with a forward-looking depth-sensing camera in the form of either a stereo camera or RGB-D camera. We use simulation experiments to validate our algorithm. In addition, we show that our algorithm achieves a significantly higher level of coverage as compared to an exploration-only approach while still allowing the MAV to fully explore the environment.","Cameras,
Three-dimensional displays,
Face,
Lattices,
Real-time systems,
Solid modeling,
Planning"
"A high payload video steganography algorithm in DWT domain based on BCH codes (15, 11)","Video steganography has become a popular topic due to the significant growth of video data over the Internet. The performance of any steganography algorithm depends on two factors: embedding efficiency and embedding payload. In this paper, a high embedding payload of video steganography algorithm has been proposed based on the BCH coding. To improve the security of the algorithm, a secret message is first encoded by BCH(n, k, t) coding. Then, it is embedded into the discrete wavelet transform (DWT) coefficients of video frames. As the DWT middle and high frequency regions are considered to be less sensitive data, the secret message is embedded only into the middle and high frequency DWT coefficients. The proposed algorithm is tested under two types of videos that contain slow and fast motion objects. The results of the proposed algorithm are compared to both the Least Significant Bit (LSB) and [1] algorithms. The results demonstrate better performance for the proposed algorithm than for the others. The hiding ratio of the proposed algorithm is approximately 28%, which is evaluated as a high embedding payload with a minimal tradeoff of visual quality. The robustness of the proposed algorithm was tested under various attacks. The results were consistent.","Discrete wavelet transforms,
Algorithm design and analysis,
Payloads,
Visualization,
Polynomials,
Image color analysis,
Encoding"
A Low-Latency and Low-Power Hybrid Scheme for On-Chip Networks,"Network-on-chip (NoC) has emerged as a vital factor that determines the performance and power consumption of many-core systems. This paper proposes a hybrid scheme for NoCs, which aims at obtaining low latency and low power consumption. In the presented hybrid scheme, a novel switching mechanism, called virtual circuit switching, is proposed to intermingle with circuit switching and packet switching. Flits traveling in virtual circuit switching can traverse the router with only one stage. In addition, multiple virtual circuit-switched (VCS) connections are allowed to share a common physical channel. Moreover, a path allocation algorithm is proposed in this paper to determine VCS connections and circuit-switched connections on a mesh-connected NoC, such that both communication latency and power are optimized. A set of synthetic and real traffic workloads are exploited to evaluate the effectiveness of the proposed hybrid scheme. The experimental results show that our proposed hybrid scheme can efficiently reduce the communication latency and power. For instance, for real traffic workloads, an average of 20.3% latency reduction and 33.2% power saving can be obtained when compared with the baseline NoC. Moreover, when compared with the NoC with virtual point-to-point connections (VIP), the proposed hybrid scheme can reduce the latency by 6.8% with the power decreasing by 11.3% averagely.","Switching circuits,
Switches,
Power demand,
Packet switching,
Hybrid power systems,
Pipelines,
Resource management"
Quantitative Analysis of Drug-Induced Complement-Mediated Cytotoxic Effect on Single Tumor Cells Using Atomic Force Microscopy and Fluorescence Microscopy,"In the antibody-based targeted therapies of B-cell lymphomas, complement-mediated cytotoxicity (CMC) is an important mechanism. CMC is activated after the binding of drugs (monoclonal antibodies) to tumor cells. The activation of CMC ultimately leads to the lysis of tumor cells. However, it remains poorly understood how CMC alters the morphology and mechanics of single tumor cells at the nanoscale. In recent years, nanoscopic observations of cellular behaviors with the use of atomic force microscopy (AFM) have contributed much to the field of cell biology. In this work, by combining AFM with fluorescence microscopy, the detailed changes in cellular ultra-microstructures and mechanical properties during the process of CMC were quantitatively investigated on single tumor cells. AFM imaging distinctly showed that the CMC effect could lead to the formation of nano holes on the tumor cells. Quantitative analysis of AFM images indicated that cell surface became lower and rougher after the CMC process. The cellular mechanics measurements showed that during the process of CMC cells firstly softened and finally stiffened, which was validated by dynamically monitoring the mechanical changes of single living cells during CMC. The experimental results provide novel insights into the antibody-dependent CMC.",
Online State-Based Structured SVM Combined With Incremental PCA for Robust Visual Tracking,"In this paper, we propose a robust state-based structured support vector machine (SVM) tracking algorithm combined with incremental principal component analysis (PCA). Different from the current structured SVM for tracking, our method directly learns and predicts the object's states and not the 2-D translation transformation during tracking. We define the object's virtual state to combine the state-based structured SVM and incremental PCA. The virtual state is considered as the most confident state of the object in every frame. The incremental PCA is used to update the virtual feature vector corresponding to the virtual state and the principal subspace of the object's feature vectors. In order to improve the accuracy of the prediction, all the feature vectors are projected onto the principal subspace in the learning and prediction process of the state-based structured SVM. Experimental results on several challenging video sequences validate the effectiveness and robustness of our approach.","Support vector machines,
Vectors,
Principal component analysis,
Robustness,
Feature extraction,
Optimization,
Visualization"
"Using Declarative Specification to Improve the Understanding, Extensibility, and Comparison of Model-Inference Algorithms","It is a staple development practice to log system behavior. Numerous powerful model-inference algorithms have been proposed to aid developers in log analysis and system understanding. Unfortunately, existing algorithms are typically declared procedurally, making them difficult to understand, extend, and compare. This paper presents InvariMint, an approach to specify model-inference algorithms declaratively. We applied the InvariMint declarative approach to two model-inference algorithms. The evaluation results illustrate that InvariMint (1) leads to new fundamental insights and better understanding of existing algorithms, (2) simplifies creation of new algorithms, including hybrids that combine or extend existing algorithms, and (3) makes it easy to compare and contrast previously published algorithms. InvariMint's declarative approach can outperform procedural implementations. For example, on a log of 50,000 events, InvariMint's declarative implementation of the kTails algorithm completes in 12 seconds, while a procedural implementation completes in 18 minutes. We also found that InvariMint's declarative version of the Synoptic algorithm can be over 170 times faster than the procedural implementation.","Inference algorithms,
Postal services,
Electronic mail,
Algorithm design and analysis,
Software algorithms,
Educational institutions,
Approximation algorithms"
Fast Object Retrieval Using Direct Spatial Matching,"The conventional bag-of-visual-words (BoW) model is popular for the large-scale object retrieval system but suffers from the critical drawback of ignoring spatial information . RANSAC-based methods attempt to remedy this drawback, but often require traversing all the feature matches for each hypothesis , leading to the heavy computational cost which limits the number of gallery images to be verified for each online query. We propose an efficient direct spatial matching (DSM) approach to directly estimate the scale variation using region sizes, in which all feature matches voted for estimating geometric transformation . DSM is much faster than RANSAC-based methods and exhaustive enumeration approaches. A logarithmic term frequency- inverse document frequency (log tf-idf) weighting scheme is introduced to boost the performance of the base system. We have conducted extensive experimental evaluations on four benchmark datasets for object retrieval. The proposed DSM method, together with a carefully-tailored reranking scheme, achieves the state-of-the-art results on the Oxford buildings and Paris datasets, which demonstrates the efficacy and scalability of our novel DSM technique for large scale object retrieval systems.","Visualization,
Computational efficiency,
Standards,
Feature extraction,
Vocabulary,
Computational modeling,
Benchmark testing"
Uncertainty Representation in Visualizations of Learning Analytics for Learners: Current Approaches and Opportunities,"Adding uncertainty information to visualizations is becoming increasingly common across domains since its addition helps ensure that informed decisions are made. This work has shown the difficulty that is inherent to representing uncertainty. Moreover, the representation of uncertainty has yet to be thoroughly explored in educational domains even though visualizations are often used in educational reporting. We analyzed 50 uncertainty-augmented visualizations from various disciplines to map out how uncertainty has been represented. We then analyzed 106 visualizations from educational reporting systems where the learner can see the visualization; these visualizations provide learners with information about several factors including their knowledge, performance, and abilities. This analysis mapped the design space that has been employed to communicate a learner's abilities, knowledge, and interests. It also revealed several opportunities for the inclusion of uncertainty information within visualizations of educational data. We describe how uncertainty information can be added to visualizations of educational data and illustrate these opportunities by augmenting several of the types of visualizations that are found in existing learning analytics reports. The definition of this design space, based on a survey of the literature, will enable the systematic exploration of how different design decisions affect learner trust, understanding, and decision making.","Uncertainty,
Visualization,
Data visualization,
Analytical models,
Shape,
Training,
Color"
Mixed Logical Inference and Probabilistic Planning for Robots in Unreliable Worlds,"Deployment of robots in practical domains poses key knowledge representation and reasoning challenges. Robots need to represent and reason with incomplete domain knowledge, acquiring and using sensor inputs based on need and availability. This paper presents an architecture that exploits the complementary strengths of declarative programming and probabilistic graphical models as a step toward addressing these challenges. Answer Set Prolog (ASP), a declarative language, is used to represent, and perform inference with, incomplete domain knowledge, including default information that holds in all but a few exceptional situations. A hierarchy of partially observable Markov decision processes (POMDPs) probabilistically models the uncertainty in sensor input processing and navigation. Nonmonotonic logical inference in ASP is used to generate a multinomial prior for probabilistic state estimation with the hierarchy of POMDPs. It is also used with historical data to construct a beta (meta) density model of priors for metareasoning and early termination of trials when appropriate. Robots equipped with this architecture automatically tailor sensor input processing and navigation to tasks at hand, revising existing knowledge using information extracted from sensor inputs. The architecture is empirically evaluated in simulation and on a mobile robot visually localizing objects in indoor domains.",
Sound and complete state estimation for linear dynamical systems under sensor attacks using Satisfiability Modulo Theory solving,"We address the problem of detecting and mitigating the effect of malicious attacks on the sensors of a linear dynamical system. We develop a novel, efficient algorithm that uses a Satisfiability Modulo Theory approach to isolate the compromised sensors and estimate the system state despite the presence of the attack, thus harnessing the intrinsic combinatorial complexity of the problem. Simulation results show that our algorithm compares favorably with alternative techniques, with respect to both runtime and estimation error.","State estimation,
Heuristic algorithms,
Complexity theory,
Optimization,
Indexes,
Upper bound,
Observability"
Rotation Invariant Texture Retrieval Considering the Scale Dependence of Gabor Wavelet,"Obtaining robust and efficient rotation-invariant texture features in content-based image retrieval field is a challenging work. We propose three efficient rotation-invariant methods for texture image retrieval using copula model based in the domains of Gabor wavelet (GW) and circularly symmetric GW (CSGW). The proposed copula models use copula function to capture the scale dependence of GW/CSGW for improving the retrieval performance. It is well known that the Kullback-Leibler distance (KLD) is the commonly used similarity measurement between probability models. However, it is difficult to deduce the closed-form of KLD between two copula models due to the complexity of the copula model. We also put forward a kind of retrieval scheme using the KLDs of marginal distributions and the KLD of copula function to calculate the KLD of copula model. The proposed texture retrieval method has low computational complexity and high retrieval precision. The experimental results on VisTex and Brodatz data sets show that the proposed retrieval method is more effective compared with the state-of-the-art methods.","Gabor filters,
Wavelet domain,
Transforms,
Computational modeling,
Image retrieval,
Feature extraction,
Merging"
Spectrum sharing in cooperative cognitive radio networks: A matching game framework,"Dynamic spectrum access allows the unlicensed wireless users (secondary users) to dynamically access the licensed bands from legacy spectrum holders (primary users) either on an opportunistic or a cooperative basis. In this paper, we focus on cooperative spectrum sharing in a wireless network consisting of multiple primary and multiple secondary users. In particular, we study the partner-selection and resource-allocation problems within a matching theory framework, in which the primary and secondary users aim at optimizing their utilities in terms of transmission rate and power consumption. We propose a distributed algorithm to find the solution of the developed matching game that results in a stable matching between the sets of the primary and secondary users. Both analytical and numerical results show that the proposed matching model is a promising approach under which the utility functions of both primary and secondary users are maximized.","Games,
Cognitive radio,
Wireless networks,
Relays,
Ad hoc networks,
Distributed algorithms"
Rapid Model Identification for Online Subcutaneous Glucose Concentration Prediction for New Subjects With Type I Diabetes,"Goal: For conventional modeling methods, the work of model identification has to be repeated with sufficient data for each subject because different subjects may have different response to exogenous inputs. This may cause repetitive cost and burden for patients and clinicians and require a lot of modeling efforts. Here, to overcome the aforementioned problems, a rapid model development strategy for new subjects is proposed using the idea of model migration for online glucose prediction. Methods: First, a base model is obtained that can be empirically identified from any subject or constructed by a priori knowledge. Then, parameters of inputs in the base model are properly revised based on a small amount of new data from new subjects so that the updated models can reflect the specific glucose dynamics excited by inputs for new subjects. These problems are investigated by developing autoregressive models with exogenous inputs (ARX) based on 30 in silico subjects using UVA/Padova metabolic simulator. Results: The prediction accuracy of the rapid modeling method is comparable to that for subject-dependent modeling method for some cases. Also, it can present better generalization ability. Conclusion: The proposed method can be regarded as an effective and economic modeling method instead of repetitive subject-dependent modeling method especially for lack of modeling data.","Predictive models,
Sugar,
Data models,
Insulin,
Biomedical measurement,
Biological system modeling,
Diabetes"
Limits on the Power of Indistinguishability Obfuscation and Functional Encryption,"Recent breakthroughs in cryptography have positioned indistinguishability obfuscation as a ""central hub"" for almost all known cryptographic tasks, and as an extremely powerful building block for new cryptographic tasks resolving long-standing and foundational open problems. However, constructions based on indistinguishability obfuscation almost always rely on non-black-box techniques, and thus the extent to which it can be used as a building block in cryptographic constructions has been completely unexplored so far. We present a framework for proving meaningful negative results on the power of indistinguishability obfuscation. By considering indistinguishability obfuscation for oracle-aided circuits, we capture the common techniques that have been used so far in constructions based on indistinguishability obfuscation. These include, in particular, non-black-box techniques such as the punctured programming approach of Sahai and Waters (STOC '14) and its variants, as well as sub-exponential security assumptions. Within our framework we prove the first negative results on the power of indistinguishability obfuscation and of the tightly related notion of functional encryption. Our results are as follows: - There is no fully black-box construction of a collision-resistant function family from an indistinguishability obfuscator for oracle-aided circuits. - There is no fully black-box construction of a key-agreement protocol with perfect completeness from a private-key functional encryption scheme for oracle-aided circuits. Specifically, we prove that any such potential constructions must suffer from an exponential security loss, and thus our results cannot be circumvented using sub-exponential security assumptions. Our framework captures constructions that may rely on a wide variety of primitives in a non-black-box manner (e.g., Obfuscating or generating a functional key for a function that uses the evaluation circuit of a puncturable pseudorandom function), and we only assume that the underlying indistinguishability obfuscator or functional encryption scheme themselves are used in a black-box manner.",
The Mirror World: Preparing for Mixed-Reality Living,"A new kind of smart space is emerging in which digital, physical, and social layers are strongly intertwined. These spaces extend the classic assistive functionality of ambient intelligence toward more proactive possibilities, where the smart environment not only monitors people as they perform tasks but also influences their plans and intentions. The authors explore this concept of the smart space as a mirror world, looking in particular at how it will affect our cognitive abilities and noting some of the research challenges that will need to be addressed. This department is part of a special issue on smart spaces.","Intelligent sensors,
Urban areas,
Mobile communication,
Software agents,
Virtual reality,
Digital systems"
Micro-Expression Recognition Using Color Spaces,"Micro-expressions are brief involuntary facial expressions that reveal genuine emotions and, thus, help detect lies. Because of their many promising applications, they have attracted the attention of researchers from various fields. Recent research reveals that two perceptual color spaces (CIELab and CIELuv) provide useful information for expression recognition. This paper is an extended version of our International Conference on Pattern Recognition paper, in which we propose a novel color space model, tensor independent color space (TICS), to help recognize micro-expressions. In this paper, we further show that CIELab and CIELuv are also helpful in recognizing micro-expressions, and we indicate why these three color spaces achieve better performance. A micro-expression color video clip is treated as a fourth-order tensor, i.e., a four-dimension array. The first two dimensions are the spatial information, the third is the temporal information, and the fourth is the color information. We transform the fourth dimension from RGB into TICS, in which the color components are as independent as possible. The combination of dynamic texture and independent color components achieves a higher accuracy than does that of RGB. In addition, we define a set of regions of interests (ROIs) based on the facial action coding system and calculated the dynamic texture histograms for each ROI. Experiments are conducted on two micro-expression databases, CASME and CASME 2, and the results show that the performances for TICS, CIELab, and CIELuv are better than those for RGB or gray.",
An Effective Area-Based Localization Algorithm for Wireless Networks,"Area-based localization algorithms use only the position of some reference nodes, called anchors, to estimate the residence area of the remaining nodes. Existing algorithms use a triangle, a ring or a circle as the geometric shape that defines the node's residence area. However, existing algorithms suffer from two major problems: (1) in some cases, they might make wrong decisions about a node presence inside a given area, or (2) they require high anchor density to achieve a low location estimation error and high ratio of localizable nodes. In this paper, we overcome these shortcomings by introducing a new approach for determining the node's residence area that is geometrically shaped as a half-symmetric lens. A novel half symmetric lens based localization algorithm (HSL) is proposed. HSL yields smaller residence areas, and consequently, better location accuracy than contemporary schemes. HSL further employs Voronoi diagram in order to boost the percentage of localizable nodes. The performance of HSL is validated through mathematical analysis, extensive simulations experiments and prototype implementation. The validation results confirm that HSL achieves better location accuracy and higher ratio of localizable nodes compared to competing algorithms.","Lenses,
Shape,
Accuracy,
Global Positioning System,
Receivers,
Prototypes,
Wireless sensor networks"
Performance analysis of a memristive crossbar PUF design,"Physical unclonable functions (PUF) provide a hardware specific unique signature or finger print for an integrated circuit that can be leveraged to mitigate several security vulnerabilities. A dense memristive crossbar PUF is described which utilizes variations in the write-time of memristors as the primary entropy source. For this work, the write-time varies according to six specific device parameters which can be directly measured from fabricated memristors and easily included in an accurate model for circuit simulation. The results presented show strong statistical performance for the proposed design in terms of entropy, uniqueness and uniformity. Furthermore, the nature of sneak path currents in the crossbar structure are leveraged to provide an exponential number of unique configurations for each response bit. Results also show that the proposed crossbar-based PUF provides improved power consumption and smaller area utilization when compared to CMOS-based and other nanoelectronic PUF circuits.",
Persymmetric adaptive detection and range estimation of a small target,"In this paper, we address the problem of detecting relatively small targets in the presence of Gaussian disturbance with unknown covariance matrix. To this end, we jointly exploit the spillover of target energy to consecutive range samples and the particular persymmetric structure of the disturbance covariance matrix to improve the performances of detection and range localization. In this context, we derive two adaptive detectors relying on the generalized likelihood ratio test and on ad hoc design procedure. Remarkably, the new receivers ensure the constant false alarm rate property with respect to the disturbance covariance matrix. The performance assessments, conducted on both simulated data and real recorded datasets, demonstrate the effectiveness of the proposed detectors compared with both the traditional unstructured counterparts and the state-of-the-art persymmetric detectors that ignore the spillover.","Detectors,
Covariance matrices,
Radar,
Gaussian processes,
Radar antennas,
Logic gates,
Doppler effect,
Receivers"
An Iterative Method for Calculating Robust Rating Scores,"Online rating systems are widely used to facilitate making decisions on the web. For fame or profit, people may try to manipulate such systems by posting unfair evaluations. Therefore, determining objective rating scores of products or services becomes a very important yet difficult problem. Existing solutions are mostly majority based, also employing temporal analysis and clustering techniques. However, they are still vulnerable to sophisticated collaborative attacks. In this paper we propose an iterative rating algorithm which is very robust against collusion attacks as well as random and biased raters. Unlike previous iterative methods, our method is not based on comparing submitted evaluations to an approximation of the final rating scores, and it entirely decouples credibility assessment of the cast evaluations from the ranking itself. This makes it more robust against sophisticated collusion attacks than the previous iterative filtering algorithms. We provide a rigorous proof of convergence of our algorithm based on the existence of a fixed point of a continuous mapping which also happens to be a stationary point of a constrained optimization objective. We have implemented and tested our rating method using both simulated data as well as real world movie rating data. Our tests demonstrate that our model calculates realistic rating scores even in the presence of massive collusion attacks and outperforms well-known algorithms in the area. The results of applying our algorithm on the real-world data obtained from MovieLens conforms highly with the rating scores given by Rotten Tomatoes movie critics as domain experts for movies.","Communities,
Nominations and elections,
Motion pictures,
Robustness,
Iterative methods,
Mathematical model,
Accuracy"
A PTAS Mechanism for Provisioning and Allocation of Heterogeneous Cloud Resources,"Cloud providers provision their heterogeneous resources such as CPUs, memory, and storage in the form of virtual machine (VM) instances which are then allocated to the users. One of the major challenges faced by the cloud providers is to allocate and provision these resources such that their profit is maximized, and the resources are utilized efficiently. Recently, cloud providers have introduced auction-based models which allow users to submit bids for their requested VMs. We address the problem of autonomic VM provisioning and allocation for the auction-based model considering multiple types of resources by designing an approximation mechanism. In addition, the mechanism determines the payment the users have to pay for using the allocated resources. This problem is computationally intractable, and our proposed mechanism is by far the strongest approximation result that can be achieved for this problem. We show that the proposed approximation mechanism is a polynomial-time approximation scheme (PTAS). Furthermore, our proposed mechanism drives the system into an equilibrium in which the users do not have incentives to manipulate the system by untruthfully reporting their VM bundle requests and valuations. We perform extensive experiments using real workload traces in order to investigate the performance of the proposed mechanism.","Resource management,
Approximation methods,
Cost accounting,
Heuristic algorithms,
Algorithm design and analysis,
Mechanical factors,
Silicon"
"An Integrated Framework for 3-D Modeling, Object Detection, and Pose Estimation From Point-Clouds","3-D modeling, object detection, and pose estimation are three of the most challenging tasks in the area of 3-D computer vision. This paper presents a novel algorithm to perform these tasks simultaneously from unordered point-clouds. Given a set of input point-clouds in the presence of clutter and occlusion, an initial model is first constructed by performing pair-wise registration between any two point-clouds. The resulting model is then updated from the remaining point-clouds using a novel model growing technique. Once the final model is reconstructed, the instances of the object are detected and the poses of its instances in the scenes are estimated. This algorithm is automatic, model free, and does not rely on any prior information about the objects in the scene. The algorithm was comprehensively tested on the University of Western Australia data set. Experimental results show that our algorithm achieved accurate modeling, detection, and pose estimation performance.","Feature extraction,
Solid modeling,
Estimation,
Silicon,
Three-dimensional displays,
Object detection,
Iterative closest point algorithm"
Minimum Rate Prediction and Optimized Histograms Modification for Reversible Data Hiding,"Prediction-error expansion (PEE)-based reversible data hiding schemes consist of two steps. First, a sharp prediction-error (PE) histogram is generated by utilizing pixel prediction strategies. Second, secret messages are reversibly embedded into the prediction-errors through expanding and shifting the PE histogram. Previous PEE methods treat the two steps independently while they either focus on pixel prediction to obtain a sharp PE histogram, or aim at histogram modification to enhance the embedding performance for a given PE histogram. This paper propose a pixel prediction method based on the minimum rate criterion for reversible data hiding, which establishes the consistency between the two steps in essence. And correspondingly, a novel optimized histograms modification scheme is presented to approximate the optimal embedding performance on the generated PE sequence. Experiments demonstrate that the proposed method outperforms the previous state-of-art counterparts significantly in terms of both the prediction accuracy and the final embedding performance.","Histograms,
Indexes,
Entropy,
Predictive models,
Image coding,
Rate-distortion,
Context"
A Sparse Coding Neural Network ASIC With On-Chip Learning for Feature Extraction and Encoding,"Hardware-based computer vision accelerators will be an essential part of future mobile devices to meet the low power and real-time processing requirement. To realize a high energy efficiency and high throughput, the accelerator architecture can be massively parallelized and tailored to vision processing, which is an advantage over software-based solutions and general-purpose hardware. In this work, we present an ASIC that is designed to learn and extract features from images and videos. The ASIC contains 256 leaky integrate-and-fire neurons connected in a scalable two-layer network of 8 × 8 grids linked in a 4-stage ring. Sparse neuron activation and the relatively small grid keep the spike collision probability low to save access arbitration. The weight memory is divided into core memory and auxiliary memory, such that the auxiliary memory is only powered on for learning to save inference power. High-throughput inference is accomplished by the parallel operation of neurons. Efficient learning is implemented by passing parameter update messages, which is further simplified by an approximation technique. A 3.06 mm2 65 nm CMOS ASIC test chip is designed to achieve a maximum inference throughput of 1.24 Gpixel/s at 1.0 V and 310 MHz, and on-chip learning can be completed in seconds. To improve the power consumption and energy efficiency, core memory supply voltage can be reduced to 440 mV to take advantage of the error resilience of the algorithm, reducing the inference power to 6.67 mW for a 140 Mpixel/s throughput at 35 MHz.","Neurons,
Encoding,
Feature extraction,
Image coding,
Application specific integrated circuits,
Inference algorithms,
Image reconstruction"
Inspection of Complex Objects Using Multiple-X-Ray Views,"This paper presents a new methodology for identifying parts of interest inside of a complex object using multiple-X-ray views. The proposed method consists of five steps: 1) image acquisition, that acquires an image sequence where the parts of the object are captured from different viewpoints; 2) geometric model estimation, that establishes a multiple-view geometric model used to find the correct correspondence among different views; 3) single-view detection, that segment potential regions of interest in each view; 4) multiple-view detection, that matches and tracks potential regions based on similarity and geometrical multiple-view constraints; and 5) analysis, that analyzes the tracked regions using multiple-view information, filtering out false alarms without eliminating existing parts of interest. In order to evaluate the effectiveness of the proposed method, the algorithm was tested on 32 cases (five applications using different segmentation approaches) yielding promising results: precision and recall were 95.7% and 93.9%, respectively. Additionally, the multiple-view information obtained from the tracked parts was effectively used for recognition purposes. In our recognition experiments, we obtained an accuracy of 96.5%. Validation experiments show that our approach achieves better performance than other representative methods in the literature.","Testing,
Image segmentation,
Inspection,
X-ray imaging,
Feature extraction,
Solid modeling,
Image sequences"
Investigating Public-Key Certificate Revocation in Smart Grid,"The public key cryptography (PKC) is essential for securing many applications in smart grid. For the secure use of the PKC, certificate revocation schemes tailored to smart grid applications should be adopted. However, little work has been done to study certificate revocation in smart grid. In this paper, we first explain different motivations that necessitate revoking certificates in smart grid. We also identify the applications that can be secured by PKC and thus need certificate revocation. Then, we explain existing certificate revocation schemes and define several metrics to assess them. Based on this assessment, we identify the applications that are proper for each scheme and discuss how the schemes can be modified to fully satisfy the requirements of its potential applications. Finally, we study certificate revocation in pseudonymous public key infrastructure (PPKI), where a large number of certified public/private keys are assigned for each node to preserve privacy. We target vehicles-to-grid communications as a potential application. Certificate revocation in this application is a challenge because of the large number of certificates. We discuss an efficient certificate revocation scheme for PPKI, named compressed certificate revocation lists (CRLs). Our analytical results demonstrate that one revocation scheme cannot satisfy the overhead/security requirements of all smart grid applications. Rather, different schemes should be employed for different applications. Moreover, we used simulations to measure the overhead of the schemes.","Smart grids,
Privacy,
Substations,
Electricity,
Public key,
Measurement"
Semiautomatic Model-Based View Planning for Active Triangulation 3-D Inspection Systems,"A semiautomatic model-based approach to the view planning problem for high-resolution active triangulation 3-D inspection systems is presented. First, a comprehensive, general, high-fidelity model of such systems is developed for the evaluation of configurations with respect to a model of task requirements, with a bounded scalar performance metric. The design process is analyzed, and the automated view planning problem is formulated only for the critically difficult aspects of design. A particle swarm optimization algorithm is applied to the latter portion, including probabilistic modeling of positioning error, using the performance metric as an objective function. The process leverages human strengths for the high-level design, refines low-level details mechanically, and provides an absolute measure of task-specific performance of the resulting design specification. The system model is validated, allowing for a reliable rapid design cycle entirely in simulation. Parameterization of the optimization algorithm is analyzed and explored empirically for performance.","Cameras,
Solid modeling,
Planning,
Inspection,
Sensors,
Laser modes,
Geometry"
Modeling of Single Event Transients With Dual Double-Exponential Current Sources: Implications for Logic Cell Characterization,"Single event effects (SEE) are a reliability concern for modern microelectronics. Bit corruptions can be caused by single event upsets (SEUs) in the storage cells or by sampling single event transients (SETs) from a logic path. An accurate prediction of soft error susceptibility from SETs requires good models to convert collected charge into compact descriptions of the current injection process. This paper describes a simple, yet effective, method to model the current waveform resulting from a charge collection event for SET circuit simulations. The model uses two double-exponential current sources in parallel, and the results illustrate why a conventional model based on one double-exponential source can be incomplete. A small set of logic cells with varying input conditions, drive strength, and output loading are simulated to extract the parameters for the dual double-exponential current sources. The parameters are based upon both the node capacitance and the restoring current (i.e., drive strength) of the logic cell.","Integrated circuit modeling,
Transient analysis,
Libraries,
Mathematical model,
Single event transients,
Computational modeling,
Load modeling"
Topological Indoor Localization and Navigation for Autonomous Mobile Robot,"Mobile robot typically has limited on-board resources and may be applied in different indoor environment. Thus, it is necessary that they can learn a map and navigate themselves autonomously with lightweight algorithms. A novel topological map-building-based localization and navigation method is proposed in this paper. Based on the depth curve provided by a 3D sensor, a progressive Bayesian classifier is developed to realize direct corridor type identification. Instead of extracting features from single observation, information from multi-observations are fused to achieve a more robust performance. A topological map generation and loop closing method are proposed to build the environment map through autonomous exploration. Based on the derived map and the Markov localization method, the robot can then localize itself and navigate freely in the indoor environment. Experiments are performed on a recently built mobile robot system, and the results verify the effectiveness of the proposed methodology.","Navigation,
Feature extraction,
Mobile robots,
Indoor environments,
Robot sensing systems,
Bayes methods"
Dynamic Sign Language Recognition for Smart Home Interactive Application Using Stochastic Linear Formal Grammar,"This paper presents the state-of-the art dynamic sign language recognition (DSLR) system for smart home interactive applications. Our novel DSLR system comprises two main subsystems: an image processing (IP) module and a stochastic linear formal grammar (SLFG) module. Our IP module enables us to recognize the individual words of the sign language (i.e., a single gesture). In this module, we used the bag-of-features (BOFs) and a local part model approach for bare hand dynamic gesture recognition from a video. We used dense sampling to extract local 3-D multiscale whole-part features. We adopted 3-D histograms of a gradient orientation descriptor to represent features. The k-means++ method was applied to cluster the visual words. Dynamic hand gesture classification was conducted using the BOFs and nonlinear support vector machine methods. We used a multiscale local part model to preserve temporal context. The SLFG module analyzes the sentences of the sign language (i.e., sequences of gestures) and determines whether or not they are syntactically valid. Therefore, the DSLR system is not only able to rule out ungrammatical sentences, but it can also make predictions about missing gestures, which, in turn, increases the accuracy of our recognition task. Our IP module alone seals the accuracy of 97% and outperforms any existing bare hand dynamic gesture recognition system. However, by exploiting syntactic pattern recognition, the SLFG module raises this accuracy by 1.65%. This makes the aggregate performance of the DSLR system as accurate as 98.65%.",
Sentiment analysis for dialectical Arabic,"This article investigates sentiment analysis in Arabic tweets with the presence of dialectical words. Sentiment analysis deals with extracting opinionated phrases from reviews, comments or tweets. i.e. to decide whether a given review or comment is positive, negative or neutral. Sentiment analysis has many applications and is very vital for many organizations. In this article, we utilize machine learning techniques to determine the polarity of tweets written in Arabic with the presence of dialects. Dialectical Arabic is abundantly present in social media and micro blogging channels. Dialectical Arabic presents challenges for topical classifications and for sentiment analysis. One example of such challenges is that stemming algorithms do not perform well with dialectical words. Another example is that dialectical Arabic uses an extended set of stopwords. In this research we introduce a framework that is capable of performing sentiment analysis on tweets written using either Modern Standard Arabic or Jordanian dialectical Arabic. The core of this framework is a dialect lexicon which maps dialectical words into their corresponding Modern Standard Arabic words. The experimentation reveals that the dialect lexicon improves the accuracies of the classifiers.","Sentiment analysis,
Niobium,
Support vector machines,
Accuracy,
Conferences,
Communication systems,
Standards"
Subspace Identification for DOA Estimation in Massive/Full-Dimension MIMO Systems: Bad Data Mitigation and Automatic Source Enumeration,"In this paper, the direction-of-arrival (DOA) estimation problem for massive multiple-input multiple-output (MIMO) systems with a two dimensional (2D) array (also known as full-dimension MIMO) is investigated, assuming no knowledge of path number, noise power, path gain correlations and bad data statistics. Based on the variational Bayesian framework, a novel iterative algorithm for subspace identification operating on tensor represented data is proposed with integrated features of effective bad data mitigation and automatic source enumeration. The subspace recovered from the proposed algorithm not only enables existing 2D DOA estimators to be readily applied, if the number of signal paths is less than the number of horizontal antennas and vertical antennas, the subspaces in elevation and azimuth domains can be separately estimated, from which one dimensional (1D) DOA estimators can be utilized, thus further lowering the complexity. Simulation results are presented to illustrate the excellent performance of the proposed subspace recovery method and subsequent DOA estimation in terms of accuracy and robustness.","Direction-of-arrival estimation,
Estimation,
MIMO,
Arrays,
Tensile stress,
Antennas,
Probabilistic logic"
Joint Neighbor Discovery and Time of Arrival Estimation in Wireless Sensor Networks via OFDMA,"This paper introduces joint neighbor discovery (ND) and coarse time-of-arrival (ToA) estimation in wireless sensor networks (WSNs) via orthogonal frequency-division multiple access. In the proposed technique, each sensor node exploits at least one orthogonal sub-carrier as its allocated signature, to respond the ND and ToA estimation requests transmitted by target nodes. The target node utilizes the orthogonality across sub-carriers to detect the transmitted signatures and their corresponding delays. This technique is energy efficient as it avoids multiple transmissions and receptions inherent in traditional ND protocols and ToA estimation techniques in WSN. Moreover, in this technique, network initiation process does not require channel information or time synchronization across sensor nodes. The performance of the proposed method is studied by evaluating the probabilities of false alarm and miss detection of the ND. In addition, ToA estimation error is calculated theoretically and via simulations. Moreover, the impact of available bandwidth on the performance and energy efficiency of ND and ToA estimation are investigated. Simulation results confirm the energy efficiency and the feasibility of the proposed method even at low signal-to-noise ratio regimes and in multi-path and frequency selective channels.","Sensors,
Time of arrival estimation,
Wireless sensor networks,
Estimation,
Wireless communication,
Distance measurement,
Joints"
Unsupervised Joint Feature Learning and Encoding for RGB-D Scene Labeling,"Most existing approaches for RGB-D indoor scene labeling employ hand-crafted features for each modality independently and combine them in a heuristic manner. There has been some attempt on directly learning features from raw RGB-D data, but the performance is not satisfactory. In this paper, we propose an unsupervised joint feature learning and encoding (JFLE) framework for RGB-D scene labeling. The main novelty of our learning framework lies in the joint optimization of feature learning and feature encoding in a coherent way, which significantly boosts the performance. By stacking basic learning structure, higher level features are derived and combined with lower level features for better representing RGB-D data. Moreover, to explore the nonlinear intrinsic characteristic of data, we further propose a more general joint deep feature learning and encoding (JDFLE) framework that introduces the nonlinear mapping into JFLE. The experimental results on the benchmark NYU depth dataset show that our approaches achieve competitive performance, compared with the state-of-the-art methods, while our methods do not need complex feature handcrafting and feature combination and can be easily applied to other data sets.","Labeling,
Image coding,
Joints,
Feature extraction,
Optimization,
Three-dimensional displays,
Encoding"
Domain Wall Magnets for Embedded Memory and Hardware Security,"Domain wall memory (DWM) is one possible candidate for embedded cache application due to its multi-level cell capability, low standby power, fast access time, good endurance, and good retention. In this paper, we utilize a physics-based model of domain wall to comprehend the process variations and Joule heating that can lead to functional issues in the memory. We propose techniques to mitigate the impact of variability and Joule heating while enabling low-power and high-frequency operation. We show that the process variations in the nanowire (NW) is not good towards robustness, but it can be very useful for device authentication. We propose physically unclonable functions (PUFs) that exploit the nonlinear DW-dynamics for secure key generation. Two flavors of PUF designs are described namely relay-PUF and memory-PUF with lower overhead and power as compared to a traditional CMOS-PUFs and offer a higher degree of resilience against cloning.","Resistance,
Heating,
Degradation,
Current density,
Substrates,
Integrated circuit modeling,
Magnetic heads"
Synchrophasor-Based Islanding Detection for Distributed Generation Systems Using Systematic Principal Component Analysis Approaches,"Systematic principal component analysis (PCA) methods are presented in this paper for reliable islanding detection for power systems with significant penetration of distributed generations (DGs), where synchrophasors, recorded by phasor measurement units, are used for system monitoring. Existing islanding detection methods, such as rate-of-change-of-frequency and vector shift are fast for processing local information; however, with the growth in installed capacity of DGs, they suffer from several drawbacks. Incumbent genset islanding detection cannot distinguish a system-wide disturbance from an islanding event, leading to maloperation. The problem is even more significant when the grid does not have sufficient inertia to limit frequency divergences in the system fault/stress due to the high penetration of DGs. To tackle such problems, this paper introduces PCA methods for islanding detection. A simple control chart is established for intuitive visualization of the transients. A recursive PCA scheme is proposed as a reliable extension of the PCA method to reduce the false alarms for time-varying process. To further reduce the computational burden, the approximate linear dependence condition errors are calculated to update the associated PCA model. The proposed PCA and RPCA methods are verified by detecting abnormal transients occurring in the U.K. utility network.","Principal component analysis,
Phasor measurement units,
Monitoring,
Islanding,
Transient analysis,
Mathematical model,
Correlation"
Self-triggered coordination over a shared network under Denial-of-Service,"The issue of security has become ever more prevalent in the analysis and design of cyber-physical systems. In this paper, we analyze a consensus network in the presence of Denial-of-Service (DoS) attacks, namely attacks that prevent communication among the network agents. By introducing a notion of Persistency-of-Communication (PoC), we provide a characterization of DoS frequency and duration such that consensus is not destroyed. An example is given to substantiate the analysis.","Computer crime,
Jamming,
Topology,
Clocks,
Time-frequency analysis,
Cyber-physical systems"
Language independent query-by-example spoken term detection using N-best phone sequences and partial matching,"In this paper, we propose a partial sequence matching based symbolic search (SS) method for the task of language independent query-by-example spoken term detection. One main drawback of conventional SS approach is the high miss rate for long queries. This is due to high variations in symbol representation of query and search audios, especially in language independent scenario. The successful matching of a query with its instances in search audio becomes exponentially more difficult as the query grows longer. To reduce miss rate, we propose a partial matching strategy, in which all partial phone sequences of a query are used to search for query instances. The partial matching is also suitable for real life applications where exact match is usually not necessary and word prefix, suffix, and order should not affect the search result. When applied to the QUESST 2014 task, results show the partial matching of phone sequences is able to reduce miss rate of long queries significantly compared with conventional full matching method. In addition, for the most challenging inexact matching queries (type 3), it also shows clear advantage over DTW-based methods.","Lattices,
Keyword search,
Speech,
Audio databases,
Indexing,
Acoustics,
Search problems"
Outage performance of cognitive radio systems with Improper Gaussian signaling,"Improper Gaussian signaling has proved its ability to improve the achievable rate of the systems that suffer from interference compared with proper Gaussian signaling. In this paper, we first study impact of improper Gaussian signaling on the performance of the cognitive radio system by analyzing the outage probability of both the primary user (PU) and the secondary user (SU). We derive exact expression of the SU outage probability and upper and lower bounds for the PU outage probability. Then, we design the SU signal by adjusting its transmitted power and the circularity coefficient to minimize the SU outage probability while maintaining a certain PU quality-of-service. Finally, we evaluate the proposed bounds and adaptive algorithms by numerical results.","Upper bound,
Quality of service,
Interference,
Cognitive radio,
Random variables,
Receivers"
Near-Threshold Energy- and Area-Efficient Reconfigurable DWPT/DWT Processor for Healthcare-Monitoring Applications,"This brief presents an energy- and area-efficient discrete wavelet packet transform (DWPT) processor design for power-constrained and cost-sensitive healthcare-monitoring applications. This DWPT processor employs recursive memory-shared architecture to achieve low hardware complexity while performing required arbitrary-basis DWPT decomposition. By exploiting inherent characteristics of different physiological signals through an entropy statistic engine, the DWPT processor core can be reconfigured to compute multilevel wavelet decomposition with effective time and frequency resolution. Various design techniques from algorithm to circuit levels, including reconfigurable computing, lifting scheme, dual-port pipeline processing, near-threshold operation, and clock gating, are applied to achieve energy efficiency. With a 0.18-μm CMOS technology at 0.5 V and 1 MHz, the DWPT core only consumes 26 μW for performing three-level 256-point DWPT decomposition with entropy statistic calculation. When integrated in an ARM Cortex-M0-based biomedical system-on-a-chip test platform, the DWPT processor achieves processing acceleration by three orders of magnitude and reduces energy consumption by four orders of magnitude compared with CPU-only implementations.","Discrete wavelet transforms,
Computer architecture,
Filtering,
Medical services,
Monitoring,
Radiation detectors,
Hardware"
A Self-Powered High-Efficiency Rectifier With Automatic Resetting of Transducer Capacitance in Piezoelectric Energy Harvesting Systems,"This paper presents a self-powered rectifier for piezoelectric energy harvesting applications, and the key idea of the proposed system is to reset the transducer capacitor at optimal instants to maximize the extracted power. The proposed rectifier consists of two switches and two active diodes. The switches discharge the transducer capacitor at optimal instants two times for every cycle. The active diodes are based on op-amps with a preset dc offset, which reduces the voltage drop and the leakage current and avoids instability. In addition, the controller for the proposed rectifier is simple to reduce the circuit complexity and the power dissipation. The proposed rectifier was designed and fabricated in 0.18-μm CMOS technology. Measured results indicate that it achieves power efficiency of 91.2%, and the amount of power extracted by the proposed rectifier is 3.5 times larger when compared with the conventional rectifiers. The proposed rectifier does not require any off chip components to enable a full chip integration, and the die area of the proposed circuit is 0.08 × 0.20 mm2.","Transducers,
Capacitors,
Synchronization,
Energy harvesting,
Discharges (electric),
Inductors,
Very large scale integration"
Shelving Interference and Joint Identification in Large-Scale RFID Systems,"Prior work on anti-collision for radio frequency identification (RFID) systems usually schedule adjacent readers to exclusively interrogate tags for avoiding reader collisions. Although such a pattern can effectively deal with collisions, the lack of readers' collaboration wastes numerous time on the scheduling process and dramatically degrades the throughput of identification. Even worse, the tags within the overlapped interrogation regions of adjacent readers (termed as contentious tags), even if the number of such tags is very small, introduce a significant delay to the identification process. In this paper, we propose a new strategy for collision resolution. First, we shelve the collisions and identify the tags that do not involve reader collisions. Second, we perform a joint identification, in which adjacent readers collaboratively identify the contentious tags. In particular, we find that neighboring readers can cause a new type of tag collision, cross-tag-collision, which may impede the joint identification. We propose a protocol stack, named Season, to undertake the tasks in two phases and solve the cross-tag-collision. We conduct extensive simulations and preliminary implementation to demonstrate the efficiency of our scheme. The results show that our scheme can achieve above 6× improvement on the identification throughput in a large-scale dense reader environment.","Protocols,
Radiofrequency identification,
Joints,
Throughput,
Delays,
Interference,
Collaboration"
Continuous second-order sliding mode control: Convergence time estimation,"The contribution of this paper is threefold. First, a vector super-twisting algorithm is designed to provide a direct extension of the conventional scalar supertwisting control, without any additional terms. An upper estimate of its convergence time is calculated. Second, a fixed time convergent continuous vector super-twisting-like algorithm is presented and its fixed convergence time is estimated. Third, an estimate of the finite convergence time of the scalar supertwisting algorithm is obtained as a particular case of the vector super-twisting one, which occurs to be less conservative than the one derived specially for the scalar case. The proposed theory is applied to F-16 jet-fighter flight control.","Convergence,
Algorithm design and analysis,
Upper bound,
Closed loop systems,
Estimation,
Computer aided software engineering,
Sliding mode control"
MAC-Layer Selfish Misbehavior in IEEE 802.11 Ad Hoc Networks: Detection and Defense,"In ad hoc networks, selfish nodes deviating from the standard MAC (Medium Access Control) protocol can significantly degrade normal nodes' performance and are usually difficult to detect. In this paper, we propose detection and defense schemes to identify and defend against MAC-layer selfish misbehavior, respectively, in IEEE 802.11 multi-hop ad hoc networks. Specifically, the non-deterministic nature of the IEEE 802.11 MAC protocol imposes great challenges to distinguishing selfish nodes from well-behaved nodes. Most traditional selfish misbehavior detection approaches are for wireless local area networks (WLANs) only. They either rely on a large amount of historical data to perform statistical detection, or employ throughput or delay models that are only valid in WLANs for detection. In contrast, we propose a realtime selfish misbehavior detection scheme for multi-hop ad hoc networks. It requires only several samples, and hence is more efficient and can adapt to channel dynamics more quickly. Then, based on the proposed detection scheme, we design three selfish misbehavior defense schemes against three typical kinds of smart selfish nodes. We find that the smart selfish nodes cannot degrade normal nodes' performance much without getting detected. Extensive simulation results are finally presented to validate the proposed detection and defense schemes.","IEEE 802.11 Standards,
Observers,
Media Access Protocol,
Ad hoc networks,
Mobile computing,
Spread spectrum communication"
A Compressive Sensing Approach to Describe Indoor Scenes for Blind People,"This paper introduces a new portable camera-based method for helping blind people to recognize indoor objects. Unlike state-of-the-art techniques, which typically perform the recognition task by limiting it to a single predefined class of objects, we propose here a completely different alternative scheme, defined as coarse description. It aims at expanding the recognition task to multiple objects and, at the same time, keeping the processing time under control by sacrificing some information details. The benefit is to increment the awareness and the perception of a blind person to his direct contextual environment. The coarse description issue is addressed via two image multilabeling strategies which differ in the way image similarity is computed. The first one makes use of the Euclidean distance measure, while the second one relies on a semantic similarity measure modeled by means of Gaussian process estimation. To achieve fast computation capability, both strategies rely on a compact image representation based on compressive sensing. The proposed methodology was assessed on two indoor datasets representing different indoor environments. Encouraging results were achieved in terms of both accuracy and processing time.","Training,
Vectors,
Semantics,
Compressed sensing,
Materials,
Matching pursuit algorithms,
Mathematical model"
Data preference matters: A new perspective of safety data dissemination in vehicular ad hoc networks,"Vehicle-to-vehicle safety data dissemination plays an increasingly important role in ensuring the safety and efficiency of vehicle transportation. When collecting safety data, vehicles always prefer data generated at a closer location over data generated at a distant location, and prefer recent data over outdated data. However, these data preferences have been overlooked in most of existing safety data dissemination protocols, preventing vehicles getting more precise traffic information. In this paper, we explore the feasibility and benefits of incorporating the data preferences of vehicles in designing efficient safety data dissemination protocols. In particular, we propose the concept of packet-value to quantify these data preferences. We then design PVCast, a packet-value-based safety data dissemination protocol in VANET. PVCast makes the dissemination decision for each packet based on its packet-value and effective dissemination coverage in order to satisfy the data preferences of all the vehicles in the network. In addition, PVCast is lightweight and fully distributed. We evaluate the performance of PVCast on the ns-2 platform by comparing it with three representative data dissemination protocols. Simulation results in a typical highway scenario show that PVCast provides a significant improvement on per-vehicle throughput, per-packet dissemination coverage with small per-packet delay. Our findings demonstrate the importance and necessity of comprehensively considering the data preferences of vehicles when designing an efficient safety data dissemination protocol for VANET.",
A QoE-driven FEC rate adaptation scheme for scalable video transmissions over MIMO systems,"We propose a forward error correction (FEC) coding rate adaptation scheme which maximizes the quality of experience (QoE), for scalable video coding (SVC) based video transmissions over multi-input multi-output (MIMO) systems. The proposed scheme adaptively selects the best set of spatial channels, number of video layers and their corresponding FEC coding rate according to channel state information (CSI) from the receiver. Unlike previous work, our proposed scheme distributes the FEC encoded bit streams to multiple spatial channels so that additional diversity gains can be obtained. Due to the complexity of the optimization, we decompose the original problem into several sub-problems, which can then be solved by a heuristic algorithm. The optimal solution can be found by choosing the best among all the candidate solutions obtained from the sub-problems. The effectiveness and superb performance of our proposed scheme can be demonstrated by many simulations with different videos and channel conditions.","Streaming media,
Forward error correction,
MIMO,
Static VAr compensators,
Decoding,
Receivers,
Channel estimation"
Experimental Validation of a Fuzzy Adaptive Voltage Controller for Three-Phase PWM Inverter of a Standalone DG Unit,"This paper investigates a disturbance observer-based fuzzy adaptive voltage controller for three-phase pulse width modulation (PWM) inverter of a standalone distributed generation (DG) unit in the existence of system uncertainties. The proposed control law includes only a voltage control loop, which has advantages such as a simple control structure and a fast transient response due to the direct control of the output voltage. Next, a disturbance observer is presented to reduce the number of the sensors and improve the control performance. Besides, the proposed strategy is insensitive to any system uncertainties, because it does not require any accurate knowledge about system parameter and load current information. Experimental results on a prototype DG unit with a TMS320F28335 DSP are demonstrated to validate the superior performance of the proposed control scheme over the conventional proportional-derivative (PD) control method and feedback linearization control (FLC) method under sudden load disturbances, system uncertainties, and nonlinear load.","Voltage control,
Observers,
Inverters,
Uncertainty,
Pulse width modulation,
Mathematical model,
PD control"
On Link Scheduling Under Blockage and Interference in 60-GHz Ad Hoc Networks,"In this paper, we tackle the problem of minimum time length link scheduling in 60-GHz ad hoc wireless networks using directional antennas with directional beamforming, under both traffic demand and signal to interference and noise ratio constraints. Both single-hop and multi-hop cases are considered. For the single-hop scenario, a binary integer programming problem is formulated by incorporating a general interference model for directional transmissions and a Markov chain-based blockage model. Two effective solution algorithms are proposed, including a greedy algorithm that maximizes the instant throughput for each time slot, and a column generation-based algorithm that iteratively improves the current link schedule. For the multi-hop scenario, we develop a more complicated problem formulation incorporating both route selection and flow conservation constraints. We also develop an effective algorithm to solve the multi-hop problem. The performance of the proposed algorithms is validated with simulations.","Ad hoc networks,
5G mobile communication,
Wireless networks,
Column generation,
Scheduling,
Column generation"
Scene text detection with robust character candidate extraction method,"The maximally stable extremal region (MSER) method has been widely used to extract character candidates, but because of its requirement for maximum stability, high text detection performance is difficult to obtain. To overcome this problem, we propose a robust character candidate extraction method that performs ER tree construction, sub-path partitioning, sub-path pruning, and character candidate selection sequentially. Then, we use the AdaBoost trained character classifier to verify the extracted character candidates. Then, we use heuristics to refine the classified character candidates and group the refined character candidates into text regions according to their geometric adjacency and color similarity. We also apply the proposed text detection method to two different color channels Cr and Cb and obtain the final detection result by combining the detection results on the three different channels. The proposed text detection method on ICDAR 2013 dataset achieved 8%, 1%, and 4% improvements in recall rate, precision rate and f-score, respectively, compared to the state-of-the-art methods.","Erbium,
Classification algorithms,
Image resolution"
Microfluidic Stretchable Radio-Frequency Devices,"Recently, the shrinking of the personal computer market has given a clear signal that it is time to divert our focus from the strategy of miniaturization of transistors to a different strategy with emerging technologies. As a new form of electronics, stretchable electronics has significantly advanced in the past few years by micro/nanofabrication of thin films of traditional stiff and hard materials such as silicon, metals, and ceramics, and especially subsequent transfer process on an elastic substrate. However, such a thin structure often suffers from high resistance that leads to low performance when long structures are required. This is particularly true for antennas in radio-frequency (RF) electronics. By introducing microfluidics into RF electronics, we found out that it was an excellent way to make high-performance stretchable RF electronics. Apart from antennas, the microfluidic approach was also adopted and further developed to various devices with integrated wireless communication. This fusion of microfluidics with RF electronics brings not only a lot of opportunities for researchers as a radically new research field, but also potentially commercial benefits for industry. As a new emerging field, a huge effort, ranging from fundamental science to technology development, is required to realize it. This paper illustrates the fundamentals in processing and relevant applications, and highlights recent advances in microfluidic RF electronics. The authors would like to inspire the electronics community to further exploit the advantages of this approach and accelerate innovations in this field.","Reconfigurable architectures,
Radio frequency,
Computers,
Microfluidics,
Liquids,
Performance evaluation,
Consumer electronics"
Non-Rigid Object Contour Tracking via a Novel Supervised Level Set Model,"We present a novel approach to non-rigid objects contour tracking in this paper based on a supervised level set model (SLSM). In contrast to most existing trackers that use bounding box to specify the tracked target, the proposed method extracts the accurate contours of the target as tracking output, which achieves better description of the non-rigid objects while reduces background pollution to the target model. Moreover, conventional level set models only emphasize the regional intensity consistency and consider no priors. Differently, the curve evolution of the proposed SLSM is object-oriented and supervised by the specific knowledge of the targets we want to track. Therefore, the SLSM can ensure a more accurate convergence to the exact targets in tracking applications. In particular, we firstly construct the appearance model for the target in an online boosting manner due to its strong discriminative power between the object and the background. Then, the learnt target model is incorporated to model the probabilities of the level set contour by a Bayesian manner, leading the curve converge to the candidate region with maximum likelihood of being the target. Finally, the accurate target region qualifies the samples fed to the boosting procedure as well as the target model prepared for the next time step. We firstly describe the proposed mechanism of two-phase SLSM for single target tracking, then give its generalized multi-phase version for dealing with multi-target tracking cases. Positive decrease rate is used to adjust the learning pace over time, enabling tracking to continue under partial and total occlusion. Experimental results on a number of challenging sequences validate the effectiveness of the proposed method.",
A Joint Segmentation and Classification Framework for Sentence Level Sentiment Classification,"In this paper, we propose a joint segmentation and classification framework for sentence-level sentiment classification. It is widely recognized that phrasal information is crucial for sentiment classification. However, existing sentiment classification algorithms typically split a sentence as a word sequence, which does not effectively handle the inconsistent sentiment polarity between a phrase and the words it contains, such as {“not bad,” “bad”} and {“a great deal of,” “great”}. We address this issue by developing a joint framework for sentence-level sentiment classification. It simultaneously generates useful segmentations and predicts sentence-level polarity based on the segmentation results. Specifically, we develop a candidate generation model to produce segmentation candidates of a sentence; a segmentation ranking model to score the usefulness of a segmentation candidate for sentiment classification; and a classification model for predicting the sentiment polarity of a segmentation. We train the joint framework directly from sentences annotated with only sentiment polarity, without using any syntactic or sentiment annotations in segmentation level. We conduct experiments for sentiment classification on two benchmark datasets: a tweet dataset and a review dataset. Experimental results show that: 1) our method performs comparably with state-of-the-art methods on both datasets; 2) joint modeling segmentation and classification outperforms pipelined baseline methods in various experimental settings.",
Unconstrained 3D face reconstruction,"This paper presents an algorithm for unconstrained 3D face reconstruction. The input to our algorithm is an “unconstrained” collection of face images captured under a diverse variation of poses, expressions, and illuminations, without meta data about cameras or timing. The output of our algorithm is a true 3D face surface model represented as a watertight triangulated surface with albedo data or texture information. 3D face reconstruction from a collection of unconstrained 2D images is a long-standing computer vision problem. Motivated by the success of the state-of-the-art method, we developed a novel photometric stereo-based method with two distinct novelties. First, working with a true 3D model allows us to enjoy the benefits of using images from all possible poses, including profiles. Second, by leveraging emerging face alignment techniques and our novel normal field-based Laplace editing, a combination of landmark constraints and photometric stereo-based normals drives our surface reconstruction. Given large photo collections and a ground truth 3D surface, we demonstrate the effectiveness and strength of our algorithm both qualitatively and quantitatively.","Three-dimensional displays,
Face,
Shape,
Image reconstruction,
Surface reconstruction,
Lighting,
Solid modeling"
Sparse Generalized Eigenvalue Problem Via Smooth Optimization,"In this paper, we consider an ℓ0-norm penalized formulation of the generalized eigenvalue problem (GEP), aimed at extracting the leading sparse generalized eigenvector of a matrix pair. The formulation involves maximization of a discontinuous nonconcave objective function over a nonconvex constraint set, and is therefore computationally intractable. To tackle the problem, we first approximate the ℓ0-norm by a continuous surrogate function. Then an algorithm is developed via iteratively majorizing the surrogate function by a quadratic separable function, which at each iteration reduces to a regular generalized eigenvalue problem. A preconditioned steepest ascent algorithm for finding the leading generalized eigenvector is provided. A systematic way based on smoothing is proposed to deal with the “singularity issue” that arises when a quadratic function is used to majorize the nondifferentiable surrogate function. For sparse GEPs with special structure, algorithms that admit a closed-form solution at every iteration are derived. Numerical experiments show that the proposed algorithms match or outperform existing algorithms in terms of computational complexity and support recovery.","Eigenvalues and eigenfunctions,
Signal processing algorithms,
Principal component analysis,
Sparse matrices,
Approximation methods,
Vectors,
Tin"
Multimodal Segmentation of Optic Disc and Cup From SD-OCT and Color Fundus Photographs Using a Machine-Learning Graph-Based Approach,"In this work, a multimodal approach is proposed to use the complementary information from fundus photographs and spectral domain optical coherence tomography (SD-OCT) volumes in order to segment the optic disc and cup boundaries. The problem is formulated as an optimization problem where the optimal solution is obtained using a machine-learning theoretical graph-based method. In particular, first the fundus photograph is registered to the 2D projection of the SD-OCT volume. Three in-region cost functions are designed using a random forest classifier corresponding to three regions of cup, rim, and background. Next, the volumes are resampled to create radial scans in which the Bruch's Membrane Opening (BMO) endpoints are easier to detect. Similar to in-region cost function design, the disc-boundary cost function is designed using a random forest classifier for which the features are created by applying the Haar Stationary Wavelet Transform (SWT) to the radial projection image. A multisurface graph-based approach utilizes the in-region and disc-boundary cost images to segment the boundaries of optic disc and cup under feasibility constraints. The approach is evaluated on 25 multimodal image pairs from 25 subjects in a leave-one-out fashion (by subject). The performances of the graph-theoretic approach using three sets of cost functions are compared: 1) using unimodal (OCT only) in-region costs, 2) using multimodal in-region costs, and 3) using multimodal in-region and disc-boundary costs. Results show that the multimodal approaches outperform the unimodal approach in segmenting the optic disc and cup.","Optical imaging,
Cost function,
Image segmentation,
Feature extraction,
Biomedical optical imaging,
Image color analysis,
Urban areas"
A primal-dual framework for real-time dense RGB-D scene flow,"This paper presents the first method to compute dense scene flow in real-time for RGB-D cameras. It is based on a variational formulation where brightness constancy and geometric consistency are imposed. Accounting for the depth data provided by RGB-D cameras, regularization of the flow field is imposed on the 3D surface (or set of surfaces) of the observed scene instead of on the image plane, leading to more geometrically consistent results. The minimization problem is efficiently solved by a primal-dual algorithm which is implemented on a GPU, achieving a previously unseen temporal performance. Several tests have been conducted to compare our approach with a state-of-the-art work (RGB-D flow) where quantitative and qualitative results are evaluated. Moreover, an additional set of experiments have been carried out to show the applicability of our work to estimate motion in real-time. Results demonstrate the accuracy of our approach, which outperforms the RGB-D flow, and which is able to estimate heterogeneous and non-rigid motions at a high frame rate.","Cameras,
Optical imaging,
Three-dimensional displays,
TV,
Approximation methods,
Real-time systems,
Graphics processing units"
Survey of High-Temperature Polymeric Encapsulants for Power Electronics Packaging,"Semiconductor encapsulation is crucial to electronic packaging because it provides protection against mechanical stress, electrical breakdown, chemical erosions, α radiations, and so on. Conventional encapsulants are only applicable below 150 °C. However, with increasing demand for high-density and high-temperature packaging, encapsulants that are functional at or above 250 °C are required. In this paper, five types of encapsulants, including conformal coatings, underfills, molding compounds, potting compounds, and glob tops, are surveyed. First, recommended properties and selection criteria of each type of encapsulant are listed. Second, standard test methods for several crucial properties, including glass-transition temperature (Tg), coefficient of thermal expansion (CTE), dielectric strength, and so on are reviewed. Afterward, commercial products with high-operation temperature are surveyed. However, the results of the survey reveal a lack of high-temperature encapsulants. Therefore, this paper reviews recent progress in achieving encapsulants with both high-temperature capability and satisfactory properties. Material compositions other than epoxy, such as polyimide (PI), bismaleimide (BMI), and cyanate ester (CE), are potential encapsulants for high-temperature (250 °C) operation, although their CTE needs to be tailored to limit internal stress. Fillers are reported to be efficient in reducing the CTE. In addition, fillers may also have a beneficial impact on the thermal stability of silicone-based encapsulants, whose high-temperature capability is limited by their thermal instability.",
PIF: A Personalized Fine-Grained Spam Filtering Scheme With Privacy Preservation in Mobile Social Networks,"Mobile social network (MSN) emerges as a promising social network paradigm that enables mobile users' information sharing in the proximity and facilitates their cyber-physical-social interactions. As the advertisements, rumors, and spams spread in MSNs, it is necessary to filter spams before they arrive at the recipients to make the MSN energy efficient. To this end, we propose a personalized fine-grained filtering scheme (PIF) with privacy preservation in MSNs. Specifically, we first develop a social-assisted filter distribution scheme, where the filter creators send filters to their social friends (i.e., filter holders). These filter holders store filters and decide to block spams or relay the desired packets through coarse-grained and fine-grained keyword filtering schemes. Meanwhile, the developed cryptographic filtering schemes protect creator's private information (i.e., keyword) embedded in the filters from directly disclosing to other users. In addition, we establish a Merkle Hash tree to store filters as leaf nodes where filter creators can check if the distributed filters need to be updated by retrieving the value of root node. It is demonstrated that the PIF can protect users' private keywords included in the filter from disclosure to others and detect forged filters. We also conduct the trace-driven simulations to show that the PIF can not only filter spams efficiently but also achieve high delivery ratio and low latency with acceptable resource consumption.","Social network services,
Privacy,
Mobile communication,
Servers,
Security,
Unsolicited electronic mail,
Tree data structures"
Bandwidth-efficient on-chip interconnect designs for GPGPUs,"Modern computational workloads require abundant thread level parallelism (TLP), necessitating highly-parallel, many-core accelerators such as General Purpose Graphics Processing Units (GPGPUs). GPGPUs place a heavy demand on the on-chip interconnect between the many cores and a few memory controllers (MCs). Thus, traffic is highly asymmetric, impacting on-chip resource utilization and system performance. Here, we analyze the communication demands of typical GPGPU applications, and propose efficient Network-on-Chip (NoC) designs to meet those demands. We show that the proposed schemes improve performance by up to 64.7%. Compared to the best of class prior work, our VC monopolizing and partitioning schemes improve performance by 25%.",
RACOG and wRACOG: Two Probabilistic Oversampling Techniques,"As machine learning techniques mature and are used to tackle complex scientific problems, challenges arise such as the imbalanced class distribution problem, where one of the target class labels is under-represented in comparison with other classes. Existing oversampling approaches for addressing this problem typically do not consider the probability distribution of the minority class while synthetically generating new samples. As a result, the minority class is not represented well which leads to high misclassification error. We introduce two probabilistic oversampling approaches, namely RACOG and wRACOG, to synthetically generating and strategically selecting new minority class samples. The proposed approaches use the joint probability distribution of data attributes and Gibbs sampling to generate new minority class samples. While RACOG selects samples produced by the Gibbs sampler based on a predefined lag, wRACOG selects those samples that have the highest probability of being misclassified by the existing learning model. We validate our approach using nine UCI data sets that were carefully modified to exhibit class imbalance and one new application domain data set with inherent extreme class imbalance. In addition, we compare the classification performance of the proposed methods with three other existing resampling techniques.","Probability distribution,
Approximation methods,
Approximation algorithms,
Probabilistic logic,
Kernel,
Joints,
Machine learning algorithms"
Normal Endmember Spectral Unmixing Method for Hyperspectral Imagery,"The normal compositional model (NCM) has been introduced to characterize mixed pixels in hyperspectral images, particularly when endmember variability needs to be considered in the unmixing process. Each pixel is modeled as a linear combination of endmembers, which are treated as Gaussian random variables in order to capture such spectral variability. Since the combination coefficients (i.e., abundances) and the endmembers are unknown variables at the same time in the NCM, the parameter estimation is more difficult in comparison with conventional approaches. In order to address this issue, we propose a new Bayesian method, termed normal endmember spectral unmixing (NESU), for improved parameter estimation in this context. It considers the endmembers as known variables (resulting from the extraction of endmember bundles), then performs optimal estimations of the remaining unknown parameters, i.e., the abundances, using Bayesian inference. The particle swarm optimization (PSO) technique is adopted to estimate the optimal values of abundances according to their posterior probabilities. The performance of the proposed algorithm is evaluated using both synthetic and real hyperspectral data. The obtained results demonstrate that the proposed method leads to significant improvements in terms of unmixing accuracies.",
A Comprehensive Analysis of Strength-Based Optimum Signal Detection in Concentration-Encoded Molecular Communication With Spike Transmission,"In this paper, a comprehensive analysis of strength-based optimum signal detection model has been presented for concentration-encoded molecular communication (CEMC) with spike (i.e., impulsive) transmission based on amplitude-shift keying (ASK) and on-off keying (OOK) modulations. Strength-based optimum signal detection problem in diffusion-based CEMC system has been investigated in detail in the presence of both diffusion noise and intersymbol interference (ISI). The receiver for optimum signal detection has been developed theoretically and explained with both analytical and simulation results of binary signal detection. Results show that the receiver thus developed can detect CEMC symbols effectively; however, the performance is influenced by three main factors, namely, communication range, transmission data rate, and receiver memory. For both ASK and OOK receivers, exact and approximate detection performances have been derived analytically depending on the probabilistic nature of molecular availability and the relationship between mean and variance of signal strengths. Correspondingly, bit error rate (BER) performance of the optimum receiver in a single CEMC link is further evaluated under various scenarios through extensive simulation experiments.","Receivers,
Signal detection,
Noise,
Nanobioscience,
Amplitude shift keying,
Bit error rate,
Molecular communication"
Match to cache: Joint user association and backhaul allocation in cache-aware small cell networks,"Caching multimedia files at the network edge has been identified as a key technology for enhancing users' quality-of-service (QoS), while reducing redundant transmissions over capacity-constrained backhauls. Nevertheless, in small cell networks, the efficiency of a caching policy depends on the ability of small base stations (SBSs) to anticipate the requests from the user equipments (UEs). In this paper, we propose a collaborative filtering (CF) scheme for estimating the required backhaul usage at each SBS, by mining the cacheability of UEs' file requests. In the proposed approach, each SBS has a two-fold objective: update the bandwidth allocation based on the estimated backhaul utilization, and, given the current bandwidth availability, identify which UEs to service. We formulate the problem as a one-to many matching game between SBSs and UEs, and we propose a novel cache-aware user association algorithm that minimizes the backhaul usage at each SBS, subject to individual QoS requirements. Simulation results, based on real-world service request logs, have shown that the proposed CF-based solution can yield significant gains in terms of backhaul efficiency and cache hit-ratio, reaching up to 25%, with a maximum gap of 9% to an optimal cache-aware association technique.","Bandwidth,
Interference,
Wireless communication,
Quality of service,
Resource management,
Bismuth,
Channel allocation"
"Impact of Interdisciplinary Research on Planning, Running, and Managing Electromobility as a Smart Grid Extension","The smart grid is concerned with energy efficiency and with the environment, being a countermeasure against the territory devastations that may originate by the fossil fuel mining industry feeding the conventional power grids. This paper deals with the integration between the electromobility and the urban power distribution network in a smart grid framework, i.e., a multi-stakeholder and multi-Internet ecosystem (Internet of Information, Internet of Energy, and Internet of Things) with edge computing capabilities supported by cloud-level services and with clean mapping between the logical and physical entities involved and their stakeholders. In particular, this paper presents some of the results obtained by us in several European projects that refer to the development of a traffic and power network co-simulation tool for electro mobility planning, platforms for recharging services, and communication and service management architectures supporting interoperability and other qualities required for the implementation of the smart grid framework. For each contribution, this paper describes the inter-disciplinary characteristics of the proposed approaches.","Smart grids,
Cloud computing,
Urban areas,
Energy storage,
Information management"
MCU Tolerance in SRAMs Through Low-Redundancy Triple Adjacent Error Correction,"Static random access memories (SRAMs) are key in electronic systems. They are used not only as standalone devices, but also embedded in application specific integrated circuits. One key challenge for memories is their susceptibility to radiation-induced soft errors that change the value of memory cells. Error correction codes (ECCs) are commonly used to ensure correct data despite soft errors effects in semiconductor memories. Single error correction/double error detection (SEC-DED) codes have been traditionally the preferred choice for data protection in SRAMs. During the last decade, the percentage of errors that affect more than one memory cell has increased substantially, mainly due to multiple cell upsets (MCUs) caused by radiation. The bits affected by these errors are physically close. To mitigate their effects, ECCs that correct single errors and double adjacent errors have been proposed. These codes, known as single error correction/double adjacent error correction (SEC-DAEC), require the same number of parity bits as traditional SEC-DED codes and a moderate increase in the decoder complexity. However, MCUs are not limited to double adjacent errors, because they affect more bits as technology scales. In this brief, new codes that can correct triple adjacent errors and 3-bit burst errors are presented. They have been implemented using a 45-nm library and compared with previous proposals, showing that our codes have better error protection with a moderate overhead and low redundancy.","Parity check codes,
Error correction codes,
Decoding,
Delays,
Very large scale integration,
Random access memory,
Complexity theory"
AOA-based localization and tracking in multi-element VLC systems,"Visible light communication (VLC) is an emerging technology that is expected to be widely used for indoor wireless communications. Accurate localization of VLC equipment has a wide variety of applications in indoor scenarios, where GPS receivers do not work. This paper proposes a new and effective method for localization of VLC devices based solely on the connectivity information. Due to narrow field of view characteristics of connected LEDs, angle of arrival to an access point can be estimated accurately. Exploiting such features, a least square estimator is developed for location estimation, and a Kalman filter is utilized for improving the tracking performance of a mobile device. Simulation results show that average localization accuracies on the order 0.2 meters can be achieved in various different access point topologies.","Light emitting diodes,
Wireless communication,
Mobile communication,
Transmitters,
Receivers,
Kalman filters,
Robots"
"Low-Power VLSI Architectures for DCT\/DWT: Precision vs Approximation for HD Video, Biomedical, and Smart Antenna Applications","The DCT and the DWT are used in a number of emerging DSP applications, such as, HD video compression, biomedical imaging, and smart antenna beamformers for wireless communications and radar. Of late, there has been much interest on fast algorithms for the computation of the above transforms using multiplier-free approximations because they result in low power and low complexity systems. Approximate methods rely on the trade-off of accuracy for lower power and/or circuit complexity/chip-area. This paper provides a detailed review of VLSI architectures and CAS implementations for both DCT/DWTs, which can be designed either for higher-accuracy or for low-power consumption. This article covers both recent theoretical advancements on discrete transforms in addition to an overview of existing VLSI architectures. The paper also discusses error free VLSI architectures that provides high accuracy systems and approximate architectures that offer high computational gain making them highly attractive for real-world applications that are subject to constraints in both chip-area as well as power. The methods discussed in the paper can be used in the design of emerging low-power digital systems having lowest complexity at the cost of a loss in accuracy?the optimal trade-off of computational accuracy for lowest possible complexity and power. A complete synopsis of available techniques, algorithms and FPGA/VLSI realizations are discussed in the paper.","Discrete cosine transforms,
Very large scale integration,
Approximation methods,
Computer architecture,
Filter banks,
Artificial intelligence,
Biomedical monitoring,
Low power electronics,
Smart antennas"
Watch-n-patch: Unsupervised understanding of actions and relations,"We focus on modeling human activities comprising multiple actions in a completely unsupervised setting. Our model learns the high-level action co-occurrence and temporal relations between the actions in the activity video. We consider the video as a sequence of short-term action clips, called action-words, and an activity is about a set of action-topics indicating which actions are present in the video. Then we propose a new probabilistic model relating the action-words and the action-topics. It allows us to model long-range action relations that commonly exist in the complex activity, which is challenging to capture in the previous works. We apply our model to unsupervised action segmentation and recognition, and also to a novel application that detects forgotten actions, which we call action patching. For evaluation, we also contribute a new challenging RGB-D activity video dataset recorded by the new Kinect v2, which contains several human daily activities as compositions of multiple actions interacted with different objects. The extensive experiments show the effectiveness of our model.","Hidden Markov models,
Feature extraction,
Training,
Joints,
Gaussian distribution,
Correlation"
System and architecture level characterization of big data applications on big and little core server architectures,"Emerging Big Data applications require a significant amount of server computational power. Big data analytics applications rely heavily on specific deep machine learning and data mining algorithms, and exhibit high computational intensity, memory intensity, I/O intensity and control intensity. Big data applications require computing resources that can efficiently scale to manage massive amounts of diverse data. However, the rapid growth in the data yields challenges to process data efficiently using current server architectures such as big Xeon cores. Furthermore, physical design constraints, such as power and density, have become the dominant limiting factor for scaling out servers. Therefore recent work advocates the use of low-power embedded cores in servers such as little Atom to address these challenges. In this work, through methodical investigation of power and performance measurements, and comprehensive system level and micro-architectural analysis, we characterize emerging big data applications on big Xeon and little Atom-based server architecture. The characterization results across a wide range of real-world big data applications and various software stacks demonstrate how the choice of big vs little core-based server for energy-efficiency is significantly influenced by the size of data, performance constraints, and presence of accelerator. Furthermore, the microarchitecture-level analysis highlights where improvement is needed in big and little cores microarchitecture.","Big data,
Servers,
Data mining,
Computer architecture,
Microarchitecture,
Atomic measurements,
Real-time systems"
Understanding Blooming Human Groups in Social Networks,"Human group, which indicates the people who share similar characteristics, is used to categorize humans into distinct populations or groups. In recent years, with the explosive growth of image, new concepts of human group are blooming in social networks . People in the same human group can be categorized by their facial and clothes appearance characteristics. In this work, we propose an approach to understanding the new concepts of human group with few positive samples. To this end, we construct visual models crossing two modalities related to human images and surrounding texts. Two convolutional neural networks based on face and upper body are constructed separately. Two different convolutional neural networks (CNNs) architectures are explored for visual pre-traing. To assist the human group recognition, we also merge global convolutional feature of the image. The surrounding texts are represented by semantical vectors and utilized as image labels. We transform words in the text into fixed length vectors by the skip-gram model. Then the texts corresponding to each image are converted into one feature vector by sparse coding and max pooling. Given a few positive samples of new concepts of human group, the visual model can be improved to understand the semantical meaning of the new label. The experimental results demonstrate the effectiveness of the proposed visual model and show the excellent learning capacity with few samples.","Visualization,
Training,
Face,
Neural networks,
Social network services,
Convolutional codes,
Semantics"
Magnetic Equivalent Circuit Modeling of the AC Homopolar Machine for Flywheel Energy Storage,"This paper develops a magnetic equivalent circuit model suitable to the design and optimization of the synchronous ac homopolar machine. The ac homopolar machine is of particular interest in the application of grid-based flywheel energy storage, where it has the potential to significantly reduce self-discharge associated with magnetic losses. The ac homopolar machine features both axial and radial magnetizing flux paths, which requires finite element analysis to be conducted in 3-D. The computation time associated with 3-D finite element modeling is highly prohibitive in the design process. The magnetic equivalent circuit model developed in this paper is shown to be a viable alternative for calculating several design performance parameters and has a computation time which is orders of magnitude less than that of 3-D finite element analysis. Results obtained from the developed model are shown to be in good agreement with finite element and experimental results for varying levels of saturation.","Electron tubes,
Rotors,
Stators,
Integrated circuit modeling,
Homopolar machines,
Computational modeling,
Magnetic circuits"
Cross-Domain Person Reidentification Using Domain Adaptation Ranking SVMs,"This paper addresses a new person reidentification problem without label information of persons under nonoverlapping target cameras. Given the matched (positive) and unmatched (negative) image pairs from source domain cameras, as well as unmatched (negative) and unlabeled image pairs from target domain cameras, we propose an adaptive ranking support vector machines (AdaRSVMs) method for reidentification under target domain cameras without person labels. To overcome the problems introduced due to the absence of matched (positive) image pairs in the target domain, we relax the discriminative constraint to a necessary condition only relying on the positive mean in the target domain. To estimate the target positive mean, we make use of all the available data from source and target domains as well as constraints in person reidentification. Inspired by adaptive learning methods, a new discriminative model with high confidence in target positive mean and low confidence in target negative image pairs is developed by refining the distance model learnt from the source domain. Experimental results show that the proposed AdaRSVM outperforms existing supervised or unsupervised, learning or non-learning reidentification methods without using label information in target cameras. Moreover, our method achieves better reidentification performance than existing domain adaptation methods derived under equal conditional probability assumption.","Vectors,
Cameras,
Adaptation models,
Equations,
Mathematical model,
Data models,
Feature extraction"
Depth Superresolution by Transduction,"This paper presents a depth superresolution (SR) method that uses both of a low-resolution (LR) depth image and a high-resolution (HR) intensity image. We formulate depth SR as a graph-based transduction problem. In particular, the HR intensity image is represented as an undirected graph, in which pixels are characterized as vertices, and their relations are encoded as an affinity function. When the vertices initially labeled with certain depth hypotheses (from the LR depth image) are regarded as input queries, all the vertices are scored with respect to the relevances to these queries by a classifying function. Each vertex is then labeled with the depth hypothesis that receives the highest relevance score. We design the classifying function by considering the local and global structures of the HR intensity image. This approach enables us to address a depth bleeding problem that typically appears in current depth SR methods. Furthermore, input queries are assigned in a probabilistic manner, making depth SR robust to noisy depth measurements. We also analyze existing depth SR methods in the context of transduction, and discuss their theoretic relations. Intensive experiments demonstrate the superiority of the proposed method over state-of-the-art methods both qualitatively and quantitatively.",
A Novel Bio-Inspired Technique for Rapid Real-Time Generator Coherency Identification,"Generator coherency identification is establishing itself as an important task to aid in the resistance of cascading failures within wide-area power systems and as a necessary preprocessing stage in real-time control for transient stability. Inspired by flocking behavior in nature, we propose a novel multiflock-based technique to identify generator coherence rapidly within a short observation window. Our measurement-based approach transforms generator data from the observation space to an information space, whereby the generator frequencies and phases characterize the movement and dynamics of boids within multiple flocks. Analysis of the boids' trajectories enables the discrimination of multiple flocks corresponding to coherent generator clusters. We demonstrate the effectiveness of our technique to identify generator coherency rapidly while exhibiting robustness to environmental noise and cyber attack on the 39-bus New England test system and a modified IEEE 118-Bus test system.","Generators,
Phasor measurement units,
Real-time systems,
Trajectory,
Acceleration,
Robustness,
Power system stability"
A Stable Marching On-In-Time Scheme for Solving the Time-Domain Electric Field Volume Integral Equation on High-Contrast Scatterers,"A time-domain electric field volume integral equation (TD-EFVIE) solver is proposed for characterizing transient electromagnetic wave interactions on high-contrast dielectric scatterers. The TD-EFVIE is discretized using the Schaubert-Wilton-Glisson (SWG) and approximate prolate spherical wave (APSW) functions in space and time, respectively. The resulting system of equations cannot be solved by a straightforward application of the marching on-in-time (MOT) scheme since the two-sided APSW interpolation functions require the knowledge of unknown “future” field samples during time marching. Causality of the MOT scheme is restored using an extrapolation technique that predicts the future samples from known “past” ones. Unlike the extrapolation techniques developed for MOT schemes that are used in solving time-domain surface integral equations, this scheme trains the extrapolation coefficients using samples of exponentials with exponents on the complex frequency plane. This increases the stability of the MOT-TD-EFVIE solver significantly, since the temporal behavior of decaying and oscillating electromagnetic modes induced inside the scatterers is very accurately taken into account by this new extrapolation scheme. Numerical results demonstrate that the proposed MOT solver maintains its stability even when applied to analyzing wave interactions on high-contrast scatterers.",
Exploiting request characteristics and internal parallelism to improve SSD performance,"In this paper, we propose a new I/O scheduler for SSDs, called Amphibian, which exploits the up-level request characteristics and the low-level internal parallelism of flash chips to improve the performance of SSD-based storage systems. Amphibian includes two parts: the size-based request ordering that gives higher priority to first processing the small requests and the Garbage Collection (GC) aware request dispatching that avoids issuing requests to the flash chips that are in the GC state. By first processing the small requests and avoiding issuing the GC-conflict requests in the I/O waiting queue, the average waiting times of the requests are reduced significantly. The extensive evaluation results show that compared with existing I/O schedulers, Amphibian improves the throughput and the average response times significantly. Consequently, the I/O performance of the SSD-based storage systems is improved.","Ash,
Parallel processing,
Time factors,
Dispatching,
Performance evaluation,
Throughput,
System software"
Functional and Cost-Based Automatic Generator for Hybrid Vehicles Topologies,"The energy efficiency of a hybrid electric vehicle is dictated by the topology (coupling option of power sources/sinks), choice (technology), and control of components. The first design area among these, the topology, has the biggest flexibility of them all, yet, so far in the literature, the topology design is limited investigated due to its high complexity. In practice, a predefined small set of topologies is used to optimize their energy efficiency by varying the power specifications of the main components (sizing). By doing so, the complete design of the vehicle is, inherently and to a certain extent, suboptimal. Moreover, various complex topologies appear on the automotive market and no tool exists to optimally choose or evaluate them. To overcome this design limitation, in this paper, a novel framework is presented that deals with the automatic generation of possible topologies given a set of components (e.g., engine, electric machine, batteries, or transmission elements). This paper uses a platform (library of components) and a hybrid knowledge base (functional and cost-based principles) to set up a constraint logic programming problem, and outputs a set of feasible topologies for hybrid electric vehicles. These are all possible topologies that could be built considering a fixed, yet large, set of components. Then, by using these results, insights are given on what construction principles are mostly critical for simulations time, and what topologies could be selected as candidate topologies for sizing and control studies. Such a framework can be used for any powertrain application; it can offer the topologies to be investigated in the design phase and can provide insightful results for optimal design analyses.","Topology,
Hybrid electric vehicles,
Hybrid power systems,
Engines,
Electric machines,
Libraries"
Saliency-Guided Color-to-Gray Conversion Using Region-Based Optimization,"Image decolorization is a fundamental problem for many real-world applications, including monochrome printing and photograph rendering. In this paper, we propose a new color-to-gray conversion method that is based on a region-based saliency model. First, we construct a parametric color-to-gray mapping function based on global color information as well as local contrast. Second, we propose a region-based saliency model that computes visual contrast among pixel regions. Third, we minimize the salience difference between the original color image and the output grayscale image in order to preserve contrast discrimination. To evaluate the performance of the proposed method in preserving contrast in complex scenarios, we have constructed a new decolorization data set with 22 images, each of which contains abundant colors and patterns. Extensive experimental evaluations on the existing and the new data sets show that the proposed method outperforms the state-of-the-art methods quantitatively and qualitatively.","Image color analysis,
Gray-scale,
Visualization,
Color,
Optimization,
Visual perception"
Parametric Frugal Sensing of Power Spectra for Moving Average Models,"Wideband spectrum sensing is a fundamental component of cognitive radio and other applications. A novel frugal sensing scheme was recently proposed as a means of crowdsourcing the task of spectrum sensing. Using a network of scattered low-end sensors transmitting randomly filtered power measurement bits to a fusion center, a non-parametric approach to spectral estimation was adopted to estimate the ambient power spectrum. Here, a parametric spectral estimation approach is considered within the context of frugal sensing. Assuming a Moving-Average (MA) representation for the signal of interest, the problem of estimating admissible MA parameters, and thus the MA power spectrum, from single bit quantized data is formulated. This turns out being a non-convex quadratically constrained quadratic program (QCQP), which is NP-Hard in general. Approximate solutions can be obtained via semi-definite relaxation (SDR) followed by randomization; but this rarely produces a feasible solution for this particular kind of QCQP. A new Sequential Parametric Convex Approximation (SPCA) method is proposed for this purpose, which can be initialized from an infeasible starting point, and yet still produce a feasible point for the QCQP, when one exists, with high probability. Simulations not only reveal the superior performance of the parametric techniques over the globally optimum solutions obtained from the non-parametric formulation, but also the better performance of the SPCA algorithm over the SDR technique.","Sensors,
Correlation,
Estimation,
Approximation methods,
Cognitive radio,
Power measurement,
Mathematical model"
3-D Resistive Memory Arrays: From Intrinsic Switching Behaviors to Optimization Guidelines,"3-D resistive switching random access memory (RRAM) is a promising candidate for high-density nonvolatile memory applications, as well as for monolithic 3-D integration interleaved with logic layers. In this paper, we develop a methodology for assessing and optimizing large-scale 3-D RRAM arrays. A systematic study on the intrinsic switching behaviors and optimization of 3-D RRAM arrays is performed, combining device measurements and 3-D array simulations. The dependence of programming voltage on array size, cell location and pulse parameters, statistical properties of operating 3-D RRAM arrays, and subthreshold disturbance on RRAM cells is experimentally investigated. Optimization guidelines for the performance and reliability of 3-D RRAM arrays from device level to architecture level are presented: 1) an optimized 1/n architecture for 100-kb 3-D RRAM arrays can improve write margin by 69.6% and reduce energy consumption by 75.6% compared with a conventional full-size array design; 2) a strategy of prioritizing storage location for reliable operation is presented; and 3) an optimal hopping barrier of oxygen ions is found to improve array immunity to disturbance.","Computer architecture,
Microprocessors,
Resistance,
Voltage measurement,
Programming,
Reliability,
Electrical resistance measurement"
Interactive Cosegmentation Using Global and Local Energy Optimization,"We propose a novel interactive cosegmentation method using global and local energy optimization. The global energy includes two terms: 1) the global scribbled energy and 2) the interimage energy. The first one utilizes the user scribbles to build the Gaussian mixture model and improve the cosegmentation performance. The second one is a global constraint, which attempts to match the histograms of common objects. To minimize the local energy, we apply the spline regression to learn the smoothness in a local neighborhood. This energy optimization can be converted into a constrained quadratic programming problem. To reduce the computational complexity, we propose an iterative optimization algorithm to decompose this optimization problem into several subproblems. The experimental results show that our method outperforms the state-of-the-art unsupervised cosegmentation and interactive cosegmentation methods on the iCoseg and MSRC benchmark data sets.","Image segmentation,
Optimization,
Histograms,
Minimization,
Splines (mathematics),
Image color analysis"
Median robust extended local binary pattern for texture classification,"Local Binary Patterns (LBP) are among the most computationally efficient amongst high-performance texture features. However, LBP is very sensitive to image noise and is unable to capture macrostructure information. To best address these disadvantages, in this paper we introduce a novel descriptor for texture classification, the Median Robust Extended Local Binary Pattern (MRELBP). In contrast to traditional LBP and many LBP variants, MRELBP compares local image medians instead of raw image intensities. We develop a multiscale LBP-type descriptor by efficiently comparing image medians over a novel sampling scheme, which can capture both microstructure and macrostructure. A comprehensive evaluation on benchmark datasets reveals MRELBP's remarkable performance (robust to gray scale variations, rotation changes and noise) relative to state-of-the-art algorithms, but nevertheless at a low computational cost, producing the best classification scores of 99.82%, 99.38% and 99.77% on three popular Outex test suites. Furthermore, MRELBP is also shown to be highly robust to image noise including Gaussian noise, Gaussian blur, Salt-and-Pepper noise and random pixel corruption.",
Dynamic Phasor Model-Based Synchrophasor Estimation Algorithm for M-Class PMU,"Phasor measurement units (PMUs) are taking an increasingly important role in power system dynamic security monitoring and control. However, traditional discrete Fourier transforms (DFTs) used by PMUs cannot obtain accurate phasor measurements during frequency excursion and transient events, being limited by its static phasor model. In this paper, a synchrophasor estimation algorithm for M-class PMUs based on the dynamic phasor model is proposed. In this algorithm, the dynamic phasor within an observation data window is approximated by the second-order Taylor expansion. The linear relationship between the second-order coefficients of the Taylor expansion and the errors caused by the DFT averaging effect is explored. Then, the linear relationship is used to compensate the raw measurement errors under a dynamic condition. Two digital filters are applied not only to eliminate the spectrum leakage caused by the dynamic inputs, but also to make the PMU immune to the out-of-band signals. The algorithm is investigated through simulation, laboratory experiments, and real data from the power system according to IEEE C37.118.1. The test results demonstrate that the proposed algorithm can meet the requirements of the standards.","Power system dynamics,
Discrete Fourier transforms,
Heuristic algorithms,
Phasor measurement units,
Measurement errors,
Frequency modulation"
Hybrid Constraints of Pure and Mixed Pixels for Soft-Then-Hard Super-Resolution Mapping With Multiple Shifted Images,"Multiple shifted images (MSIs) have been widely applied to many super-resolution mapping (SRM) approaches to improve the accuracy of fine-scale land-cover maps. Most SRM methods with MSIs involve two processes: subpixel sharpening and class allocation. Complementary information from the MSIs has been successfully adopted to produce soft attribute values of subpixels during the subpixel sharpening process. Such information, however, is not used in the second process of class allocation. In this paper, a new class-allocation algorithm, named “hybrid constraints of pure and mixed pixels” (HCPMP), is proposed to allocate land-cover classes to subpixels using MSIs. HCPMP first determines the classes of subpixels that overlap with the pure pixels of auxiliary images in MSIs, after which the remaining subpixels are classified using information derived from the mixed pixels of the base image in MSIs. An artificial image and two remote sensing images were used to evaluate the performance of the proposed HCPMP algorithm. The experimental results demonstrate that HCPMP successfully applied MSIs to produce SRM maps that are visually closer to the reference images and that have greater accuracy than five existing class-allocation algorithms. Especially, it can produce more accurate SRM maps for high-resolution land-cover classes than low-resolution cases. The algorithm takes slightly less runtime than class allocation using linear optimization techniques. Hence, HCPMP provides a valuable new solution for class allocation in SRM using auxiliary data from MSIs.","Resource management,
Accuracy,
Remote sensing,
Image resolution,
Uncertainty,
Earth,
DH-HEMTs"
Truthful online double auctions for dynamic mobile crowdsourcing,"Stimulating both service users and service providers is of paramount importance to mobile crowdsourcing. A few incentive mechanisms have been proposed, but all of them have focused only on one-sided interactions either among service users or among service providers. For the first time, to the best of our knowledge, we investigate the important two-sided online interactions among service users and service providers in mobile crowdsourcing. We model such interactions as online double auctions, explicitly taking the dynamic nature of both users and providers into account We propose a general framework for the design of truthful online double auctions for dynamic mobile crowdsourcing. The framework is expressive and can work with different price schedules. We propose price-ranked online double auctions with four price schedules to implement the framework, which are suitable for different scenarios. With theoretical analysis and extensive simulations we demonstrate that the proposed auctions are strategy-proof, individual rational, and ensure budget balance.","Conferences,
Computers"
Distance metric learning for RRT-based motion planning with constant-time inference,"The distance metric is a key component in RRT-based motion planning that deeply affects coverage of the state space, path quality and planning time. With the goal to speed up planning time, we introduce a learning approach to approximate the distance metric for RRT-based planners. By exploiting a novel steer function which solves the two-point boundary value problem for wheeled mobile robots, we train a simple nonlinear parametric model with constant-time inference that is shown to predict distances accurately in terms of regression and ranking performance. In an extensive analysis we compare our approach to an Euclidean distance baseline, consider four alternative regression models and study the impact of domain-specific feature expansion. The learning approach is shown to be faster in planning time by several factors at negligible loss of path quality.","Planning,
Euclidean distance,
Approximation methods,
Robots,
Computational modeling,
Vegetation"
OPoR: Enabling Proof of Retrievability in Cloud Computing with Resource-Constrained Devices,"Cloud computing moves the application software and databases to the centralized large data centers, where the management of the data and services may not be fully trustworthy. In this work, we study the problem of ensuring the integrity of data storage in cloud computing. To reduce the computational cost at user side during the integrity verification of their data, the notion of public verifiability has been proposed. However, the challenge is that the computational burden is too huge for the users with resource-constrained devices to compute the public authentication tags of file blocks. To tackle the challenge, we propose OPoR, a new cloud storage scheme involving a cloud storage server and a cloud audit server, where the latter is assumed to be semi-honest. In particular, we consider the task of allowing the cloud audit server, on behalf of the cloud users, to pre-process the data before uploading to the cloud storage server and later verifying the data integrity. OPoR outsources and offloads the heavy computation of the tag generation to the cloud audit server and eliminates the involvement of user in the auditing and in the pre-processing phases. Furthermore, we strengthen the proof of retrievability (PoR) model to support dynamic data operations, as well as ensure security against reset attacks launched by the cloud storage server in the upload phase.","Servers,
Cloud computing,
Memory,
Computational modeling,
Protocols,
Authentication"
Retargeting Semantically-Rich Photos,"Semantically-rich photos contain a rich variety of semantic objects (e.g., pedestrians and bicycles). Retargeting these photos is a challenging task since each semantic object has fixed geometric characteristics. Shrinking these objects simultaneously during retargeting is prone to distortion. In this paper, we propose to retarget semantically-rich photos by detecting photo semantics from image tags, which are predicted by a multi-label SVM. The key technique is a generative model termed latent stability discovery (LSD). It can robustly localize various semantic objects in a photo by making use of the predicted noisy image tags. Based on LSD, a feature fusion algorithm is proposed to detect salient regions at both the low-level and high-level. These salient regions are linked into a path sequentially to simulate human visual perception . Finally, we learn the prior distribution of such paths from aesthetically pleasing training photos. The prior enforces the path of a retargeted photo to be maximally similar to those from the training photos. In the experiment, we collect 217 1600 ×1200 photos, each containing over seven salient objects. Comprehensive user studies demonstrate the competitiveness of our method.","Semantics,
Visualization,
Noise measurement,
Adaptation models,
Feature extraction,
Computational modeling,
Distortion"
FastRAQ: A Fast Approach to Range-Aggregate Queries in Big Data Environments,"Range-aggregate queries are to apply a certain aggregate function on all tuples within given query ranges. Existing approaches to range-aggregate queries are insufficient to quickly provide accurate results in big data environments. In this paper, we propose FastRAQ-a fast approach to range-aggregate queries in big data environments. FastRAQ first divides big data into independent partitions with a balanced partitioning algorithm, and then generates a local estimation sketch for each partition. When a range-aggregate query request arrives, FastRAQ obtains the result directly by summarizing local estimates from all partitions. FastRAQ has O(1) time complexity for data updates and O(N/P×B) time complexity for range-aggregate queries, where N is the number of distinct tuples for all dimensions, P is the partition number, and B is the bucket number in the histogram. We implement the FastRAQ approach on the Linux platform, and evaluate its performance with about 10 billions data records. Experimental results demonstrate that FastRAQ provides range-aggregate query results within a time period two orders of magnitude lower than that of Hive, while the relative error is less than 3 percent within the given confidence interval.","Histograms,
Big data,
Partitioning algorithms,
Vectors,
Indexes,
Servers,
Aggregates"
Performance Evaluations of Quantum Key Distribution System Architectures,"Quantum key distribution (QKD) exploits the laws of quantum physics to generate shared secret cryptographic keys and can detect eavesdroppers during the key generation process. However, previous QKD research has focused more on theory than practice.","Cryptography,
Receivers,
Photonics,
Encoding,
Protocols,
Physics,
Quantum physics,
Performance evaluation"
How do developers react to API evolution? The Pharo ecosystem case,"Software engineering research now considers that no system is an island, but it is part of an ecosystem involving other systems, developers, users, hardware, ... When one system (e.g., a framework) evolves, its clients often need to adapt. Client developers might need to adapt to functionalities, client systems might need to be adapted to a new API, client users might need to adapt to a new User Interface. The consequences of such changes are yet unclear, what proportion of the ecosystem might be expected to react, how long might it take for a change to diffuse in the ecosystem, do all clients react in the same way? This paper reports on an exploratory study aimed at observing API evolution and its impact on a large-scale software ecosystem, Pharo, which has about 3,600 distinct systems, more than 2,800 contributors, and six years of evolution. We analyze 118 API changes and answer research questions regarding the magnitude, duration, extension, and consistency of such changes in the ecosystem. The results of this study help to characterize the impact of API evolution in large software ecosystems, and provide the basis to better understand how such impact can be alleviated.","Ecosystems,
Open source software,
Context,
History,
Computer science,
Association rules"
Learning Visualizations by Analogy: Promoting Visual Literacy through Visualization Morphing,"We propose the concept of teaching (and learning) unfamiliar visualizations by analogy, that is, demonstrating an unfamiliar visualization method by linking it to another more familiar one, where the in-betweens are designed to bridge the gap of these two visualizations and explain the difference in a gradual manner. As opposed to a textual description, our morphing explains an unfamiliar visualization through purely visual means. We demonstrate our idea by ways of four visualization pair examples: data table and parallel coordinates, scatterplot matrix and hyperbox, linear chart and spiral chart, and hierarchical pie chart and treemap. The analogy is commutative i.e. any member of the pair can be the unfamiliar visualization. A series of studies showed that this new paradigm can be an effective teaching tool. The participants could understand the unfamiliar visualization methods in all of the four pairs either fully or at least significantly better after they observed or interacted with the transitions from the familiar counterpart. The four examples suggest how helpful visualization pairings be identified and they will hopefully inspire other visualization morphings and associated transition strategies to be identified.","Data visualization,
Visualization,
Animation,
Education,
Joining processes,
Spirals,
Layout"
Genetic Algorithm-Based Classifiers Fusion for Multisensor Activity Recognition of Elderly People,"Activity recognition of an elderly person can be used to provide information and intelligent services to health care professionals, carers, elderly people, and their families so that the elderly people can remain at homes independently. This study investigates the use and contribution of wrist-worn multisensors for activity recognition. We found that accelerometers are the most important sensors and heart rate data can be used to boost classification of activities with diverse heart rates. We propose a genetic algorithm-based fusion weight selection (GAFW) approach which utilizes GA to find fusion weights. For all possible classifier combinations and fusion methods, the study shows that 98% of times GAFW can achieve equal or higher accuracy than the best classifier within the group.",
Straintronics-Based Random Access Memory as Universal Data Storage Devices,"Nanomagnetic and spin-based memories are distinguished for their high data endurance in comparison with their charge-based peers. However, they have drawbacks, such as high write energy and poor scalability due to high write current. In this paper, we apply the straintronics principle that seeks the combination of piezoelectricity and inverse magnetostriction (Villari effect), to design a proof-of-principle 2 Kb nonvolatile magnetic memory in 65 nm CMOS technology. Our simulation results show read-access and write-cycle energies as low as 49 and 143 fJ/b, respectively. At a nominal supply level of 1 V, reading can be performed as fast as 562 MHz. Write error rates <;10-7 and 10-15 can be obtained at 10 and 5 MHz, respectively. In addition to nonvolatility, ultralow energy per operation, and high performance, our STRs memory has a high storage density with a cell size as small as 0.2 μm2.","Magnetization,
Vectors,
Stress,
Random access memory,
Magnetostriction,
Anisotropic magnetoresistance,
Cobalt"
Person tracking and following with 2D laser scanners,"Having accurate knowledge of the positions of people around a robot provides rich, objective and quantitative data that can be highly useful for a wide range of tasks, including autonomous person following. The primary objective of this research is to promote the development of robust, repeatable and transferable software for robots that can automatically detect, track and follow people in their environment. The work is strongly motivated by the need for such functionality onboard an intelligent power wheelchair robot designed to assist people with mobility impairments. In this paper we propose a new algorithm for robust detection, tracking and following from laser data. We show that the approach is effective in various environments, both indoor and outdoor, and on different robot platforms (the intelligent power wheelchair and a Clearpath Husky). The method has been implemented in the Robot Operating System (ROS) framework and will be publicly released as a ROS package. We also describe and will release several datasets designed to promote the standardized evaluation of similar algorithms.","Lasers,
Tracking,
Legged locomotion,
Robot sensing systems"
Machine-Learning-Based Hotspot Detection Using Topological Classification and Critical Feature Extraction,"Because of the widening sub-wavelength lithography gap in advanced fabrication technology, lithography hotspot detection has become an essential task in design for manufacturability. Unlike current state-of-the-art works, which unite pattern matching and machine-learning engines, we fully exploit the strengths of machine learning using novel techniques. By combing topological classification and critical feature extraction, our hotspot detection framework achieves very high accuracy. Furthermore, to speed-up the evaluation, we verify only possible layout clips instead of full-layout scanning. We utilize feedback learning and present redundant clip removal to reduce the false alarm. Experimental results show that the proposed framework is very accurate and demonstrates a rapid training convergence. Moreover, our framework outperforms the 2012 CAD contest at International Conference on ComputerAided Design (ICCAD) winner on accuracy and false alarm.","Feature extraction,
Kernel,
Support vector machines,
Training,
Layout,
Accuracy,
Topology"
Enhancing the determination of aspect categories and their polarities in Arabic reviews using lexicon-based approaches,"Sentiment Analysis (SA) is the process of determining the sentiment of a text written in a natural language to be positive, negative or neutral. It is one of the most interesting subfields of natural language processing (NLP) and Web mining due to its diverse applications and the challenges associated with applying it on the massive amounts of textual data available online (especially, on social networks). Most of the current works on SA focus on the English language and work on the sentence-level or the document-level. This work focuses on the less studied version of SA, which is aspect-based SA (ABSA) for the Arabic language. Specifically, this work considers two ABSA tasks: aspect category determination and aspect category polarity determination, and makes use of the publicly available human annotated Arabic dataset (HAAD) along with its baseline experiments conducted by HAAD providers. In this work, several lexicon-based approaches are presented for the two tasks at hand and show that some of the presented approaches significantly outperforms the best known result on the given dataset.",
Parameter Identification of PMSMs Using Experimental Measurements and a PSO Algorithm,"This paper introduces a particle swarm optimization (PSO) algorithm that uses experimental measurements for the identification of the direct (
d
) and quadrature (
q
) stator inductances and the stator resistance of permanent-magnet synchronous machines (PMSMs). Strategies for the identification of stator resistance and flux linkage of permanent magnets are also presented. The developed PSO algorithm has the advantages of fast and stable convergence characteristics, and it is relatively easy to implement; moreover, neither voltage source inverters nor closed-loop control strategies are needed. In this paper, the experimental results obtained by PSO are compared with other ones obtained through a current decay test to demonstrate the effectiveness of the presented method. A 32-bit C2000 real-time microcontroller and a commercial surface-mounted PMSM have been used to carry out the experimental measurements.",
Optimum Power Control at Finite Blocklength,"This paper investigates the maximal channel coding rate achievable at a given blocklength n and error probability ϵ, when the codewords are subjected to a long-term (i.e., averaged-over-all-codeword) power constraint. The second-order term in the large-n expansion of the maximal channel coding rate is characterized both for additive white Gaussian noise (AWGN) channels and for quasi-static fading channels with perfect channel state information available at both the transmitter and the receiver. It is shown that in both the cases, the second-order term is proportional to (n-1 ln n)1/2. For the quasi-static fading case, this second-order term is achieved by truncated channel inversion, namely, by concatenating a dispersion-optimal code for an AWGN channel subject to a short-term power constraint, with a power controller that inverts the channel whenever the fading gain is above a certain threshold. Easy-to-evaluate approximations of the maximal channel coding rate are developed for both the AWGN and the quasi-static fading case.","Fading,
AWGN channels,
Probability distribution,
Channel coding,
Error probability,
Random variables,
Receivers"
"Unified scaling of polar codes: Error exponent, scaling exponent, moderate deviations, and error floors","Consider transmission of a polar code of block length N and rate R over a binary memoryless symmetric channel W with capacity I(W) and Bhattacharyya parameter Z(W) and let Pe be the error probability under successive cancellation decoding. Recall that in the error exponent regime, the channel W and R <; I(W) are fixed, while Pe scales roughly as 2-√(N). In the scaling exponent regime, the channel W and Pe are fixed, while the gap to capacity I(W) - R scales as N-1/μ, with 3.579 ≤ μ ≤ 5.702 for any W. We develop a unified framework to characterize the relationship between R, N, Pe, and W. First, we provide the tighter upper bound μ ≤ 4.714, valid for any W. Furthermore, when W is a binary erasure channel, we obtain an upper bound approaching very closely the value which was previously derived in a heuristic manner. Secondly, we consider a moderate deviations regime and we study how fast both the gap to capacity I(W) - R and the error probability Pe simultaneously go to 0 as N goes large. Thirdly, we prove that polar codes are not affected by error floors. To do so, we fix a polar code of block length N and rate R, we let the channel W vary, and we show that Pe scales roughly as Z(W)√(N).","Error probability,
Decoding,
Upper bound,
Eigenvalues and eigenfunctions,
Capacity planning,
Zinc,
Encoding"
Asymmetric Social Proximity Based Private Matching Protocols for Online Social Networks,"The explosive growth of Online Social Networks (OSNs) over the past few years has redefined the way people interact with existing friends and especially make new friends. Some works propose to let people become friends if they have similar profile attributes. However, profile matching involves an inherent privacy risk of exposing private profile information to strangers in the cyberspace. The existing solutions to the problem attempt to protect users' privacy by privately computing the intersection or intersection cardinality of the profile attribute sets of two users. These schemes have some limitations and can still reveal users' privacy. In this paper, we leverage community structures to redefine the OSN model and propose a realistic asymmetric social proximity measure between two users. Then, based on the proposed asymmetric social proximity, we design three private matching protocols, which provide different privacy levels and can protect users' privacy better than the previous works. We also analyze the computation and communication cost of these protocols. Finally, we validate our proposed asymmetric proximity measure using real social network data and conduct extensive simulations to evaluate the performance of the proposed protocols in terms of computation cost, communication cost, total running time, and energy consumption. The results show the efficacy of our proposed proximity measure and better performance of our protocols over the state-of-the-art protocols.","Protocols,
Communities,
Privacy,
Social network services,
Servers,
Encryption"
Stochastic Comparisons of Series and Parallel Systems With Generalized Exponential Components,"This paper examines the problem of the stochastic comparison of series and parallel systems with s-independent heterogeneous generalized exponential components. The results established here are developed in three directions. First, we consider a system with possibly different shape and scale parameters, and obtain some ordering results when its matrix of parameters changes to another matrix, in the certain mathematical sense. Next, by using the concept of vector majorization and related orders, we establish various ordering results for the comparisons of series and parallel systems, when their component's lifetimes have either the same shape parameters with possibly different scale parameters, or the same scale parameters with possibly different shape parameters. Finally, some of the known results on various stochastic orderings between parallel systems in the exponential case are extended to the case when the lifetimes of components follow the generalized exponential distributions. The results of this paper can be used in practical situations to replace components of series and parallel systems by new components, or to find various bounds for the important aging characteristics of these systems.",
The harsh rule of the goals: Data-driven performance indicators for football teams,"Sports analytics in general, and football (soccer in USA) analytics in particular, have evolved in recent years in an amazing way, thanks to automated or semi-automated sensing technologies that provide high-fidelity data streams extracted from every game. In this paper we propose a data-driven approach and show that there is a large potential to boost the understanding of football team performance. From observational data of football games we extract a set of pass-based performance indicators and summarize them in the H indicator. We observe a strong correlation among the proposed indicator and the success of a team, and therefore perform a simulation on the four major European championships (78 teams, almost 1500 games). The outcome of each game in the championship was replaced by a synthetic outcome (win, loss or draw) based on the performance indicators computed for each team. We found that the final rankings in the simulated championships are very close to the actual rankings in the real championships, and show that teams with high ranking error show extreme values of a defense/attack efficiency measure, the Pezzali score. Our results are surprising given the simplicity of the proposed indicators, suggesting that a complex systems' view on football data has the potential of revealing hidden patterns and behavior of superior quality.","Games,
Correlation,
Europe,
Cities and towns,
Electronic mail,
Data mining,
Computer science"
Reliable Physical Unclonable Functions Using Data Retention Voltage of SRAM Cells,"Physical unclonable functions (PUFs) are circuits that produce outputs determined by random physical variations from fabrication. The PUF studied in this paper utilizes the variation sensitivity of static random access memory (SRAM) data retention voltage (DRV), the minimum voltage at which each cell can retain state. Prior work shows that DRV can uniquely identify circuit instances with 28% greater success than SRAM power-up states that are used in PUFs [1]. However, DRV is highly sensitive to temperature, and until now this makes it unreliable and unsuitable for use in a PUF. In this paper, we enable DRV PUFs by proposing a DRV-based hash function that is insensitive to temperature. The new hash function, denoted DRV-based hashing (DH), is reliable across temperatures because it utilizes the temperature-insensitive ordering of DRVs across cells, instead of using the DRVs in absolute terms. To evaluate the security and performance of the DRV PUF, we use DRV measurements from commercially available SRAM chips, and use data from a novel DRV prediction algorithm. The prediction algorithm uses machine learning for fast and accurate simulation-free estimation of any cell's DRV, and the prediction error in comparison to circuit simulation has a standard deviation of 0.35 mV. We demonstrate the DRV PUF using two applications-secret key generation and identification. In secret key generation, we introduce a new circuit-level reliability knob as an alternative to error correcting codes. In the identification application, our approach is compared to prior work and shown to result in a smaller false-positive identification rate for any desired true-positive identification rate.","SRAM cells,
Transistors,
Integrated circuit modeling,
Reliability,
Temperature sensors,
Temperature measurement"
On Hybrid IR and AR Service Provisioning in Elastic Optical Networks,"This paper investigates hybrid immediate reservation (IR) and advance reservation (AR) service provisioning in elastic optical networks, with the objective to minimize IR/AR service conflicts. We design algorithms to coordinate service provisioning of IR and AR requests. Specifically, both proactive and reactive IR provisioning schemes are considered to minimize IR service failures. Our AR scheduling algorithm can coordinate AR service provisioning with various IR traffic patterns, balance spectrum utilization in both time and spectral domains, and reduce IR/AR service conflicts. Simulation results verify that our proposed IR + AR schemes can significantly reduce IR service failures as well as routing and spectrum allocation reconfigurations in IR service provisioning. Moreover, the results indicate that the proposed IR + AR schemes can achieve more performance gain from AR flexibility when compared with two existing benchmarks.","Indexes,
Bandwidth,
Optical fiber networks,
Interrupters,
Algorithm design and analysis,
Spectral analysis,
Routing"
Stochastic Cost-Profit Tradeoff Model for Locating an Automotive Service Enterprise,"Facility location allocation (FLA) is considered as the problem of finding optimally a facility's location with the maximum customer satisfaction, the maximum profit of investors of the facility, and the minimum transportation cost of its oriented-customers. In practice, some factors of the FLA problem, i.e., customer demands, allocations, even locations of customers and facilities, are usually changing, and thus the problem features with uncertainty. To account for this uncertainty, some researchers have addressed the stochastic profit and cost issues of FLA. However, a decision-maker hopes to obtain the specific profit of investors of building facility and meanwhile to minimize the cost of target customers. To handle this issue via a more practical manner, it is essential to address the cost-profit tradeoff issue of FLA. Moreover, some region constraints can greatly influence FLA. By taking the vehicle inspection station as a typical automotive service enterprise example, this work presents new stochastic cost-profit tradeoff FLA models with region constraints. A hybrid algorithm integrating stochastic simulation and Genetic Algorithms (GA) is proposed to solve the proposed models. Some numerical examples are given to illustrate the proposed models and the effectiveness of the proposed algorithm.","Vehicles,
Inspection,
Stochastic processes,
Automotive engineering,
Biological cells,
Numerical models"
Using Benchmarks for Radiation Testing of Microprocessors and FPGAs,"Performance benchmarks have been used over the years to compare different systems. These benchmarks can be useful for researchers trying to determine how changes to the technology, architecture, or compiler affect the system's performance. No such standard exists for systems deployed into high radiation environments, making it difficult to assess whether changes in the fabrication process, circuitry, architecture, or software affect reliability or radiation sensitivity. In this paper, we propose a benchmark suite for high-reliability systems that is designed for field-programmable gate arrays and microprocessors. We describe the development process and report neutron test data for the hardware and software benchmarks.",
Network Output Controllability-Based Method for Drug Target Identification,"Biomolecules do not perform their functions alone, but interactively with one another to form so called biomolecular networks. It is well known that a complex disease stems from the malfunctions of corresponding biomolecular networks. Therefore, one of important tasks is to identify drug targets from biomolecular networks. In this study, the drug target identification is formulated as a problem of finding steering nodes in biomolecular networks while the concept of network output controllability is applied to the problem of drug target identification. By applying control signals to these steering nodes, the biomolecular networks are expected to be transited from one state to another. A graph-theoretic algorithm has been proposed to find a minimum set of steering nodes in biomolecular networks which can be a potential set of drug targets. Application results of the method to real biomolecular networks show that identified potential drug targets are in agreement with existing research results. This indicates that the method can generate testable predictions and provide insights into experimental design of drug discovery.","Drugs,
Molecular biophysics,
Controllability,
Diseases,
Bipartite graph,
Biological system modeling,
Biochemistry"
Achieving authorized and ranked multi-keyword search over encrypted cloud data,"In cloud computing, it is important to protect user data. Thus, data owners usually encrypt their data before outsourcing them to the cloud server for security and privacy concerns. At the same time, very often users need to find data for specific keywords of interest to them. This motivates the research on the searchable encryption technique, which allows the search user to search over the encrypted data. Many mechanisms have been proposed, and are mainly focusing on the symmetric searchable encryption (SSE) technique. However, they do not consider the search authorization problem that requires the cloud server only to return the search results to authorized users. In this paper, we propose an authorized and ranked multi-keyword search scheme (ARMS) over encrypted cloud data by leveraging the ciphertext policy attribute-based encryption (CP-ABE) and SSE techniques. Security analysis demonstrates that the proposed ARMS scheme can achieve confidentiality of documents, trapdoor unlinkability and collusion resistance. Extensive experiments show that the ARMS is more superior and efficient than existing approaches in terms of functionalities and computational overhead.","Servers,
Sun,
Indexes,
Authorization,
Encryption"
Energy modeling of system settings: A crowdsourced approach,"The question “Where has my battery life gone?” remains a common source of frustration for many smartphone users. With the increased complexity of smartphone applications, and the increasing number of system settings affecting them, understanding and optimizing battery use has become a difficult chore. The present paper develops a novel approach for constructing energy models from crowdsourced measurements. In contrast to previous approaches, which have focused on the effect of a specific sensor, system setting or application, our approach can simultaneously capture relationships between multiple factors, and provide a unified view of the energy state of the mobile device. We demonstrate the validity of using crowdsourced measurements for constructing battery models through a combination of large-scale analysis of a dataset containing battery discharge and system state measurements and hardware power measurements. The results indicate that the models captured by our approach are both in line with previous studies on battery consumption and empirical measurements, providing a cost-effective way to construct energy models during normal operations of the device. The analysis also provides several new insights about battery consumption. For example, our analysis shows the energy use of high CPU activity with automatic screen brightness is actually higher (resulting in around 9 minutes shorter battery lifetime on average) than with a medium CPU load and manual screen brightness; a Wi-Fi signal strength drop of one bar can result in a battery life loss of over 13%; and a smartphone sitting in the sun can experience over 50% worse battery life than one indoors in cool conditions.",
Hierarchical design of robust and low data dependent FinFET based SRAM array,"This paper proposes a new FinFET based SRAM cell and a cache architecture that efficiently exploits our SRAM cell for low-power and robust memory design. Our cache architecture uses invert coding scheme to encode the input data of a word line by taking into account the data composition. Based on the new data distribution, we propose two new asymmetric SRAM cells (AABG and ADWL) utilizing adaptive back-gate feedback that significantly improve cache power consumption and reliability, and provide higher performance in state-of-the-art SRAM caches. The results show that the AABG cell is a good candidate for robust and low power caches, while the ADWL-based SRAM cache is low power and high performance cache. The simulations are performed on SPEC CPU 2006 benchmarks with GEM5 and HSPICE in 20nm independent gate FinFET technology. The results show that the proposed AABG (ADWL)-based cache improves static and dynamic power by at least 13% and 35% (17% and 12%) respectively, compared to other state-of-the-art cells, while guaranteeing 2.7X (1.98X) lower NBTI degradation with less than 1.5% area overhead.","Computer architecture,
Microprocessors,
SRAM cells,
Logic gates,
FinFETs"
Are Slice-Based Cohesion Metrics Actually Useful in Effort-Aware Post-Release Fault-Proneness Prediction? An Empirical Study,"Background. Slice-based cohesion metrics leverage program slices with respect to the output variables of a module to quantify the strength of functional relatedness of the elements within the module. Although slice-based cohesion metrics have been proposed for many years, few empirical studies have been conducted to examine their actual usefulness in predicting fault-proneness. Objective. We aim to provide an in-depth understanding of the ability of slice-based cohesion metrics in effort-aware post-release fault-proneness prediction, i.e. their effectiveness in helping practitioners find post-release faults when taking into account the effort needed to test or inspect the code. Method. We use the most commonly used code and process metrics, including size, structural complexity, Halstead's software science, and code churn metrics, as the baseline metrics. First, we employ principal component analysis to analyze the relationships between slice-based cohesion metrics and the baseline metrics. Then, we use univariate prediction models to investigate the correlations between slice-based cohesion metrics and post-release fault-proneness. Finally, we build multivariate prediction models to examine the effectiveness of slice-based cohesion metrics in effort-aware post-release fault-proneness prediction when used alone or used together with the baseline code and process metrics. Results. Based on open-source software systems, our results show that: 1) slice-based cohesion metrics are not redundant with respect to the baseline code and process metrics; 2) most slice-based cohesion metrics are significantly negatively related to post-release fault-proneness; 3) slice-based cohesion metrics in general do not outperform the baseline metrics when predicting post-release fault-proneness; and 4) when used with the baseline metrics together, however, slice-based cohesion metrics can produce a statistically significant and practically important improvement of the effectiveness in effort-aware post-release fault-proneness prediction. Conclusion. Slice-based cohesion metrics are complementary to the most commonly used code and process metrics and are of practical value in the context of effort-aware post-release fault-proneness prediction.",
Combining Artificial Bee Colony With Ordinal Optimization for Stochastic Economic Lot Scheduling Problem,"The stochastic economic lot scheduling problem (SELSP) considers the make-to-stock production of multiple standardized products on a single machine with limited capacity and set-up costs under random demands, random set-up times, and random production times. The SELSP is an NP-hard inventory problem. Current solutions for the SELSP can be classified as analytic or heuristic. In both approaches, however, the computation time needed to obtain an optimal solution is still unsatisfactory. In this paper, the SELSP is first formulated as a fixed-sequence base-stock (FSBS) system with quantity-limited lot-sizing policy. An algorithm combining artificial bee colony (ABC) approach and ordinal optimization (OO) theory, abbreviated as ABCOO, is then proposed to find a good enough base-stock level of the FSBS system using reasonable computation time. The proposed algorithm combines the advantage of multidirectional search in ABC with the advantage of goal softening in OO. Finally, the ABCOO algorithm is used to solve an SELSP involving 12 products and three queuing models. Test results obtained by the ABCOO algorithm are compared with four lot-sizing policies and three meta-heuristic methods. The base-stock level obtained by the ABCOO algorithm is excellent in terms of solution quality and computational efficiency. Furthermore, a time series forecasting technique is used to predict the variant demand rates needed to resolve time-lag problems of the ABCOO algorithm. Tests of the forecasting technique confirm that it considerably improves the performance and enables the proposed algorithm real-time applications.",
Implementation of a New RFID Authentication Protocol for EPC Gen2 Standard,"Researchers have revealed that electronic product code (EPC) Gen2 standard, which is designed for passive ultrahigh-frequency radio frequency identification has various security problems. To solve these problems, some authors have proposed many lightweight protocols to enhance security. However, it is still unclear about the feasibility of such protocols, since the hardware implementation of such protocols has long been neglected. Besides, it is extremely challengeable to achieve the balance among security, low power, and low cost. In this paper, a new lightweight mutual authentication protocol based on variable linear feedback shift registers is proposed, and its security analysis is described. An ASIC implementation of the new protocol compliant with the EPC Gen2 standard is presented as well. Several low-power techniques are used to obtain the goal of low-power consumption. The implementation result shows that the area of the baseband is 0.16 mm2 and power consumption is 5.5 μW. As far as we know, this is the first ASIC implementation of a lightweight protocol compliant to EPC Gen2 standard. We believe that this design will bring a novel insight to future implementations for EPC Gen2v2 standard, which is ratified recently.",
Efficient Attribute-Based Comparable Data Access Control,"With the proliferation of mobile devices in recent years, there is a growing concern regarding secure data storage, secure computation, and fine-grained access control in data sharing for these resource-constrained devices in a cloud computing environment. In this work, we propose a new efficient framework named Constant-size Ciphertext Policy Comparative Attribute-Based Encryption (CCP-CABE) with the support of negative attributes and wildcards. It embeds the comparable attribute ranges of all the attributes into the user's key, and incorporates the attribute constraints of all the attributes into one piece of ciphertext during the encryption process to enforce flexible access control policies with various range relationships. Accordingly, CCP-CABE achieves the efficiency because it generates constant-size keys and ciphertext regardless of the number of involved attributes, and it also keeps the computation cost constant on lightweight mobile devices. We further discuss how to extend CCP-CABE to fit a scenario with multiple attribute domains, such that the decryption proceeds from the least privileged attribute domain to the most privileged one to help protect the privacy of the access policy. We provide security analysis and performance evaluation to demonstrate their efficiency at the end.","Encryption,
Access control,
Medical services,
Mobile handsets,
Generators"
Uniplanar Differentially Driven Ultrawideband Polarization Diversity Antenna With Band-Notched Characteristics,"A uniplanar ultrawideband (UWB) polarization diversity differential antenna with band-notched characteristics is presented in this letter for the first time. The antenna employs octagonal-shaped slot and two pairs of differentially fed monopoles being orthogonal to each other to achieve polarization diversity performance over the UWB. To effectively notch the 5.5-GHz WLAN band, the arc-shaped slots are inserted in the monopoles. As a result, the proposed antenna can achieve a wide impedance bandwidth of 143% (3-11 GHz) for the differential reflection coefficient less than -10 dB along with a notch band from 5 to 6.1 GHz. High differential port-to-port isolation of better than 40 dB and low cross polarization are also obtained by adopting a differential feeding mechanism. A prototype has been fabricated and tested. Results show that the antenna is very suitable for the applications in UWB wireless communication systems.","Ultra wideband antennas,
Antenna measurements,
Ports (Computers),
Scattering parameters,
Dipole antennas,
Slot antennas"
Deep learning and the information bottleneck principle,"Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.","Distortion,
Complexity theory,
Mutual information,
Bifurcation,
Computer architecture,
Feature extraction,
Training"
A socially optimal resource and revenue sharing mechanism in cloud federations,"A federation of cloud providers (CPs) consists of a set of self-interested CPs that cooperate in order to provide virtual machine (VM) resources requested by users. The CPs by virtue of being part of a federation can make some profit by selling their unused VM capacity. This paper presents an efficient mechanism of resource and revenue sharing in a cloud federation that motivates the CPs to cooperate. The proposed mechanism models the interactions among the CPs in a federation as a coalition game. In contrast to existing approaches, the game model aims at maximizing the social welfare or total profit of the CPs in a federation to promote their long-term individual profit. In addition, we present a comprehensive analysis of the related costs and revenue associated with the various decisions of the CPs related to their joining in a federation. Various simulations were carried out to validate and verify the effectiveness of the proposed cooperative capacity sharing mechanism. Simulation results demonstrated that the proposed mechanism can satisfy the fairness and stability properties, maximize the social welfare the CPs in a federation and achieve cost effective resource sharing.","Yttrium,
TV,
Games,
Manganese"
Cluster-Based Epidemic Control through Smartphone-Based Body Area Networks,"Increasing population density, closer social contact and interactions make epidemic control difficult. Traditional offline epidemic control methods (e.g., using medical survey or medical records) or model-based approach are not effective due to its inability to gather health data and social contact information simultaneously or impractical statistical assumption about the dynamics of social contact networks, respectively. In addition, it is challenging to find optimal sets of people to be quarantined to contain the spread of epidemics for large populations due to high computational complexity. Unlike these approaches, in this paper, a novel cluster-based epidemic control scheme is proposed based on Smartphone-based body area networks. The proposed scheme divides the populations into multiple clusters based on their physical location and social contact information. The proposed control schemes are applied within the cluster or between clusters. Further, we develop a computational efficient approach called UGP to enable an effective clusterbased quarantine strategy using graph theory for large scale networks (i.e., populations). The effectiveness of the proposed methods is demonstrated through both simulations and experiments on real social contact networks.",
Fashion Parsing With Video Context,"In this paper, we propose a novel semi- supervised learning strategy to address human parsing. Existing human parsing datasets are relatively small due to the required tedious human labeling. We present a general, affordable and scalable solution, which harnesses the rich contexts in those easily available web videos to boost any existing human parser. First, we crawl a large number of unlabeled videos from the web. Then for each video, the cross-frame contexts are utilized for human pose co- estimation , and then video co-parsing to obtain satisfactory human parsing results for all frames. More specifically, SIFT flow and super-pixel matching are used to build correspondences across different frames, and these correspondences then contextualize the pose estimation and human parsing in individual frames. Finally these parsed video frames are used as the reference corpus for the non-parametric human parsing component of the whole solution. To further improve the accuracy of video co-parsing, we propose an active learning method to incorporate human guidance, where the labelers are required to assess the accuracies of the pose estimation results of certain selected video frames. Then we take reliable frames as the seed frames to guide the video pose co-estimation. Our human parsing framework can then easily incorporate the human feedback to train a better fashion parser. Extensive experiments on two benchmark fashion datasets as well as a newly collected challenging Fashion Icon dataset well demonstrate the encouraging performance gain from our general pipeline for human parsing.",
Robust Subspace Clustering With Complex Noise,"Subspace clustering has important and wide applications in computer vision and pattern recognition. It is a challenging task to learn low-dimensional subspace structures due to complex noise existing in high-dimensional data. Complex noise has much more complex statistical structures, and is neither Gaussian nor Laplacian noise. Recent subspace clustering methods usually assume a sparse representation of the errors incurred by noise and correct these errors iteratively. However, large corruptions incurred by complex noise cannot be well addressed by these methods. A novel optimization model for robust subspace clustering is proposed in this paper. Its objective function mainly includes two parts. The first part aims to achieve a sparse representation of each high-dimensional data point with other data points. The second part aims to maximize the correntropy between a given data point and its low-dimensional representation with other points. Correntropy is a robust measure so that the influence of large corruptions on subspace clustering can be greatly suppressed. An extension of pairwise link constraints is also proposed as prior information to deal with complex noise. Half-quadratic minimization is provided as an efficient solution to the proposed robust subspace clustering formulations. Experimental results on three commonly used data sets show that our method outperforms state-of-the-art subspace clustering methods.","Robustness,
Noise,
Clustering methods,
Optimization,
Minimization,
Sparse matrices,
Computer vision"
Privacy and Quality Preserving Multimedia Data Aggregation for Participatory Sensing Systems,"With the popularity of mobile wireless devices equipped with various kinds of sensing abilities, a new service paradigm named participatory sensing has emerged to provide users with brand new life experience. However, the wide application of participatory sensing has its own challenges, among which privacy and multimedia data quality preservations are two critical problems. Unfortunately, none of the existing work has fully solved the problem of privacy and quality preserving participatory sensing with multimedia data. In this paper, we propose SLICER, which is the first k-anonymous privacy preserving scheme for participatory sensing with multimedia data. SLICER integrates a data coding technique and message transfer strategies, to achieve strong protection of participants' privacy, while maintaining high data quality. Specifically, we study two kinds of data transfer strategies, namely transfer on meet up (TMU) and minimal cost transfer (MCT). For MCT, we propose two different but complimentary algorithms, including an approximation algorithm and a heuristic algorithm, subject to different strengths of the requirement. Furthermore, we have implemented SLICER and evaluated its performance using publicly released taxi traces. Our evaluation results show that SLICER achieves high data quality, with low computation and communication overhead.",
A New Biocryptosystem-Oriented Security Analysis Framework and Implementation of Multibiometric Cryptosystems Based on Decision Level Fusion,"Biometric cryptosystems provide an innovative solution for cryptographic key generation, encryption as well as biometric template protection. Besides high authentication accuracy, a good biometric cryptosystem is expected to protect biometric templates effectively, which requires that helper data does not reveal significant information about the templates. Previous works predominantly follow an appropriate entropy definition to measure the security of biometric cryptosystems. In this paper, we point out limitations of entropy-based security analysis and propose a new security analysis framework that combines information-theoretic approach with computational security. In addition, we construct a fingerprint-based multibiometric cryptosystem (MBC) using decision level fusion. Hash functions are employed in our construction to further protect each single biometric trait. The experimental results and security analysis demonstrate that the proposed MBC provides stronger security and better authentication accuracy compared with a cryptosystem based on single biometric.",
Self-Organizing Resource Management Framework in OFDMA Femtocells,"Next generation wireless networks (i.e., WiMAX, LTE) provide higher bandwidth and spectrum efficiency leveraging smaller (femto) cells with orthogonal frequency division multiple access (OFDMA). The uncoordinated, dense deployments of femtocells however, pose several unique challenges relating to interference and resource management in OFDMA femtocell networks. Towards addressing these challenges, we propose RADION, a distributed resource management framework that effectively manages interference across femtocells. RADION's core building blocks enable femtocells to opportunistically determine the available resources in a completely distributed and efficient manner. Further, RADION's modular nature paves the way for different resource management solutions to be incorporated in the framework. We implement RADION on a real WiMAX femtocell testbed deployed in a typical indoor setting. Two distributed solutions are enabled through RADION and their performance is studied to highlight their quick self-organization into efficient resource allocations.","Femtocells,
Interference,
Resource management,
Throughput,
OFDM,
WiMAX,
Mobile computing"
Neighborhood Filtering Strategies for Overlay Construction in P2P-TV Systems: Design and Experimental Comparison,"Peer-to-peer live-streaming (P2P-TV) systems' goal is disseminating real-time video content using peer-to-peer technology. Their performance is driven by the overlay topology, i.e., the virtual topology that peers use to exchange video chunks. Several proposals have been made in the past to optimize it, yet few experimental studies have corroborated results. The aim of this paper is to provide a comprehensive experimental comparison based on PeerStreamer in order to benchmark different strategies for the construction and maintenance of the overlay topology in P2P-TV systems. We present only experimental results in which fully distributed strategies are evaluated in both controlled experiments and the Internet using thousands of peers. Results confirm that the topological properties of the overlay have a deep impact on both user quality of experience and network load. Strategies based solely on random peer selection are greatly outperformed by smart yet simple and actually implementable strategies. The most performing strategy we devise guarantees to deliver almost all chunks to all peers with a playout delay as low as 6 s even when system load approaches 1, and in almost adversarial network scenarios. PeerStreamer is open-source to make results reproducible and allow further research by the community.","Topology,
Measurement,
Streaming media,
Bandwidth,
Peer-to-peer computing,
Benchmark testing,
Network topology"
Multi-Layer and Recursive Neural Networks for Metagenomic Classification,"Recent advances in machine learning, specifically in deep learning with neural networks, has made a profound impact on fields such as natural language processing, image classification, and language modeling; however, feasibility and potential benefits of the approaches to metagenomic data analysis has been largely under-explored. Deep learning exploits many layers of learning nonlinear feature representations, typically in an unsupervised fashion, and recent results have shown outstanding generalization performance on previously unseen data. Furthermore, some deep learning methods can also represent the structure in a data set. Consequently, deep learning and neural networks may prove to be an appropriate approach for metagenomic data. To determine whether such approaches are indeed appropriate for metagenomics, we experiment with two deep learning methods: i) a deep belief network, and ii) a recursive neural network, the latter of which provides a tree representing the structure of the data. We compare these approaches to the standard multi-layer perceptron, which has been well-established in the machine learning community as a powerful prediction algorithm, though its presence is largely missing in metagenomics literature. We find that traditional neural networks can be quite powerful classifiers on metagenomic data compared to baseline methods, such as random forests. On the other hand, while the deep learning approaches did not result in improvements to the classification accuracy, they do provide the ability to learn hierarchical representations of a data set that standard classification methods do not allow. Our goal in this effort is not to determine the best algorithm in terms accuracy-as that depends on the specific application-but rather to highlight the benefits and drawbacks of each of the approach we discuss and provide insight on how they can be improved for predictive metagenomic analysis.","Neural networks,
Machine learning,
Feature extraction,
Nanobioscience,
Training,
Vegetation,
Organisms"
Big data analytics in power distribution systems,"Penetration of advanced sensor systems such as advanced metering infrastructure (AMI), high-frequency overhead and underground current and voltage sensors have been increasing significantly in power distribution systems over the past few years. According to U.S. energy information administration (EIA), the aggregated AMI installation experienced a 17 times increase from 2007 to 2012. The AMI usually collects electricity usage data every 15 minute, instead of once a month. This is a 3,000 fold increase in the amount of data utilities would have processed in the past. It is estimated that the electricity usage data collected through AMI in the U.S. amount to well above 100 terabytes in 2012. To unleash full value of the complex data sets, innovative big data algorithms need to be developed to transform the way we operate and plan for the distribution system. This paper not only proposes promising applications but also provides an in-depth discussion of technical and regulatory challenges and risks of big data analytics in power distribution systems. In addition, a flexible system architecture design is proposed to handle heterogeneous big data analysis workloads.","Big data,
Power distribution,
Planning,
Distributed databases,
State estimation,
Industries,
Data privacy"
Wearable Sensor-Based Behavioral Anomaly Detection in Smart Assisted Living Systems,"Detecting behavioral anomalies in human daily life is important to developing smart assisted-living systems for elderly care. Based on data collected from wearable motion sensors and the associated locational context, this paper presents a coherent anomaly detection framework to effectively detect different behavioral anomalies in human daily life. Four types of anomalies, including spatial anomaly, timing anomaly, duration anomaly, and sequence anomaly, are detected using a probabilistic theoretical framework. This framework is based on complex activity recognition using dynamic Bayesian network modeling. The maximum-likelihood estimation algorithm and Laplace smoothing are used in learning the parameters in the anomaly detection model. We conducted experimental evaluation in a mock apartment environment, and the results verified the effectiveness of the proposed framework. We expect that this behavioral anomaly detection system can be integrated into future smart homes for elderly care.",
Assessment and Classification of Early-Stage Multiple Sclerosis With Inertial Sensors: Comparison Against Clinical Measures of Disease State,"A cross-sectional study on patients with early-stage multiple sclerosis (MS) was conducted to examine the reliability of manual and automatic mobility measures derived from shank-mounted inertial sensors during the Timed Up and Go (TUG) test, compared to control subjects. Furthermore, we aimed to determine if disease status [as measured by the Multiple Sclerosis Impact Scale (MSIS-20) and the Expanded Disability Status Score (EDSS)] can be explained by measurements obtained using inertial sensors. We also aimed to determine if patients with early-stage MS could be automatically distinguished from healthy controls subjects, using inertial parameters recorded during the TUG test. The mobility of 38 patients (aged 25-65 years, 14 M, 24 F), diagnosed with relapsing-remitting MS and 33 healthy controls (14 M, 19 F, age 50-65), was assessed using the TUG test, while patients wore inertial sensors on each shank. Reliability analysis showed that 36 of 53 mobility parameters obtained during the TUG showed excellent intrasession reliability, while nine of 53 showed moderate reliability. This compared favorably with the reliability of the mobility parameters in healthy controls. Exploratory regression models of the EDSS and MSIS-20 scales were derived, using mobility parameters and an elastic net procedure in order to determine which mobility parameters influence disease state. A cross-validated elastic net regularized regression model for MSIS-20 yielded a mean square error (MSE) of 1.1 with 10 degrees of freedom (DoF). Similarly, an elastic net regularized regression model for EDSS yielded a cross-validated MSE of 1.3 with 10 DoF. Classification results show that the mobility parameters of participants with early-stage MS could be distinguished from controls with 96.90% accuracy. Results suggest that mobility parameters derived from MS patients while completing the TUG test are reliable, are associated with disease state in MS, and may have utility in screening for early-stage MS.","Sensors,
Reliability,
Multiple sclerosis,
Biomedical measurement,
Data models,
Informatics"
FinFET Evolution Toward Stacked-Nanowire FET for CMOS Technology Scaling,"The performance of an evolutionary FinFET design (iFinFET) is benchmarked against that of the conventional bulk FinFET and stacked-nanowire gate-all-around (GAA) FET, through3-D device simulations, for both n-channel and p-channel transistors. The results show that the iFinFET provides for improved electrostatic integrity relative to the FinFET, but with substantially less gate capacitance penalty relative to the GAA FET. Thus, iFinFET technology offers a technological pathway for continued transistor scaling with performance improvement, for future low-power system-on-chip applications.","FinFETs,
Nanowires,
System-on-chip,
CMOS technology"
Wavelet Transform With Histogram-Based Threshold Estimation for Online Partial Discharge Signal Denoising,"Online condition assessment of the power system devices and apparatus is considered vital for robust operation, where partial discharge (PD) detection is employed as a diagnosis tool. PD measurements, however, are corrupted with different types of noises such as white noise, random noise, and discrete spectral interferences. Hence, the denoising of such corrupted PD signals remains a challenging problem in PD signal detection and classification. The challenge lies in removing these noises from the online PD signal measurements effectively, while retaining its discriminant features and characteristics. In this paper, wavelet-based denoising with a new histogram-based threshold function and selection rule is proposed. The proposed threshold estimation technique obtains two different threshold values for each wavelet sub-band and uses a prodigious thresholding function that conserves the original signal energy. Moreover, two signal-to-noise ratio (SNR) estimation techniques are derived to fit with actual PD signals corrupted with real noise. The proposed technique is applied on different acoustic and current measured PD signals to examine its performance under different noisy environments. The simulation results confirm the merits of the proposed denoising technique compared with other existing wavelet-based techniques by measuring four evaluation metrics: 1) SNR; 2) cross-correlation coefficient; 3) mean square error; and 4) reduction in noise level.","Partial discharges,
Noise reduction,
Wavelet transforms,
White noise,
Signal to noise ratio,
Interference suppression"
Improving Link Ranking Quality by Quasi-Common Neighbourhood,"Most of the best performing link prediction ranking measures evaluate the common neighbourhood of a pair of nodes in a network, in order to assess the likelihood of a new link. On the other hand, the same zero rank value is given to node pairs with no common neighbourhood, which usually are a large number of potentially new links, thus resulting in very low quality overall link ranking in terms of average edit distance to the optimal rank. In this paper we introduce a general technique for improving the quality of the ranking of common neighbours-based measures. The proposed method iteratively applies any given ranking measure to the quasi-common neighbours of the node pair. Experiments held on widely accepted datasets show that QCNAA, a quasi-common neighbourhood measure derived from the well know Adamic-Adar (AA), generates rankings which generally improve the ranking quality, while maintaining the prediction capability of the original AA measure.",
Localization on OpenStreetMap data using a 3D laser scanner,"To determine the pose of a vehicle is a fundamental problem in mobile robotics. Most approaches relate the current sensor observations to a map generated with previously acquired data of the same system or by another system with a similar sensor setup. Unfortunately, previously acquired data is not always available. In outdoor settings, GPS is a very useful tool to determine a global estimate of the vehicles pose. Unfortunately, GPS tends to be unreliable in situations in which a clear view to the sky is restricted. Yet, one can make use of publicly available map material as prior information. In this paper, we describe an approach to localize a robot equipped with a 3D range scanner with respect to a road network created from OpenStreetMap data. To successfully localize a mobile robot we propose a road classification scheme for 3D range data together with a novel sensor model, which relates the classification results to a road network. Compared to other approaches, our system does not require the robot to actually travel on the road network. We evaluate our approach in extensive experiments on simulated and real data and compare favorably to two state-of-the-art methods on those data.","Roads,
Robot sensing systems,
Mobile robots,
Three-dimensional displays,
Standards,
Global Positioning System"
Brain Informatics-Based Big Data and the Wisdom Web of Things,"The authors summarize the main aspects of brain informatics based big data interacting in the social-cyber-physical space of the Wisdom Web of Things (W2T). In particular, they focus on how to realize human-level collective intelligence as a big data sharing mind--a harmonized collectivity of consciousness on the W2T that uses brain-inspired intelligent technologies to provide wisdom services. Finally, the authors propose five guiding principles to deeper understanding the nature of the vigorous interaction and interdependence of brain-body-environment.","Big data,
Electroencephalography,
Biomedical monitoring,
Internet of things,
Visualization,
Magnetic resonance imaging,
Brain modeling"
Errors and Power When Communicating With Spins,"We consider a network composed of a finite set of communicating nodes that send individual particles to each other, and each particle can carry binary information. Though our main motivation is related to communications in nanonetworks with electrons that carry magnetic spin as the bipolar information, one can also imagine that the particles may be molecules that use chirality to convey information. Since it is difficult for a particle to carry an identifier that conveys the identity of the source or destination, each node receives particles whose source cannot be ascertained since physical imperfections may result in particles being directed to the wrong destination in a manner that interferes with the correctly directed particles, and particles that should arrive at a node may be received by some other node. In addition, noise may randomly switch the polarity of particles, and in the case of magnetic spin, we can also have the effect of entanglement. We estimate the error probability in such a multipoint network as a function of the rate of flow of particles, and the power consumption per communicating pair of nodes. We then design a bipolar detector and show that it can significantly eliminate the effect of errors.",
Sparse Representation Based on Set-to-Set Distance for Hyperspectral Image Classification,"Sparse representation-based classification model has been widely applied into hyperspectral image (HSI) classification. Its mechanism is based on the assumption that the nonzero coefficients in the sparse representation mainly lie in the correct class-dependent low-dimensional subspace. However, the high similarity of pixels between some different classes exists in the HSI, which makes the classification process very unstable. In this paper, we propose a sparse representation based on the set-to-set distance (SRSTSD) for HSI classification. Through utilizing the set-to-set distance, the spatial information is incorporated into the sparse representation-based model. Moreover, to further exploit the spatial structure of the pixel, we also propose a patch-based SRSTSD (PSRSTSD) model. Experimental results demonstrate that our proposed methods can achieve excellent classification performance.","Training,
Linear programming,
Mathematical model,
Joints,
Sparse matrices,
Hyperspectral imaging,
Biological system modeling"
Multitask TSK Fuzzy System Modeling by Mining Intertask Common Hidden Structure,"The classical fuzzy system modeling methods implicitly assume data generated from a single task, which is essentially not in accordance with many practical scenarios where data can be acquired from the perspective of multiple tasks. Although one can build an individual fuzzy system model for each task, the result indeed tells us that the individual modeling approach will get poor generalization ability due to ignoring the intertask hidden correlation. In order to circumvent this shortcoming, we consider a general framework for preserving the independent information among different tasks and mining hidden correlation information among all tasks in multitask fuzzy modeling. In this framework, a low-dimensional subspace (structure) is assumed to be shared among all tasks and hence be the hidden correlation information among all tasks. Under this framework, a multitask Takagi-Sugeno-Kang (TSK) fuzzy system model called MTCS-TSK-FS (TSK-FS for multiple tasks with common hidden structure), based on the classical L2-norm TSK fuzzy system, is proposed in this paper. The proposed model can not only take advantage of independent sample information from the original space for each task, but also effectively use the intertask common hidden structure among multiple tasks to enhance the generalization performance of the built fuzzy systems. Experiments on synthetic and real-world datasets demonstrate the applicability and distinctive performance of the proposed multitask fuzzy system model in multitask regression learning scenarios.","Fuzzy systems,
Correlation,
Periodic structures,
Training,
Linear programming,
Educational institutions,
Learning systems"
"Delivery of adaptive bit rate video: balancing fairness, efficiency and quality","HTTP streaming currently dominates Internet traffic. It is increasingly common that video players employ adaptive bitrate (ABR) streaming strategies to maximise the user experience by selecting the highest video representation while targeting stall-free playback. Our interest lies in the common situation where a set of video flows are competing for access to a shared bottleneck link, such as in a cellular radio access network. We observe that ISPs (e.g. cellular operators) are considering innetwork techniques for resource allocation and sharing among different users. Buoyed by the ability of software defined networks (SDN) to offer flow-specific control and traffic shaping, we focus on traffic shaping techniques, and experimentally analyse the effect on ABR video flows when sharing a bottleneck link. We conduct experiments using the GPAC video player operating over a Mininet virtual network. We conclude that traffic shaping can allow a balance of fairness, efficiency and quality. Traffic shaping ABR videos reduce the number of stalls and quality switches, while also reducing the peaks for the aggregate network traffic.",
Simultaneously Optimizing Spatial Spectral Features Based on Mutual Information for EEG Classification,"High performance of the brain-computer interface (BCI) needs efficient algorithms to extract discriminative features from raw electroencephalography (EEG) signals. In this paper, we present a novel scheme to extract spatial spectral features for the motor imagery-based BCI. The learning task is formulated by maximizing the mutual information between spatial spectral features (MMISS) and class labels, by which a unique objective function directly related to Bayes classification error is optimized. The spatial spectral features are assumed to follow a parametric Gaussian distribution, which has been validated by the normal distribution Mardia's test, and under this assumption the estimation of mutual information is derived. We propose a gradient based alternative and iterative learning algorithm to optimize the cost function and derive the spatial and spectral filters simultaneously. The experimental results on dataset IVa of BCI competition III and dataset IIa of BCI competition IV show that the proposed MMISS is able to efficiently extract discriminative features from motor imagery-based EEG signals to enhance the classification accuracy compared to other existing algorithms.","Mutual information,
Electroencephalography,
Vectors,
Feature extraction,
Gaussian distribution,
Cost function"
Energy-Efficient Indoor Localization of Smart Hand-Held Devices Using Bluetooth,"Indoor localization of smart hand-held devices is essential for location-based services of pervasive applications. The previous research mainly focuses on exploring wireless signal fingerprints for this purpose, and several shortcomings need to be addressed first before real-world usage, e.g., demanding a large number of access points or labor-intensive site survey. In this paper, through a systematic empirical study, we first gain in-depth understandings of Bluetooth characteristics, i.e., the impact of various factors, such as distance, orientation, and obstacles on the Bluetooth received signal strength indicator (RSSI). Then, by mining from historical data, a novel localization model is built to describe the relationship between the RSSI and the device location. On this basis, we present an energy-efficient indoor localization scheme that leverages user motions to iteratively shrink the search space to locate the target device. An Motion-assisted Device Tracking Algorithm has been prototyped and evaluated in several real-world scenarios. Extensive experiments show that our algorithm is efficient in terms of localization accuracy, searching time and energy consumption.",
Round-Efficient and Sender-Unrestricted Dynamic Group Key Agreement Protocol for Secure Group Communications,"Modern collaborative and group-oriented applications typically involve communications over open networks. Given the openness of today's networks, communications among group members must be secure and, at the same time, efficient. Group key agreement (GKA) is widely employed for secure group communications in modern collaborative and group-oriented applications. This paper studies the problem of GKA in identity-based cryptosystems with an emphasis on round-efficient, sender-unrestricted, member-dynamic, and provably secure key escrow freeness. The problem is resolved by proposing a one-round dynamic asymmetric GKA protocol which allows a group of members to dynamically establish a public group encryption key, while each member has a different secret decryption key in an identity-based cryptosystem. Knowing the group encryption key, any entity can encrypt to the group members so that only the members can decrypt. We construct this protocol with a strongly unforgeable stateful identity-based batch multisignature scheme. The proposed protocol is shown to be secure under the k -bilinear Diffie-Hellman exponent assumption.","Protocols,
Encryption,
Games,
Receivers,
Collaboration"
Processes Meet Big Data: Connecting Data Science with Process Science,"As more and more companies are embracing Big data, it has become apparent that the ultimate challenge is to relate massive amounts of event data to processes that are highly dynamic. To unleash the value of event data, events need to be tightly connected to the control and management of operational processes. However, the primary focus of Big data technologies is currently on storage, processing, and rather simple analytical tasks. Big data initiatives rarely focus on the improvement of end-to-end processes. To address this mismatch, we advocate a better integration of data science, data technology and process science. Data science approaches tend to be process agonistic whereas process science approaches tend to be model-driven without considering the “evidence” hidden in the data. Process mining aims to bridge this gap. This editorial discusses the interplay between data science and process science and relates process mining to Big data technologies, service orientation, and cloud computing.","Data mining,
Big data,
Computational modeling,
Analytical models,
Organizations"
High-Endurance Hybrid Cache Design in CMP Architecture With Cache Partitioning and Access-Aware Policies,"In recent years, nonvolatile memory (NVM) technologies, such as spin-transfer torque random-access memory (RAM) (STT-RAM) and phase change RAM, have drawn a lot of attention due to their low leakage and high density. However, both of these NVMs suffer from high write latency and limited endurance problems. To mitigate the write pressure on NVM, many static RAM (SRAM)/NVM hybrid cache designs have been proposed with write management policies. Unfortunately, existing hybrid cache designs do not consider the unbalanced workload of each core in (chip multiprocessor) architecture, resulting in unbalanced wear out of hybrid caches. This paper considers the unbalanced write distribution of a hybrid cache for CMP architecture as well as a novel hybrid cache design that includes SRAM cache, STT-RAM cache, and STT-RAM/SRAM hybrid cache banks. Based on the proposed hybrid cache design, two access-aware policies are proposed to mitigate unbalanced wearout of the STT-RAM region, and a wearout-aware dynamic cache partitioning scheme is proposed to dynamically partition the hybrid cache, improving the unbalanced write pressure among different cache partitions. The experimental results show that our proposed scheme and policies can achieve an average of 89 times improvement in cache lifetime and are able to reduce energy consumption by 58% compared with a SRAM cache.",
Streaming Codes for Multicast Over Burst Erasure Channels,"We study low-delay erasure correction codes in a real-time streaming setup. The encoder observes a stream of source packets and outputs the channel packets in a causal fashion, which are broadcast to two receivers over burst-erasure channels. Each receiver must decode the source packets sequentially with a deadline of Ti, while its channel can introduce an erasure burst of maximum length Bi, where i ∈ {1,2} and w.l.o.g. B2 > B1. We study the associated capacity as a function of the burst lengths and decoding deadlines. We observe that the operation of the system can be divided into two main regimes. The so-called large-delay regime corresponds to the case when either T1 ≥ B2 or T2 ≥ B1 + B2. We show that for these parameters, the optimal code is obtained through simple modifications of previously proposed single-user codes by Martinian et al. and the diversity embedded streaming codes proposed by Badr et al. When both T1 <; B2 and T2 <; B1 + B2, the system is said to be in the low-delay regime. We propose a new code construction and establish its optimality when T2 ≥ T1 + B1. In the case when T2 <; T1 + B1, we establish upper and lower bounds on the capacity and characterize the exact capacity when either T1 = B1 or T2 = B2. Our upper bounds in the low-delay regime are based on novel information theoretic arguments that capture the tension between the decoding constraints at the two receivers.","Delays,
Decoding,
Receivers,
Parity check codes,
Upper bound,
Encoding"
Parallel Construction of Independent Spanning Trees on Enhanced Hypercubes,"The use of multiple independent spanning trees (ISTs) for data broadcasting in networks provides a number of advantages, including the increase of fault-tolerance, bandwidth and security. Thus, the designs of multiple ISTs on several classes of networks have been widely investigated. In this paper, we give an algorithm to construct ISTs on enhanced hypercubes Qn,k, which contain folded hypercubes as a subclass. Moreover, we show that these ISTs are near optimal for heights and path lengths. Let D(Qn,k) denote the diameter of Qn,k. If n - k is odd or n - k ∈ {2; n}, we show that all the heights of ISTs are equal to D(Qn,k) + 1, and thus are optimal. Otherwise, we show that each path from a node to the root in a spanning tree has length at most D(Qn,k) + 2. In particular, no more than 2.15 percent of nodes have the maximum path length. As a by-product, we improve the upper bound of wide diameter (respectively, fault diameter) of Qn,k from these path lengths.","Hypercubes,
Vegetation,
Fault tolerance,
Fault tolerant systems,
Educational institutions,
Electronic mail,
Broadcasting"
Distributed Fault-Tolerant Topology Control in Cooperative Wireless Ad Hoc Networks,"Current researches on topology control with cooperative communication (CC) in wireless ad hoc networks have focused on network connectivity, path energy-efficiency and node transmission power reduction. However, fault-tolerance related issues have not been adequately addressed. In this paper, we propose a CC-based scheme to achieve more efficient fault-tolerant topology control. We first define k-connectivity under the CC model and then design a distributed scheme for building a t-spanner with k-connectivity of an arbitrary communication network. Simulation results confirm that the proposed scheme can tolerate node failures as well as exploit the advantage of CC to achieve path energy-efficiency and lower power consumption of the network.","Topology,
Network topology,
Fault tolerance,
Fault tolerant systems,
Energy consumption,
Cooperative communication,
Energy efficiency"
Automatic Optic Disc Detection in OCT Slices via Low-Rank Reconstruction,"Optic disc measurements provide useful diagnostic information as they have correlations with certain eye diseases. In this paper, we provide an automatic method for detecting the optic disc in a single OCT slice. Our method is developed from the observation that the retinal pigment epithelium (RPE) which bounds the optic disc has a low-rank appearance structure that differs from areas within the disc. To detect the disc, our method acquires from the OCT image an RPE appearance model that is specific to the individual and imaging conditions, by learning a low-rank dictionary from image areas known to be part of the RPE according to priors on ocular anatomy. The edge of the RPE, where the optic disc is located, is then found by traversing the retinal layer containing the RPE, reconstructing local appearance with the low-rank model, and detecting the point at which appearance starts to deviate (i.e., increased reconstruction error). To aid in this detection, we also introduce a geometrical constraint called the distance bias that accounts for the smooth shape of the RPE. Experiments demonstrate that our method outperforms other OCT techniques in localizing the optic disc and estimating disc width. Moreover, we also show the potential usage of our method on optic disc area detection in 3-D OCT volumes.","Adaptive optics,
Optical imaging,
Biomedical optical imaging,
Feature extraction,
Retina,
Image reconstruction"
Hybrid consensus-based formation control of agents with second order dynamics,"In this paper, a novel hybrid consensus based formation controller is designed for agents moving in the x-y plane to drive them to a goal point while maintaining a specified formation. The proposed hybrid automaton consists of two discrete states, each with continuous dynamics: a regulation state and a formation keeping state. The controller in the regulation state is designed to drive the agent to a goal position while the formation keeping controller ensures that the agents achieve a specified geometric formation prior to reaching their goalposition. The proposed controller creates hybrid dynamics from the interactions between the continuous and discrete states. The analysis and design of hybrid systems is generally more difficult than that of purely discrete or purely continuous systems since the discrete dynamics may affect the continuous evolution and vice versa. Therefore, the stability of the hybrid approach is proven by using multiple Lyapunov functions and also considers the switching conditions between the regulation and the formation states. The Lyapunov based approach demonstrates that the formation errors converge to a small bounded region around the origin and the size of the bound can be adjusted by using the switching conditions. Convergence to goal position while in formation is also demonstrated in the same Lyapunov analysis, and simulation results verify the theoretical conjectures.","Switches,
Lyapunov methods,
Automata,
Robot kinematics,
Continuous time systems,
Stability analysis"
Accurate Vessel Segmentation With Constrained B-Snake,"We describe an active contour framework with accurate shape and size constraints on the vessel cross-sectional planes to produce the vessel segmentation. It starts with a multiscale vessel axis tracing in a 3D computed tomography (CT) data, followed by vessel boundary delineation on the cross-sectional planes derived from the extracted axis. The vessel boundary surface is deformed under constrained movements on the cross sections and is voxelized to produce the final vascular segmentation. The novelty of this paper lies in the accurate contour point detection of thin vessels based on the CT scanning model, in the efficient implementation of missing contour points in the problematic regions and in the active contour model with accurate shape and size constraints. The main advantage of our framework is that it avoids disconnected and incomplete segmentation of the vessels in the problematic regions that contain touching vessels (vessels in close proximity to each other), diseased portions (pathologic structure attached to a vessel), and thin vessels. It is particularly suitable for accurate segmentation of thin and low contrast vessels. Our method is evaluated and demonstrated on CT data sets from our partner site, and its results are compared with three related methods. Our method is also tested on two publicly available databases and its results are compared with the recently published method. The applicability of the proposed method to some challenging clinical problems, the segmentation of the vessels in the problematic regions, is demonstrated with good results on both quantitative and qualitative experimentations; our segmentation algorithm can delineate vessel boundaries that have level of variability similar to those obtained manually.",
Revealing the Trace of High-Quality JPEG Compression Through Quantization Noise Analysis,"To identify whether an image has been JPEG compressed is an important issue in forensic practice. The state-of-the-art methods fail to identify high-quality compressed images, which are common on the Internet. In this paper, we provide a novel quantization noise-based solution to reveal the traces of JPEG compression. Based on the analysis of noises in multiple-cycle JPEG compression, we define a quantity called forward quantization noise. We analytically derive that a decompressed JPEG image has a lower variance of forward quantization noise than its uncompressed counterpart. With the conclusion, we develop a simple yet very effective detection algorithm to identify decompressed JPEG images. We show that our method outperforms the state-of-the-art methods by a large margin especially for high-quality compressed images through extensive experiments on various sources of images. We also demonstrate that the proposed method is robust to small image size and chroma subsampling. The proposed algorithm can be applied in some practical applications, such as Internet image classification and forgery detection.","Quantization (signal),
Noise,
Image coding,
Transform coding,
Discrete cosine transforms,
Upper bound,
Forensics"
Stealthy attacks meets insider threats: A three-player game model,"Advanced persistent threat (APT) is becoming a major threat to cyber security. As APT attacks are often launched by well funded entities that are persistent and stealthy in achieving their goals, they are highly challenging to combat in a cost-effective way. The situation becomes even worse when a sophisticated attacker is further assisted by an insider with privileged access to the inside information. Although stealthy attacks and insider threats have been considered separately in previous works, the coupling of the two is not well understood. As both types of threats are incentive driven, game theory provides a proper tool to understand the fundamental tradeoffs involved. In this paper, we propose the first three-player attacker-defender-insider game to model the strategic interactions among the three parties. Our game extends the two-player FlipIt game model for stealthy takeover by introducing an insider that can trade information to the attacker for a profit. We characterize the subgame perfect equilibria of the game with the defender as the leader and the attacker and the insider as the followers, under two different information trading processes. We make various observations and discuss approaches for achieving more efficient defense in the face of both APT and insider threats.","Games,
Computational modeling,
Computer security,
Real-time systems,
Numerical models,
Face"
Impact of process-variations in STTRAM and adaptive boosting for robustness,"Spin-Torque Transfer Random Access Memory (STTRAM) is a promising technology for high density on-chip cache due to low standby power. Additionally, it offers fast access time, good endurance and retention. However, it suffers from poor write latency and write power. Additionally we observe that process variation can result in large spread in write and read latency variations. The performance of conventionally designed STTRAM cache can degrade as much as 10% due to process variations. We propose a novel and adaptive write current boosting to address this issue. The bits experiencing worst-case write latency are fixed through write current boosting. Simulations show 80% power improvement compared to boosting all bit-cells and 13% performance improvement compared to worst case latency due to process variation over a wide range of PARSEC benchmarks.","Boosting,
Random access memory,
Mathematical model,
Magnetic tunneling,
Monte Carlo methods,
Curve fitting,
Benchmark testing"
Investigation of Single-Bit and Multiple-Bit Upsets in Oxide RRAM-Based 1T1R and Crossbar Memory Arrays,"In this paper, the susceptibility of oxide-based resistive switching random memory (RRAM) to heavy ion strikes is investigated. A physics-based SPICE model calibrated with HfOx RRAM is employed for circuit and array-level simulations. The RRAM state-flipping is attributed to the transient photocurrents at neighboring transistors. Single-bit-upset (SBU) caused by either single-event upset (SEU) or multiple-event upset (MEU) is modeled and simulated in the one-transistor and one-resistor (1T1R) array, which corroborates with experimental observations. In addition, circuit simulation is performed to investigate the impact of transient-induced soft errors in a 1024 ×1024 crossbar array. The sensitive locations in crossbar arrays are the driver circuits at the edge of the array. The simulations show that the crossbar array with HfOx RRAM is of high radiation tolerance thanks to the V/2 bias scheme. However, multiple-bit upset (MBU) may occur if using other oxide materials with lower operation voltage. Voltage spikes generated at the edge of the array may propagate along rows or columns as there is no isolation between cells in the crossbar array.","Transistors,
Photoconductivity,
Transient analysis,
Resistance,
Switches,
Junctions,
Integrated circuit modeling"
Analysis and Design of Digital Chaotic Systems With Desirable Performance via Feedback Control,"The dynamical degradation of digital chaotic systems (DCSs) often has serious negative influences on some digital chaos-based systems and then becomes one of the bottleneck problems stopping chaos from some applications. In this paper, we first restrict the Devaney's chaos definition to finite state sets to describe the chaotic motion of digital systems. Then, we propose a novel control method for DCSs based on the differential mean value theorem and state feedback technology. Simulation results show the effectiveness, robustness, and superiority of the proposed method. Finally, we construct a new pseudorandom number generator (PRNG) and evaluate its randomness via NIST SP800-22 and TestU01 test suites. Statistical test results show that the proposed PRNG has high reliability of randomness, thus it can be used for cryptography and other potential applications.","Chaos,
Digital systems,
Orbits,
Control systems,
Space vehicles,
Logistics,
Correlation"
3-D Point Cloud Object Detection Based on Supervoxel Neighborhood With Hough Forest Framework,"Object detection in three-dimensional (3-D) laser scanning point clouds of complex urban environment is a challenging problem. Existing methods are limited by their robustness to complex situations such as occlusion, overlap, and rotation or by their computational efficiency. This paper proposes a high computationally efficient method integrating supervoxel with Hough forest framework for detecting objects from 3-D laser scanning point clouds. First, a point cloud is over-segmented into spatially consistent supervoxels. Each supervoxel together with its first-order neighborhood is grouped into one local patch. All the local patches are described by both structure and reflectance features, and then used in the training stage for learning a random forest classifier as well as the detection stage to vote for the possible location of the object center. Second, local reference frame and circular voting strategies are introduced to achieve the invariance to the azimuth rotation of objects. Finally, objects are detected at the peak points in 3-D Hough voting space. The performance of our proposed method is evaluated on real-world point cloud data collected by the up-to-date mobile laser scanning system. Experimental results demonstrate that our proposed method outperforms state-of-the-art 3-D object detection methods with high computational efficiency.","Three-dimensional displays,
Object detection,
Training,
Shape,
Roads,
Lasers,
Feature extraction"
"An Integrated Widefield Imaging and Spectroscopy System for Contrast-Enhanced, Image-Guided Resection of Tumors","Tumor recurrence following surgery is a common and unresolved medical problem of great importance since surgery is the most widely used treatment for solid-mass tumors worldwide. A contributing factor to tumor recurrence is the presence of residual tumor remaining at or near the surgical site following surgery. Goal: The primary objective of this study was to develop and evaluate an image-guided surgery system based on a near-infrared, handheld excitation source and spectrograph in combination with a widefield video imaging system. Methods: This system was designed to detect the fluorescence of near-infrared contrast agents and, in particular, indocyanine green (ICG). The imaging system was evaluated for its optical performance and ability to detect the presence of ICG in tumors in an ectopic murine tumor model as well as in spontaneous tumors arising in canines. Results: In both settings, an intravenous ICG infusion provided tumor contrast. In both the murine models and surgical specimens from canines, ICG preferentially accumulated in tumor tissue compared to surrounding normal tissue. The resulting contrast was sufficient to distinguish neoplasia from normal tissue; in the canine surgical specimens, the contrast was sufficient to permit identification of neoplasia on the marginal surface of the specimen. Conclusion: These results demonstrate a unique concept in image-guided surgery by combining local excitation and spectroscopy with widefield imaging. Significance: The ability to readily detect ICG in canines with spontaneous tumors in a clinical setting exemplifies the potential for further clinical translation; the promising results of detecting neoplasia on the marginal specimen surface underscore the clinical utility.","Tumors,
Surgery,
Cameras,
Lenses,
Probes,
Optical filters"
Achievable rates of multi-user millimeter wave systems with hybrid precoding,"Millimeter wave (mmWave) systems will likely employ large antenna arrays at both the transmitters and receivers. A natural application of antenna arrays is simultaneous transmission to multiple users, which requires multi-user precoding at the transmitter. Hardware constraints, however, make it difficult to apply conventional lower frequency MIMO precoding techniques at mmWave. This paper proposes and analyzes a low complexity hybrid analog/digital precoding algorithm for downlink multi-user mmWave systems. Hybrid precoding involves a combination of analog and digital processing that is motivated by the requirement to reduce the power consumption of the complete radio frequency and mixed signal hardware. The proposed algorithm configures hybrid precoders at the transmitter and analog combiners at multiple receivers with a small training and feedback overhead. For this algorithm, we derive a lower bound on the achievable rate for the case of single-path channels, show its asymptotic optimality at large numbers of antennas, and make useful insights for more general cases. Simulation results show that the proposed algorithm offers higher sum rates compared with analog-only beamforming, and approaches the performance of the unconstrained digital precoding solutions.","Radio frequency,
Array signal processing,
Algorithm design and analysis,
Antenna arrays,
NIST,
MIMO,
Baseband"
Depth-Preserving Warping for Stereo Image Retargeting,"The popularity of stereo images and various display devices poses the need of stereo image retargeting techniques. Existing warping-based retargeting methods can well preserve the shape of salient objects in a retargeted stereo image pair. Nevertheless, these methods often incur depth distortion, since they attempt to preserve depth by maintaining the disparity of a set of sparse correspondences, rather than directly controlling the warping. In this paper, by considering how to directly control the warping functions, we propose a warping-based stereo image retargeting approach that can simultaneously preserve the shape of salient objects and the depth of 3D scenes. We first characterize the depth distortion in terms of warping functions to investigate the impact of a warping function on depth distortion. Based on the depth distortion model, we then exploit binocular visual characteristics of stereo images to derive region-based depth-preserving constraints which directly control the warping functions so as to faithfully preserve the depth of 3D scenes. Third, with the region-based depth-preserving constraints, we present a novel warping-based stereo image retargeting framework. Since the depth-preserving constraints are derived regardless of shape preservation, we relax the depth-preserving constraints to fulfill a tradeoff between shape preservation and depth preservation. Finally, we propose a quad-based implementation of the proposed framework. The results demonstrate the efficacy of our method in both depth and shape preservation for stereo image retargeting.",
No-Reference Video Quality Assessment Based on Artifact Measurement and Statistical Analysis,"A discrete cosine transform (DCT)-based no-reference video quality prediction model is proposed that measures artifacts and analyzes the statistics of compressed natural videos. The model has two stages: 1) distortion measurement and 2) nonlinear mapping. In the first stage, an unsigned ac band, three frequency bands, and two orientation bands are generated from the DCT coefficients of each decoded frame in a video sequence. Six efficient frame-level features are then extracted to quantify the distortion of natural scenes. In the second stage, each frame-level feature of all frames is transformed to a corresponding video-level feature via a temporal pooling, then a trained multilayer neural network takes all video-level features as inputs and outputs, a score as the predicted quality of the video sequence. The proposed method was tested on videos with various compression types, content, and resolution in four databases. We compared our model with a linear model, a support-vector-regression-based model, a state-of-the-art training-based model, and a four popular full-reference metrics. Detailed experimental results demonstrate that the results of the proposed method are highly correlated with the subjective assessments.","Feature extraction,
Distortion measurement,
Nonlinear distortion,
Discrete cosine transforms,
Quality assessment,
Video recording,
Neural networks"
Discriminative learning of iteration-wise priors for blind deconvolution,"The maximum a posterior (MAP)-based blind deconvolution framework generally involves two stages: blur kernel estimation and non-blind restoration. For blur kernel estimation, sharp edge prediction and carefully designed image priors are vital to the success of MAP. In this paper, we propose a blind deconvolution framework together with iteration specific priors for better blur kernel estimation. The family of hyper-Laplacian (Pr(d) ∝ e-∥d∥pp/λ) is adopted for modeling iteration-wise priors of image gra- dients, where each iteration has its own model parameters {λ(t), p(t)}. To avoid heavy parameter tuning, all iteration-wise model parameters can be learned using our principled discriminative learning model from a training set, and can be directly applied to other dataset and real blurry images. Interestingly, with the generalized shrinkage / thresholding operator, negative p value (p <;0) is allowable and we find that it contributes more in estimating the coarse shape of blur kernel. Experimental results on synthetic and real world images demonstrate that our method achieves better deblurring results than the existing gradient prior-based methods. Compared with the state-of-the-art patch prior-based method, our method is competitive in restoration results but is much more efficient.","realistic images,
deconvolution,
edge detection,
estimation theory,
gradient methods,
image restoration,
learning (artificial intelligence)"
Detection and Rectification of Distorted Fingerprints,"Elastic distortion of fingerprints is one of the major causes for false non-match. While this problem affects all fingerprint recognition applications, it is especially dangerous in negative recognition applications, such as watchlist and deduplication applications. In such applications, malicious users may purposely distort their fingerprints to evade identification. In this paper, we proposed novel algorithms to detect and rectify skin distortion based on a single fingerprint image. Distortion detection is viewed as a two-class classification problem, for which the registered ridge orientation map and period map of a fingerprint are used as the feature vector and a SVM classifier is trained to perform the classification task. Distortion rectification (or equivalently distortion field estimation) is viewed as a regression problem, where the input is a distorted fingerprint and the output is the distortion field. To solve this problem, a database (called reference database) of various distorted reference fingerprints and corresponding distortion fields is built in the offline stage, and then in the online stage, the nearest neighbor of the input fingerprint is found in the reference database and the corresponding distortion field is used to transform the input fingerprint into a normal one. Promising results have been obtained on three databases containing many distorted fingerprints, namely FVC2004 DB1, Tsinghua Distorted Fingerprint database, and the NIST SD27 latent fingerprint database.","Databases,
Vectors,
Feature extraction,
Training,
Fingerprint recognition,
Skin,
Force"
Survey and comparison of MADM methods for network selection access in heterogeneous networks,"One of the key features of the the next generation of networks is the coexistence of multiple radio access technologies such as WIFI, WIMAX and LTE. This heterogeneous environment provides to the mobile users the possibility to use different services at any time and any where. Various multiple attribute decision making (MADM) algorithms have been proposed to manage the terminal mobility while ensuring the best continuity of services. Among the most MADM methods which are widely used for solving the network selection problem in the research literature are SAW, MEW, TOPSIS, GRA, VIKOR, DIA, E-TOPSIS and FADM. This paper evaluates the performance of eight MADM methods, that aim to ensure the seamless network selection under the principle always best connected.","Surface acoustic waves,
Handover,
Algorithm design and analysis,
Mobile communication,
Quality of service,
Performance evaluation"
DIBR synthesized image quality assessment based on morphological wavelets,"Most of the Depth Image Based Rendering (DIBR) techniques produce synthesized images which contain nonuniform geometric distortions affecting edges coherency. This type of distortions are challenging for common image quality metrics. Morphological filters maintain important geometric information such as edges across different resolution levels. In this paper, morphological wavelet peak signal-to-noise ratio measure, MW-PSNR, based on morphological wavelet decomposition is proposed to tackle the evaluation of DIBR synthesized images. It is shown that MW-PSNR achieves much higher correlation with human judgment compared to the state-of-the-art image quality measures in this context.",
Topological Spatial Verification for Instance Search,"This paper proposes an elastic spatial verification method for Instance Search, particularly for dealing with non-planar and non-rigid queries exhibiting complex spatial transformations. Different from existing models that map keypoints between images based on a linear transformation (e.g., affine, homography), our model exploits the topological arrangement of keypoints to address the non-linear spatial transformations that are extremely common in real life situations. In particular, we propose a novel technique to elastically verify the topological spatial consistency with the triangulated graph through a “sketch-and-match” scheme. The spatial topology configuration, emphasizing relative positioning rather than absolute coordinates, is first sketched by a triangulated graph, whose edges essentially capture the topological layout of the corresponding keypoints. Next, the spatial consistency is efficiently estimated as the number of common edges between the triangulated graphs. Compared to the existing methods, our technique is much more effective in modeling the complex spatial transformations of non-planar and non-rigid instances, while being compatible to instances with simple linear transformations. Moreover, our method is by nature more robust in spatial verification by considering the locations, rather than the local geometry of keypoints, which are sensitive to motions and viewpoint changes. We evaluate our method extensively on three years of TRECVID datasets, as well as our own dataset MQA, showing large improvement over other methods for the task of Instance Search.","Geometry,
Topology,
Search problems,
Three-dimensional displays,
Visualization,
Context,
Robustness"
Consensus in Continuous-Time Multiagent Systems Under Discontinuous Nonlinear Protocols,"In this paper, we provide a theoretical analysis for nonlinear discontinuous consensus protocols in networks of multiagents over weighted directed graphs. By integrating the analytic tools from nonsmooth stability analysis and graph theory, we investigate networks with both fixed topology and randomly switching topology. For networks with a fixed topology, we provide a sufficient and necessary condition for asymptotic consensus, and the consensus value can be explicitly calculated. As to networks with switching topologies, we provide a sufficient condition for the network to realize consensus almost surely. In particular, we consider the case that the switching sequence is independent and identically distributed. As applications of the theoretical results, we introduce a generalized blinking model and show that consensus can be realized almost surely under the proposed protocols. Numerical simulations are also provided to illustrate the theoretical results.","Protocols,
Network topology,
Topology,
Switches,
Laplace equations,
Convergence,
Multi-agent systems"
Distributed security constrained economic dispatch,"In this paper, we investigate two decomposition methods for their convergence rate which are used to solve security constrained economic dispatch (SCED): 1) Lagrangian Relaxation (LR), and 2) Augmented Lagrangian Relaxation (ALR). First, the centralized SCED problem is posed for a 6-bus test network and then it is decomposed into subproblems using both of the methods. In order to model the tie-line between decomposed areas of the test network, a novel method is proposed. The advantages and drawbacks of each method are discussed in terms of accuracy and information privacy. We show that there is a tradeoff between the information privacy and the convergence rate. It has been found that ALR converges faster compared to LR, due to the large amount of shared data.","Load flow,
Generators,
Optimization,
Linear programming,
Security,
Economics"
On Resistive Networks of Constant-Power Devices,"This brief examines the behavior of DC circuits comprised of resistively interconnected constant-power devices (CPDs), as may arise in dc microgrids containing microsources and constant-power loads. We derive a sufficient condition for all operating points of the circuit to lie in a desirable set, where the average nodal voltage level is high, and nodal voltages are tightly clustered near one another. Our condition has the elegant physical interpretation that the ratio of resistive losses to total injected power should be small compared with a measure of network heterogeneity, as quantified by a ratio of conductance matrix eigenvalues. Perhaps surprisingly, the interplay between the circuit topology, branch conductances, and CPDs implicitly defines a nominal voltage level for the circuit, despite the explicit absence of voltage-regulated nodes.","Ports (Computers),
Mathematical model,
Microgrids,
Voltage control,
Circuits and systems,
Power system stability,
Transmission line matrix methods"
A Case of Lightweight PUF Constructions: Cryptanalysis and Machine Learning Attacks,"Due to their unique physical properties, physically unclonable functions (PUF) have been proposed widely as versatile cryptographic primitives. It is desirable that silicon PUF circuits should be lightweight, i.e., have low-hardware resource requirements. However, it is also of primary importance that such demands of low hardware overhead should not compromise the security aspects of PUF circuits. In this paper, we develop two different mathematical attacks on previously proposed lightweight PUF circuits, namely composite PUF and the multibit output lightweight secure PUF (LSPUF). We show that independence of various components of composite PUF can be used to develop divide and conquer attacks which can be used to determine the responses to unknown challenges. We reduce the complexity of the attack using a machine learning-based modeling analysis. In addition, we elucidate a special property of the output network of LSPUF to show how such feature can be leveraged by an adversary to perform an intelligent model building attack. The theoretical inferences are validated through experimental results. More specifically, proposed attacks on composite PUF are validated using the challenge-response pairs (CRPs) from its field programmable gate array (FPGA) implementation, and attack on LSPUF is validated using the CRPs of both simulated and FPGA implemented LSPUF.","Cryptography,
Computational modeling,
Partitioning algorithms,
Hardware,
Integrated circuit reliability"
Economizing TSV Resources in 3-D Network-on-Chip Design,"The confluence of 3-D integration and network-on-chip (NoC) provides an effective solution to the scalability problem of on-chip interconnects. In 3-D integration, through-silicon via (TSV) is considered to be the most promising bonding technology. However, TSVs are also precious link resources because they consume significant chip area and possibly lead to routing congestion in the physical design stage. In addition, TSVs suffer from serious yield losses that shrink the effective TSV density. Thus, it is necessary to implement a TSV-economical 3-D NoC architecture in cost-effective design. For symmetric 3-D mesh NoCs, we observe that the TSVs bandwidth utilization is low and they rarely become the contention spots in networks as planar links. Based on this observation, we propose the TSV sharing (TS) scheme to save TSVs in 3-D NoC by enabling neighboring routers to share the vertical channels in a time division multiplexing way. We also investigate different TS implementation alternatives and show how TS improves TSV-effectiveness (TE) in multicore processors through a design space exploration. In experiments, we comprehensively evaluate TSs influence on all layers of system. It is shown that the proposed method significantly promotes TE with negligible performance overhead.","Through-silicon vias,
Routing,
Bandwidth,
Wiring,
Topology,
Time division multiplexing,
Bonding"
Disulfide Connectivity Prediction Based on Modelled Protein 3D Structural Information and Random Forest Regression,"Disulfide connectivity is an important protein structural characteristic. Accurately predicting disulfide connectivity solely from protein sequence helps to improve the intrinsic understanding of protein structure and function, especially in the post-genome era where large volume of sequenced proteins without being functional annotated is quickly accumulated. In this study, a new feature extracted from the predicted protein 3D structural information is proposed and integrated with traditional features to form discriminative features. Based on the extracted features, a random forest regression model is performed to predict protein disulfide connectivity. We compare the proposed method with popular existing predictors by performing both cross-validation and independent validation tests on benchmark datasets. The experimental results demonstrate the superiority of the proposed method over existing predictors. We believe the superiority of the proposed method benefits from both the good discriminative capability of the newly developed features and the powerful modelling capability of the random forest. The web server implementation, called TargetDisulfide, and the benchmark datasets are freely available at: http://csbio.njust.edu.cn/bioinf/TargetDisulfide for academic use.","Proteins,
Feature extraction,
Three-dimensional displays,
Bioinformatics,
Benchmark testing,
Educational institutions"
BIK-BUS: Biologically Motivated 3D Keypoint Based on Bottom-Up Saliency,"One of the major problems found when developing a 3D recognition system involves the choice of keypoint detector and descriptor. To help solve this problem, we present a new method for the detection of 3D keypoints on point clouds and we perform benchmarking between each pair of 3D keypoint detector and 3D descriptor to evaluate their performance on object and category recognition. These evaluations are done in a public database of real 3D objects. Our keypoint detector is inspired by the behavior and neural architecture of the primate visual system. The 3D keypoints are extracted based on a bottom-up 3D saliency map, that is, a map that encodes the saliency of objects in the visual environment. The saliency map is determined by computing conspicuity maps (a combination across different modalities) of the orientation, intensity, and color information in a bottom-up and in a purely stimulus-driven manner. These three conspicuity maps are fused into a 3D saliency map and, finally, the focus of attention (or keypoint location) is sequentially directed to the most salient points in this map. Inhibiting this location automatically allows the system to attend to the next most salient location. The main conclusions are: with a similar average number of keypoints, our 3D keypoint detector outperforms the other eight 3D keypoint detectors evaluated by achieving the best result in 32 of the evaluated metrics in the category and object recognition experiments, when the second best detector only obtained the best result in eight of these metrics. The unique drawback is the computational time, since biologically inspired 3D keypoint based on bottom-up saliency is slower than the other detectors. Given that there are big differences in terms of recognition performance, size and time requirements, the selection of the keypoint detector and descriptor has to be matched to the desired task and we give some directions to facilitate this choice.",
Weakly Semi-Supervised Deep Learning for Multi-Label Image Annotation,"In this paper, we study leveraging both weakly labeled images and unlabeled images for multi-label image annotation. Motivated by the recent advance in deep learning, we propose an approach called weakly semi-supervised deep learning for multi-label image annotation (WeSed). In WeSed, a novel weakly weighted pairwise ranking loss is effectively utilized to handle weakly labeled images, while a triplet similarity loss is employed to harness unlabeled images. WeSed enables us to train deep convolutional neural network (CNN) with images from social networks where images are either only weakly labeled with several labels or unlabeled. We also design an efficient algorithm to sample high-quality image triplets from large image datasets to fine-tune the CNN. WeSed is evaluated on benchmark datasets for multi-label annotation. The experiments demonstrate the effectiveness of our proposed approach and show that the leverage of the weakly labeled images and unlabeled images leads to a significantly better performance.","Training,
Semantics,
Machine learning,
Visualization,
Big data,
Neural networks,
Social network services"
Fault-tolerant application placement in heterogeneous cloud environments,"The Internet of Things (IoT) has inspired a myriad of real-time applications, such as robotics and human-machine interaction. Many IoT applications have significant computational requirements, while at the same time they demand very low latencies. The cloud can provide the needed resources on-demand, however often fails to meet these timing requirements. Low response time can only be realized by having computational infrastructure in close vicinity. Therefore we investigate to what extent the cloud can be extended in the direct wireless surroundings of the IoT devices. This environment is highly heterogeneous as it comprises a wide variety of devices, connected using a plethora of technologies (both wired and wireless). A direct implication is that, compared to traditional cloud infrastructure, many of those nodes and links are likely to fail. We propose an application placement that can overcome failure-related challenges. We demonstrate that availability-awareness can increase the number of applications that can be hosted simultaneously by 132%. Furthermore we find that an additional increase of 54% can be realized through redundant provisioning of resources.",
Socially-optimal online spectrum auctions for secondary wireless communication,"Spectrum auctions are efficient mechanisms for licensed users to relinquish their under-utilized spectrum to secondary links for monetary remuneration. Truthfulness and social welfare maximization are two natural goals in such auctions, but cannot be achieved simultaneously with polynomial-time complexity by existing methods, even in a static network with fixed parameters. The challenge escalates in practical systems with QoS requirements and volatile traffic demands for secondary communication. Online, dynamic decisions are required for rate control, channel evaluation/bidding, and packet dropping at each secondary link, as well as for winner determination and pricing at the primary user. This work proposes an online spectrum auction framework with cross-layer decision making and randomized winner determination on the fly. The framework is truthful-in-expectation, and achieves close-to-offline-optimal time-averaged social welfare and individual utilities with polynomial time complexity. A new method is introduced for online channel evaluation in a stochastic setting. Simulation studies further verify the efficacy of the proposed auction in practical scenarios.","Delays,
Optimization,
Channel allocation,
Quality of service,
Algorithm design and analysis,
Conferences,
Computers"
Modeling of Whispering Gallery Modes for Rare Earth Spectroscopic Characterization,"A refined model of a mid-IR amplifier, constituted by a tapered chalcogenide fiber coupled to an erbium-doped chalcogenide microsphere, is integrated with a global solution search procedure based on particle swarm optimization approach. It is implemented in a computer code in order to obtain an inversion algorithm useful to evaluate the spectroscopic parameters of rare-earth-doped glass microspheres. The rare earth parameters can be recovered by means of the optical gain measurement. The error in evaluation of the erbium lifetime τ41 is <;3.5%. It is <;0.5% for the other lifetimes and ion-ion interaction parameters. These excellent results are obtained since whispering gallery mode electromagnetic field interacts with rare earth for long effective distances.",
Maurer-Cartan Forms for Fields on Surfaces: Application to Heart Fiber Geometry,"We study the space of first order models of smooth frame fields using the method of moving frames. By exploiting the Maurer-Cartan matrix of connection forms we develop geometrical embeddings for frame fields which lie on spherical, ellipsoidal and generalized helicoid surfaces. We design methods for optimizing connection forms in local neighborhoods and apply these to a statistical analysis of heart fiber geometry, using diffusion magnetic resonance imaging. This application of moving frames corroborates and extends recent characterizations of muscle fiber orientation in the heart wall, but also provides for a rich geometrical interpretation. In particular, we can now obtain direct local measurements of the variation of the helix and transverse angles, of fiber fanning and twisting, and of the curvatures of the heart wall in which these fibers lie.","Geometry,
Differential geometry,
Approximation methods,
Transmission line matrix methods,
Numerical models"
Multimodal Interferometer Based on a Suspended Core Fiber for Simultaneous Measurement of Physical Parameters,"In this study, a multimodal interferometer based on a suspended core photonic crystal fiber (PCF) for simultaneous strain and temperature measurements is proposed. The structure is also employed for angle measurements. The sensor comprises a 3-mm-suspended core PCF between SMFs and is based on the combination of two multimodal interferences with different frequency fringe patterns. The interferometric patterns show different sensitivity responses to strain and temperature. Through a low-pass frequency filtering of the detected spectrum, the wavelength shift of the two patterns can be measured allowing the discrimination of strain and temperature effects with resolutions of 0.45 °C and 4.02 με, respectively. The sensor is also characterized for angle measurements showing a maximum sensitivity of 9.17 pm/° in the range from 0° to 90°. It is demonstrated that with this sensing structure is possible to obtain simultaneous measurement of bend angle and temperature with resolutions of 1.69 ° and 0.92 °C, respectively.","Temperature measurement,
Strain,
Optical fiber sensors,
Temperature sensors,
Optical fibers,
Photonic crystal fibers"
A Probabilistic Approach for Color Correction in Image Mosaicking Applications,"Image mosaicking applications require both geometrical and photometrical registrations between the images that compose the mosaic. This paper proposes a probabilistic color correction algorithm for correcting the photometrical disparities. First, the image to be color corrected is segmented into several regions using mean shift. Then, connected regions are extracted using a region fusion algorithm. Local joint image histograms of each region are modeled as collections of truncated Gaussians using a maximum likelihood estimation procedure. Then, local color palette mapping functions are computed using these sets of Gaussians. The color correction is performed by applying those functions to all the regions of the image. An extensive comparison with ten other state of the art color correction algorithms is presented, using two different image pair data sets. Results show that the proposed approach obtains the best average scores in both data sets and evaluation metrics and is also the most robust to failures.","Image color analysis,
Probabilistic logic,
Image segmentation,
Histograms,
Transfer functions,
Joints,
Measurement"
Regularization Designs for Uniform Spatial Resolution and Noise Properties in Statistical Image Reconstruction for 3-D X-ray CT,"Statistical image reconstruction methods for X-ray computed tomography (CT) provide improved spatial resolution and noise properties over conventional filtered back-projection (FBP) reconstruction, along with other potential advantages such as reduced patient dose and artifacts. Conventional regularized image reconstruction leads to spatially variant spatial resolution and noise characteristics because of interactions between the system models and the regularization. Previous regularization design methods aiming to solve such issues mostly rely on circulant approximations of the Fisher information matrix that are very inaccurate for undersampled geometries like short-scan cone-beam CT. This paper extends the regularization method proposed in [1] to 3-D cone-beam CT by introducing a hypothetical scanning geometry that helps address the sampling properties. The proposed regularization designs were compared with the original method in [1] with both phantom simulation and clinical reconstruction in 3-D axial X-ray CT. The proposed regularization methods yield improved spatial resolution or noise uniformity in statistical image reconstruction for short-scan axial cone-beam CT.",
Visual Tracking via Constrained Incremental Non-negative Matrix Factorization,"This letter presents a novel visual tracking algorithm by using Incremental Non-negative Matrix Factorization (INMF) and dual ℓ1-norm constraints. Firstly, we introduce one ℓ1 regularization into the NMF reconstruction, which enables appearance model to tolerate different noises to some extent. Meanwhile, we enforce another ℓ1 regularization on the projection coefficients when using iterative operators to obtain NMF basis vectors for the effective tracking. Secondly, to obtain the sparse error and projection coefficient matrice, we present an iterative algorithm to solve the optimal problem, which ensures the representation is more robust. Finally, we take partial occlusion into construct likelihood function, and combined with INMF learning to update appearance model for alleviating tracking drift. Experimental results compared with the state-of-the-art tracking methods demonstrate the proposed algorithm achieves favorable performance when the object undergoes large occlusion, motion blur and illumination changes.","Signal processing algorithms,
Target tracking,
Sparse matrices,
Vectors,
Visualization,
Image reconstruction"
Efficient Lattice Boltzmann Solver for Patient-Specific Radiofrequency Ablation of Hepatic Tumors,"Radiofrequency ablation (RFA) is an established treatment for liver cancer when resection is not possible. Yet, its optimal delivery is challenged by the presence of large blood vessels and the time-varying thermal conductivity of biological tissue. Incomplete treatment and an increased risk of recurrence are therefore common. A tool that would enable the accurate planning of RFA is hence necessary. This manuscript describes a new method to compute the extent of ablation required based on the Lattice Boltzmann Method (LBM) and patient-specific, pre-operative images. A detailed anatomical model of the liver is obtained from volumetric images. Then a computational model of heat diffusion, cellular necrosis, and blood flow through the vessels and liver is employed to compute the extent of ablated tissue given the probe location, ablation duration and biological parameters. The model was verified against an analytical solution, showing good fidelity. We also evaluated the predictive power of the proposed framework on ten patients who underwent RFA, for whom pre- and post-operative images were available. Comparisons between the computed ablation extent and ground truth, as observed in postoperative images, were promising (DICE index: 42%, sensitivity: 67%, positive predictive value: 38%). The importance of considering liver perfusion while simulating electrical-heating ablation was also highlighted. Implemented on graphics processing units (GPU), our method simulates 1 minute of ablation in 1.14 minutes, allowing near real-time computation.","Mathematical model,
Computational modeling,
Blood,
Liver,
Biological system modeling,
Heat transfer,
Equations"
Backstepping Fuzzy-Neural-Network Control Design for Hybrid Maglev Transportation System,"This paper focuses on the design of a backstepping fuzzy-neural-network control (BFNNC) for the online levitated balancing and propulsive positioning of a hybrid magnetic levitation (maglev) transportation system. The dynamic model of the hybrid maglev transportation system including levitated hybrid electromagnets to reduce the suspension power loss and the friction force during linear movement and a propulsive linear induction motor based on the concepts of mechanical geometry and motion dynamics is first constructed. The ultimate goal is to design an online fuzzy neural network (FNN) control methodology to cope with the problem of the complicated control transformation and the chattering control effort in backstepping control (BSC) design, and to directly ensure the stability of the controlled system without the requirement of strict constraints, detailed system information, and auxiliary compensated controllers despite the existence of uncertainties. In the proposed BFNNC scheme, an FNN control is utilized to be the major control role by imitating the BSC strategy, and adaptation laws for network parameters are derived in the sense of projection algorithm and Lyapunov stability theorem to ensure the network convergence as well as stable control performance. The effectiveness of the proposed control strategy for the hybrid maglev transportation system is verified by experimental results, and the superiority of the BFNNC scheme is indicated in comparison with the BSC strategy and the backstepping particle-swarm-optimization control system in previous research.","Transportation,
Force,
Electromagnets,
Mathematical model,
Uncertainty,
Magnetic levitation"
Region-Based Object Recognition by Color Segmentation Using a Simplified PCNN,"In this paper, we propose a region-based object recognition (RBOR) method to identify objects from complex real-world scenes. First, the proposed method performs color image segmentation by a simplified pulse-coupled neural network (SPCNN) for the object model image and test image, and then conducts a region-based matching between them. Hence, we name it as RBOR with SPCNN (SPCNN-RBOR). Hereinto, the values of SPCNN parameters are automatically set by our previously proposed method in terms of each object model. In order to reduce various light intensity effects and take advantage of SPCNN high resolution on low intensities for achieving optimized color segmentation, a transformation integrating normalized Red Green Blue (RGB) with opponent color spaces is introduced. A novel image segmentation strategy is suggested to group the pixels firing synchronously throughout all the transformed channels of an image. Based on the segmentation results, a series of adaptive thresholds, which is adjustable according to the specific object model is employed to remove outlier region blobs, form potential clusters, and refine the clusters in test images. The proposed SPCNN-RBOR method overcomes the drawback of feature-based methods that inevitably includes background information into local invariant feature descriptors when keypoints locate near object boundaries. A large number of experiments have proved that the proposed SPCNN-RBOR method is robust for diverse complex variations, even under partial occlusion and highly cluttered environments. In addition, the SPCNN-RBOR method works well in not only identifying textured objects, but also in less-textured ones, which significantly outperforms the current feature-based methods.","Image color analysis,
Image segmentation,
Object recognition,
Color,
Neurons,
Feature extraction,
Robustness"
A self-optimization approach for L-SHADE incorporated with eigenvector-based crossover and successful-parent-selecting framework on CEC 2015 benchmark set,"A self-optimization approach and a new success-history based adaptive differential evolution with linear population size reduction (L-SHADE) which is incorporated with an eigenvector-based (EIG) crossover and a successful-parent-selecting (SPS) framework are proposed in this paper. The EIG crossover is a rotationally invariant operator which provides superior performance on numerical optimization problems with highly correlated variables. The SPS framework provides an alternative of the selection of parents to prevent the situation of stagnation. The proposed SPS-L-SHADE-EIG combines the L-SHADE with the EIG and SPS frameworks. To further improve the performance, the parameters of SPS-L-SHADE-EIG are self-optimized in terms of each function under IEEE Congress on Evolutionary Computation (CEC) benchmark set in 2015. The stochastic population search causes the performance of SPS-L-SHADE-EIG noisy, and therefore we deal with the noise by re-evaluating the parameters if the parameters are not updated for more than an unacceptable amount of times. The experiment evaluates the performance of the self-optimized SPS-L-SHADE-EIG in CEC 2015 real-parameter single objective optimization competition.","Sociology,
Optimization,
Covariance matrices,
Uncertainty,
Erbium,
Benchmark testing"
CCCloud: Context-Aware and Credible Cloud Service Selection Based on Subjective Assessment and Objective Assessment,"Due to the diversity and dynamic nature of cloud services, it is usually hard for potential cloud consumers to select the most suitable cloud service. This paper proposes CCCloud: a context-aware and credible cloud service selection model based on the comparison and aggregation of subjective assessments extracted from ordinary cloud consumers and objective assessments from quantitative performance testing parties. We propose a novel approach to evaluate cloud users' credibility, which not only can accurately evaluate how truthfully they assess cloud services, but also resist user collusion. In addition, in our model, objective assessments are used as benchmarks to filter out potentially biased subjective assessments, and then objective assessments and subjective assessments are aggregated to evaluate the overall performance of a cloud service. Furthermore, our model takes the contexts of objective assessments and subjective assessments into account. By calculating the similarity between different contexts, the benchmark level of objective assessments is dynamically adjusted according to context similarity, and the aggregated final scores of alternative cloud services are weighted by the similarity between the contexts of a potential cloud consumer and every testing party. This makes our cloud service selection model reflect potential cloud consumers' customized requirements more effectively. Finally, our proposed model is evaluated through the experiments conducted under different conditions. The experimental results demonstrate that our model significantly outperforms the existing work, especially in the resistance of user collusion.","Context,
Benchmark testing,
Market research,
Time factors,
Context modeling,
Monitoring"
A High Power Stress-Gradient Resilient RF MEMS Capacitive Switch,"A high power-handling radio frequency (RF) microelectromechanical systems capacitive switch with low sensitivity to both in-plane stress and stress gradients is presented. The novel switch consists of four cantilever beams, which are tied together using an optimized center joint to minimize the effects of biaxial stress and stress gradients. Dimples with a thickness of 0.3 μm are used to result in an air dielectric in the down-state position, which greatly improves the reliability, while still maintaining a measured capacitance ratio of 5. The switch is capable of handling an RF power >12 W under hot switching conditions, as well as having low sensitivity to temperature variations (~20 mV/°C for Vp). Application areas are in high power reconfigurable filters, matching networks, and tunable antennas for modern communication systems.","Switches,
Stress,
Joints,
Radio frequency,
Springs,
Structural beams,
Analytical models"
Minimizing average coflow completion time with decentralized scheduling,"In current data centers, an application (e.g. MapReduce) usually generates a collection of parallel flows sharing a common goal. These flows compose a coflow and only completing them all is meaningful. Accordingly, minimizing the average coflow completion time (CCT) becomes a critical objective for flow scheduling. In this topic, the state-of-the-art centralized method, Varys, achieves a good average CCT; but it has the scalability problem. Alternatively, the only existing decentralized method, Baraat, suffers from the head-of-line blocking problem. To solve these problems, we propose D-CAS, a preemptive, decentralized, coflow-aware scheduling system in this paper. D-CAS pursues coflow-level remaining-time-first (MRTF) principle by leveraging a simple negotiation mechanism between each coflow's data senders and receivers. As the MRTF principle is inherently preemptive and proven to be a near-optimal guideline to minimize average CCT, D-CAS avoids the head-of-line blocking problem and gets good performances. Through extensive simulations, we find that D-CAS achieves a performance close to Varys (gap <; 15%) and outperforms Baraat significantly (about 1.4-4×).",
VEGAS: Visual influEnce GrAph Summarization on Citation Networks,"Visually analyzing citation networks poses challenges to many fields of the data mining research. How can we summarize a large citation graph according to the user's interest? In particular, how can we illustrate the impact of a highly influential paper through the summarization? Can we maintain the sensory node-link graph structure while revealing the flow-based influence patterns and preserving a fine readability? The state-of-the-art influence maximization algorithms can detect the most influential node in a citation network, but fail to summarize a graph structure to account for its influence. On the other hand, existing graph summarization methods fold large graphs into clustered views, but can not reveal the hidden influence patterns underneath the citation network. In this paper, we first formally define the Influence Graph Summarization problem on citation networks. Second, we propose a matrix decomposition based algorithm pipeline to solve the IGS problem. Our method can not only highlight the flow-based influence patterns, but also easily extend to support the rich attribute information. A prototype system called VEGAS implementing this pipeline is also developed. Third, we present a theoretical analysis on our main algorithm, which is equivalent to the kernel k-mean clustering. It can be proved that the matrix decomposition based algorithm can approximate the objective of the proposed IGS problem. Last, we conduct comprehensive experiments with real-world citation networks to compare the proposed algorithm with classical graph summarization methods. Evaluation results demonstrate that our method significantly outperforms the previous ones in optimizing both the quantitative IGS objective and the quality of the visual summarizations.","Matrix decomposition,
Clustering algorithms,
Algorithm design and analysis,
Citation analysis,
Approximation algorithms"
Dynamic cell activation and user association for green 5G heterogeneous cellular networks,"The mobile traffic explosion predicted to be increased by 1000 times in the next 10 years has become a remarkable issue due to the proliferation of smart devices such as smart phones or tablets. Energy consumption of information processing is also becoming an economic issue for operators. It is a critical task to design the next generation cellular networks (5G) to be both spectral/energy efficient. This paper considers a future C-RAN based cloud cooperated HetNet which enables global resource optimization among smallcells. The architecture allows optimal user association for data offloading as well as dynamic ON/OFF of smallcell BSs in adaptation to daily data traffic. A joint optimization on both user association and dynamic ON/OFF scheme of BSs to maximizing the system rate over consumed energy of the network investigated in the paper reveals that without sacrificing the system's power resource, our proposed approach can effectively deactivate unnecessary BSs and attain the target 1000× system rate gain in the case of mm-wave smallcells.","Optimization,
Computer architecture,
Power demand,
Base stations,
Resource management,
5G mobile communication,
Heuristic algorithms"
Managing Laser Power in Silicon-Photonic NoC Through Cache and NoC Reconfiguration,"In manycore systems, the silicon-photonic link technology is projected to replace electrical link technology for global communication in network-on-chip (NoC) as it can provide as much as an order of magnitude higher bandwidth density and lower data-dependent power. However, a large amount of fixed power is dissipated in the laser sources required to drive these silicon-photonic links, which negates any bandwidth density advantages. This large laser power dissipation depends on the number of on-chip silicon-photonic links, the bandwidth of each link, and the photonic losses along each link. In this paper, we propose to reduce the laser power dissipation at runtime by dynamically activating/deactivating L2 cache banks and switching ON/OFF the corresponding silicon-photonic links in the NoC. This method effectively throttles the total on-chip NoC bandwidth at runtime according to the memory access features of the applications running on the manycore system. Full-system simulation utilizing Princeton application repository for shared-memory computers and Stanford parallel applications for shared-memory-2 parallel benchmarks reveal that our proposed technique achieves on an average 23.8% (peak value 74.3%) savings in laser power, and 9.2% (peak value 26.9%) lower energy-delay product for the whole system at the cost of 0.65% loss (peak value 2.6%) in instructions per cycle on average when compared to the cases where all L2 cache banks are always active.","Power lasers,
Photonics,
Waveguide lasers,
System-on-chip,
Optical waveguides,
Bandwidth,
Switches"
Controlled In-Plane Locomotion of a Hexapod Using a Single Actuator,"This paper presents “1STAR,” which is the first robot that is driven by a single actuator but can be directly commanded to move straight or turn clockwise or counterclockwise. The legged robot relies on a novel actuation gait, which exploits the compliance disparity between alternate stance tripods, to generate rotation by continuously accelerating and decelerating the legs. The direction of turning depends on the configuration of the legs-tripod left or right-and the timing of the acceleration and deceleration. Alternating leg acceleration in successive steps allows for continuous rotation in the desired direction. The turning radius can be varied by changing the timing of the leg acceleration and deceleration without changing the cycle frequency and linear speed. A simplified kinematic motion model of a robot is presented, and a dynamic simulation is performed to analyze the behavior and optimize robot parameters. The locomotion gait is verified experimentally using our newly designed “1STAR” robot.",
"Hessian Semi-Supervised Sparse Feature Selection Based on
L
2,1/2
-Matrix Norm","Semi-supervised sparse feature selection, which can exploit the small number labeled data and large number unlabeled data simultaneously, has become an important technique in many applications on large-scale web image owing to its high efficiency and effectiveness. Recently, graph Laplacian-based semi-supervised sparse feature selection has obtained considerable attention, but it suffers with only few labeled data because Laplacian regularization is short of extrapolating power. In this paper we propose a novel semi-supervised sparse feature selection framework based on Hessian regularization and l2,1/2- matrix norm, namely Hessian sparse feature selection based on L2,1/2- matrix norm (HFSL). Hessian regularization favors functions whose values vary linearly with respect to geodesic distance and preserves the local manifold structure well, leading to good extrapolating power to boost semi-supervised learning, and then to enhance HFSL performance. The l2,1/2-matrix norm model makes HFSL select the most discriminative sparse features with good robustness. An efficient iterative algorithm is designed to optimize the objective function. We apply our algorithm into the image annotation task and conduct extensive experiments on two web image datasets. The results demonstrate that our algorithm outperforms state-of-the-art sparse feature selection methods and is promising for large-scale web image applications.","Laplace equations,
Semisupervised learning,
Manifolds,
Educational institutions,
Information science,
Training data,
Robustness"
"A 32 kb Macro with 8T Soft Error Robust, SRAM Cell in 65-nm CMOS","A 32-kb macro containing an eight-transistor soft error robust SRAM cell with differential read and write capabilities is presented. The 8T cell does not have dedicated access transistors, and its quad-latch configuration stores data on four interlocked storage nodes. The macro was designed in a 65-nm CMOS process. The cell demonstrates excellent read data stability down to 0.55 V and is well suited for low-voltage, low-power applications. Neutron radiation testing on the macro exhibits at least 15× improvement in Failure in Time (FIT) rate compared with the conventional 6T SRAM cell in 65-nm CMOS technology.",
Performance of downlink massive MIMO in ricean fading channels with ZF precoder,"We investigate the achievable sum rate and energy efficiency of zero-forcing precoded downlink massive multiple-input multiple-output systems in Ricean fading channels. A simple and accurate approximation of the average sum rate is presented, which is valid for a system with arbitrary rank channel means. Based on this expression, the optimal power allocation strategy maximizing the average sum rate is derived. Moreover, considering a general power consumption model, the energy efficiency of the system with rank-1 channel means is characterized. Specifically, the impact of key system parameters, such as the number of users N, the number of BS antennas M, Ricean factor K and the signal-to-noise ratio (SNR) ρ are studied, and closed-form expressions for the optimal ρ and M maximizing the energy efficiency are derived. Our findings show that the optimal power allocation scheme follows the water filling principle, and it can substantially enhance the average sum rate in the presence of strong line-of-sight effect in the low SNR regime. In addition, we demonstrate that the Ricean factor K has significant impact on the optimal values of M, N and ρ.","Fading,
MIMO,
Antennas,
Signal to noise ratio,
Power demand,
Approximation methods,
Resource management"
Object classification using dictionary learning and RGB-D covariance descriptors,"In this paper, we introduce a dictionary learning framework using RGB-D covariance descriptors on point cloud data for performing object classification. Dictionary learning in combination with RGB-D covariance descriptors provides a compact and flexible description of point cloud data. Furthermore, the proposed framework is ideal for updating and sharing dictionaries among robots in a decentralized or cloud network. This work demonstrates the increased performance of 3D object classification utilizing covariance descriptors and dictionary learning over previous results with experiments performed on a publicly available RGB-D database.","Dictionaries,
Three-dimensional displays,
Visualization,
Shape,
Covariance matrices,
Databases,
Robots"
Dual Polarized Wideband Directional Coupled Sectorial Loop Antennas for Radar and Mobile Base-Station Applications,"This paper presents a new dual polarized antenna structure with matching and radiation characteristics suitable for radar and base-station applications. Two slightly different designs based on a dual polarized radiating element are presented. For radar applications, the radiating element is used to excite the two degenerate modes of a cavity with square cross-section. The resulting overall antenna size is 0.5λm × 0.5λm × 0.2λm, where λm is the free space wavelength at the minimum operating frequency. The measured results showed isolation better than 30 dB and voltage standing wave ratio (VSWR) less than 2.5 over 1-1.95 GHz as well as good radiation pattern performance. For base-station applications, the exciting element was placed in front of a metallic ground plane to increase the beamwidth. This results in a smaller antenna size (0.38λm × 0.38λm × 0.25λm) at the expense of reduced directivity. The antenna is designed to work over 1710- 2170 MHz which covers three common frequency bands of mobile radio application. The measured results showed return loss better than 14 dB over the operating band and more than 30 dB polarization isolation.","Cavity resonators,
Radar antennas,
Feeds,
Bandwidth,
Slot antennas,
Base stations"
Kernelized Relaxed Margin Components Analysis for Person Re-identification,"Person re-identification across disjoint camera views plays a significant role in video surveillance. Several margin-based metric learning algorithms have recently been proposed to learn an optimal metric, with the goal that samples of the same person always belong to the same class while those from different classes are separated by a large margin. These approaches require no modification or extension in order to solve problems of multiple (as opposed to binary) classification. However, the formation of the margin in these methods is not scalable, and thus cannot adequately use inter-class information according to the relevant practical application. To address this issue, we propose a novel algorithm called Relaxed Margin Components Analysis (RMCA) to “relax” the margin constraint. Furthermore, we equip our RMCA with a kernel function to form a Kernelized RMCA (KRMCA) to learn non-linear distance metrics in order to further improve re-identification accuracy. Promising results from experiments on several public datasets demonstrate the effectiveness of our method.",
A networked swarm model for UAV deployment in the assessment of forest environments,"Autonomous Unmanned Aerial Vehicles (UAVs) have gained popularity due to their many potential application fields. Alongside sophisticated sensors, UAVs can be equipped with communication adaptors aimed for inter-UAV communication. Inter-communication of UAVs to form a UAV swarm raises questions on how to manage its communication structure and mobility. In this paper, we consider therefore the problem of establishing an efficient swarm movement model and a network topology between a collection of UAVs, which are specifically deployed for the scenario of high-quality forest-mapping. The forest environment with its highly heterogeneous distribution of trees and obstacles represents an extreme challenge for a UAV swarm. It requires the swarm to constantly avoid possible collisions with trees, to change autonomously the trajectory, which can lead to disconnection to the swarm, and to reconnect to the swarm after passing the obstacle, while continue collecting environmental data that needs to be fused and assessed efficiently. In this paper, we propose a novel solution to the formation flight problem for UAV swarms. The proposed method provides an adaptive and reliable network structure, which maintains swarm connectivity and communicability. These characteristics are needed to achieve a detailed and accurate description of the environment from the data acquired by the UAV swarm. The main characteristics of our approach are high scalability regarding the number of UAVs in the swarm and the adaptive network topology within the swarm.","Vegetation,
Network topology,
Communication networks,
Base stations,
Adaptive systems,
Navigation,
Nominations and elections"
Response Time Based Optimal Web Service Selection,"Selecting an optimal web service among a list of functionally equivalent web services still remains a challenging issue. For Internet services, the presence of low-performance servers, high latency or overall poor service quality can translate into lost sales, user frustration, and customers lost. In this paper, we propose a novel method for QoS metrification based on Hidden Markov Models (HMM), which further suggests an optimal path for the execution of user requests. The technique we show can be used to measure and predict the behavior of Web Services in terms of response time, and can thus be used to rank services quantitatively rather than just qualitatively. We demonstrate the feasibility and usefulness of our methodology by drawing experiments on real world data. The results have shown how our proposed method can help the user to automatically select the most reliable Web Service taking into account several metrics, among them, system predictability and response time variability. Later ROC curve shows a 12 percent improvement in prediction accuracy using HMM.","Web services,
Hidden Markov models,
Time factors,
Quality of service,
Computational modeling,
Delays,
Probabilistic logic"
Persim 3D: Context-Driven Simulation and Modeling of Human Activities in Smart Spaces,"Automated understanding and recognition of human activities and behaviors in a smart space (e.g., smart house) is of paramount importance to many critical human-centered applications. Recognized activities are the input to the pervasive computer (the smart space) which intelligently interacts with the users to maintain the application's goal be it assistance, safety, child-development, entertainment or other goals. Research in this area is fascinating but severely lacks adequate validation which often relies on datasets that contain sensory data representing the activities. Availing adequate datasets that can be used in a large variety of spaces, for different user groups, and aiming at different goals is very challenging. This is due to the prohibitive cost and the human capital needed to instrument physical spaces and to recruit human subjects to perform the activities and generate data. Simulation of human activities in smart spaces has therefore emerged as an alternative approach to bridge this deficit. Traditional event-driven approaches have been proposed. However, the complexity of human activity simulation was proved to be challenging to these initial simulation efforts. In this paper, we present Persim 3D-an alternative context-driven approach to simulating human activities capable of supporting complex activity scenarios. We present the context-activity-action nexus and show how our approach combines modeling and visualization of actions with context and activity simulation. We present the Persim 3D architecture and algorithms, and describe a detailed validation study of our approach to verify the accuracy and realism of the simulation output (datasets and visualizations) and the scalability of the human effort in using Persim 3D to simulate complex scenarios. We show positive and promising results that validate our approach.",
Cost-Minimizing Dynamic Migration of Content Distribution Services into Hybrid Clouds,"With the recent advent of cloud computing technologies, a growing number of content distribution applications are contemplating a switch to cloud-based services, for better scalability and lower cost. Two key tasks are involved for such a move: to migrate the contents to cloud storage, and to distribute the Web service load to cloud-based Web services. The main issue is to best utilize the cloud as well as the application provider's existing private cloud, to serve volatile requests with service response time guarantee at all times, while incurring the minimum operational cost. While it may not be too difficult to design a simple heuristic, proposing one with guaranteed cost optimality over a long run of the system constitutes an intimidating challenge. Employing Lyapunov optimization techniques, we design a dynamic control algorithm to optimally place contents and dispatch requests in a hybrid cloud infrastructure spanning geo-distributed data centers, which minimizes overall operational cost overtime, subject to service response time constraints. Rigorous analysis shows that the algorithm nicely bounds the response times within the preset QoS target, and guarantees that the overall cost is within a small constant gap from the optimum achieved by a T-slot lookahead mechanism with known future information. We verify the performance of our dynamic algorithm with prototype-based evaluation.","Cloud computing,
Heuristic algorithms,
Content management,
Algorithm design and analysis,
Bandwidth,
Servers"
A Single-Chip 32-Channel Analog Beamformer With 4-ns Delay Resolution and 768-ns Maximum Delay Range for Ultrasound Medical Imaging With a Linear Array Transducer,"A single-chip 32-channel analog beamformer is proposed. It achieves a delay resolution of 4 ns and a maximum delay range of 768 ns. It has a focal-point based architecture, which consists of 7 sub-analog beamformers (sub-ABF). Each sub-ABF performs a RX focusing operation for a single focal point. Seven sub-ABFs perform a time-interleaving operation to achieve the maximum delay range of 768 ns. Phase interpolators are used in sub-ABFs to generate sampling clocks with the delay resolution of 4 ns from a low frequency system clock of 5 MHz. Each sub-ABF samples 32 echo signals at different times into sampling capacitors, which work as analog memory cells. The sampled 32 echo signals of each sub-ABF are originated from one target focal point at one instance. They are summed at one instance in a sub-ABF to perform the RX focusing for the target focal point. The proposed ABF chip has been fabricated in a 0.13- μm CMOS process with an active area of 16 mm 2. The total power consumption is 287 mW. In measurement, the digital echo signals from a commercial ultrasound medical imaging machine were applied to the fabricated chip through commercial DAC chips. Due to the speed limitation of the DAC chips, the delay resolution was relaxed to 10 ns for the real-time measurement. A linear array transducer with no steering operation is used in this work.","Delays,
Transducers,
Focusing,
Ultrasonic imaging,
Clocks,
Radiation detectors,
Signal resolution"
Augmented Reality 3D Displays With Micro Integral Imaging,"In this paper, we present a 3D augmented reality micro integral imaging display system by combining conventional integral imaging and an augmented reality technique. Compared with conventional integral imaging, our proposed system has two advantages: 1) it provides 3D augmented reality display capability and 2) it has a compact design. To validate the feasibility of our proposed method, we experimented with a 3D scene and used two computer-generated objects for augmented reality. By combining the captured 2D elemental images of the 3D object and the computer generated virtual objects, we reconstruct 3D images for the augmented reality micro integral imaging display system. To the best of our knowledge, the first report on a video see through 3D augmented reality display has been experimentally demonstrated with a micro integral imaging display system. The proposed 3D system has potential to be applied to the head mounted display system due to its small form factor.",
MRDataCube: Data cube computation using MapReduce,"Data cube is used as an OLAP (On-Line Analytical Processing) model to implement multidimensional analyses in many fields of application. Computing a data cube requires a long sequence of basic operations and storage costs. Exponentially accumulating amounts of data have reached a magnitude that overwhelms the processing capacities of single computers. In this paper, we implement a large-scale data cube computation based on distributed parallel computing using the MapReduce (MR) computational framework. For this purpose, we developed a new algorithm, MRDataCube, which incorporates the MR mechanism into data cube computations such that effective data cube computations are enabled even when using the same computing resources. The proposed MRDataCube consists of two-level MR phases, namely, MRSpread and MRAssemble. The main feature of this algorithm is a continuous data reduction through the combination of partial cuboids and partial cells that are emitted when the computation undergoes these two phases. From the experimental results we revealed that MRDataCube outperforms all other algorithms.",
Deadline constrained cloud computing resources scheduling for cost optimization based on dynamic objective genetic algorithm,"Cloud computing resources scheduling is significant for executing the workflows in cloud platform because it relates to both the execution time and execution cost. In order to take both the time and cost into consideration, Rodriguez and Buyya have proposed a cost-minimization and deadline-constrained workflow scheduling model on cloud computing. Their model has great applicability but the solution of their particle swarm optimization (PSO) approach is not good enough and cannot meet a tight deadline condition. In this paper, we propose a genetic algorithm (GA) approach to solve this model. In order to tackle with the tight deadline condition, a dynamic objective strategy is further proposed to let GA focus on optimize the execution time objective to meet the deadline constraint when the feasible solution hasn't been obtained. After obtaining a feasible solution, the GA focuses on optimizing the execution cost within the deadline constraint. Therefore, the proposed dynamic objective GA (DOGA) has adaptive ability to the search environment to different objectives. We have conduct extensive experiments based on workflows with different scales and different cloud resources. Experimental results show that DOGA can find better solution with smaller cost than PSO does on different scheduling scales and different deadline conditions. DOGA approach is more applicable to be used in commercial activities.","Computational modeling,
Biological cells"
Reflectance hashing for material recognition,"We introduce a novel method for using reflectance to identify materials. Reflectance offers a unique signature of the material but is challenging to measure and use for recognizing materials due to its high-dimensionality. In this work, one-shot reflectance of a material surface which we refer to as a reflectance disk is capturing using a unique optical camera. The pixel coordinates of these reflectance disks correspond to the surface viewing angles. The reflectance has class-specific stucture and angular gradients computed in this reflectance space reveal the material class. These reflectance disks encode discriminative information for efficient and accurate material recognition. We introduce a framework called reflectance hashing that models the reflectance disks with dictionary learning and binary hashing. We demonstrate the effectiveness of reflectance hashing for material recognition with a number of real-world materials.",
Efficient illuminant estimation for color constancy using grey pixels,"Illuminant estimation is a key step for computational color constancy. Instead of using the grey world or grey edge assumptions, we propose in this paper a novel method for illuminant estimation by using the information of grey pixels detected in a given color-biased image. The underlying hypothesis is that most of the natural images include some detectable pixels that are at least approximately grey, which can be reliably utilized for illuminant estimation. We first validate our assumption through comprehensive statistical evaluation on diverse collection of datasets and then put forward a novel grey pixel detection method based on the illuminant-invariant measure (IIM) in three logarithmic color channels. Then the light source color of a scene can be easily estimated from the detected grey pixels. Experimental results on four benchmark datasets (three recorded under single illuminant and one under multiple illuminants) show that the proposed method outperforms most of the state-of-the-art color constancy approaches with the inherent merit of low computational cost.","Image color analysis,
Estimation,
Indexes,
Light sources,
Image edge detection,
Benchmark testing,
Standards"
Joint Workload and Battery Scheduling with Heterogeneous Service Delay Guaranteesfor Data Center Energy Cost Minimization,"In this paper, we investigate the problem of minimizing the long-term energy cost for an Internet data center (IDC) in deregulated electricity markets. Specifically, IDC operators intend to minimize energy cost by scheduling workload and battery jointly, which can fully exploit the temporal diversity of electricity price. First, we formulate a stochastic optimization problem taking heterogeneous service delay guarantees and battery management into account. Then, we design an online operation algorithm to solve the problem based on Lyapunov optimization technique. Meanwhile, we analyze the feasibility and performance guarantee of the proposed algorithm. Finally, extensive simulation results based on real-world data show the effectiveness of the proposed algorithm.","Batteries,
Delays,
Electricity,
Optimization,
Algorithm design and analysis,
Electricity supply industry,
Energy states"
A proposal of interaction system between visitor and collection in museum hall by iBeacon,"Beacon is an in door positioning system provided by Apple based on BLE (Bluetooth Low Energy) technology. Smart devices, such as iPhone or Android phone can detect advertising signals sent by the low energy consumption tiny device. Notifications will be pushed automatically to the user when smart device with iBeacon Apps come to certain areas. It provides promising and portfolio usage scenarios for business, such as retail stores, to push related information about customers' interested items with the awareness of customers' location. This technology also can be used in museum scenario. In this research, we described the principle of iBeacon, and addressed a design of interaction system between visitors and collections supported by iBeacon technology.","Advertising,
History,
Bluetooth,
Energy consumption,
Standards,
Smart phones"
Sizing Energy Storage to Mitigate Wind Power Forecast Error Impacts by Signal Processing Techniques,"This paper proposes to use discrete Fourier transform (DFT) and discrete wavelet transform (DWT) methods to schedule grid-scale energy storage systems to mitigate wind power forecast error impacts while considering energy storage properties. This is accomplished by decomposing the wind forecast error signal to different time-varying periodic components to schedule sodium sulfur (NaS) batteries, compressed air energy storage (CAES), and conventional generators. The advantage of signal processing techniques is that the resultant decomposed components are appropriate for cycling of each energy storage technology. It is also beneficial for conventional generators, which are more efficient to operate close to rated capacity. The tradeoff between installing more energy storage units and decreasing the wind spillage, back-up energy, and the standard deviation of residual forecast error signal is analyzed. The NaS battery life cycle analysis and CAES contribution on increasing NaS battery lifetime are studied. The impact of considering the frequency bias constant to allow small frequency deviations is also investigated. To showcase the applicability of the proposed approach, a simulation case study based on a real-world 5-min interval wind data from Bonneville Power Administration (BPA) in 2013 is presented.","Wind forecasting,
Wind power generation,
Discrete wavelet transforms,
Energy storage,
Discrete Fourier transforms"
AYUSH: A Technique for Extending Lifetime of SRAM-NVM Hybrid Caches,"Recently, researchers have explored way-based hybrid SRAM-NVM (non-volatile memory) last level caches (LLCs) to bring the best of SRAM and NVM together. However, the limited write endurance of NVMs restricts the lifetime of these hybrid caches. We present AYUSH, a technique to enhance the lifetime of hybrid caches, which works by using data-migration to preferentially use SRAM for storing frequently-reused data. Microarchitectural simulations confirm that AYUSH achieves larger improvement in lifetime than a previous technique and also maintains performance and energy efficiency. For single, dual and quad-core workloads, the average increase in cache lifetime with AYUSH is 6.90, 24.06 and 47.62×, respectively.","Random access memory,
Nonvolatile memory,
Benchmark testing,
Energy loss,
Cache memory,
Radiation detectors,
SRAM"
Accurate Segmentation of Partially Overlapping Cervical Cells Based on Dynamic Sparse Contour Searching and GVF Snake Model,"Overlapping cells segmentation is one of the challenging topics in medical image processing. In this paper, we propose to approximately represent the cell contour as a set of sparse contour points, which can be further partitioned into two parts: the strong contour points and the weak contour points. We consider the cell contour extraction as a contour points locating problem and propose an effective and robust framework for segmentation of partially overlapping cells in cervical smear images. First, the cell nucleus and the background are extracted by a morphological filtering-based K-means clustering algorithm. Second, a gradient decomposition-based edge enhancement method is developed for enhancing the true edges belonging to the center cell. Then, a dynamic sparse contour searching algorithm is proposed to gradually locate the weak contour points in the cell overlapping regions based on the strong contour points. This algorithm involves the least squares estimation and a dynamic searching principle, and is thus effective to cope with the cell overlapping problem. Using the located contour points, the Gradient Vector Flow Snake model is finally employed to extract the accurate cell contour. Experiments have been performed on two cervical smear image datasets containing both single cells and partially overlapping cells. The high accuracy of the cell contour extraction result validates the effectiveness of the proposed method.","Image segmentation,
Image edge detection,
Filtering,
Clustering algorithms,
Heuristic algorithms,
Shape,
Histograms"
Unifying Two Views on Multiple Mean-Payoff Objectives in Markov Decision Processes,"We consider Markov decision processes (MDPs) with multiple limit-average (or mean-payoff) objectives. There exist two different views: (i) the expectation semantics, where the goal is to optimize the expected mean-payoff objective, and (ii) the satisfaction semantics, where the goal is to maximize the probability of runs such that the mean-payoff value stays above a given vector. We consider optimization with respect to both objectives at once, thus unifying the existing semantics. Precisely, the goal is to optimize the expectation while ensuring the satisfaction constraint. Our problem captures the notion of optimization with respect to strategies that are risk-averse (i.e., ensure certain probabilistic guarantee). Our main results are as follows: First, we present algorithms for the decision problems, which are always polynomial in the size of the MDP. We also show that an approximation of the Pareto curve can be computed in time polynomial in the size of the MDP, and the approximation factor, but exponential in the number of dimensions. Second, we present a complete characterization of the strategy complexity (in terms of memory bounds and randomization) required to solve our problem.",
Accelerate RDP RAID-6 Scaling by Reducing Disk I/Os and XOR Operations,"Disk additions to an RAID-6 storage system can increase the I/O parallelism and expand the storage capacity simultaneously. To regain load balance among all disks including old and new, RAID-6 scaling requires moving certain data blocks onto newly added disks. Existing approaches to RAID-6 scaling, restricted by preserving a round-robin data distribution, require migrating all the data, which results in an expensive cost for RAID-6 scaling. In this paper, we propose RS6-a new approach to accelerating RDP RAID-6 scaling by reducing disk I/Os and XOR operations. First, RS6 minimizes the number of data blocks to be moved while maintaining a uniform data distribution across all data disks. Second, RS6 piggybacks parity updates during data migration to reduce the cost of maintaining consistent parities. Third, RS6 selects parameters of data migration so as to reduce disk I/Os for parity updates. Our mathematical analysis indicates that RS6 provides uniform data distribution, minimal data migration, and fast data addressing. We also conducted extensive simulation experiments to quantitatively characterize the properties of RS6. The results show that, compared with existing “moving-everything” Round-Robin approaches, RS6 reduces the number of blocks to be moved by 60.0%-88.9%, and saves the migration time by 40.27%-69.88%.","Arrays,
Nickel,
Acceleration,
Layout,
Servers,
Calculators,
Writing"
Robust counterfeit PCB detection exploiting intrinsic trace impedance variations,"The long and distributed supply chain of printed circuit boards (PCBs) makes them vulnerable to different forms of counterfeiting attacks. Existing chip-level integrity validation approaches cannot be readily extended to PCB. In this paper, we address this issue with a novel PCB authentication approach that creates robust, unique signatures from a PCB based on process-induced variations in its trace impedances. The approach comes at virtually zero design and hardware overhead and can be applied to legacy PCBs. Experiments with two sets of commercial PCBs as well as a set of custom designed PCBs show that the proposed approach can obtain unique authentication signature with inter-PCB hamming distance of 47.94% or higher.","Impedance,
Authentication,
Impedance measurement,
High definition video,
Copper,
Electrical resistance measurement,
Probes"
Wind Power Dispatch Margin for Flexible Energy and Reserve Scheduling With Increased Wind Generation,"With the significant penetration of wind generation, the variability and uncertainty of wind energy poses new challenges to power system operations. In particular, more rapid reserve is required, which may result in the scarcity of balancing services. With the increasing penetration of renewable generation, it is envisaged that renewable resources will be required to partake in the system balancing tasks. In this paper, a combined flexible dispatch and reserve scheduling policy is proposed by determining a flexible wind dispatch margin. In order to provide a flexible dispatch margin, wind generators underschedule in the hour-ahead energy market, so as to hold some expected output for reserves. Additional wind energy is then available for mitigating forecast errors and other system uncertainties. This paper presents a framework to find the optimal policy to incorporate the flexible wind dispatch margin into the hour-ahead market. A finite-state Markov chain wind power forecast model, based on spatio-temporal analysis, is utilized. The presented framework is used to find the appropriate level of wind dispatch margin. The proposed approach is tested and the wind generation data are used to analyze the effectiveness of the presented model in coping with forecast errors and achieving a more secure system operation.","Wind forecasting,
Wind power generation,
Power generation economics,
Wind energy generation,
Power generation dispatch,
Power system reliability"
Order Preserving Sparse Coding,"In this paper, we investigate order-preserving sparse coding for classifying structured data whose atomic features possess ordering relationships. Examples include time sequences where individual frame-wise features are temporally ordered, as well as still images (landscape, street view, etc.) where different regions of the image are spatially ordered. Classification of these structured data is often tackled by first decomposing the input data into individual atomic features, then performing sparse coding or other processing for each atomic feature vector independently, and finally aggregating individual responses to classify the input data. However, this heuristic approach ignores the underlying order of the individual atomic features within the input data, and results in suboptimal discriminative capability. In this work, we introduce an order preserving regularizer which aims to preserve the ordering structure of the reconstruction coefficients within the sparse coding framework. An efficient Nesterov-type smooth approximation method is developed for optimization of the new regularization criterion, with theoretically guaranteed error bound. We perform extensive experiments for time series classification on a synthetic dataset, several machine learning benchmarks, and an RGB-D human activity dataset. We also report experiments for scene classification on a benchmark image dataset. The encoded representation is discriminative and robust, and our classifier outperforms state-of-the-art methods on these tasks.",
Combining Relevance Language Modeling and Clarity Measure for Extractive Speech Summarization,"Extractive speech summarization, which purports to select an indicative set of sentences from a spoken document so as to succinctly represent the most important aspects of the document, has garnered much research over the years. In this paper, we cast extractive speech summarization as an ad-hoc information retrieval (IR) problem and investigate various language modeling (LM) methods for important sentence selection. The main contributions of this paper are four-fold. First, we explore a novel sentence modeling paradigm built on top of the notion of relevance, where the relationship between a candidate summary sentence and a spoken document to be summarized is discovered through different granularities of context for relevance modeling. Second, not only lexical but also topical cues inherent in the spoken document are exploited for sentence modeling. Third, we propose a novel clarity measure for use in important sentence selection, which can help quantify the thematic specificity of each individual sentence that is deemed to be a crucial indicator orthogonal to the relevance measure provided by the LM-based methods. Fourth, in an attempt to lessen summarization performance degradation caused by imperfect speech recognition, we investigate making use of different levels of index features for LM-based sentence modeling, including words, subword-level units, and their combination. Experiments on broadcast news summarization seem to demonstrate the performance merits of our methods when compared to several existing well-developed and/or state-of-the-art methods.",
RC-MAC: A Receiver-Centric MAC Protocol for Event-Driven Wireless Sensor Networks,"Event-driven wireless sensor networks (WSNs) usually operate under light traffic load. However, when an event is detected, a large number of packets may be generated. A MAC protocol designed for this kind of WSNs should be able to swiftly adapt to the two conditions. Most WSN MAC protocols are optimized for light traffic for the energy efficiency consideration. In this paper, we propose a novel receiver-centric MAC protocol called RC-MAC that seamlessly integrates duty cycling and receiver-centric scheduling, providing high throughput without sacrificing the energy efficiency. To handle bursty traffic triggered by an event, RC-MAC takes advantage of the underlying data gathering tree structure of WSNs and the multichannel technique supported by current IEEE 802.15.4 RF transceivers to assist scheduling of medium access. The throughput is improved in two phases with receiver-centric medium access scheduling and distributed channel assignment. First, on a data gathering tree, a receiver is able to coordinate the medium access of multiple senders so as to reduce collisions and achieve high throughput. Second, different receivers coordinate their senders in different channels and the throughput is further improved by allowing parallel data gathering. Observing packet processing time on low cost sensor nodes, we design a scheduling pattern that ensures fairness between source nodes without sacrificing the throughput. We evaluate the performance of our RC-MAC through measurements of an implementation in TinyOS on TelosB motes and extensive ns-2 simulations. Compared with contention-based and scheduling-based MAC protocols, we show that the throughput and the fairness under heavy traffic load are significantly improved by the receiver-centric scheduling. Due to the high throughput, the energy efficiency is also improved.",
