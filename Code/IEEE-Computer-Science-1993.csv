Title,Abstract,Keywords
Comparing images using the Hausdorff distance,"The Hausdorff distance measures the extent to which each point of a model set lies near some point of an image set and vice versa. Thus, this distance can be used to determine the degree of resemblance between two objects that are superimposed on one another. Efficient algorithms for computing the Hausdorff distance between all possible relative positions of a binary image and a model are presented. The focus is primarily on the case in which the model is only allowed to translate with respect to the image. The techniques are extended to rigid motion. The Hausdorff distance computation differs from many other shape comparison methods in that no correspondence between the model and the image is derived. The method is quite tolerant of small position errors such as those that occur with edge detectors and other feature extraction methods. It is shown that the method extends naturally to the problem of comparing a portion of a model against an image.","Shape,
Image edge detection,
Pattern recognition,
Detectors,
Feature extraction,
Computer vision,
Pattern matching,
Councils,
Scholarships,
Computer science"
Vague sets,"A vague set is a set of objects, each of which has a grade of membership whose value is a continuous subinterval of","Fuzzy sets,
Upper bound,
TV,
Computer science"
RSVP: a new resource ReSerVation Protocol,"A resource reservation protocol (RSVP), a flexible and scalable receiver-oriented simplex protocol, is described. RSVP provides receiver-initiated reservations to accommodate heterogeneity among receivers as well as dynamic membership changes; separates the filters from the reservation, thus allowing channel changing behavior; supports a dynamic and robust multipoint-to-multipoint communication model by taking a soft-state approach in maintaining resource reservations; and decouples the reservation and routing functions. A simple network configuration with five hosts connected by seven point-to-point links and three switches is presented to illustrate how RSVP works. Related work and unresolved issues are discussed.","Protocols,
Quality of service,
Routing,
Web and internet services,
Telecommunication traffic,
Computer science,
Proposals,
Unicast,
Computer architecture,
Application software"
Transactional Memory: Architectural Support For Lock-free Data Structures,,"Data structures,
System recovery,
Programming profession,
Laboratories,
Computer science,
Protocols,
Software performance,
Computer architecture,
Read-write memory,
Registers"
Switching regression models and fuzzy clustering,"A family of objective functions called fuzzy c-regression models, which can be used too fit switching regression models to certain types of mixed data, is presented. Minimization of particular objective functions in the family yields simultaneous estimates for the parameters of c regression models, together with a fuzzy c-partitioning of the data. A general optimization approach for the family of objective functions is given and corresponding theoretical convergence results are discussed. The approach is illustrated by two numerical examples that show how it can be used to fit mixed data to coupled linear and nonlinear models.","Parameter estimation,
Clustering algorithms,
Fuzzy sets,
Covariance matrix,
Computer science,
Linear approximation,
Marine animals,
Yield estimation,
Convergence,
Couplings"
"Pricing in computer networks: motivation, formulation, and example","The role of pricing policies in multiple service class networks is studied. An abstract formulation of service disciplines and pricing policies that allows the interplay between service disciplines and pricing policies in determining overall network performance to be described more clearly is presented. Effective multiclass service disciplines allow networks to focus resources on performance-sensitive applications, while effective pricing policies allows the benefits of multiple service classes to be spread around to all users. Furthermore, the incentives formed by service disciplines and pricing policies must be carefully tuned so that user self-interest leads to optimal overall network performance. These concepts are illustrated through simulation of several simple example networks. It is found that it is possible to set the prices so that users of every application type are more satisfied with the combined cost and performance of a network with service-class-sensitive prices.","Pricing,
Intelligent networks,
Computer networks,
Computer science,
Scheduling algorithm,
Roads,
Telecommunication traffic,
Costs,
Application software,
Hardware"
Elastic bands: connecting path planning and control,"Elastic bands are proposed as the basis for a framework to close the gap between global path planning and real-time sensor-based robot control. An elastic band is a deformable collision-free path. The initial shape of the elastic is the free path generated by a planner. Subjected to artificial forces, the elastic band deforms in real time to a short and smooth path that maintains clearance from the obstacles. The elastic continues to deform as changes in the environment are detected by sensors, enabling the robot to accommodate uncertainties and react to unexpected and moving obstacles. While providing a tight connection between the robot and its environment, the elastic band preserves the global nature of the planned path. The framework is outlined, and an efficient implementation based on bubbles is discussed.",
Generalized clustering networks and Kohonen's self-organizing scheme,"The relationship between the sequential hard c-means (SHCM) and learning vector quantization (LVQ) clustering algorithms is discussed. The impact and interaction of these two families of methods with Kohonen's self-organizing feature mapping (SOFM), which is not a clustering method but often lends ideas to clustering algorithms, are considered. A generalization of LVQ that updates all nodes for a given input vector is proposed. The network attempts to find a minimum of a well-defined objective function. The learning rules depend on the degree of distance match to the winner node; the lesser the degree of match with the winner, the greater the impact on nonwinner nodes. Numerical results indicate that the terminal prototypes generated by this modification of LVQ are generally insensitive to initialization and independent of any choice of learning coefficient. IRIS data obtained by E. Anderson's (1939) is used to illustrate the proposed method. Results are compared with the standard LVQ approach.","Clustering algorithms,
Prototypes,
Vector quantization,
Computer science,
Two dimensional displays,
Algorithm design and analysis,
Clustering methods,
Iris,
Neural networks,
Computer displays"
An exact solution to the transistor sizing problem for CMOS circuits using convex optimization,"A general sequential circuit consists of a number of combinational stages that lie between latches. For the circuit to meet a given clocking specification, it is necessary for each combinational stage to satisfy a certain delay requirement. Roughly speaking, increasing the sizes of some transistors in a stage reduces the delay, with the penalty of increased area. The problem of transistor sizing is to minimize the area of a combinational stage, subject to its delay being less than a given specification. Although this problem has been recognized as a convex programming problem, most existing approaches do not take full advantage of this fact, and often give nonoptimal results. An efficient convex optimization algorithm has been used here. This algorithm is guaranteed to find the exact solution to the convex programming problem. We have also improved upon existing methods for computing the circuit delay as an Elmore time constant, to achieve higher accuracy, CMOS circuit examples, including a combinational circuit with 832 transistors are presented to demonstrate the efficacy of the new algorithm.",
Correction of intensity variations in MR images for computer-aided tissue classification,"A number of supervised and unsupervised pattern recognition techniques have been proposed in recent years for the segmentation and the quantitative analysis of MR images. However, the efficacy of these techniques is affected by acquisition artifacts such as inter-slice, intra-slice, and inter-patient intensity variations. Here a new approach to the correction of intra-slice intensity variations is presented. Results demonstrate that the correction process enhances the performance of backpropagation neural network classifiers designed for the segmentation of the images. Two slightly different versions of the method are presented. The first version fits an intensity correction surface directly to reference points selected by the user in the images. The second version fits the surface to reference points obtained by an intermediate classification operation. Qualitative and quantitative evaluation of both methods reveals that the first one leads to a better correction of the images than the second but that it is more sensitive to operator errors.","Neoplasms,
Magnetic resonance imaging,
Image segmentation,
Size measurement,
Alzheimer's disease,
Degenerative diseases,
Robustness,
Ultrasonic imaging,
Image recognition,
Image analysis"
Perfect hash functions made parallel-Lazy functional programming on a distributed multiprocessor,"A programming technique for efficient parallel search is described. The authors study a search problem for which a heuristic preprocess makes sequential execution feasible. Two key questions are addressed. (1) How can this algorithm, optimized for sequential execution, be programmed in parallel to produce significant speedup? (2) how can this be done in a purely functional language without compromising either conciseness or referential transparency? The authors describe programming techniques for efficient parallel search in a lazy and pure functional language. These techniques are applied to an illustrative example. Results of execution on a real parallel machine are given.","Functional programming,
Parallel programming,
Parallel machines,
Parallel processing,
Concurrent computing,
Computer science,
Search problems"
Parallel computations on reconfigurable meshes,"The mesh with reconfigurable bus is presented as a model of computation. The reconfigurable mesh captures salient features from a variety of sources, including the CAAPP, CHiP, polymorphic-torus network, and bus automation. It consists of an array of processors interconnected by a reconfigurable bus system that can be used to dynamically obtain various interconnection patterns between the processors. A variety of fundamental data-movement operations for the reconfigurable mesh are introduced. Based on these operations, algorithms that are efficient for solving a variety of problems involving graphs and digitized images are also introduced. The algorithms are asymptotically superior to those previously obtained for the aforementioned reconfigurable architectures, as well as to those previously obtained for the mesh, the mesh with multiple broadcasting, the mesh with multiple buses, the mesh-of-trees, and the pyramid computer. The power of reconfigurability is illustrated by solving some problems, such as the exclusive OR, more efficiently on the reconfigurable mesh than is possible on the programmable random-access memory (PRAM).","Concurrent computing,
Broadcasting,
Computational modeling,
Phase change random access memory,
Laboratories,
Computer science,
Computer networks,
Automata,
Reconfigurable architectures,
Parallel algorithms"
Automatic detection of brain contours in MRI data sets,"A software procedure is presented for fully automated detection of brain contours from single-echo 3-D MRI data, developed initially for scans with coronal orientation. The procedure detects structures in a head data volume in a hierarchical fashion. Automatic detection starts with a histogram-based thresholding step, whenever necessary preceded by an image intensity correction procedure. This step is followed by a morphological procedure which refines the binary threshold mask images. Anatomical knowledge, essential for the discrimination between desired and undesired structures, is implemented in this step through a sequence of conventional and novel morphological operations, using 2-D and 3-D operations. A final step of the procedure performs overlap tests on candidate brain regions of interest in neighboring slice images to propagate coherent 2-D brain masks through the third dimension. Results are presented for test runs of the procedure on 23 coronal whole-brain data sets, and one sagittal whole-brain data set. Finally, the potential of the technique for generalization to other problems is discussed, as well as limitations of the technique.","Magnetic resonance imaging,
Image segmentation,
Rendering (computer graphics),
Biomedical imaging,
Testing,
Automation,
Magnetic heads,
Morphological operations,
Performance evaluation,
Image analysis"
Spatial reasoning for the automatic recognition of machinable features in solid models,"Discusses an automatic feature recognizer that decomposes the total volume to be machined into volumetric features that satisfy stringent conditions for manufacturability, and correspond to operations typically performed in 3-axis machining centers. Unlike most of the previous research, the approach is based on general techniques for dealing with features with intersecting volumes. Feature interactions are represented explicitly in the recognizer's output, to facilitate spatial reasoning in subsequent planning stages. A generate-and-test strategy is used. OPS-5 production rules generate hints or clues for the existence of features, and post them on a blackboard. The clues are assessed, and those judged promising are processed to ensure that they correspond to actual features, and to gather information for process planning. Computational geometry techniques are used to produce the largest volumetric feature compatible with the available data. The feature's accessibility, and its interactions with others are analyzed. The validity tests ensure that the proposed features are accessible, do not intrude into the desired part, and satisfy other machinability conditions. The process continues until it produces a complete decomposition of the volume to be machined into fully-specified features.",
Protecting poorly chosen secrets from guessing attacks,"In a security system that allows people to choose their own passwords, people tend to choose passwords that can be easily guessed. This weakness exists in practically all widely used systems. Instead of forcing users to choose secrets that are likely to be difficult for them to remember, solutions that maintain user convenience and a high level of security at the same time are proposed. The basic idea is to ensure that data available to the attacker is sufficiently unpredictable to prevent an offline verification of whether a guess is successful or not. Common forms of guessing attacks are examined, examples of cryptographic protocols that are immune to such attacks are developed, and a systematic way to examine protocols to detect vulnerabilities to such attacks is suggested.","Protection,
Cryptography,
Laboratories,
Cryptographic protocols,
Computer science,
Data security,
Information security,
Operating systems,
Authentication,
Dictionaries"
An experimental comparison of the effectiveness of branch testing and data flow testing,"An experiment comparing the effectiveness of the all-uses and all-edges test data adequacy criteria is discussed. The experiment was designed to overcome some of the deficiencies of previous software testing experiments. A large number of test sets was randomly generated for each of nine subject programs with subtle errors. For each test set, the percentages of executable edges and definition-use associations covered were measured, and it was determined whether the test set exposed an error. Hypothesis testing was used to investigate whether all-uses adequate test sets are more likely to expose errors than are all-edges adequate test sets. Logistic regression analysis was used to investigate whether the probability that a test set exposes an error increases as the percentage of definition-use associations or edges covered by it increases. Error exposing ability was shown to be strongly positively correlated to percentage of covered definition-use associations in only four of the nine subjects. Error exposing ability was also shown to be positively correlated to the percentage of covered edges in four different subjects, but the relationship was weaker.","Software testing,
Data analysis,
Computer science,
Performance evaluation,
Random number generation,
Logistics,
Regression analysis,
Genetic mutations,
Acoustic testing,
Error correction"
A reduced-area scheme for carry-select adders,"The carry-select or conditional-sum adders require carry-chain evaluations for each block for both the values of block-carry-in, 0 and 1. The author introduces a scheme to generate carry bits with block-carry-in 1 from the carries of a block with block-carry-in 0. This scheme is then applied to carry-select and parallel-prefix adders to derive a more area-efficient implementation for both the cases. The proposed carry-select scheme is assessed relative to carry-ripple, classical carry-select, and carry-skip adders. The analytic evaluation is done with respect to the gate-count model for area and gate-delay units for time.","Delay,
Logic,
Computer science,
Counting circuits,
Microprocessors,
Signal processing,
Time factors,
Pipelines,
Wires,
Costs"
Trapezoid self-scheduling: a practical scheduling scheme for parallel compilers,"A practical processor self-scheduling scheme, trapezoid self-scheduling, is proposed for arbitrary parallel nested loops in shared-memory multiprocessors. Generally, loops are the richest source of parallelism in parallel programs. To dynamically allocate loop iterations to processors, one may achieve load balancing among processors at the expense of run-time scheduling overhead. By linearly decreasing the chunk size at run time, the best tradeoff between the scheduling overhead and balanced workload can be obtained in the proposed trapezoid self-scheduling approach. Due to its simplicity and flexibility, this approach can be efficiently implemented in any parallel compiler. The small and predictable number of chores also allow efficient management of memory in a static fashion. The experiments conducted in a 96-node Butterfly GP-1000 clearly show the advantage of the trapezoid self-scheduling over other well-known self-scheduling approaches.","Processor scheduling,
Load management,
Dynamic scheduling,
Multiprocessing systems,
Memory management,
Parallel processing,
Runtime,
Parallel languages,
Programming profession,
Computer science"
Rate-controlled static-priority queueing,"The authors propose a service discipline, called the rate-controlled static-priority (RCSP) queuing discipline, that provides throughput, delay, delay jitter, and loss free guarantees in a connection-oriented packet-switching network. The RCSP queuing discipline avoids both time-framing and sorted priority queues; it achieves flexibility in the allocation of delay and bandwidth, as well as simplicity of implementation. The key idea is to separate rate-control and delay-control functions in the design of the server. Applying this separation of functions results in a class of service disciplines of which RCSP is an instance.",
The Midway distributed shared memory system,"The authors describe the motivation, design, and performance of Midway, a programming system for a distributed shared memory multicomputer (DSM) such as an ATM-based cluster, a CM-5, or a Paragon. Midway supports a novel memory consistency model called entry consistency (EC). EC guarantees that shared data become consistent at a processor when the processor acquires a synchronization object known to guard the data. EC is weaker than other models described in the literature, such as processor consistency and release consistency, but it makes possible higher performance implementations of the underlying consistency protocols. Midway programs are written in C, and the association between synchronization objects and data must be made with explicit annotations. As a result, pure entry consistent programs can require more annotations than programs written to other models. Midway also supports the stronger release consistent and processor consistent models at the granularity of individual data items.","Frequency synchronization,
Programming profession,
Computer science,
Protocols,
Information science,
Contracts,
US Government,
Parallel programming,
Program processors,
Delay"
Parameterized point pattern matching and its application to recognition of object families,"The problem of recognizing and localizing objects that can vary in parameterized ways is considered. To achieve this goal, a concept of parameterized point pattern is introduced to model parameterized families of such objects, and a parameterized point pattern matching algorithm is proposed. A parameterized point pattern is a very flexible concept that can be used to model a large class of parameterized objects, such as a pair of scissors with rotating blades. The proposed matching algorithm is formulated as a tree search procedure, and it generates all maximum matchings satisfying a condition called delta -boundedness. Several pruning methods based on the condition of delta -boundedness and their efficient computing techniques are given. The proposed matching algorithm is applied to a real shape matching problem in order to check the validity of the approach.","Pattern matching,
Pattern recognition,
Shape,
Blades,
Computer vision,
Object recognition,
Information science"
The End Of The Line For Static Cyclic Scheduling?,,
Using Genetic Algorithms to Explore Pattern Recognition in the Immune System,"This paper describes an immune system model based on binary strings. The purpose of the model is to study the pattern-recognition processes and learning that take place at both the individual and species levels in the immune system. The genetic algorithm (GA) is a central component of the model. The paper reports simulation experiments on two pattern-recognition problems that are relevant to natural immune systems. Finally, it reviews the relation between the model and explicit fitness-sharing techniques for genetic algorithms, showing that the immune system model implements a form of implicit fitness sharing.",
Performance evaluation of multipoint routing algorithms,"The problem of developing efficient multipoint routing algorithms for asynchronous transfer mode (ATM) networks is considered. Emphasis is placed on practical algorithms that have efficient distributed implementation. In particular, the weighted greedy algorithm (WGA) is investigated. This algorithm is of particular interest since one version can be implemented as a simple extension of point-to-point routing and since a straightforward distributed implementation is possible. The performance of the WGA is studied by means of computer simulations and compared to that of a theoretically good algorithm. Experiments are conducted under realistic conditions involving different connection types, including point-to-point and dynamic multipoint connections. Performance is evaluated in terms of an algorithm's load carrying potential. The goal is to find algorithms that maximize the load carrying ability of a network.","Routing,
Bandwidth,
Costs,
Asynchronous transfer mode,
Greedy algorithms,
Switches,
Tree graphs,
Computer science,
Computer simulation,
Communication networks"
Fast message ordering and membership using a logical token-passing ring,"The Totem protocol supports consistent concurrent operations by placing a total order on broadcast messages. This total order is achieved by including a sequence number in a token circulated around a logical ring that is imposed on a set of processors in a broadcast domain. A membership algorithm handles reconfiguration, including restarting of a failed processor and remerging of a partitioned network. Effective flow-control allows the protocol to achieve message ordering rates two to three times higher than the best prior protocols. The single-ring total ordering protocol of Totem provides fault-tolerant agreed and safe delivery of messages within a broadcast domain.",
"Searching for Diverse, Cooperative Populations with Genetic Algorithms","In typical applications, genetic algorithms (GAs) process populations of potential problem solutions to evolve a single population member that specifies an ‘optimized’ solution. The majority of GA analysis has focused on these optimization applications. In other applications (notably learning classifier systems and certain connectionist learning systems), a GA searches for a population of cooperative structures that jointly perform a computational task. This paper presents an analysis of this type of GA problem. The analysis considers a simplified genetics-based machine learning system: a model of an immune system. In this model, a GA must discover a set of pattern-matching antibodies that effectively match a set of antigen patterns. Analysis shows how a GA can automatically evolve and sustain a diverse, cooperative population. The cooperation emerges as a natural part of the antigen-antibody matching procedure. This emergent effect is shown to be similar to fitness sharing, an explicit technique for multimodal GA optimization. Further analysis shows how the GA population can adapt to express various degrees of generalization. The results show how GAs can automatically and simultaneously discover effective groups of cooperative computational structures.",
SubGemini: Identifying SubCircuits using a Fast Subgraph Isomorphism Algorithm,"The problem of finding subcircuits in a larger circuit arises in many contexts in computer-aided design. This is a problem currently solved using ad hoc techniques that rely on the circuit technology and implementation details. For example, channel graphs and signal flow are often used to extract simple gates from a transistor layout. Such techniques, however, do not generalize to different subcircuit structures and do not transfer to other technologies. We present a technology-independent algorithm for this problem based on a solution to the subgraph isomorphism problem. Although this problem is known to be NP-complete, our solution is very fast in practice for real circuits. We describe the algorithm, which uses an extension of the graph partitioning algorithm used by Gemini [3] for graph isomorphism, and present experimental results that show that the typical running time for large CMOS circuits is approximately linear in the total number of devices within the subcircuits being matched.","Libraries,
Partitioning algorithms,
Integrated circuit interconnections,
Tree graphs,
Computer science,
Design engineering,
Design automation,
Circuit synthesis,
Analog circuits,
Labeling"
An evaluation of bottom-up and top-down thread generation techniques,"Due to increasing cache-miss latencies, cache control instructions are being implemented for future systems. The authors study the memory referencing behavior of individual machine-level instructions using simulations of fully-associative caches under MIN replacement. Their objective is to obtain a deeper understanding of useful program behavior that can be eventually employed at optimizing programs and to motivate architectural features aimed at improving the efficacy of memory hierarchies. The simulation results show that a very small number of load/store instructions account for a majority of data cache misses. Specifically, fewer than 10 instructions account for half the misses for six out of nine SPEC89 benchmarks. Selectively prefetching data referenced by a small number of instructions identified through profiling can reduce overall miss ratio significantly while only incurring a small number of unnecessary prefetches.<>",
An adaptive Gaussian filter for noise reduction and edge detection,"Gaussian filtering has been intensively studied in image processing and computer vision. Using a Gaussian filter for noise suppression, the noise is smoothed out, at the same time the signal is also distorted. The use of a Gaussian filter as pre-processing for edge detection will also give rise to edge position displacement, edges vanishing, and phantom edges. Here, the authors first review various techniques for these problems. They then propose an adaptive Gaussian filtering algorithm in which the filter variance is adapted to both the noise characteristics and the local variance of the signal.","Adaptive filters,
Noise reduction,
Image edge detection,
Gaussian noise,
Imaging phantoms,
Filtering algorithms,
Digital filters,
Image processing,
Computer vision,
Distortion"
High-Level Transformations for Minimizing Syntactic Variances,"Most synthesis systems generate designs from hardware descriptions by relating each language construct to a particular hardware structure. Thus, designs obtained from these systems are dependent on description styles. In other words, semantically equivalent descriptions with different orderings or groupings of conditional and assignment statements could generate designs with distinctively different costs and performance. This paper introduces an approach for minimizing the syntactic variance of different description styles. Experimental data on several examples shows the effectiveness of the proposed approach.",
Parallel search algorithms for robot motion planning,"The authors show that parallel search techniques derived from their sequential counterparts can enable the solution of instances of the robot motion planning problem which are computationally infeasible on sequential machines. A parallel version of a robot motion planning algorithm based on quasibest first search with randomized escape from local minima and random backtracking is presented. Its performance on a problem instance, which was computationally infeasible on a single processor of an nCUBE2 multicomputer, is discussed. The limitations of parallel robot motion planning systems are discussed, and a course for future work is suggested.","Robot motion,
Motion planning,
Concurrent computing,
Military computing,
Computer science,
Tracking,
Path planning,
Parallel robots,
Shape,
Random access memory"
The design of a neuro-microprocessor,The architecture of a neuro-microprocessor is presented. This processor was designed using the results of careful analysis of a set of applications and extensive simulation of moderate-precision arithmetic for back-propagation networks. Simulated performance results and test-chip results for the processor are presented. This work is an important intermediate step in the development of a connectionist network supercomputer.,"Arithmetic,
Supercomputers,
Microprocessors,
Computational modeling,
Application software,
Computer science,
Speech recognition,
Process design,
Analytical models,
Testing"
Measuring and assessing maintainability at the end of high level design,"Software architecture appears to be one of the main factors affecting software maintainability. Therefore, in order to be able to predict and assess maintainability early in the development process one needs to be able to measure the high-level design characteristics that affect the change process. To this end, a measurement approach based on precise assumptions derived from the change process is proposed. The change process is based on object-oriented design principles and is partially language independent. Metrics for cohesion, coupling, and visibility are defined in order to capture the difficulty of isolating, understanding, designing and validating changes.","Software maintenance,
Software systems,
Computer languages,
NASA,
Software testing,
Software design,
Predictive models,
Computer science,
Educational institutions,
Software architecture"
Memory servers for multicomputers,"A virtual memory management technique for multicomputers called memory servers is investigated. The memory server model extends the memory hierarchy of multicomputers by introducing a remote memory server layer. Memory servers are multicomputer nodes whose memory is used for fast backing storage and logically lie between the local physical memory and disks. The authors present the model, describe how the model supports sequential programs, message-passing programs, and shared virtual memory systems, discuss several design issues, and show preliminary results of a prototype implementation on an Intel iPSC/860.",
Multiple-way network partitioning with different cost functions,"An adaptation to multiple blocks of a two-block network partitioning algorithm by Krishnamurthy was previously presented and analyzed by the author (see ibid., vol.38, p.62-81, 1989). The algorithm assumed one of several possible generalizations of two-way partitioning to multiple-way partitioning. The problem of adapting this algorithm to work with different generalizations more suitable for other types of applications of network partitioning is considered. It is shown that certain portions of the algorithm must be revised in order to maintain a relatively low time complexity for the modified algorithms. Experimental results are given.",
7.5 MFLIPS fuzzy microprocessor using SIMD and logic-in-memory structure,"Two fuzzy microprocessors have been developed as VLSI chips. One is an if-part processor with single instruction, multiple data (SIMD) architecture, and the other is a then-part processor with logic-in-memory. The system configuration using the chips can execute fuzzy inference for if-then fuzzy rules. The speed of inference including defuzzification is 7.5 M fuzzy logical inferences per second (FLIPS), and the system can process 960 rules and 16 input and output variables. The rule format can be easily changed by rewriting the instructions stored in the memory. The processors require no external memory since the knowledge-base can be stored in the internal memory.","Fuzzy logic,
Microprocessors,
Fuzzy sets,
Hardware,
Parallel architectures,
Parallel processing,
Computer science,
CMOS process,
Mathematical model,
Knowledge based systems"
Efficient transparent optimistic rollback recovery for distributed application programs,"A transparent rollback-recovery method that adds very little overhead to distributed application programs and efficiently supports the quick commit of all output to the outside world is introduced. Each process can independently choose at any time either to use checkpointing alone (as in consistent checkpointing) or to use optimistic message logging. The system is based on a new commit algorithm that requires communication with and information about the minimum number of other processes in the system, and supports the recovery of both deterministic and nondeterministic processes.","Application software,
Checkpointing,
Optimization methods,
Propagation delay,
Fault tolerance,
Computer science,
Information science,
Concurrent computing,
Contracts,
Programming profession"
Utilization of Multiport Memories in Data Path Synthesis,"In this paper, a new approach to the problem of allocating multiport memory modules for data storage is presented. Previous approaches divide the allocation problem into two separate steps: (i) grouping the variables (or registers) to form memory modules and (ii) determining the interconnections between the memory modules and functional units. Yet, there is no easy way to predict the result of step (ii) during step (i). In our approach, we place primary importance on the cost of interconnections. Consequently, we try to minimize the cost of interconnections first and then to group the variables to form memory modules later. For a number of benchmark problems, it has been shown that this approach is quite effective.","Registers,
Costs,
High level synthesis,
Hardware,
Integer linear programming,
Computer science,
Design automation,
Processor scheduling,
Read-write memory,
Multiplexing"
Guaranteeing synchronous messages with arbitrary deadline constraints in an FDDI network,"Issues related to guaranteeing synchronous messages with arbitrary deadline constraints in a fiber distributed data interface (FDDI) network are addressed. It is shown that several network parameters must be set carefully if message deadlines are to be satisfied. Message deadlines can only be met if sufficient synchronous bandwidth is allocated to each mode. Thus, proper synchronous bandwidth allocation is essential if deadlines are to be guaranteed. The target token rotation time (TTRT) determines both the speed of token circulation and the network utilization available to user applications. TTRT should also be chosen carefully to ensure that the token circulates fast enough while maintaining a high available utilization. Sufficient buffer space must be provided for outgoing messages, otherwise messages could be lost due to buffer overflow. An integrated method for allocating the synchronous bandwidth and selecting TTRT so that the time constraints of synchronous messages with arbitrary deadlines are guaranteed to be met is proposed and analyzed.","Intelligent networks,
FDDI,
Bandwidth,
Access protocols,
Channel allocation,
Upper bound,
Application software,
Spine,
Computer science,
Time factors"
"TIM: A Timing Package for Two-Phase, Level-Clocked Circuitry","TIM is a versatile and efficient tool for verifying and optimizing the timing of two-phase, level-clocked circuitry. TIM performs a variety of functions, such as timing verification, clock tuning, retiming for maximum speed of operation, retiming for minimum number of latches, and sensitivity analysis. In this paper, we present new polynomial-time optimization algorithms for retiming and sensitivity analysis, and we describe the implementation of the new and previously reported algorithms in TIM. We also present empirical results from the application of TIM to sequential circuitry obtained from academic and industrial sources. Our experiments show that the number of latches in edge-triggered designs which have been retimed for maximum performance can be substantially reduced in corresponding two-phase, level-clocked designs that operate at the same speed.",
Coincident bit counting-a new criterion for image registration,"A similarity measure based on the number of coincident bits in multichannel images is presented. The similarity criterion incorporated in the image registration algorithm uses a coincident bit counting (CBC) method to obtain the number of matching bits between the frames of interest. The CBC method not only performs favorably compared with traditional techniques, but also renders simpler implementation in conventional computing machines. An image registration algorithm that incorporates the CBC criterion is proposed to determine the translation motion among sequences of images. The errors caused by noise, misregistration, and a combination of these two are analyzed. Some experimental studies using low-contrast coronary images from a digital angiographic sequence are discussed. The results compare favorably with those obtained by using other nonparametric methods.","Image registration,
Angiography,
Rendering (computer graphics),
Mammography,
Radiography,
Data mining,
Pixel,
Testing,
Displacement measurement,
Noise robustness"
Recovering reflectance and illumination in a world of painted polyhedra,"To be immune to variations in illumination, a vision system needs to be able to decompose images into their illumination and surface reflectance components. Most computational studies thus far have been concerned with strategies for solving the problem in the restricted domain of 2-D Mondrians. This domain has the simplifying characteristic of permitting discontinuities only in the reflectance distribution while the illumination distribution is constrained to vary smoothly. Such approaches prove inadequate in a 3-D world of painted polyhedra which allows for the existence of discontinuities in both the reflectance and illumination distributions. The authors propose a two-stage computational strategy for interpreting images acquired in such a domain. The first stage attempts to use simple local gray-level junction analysis to classify the observed image edges into the illumination or reflectance categories. Subsequent processing verifies the global consistency of these local inferences while also reasoning about the 3-D structure of the object and the illumination source direction.","Reflectivity,
Lighting,
Machine vision,
Humans,
Laboratories,
Layout,
Cognitive science,
Brain modeling,
Immune system,
Visual system"
Symmetries and discriminability in feedforward network architectures,"This paper investigates the effects of introducing symmetries into feedforward neural networks in what are termed symmetry networks. This technique allows more efficient training for problems in which we require the output of a network to be invariant under a set of transformations of the input. The particular problem of graph recognition is considered. In this case the network is designed to deliver the same output for isomorphic graphs. This leads to the question of which inputs can be distinguished by such architectures. A theorem characterizing when two inputs can be distinguished by a symmetry network is given. As a consequence, a particular network design is shown to be able to distinguish nonisomorphic graphs if and only if the graph reconstruction conjecture holds.","Intelligent networks,
Neural networks,
Feedforward neural networks,
Multilayer perceptrons,
Books,
Delay effects,
Neurons,
Computer science,
Handwriting recognition"
Bisimulation and open maps,"An abstract definition of bisimulation is presented. It allows a uniform definition of bisimulation across a range of different models for parallel computation presented as categories. As examples, transition systems, synchronization trees, transition systems with independence (an abstraction from Petri nets), and labeled event structures are considered. On transition systems, the abstract definition readily specialises to Milner's (1989) strong bisimulation. On event structures, it explains and leads to a revision of the history-preserving bisimulation of Rabinovitch and Traktenbrot (1988), and Goltz and van Glabeek (1989). A tie-up with open maps in a (pre)topos brings to light a promising new model, presheaves on categories of pomsets, into which the usual category of labeled event structures embeds fully and faithfully. As an indication of its promise, this new presheaf model has refinement operators, though further work is required to justify their appropriateness and understand their relation to previous attempts.<>",
Performance analysis of job scheduling policies in parallel supercomputing environments,"The authors analyze three general classes of scheduling policies under a workload typical of large-scale scientific computing. These policies differ in the manner in which processors are partitioned among the jobs as well as the way in which jobs are prioritized for execution on the partitions. The results indicate that existing static schemes to not perform well under varying workloads. Adaptive policies tend to make better scheduling decisions, but their ability to adjust to workload changes is limited. Dynamic partitioning policies, on the other hand, yield the best performance and can be tuned to provide desired performance differences among jobs with varying resource demands.","Performance analysis,
Processor scheduling,
Application software,
Parallel processing,
Throughput,
Energy management,
Power system management,
Computer science,
Scientific computing,
Large-scale systems"
Parity Logging Overcoming The Small Write Problem In Redundant Disk Arrays,,"Costs,
Bandwidth,
Power system reliability,
Computer science,
Analytical models,
Drives,
Encoding,
Redundancy,
Throughput"
Supporting application-specific resolution in an optimistically replicated file system,"We describe an interface to incorporate application-specific knowledge for conflict resolution in an optimistically replicated file system. Conflicts arise in such systems because replicas of an object can be modified simultaneously in different network partitions. Application-specific knowledge is made available by the application writer in specialized tools called Application-Specific Resolvers (or ASRS). The interface we describe here is used to bind ASRs to objects and to specify the conditions under which a specific ASR is invoked. This allows the system to make conflict resolution transparent to the user, thus improving the usability of optimistic replication.","File systems,
Automatic speech recognition,
Network servers,
Venus,
Availability,
File servers,
Computer science,
Usability,
Calendars,
Utility programs"
Verifying programs with unreliable channels,"The verification of a particular class of infinite-state systems, namely, systems consisting of finite-state processes that communicate via unbounded lossy FIFO channels, is considered. This class is able to model, e.g., link protocols such as the Alternating Bit Protocol and HDLC. For this class of systems, it is shown that several interesting verification problems are decidable by giving algorithms for verifying: the reachability problem (whether a finite set of global states is reachable from some other global state of the system); the safety property over traces, formulated as regular sets of allowed finite traces; and eventuality properties (whether all computations of a system eventually reach a given set of states). The algorithms are used to verify some idealized sliding-window protocols with reasonable time and space resources.","Protocols,
Safety,
Hardware,
Data engineering,
Contracts,
Microwave integrated circuits,
Clocks,
Algorithm design and analysis"
Reducing BDD Size by Exploiting Functional Dependencies,"Many researchers have reported that the use of Boolean decision diagrams (BDDs) greatly increases the size of hardware designs that can be formally verified automatically. Our own experience with automatic verification of high-level aspects of hardware design, such as protocols for cache coherence and communications, contradicts previous results; in fact, BDDs have been substantially inferior to brute-force algorithms that store states explicitly in a table. We believe that new techniques will be needed to realize the potential advantages of BDD verification at the protocol level. Here, we identify functionally dependent variables as a common cause of BDD-size blowup, and describe new techniques to avoid the problem. Using the improved algorithm, we reduce an exponentially-sized problem to a provably O(n log n)-sized one, achieving several orders of magnitude reduction in BDD size.","Binary decision diagrams,
Hardware,
Protocols,
Data structures,
Boolean functions,
Formal verification,
Computer science,
Algorithm design and analysis,
Costs,
Refining"
A strategy for conceptual model acquisition,"A strategy for conceptual model acquisition is proposed. Knowledge acquisition is performed with a simple structure, i.e., the lexicon. Using the lexicon and an AI-based approach, a conceptual model is derived. The approach assists in the construction of a first cut version of the conceptual model, which should undergo a validation process. A prototype is built using an object-oriented AI shell. The system is tested with a library example (a 50 entries lexicon).","Object oriented modeling,
Vocabulary,
Systems engineering and theory,
Software systems,
Natural languages,
Prototypes,
Computer science,
Software libraries,
Books,
Context modeling"
Impact of radiation-induced nonuniform damage near MOSFET junctions,"Laterally nonuniform distributions of radiation-induced oxide charge and interface traps near MOSFET junctions have been found in a variety of samples. As revealed by three independent measurement techniques, the degree of nonuniformity depends strongly on the process technology. Such lateral nonuniformity could arise from the lateral variation of the oxide field near the channel edges during irradiation and the different diode properties in these regions compared to those in the main channel region. These channel edge effects can significantly affect MOSFET device parameters such as the threshold voltage, transconductance, channel resistance, and effective channel length. This is especially the case for submicron devices. Results from computer simulation indicate that the edge damage alone could contribute to a major portion of the transconductance degradation in irradiated submicron devices.","MOSFET circuits,
Transconductance,
Charge pumps,
Laboratories,
Microelectronics,
Current measurement,
Charge measurement,
Contact resistance,
Q measurement,
Pulse measurements"
A continuation method for emission tomography,"The authors describe a continuation method in which the minimum of the energy function corresponding to one member of the Phi function sequence is used as an initial condition for the minimization of the next, less approximate, stage. This continuation method is implemented using a GEM-ICM (generalized expectation maximization-iterated conditioned mode) procedure. Simulation results show improvement using this continuation method relative to using Phi * alone, and to conventional EM reconstructions.","Annealing,
Computed tomography,
Temperature,
Image reconstruction,
Radiology,
Minimization methods,
Reconstruction algorithms,
Maximum likelihood estimation,
Computer science,
Nuclear and plasma sciences"
Sphere packing and local majorities in graphs,"The paper concerns some extremal problems on packing spheres in graphs and covering graphs by spheres. Tight bounds are provided for these problems on general graphs. The bounds are then applied to answer the following question: Let f be a nonnegative function defined on the vertices of a graph G, and suppose one has a lower bound on the local averages of f, i.e., on f's average over every j-neighborhood in G for j=1,. . .,r. What can be concluded globally? I.e, what can be said about the average of f over all G? This question arose in connection with issues of locality in distributed network computation. The average estimation problem with unit radius balls is also studied for some special classes of graphs.","Computer science,
Extraterrestrial measurements,
Computer networks,
Distributed computing,
Mathematics,
Career development,
Contracts,
Books,
Heart,
Codes"
A possible world semantics for disjunctive databases,"The fundamental problem that arises when a ground atom in a disjunctive database is assumed false is discussed. There are basically two different approaches for inferring negative information for disjunctive databases: J. Minker's (1982) generalized closed world assumption (GCWA) and K.A. Ross and R.W. Topor's (1988) disjunctive database rule (DDR). It is argued that neither approach is satisfactory. A database semantics called PWS is proposed. It is shown that for propositional databases with no negative clauses, the problem of determining if a negative ground literal is inferred under the GCWA is co-NP-hard, while the same problem can be solved efficiently under the DDR and PWS. However, in the general case, the problem becomes co-NP-complete for the DDR and PWS. Relationships among GCWA, DDR, and PWS are highlighted. In general, disjunctive clauses are interpreted inclusively under the DDR and unpredictably under the GCWA.","Deductive databases,
Councils,
Computer science,
Logic"
A strategic negotiations model with applications to an international crisis,"The area of automated negotiation has been of particular interest in AI due to the important role negotiations play in facilitating understanding and the achievement of cooperation among entities with differing interests, whether they be individuals, organizations, governments, or automated agents. A strategic model for negotiation of alternative offers is presented with specific application to international crises. In the model, both players can opt out, and while one loses over time, the other gains (up to a point). Specific issues are: conflicting objectives and utility functions of parties and the impact of time on bargaining behavior in crises. The general model has relevance to the hostage crisis from which it was built, and subsequent applicability in building an automated negotiation agent for experimental and training purposes.","Artificial intelligence,
Government,
Analytical models,
Game theory,
Optimized production technology,
Virtual prototyping,
Environmental economics,
Decision making,
Mathematics,
Computer science"
Is it easier to write matrix manipulation programs visually or textually? An empirical study,"Empirical studies comparing the effectiveness of visual languages versus textual languages have rarely been attempted. We describe an experiment conducted on programmers solving vector and matrix manipulation tasks using the visual language Forms/3, the textual language Pascal, and a textual matrix manipulation language with the capabilities of APL. Our motivation, experimental approach, some of the difficulties experienced in attempting this type of empirical study, and a summary of the experimental results and insights gained are presented.","Computer languages,
Animation,
Programming profession,
Computer science,
Area measurement"
Performance of buffered multistage interconnection networks in non uniform traffic environment,"Multistage interconnection networks (MIN) are used to connect processors to memories in shared memory multiprocessor systems. A generalized Markov chain model for the performance evaluation of a single-buffered Omega network, in the presence of a hot spot, is proposed. The proposed model produces better results than existing models.","Multiprocessor interconnection networks,
Intelligent networks,
Telecommunication traffic,
Traffic control,
Analytical models,
Multiprocessing systems,
Switches,
Routing,
Computer science,
Fabrics"
Identification of human faces through texture-based feature recognition and neural network technology,"A method is presented to infer the presence of a human face in an image through the identification of face-like textures. The selected textures are those of human hair and skin. The second-order statistics method is used for texture representation. This method employs a set of co-occurrence matrices, from which features can be calculated that can characterize a texture. The cascade-correlation neural network architecture is used for supervised classification of textures. The Kohonen self-organizing feature map shows the clustering of the different texture types. Classification performance is generally above 80%, which is sufficient to clearly outline a face in an image.","Humans,
Face recognition,
Neural networks,
Face detection,
Hair,
Skin,
Springs,
Statistics,
Computer science,
Digital images"
Modeling live and dead lines in cache memory systems,"An analytical model that predicts the fraction of live and dead lines present in a cache memory in a multitasking environment is presented. The model is two-fold. The first portion evaluates the number of live lines created in a fully associative cache during the execution of a process. The second portion models the interaction of two processes that share a cache and run in an interleaved fashion. The model admits direct-mapped, set-associative, and fully associative cache architectures. The complete model assumes a hyperbolic (or fractal) model of program behavior. It predicts the variations of the total number of lines (footprint) as well as the number of live lines held by a process in the various caches as a function of the number of cache accesses. The accuracy of the model is validated through trace driven simulations.","Cache memory,
Predictive models,
Multitasking,
Fractals,
Computer science,
Analytical models,
Computational modeling,
Computer architecture,
Hardware"
Understanding noise: The critical role of motion error in scene reconstruction,"In structure from motion algorithms, the error in the estimated motion affects each reconstructed 3-D point in a systematic way. The authors attempt to isolate the effect of the motion error as correlations in the structure error and show theoretically that these correlations can improve existing multi-frame structure from motion techniques. Experimental results and previously reported work confirm the theoretical predictions.","Layout,
Image reconstruction,
Covariance matrix,
Cameras,
Computer errors,
Motion estimation,
Robot vision systems,
Computer science,
Binary search trees,
Electrical capacitance tomography"
Detection of dimension sets in engineering drawings,"A system for detecting dimension sets in engineering drawings that are drawn to ANSI drafting standards is presented. A new rule-based text/graphics separation algorithm and a model-based procedure for detecting arrowheads in any orientation have been developed. Arrowhead tracking and search methods are used to extract leaders, tails, and witness lines from segmented images containing only graphics. Text blocks and feature control frames extracted from the segmented images are then associated with their corresponding leaders to obtain complete dimension sets. Object lines are then separated from centerlines and hatching lines. Experimental results are presented.",
A general architecture for load balancing in a distributed-memory environment,"The goal of load balancing is to assign to each node a number of tasks proportional to its performance. On distributed-memory machines, it is important to take data dependencies into account when distributing tasks, since they have a big impact on the communication requirements of the distributed application. The authors present a load balancing architecture that can deal with applications with heterogeneous tasks. The idea is to provide a set of load balancers that are effective for different types of homogeneous tasks, and to allow users to combine these load balancers for applications with heterogeneous tasks. This architecture was implemented on the Nectar multicomputer and performance results are presented for several applications with homogeneous and heterogeneous tasks.","Load management,
Computer architecture,
Distributed computing,
Programming profession,
Information systems,
Computer industry,
Computer science,
Parallel processing,
Program processors,
Application software"
"On some topological properties of hypercube, incomplete hypercube and supercube","Hamiltonian properties of hypercube, incomplete hypercube and supercube are examined. It is known that in a nonfaulty hypercube there are at least n! Hamiltonian cycles. The authors extend this result showing that the lower bound is at least 2/sup n-3/n! They show that with at most n-2 faulty links a faulty hypercube has at least 2(n-2)! Hamiltonian cycles. They establish that an incomplete hypercube with odd (even) number of nodes has (n-2)! Hamiltonian paths (cycles). They show that a supercube has at least (n-1)! Hamiltonian cycles and when the number of nodes is 2/sup n-1/+2/sup n-2/, then the number of Hamiltonian cycles is at least as high as 2(n-1)!.","Hypercubes,
Computer science,
Multiprocessor interconnection networks,
Hamming distance"
Efficient verification of symmetric concurrent systems,"Previously (Proc. 11th Symp. on Computer Hardware Description Languages and their Application, April 1993), we proposed a reduction technique based on symmetries to alleviate the state explosion problem in automatic verification of concurrent systems. This paper describes the results of testing the technique on a wide range of algorithms and protocols, including realistic multiprocessor synchronization algorithms and cache coherence protocols. Memory requirements were reduced by amounts ranging from 83% to over 99%, and time requirements were often reduced as well. We also consider the effectiveness of the technique on different types of symmetries, such as symmetries in identical system components and symmetries in data values.",
Computing the generalized aspect graph for objects with moving parts,"Algorithms for computing the aspect graph representation are generalized to include a larger, more realistic domain of objects known as articulated assemblies those objects composed of rigid parts with articulated connections allowed between parts. The generalization suggests two slightly different representations: one that directly summarizes the possible general views of the object and another (hierarchical) form summarizing the possible general configurations and their respective views. Algorithms are outlined for computing both representations. The generalized aspect graphs of assemblies formed using translational connections are examined.","Assembly,
Computer vision,
Partitioning algorithms,
Computer science,
Information analysis,
Object recognition,
Layout,
Shape,
Solid modeling,
Kinematics"
Inhibitory grids and the assignment problem,"A family of symmetric neural networks that solve a simple version of the assignment problem (AP) is analyzed. The authors analyze the suboptimal performance of these networks and compare the results to optimal answers obtained by linear programming techniques. They then use the interactive activation model to define the network dynamics-a model that is closely related to the Hopfield-Tank model. A systematic analysis of hypercube corner stability and eigenspaces of the connection strength matrix leads to network parameters that give feasible solutions 100% of the time and to a projection algorithm that significantly improves performance. Two formulations of the problem are discussed: (i) nearest corner: encode the assignment numbers as initial activations, and (ii) lowest energy corner: encode the assignment numbers as external inputs.","Neural networks,
Linear programming,
Performance analysis,
Algorithm design and analysis,
Hypercubes,
Stability analysis,
Projection algorithms,
Random number generation,
Computer science,
Analog circuits"
A formal approach to the comparison of object-oriented analysis and design methodologies,"Presents a comparison of six object-oriented analysis and design methodologies. For each of the methodologies, a formal representation of it is constructed as a metaprocess model and a meta-data model. These two metamodels of a methodology represent the steps of the analysis and design, the concepts and the techniques provided by this methodology. Based on this uniform representation, an extensive comparison of these six methodologies is then performed. The results are given as a set of tables in which the similarity and differences of these methodologies are exhibited. Adopting this formal approach, one can avoid errors caused by misunderstanding or misinterpretation of these methodologies. Consequently, an accurate and unbiased comparison is made possible.","Design methodology,
Object oriented modeling,
Information analysis,
Switches,
Information systems,
Computer science,
Conference proceedings,
Books,
Technology planning,
Data mining"
The beginnings of the Manchester computer phenomenon: people and influences,"The development of computers at the University of Manchester in the late 1940s is discussed. Scientific computation in Britain during and immediately after World War II is briefly described. Computers at the University were initially influenced by M.H.A. Newman and F.C. Williams. Biographies of these two men are given, and their wartime work is examined in the light of computer development at Manchester. The development at Manchester of the first prototype stored-program computer, the Manchester baby, is also discussed.","Military computing,
Mathematics,
Physics computing,
Biographies,
Computer science,
Prototypes,
Pediatrics,
Moon,
Bridges,
Calculators"
An availability model for MIN-based multiprocessors,"System decomposition is a novel technique for modeling the dependability of complex systems without constructing a single-level Markov Chain (MC). This is demonstrated in this paper for the availability computation of a class of multiprocessors that uses 4*4 switching elements for the multistage interconnection network (MIN). The availability model is known as task-based availability, where a system is considered operational as long as the task requirements are satisfied. The authors develop two simple MC's for the processors and memories and solve them using a software package, called HARP. The probabilities of i processing elements (PE's) and j memory modules (MM's) working at any time t, denoted as Pi(t) and Pj(t), are obtained from their corresponding MC's. The effect of the MIN is captured in the model by finding the number of switches required for the connection of i PE's and j MM's. A third MC is then developed for the switches to find the probability that the MIN provides the required (i*j) connection. Multiplying this term with Pi(t) and Pj(t), the probability of an (i*j) working group is obtained. The methodology is generalized to model arbitrary as well as larger size systems. Transient and steady state availabilities are computed for a variety of MIN configurations and the results are validated through simulation.","Switches,
Availability,
Multiprocessor interconnection networks,
Fault tolerance,
Computer science,
Application software,
Computer networks,
Software packages,
Steady-state,
Computational modeling"
Design Management Using Dynamically Defined Flows,"Many CAD frameworks now use the notion of a design flow to help provide methodology management services. Most flow-based approaches are limited, however, in that they involve a fixed sequence of operations specified in advance, restrict designers to using only those flows, and ""hardwire"" specific tools to flows. To overcome this, we introduce the concept of ""dynamically defined flows"" as tool-independent flows that are built up, on demand, by designers. Dynamically defined flows can be used to provide a semantically rich means for browsing the design history database as well as to provide support for multiple design approaches, such as goal-based, tool-based, data-based and plan-based design.","Design automation,
History,
Process design,
Databases,
Computer science,
Design engineering,
Engineering management,
Organizing,
Tree graphs,
Content addressable storage"
Batch scheduling in parallel database systems,Many techniques for query scheduling in a parallel database system schedule a single query at a time. The scheduling of queries for parallel database systems by dividing the workload into batches is investigated. Scheduling algorithms that exploit the common operations within the queries in a batch are proposed. The performance of the proposed algorithms is studied using a simple analytical model and a detailed simulation model. It is shown that batch scheduling can provide significant savings compared to single query scheduling for a variety of system and workload parameters.,"Database systems,
Processor scheduling,
Runtime,
Computer science,
Scheduling algorithm,
Analytical models,
Resource management,
Throughput,
Optimization methods,
Database machines"
Improved bounds for algorithm-based fault tolerance,"Lower and upper bounds are established for the combinatorial problem of constructing minimal test sets for error detection in multiprocessor systems. The construction for detecting two errors produces minimal test sets, while that for three errors produces test sets whose size exceeds the lower bound by at most one. Also presented is a divide-and-conquer construction scheme for four or more errors.","Fault tolerance,
Upper bound,
Multiprocessing systems,
System testing,
Fault detection,
Communication system control,
Computer science,
Fault tolerant systems,
Computer errors"
"Signal propagation, with application to a lower bound on the depth of noisy formulas","We study the decay of an information signal propagating through a series of noisy channels. We obtain exact bounds on such decay, and as a result provide a new lower bound on the depth of formulas with noisy components. This improves upon previous work of N. Pippenger (1988) and significantly decreases the gap between his lower bound and the classical upper bound of von Neumann. We also discuss connections between our work and the study of mixing rates of Markov chains.","Acoustic noise,
Upper bound,
Application software,
Random variables,
Signal to noise ratio,
Circuit noise,
Computer science,
Acoustic propagation,
Wire,
Codes"
The shadow algorithm: a scheduling technique for both compiled and interpreted simulation,"The shadow algorithm, which is an event-driven unit-delay simulation technique that has been designed to take advantage of the instruction caches present in many of the latest workstations, is discussed. The algorithm is based on the threaded-code technique, but uses a dynamically created linked list of environments called shadows. Compiled shadow algorithm simulations run in about 1/5th the time required for a conventional interpreted event-driven simulation. The interpreted shadow algorithm runs in about 1/4th the time of a conventional interpretive simulation.","Scheduling algorithm,
Computational modeling,
Discrete event simulation,
Circuit simulation,
Algorithm design and analysis,
Workstations,
Microelectronics,
Computer science,
Timing,
Processor scheduling"
Executive information systems: their impact on executive decision making,"An executive information system (EIS) is a computer-based information system designed to provide senior managers with access to information relevant to their management activities. The use of these systems by executives may become a particularly important component of their decision making behavior. The effects of EIS use on aspects of the decision making process are examined by surveying 46 executive users of EIS. The frequency of EIS use and the length of time of EIS use are shown to increase problem identification speed, decision making speed, and the extent of analysis in decision making.","Information systems,
Decision making,
Management information systems,
Decision support systems,
Information management,
Spatial databases,
Information analysis,
Globalization,
Frequency,
Availability"
Project Triton: towards improved programmability of parallel machines,"The approach taken in the Triton project is to let a high-level machine-independent parallel programming language drive the design of parallel hardware. This approach permits machine-independent parallel programs to be compiled into efficient machine code. The main results are as follows: (1) The parallel programming language Modula-2* extends Modula-2 with constructs for expressing a wide range of parallel algorithms in a high-level, portable, and readable way. (2) Techniques are used for efficiently translating Modula-2* programs to several modern parallel architectures and deriving recommendations for future parallel machine architectures. (3) Triton/1 is a scalable, mixed-mode SIMD/MIMD parallel computer with a highly efficient communications network. It overcomes several deficiencies of current parallel hardware and adequately supports high-level parallel languages.","Parallel machines,
Parallel programming,
Hardware,
Parallel algorithms,
Parallel architectures,
Computer architecture,
Computer networks,
Concurrent computing,
Portable computers,
Communication networks"
Reusable component retrieval for real-time applications,"The growth of reuse and the advent of software repositories has led to the design of mechanisms to retrieve reusable assets. The most popular retrieval mechanisms, namely browsers, keyword searches, and multi-attribute searches offer limited precision in large domains or across domains. The use of formal algebraic specifications as search keys for reusable components leads to increased precision and forms the basis for future automated component integration. Components with real-time characteristics add another dimension to the search process. The paper proposes a method for retrieving reusable components using formal specifications with additional filters to find components that meet specific real-time criteria.","Formal specifications,
Computer science,
Software reusability,
Keyword search,
Application software,
Real time systems,
Software engineering,
Springs,
Filters,
Time factors"
,,
Hierarchical learning of robot skills by reinforcement,"It is shown how reinforcement learning can be made practical for complex problems by introducing hierarchical learning. The agent at first learns elementary skills for solving elementary problems. To learn a new skill for solving a complex problem later on, the agent can ignore the low-level details and focus on the problem of coordinating the elementary skills it has developed. A physically-realistic mobile robot simulator is used to demonstrate the success and importance of hierarchical learning. For fast learning, artificial neural networks are used to generalize experiences, and a teaching technique is employed to save many learning trials of the simulated robot.",
Timed Petri net models of flexible manufacturing cells,"It is shown that a class of flexible manufacturing cells can be conveniently modeled and evaluated by timed Petri nets. For simple schedules, the modeling nets are covered by conflict-free invariant subnets, so the performance of the model is determined by the performance of its subnets. For composite schedules, the invariant subnets are free-choice, so a more elaborate approach to evaluating the performance of the model must be used.","Flexible manufacturing systems,
Virtual manufacturing,
Job shop scheduling,
Petri nets,
Throughput,
Robots,
Frequency,
Robotics and automation,
Computer science,
Computer aided manufacturing"
A proposal for error-tolerating codes,"An extended concept of error-tolerating codes is presented and some examples of error-tolerating codes are introduced. An erroneous codeword of the proposed error-tolerating code may occur in the codespace; however, in this case, the erroneous codeword is required to be in a defined neighborhood of the original codeword. When no error is detected in a word, the word may differ from the original codeword, but it is trustworthy and can be used in a system without any error-correction or error-recovery procedures. An error-tolerating code is presented as an example. This code can be used for to implement analog-to-digital converting devices which are useful for dependable high-speed real-time control systems.","Proposals,
Computer errors,
Error correction codes,
Computer science,
Real time systems,
Control systems,
Fault tolerance,
Hamming distance"
Facilitating the comprehension of C-programs: an experimental study,"A software environment called CARE (computer-aided re-engineering) that facilitates the comprehension of existing C programs is described. Program comprehension in CARE is accomplished by visualizing program dependencies (i.e. entities and their relations). A repository of such dependencies is maintained and displayed using a graphical model which combines control and data-flow information. Moreover, CARE entails transformation tools and abstraction mechanisms that support monolithic and multiple-view organization of program dependencies. Results from an experimental study with the CARE environment has shown that the productivity of its users was increased and the quality of the changes made during a software maintenance task was improving. Finally, the lessons learned from an empirical evaluation of the CARE environment indicated that its graphical model, transformation tools and abstraction mechanisms constitute a promising platform for the comprehension of C programs.","Software maintenance,
Graphical models,
Software tools,
Visualization,
Computer science,
Productivity,
Computer displays,
User interfaces,
History,
Tail"
A smart buffer for tracking using motion data,"Responsive vision is vision responding to the environment. The characteristics of a responsive system are: active response in dynamic environment, real time computation, and using multiple modalities in a multi-purpose system. The vision engine is a general purpose for general vision tasks. Early vision processing, e.g., optical flow and stereo is implemented in near real-time using the Datacube, producing dense displacement fields at near video rates, which are then transferred to a transputer subsystem, where data dependent processing occurs in parallel on subimages. The authors use the vision engine for complex processing under real-time constraints, the differences between the processing rates in a robotic system require smart buffers, objects that can buffer data between perception, reasoning and action processes. Smart buffers offer a simple interface between asynchronous processing tasks and simplify the structure of multiprocessor vision systems. The authors describe a simple motion tracker that uses a smart buffer to mediate between early and middle vision processing. The smart buffer permits the system to sense during action by letting the sensing component accumulate visual data in the course of action.","Tracking,
Real time systems,
Machine vision,
Intelligent robots,
Robot vision systems,
Robot sensing systems,
Sensor systems,
Computer science,
Optical buffering,
Optical sensors"
Microprocessor design for nonelectrical engineers: an integrated project oriented approach,The instructional techniques used at Georgia Institute of Technology in the undergraduate microprocessor laboratory class in the School of Mechanical Engineering are described. The class stresses two nontraditional teaching methods. The class is taught in an integrated style with both software and hardware concepts being introduced and developed simultaneously. The class includes a final project in which groups of students are required to complete a design project that integrates hardware and software design with electronic interfacing design and mechanical systems analysis. An overview of the curriculum is presented as an introduction to the novel teaching methods. The methods are also illustrated by project descriptions drawn from the class archives.,"Microprocessors,
Design engineering,
Mechanical engineering,
Assembly,
Hardware,
Engineering education,
Read only memory,
Software design,
Electrical engineering,
Digital circuits"
An efficient algorithm for VLSI network partitioning problem using a cost function with balancing factor,"This paper presents an efficient algorithm for network partitioning problem, which improves Fiduccia and Mattheyses' (F-M's) algorithm (1982). We have noticed that the main problem of F-M's algorithm is that the cell move operation is largely influenced by the balancing constraint. In order to handle this kind of inherent limitation in F-M's algorithm, a cost function is adopted which reflects balance degree of a partition as well as its cutset size. The weighting factor R is introduced in the cost function to determine the relative importance of the two factors: cutset size and balance degree. Using this cost function, we propose an iterative improvement algorithm which has the time complexity of O(b(m+c/sup 2/)), where b is the number of blocks, m is the size of network, and c is the number of cells. It is proven that the proposed algorithm guarantees to find a balanced partition if the value of R satisfies a certain condition. Experimental results show that the proposed algorithm outperforms F-M's algorithm in most cases.","Partitioning algorithms,
Very large scale integration,
Cost function,
Iterative algorithms,
Computer science,
Integrated circuit interconnections,
Design automation,
Heuristic algorithms,
Polynomials"
A formal model of re-execution in software process,"Redoing has been introduced as a fundamental mechanism to handle the dynamics and flexibility required in the software process. It is an operation that involves canceling a part of a process enaction that is polluted by erroneous and incomplete activities and doing that part again. In order to make redoing effective, it is essential to detect the cause of errors correctly. A functional model that makes it easy to do this by dependency analysis is presented. A formal semantics of redoing this metaoperations which can handle the computational history as data is given. Its effectiveness is shown using the ISPW6 example process. Some extensions to minimize the cost of reexecution and to create scripts incrementally are proposed.",
Multiprocessor join scheduling,"A practical join processing strategy that allows effective utilization of arbitrary degrees of parallelism in both the I/O subsystem and join processing subsystems is presented. Analytic bounds on the minimum execution time, minimum number of processors, and processor utilization are presented along with bounds on the execution time, given a fixed number of processors. These bounds assume that sufficient buffers are available. An analytic lower bound on buffer requirements as well as a practical heuristic for use in limited buffer environments are also presented. A sampling of corroborative simulation results are included.","Parallel processing,
Processor scheduling,
Concurrent computing,
Computer science,
Costs,
System performance,
Laboratories,
Bandwidth,
Query processing,
Sampling methods"
Efficient feed-forward volume rendering techniques for vector and parallel processors,"Rendering volumes represented as a 3D grid of voxels requires an overwhelming amount of processing power. In this paper we investigate efficient techniques for rendering semi-transparent volumes on vector and parallel processors. Parallelism inherent in a regular grid is obtained by decomposing the volume into geometric primitives called beams, slices and slabs of voxels. By using the adjacent properties of voxels in beams and slices, efficient incremental transformation schemes are developed. The slab decomposition of the volume allows the implementation of an efficient parallel feed-forward renderer which includes the splatting technique for image reconstruction and a back-to-front method for creating images. The authors report the implementation of this feed-forward volume renderer on a hierarchical shared memory machine with individual pipelined processors.","Feedforward systems,
Rendering (computer graphics),
Pixel,
Slabs,
Matrix decomposition,
Image reconstruction,
Concurrent computing,
Grid computing,
Information science,
Parallel processing"
Optimal control of a somersaulting platform diver: a numerical approach,"The somersaulting maneuver of a platform diver is studied. An effective numerical approach for obtaining an optimal solution for this motion is given. The diver is modeled as a planar system of interconnected multibodies, and controllability is proved in a sense dictated by the problem. A time-optimal control problem with state and control constraints is set up and solved using a numerical approach. The numerical solution agrees well with motions executed by professional divers.","Optimal control,
Controllability,
Hip,
Shoulder,
Mechanical engineering,
Computer science,
Automation,
Robustness,
Interconnected systems,
Manipulator dynamics"
Interacting visual abstractions of programs,What visual program abstractions support programming? We explore this question for object-oriented programming with reference to programming tasks such as modification engineering and program development. We present ten related abstractions (views) of a program using visual constructs based on empirical and observational studies. We explain the dynamic and interactive nature of the views and suggest how they would be used in programming tasks.,"Data visualization,
Programming profession,
Dynamic programming,
Object oriented programming,
Computer science,
Distributed control,
Displays,
Humans,
Information processing,
Computer languages"
Wavelet transform embeddings in mesh architectures,"To efficiently use wavelet transforms in parallel mesh architectures, it is necessary to identify efficient embeddings of wavelet transform coefficients into such meshes. Two forms of 2D wavelet transform embedding into 2D meshes (with and without reconfigurability) are considered, and time performances for these embeddings over classes of image processing algorithms are compared. This demonstrates the superiority of one of these embeddings.","Wavelet transforms,
Image resolution,
Filters,
Computer architecture,
Signal resolution,
Costs,
Performance evaluation,
Computer science,
Image processing,
Signal processing"
On over-the-cell channel routing,The authors consider two over-the-cell channel routing problems: the over-the-cell planar routing problem and the over-the-cell net assignment problem. They present optimal algorithms for solving the two problems. Experimental results are also provided to demonstrate the efficiency and effectiveness of the algorithms.,"Routing,
Pins,
Roentgenium,
Sun,
Computer science,
Fabrication"
A best-first language processing model integrating the unification grammar and Markov language model for speech recognition applications,"A language processing model is proposed in which the grammatical approach of unification grammar and the statistical approach of Markov language models are properly integrated in a word lattice chart parsing algorithm with different best-first parsing strategies. This model has been successfully implemented in experiments on Mandarin speech recognition although it is language-independent. Test results show that significant improvements in both correct rate of recognition and computation speed can be achieved. A correct rate of 93.8% and 5 s per sentence on an IBM PC/AT, as compared with 73.8% and 25 s using unification grammar alone and 82.2% and 3 s using a Markov language model alone, was achieved. This high performance is due to the effective rejection of noisy word hypothesis interferences; that is, the unification-based grammatical analysis eliminates all illegal combinations, while the Markovian probabilities of constituents combined with the considerations on constituent length indicate the correct direction of processing.","Natural languages,
Lattices,
Speech recognition,
Acoustic applications,
Signal processing,
Signal processing algorithms,
Testing,
Computer science,
Information science,
Interference elimination"
Modelling and proving of truly concurrent systems with CATNets,Concurrent Algebraic Term Nets (CATNets in short) are a semi-graphical formalism for modelling and prototyping concurrent systems. In this paper we show how this formalism may be used to design an elegant solution to a router problem. Then we show how the semantic framework of CATNets may be used to perform automatic proving.,"Petri nets,
Logic,
Computer science,
Concurrent computing,
Software design,
Data models,
Prototypes,
Equations"
Selectivity,"A set is P-selective if there is a polynomial-time (p-time) semi-decision algorithm for the set-an algorithm that, given any two strings, decides which is ""more likely"" to be in the set. This paper studies two natural generalizations of P-selectivity: the NP-selective sets and the sets reducible to P-selective sets via p-time reductions. We show that even NP-selective sets are unlikely to be NP-complete, and we establish a strict hierarchy among the various reductions to P-selective sets.",
"Passive-space and time view: vector clocks for achieving higher performance, program correction, and distributed computing","We have noticed two problems with viewing a process as a sequence of events. The first problem is the complete loss of information about potential intra-process concurrency for both sequential and distributed computations, and partial loss of information about potential inter-process concurrency for distributed computations. The second problem is that the resulting reasoning framework does not lend itself to refinement (from sequential computing or a given set of distributed processes) to a preferable set of distributed processes. We argue that it is more natural to view a computation, either distributed or sequential, as a partially ordered set of events. Doing so leads to a view, called passive-space and time view, which we propose. To aid users of the relation ""Affects"" in developing algorithms, we define vector clocks, that are global logical clocks, so that the relation ""Affects"", and hence all potential concurrency, between events can be identified from their timestamps assigned.","Clocks,
Concurrent computing,
Distributed computing,
Costs,
Performance loss,
High performance computing,
Process design,
Parallel processing,
Debugging,
Computer science"
Predictability of load/store instruction latencies,"Presents a model of coarse grain dataflow execution. The authors present one top down and two bottom up methods for generation of multithreaded code, and evaluate their effectiveness. The bottom up techniques start from a fine-grain dataflow graph and coalesce this into coarse-grain clusters. The top down technique generates clusters directly from the intermediate data dependence graph used for compiler optimizations. The authors discuss the relevant phases in the compilation process. They compare the effectiveness of the strategies by measuring the total number of clusters executed, the total number of instructions executed, cluster size, and number of matches per cluster. It turns out that the top down method generates more efficient code, and larger clusters. However the number of matches per cluster is larger for the top down method, which could incur higher cluster synchronization costs.<>","Yarn,
Size measurement,
Parallel processing,
Delay,
Hardware,
Computer science,
Costs,
Hybrid power systems,
Computer architecture,
Registers"
The development and implementation of a cell controller framework,"National Semiconductor Corporation (NSC) was selected by SEMATECH as one of two semiconductor companies for pilot testing a cell control architecture that is referred to as the strategic cell controller (SCC) throughout this paper. SCC is an architecture for semiconductor equipment real time control, monitoring, and integration to the rest of the factory. SCC was developed with the objective of supplying the industry with a common framework for cell controllers. This paper describes the architecture framework of the SCC under the NSC fabrication automation context. The heart of SCC is the integrated tool architecture that provides a logical configuration and integration of software automation tools for real time control capabilities in a truly distributed processing and client/server manner. SCC also provides a generic layer of equipment interfaces named 'virtual factory equipment interfaces' (VFEI) that can accommodate many other industry standards for equipment interface.","Automatic control,
Computer architecture,
Manufacturing automation,
Semiconductor device testing,
Monitoring,
Production facilities,
Industrial control,
Fabrication,
Heart,
Software tools"
Discovery of inexact concepts from structural data,"Concept discovery in structural data requires the identification of repetitive substructures in the data. A method for discovering substructures in data using an inexact graph match is described. An implementation of the authors' SUBDUE system that employs an inexact graph match to discover substructures which occur often in the data, but not always in the same form, is described. This inexact substructure discovery can be used to formulate fuzzy concepts, compress the data description, and discover interesting structures in data that are found either in an identical or in a slightly convoluted form. Examples from the domains of scene analysis and chemical compound analysis demonstrate the benefits of the inexact discovery technique.","Psychology,
Image analysis,
Chemical analysis,
Data analysis,
Databases,
Chemical compounds,
Data compression,
Data mining,
Computer science,
Heuristic algorithms"
Visual echo analysis,"The term visual echoes is introduced as a common framework for the analysis of multi-frame optical flow, binocular and trinocular stereo, stationary texture and boundary symmetries. The authors examined cepstral filtering, a powerful nonlinear adaptive technique for the retrieval of echoes, as a common methodology to address these visual routines. They consider the application of cepstral analysis to computational vision, review improvements to traditional methods, and provide a comparison with other routines presently used. A general multievidential correlation approach is introduced which lends itself to several computational techniques. CepsCorr, it is called, is a simple general technique that can accept different matching routines as its measurement kernel. The evidence provided by each iteration of cepsCorr can then be combined to provide a more accurate estimate of motion or binocular disparity.","Cepstral analysis,
Cepstrum,
Filtering,
Sea measurements,
Motion analysis,
Kernel,
Intelligent robots,
Layout,
Computer vision,
Computer science"
Image Understanding: A Driving Application for Research in Heterogeneous Parallel Processing,,
Efficient evaluation of traversal recursive queries using connectivity index,"Introduces the connectivity index, an access structure for the efficient evaluation of traversal-recursive queries. Unlike conventional bottom-up evaluation techniques that require the creation of temporary files and scanning of the relations many times in computing the relational operators, the new access strategy requires only a single-pass scan of the index file. The proposed scheme is illustrated using examples. Algorithms for the maintenance of the index structure are presented.","Data structures,
Computer science,
Indexes,
Spatial databases,
Deductive databases,
Tree graphs,
Bills of materials,
Clustering algorithms,
Data models,
Ear"
A parallel object-oriented framework for stencil algorithms,"The authors present an object-oriented framework for constructing parallel implementations of stencil algorithms. This framework simplifies the development process by encapsulating the common aspects of stencil algorithms in a base stencil class so that application-specific derived classes can be easily defined via inheritance and overloading. In addition, the stencil base class contains mechanisms for parallel execution. The result is a high-performance, parallel, application-specific stencil class. The authors present the design rationale for the base class and illustrate the derivation process by defining two subclasses, an image convolution class and a PDE solver. The classes have been implemented in Mentat, an object-oriented parallel programming system that is available on a variety of platforms. Performance results are given for a network of Sun SPARCstation IPCs.","Convolution,
Iterative algorithms,
Parallel programming,
Sun,
Workstations,
Computer science,
Partial differential equations,
Concurrent computing,
Parallel architectures,
Investments"
Identification of thermal and electrical time constants in SOIMOSFETS from small signal measurements,This paper describes the use of small-signal drain admittance measurements to characterise the dynamic behaviour of SOI MOSFETS. The techniques are used to identify clearly and quantify the electrical and thermal internal feedback mechanisms which give rise to anomalous time and frequency domain behaviour.,"Signal processing,
Electric variables measurement,
Time measurement,
Feedback,
Thermal resistance,
Immune system,
Electric resistance,
MOSFETs,
Frequency,
Admittance"
A New Block Coded Modulation Scheme and its Soft Decision Decoding,,"Modulation coding,
Decoding,
Error correction codes,
Block codes,
Protection,
Computer science,
Mathematics,
Digital modulation,
Digital communication,
Hamming distance"
Neural networks in specification level software size estimation,"Presents a neural network approach to software size estimation. A multilayer feedforward network is trained using the backpropagation algorithm. The training and testing data consist of randomly generated structured analysis descriptions as input data and corresponding algorithm based size metric values as output data. The size metrics used in the experiments are Albrecht's (1979) function points, Symon's (1988) Mark II function points, and DeMarco's (1982) function bang metric. The experiments indicate that neural networks can learn to calculate software size estimates. In each of the experiments it was found that the results depend on the features of the input data, the metric, and the convergence criteria used. The results also encourage the development of a general input set to represent size-related features of graph-based system descriptions.","Neural networks,
Intelligent networks,
Size measurement,
Software measurement,
Backpropagation algorithms,
Testing,
Costs,
Software systems,
Computer science,
Multi-layer neural network"
Realtime collision detection for virtual reality applications,"Virtual reality technology aims at the expansion of the communication bandwidth by providing users with 3D immersive environments. For the true direct manipulation of the environments, fast collision detection must be provided to increase the sense of reality. A collision detection scheme for virtual reality applications is proposed. The method exploits a hierarchical object representation to facilitate the detection of colliding segments.","Virtual reality,
Object detection,
Application software,
Bandwidth,
Humans,
Artificial intelligence,
Computer science,
Computer graphics,
Robot sensing systems,
Data structures"
Enhancing accuracy of software reliability prediction,"The measurement and prediction of software reliability require the use of the software reliability growth models (SRGMs). The predictive quality can be measured by the average end-point projection error. In this paper, the effects of two orthogonal classes of approaches to improve prediction capability of a SRM have been examined using a large number of data sets. The first approach is preprocessing of data to filter out short term noise. The second is to overcome the bias inherent in the model. The results show that proper application of these two approaches can be more important than the selection of the model.","Software reliability,
Software testing,
Predictive models,
Application software,
System testing,
Filters,
Smoothing methods,
Computer science,
Software measurement,
Costs"
Folded Petersen cube networks: new competitors for the hypercubes,"We introduce and analyze a new interconnection topology, called the k-dimensional folded Petersen (F P/sub k//) network, which is constructed by iteratively applying the cartesian product on the well-known Petersen graph. Our generalization, the folded Petersen cube F P Q/sub n,k/ = Q /sub n/ /spl times/ F P/sub k//, is a product of the n-dimensional binary hypercube (Q/sub n/) and F P/sub k//. The P FQ/sub n,k/ topology provides regularity, node-and edge-symmetry, optimal connectivity (and therefore maximal fault-tolerance), logarithmic diameter, modularity, and permits self-routing and broadcasting algorithms even in the presence of faults. With the same node-degree and connectivity, F PQ/sub n,k/ provides smaller diameter with more nodes and higher packing density than the (n + 3k)-dimensional binary hypercube Q/sub n+3k/. Also F PQ/sub n,k/ admits efficient embeddings of many computationally important structures such as rings, meshes, hypercubes, and several tree-related networks.","Hypercubes,
Network topology,
Computer science,
Costs,
Broadcasting,
Fault tolerance,
Computer networks,
Embedded computing,
Tree graphs,
Multiprocessor interconnection"
A robust over-the-cell channel router,"An efficient algorithm for over-the-cell routing in the standard cell layout design technology is presented. Two variations are discussed: one aims to minimize the channel density with fewest tracks over the cells while the other aims to minimize the final channel width. The algorithm can fit both the two-layer and three-layer routing models. With the two-layer model, there is a single routing layer over the cells for intercell connections. With the three-layer model, there are two disjoint routing layers over the cells for intercell connections. In this approach, the problem is decomposed into two phases: (1) over-the-cell routing and (2) conventional channel routing. The over-the-cell routing phase, which is executed iteratively, consists of two steps, routing over the cells and choosing net segments within the channel. For each iteration in the over-the-cell routing phase, the algorithm removes a net or a subnet which intersects the column with the highest column density and routes it over the cells according to some prioritized criteria. In comparison with the previous researches, this approach achieved the best effectiveness and has used the least CPU-time.","Robustness,
Routing,
Integrated circuit interconnections,
Information science,
Algorithm design and analysis,
Iterative algorithms,
Very large scale integration,
Fabrication,
Councils,
Integrated circuit modeling"
An iterative combinational logic synthesis technique using spectral information,The spectral information of a Boolean function provides data regarding the correlation between the input variables and the output of the function. A spectral based methodology for combinational logic synthesis using linear transforms is introduced. An analysis of the properties of the spectra obtained from these transforms is provided and a synthesis algorithm using spectral techniques is presented. This result is significant since it provides an algebraic method for including XOR gates in the synthesis process without resorting to manipulation of symbolic Boolean equations.,"Boolean functions,
Circuit synthesis,
Vectors,
Input variables,
Multivalued logic,
Logic circuits,
Computer science,
Data engineering,
Algorithm design and analysis,
Digital systems"
Global navigation for ARK,"ARK (Autonomous Robot for a Known environment), is a visually-guided mobile robot which is being constructed as part of the Precarn project in mobile robotics. ARK operates in a previously mapped environment and navigates with respect to visual landmarks that have been previously located. While the robot moves, it utilizes an active vision sensor to register the robot with respect to these landmarks. As the landmarks may be scarce in certain regions of its environment, ARK plans paths which minimize both path length and path uncertainty. The global path planner assumes that the robot will use a Kalman filter to integrate landmark information with odometry data to correct path deviations as the robot moves, and then uses this information to choose a path which reduces the expected path deviation.","Navigation,
Robot sensing systems,
Service robots,
Mobile robots,
Robot vision systems,
Path planning,
Remotely operated vehicles,
Manufacturing industries,
Computer science,
Infrared sensors"
A practical constant time sorting network,"The authors propose a novel VLSI sorting network implementing Leighton's column sort. The network is mech-based and modular; it consists of comparison-exchange processing elements (PEs), routing paths, and short broadcast buses. Each bus contains a small number of simple switches that the authors call shift switches. They enhance and simplify the previously proposed shift switching mechanism to obtain an efficient O(1) VLSI-optimal sorting algorithm. From a theoretical perspective, the new approach reduces significantly both the number of PEs (from N/sup 2/ to N/sup 13/9/) and the number of broadcasts from more than 58 bus broadcasts, each over N switches, to at most 16 bus broadcasts, each over N/sup 4/9/ switches. From a practical standpoint, the network features a significant time-performance gain in comparison with the bitonic sorting circuit, especially when multiple smaller size arrays are sorted in parallel.","Sorting,
Switches,
Broadcasting,
Very large scale integration,
Circuits,
Delay,
Computer science,
Optical arrays,
Routing,
Performance gain"
Parallel software engineering with PARSE,"The aims of the PARSE methodology are described, and the process graph design notation is summarised. Process graphs are a new graphical notation for describing systems comprising a collection of parallel processes in a language- and architecture-independent fashion. Further, process graph designs can be mechanically transformed into Petri nets to give a more detailed, executable design specification. Some simple process graphs and their corresponding Petri nets are described in order to demonstrate this transformation process. A more extensive example then illustrates the initial stages of the design process in practice.","Software engineering,
Process design,
Petri nets,
Process control,
Computer science,
Performance analysis,
Computer aided software engineering,
Control systems,
Design engineering,
Australia"
Evaluation of closely coupled systems for high performance database processing,"Closely coupled systems aim at a more efficient communication and cooperation between processing nodes compared to loosely coupled systems. This can be achieved by using globally shared semiconductor memory to speed up the exchange of messages or to store global data structures. For distributed database processing, the database sharing (shared disk) architecture can benefit most from such a close coupling. The author presents a detailed simulation study of closely coupled database sharing systems. A shared store called global extended memory (GEM) was used for system-wide concurrency and coherency control, and to improve input/output (I/O) performance. The performance of such an architecture is evaluated and compared with loosely coupled database sharing systems employing the primary copy approach for concurrency and coherency control. In particular, the impact of different update strategies (FORCE vs. NOFORCE) and workload allocation schemes (random vs. affinity-based routing) is studied. The use of shared disk caches implementing a global database buffer is also considered. Simulation results are presented for synthetically generated debit-credit workloads and a real-life workload represented by a database trace.","Transaction databases,
Distributed databases,
Relational databases,
Control systems,
Scalability,
Operating systems,
Computer science,
Semiconductor memory,
Data structures,
Concurrent computing"
Efficient out-of-core algorithms for linear relaxation using blocking covers,"When a numerical computation fails to fit in the primary memory of a serial or parallel computer, a so-called ""out-of-core"" algorithm must be used which moves data between primary and secondary memories. In this paper, we study out-of-core algorithms for sparse linear relaxation problems in which each iteration of the algorithm updates the state of every vertex in a graph with a linear combination of the states of its neighbors. We give a general method that can save substantially on the I/O traffic for many problems. For example, our technique allows a computer with M words of primary memory to perform T=/spl Omega/(M/sup 1/5/) cycles of a multigrid algorithm for a two-dimensional elliptic solver over an n-point domain using only /spl Theta/(nT/M/sup 1/5/) I/O transfers, as compared with the naive algorithm which requires /spl Omega/(nT) I/O's.","Vectors,
Computer science,
Concurrent computing,
Iterative algorithms,
National electric code,
Transmission line matrix methods,
Jacobian matrices,
Gaussian processes,
Equations,
Costs"
Acceleration methods for the iterative solution of electromagnetic scattering problems,"We present a simple but effective technique for accelerating the convergence of iterative methods in the solution of electromagnetic scattering problems described by a second-kind integral equation (SKIE). We call the technique “complexification and extrapolation,” or simply “complexification.” It is based on the mathematical principle of limiting absorption, and it alleviates the difficulties arising from the interior resonances of this SKIE, thus allowing the efficient solution of scattering from electrically large objects. The technique involves introducing an imaginary part to the real wavenumber and solving the problem, then repeating with a different imaginary part and extrapolating the solutions linearly back to the real axis. For higher-order extrapolations we use additional complex wavenumbers. We have tested the method on a number of closed two-dimensional conducting scatterers, using this SKIE discretized by Nyström's method and solved by the fast multipole method. We use a variant of the conjugate gradient (CG) method that we call the pseudoconjugate gradient (PCG) method. The PCG method as we employ it performs only 1.2 matrix vector products on average per iteration, as opposed to two for the standard CG. Complexification gives excellent results. Solutions are fast and accurate. The condition number of the discrete matrix is asymptotically bounded for a given problem as the number of points per wavelength increases. The empirical evidence we have gathered thus far also suggests that the condition number is essentially asymptotically bounded as the electrical size of the scatterer increases, holding the number of points per wavelength fixed. Thus the technique has great potential in the solution of scattering from electrically large objects. Note that the technique of complexification is not limited to the fast multipole method and should be of broad applicability in the numerical solution of scattering problems.","Iterative methods,
Acceleration,
Extrapolation,
Electromagnetic scattering,
Integral equations,
Convergence"
An efficient and highly available read-one write-all protocol for replicated data management,"A read-one write-all (ROWA) protocol for replicated data that allows a system to adjust to failures dynamically in order to keep the data available is proposed. If failures arrive mostly sequentially, the protocol keeps the data available as long as there is at least one operational replica. This is achieved by making the epoch mechanism, previously applicable to non-ROWA schemes only, usable within the ROWA discipline. Also, adjusting the system to a new configuration in the protocol is done completely asynchronously with reads and writes. In contrast, in the existing dynamic schemes (both ROWA and non-ROWA), system reconfiguration may interfere with and delay user transactions.","Protocols,
Engineering management,
Computer science,
Data engineering,
Delay,
Permission,
Application software,
Proposals,
Control systems"
Adaptive wormhole routing in hypercube multicomputers,"We propose a uniform adaptive routing strategy for wormhole-routed hypercube networks that accommodates both unicast and multicast communication. Based on a node labeling method, the resultant routing algorithms are shown to be deadlock-free without requiring virtual channels. The order in which the destinations are visited is important to efficiency. We present an ordering algorithm, quadratic in the number of destinations, which is optimal in that it minimizes the traffic generated under the proposed paradigm. A greedy algorithm is also proposed for ordering the destinations, which requires less time and space to execute but creates more traffic than the optimal algorithm. Simulation results that evaluate the performance of the proposed routing algorithms are presented.","Routing,
Hypercubes,
Multicast algorithms,
System recovery,
Unicast,
Intelligent networks,
Computer science,
Labeling,
Greedy algorithms,
US Department of Energy"
An Approach Towards Predictable Real-Time Transaction Processing,,
Representation and symbolic manipulation of linearly inductive Boolean functions,"We consider a class of practically useful Boolean functions, called linearly inductive functions (LIFs), and present a canonical representation as well as algorithms for their automatic symbolic manipulation. LIFs can be used to capture structural induction in parameterized circuit descriptions, whereby our LIF representation provides a fixed-sized representation for all size instances of a circuit. Furthermore, since LIFs can naturally capture the temporal induction inherent in sequential system descriptions, our representation also provides a canonical form for sequential functions. This allows for a wide range of applications of symbolic LIF manipulation in the verification and synthesis of digital systems. We also present practical results from a preliminary implementation of a general purpose LIF package.","Boolean functions,
Circuits,
Binary decision diagrams,
Hardware,
Adders,
Automata,
Computer science,
Radio access networks,
Packaging,
Very large scale integration"
Optimal design of reference models using simulated annealing combined with an improved LVQ3,"For the recognition of large-set handwritten characters, classification methods based on pattern matching have been commonly used, and good reference models play a very important role in achieving high performance in these methods. Learning vector quantization (LVQ) has been studied intensively to generate good reference models in speech recognition since 1986. However, the design of reference models based on LVQ has several drawbacks for the recognition of large-set handwritten characters. To cope with these, the authors propose a method for the optimal design of reference models using simulated annealing combined with an improved LVQ3 for the recognition of large-set handwritten characters. Experimental results reveal that the proposed method is superior to the conventional method based on averaging and other LVQ-based methods.","Simulated annealing,
Handwriting recognition,
Ink,
Speech recognition,
Character recognition,
Iterative algorithms,
Computational modeling,
Computer science,
Pattern recognition,
Pattern matching"
Visual tools for temporal reasoning,"We describe a prototype toolkit for reasoning about Graphical Interval Logic (GIL) specifications of concurrent systems. GIL is a visual temporal logic that is intended to be more intuitive and easier to use than standard textual temporal logics. The GIL toolkit helps system designers to create graphical specifications of concurrent systems, to verify properties of those systems from their specifications, and to generate models that satisfy the specifications. The toolkit provides a visual interface with specifications, proofs, and models all depicted graphically. The paper describes the toolkit, discusses its implementation, and provides an illustration of its use.","Gas insulated transmission lines,
Logic design,
Timing,
Prototypes,
Computer science,
Hardware,
Signal design,
User interfaces,
Formal specifications,
Software design"
Catastrophic forgetting in neural networks: the role of rehearsal mechanisms,"The author examines the problem of catastrophic forgetting-the overwriting of old information-in neural networks. He notes that R. Ratcliff's (1990) experiments with rehearsal regimes are a possible solution to catastrophic forgetting and describes sweep rehearsal-a much more effective regime. The use of sweep rehearsal, however, eventually encounters practical limits as the ability to recognize learned items begins to diminish. The author suggests that sweep rehearsal extends the approach of rehearsal mechanisms as far as is practicable, and exposes their eventual limitations.","Intelligent networks,
Neural networks,
Supervised learning,
Information processing,
Unsupervised learning,
Computer science,
Robustness,
Formal specifications,
Stability,
Learning systems"
New redundant representations of complex numbers and vectors,"The authors present a redundant representation for complex numbers called polygonal representation. This representation enables fast carry-free addition, in a way quite similar to the carry-free addition in signed-digit number systems and is convenient for multiplication. The technique is generalized in order to handle n-dimensional vectors.",
The implementation of a first-order logic AGM belief revision system,"Belief revision is increasingly being seen as central to a number of fundamental problems in artificial intelligence such as nonmonotonic reasoning, reasoning about action, truth maintenance and database update. The authors describe the first implementation of an AGM belief revision system. The system is based on classical first-order logic, and for any finitely representable belief state, it efficiently computes expansions, contractions and revision satisfying the AGM postulates for rational belief change. The system uses a finite base to represent a belief set, and interprets a partially specified entrenchment as representing a unique most conservative entrenchment-this is motivated by considerations of evidence and by the close connections between belief revision and nonmonotonic reasoning. The authors describe in detail the algorithms for belief change, and give some examples of the system's operation.","Logic,
Artificial intelligence,
Databases,
Knowledge based systems,
Computer science,
Qualifications,
Power system modeling,
Mathematical model,
Computational modeling"
Knowledge-based systems: an exploratory study of new developers,"It is pointed out that matching potentially strong developers with appropriate knowledge-based system (KBS) development projects can optimize an organization's allocation of scarce human and financial resources. In a broader sense, it can contribute to supporting an organization's effort to develop the creative computer systems necessary for competitive positioning. To test this hypothesis, the authors report the results of a study of 91 developers new to KBS technology. This group served as a test bed to explore an answer to the question 'can we learn what kind of developer creates a successful (i.e., innovative and useful) knowledge-based system?' In other words, it there a 'successful KBS developer' profile? The results provide tentative answers that need to be reconsidered with more rigorous further study.","Knowledge based systems,
Humans,
System testing"
Techniques for multimodality image registration,"The authors describe the development of techniques used for cross-modality correlation of medical images. To accomplish this goal, software routines were developed which automate and standardize the comparison of images within and between three-dimensional tomographic imaging modalities. Data from phantoms and clinical studies reflect the success of this technique.","Image registration,
Magnetic heads,
Biomedical imaging,
Optical imaging,
Positron emission tomography,
Computed tomography,
Magnetic resonance imaging,
Image analysis,
Radiology,
Computer science"
Knowledge based tools for risk assessment in software development and reuse,The authors present the techniques and architecture of a knowledge-based support system currently under development for risk analysis in software generation and reuse processes. They describe the main components and their relationships. Another tool that supports risk reduction is for consistency management. This tool analyzes the effects of changes and repairs.,
Data shaders,"The process of visualizing a scientific data set requires an extensive knowledge of the domain in which the data set is created. Because an in-depth knowledge of all scientific domains is not available to the creator of visualization software, a flexible and extensible visualization system is essential in providing a productive tool to the scientist. This paper presents a shading language, based on the RenderMan shading language, that extends the shading model used to render volume data sets. Data shaders, written in this shading language, give the users of a volume rendering system a means of specifying how a volume data set is to be rendered. This flexibility is useful both as a visualization tool in the scientific community and as a research tool in the visualization community.",
Implementing KADS expertise models with Model-K,"The KADS (knowledge acquisition and design structuring) system, which guides knowledge engineering using organizational models, task models, expertise models, cooperation models, and design models, is reviewed. Model-K, the result of combining high-level languages with KADS to reach a smoother and speeder transition from the conceptual model to a prototype and the running system, is reviewed. Model-K closes the gap between the knowledge level and the symbolic level, letting developers specify KADS conceptual models and refine them to operational systems. The language lets developers arbitrarily interleave both activities, thereby supporting early prototyping at the highest level. Systems written in model-K contain their own conceptual model, making them more transparent and easier for experts and users to understand and for knowledge engineers to maintain.",
Distance accumulation and planar curvature,"The authors present a method, called distance accumulation, of computing features of closed planar boundaries of 2-D digital images, or closed curves. Distance accumulation is computed by accumulating the distance from a point in the boundary to a chord specified by moving end points. Experimental results with simulated and real images showed its robustness. The analysis of its relation to planar curvature matches experimental results well.",
Fault-tolerant integration of abstract sensor estimates using multiresolution decomposition,"This paper proposes a method of applying the idea of multiresolution to the problem of fault-tolerant integration of abstract sensor estimates when the number of sensors is very large and a large number of sensor faults are tame. We give an optimal O(N log N) algorithm, where N is the total number of sensors, which implements this idea efficiently.",
On a possibilistic approach to reliability theory,"The reliability functions introduced are possibilistic extensions of the classical probabilistic reliability function. In the past, the concept reliability of a system has been defined in a probabilistic way, while the systems could assume either one out of two possible states. Since 1978, the concept of multistate structure functions has been introduced to overcome the shortcomings of the binary approach. A system that is either completely functioning or totally failing is in many cases not quite realistic. Applying possibility theory instead of the classical probability theory provides reliability theory with new and important tools. These concepts make possible the modeling of the possibility of failure and functioning rather than the probability of failure and functioning, which is in many cases more difficult to estimate. Some basic theorems of a possibilistic approach to reliability theory are presented.",
Certification trails and software design for testability,"This paper investigates design techniques which may be applied to make program testing easier. We present methods for modifying a program to generate additional data which we refer to as a certification trail. This additional data is designed to allow the program output to be checked more quickly and effectively. Certification trails have heretofore been described primarily from a theoretical perspective. In this paper, we report on a comprehensive attempt to assess experimentally the performance and overall value of the certification trail method. The method has been applied to nine fundamental, well-known algorithms for the following problems: convex hull, sorting, huffman tree, shortest path, closest pair, line segment intersection, longest increasing subsequence, skyline, and voronoi diagram. Run-time performance data for each of these problems is given, and selected problems are described in more detail. Our results indicate that there are many cases in which certification trails allow for significantly faster overall program execution time than a two-version programming approach, and also give further evidence of the breadth of applicability of this method.",
On synchronous strictly non-blocking concentrators and generalized-concentrators,"The optimal bound of (n-m+c)c+(m-c) and an Omega (k(n-m+c)c/sup 1/k/) lower bound on the size of synchronous strictly non-blocking c-limited (n,m)-concentrators with depth 1 and depth k respectively are proved. A consequence of the lower-bound result is an Theta (n/sup 1+1/k/) bound on the size of synchronous strictly non-blocking fixed ratio gamma n-limited ( alpha n, beta n)-concentrators ( gamma < beta ) with constant depth k. For synchronous strictly non-blocking (c,r)-limited (n,m)-generalized-concentrators, the optimal size of nc-(/sup m-c///sub r/)(c-r) for depth 1 and a lower bound size-depth tradeoff Omega ((n-/sup m///sub r/+/sup c///sub r/)r/sup k-1/k/c/sup 1/k/) for constant depth k and r=o(c) are also presented.",
On the bias of Mahalanobis distance due to limited sample size effect,"The relationship between sample size and the bias of principal components of Mahalanobis distance is studied by computer simulation. The results shows that the bias of Mahalanobis distance in non-dominant components (the components corresponding to smaller eigenvalues of the covariance matrix) are larger than those in dominant components, and that the bias is smaller when the non-dominant eigenvalues are replaced by a larger value. The obtained relationship is helpful to know the sample size needed to estimate mean vectors and covariance matrices. For given sample size, the relationship suggests and determines the number of reliable eigenvectors which should be employed in modified Mahalanobis distance to compensate the bias.",
Texture discrimination by local generalized symmetry,"Texture consists of local variance of gray level or edge intensity values. The authors have recently presented a generalized symmetry operator that captures local spatial relations of image patterns. They show that activity differences in the continuous intensity map produced by the local generalized symmetry operator can be efficiently used to detect texture boundaries. Using almost all available quantitative results of human performance in artificial texture discrimination, the authors show that the algorithm favorably compares with other computational approaches. Stressing the necessity of benchmarks for computer vision algorithms, the authors also discuss an exhaustive set of textures that could be used as experimental stimuli for both humans and machines. The performance of the algorithm is demonstrated on some of these artificial textures as well as on natural images.",
CARE: An environment for understanding and re-engineering C programs,"The authors' focus is on facilitating incremental understanding and re-engineering of existing C programs. A software environment called CARE (computer-aided re-engineering) is used as a vehicle toward that goal. CARE maintains a repository of control-flow and data-flow dependencies (i.e., entities and their relations) of C programs. These dependencies can be visualized using a novel presentation model. Moreover, CARE entails transformation tools that support various ways of displaying program dependencies and facilitate incremental program modifications. An empirical evaluation of the CARE environment using small size C programs is performed. In addition, CARE is used in order to modify the source code of a medium-to-large size program. The results from this empirical evaluation of CARE indicate that its presentation model and transformation tools are a promising step towards improving the effectiveness of understanding and re-engineering existing C programs. Finally, the authors discuss some issues raised during the modification exercise with CARE when using a medium-to-large size program.",
The 1992 SRC Algorithm Animation Festival,"During the last two weeks of July 1992, twenty researchers at Digital Equipment Corporation's Systems Research Center participated in the 1st Annual SRC Algorithm Animation Festival. Only two of the researchers had previously animated an algorithm, and not too many more had ever written an application that involved graphics. The author reports on the Animation Festival, describing why we did it and what we did, and commenting on what we learned.",
Applying noninterference to composition of systems: a more practical approach,"As we know, current hookup or composable properties may impose over-strong security requirements on component systems. To overcome this problem, connectivities of the components have to be considered in order to appropriately handle their composition. Based on such a consideration, in this paper we adopt the concept of rely- and guarantee-conditions to present a composable property of noninterference. We enforce the requirement of noninterference only on some input-output entities of each component with regard to its connectivity, and communication constraints on its others so as to ensure that their entire system can satisfy noninterference. This enables the system and its components to possess different security properties, i.e. the security property of the system can be logically stronger than security properties of its components.",
Efficient multiprecision floating point multiplication with optimal directional rounding,"An algorithm is described for multiplying multiprecision floating-point numbers. The algorithm can produce either the smallest floating-point number greater than or equal to the true product, or the greatest floating-point number smaller than or equal to the true product. Software implementations of multiprecision floating-point multiplication can reduce the computation time by a factor of two if they do not compute the low-order digits of the product of the two mantissas. However, these algorithms do not necessarily provide optimally rounded results. The algorithms described here is guaranteed to produce optimally rounded results and typically obtains the same savings.",
On the Bit-Level Complexity of Bitonic Sorting Networks,Bitonic sorting networks can be implemented with a bit-level cost complexity of O(N log^2 N) using comparators with bit-level O(1) time and cost complexities. Items to be sorted are pipelined (worm-hole routed) bit-serially most-significant-bit first through the network. The cost complexity can be reduced to O(N log N) by recirculating items of length O(logN) through logN stages.,
Simulation and generation of I/sub DDQ/ tests for bridging faults in combinational circuits,"In the absence of information about the layout and for better defect coverage test generation and fault simulation systems must target all bridging faults. The authors show that an I/sub DDQ/ Test Set that detects all two line bridging faults also detects all multiple line, single cluster bridging faults. A novel algorithm for simulating I/sub DDQ/ tests for all two-line bridging faults in combinational circuits is presented. Experimental results on using randomly generated I/sub DDQ/ test sets for detecting bridging faults are presented. These results point to the computational feasibility of targeting all two line bridging faults in combinational circuits, for the purpose of I/sub DDQ/ test generation.",
Intelligent tutoring issues for air traffic control training,"A system designed for air traffic control (ATC) training is described. The system consists of a computer simulation of an ATC radar workstation, a computer model of an ATC expert and other components that allow for automatic evaluation and coaching of an ATC student. The rationale for such a system is presented, along with a discussion of computer intelligent training methodologies. The architectural design of the system is described and those design features implemented in the current version of the system are discussed. Finally, there is a discussion of current and future research and system development: ideas for incorporating intelligent tutoring into the system software, techniques to be used by the system in evaluating student performance, and parameters and metrics to be used in generating ATC training exercises.",
Generating maximal fault coverage conformance test sequences of reduced length for communication protocols,"This paper focuses on a technique to reduce the length of maximal fault coverage test sequences for communication protocols by removing redundant test segments. This approach conceptually begins with all the test segments needed for the generation of maximal fault coverage test sequences, analyzes the structure of the specified finite state machine for the protocol, and shows that certain segments in these tests are unnecessary to guarantee maximal fault coverage. From this analysis an algorithm is proposed for generating the reduced length sequences that still guarantee maximal fault coverage. The authors describe how these tests are in some sense minimal, or near minimal, length test sequences without losing fault coverage.",
Detection and discrimination of injected network faults,"Six hundred faults were induced by injection into five live campus networks at Carnegie Mellon University in order to determine whether or not particular network faults have unique signatures as determined by out-of-band monitoring instrumentation. If unique signatures span networks, then the monitoring instrumentation can be used to diagnose network faults, or distinguish among fault classes, without human intervention, using machine-generated diagnostic decision rules. This would be especially useful in large, unmanned systems in which the occurrence of novel or unanticipated faults can be catastrophic. Results indicate that significant accuracy in automated detection and discrimination among fault types can be obtained using anomaly signatures as described.",
Fast and Efficient Strategies for Cubic and Non-Cubic Allocation in Hypercube Multiprocessors,"A new approach for dynamic processor allo cation in hypercube multiprocessors which sup ports a multi-user environment is proposed. A dynamic binary tree is used for processor allo cation along with an array of free lists. Two al gorithms are proposed based on this approach that are capable of handling cubic as well as non-cubic allocation efficiently. The time com plexities for both allocation and deallocation are shown to be polynomial; orders of mag nitude improvement over the existing expo nential and even super-exponential algorithms. Unlike the existing strategies, the proposed strategies are best-fit strategies and do not ex cessively fragment the hypercube. Simulation results indicate that the proposed strategies outperform the existing ones in terms of pa rameters such as average delay in honoring a request, average allocation time and average deallocation time.",
Fuzzy approach to document recognition,"The authors present a new approach to document recognition using fuzzy rules. The system uses information such as relative locations, relative sizes, and positions. A prototype DOCREC-III is described, which takes bitmap scanned images as input and uses spatial knowledge (layout structure) to reason about the rectangular segments (logical structure) in technical papers. The system provides a compact rule base with accuracy and efficiency. The rules are concise but powerful enough to recognize a variety of layout structures observed in technical papers.",
Stable grasping with a multi-fingered robot hand: a behavior-based approach,"The paper describes the software design approach and implementation of a stable grasp strategy to control a multifingered robot hand in a dynamic and uncertain environment. The overall design starts with a reactive system, called the Grasp Reactor, which measures the environment, and produces actions based on the environmental situations present. To improve the robustness of the Grasp Reactor, it is augmented with a deliberative component which executes concurrently with the Grasp Reactor. This component, called the Grasp Advisor, communicates global constraints to the Grasp Reactor to improve its decision making capability.",
Performance evaluation of a bandwidth allocation scheme for guaranteeing synchronous messages with arbitrary deadlines in an FDDI network,"We study the performance of FDDI networks in terms of their guarantee probability, i.e., the probability that a set of synchronous messages are guaranteed to meet their deadlines. Traditional techniques such as queuing analysis cannot be directly used to derive the guarantee probability. To counter this problem, we develop a new geometric model of schedulability. Based on this model, we obtain a numerical method to compute the exact values of the guarantee probability. A closed-form approximation for the guarantee probability is also derived, and is shown to be relatively accurate and computationally efficient. The network performance is then systematically examined in terms of the guarantee probability. We find that there is a high probability that a randomly chosen message set can be guaranteed even when the real-time traffic is increased beyond the worst case achievable utilization bound. Hence, FDDI networks are applicable for real-time applications in a wide range of loading conditions.","Channel allocation,
FDDI,
Telecommunication traffic,
Traffic control,
Real time systems,
Access protocols,
Optical fibers,
Delay,
Computer science,
Queueing analysis"
Learning an intersection of k halfspaces over a uniform distribution,"We present a polynomial-time algorithm to learn an intersection of a constant number of halfspaces in n dimensions, over the uniform distribution on an n-dimensional ball. The algorithm we present in fact can learn an intersection of an arbitrary (polynomial) number of halfspaces over this distribution, if the subspace spanned by the normal vectors to the bounding hyperplanes has constant dimension. This generalizes previous results for this distribution, in particular a result of E.B. Baum (1990) who showed how to learn an intersection of 2 halfspaces defined by hyperplanes that pass through the origin (his results in fact held for a variety of symmetric distributions). Our algorithm uses estimates of second moments to find vectors in a low-dimensional ""relevant subspace"". We believe that the algorithmic techniques studied here may be useful in other geometric learning applications.",
Processor assignment in heterogeneous message passing parallel architectures,"The authors propose new scheduling algorithms for loosely coupled message passing heterogeneous multiprocessors. These algorithms are extensions to previous work on scheduling in heterogeneous environments by D.A. Menasce and V. Almeida (1992). It is assumed that parallel jobs are structured as task graphs and that tasks communicate with each other by exchanging messages at synchronization points. A Markov chain based analyzer was built to obtain parallel application execution times for each of the algorithms, and their performances are compared.",
A heuristic approach for embedding communication patterns in an interconnection cached parallel processing network,"The problem of identifying whether a graph has a bounded l-contraction for a given integer l is known to be NP-complete for l>2. The authors describe a heuristic approach based on simulated annealing to approximate the solution of this problem. Performance results of their algorithm on graphs representing classical topologies (e.g. trees, grids, hypercubes and cube connected cycles), are presented as well.",
Disconnected operation in a multi-user software development environment,"Software Development Environments have traditionally relied upon a central project database and file repository, accessible to a programmer's workstation via a local area network connection. The introduction of powerful mobile computers has demonstrated the need for a new model, which allows for machines with transient network connectivity to assist programmers in product development. The authors propose a process-based checkout model by which process and product files that may be needed during a planned period of disconnectivity are prefetched with minimal user effort. Rather than selecting each file by hand, which is tedious and error-prone, the user only informs the environment of the portion of the software development process intended to be executed while disconnected. The environment is then responsible for prefetching the necessary files. The authors hope that this approach will enable programmers to continue working on a project without network access.",
Linking the fuzzy set theory to organizational routines: a study in personnel evaluation in a large company,"The authors discuss the application of fuzzy set theory to a personnel evaluation procedure. The effectiveness of fuzzy concepts and methods depends on the approach used for the analysis of organizational issues. The current process for evaluating potential candidates for higher positions in the company hierarchy is managed by a procedure which comprises three important aspects: organizational relationships, rating sheets, and operating rules. The goal of the present research was to modify neither the organizational aspects nor the rating sheet, but to focus only on the meaning of the ratings. Fuzzy concepts and operators are used to interpret the meanings attributed to the items by each evaluator and to propose a procedure for rating aggregation. The main result is a multiple ranking. The decision-maker can use the multiple ranking of the candidates to choose the most appropriate criterion according to the strategy of the company and to the specific management issues. In this way the decision-maker can easily adapt the criterion of ideal candidate to different environmental situations.",
Type theory and recursion,Summary form only given. Type theory and recursion are analyzed in terms of intuitionistic linear type theory. This is compatible with a general recursion operator for the intuitionistic functions. The author considers second-order intuitionistic linear type theory whose primitive type constructions are linear and intuitionistic function types and second-order quantification.<>,"Logic,
Algebra,
Computer science,
Ear,
Equations,
Laboratories,
Calculus,
Power system modeling,
Computer languages,
Parametric statistics"
Non-orthogonal Gabor representation of event-related potentials,,
On completeness of the mu -calculus,"The long-standing problem of the complete axiomatization of the propositional mu -calculus introduced by D. Kozen (1983) is addressed. The approach can be roughly described as a modified tableau method in the sense that infinite trees labeled with sets of formulas are investigated. The tableau method has already been used in the original paper by Kozen. The reexamination of the general tableau method presented is due to advances in automata theory, especially S. Safra's determinization procedure (1988), connections between automata on infinite trees and games, and experience with the model checking. A finitary complete axiom system for the mu -calculus is obtained. It can be roughly described as a system for propositional modal logic with the addition of a induction rule to reason about least fixpoints.",
Detection of defective media in disks,"The authors present new improved methods for detecting latent sector faults in a disk subsystem as caused by media deterioration of the disk magnetic storage material. Usually, sectors in a disk are accessed using uneven patterns causing some of the sectors to be accessed only seldom. In case of media deterioration on the rarely accessed sectors, a latent disk fault may remain undetected for a long time. To detect latent sector faults, a disk is scanned through periodically. An adaptive algorithm is proposed to utilize the idle time for the disk for scanning commonly used disks that comply with SCSI-II interface standards.",
"A weak version of the Blum, Shub and Smale model","We propose a weak version of the Blum-Shub-Smale model (1989) of computation over the real numbers. In this weak model only a ""moderate"" usage of multiplications and divisions is allowed. The class of languages recognizable in polynomial time as shown to be the complexity class P/poly. This implies under a standard complexity-theoretic assumption that P/spl ne/NP in the weak model, and that problems such as the real traveling salesman problem cannot be solved in polynomial time. As an application, we generalize recent results of H.T. Siegelmann and E.D. Sontag (1993) on recurrent neural networks, and of W. Maass (1993) on feedforward nets.",
A theory of over-learning in the presence of noise,The over-learning problem for multilayer feedforward neural networks is discussed. A framework is proposed for the over-learning problem with noise free training data. It is shown that the framework is still valid in the case of noisy training data. It is applied to the case where the rote memorization criterion is used as a substitute for the Wiener criterion. Necessary and sufficient conditions for two kinds of admissibility of the rote memorization criterion by the Wiener criterion are obtained. These conditions lead to a method for choosing a training set which prevents Wiener-over-learning.,"Neural networks,
Training data,
Multi-layer neural network,
Feedforward neural networks,
Intelligent networks,
Computer science,
Sufficient conditions,
Inverse problems,
Vectors,
Presses"
Recovering and tracking pose of curved 3D objects from 2D images,"A method of locating and tracking rigid moving objects with arbitrary curved surfaces is presented. Motion of the moving objects in a sequence of images is used to perform image segmentation and boundary extraction. The silhouette of the object model is derived by the curvature method of Basri and Ullman. The derived silhouette is then fitted to the observed silhouette to determine the object pose. Correspondence is guided by template matching, where the similarity measure is based on the minimization of the overall Euclidean distance between the derived silhouette and the observed silhouette. Bench tests and simulations confirm the viability of the approach, even when the observed silhouette is imperfect due to partial occlusion of the object or imperfect boundary extraction.","Euclidean distance,
Layout,
Computer science,
Image segmentation,
Testing,
Rough surfaces,
Surface roughness,
Object recognition,
Machine vision,
Feature extraction"
Trail: a track-based logging disk architecture for zero-overhead writes,"A novel disk architecture called Trail is proposed to optimize the disk write latency without sacrificing the disk read performance. This architecture features a track-based logging technique, which essentially reduces a disk write latency to the transfer delay. In addition, this disk architecture allows concurrent read/write, and implicit write scheduling without compromising data integrity. Through a synthetic-trace simulation study, we have shown that for transaction processing workloads, the write latency improvement of Trail over conventional disk devices is at least an order of magnitude. Trail's read latency performance is also better in all cases, sometimes the improvement is also over an order of magnitude. In terms of disk bandwidth utilization, the Trail architecture has a close to 100% write bandwidth efficiency and a read bandwidth efficiency at least as good as a conventional disk.",
Exploiting Spatial and Temporal Parallelism in the Multithreaded Node Architecture Implemented on Superscalar RISC Processors,"In most multithreaded node architectures moti- vated by the dataflow computational model, spatial parallelism could not be exploited at the thread level due to the resource deficit incurred by their inter nal organization. So we proposed a node architecture exploiting both spatial and temporal parallelism of a program. A multi-port non-blocking data cache is in corporated into our design to cope with the excessive data bandwidth required in parallel execution of mul tiple threads. The proposed node architecture may contribute to greatly reducing communication latency through the interconnection network. Simulation re sults show that parallel loops can be executed on this architecture more efficiently than on other competi tive ones.",
Applying the CHAOS/PARTI library to irregular problems in computational chemistry and computational aerodynamics,"This paper describes a number of optimizations that can be used to support the efficient execution of irregular problems on distributed memory parallel machines. We describe software primitives that (1) coordinate interprocessor data movement, (2) manage the storage of, and access to, copies of off-processor data, (3) minimize interprocessor communication requirements and (4) support a shared name space. The performance of the primitives is characterized by examination of kernels from real applications and from a full implementation of a large unstructured adaptive application (the molecular dynamics code CHARMM).",
Toward a Steiner engine: enhanced serial and parallel implementations of the iterated 1-Steiner MRST algorithm,"The minimum rectilinear Steiner tree (MRST) problem is known to be NP-hard, and the best performing MRST heuristic to date is the Iterated 1-Steiner (I1S) method recently proposed by A.B. Kahng and G. Robins (1992). The authors develop a straightforward, efficient implementation of I1S, achieving speedup factors of over 200 compared to previous implementations. They also propose a parallel implementation of I1S that achieves high parallel speedup on K processors. Extensive empirical testing confirms the viability of the approach, which allows the benchmarking of I1S on nets containing several hundred pins.",
Some results on the decision and construction for Sheffer functions in partial k-valued logic,"Decisions and construction for Sheffer functions in P/sub k/ and P/sub k/* in partial k-valued logic are considered. The solution of these problems depends on the solution of the decision problem of completeness in P/sub k/ and P/sub k/* and is reduced to determining the minimal coverings of precomplete classes in P/sub k/ and P/sub k/*, respectively. The pseudo-linear function set denoted by L/sub p/ is proved here to be the component part of the minimal covering of precomplete classes in P/sub k/*.",
Loop neural network model for associative memory,"Proposes a new associative memory neural net (NN) model called the loop neural network model, and the theoretical proof of this NN's stability is given. Experiments show that this NN model is much more powerful than the McCulloch-Pitts model, the discrete Hopfield NN, the continuous Hopfield NN, the discrete bidirectional associative memory NN, the continuous and adaptive bidirectional associative memory NN, the backpropagation NN, and the optimally designed nonlinear continuous NN.",
Optimization by reduction to maximum clique,"MAX-CLIQUE is the optimization problem of finding a largest clique in a given graph. By reduction to MAX-CLIQUE, the following three NP-hard optimization problems in a binary weights Hopfield net special case are solved: minimum vertex and set cover, constraint satisfaction problems (N-queens), and Boolean satisfiability (using a recent reduction). The approximation performance is experimentally determined on uniformly-at-random generated instances. The author's optimizing dynamics are discrete and converge, independently of the problem, in O(number of units) unit-switches. Several problems are optimized in a single binary weights (0/-1) network, which, for all problems, admits no invalid solutions. All reductions, except one, are goodness-preserving in a formal sense. This is contrasted with the variety of handcrafted energy functions for the same individual problems in the literature, several of which admit invalid solutions.","Neural networks,
Computer science,
Constraint optimization"
Reduced interprocessor-communication architecture for supporting programming models,"The paper presents an execution model and a processor architecture for general purpose massively parallel computers. To construct an efficient massively parallel computer: the execution model should be natural enough to map an actual problem structure into a processor architecture; each processor should have efficient and simple communication structure; and computation and communication should be tightly coupled and their operation should be highly overlapped. To meet these, we obtain a simplified architecture with a Continuation Driven Execution Model. We call this architecture RICA. RICA consists of a simplified message handling pipeline, a continuation-driven thread invocation mechanism, a RISC core for instruction execution, a message generation pipeline which can send messages asynchronously with other operations, and a thread switching mechanism with little overhead, all of which are fused in a simple architecture. Next, we state how RICA realizes parallel primitives of programming models and how efficiently it does. The primitives examined are-shared memory primitives, message passing primitives and barriers.",
Friction Estimation in Multimass Systems,"An observer for estimating the vector of Coulomb friction force coefficients in a multimass system is presented. The vector is assumed to be a linear combination of sgn(·) functions of relative velocities of the contacting masses. Two different nonlinear observers are proposed to estimate the friction coefficients when the velocities of the masses can be measured. When only the positions of the masses can be measured, an additional (reduced-order observer) is used to estimate the velocities of the masses. Excellent performance of the proposed system in the presence of white noise, is demonstrated by simulation.",
A knowledge-based technique for localizing externally attached markers in MR and CT volume images of the head,,
Polynomial isomorphism of 1-L-complete sets,Let C be any complexity class closed under log-lin reductions. It is shown that all complete sets for C under 1-L reductions are polynomial time isomorphic to one other. It is indicated how to generalize the result to reductions computed by finite-crossing machines.,
Supporting multiple tool integration paradigms within a single environment,"In the domain of effective software development, tool integration is a key issue. In effect, tools can be integrated using a variety of the interfacing paradigms. In most software development environments to date, tool integration is based on a single-paradigm tool interface which may not be suitable for integrating a diverse range of tools. It is desirable to have various interfacing paradigms for flexible and effective tool integration within a single environment. The authors discuss research into a generic interface supporting uncoupled, tightly coupled, and loosely coupled interfacing paradigms within a single prototype environment for interactive software development.",
Random test length for bounded faults in RAMs,"The authors study a very general class of memory faults that includes the usual stuck-at, coupling, and pattern-sensitive faults. This is the class that consists of 'bounded faults' that is, faults that involve a bounded number of cells. Some bounded faults are known to require deterministic tests of length proportional to n log/sub 2/ n, where n is the total number of memory cells. The main result of this paper is that, for any bounded fault satisfying certain mild conditions, the random test length required for a given level of confidence is always O(n).",
Solid-state laser driver for IFE power plants,"Summary form only given. The authors present the concept of a diode-pumped solid-state laser driver in the context of a power plant for inertial fusion energy (IFE) based on the cost and efficiency analyses published for Sombrero. A systems-analysis computer code has been used to optimize the design parameters in selecting the best driver configuration. The development of this configuration poses significantly lower risks than that for other driver options, for three reasons. First, up-front costs and final technical performance risk can be significantly reduced because the system is modular and can be tested at dramatically reduced scale. Second, as a consequence of the experience gleaned from Nova and other large fusion lasers, much of the fundamental physics is already well-understood. Third, many of the novel laser technologies envisioned for the IFE driver are inherently of interest to various scientific and industrial communities.",
Enterprise-wide management: a paradigm for constructing organizational decision support systems,"Presents the enterprise management problem solving paradigm (EMP), a general approach for building organizational decision support systems capable of solving complex enterprise management problems. The authors describe the formalism upon which EMP is based and the fundamental concepts involved with EMP-based problem solutions. In particular, they discuss the cornerstone of EMP systems, the probot ('process robot'), and introduce the Campbell-Whitehair conjecture, which suggests constraints that can be used to effectively reduce the cost of problem solving in many enterprise management domains. They also discuss several research projects that validate EMP, some results from initial efforts to prototype comprehensive enterprise management systems, and some of the more significant issues encountered during these efforts.",
Parallel FFT Algorithms for Cache Based Shared Memory Multiprocessors,"Shared memory multiprocessors with cache require careful consideration of cache parameters while implementing an algorithm to obtain optimal performance. In this paper, we study the implementation of some existing FFT algorithms and analyze the number of cache misses based on the problem size, number of processors, cache size, and block size. We also propose a new FFT algorithm which minimizes the number of cache misses.",
The Validation of a Multiprocessor Simulator,"In this paper, we present the design and implementation of a multiprocessor simulator written in the language SimCal. We use the simulator to test our scheme to partition a sequential program for parallel execution on a shared memory, asynchronous multiprocessor. The results of the simulations indicate that our partitioning scheme can provide significant speed-up by executing the program in parallel. We then execute the partitioned program on an actual multiprocessor and find a high degree of correlation between the simulations and the actual executions. This correlation serves to validate our simulator. We then use the multiprocessor simulator to hypothetically extended the actual multiprocessor and we show that adding more processors will not provide significant improvement in the parallel executions unless the communication structure is also improved to contain more parallelism.",
PBGUNS: A digital computer program for the simulation of electron and ion beams on a PC,Summary form only given. The SNOW code (for ion beams) and the SPEED code (for relativistic electron beams) have been combined into one FORTRAN 77 program for simulation of any type of axisymmetric or 2-D particle beam on a PC. PBGUNS uses relaxation techniques to do a Poisson simulation of both electron and ion beams of any energy in axisymmetric or rectangular configurations. It uses quadratic equations to simulate electrode boundaries on a rectangular mesh of squares. A typical input data set is between 15 and 40 lines long. A fine mesh automatically covers the cathode and/or plasma region to improve the accuracy of the calculations and to obtain excellent agreement with either theory or experiment. Results are presented for a microperveance 1.9 electron gun. The microperveance was easily obtained with no thermal effect.,
Performance evaluation of nonlinear shape normalization methods for the recognition of large-set handwritten characters,"Recently, several nonlinear shape normalization methods have been proposed in order to compensate for shape distortions in large-set handwritten characters. The authors review these methods from the two points of view: feature projection and feature density equalization. The former makes a feature projection histogram by projecting a certain feature at each point into horizontal- or vertical-axis and the latter equalizes the feature densities of input image by re-sampling the feature projection histogram. Then, a quantitative evaluation for these methods has been made based on the following criteria: recognition rate, processing speed, computational complexity, and degree of variation.",
Preserving visual perception by learning natural clustering,"The neural clustering behavior of self-organizing neural networks enables the learning of perceptually meaningful pattern features and makes it possible to store pictorial data in an effective way. The authors experiments show that the storage of perceptual features requires a fraction of the size of the original data, and still renders little or no difference compared with the original. Experimental results of natural clustering and non-trivial clustering from corner-propagation networks using feature map and frequency-sensitive variations of the Kohonen network are shown and discussed.",
Weak plate mechanical models in Bayesian reconstruction for emission tomography,"Bayesian reconstruction methods for emission tomography allow the introduction of prior information in the form of spatial smoothness constraints on the underlying object. The authors extend these priors to model the type of smoothness that favors piecewise linear regions. Empirical evidence that this extension is useful is found in animal autoradiographs that show regions of radionuclide density whose structure is far from piecewise flat. The extension uses a ""weak plate"" prior (A. Blake and A. Zisserman, 1987) that allows for piecewise-ramplike regions in the reconstruction. Here, discontinuities include creases-discontinuities in the object gradient rather than in the object itself. To incorporate their new prior in a MAP approach, the authors model the prior as a Gibbs distribution and use a GEM formulation for the optimization. They use mathematical phantoms and a phantom derived from an autoradiograph to illustrate the efficacy of the weak plate prior as compared to more conventional priors.",
Collaboration technology for organization design,"The significance, bases, and means for developing multiuser computer-based environments for supporting organization design are discussed. Organization design: is defined in terms of organization work, structure, and process; is an ongoing, evolutionary phenomenon; and can and should be an inclusive, distributed, multiparticipant effort. The requirements for computer-based technology that supports this working perspective and an overview of a prototype technology that addresses these requirements is presented. The prototype technology consists of two interacting components: Deva, an interactive, multiuser graphical editor for managing process descriptions, and GPOD, an associated group process for using Deva for organization design. It is concluded that such technologies will enable organizations to become self-organizing systems, thereby allowing them to more effectively compete and survive in today's rapidly changing environment.",
Fuzzy RCE neural network,"The authors propose a supervised fuzzy neural network called a fuzzy restricted Columb energy (fuzzy RCE) network for classification problems. In a fuzzy RCE, each hidden neuron is a fuzzy prototype which can be used to represent one or many training patterns. At the learning stage, the fuzzy membership functions of prototype neurons can be automatically adjusted according to the training data. The simulation results on handwritten alphanumeric characters show that the proposed model learns very fast and has good recognition performance.",
Several new classes of measures of fuzziness,"The authors introduce two new general classes of measures of fuzziness, called the additive and multiplicative classes. Usually three axioms are required for fuzziness measures. The classes not only satisfy these three basic axioms, but also two other desirable axioms. The multiplicative class is based on nonnegative, monotone increasing concave functions. The additive class requires only nonnegative concave functions. Constructing a measure of fuzziness under each of these classes is simple, as the required functional form does not have restrictions. It is demonstrated that several existing measures of fuzziness are special cases of these new classes.",
Control flow prediction for dynamic ILP processors,"Addresses a two-fold question: whether there is enough parallelism in numeric and non-numeric workloads, such as the SPEC92 benchmark suite, under ideal conditions, disregarding any resource constraints and more importantly, whether a high ideal parallelism can be further characterized to assess its extractability with finite resources. The authors have designed and implemented an analysis tool that accepts as input a dynamic execution trace from an IBM RS/6000 environment, and outputs a parallelized instruction trace (schedule) that could be executed on an abstract machine with unlimited functional units and various constraints on the rest of its resources, namely, registers, stack and memory. They also analyze two different instruction scheduling policies: greedy and lazy. The paper further offers a characterization of ideal parallelism (obtainable on a machine with infinite resources) using a measure called slack to assess its sustainability with finite resources.<>",
Supporting a dynamic SPMD in a multi-threaded architecture,"The authors present a multithreaded architecture model which can efficiently support a single-program multiple-data (SPMD) computation of programs with dynamic data structures. It is based on a dynamic SPMD model where the access delay due to a remote reference of a dynamic data structure can be tolerated by having multiple threads of control concurrently in execution within each processor. However, the present model permits the exploitation of locality of references through the use of caches for remote memory operations. When a remote memory access operation is encountered and cannot be satisfied locally, the processor can have the flexibility of migrating the thread to a remote processor when (and only when) such migration is desirable.",
Multiple combined recognition system for automatic processing of credit card slip applications,"The authors developed a system that utilizes a multiple combined method. For the recognizer, they used three representative recognizers: a structural, a statistical, and a neural network approach. They also used three combining methods (a vote, a Bayesian, and BKS) to combine the results obtained from three recognizers. This system is applied to credit card slip recognition. For recognizing printed numerals, the authors use template matching, and for handwritten numerals, a multiple combined system is used. Reliability about 99% was achieved in handwritten numeral recognition and 81% reliability in credit card slip recognition. L. Lam and C. Y. Suen's (1988) standard handwritten numeral data showing high reliability of above 95%.",
Z meets Haskell: A case study,"Z is a popular specification language which has also been used as a design tool, although much less frequently. Haskell is a programming language that was recently developed to serve as a standard for non-strict, purely functional languages. Although functional languages have proved to be excellent prototyping tools, Haskell was designed as a general purpose language which could be employed to build large applications. In this paper, we show that the formal language Z is an effective design tool when a software system is implemented in a functional language. We trace the development of a simple system from its beginning specification written in Z to its final implementation as a Haskell program. The case study is based on a specification, the class manager's assistant, found in the literature.",
Minimum Completion Time Criterion for Parallel Sparse Cholesky Factorization,"It is well known that a judicious choice of ordering has great impact on the sparse matrix factorization. Many proposed reordering algorithms attempt to minimize the corresponding elimination tree height, which is, however, not an accurate indication of the actual parallel factorization time. We will illustrate the appalling discrepancy with a contrived example.",
FLEX: a tool for building efficient and flexible systems,"Modern operating systems must support a wide variety of services for a diverse set of users. Designers of these systems face a tradeoff between functionality and performance. Systems like Mach provide a set of general abstractions and attempt to handle every situation, which can lead to poor performance for common cases. Other systems, such as Unix, provide a small set of abstractions that can be made very efficient, at the expense of functionality. We are implementing a flexible system building tool, FLEX, that allows us to support a powerful operating systems interface efficiently by constructing specialized module implementations at runtime. FLEX improves the performance of existing systems by optimizing interprocess communications paths and relocating servers and clients to reduce communications overhead. These facilities improve the performance of Unix system calls on Mach from 20-400%. Furthermore, FLEX can dynamically extend the kernel in a controlled fashion, which gives user programs access to privileged data and devices not envisioned by the original operating system implementor.",
Computer-aided cartographical system for map digitizing,"The authors present a PC-based cartographical system to digitize maps. A memory restriction made us develop special technologies and techniques to digitize large-sized map-drawings. The combination of manual digitizing and labeling with automatic vectorization and recognition, and interactive editing allowed us to get satisfactory time characteristics for digitizing complex maps. To process automatically scanned maps in a restrictive computer memory, an effective pipeline oriented scheme and new techniques have been developed. A new process called object labeling has been introduced to speed up the interpretation process. An output database structure has been suggested to store all needed information about the map.",
Printed Japanese character recognition based on multiple modified LVQ neural network,"A multiple modified LVQ neural network model that can recognize Japanese characters over 3000 categories with high performance both in accuracy and speed is proposed. The multiple modified LVQ network is based on the LVQ (learning vector quantization) neural network and a large scale of network can be implemented easily because of its simple structure. This network has a training function of fast convergence and of easy modification without disturbing past trained weights for Japanese character recognition. An experimental system using a neuro-computer with four digital neuro-chips and experimental results are described. With the experimental system it takes 18 minutes to learn 35,000 samples by 20 training cycles, while it takes more than one week with a workstation. Moreover it can recognize about 350 characters a second for 3584 categories. High recognition rate of 100% for training fonts and of over 99% for testing fonts were achieved with 49,500 samples.",
Deterministic semantics of set-oriented update sequences,"An iterator is proposed that allows sequences of update operations to be applied in a set-oriented way with deterministic semantics. Because the mechanism is independent of a particular model, it can be used in the relational and in object-oriented ones. Thus, the deterministic semantics of embedded structured query language (SQL) cursors and of triggers that are applied after (set-oriented) SQL updates can be checked. The iterator can be used to apply object-oriented methods, which are usually update sequences defined on a single object, to sets in a deterministic way.",
"Random sampling in matroids, with applications to graph connectivity and minimum spanning trees","Random sampling is a powerful way to gather information about a group by considering only a small part of it. We give a paradigm for applying this technique to optimization problems, and demonstrate its effectiveness on matroids. Matroids abstractly model many optimization problems that can be solved by greedy methods, such as the minimum spanning tree (MST) problem. Our results have several applications. We give an algorithm that uses simple data structures to construct an MST in O(m+n log n) time. We give bounds on the connectivity (minimum cut) of a graph suffering random edge failures. We give fast algorithms for packing matroid bases, with particular attention to packing spanning trees in graphs.","Sampling methods,
Tree graphs,
Computer science,
Graphics,
Application software,
Optimization methods,
Data structures,
Statistics,
Data analysis,
Greedy algorithms"
Performance evaluation of dynamic sharing of processors in two-stage parallel processing systems,"The performance of job scheduling is studied in a large parallel processing system where a job is modeled as a concatenation of two stages which must be processed in sequence. P/sub i/ is the number of processors required by stage P as the total number of processors in the system. A large parallel computing system is considered where Max(P/sub 1/, P/sub 2/)>or=P>>1 and Max(P/sub 1/, P/sub 2/)>>Min(P/sub 1/, P/sub 2/). For such systems, exact expressions for the mean system delay are obtained for various job models and disciplines. The results show that the priority should be given to jobs working on the stage which requires fewer processors. The large parallel system (i.e. P>>1) condition is then relaxed to obtain the mean system time for two job models when the priority is given to the second stage. Moreover, a scale-up rule is introduced to obtain the approximated delay performance when the system provides more processors than the maximum number of processors required by both stages (i.e. P>Max(P/sub 1/, P/sub 2/)). An approximation model is given for jobs with more than two stages.",
A circulant matrix based approach to storage schemes for parallel memory systems,"We introduce a memory storage scheme allowing conflict-free parallel access to rows, columns, square blocks, distributed blocks, and positive and negative diagonals of two dimensional arrays. Unlike the existing schemes, the proposed scheme can be used for an arbitrary number of memory modules and an arbitrary size of the arrays. We develop a systematic procedure for the memory allocation based on a placement matrix constructed using circulant matrices.",
Control parameterization and robustness of feedback systems: an asymptotic analysis,"The problem of robust design is regarded as a parameterization problem, and the choice of parameters to satisfy with respect to a class of bounded perturbations is considered. Application areas for the general results derived include multivariate root-locus robustness, design based on simplified or reduced plant models, and singular perturbation analysis. The results are based on asymptotic analysis of feedback structures and a proof of the existence of parameter ranges for robust stability.",
An efficient heuristic for permutation packet routing on meshes with low buffer requirements,"Even though exact algorithms exist for permutation routine of n/sup 2/ messages on a n*n mesh of processors which require constant size queues, the constants are very large and the algorithms very complicated to implement. A novel, simple heuristic for the above problem is presented. It uses constant and very small size queues (size=2). For all the simulations run on randomly generated data, the number of routing steps that is required by the algorithm is almost equal to the maximum distance a packet has to travel. A pathological case is demonstrated where the routing takes more than the optimal, and it is proved that the upper bound on the number of required steps is O(n/sup 2/). Furthermore, it is shown that the heuristic routes in optimal time inversion, transposition, and rotations, three special routing problems that appear very often in the design of parallel algorithms.",
Fast carry free adder design using QSD number system,"A high speed parallel full adder is designed which can perform carry-free addition of two modified signed digit quaternary numbers. For digital implementation, the sign digit quaternary numbers are represented using 3-bit 2's complement notation. The adder truth table with possible schemes of the electronic and optical implementation are provided.",
A new performance driven macro-cell placement algorithm,"The authors present a new performance-driven macro-cell placement algorithm. They introduce the concept of a window which is an estimate of the initial placement of a module. There are three phases in the algorithm. In phase one, an initial window for each module is constructed. In phase two, a novel force-directed approach is used to reduce the size of each window in an iterative process so as to determine an initial placement of the modules. In phase three, the same force-directed concept is used to refine the placement. Timing and physical constraints are used in all phases to guide the placement process. The effectiveness of the algorithm is demonstrated by comparing the experimental results with those produced by TimberWolfMC and the GVL algorithm.",
,,
Large-set handwritten character recognition with multiple stochastic models,"An efficient recognition scheme for large-set handwritten characters is proposed in the framework of multiple stochastic models, in this case, first order hidden Markov models which can model stochastically the input pattern with numerous variations. In this scheme, after extracting four kinds of regional projection contours for an input pattern by using the regional projection contour transformation, four kinds of HMMs are constructed during the training phase based on the direction components of these contours. In the recognition phase, the four kinds of HMMs constructed in the training phase are combined to output the final recognition result for an input pattern.",
Data partitioning for networked parallel processing,"The workstation model of parallel processing presents specific challenges caused by the latency of the communications network and the workload imbalance that arises from the heterogeneity of the nodes. Data partitioning is critically important for parallel processing in this environment. We mathematically characterize the communication costs for four data decomposition schemes: scatter, contiguous point, contiguous row, and block. These methods are analyzed in terms of problem size, number of processors, network speed, and communication pattern. Bounds are established for the performance of these decomposition schemes that can be used to make better-informed data partitioning decisions.",
Restructuring binary decision diagrams based on functional equivalence,A method to restructure binary decision diagrams (BDDs) from a given input ordering to any other ordering is proposed. This technique is based on the concept of functional equivalence and BBDs structure equivalence. A transpositional operator is developed to implement the transformation. It is shown that this transformation is used to find a good input variable ordering for BBDs a good input partition for communication complexity based multilevel logic synthesis. Experimental results are presented.,
Delay analysis of various service disciplines in symmetric token passing networks,"An approach to the delay analysis of various service disciplines in symmetric token passing networks is presented. It is shown that exact or approximate accurate expressions for the average packet delay of different service disciplines can be directly derived by the delay expression of the exhaustive service system. This can be accomplished by inflating, by an appropriate factor, the packet size of the discipline whose performance is analyzed and then using the inflated packet in the delay expression of the exhaustive service system. The method is applied to the analysis of the limited service and TTS disciplines, and its accuracy is verified by simulation results. The advantages of the analytic method presented are its generality, higher accuracy over previous analytic methods, and insensitivity to network latency and other system parameters.",
Manipulating general vectors on synchronous binary n-cube,"The author describes efficient manipulations of general vectors on the synchronous binary n-cube structure. A general vector is defined as a set of elements stored in consecutive processors with arbitrary length and starting point, and one element per processor. New routing methods for manipulating general vectors are presented. The author focuses on six major vector manipulating functions: merge, split, rotation, reverse, compression, and expansion. They are frequently used to extract and structure data parallelism in image processing and parallel solutions of linear systems. It is observed that varying the dimension order is a key to collision-free vector manipulations. A formal network model is developed for determining when link collisions occur. With the aid of this network model dimension orders yielding collision-free routine for the six manipulating functions are identified. Collision-free routing allows data communication to complete in the optimal time-single network cycle. The dimension orders are easy to encode and decode, and they are feasible for physical implementation.",
Optimal algorithms on the pipelined hypercube and related networks,"Parallel algorithms for several important combinatorial problems such as the all nearest smaller values problem, triangulating a monotone polygon, and line packing are presented. These algorithms achieve linear speedups on the pipelined hypercube, and provably optimal speedups on the shuffle-exchange and the cube-connected-cycles for any number p of processors satisfying 1",
On features used for handwritten character recognition in a neural network environment,Neural nets are considered as the underlying computing mechanism for a robust approach to the problem of handwritten character recognition. It is expected that recognition mechanisms will be developed through learning algorithms. A key factor to this problem is the set of primitive features which are used to form the raw input vectors representing the digitized image of a character. The authors have explored a number of conventional and new features that can be used in concert with adaptive clustering schemes. Experiences of the performance of these features are presented. A feature which the authors call shadow and which is presented here has produced particularly encouraging results.,
Taking it to the limit: on infinite variants of NP-complete problems,"Infinite, recursive versions of NP optimization problems are defined. For example, MAX CLIQUE becomes the question of whether a recursive graph contains an infinite clique. The work was motivated by trying to understand what makes some NP problems highly undecidable in the infinite case, while others remain on low levels of the arithmetical hierarchy. Two results are proved; one enables using knowledge about the infinite case to yield implications to the finite case, and the other enables implications in the other direction. Taken together, the two results provide a method for proving (finitary) problems to be outside the syntactic class MAX NP, hence outside MAX SNP too. The technique is illustrated with many examples.",
Top-down lower bounds for depth 3 circuits,We present a top-down lower bound method for depth 3 AND-OR-NOT circuits which is simpler than the previous methods and in some cases gives better lower bounds. In particular we prove that depth 3 AND-OR-NOT circuits that compute PARITY resp. MAJORITY require size at least 2/sup 0.618/ .../spl radic/n/ resp. 2/sup 0.849/.../spl radic/n/. This is the first simple proof of a strong lower bound by a top-down argument for non-monotone circuits.,
A parallel algorithm for multiple edge updates of minimum spanning trees,"The authors present a parallel algorithm for the multiple edge update problem on a minimum spanning tree. This problem is defined as follows: given a minimum spanning tree T(V,E/sub T/) of an undirected graph G(V,E), where mod V mod =n and E/sub T/ is the set of tree edges, recompute a new minimum spanning tree when (1) adding K new edges, (2) changing the weights of existent K edges, or (3) deleting a vertex of degree K in the tree, where 1",
Efficient Use of Dynamically tagged Directories Through Compiler Analysis,"Dynamiically tagged directories have been recently proposed as a memory-efficient mechanism for maintaining cache coherence in large-scale shared-memory multiprocessors. In order to efficiently use these directories, the number of pointer operations must be minimized and pointers should be allocated as late as possible. If pointers are allocated too early, frequent pointer overflow will occur, which in turn may cause cache thrashing.",
Learning Competition and Cooperation,"Competitive activation mechanisms introduce competitive or inhibitory interactions between units through functional mechanisms instead of inhibitory connections. A unit receives input from another unit proportional to its own activation as well as to that of the sending unit and the connection strength between the two. This, plus the finite output from any unit, induces competition among units that receive activation from the same unit. Here we present a backpropagation learning rule for use with competitive activation mechanisms and show empirically how this learning rule successfully trains networks to perform an exclusive-OR task and a diagnosis task. In particular, networks trained by this learning rule are found to outperform standard backpropagation networks with novel patterns in the diagnosis problem. The ability of competitive networks to bring about context-sensitive competition and cooperation among a set of units proved to be crucial in diagnosing multiple disorders.",
FAST-SC: Fast Fault Simulation in Synchronous Sequential circuits,,
Three-dimensional graphical programming in CAEL,"In the visual programming community, many interesting graphical representations have been reported. Most have a 2D or 2.5D appearance on screen to reflect the inherent multi-dimensionality of the programming constructs being represented. By going to a three-dimensional representation, this reflection can go a step further. With ever increasing 3D graphics rendering capabilities, it moreover becomes feasible to extend the dimensionality of the program (and data structure) depiction. The authors follow this approach by realizing 3D graphical programming techniques within CAEL, our interactive computer animation environment language. The paper elucidates the underlying concepts, architecture and 3D representations utilize in CAEL.",
Distributed channel allocation in ATM networks,"This paper proposes a distributed channel allocation mechanism for ATM networks. In this mechanism, agents are assigned to traffic sources and allocate channels to incoming calls in a distributed manner. Channel allocation is based only on the sampled channel utilization values locally available to agents. There is no direct exchange of information assumed between agents. Due to the distributed nature of the proposed mechanism, this mechanism causes oscillations during channel utilization when there is a delay associated with the sampling of channel utilizations and the processing of sampled values at agents. This oscillation increases the cell loss in a channel. According we propose methods for estimating channel utilization in order to reduce the oscillations and show their effectiveness through simulations. The proposed mechanism requires little computational processing, is simple to implement, and achieves efficient channel allocation even if highly bursty calls. It is therefore suitable for ATM networks.",
A portable abstract machine model for image processing: an implementation technique for software tools,"This paper discusses the design of an abstract machine model for low-level image processing. Two software development tools for parallel image processing, namely a high-level programming language and a workbench environment, are described briefly. We then present the abstract machine model as a portable implementation technique for the language and environment.",
Global semigroup operations in faulty SIMD hypercubes,"The authors consider the problem of computing a global semigroup operation (such as addition and multiplication) on a faulty hypercube. In particular, they study the problem of performing such an operation in an n-dimensional SIMD hypercube Q/sub n/, with upto n-1 node and/or link faults. In an SIMD hypercube, during a communication step, nodes can exchange information with their neighbors only across a specific dimension. Given a set of most n-1 faults they develop an ordering d/sub 1/, d/sub 2/,. . .,d/sub n/ of n dimensions, depending on where the faults are located. An important and useful property of this dimension ordering is the following: if the n-cube is partitioned into k-subcubes using the first k dimensions f this ordering, namely d/sub 1/,d/sub 2/. . .d/sub k/ for any 1",
Design of Active Suspension System in the Presence of Physical Parametric Uncertainties,The purpose of the paper is to study the design of the active wheel suspension system. The goal of the control design is the disturbance attenuation with respect to the road disturbances when some of the physical parameters of the system are uncertain. On the basis of a linear quarter-car model the tire stiffness and suspension stiffness are assummed to be uncertain. In this paper the authors deal with some new robust design methods. They examine the applicability of H∞ control in case of the active suspension system using a quarter-car model. The problem is solved as a direct state-feedback H∞ control problem and in case of structured uncertainties as an RLQR (Robust LQR) design task. On the basis of combination of these two methods new procedure is proposed.,
Investigation of the exhibition of facial expressions within human computer interaction,"This paper describes research which was conducted to determine if humans exhibit facial expressions while interacting with a computer system. Fourteen college-aged subjects were chosen for the experiment. The subjects included 3 Hispanics and 11 Caucasians. Six of the subjects' were female. Each of these subjects performed five computer-based tasks which were chosen to simulate a wide range of typical applications; one of these tasks was a baseline. The subject's facial expressions were videotaped and later analyzed using the Ekman and Friesen Facial Action Coding System. The analysis revealed that the subjects did indeed exhibit facial expressions; an analysis of variance showed a significant difference between task types. In addition, an ethological analysis revealed a surprising number of facial expression maskings.",
Compositional software reuse with case-based reasoning,"Case-based reasoning can be applied to software reuse. The approach presented goes beyond furnishing a library of potentially reusable modules and provides a tool that supports the process of reusing software. It uses case-based reasoning to add flexibility and adaptability to the compositional model of reuse. The authors describe the structure of the case base, emphasizing the case acquisition process during which high level functional information is associated with its components. The system performs advanced data-flow analysis of source code to guide acquisition of the functional specification of a library of software modules. The system then decomposes a user's problem, retrieves matching cases, and adapts and assembles their code. The data-flow of the result is again analyzed to produce test cases which can be used to evaluate the success of case-based reasoning.",
"Integrating group support systems, joint application development, and computer-aided software engineering for requirements specification","The possibility of integrating group support systems (GSSs), joint application development (JAD), and computer-aided software engineering (CASE) tools to support the requirements specification processes is examined. The relevance of GSSs, JAD, and CASE to requirements specification is discussed. An integration framework is proposed and is augmented by a domain-analysis methodology. A pilot study conducted to assess the effectiveness of applying the domain-analysis methodology in using GSSs for requirements specification is reported.",
Modelling errors in restriction mapping,"Restriction mapping is a process by which sites along an unsequenced DNA molecule are located through measurement of the distance between them. The authors consider a model for handling errors in restriction maps in which the error in measurement is modeled by using a normal distribution. Minimum message length techniques are applied to evaluate the relative merit of competing solutions to a restriction mapping problem. This is simplified, for cases where the cost of the model is equivalent, to a maximum likelihood criterion, which is used to rank multiple solutions by considering each arrangement as a different hypothesis.",
Load balancing and selection on the star and pancake interconnection networks,"Algorithms for load balancing and selection on the star and pancake interconnection networks are presented. The time complexity of the selection algorithm is discussed. A major component of the selection algorithm is a procedure that balances the loads among all the processors in both networks. Previous results that are either related to the result, or that are used by the algorithms are reviewed.",
Steps towards computer assisted locking of intramedullary nails,,
Evaluation method for an automatic map interpretation system for cadastral maps,"A base line system for automatic interpretation of Dutch cadastral maps is discussed. Knowledge of the rules for drawing these maps is incorporated in the system. Also, a method for evaluating this system is presented. This method consists of different parts which subsequently evaluate the vectorization, the performance on finding parcels, and the performance on finding parcel numbers. Parts of this evaluation method may also be applicable for other line drawing interpretation systems.",
An environment for evaluating architectures for spatially mapped computation: System architecture and initial results,An environment which addresses several problems in evaluating massively parallel array architectures is described. A realistic workload including a series of applications currently being used as building blocks in vision research has been constructed. Both flexibility in architectural parameter selection and simulation efficiency are maintained by combining virtual machine emulation with trace driven simulation. The tradeoff between fairness to diverse target architectures and programmability of the test programs is addressed through the use of operator and application libraries. Initial results are presented indicating the appropriate balance between register file and cache to optimize performance under varying levels of processor element virtualization.,
Graphical parametrised structural descriptions of VLSI devices,This paper describes the visual programming language used for giving parametrised structural descriptions of devices in the graphical VLSI design environment VIDE (Visual Integrated Design Environment).,
Algorithms and design: the CRAY APP shared-memory system,"Analysis of fundamental algorithms of computational science drove the design of the CRAY APP system. The important characteristics central to many applications are exploited through the use of shared-memory programming techniques using existing compiler technology. A cluster-capable 84-processor system, the CRAY APP, provides a flat shared memory, low memory latency, fast barrier synchronization, and hardware-assisted parallel support. A patented crossbar/bus architecture provides system economy. Deterministic system behavior allows the compilers to view the system as a single virtual processor. For even higher performance, multiple CRAY APPs can be clustered. Cluster configurations may also contain a globally accessible memory. High-bandwidth low-latency connections allow this configuration to be effective for applications that require more performance than one CRAY APP.",
Mapping to reduce contention in multiprocessor architectures,Reducing communication overhead has been widely recognized as a requirement for achieving efficient mappings which substantially reduce the execution time of parallel algorithms. This paper presents an iterative heuristic for static mapping of parallel algorithms to architectures. Special attention is given to measuring and reducing channel contention. Experimental results are used to show the effects of channel contention for packet-switched networks and the improvement realized by the authors' heuristic. They also present preliminary results for wormhole-routed networks.,
Analyzing performance of large scale parallel systems,"The authors study the impact of parallel processing overhead and the degree of concurrency of a parallel algorithm on the optimal number of processors to be used when the criterion for optimality is minimizing the parallel execution time. They evaluate a more general criterion of optimality and show how operating at the optimal point is equivalent to operating at a unique value of efficiency, which is a characteristic of the criterion of optimality and the properties of the parallel system under study. The technical results derived are put in perspective with similar results that have appeared in the literature. It is shown that this study generalizes and/or extends these earlier results.",
Resynthesis for testability of redundant combinational circuits,"This paper presents an algorithm to generate circuits which are irredundant for stuck-at fault testing but which preserve all the properties of the original design; then any state-of-the-art ATPG procedure can be applied to the modified network. The algorithm makes use of additional control inputs to convert the redundant AND-OR function of the circuit, represented as the sum of all its prime implicants, into the irredundant one.",
Program and interface slicing for reverse engineering,"Reverse engineering involves a great deal of effort in comprehension of the current implementation of a software system and the ways in which it differs from the original design. Automated support tools are critical to the success of such efforts. It is shown how program slicing techniques can be employed to assist in the comprehension of large software systems, through traditional slicing techniques at the statement level, and through a new technique, interface slicing, at the module level.",
The Planetary Data System data model,"The authors describe the object-based data model in use by the Planetary Data System (PDS). This model, based on the Object Description Language (ODL) and consisting of keyword/value statements, is both human- and computer-readable and has been used to label large volumes of science data being prepared for CD-ROM archive volumes. The use of ODL for defining the objects that compose the PDS model, as well as its use in the actual labeling, has shown it to be a powerful yet simple tool for supporting the science-data archive process.",
On scalable net modeling of OLTP,"Practical experiments with the net modeling of OLTP (online transaction processing) applications are discussed. The goal was to propose a convenient and flexible model that would be easy to modify with respect to different scheduling algorithms, number of processors, and disks. The parameters of the model may be varied depending on the size of available memory and timing in a model in order to provide the necessary information to analyze the functioning of the system under different transaction rates and conditions, to identify bottlenecks and potential inefficiencies in the system design. The main effort was focused on speeding up the simulation through combining nets with code, using refinement techniques, and exploiting the scalability of colored Petri nets.",
,,
Authentication in wireless communications,"Easy access to radio links makes wireless communication susceptible to the exposure of sensitive information and fraudulent use of the services. These threats may come from outsiders who can only collect information on the radio links, or insiders who can somehow access a system's secret information. Through an authentication protocol, which verifies the identities of both parties over the wireless link and then establishes a common secret key between them, these threats can be reduced or even completely eliminated. With emphasis on the PCS- and GSM-like communication environments where users roam among multiple service domains and portable units are equipped with only limited battery power, the authors propose two efficient authentication protocols to provide services such as message confidentiality, caller ID confidentiality, call intractability, and fraud control.",
Adaptive message logging for incremental replay of message-passing programs,"This paper presents an adaptive message logging algorithm that keeps time and space costs low by logging only a fraction of the messages. The algorithm dynamically tracks dependences among messages to determine which cause domino effects and must be traced. The domino effect can force a replay to start arbitrarily far back in the execution, and domino-free replay allows any part of the execution to be quickly reexecuted. Experiments on an iPSC/860 hypercube indicate that our algorithm logs only 1-10% of the messages, a one to two order of magnitude reduction over past schemes which log every message. The experiments also show that the resulting logs provide a small bound on the amount of reexecution needed to satisfy any replay request. The new logging algorithm thus reduces the overhead of message logging while bounding the response time to replay requests.",
Computer aided tuning tool for fuzzy controllers,The authors describe a procedure related to fuzzy controller tuning. The target is reached through an interactive procedure based on largely confirmed linearization and optimization methods aimed at maintaining the process physical image. A real application example shows how by linearization and optimization it is possible to design and tune fuzzy controllers that are dedicated to closed-loop control of ill-defined nonlinear mechanical processes. It is also shown that it is possible to avoid trial and error procedures that cannot give a good validation of the result.,
Automatic touring in a hypertext system,"A hypertext system connects information into a graph structure were related nodes of information are connected by links. The user browses through this network of links to gain knowledge. The authors propose an autonomous information gathering process which monitors the user's progress through the network, and a data structure for storing information about the user's activities in a form that can be used to aid this user, and other users of the hypertext. This information can be used to suggest anchors to the user; enhance local and global views; allow the hypertext author or user to easily create guided tours, and create a global body of information making hypertexts stored across multiple sites more efficient. An implementation of this process is shown which gathers the information, and gives suggestions to the user on which link to use based on the previously collected information.",
Efficient electronic implementation of modified signed-digit trinary carry free adder,An efficient carry-free addition and borrow-free subtraction of modified signed-digit trinary number scheme is presented which may be used for parallel computing application. A digital 2 bit prototype adder was designed and implemented using electrically programmable logic device (EPLD).,
TUBA: replacing IP with CLNP,"The Connectionless Network Protocol (CLNP), which is supported by the associated OSI routing protocols, is proposed as a replacement for the Internet Protocol (IP). The basis of the proposal is to run the Internet transport protocols, the Transmission Control Protocol (TCP), and the User Datagram Protocol (UDP) on top of CLNP in an approach known as TCP and UDP with bigger addresses (TUBA). The fundamentals of CLNP and the OSI connectionless routing architecture, the operation of the IP suite with CLNP replacing IP, the support of Internet applications operating on top of TUBA, and a transition plan to a TUBA Internet are discussed.",
Planning velocity profiles from task-level constraints and environment uncertainties,"A method for parameterizing robot trajectories in the presence of uncertainties is presented. The planning process is defined as a problem of constrained optimization and the concept of a task's difficulty is used as an optimization criterion. The task difficulty, as defined by the authors, comprises the combined effects of velocity and uncertainty, mimicking human perception of difficulty in positioning tasks. The success probability is used as a constraint necessary for planning tasks with contradicting requirements. This planning paradigm is demonstrated with an experiment that contains opposing requirements: reaching the obstacle in a given time, but without exceeding certain maximal impact force. The planner is implemented on a real system.",
A Comparison Based Parallel Sorting Algorithm,"We present a fast comparison based parallel sorting algorithm that can handle arbitrary key types. Data movement is the major portion of sorting time for most algorithms in the literature. Our algorithm is parameterized so that is can be tuned to control data movement time, especially for large data sets. Parallel histograms are used to partition the key set exactly. The algorithm is architecture independent, and has been implemented in the CHARM portable parallel programming system, allowing it to be efficiently run on virtually any MIMD computer. Performance results for sorting different data sets are presented.",
Architectures for intelligent control systems: The science of autonomous intelligence,"This new area of engineering (AICS), endeavor, architectures for intelligent control systems, has generated a number of often controversial results and directions. It is rooted in control theory, artificial intelligence, computer architectures, software engineering as well as in psychology, biology, linguistics, and other disciplines. A question arises: is this a science, or just an intersection of different scientific technologies and techniques? The author views AICS as a science, albeit not a typical one.",
General bounds on statistical query learning and PAC learning with noise via hypothesis boosting,We derive general bounds on the complexity of learning in the statistical query model and in the PAC model with classification noise. We do so by considering the problem of boosting the accuracy of weak learning algorithms which fall within the statistical query model. This new model was introduced by M. Kearns (1993) to provide a general framework for efficient PAC learning in the presence of classification noise.,"Boosting,
Upper bound,
Machine learning,
Laboratories,
Computer science,
Contracts,
Extraterrestrial measurements,
Noise measurement,
Size measurement,
Machine learning algorithms"
A discrete event framework for intelligent inspection,The problem of intelligent inspection is addressed. Discrete event dynamic systems (DEDSs) are used to guide the sensing of mechanical parts for industrial inspection. An agent is used to sense the environment and to feed the relevant data to a control module that makes design and sensing strategy choices which affect inspection activities. The autonomous sensing system can be modeled efficiently within the DEDS framework.,
On the form-closure of polygonal objects with frictional and frictionless contact models,"The problem of form-closure for three-fingered grasps of polygonal objects under various combinations of contact models at the contact points is investigated. It is shown that equilibrium can be maintained even when some of the contacts between the fingers and the grasped object are frictionless and tangential contact forces do not exist. Feasible regions for location of the fingers, and for safe manipulation of the object under various combination of contact models are identified.",
Specification of deterministic execution timing schema for parallel programs on a multiprocessor,"To guarantee the correctness of hard real-time software systems, it is necessary to have a priori knowledge of the deterministic execution times of the system components. Timing schema are formulae based on source program elements to calculate the execution time of programs. Deterministic timing schema or formulae are proposed in this paper for predicting the best and worst case execution times of parallel and distributed programs. The total execution time is computed from the schema provided for a variety of parallel program constructs for shared variable interactions through critical sections and, general semaphores for distributed message passing and remote procedure calls. As an initial attempt to validate the proposition, we have conducted a series of experiments on a shared memory multiprocessor (tightly coupled) system. In one of such experiments involving simplest process structures, where no process interactions occur except to synchronize the initiation and termination of processes, the timing schema based approach has been shown to exhibit safe and reasonably tight predictions. The representative implementations that obey the schema and the methods of incorporating some of the underlying hardware contentions and indeterminacies have also been studied. Predictable timing behaviour in concurrent systems is indeed a possibility using the schema approach.",
A load balancing multicast tree approach for group-based multimedia applications,"The authors formulate and propose an algorithm for the LBMT (load-balancing multicast tree) problem whose main objective is to accomplish traffic load balance while minimizing the number of multicast trees for a group. In order to fulfill these objectives, the multiple multicast tree concept, whose only disadvantage is the high tree maintenance cost, is introduced. Since the tree maintenance cost is proportional to the number of multicast trees for a multicast group, it is necessary to minimize the number of multicast trees. The authors' LBMT algorithm is based on the minimal Steiner tree approach by using the information on the available capacities of the links. For the algorithm, several link cost functions which take the available capacities on both directions into account are proposed.",
On the complexities of leader election algorithms,"We show the relationship between the number of messages and time for leader election in general networks. Specifically, the paper proves that every O(D)/sup 1/ time algorithm for leader election in general networks requires /spl Omega/(m log D) messages. We show that this lower bound is tight by presenting a simple O(m log D) message complexity and O(D) time distributed algorithm for leader election in general networks. Finally, B. Awerbuch (1987) presented an O(m+n log n) message and O(n) time distributed algorithm for leader election in general networks, which is optimal for the number of messages. We present another algorithm that matches Awerbuch's complexities, but our algorithm is simpler than Awerbuch's algorithm.",
Microwave propagation constant for a vegetation canopy at X band,"An equivalent-medium model is developed for vegetation media to relate the propagation constant γ, associated with propagation of the mean field through a vegetation canopy, to the geometrical and dielectric parameters of the canopy constituents at high frequencies. The model is intended for media containing vertical dielectric cylinders, representing the stalks, and randomly oriented, arbitrary shaped thin dielectric disks, representing the leaves. The formulation accounts for absorption and scattering losses by both stalks and leaves. A resistive sheet model in conjunction with the physical optics approximation is used to model scattering by the canopy leaves, which is valid when the leaf dimensions are larger than a wavelength. The model is found to be in good agreement with experimental results at 10.2 GHz. The experimental component of the study included measurements of the attenuation loss for horizontally polarized and vertically polarized waves transmitted through a fully grown corn canopy. The measurements were made at incidence angles of 20°, 40°, 60°, and 90° relative to normal incidence. The proposed model is suitable for cornlike canopies, provided the leaves are larger than λ in size.",
On teaching AI and expert systems courses,"The experiences of faculty members from departments of engineering, mathematics, and computer science throughout the United States and Puerto Rico who came together for three weeks to discuss effective ways to teach artificial intelligence to undergraduates are outlined. The paper describes the rationale for the development of three main topic areas: artificial intelligence, expert systems, and symbolic and logic programming, and it includes syllabi for these topics. Also included is a discussion of the results obtained after a year of using the materials and techniques gathered during the original meeting.",
The multi-ring reconfigurable multiprocessor network for computer vision,A novel architecture based on a reconfigurable multi-ring mutiprocessor network is described. The reconfigurability of the architecture is shown to result in a low network diameter and also a low degree of connectivity for each node in the network. The mathematical properties of the network topology and the hardware for the reconfiguration switch are described. Primitive parallel operations on the network topology are described and analyzed. The architecture is shown to contain a single one-factor of the Boolean hypercube in a given configuration. A large class of algorithms for the Boolean n-cube is shown to map efficiently on the proposed architecture without loss of performance. The architecture is shown to be well suited for a number of problems in low- and intermediate-level computer vision.,
Universal emulations with sublogarithmic slowdown,The existence of bounded degree networks which can emulate the computation of any bounded degree network of the same size with logarithmic slowdown is well-known. The butterfly is an example of such a universal network. Leiserson was the first to introduce the concept of an area-universal network: a network with VLSI layout area A which can emulate any network of the same size and layout area with logarithmic slowdown. His results imply the existence of an N-node network with layout area O(N log/sup 2/ N) which can emulate any N-node planar network with O(log N) slowdown. The main results of this paper are: There exists an N-node network with layout area O(N log/sup 2/ N) which can emulate any N-node planar network with O(loglogN) slowdown. The N-node butterfly (and hypercube) can emulate any network with VLSI layout area N/sup 2-/spl epsiv// (/spl epsiv/>0) with O(loglogN) slowdown. We also discuss sublogarithmic bounds for the slowdown of emulations of arbitrary bounded degree networks.,
Real-time dissemination of continuous media in packet-switched networks,"The authors present a model of communication in a packet-switched network called continuous-media (CM) dissemination, which is the distribution of digital audio, video, and other periodic time-correlated data streams, from a source to multiple receivers. This model is similar to that of a cable TV system. The authors discuss an important design principle, the principle of loose coupling between a source and multiple receivers, for supporting this type of communication. The main argument for loose coupling is that there can be an arbitrary number of receivers for a single source of a CM multistream, and that the complexity of keeping track of the states of all receivers would overwhelm the source. Applications of the design principle include group addressing, proactive dynamic control mechanisms, and individualized tailoring of the CM multistream by receivers with limited effect on the source.",
Maintaining bipartite matchings in the presence of failures,"The authors present an on-line distributed reconfiguration algorithm for finding a new maximum matching incrementally after some nodes have failed. Their algorithm is deadlock free, and with k failures maintains at least M-k matching pairs during the reconfiguration process, where M is the size of the original maximum matching. The algorithm tolerates failures that occur during reconfiguration. The worst-case reconfiguration time is O(k min( mod A mod , mod B mod )) after k failures, where A and B are the node sets, but simulations show that the average-case reconfiguration time is much better. The algorithm is also simple enough to be implemented in hardware.",
Gpss a Gpss Implementation with Hierarchical Modeling Features,Though GPSS is about 32 years old it has not been changed in its main algorithms since Henriksens new version (see Henriksen 1976). This paper describes some new features of a GPSS implementation in order to improve the macro concept of GPSS. Besides a short review on environments for simulation systems is given. Finally an OS/2 environmental frame for the new GPSS is suggested.,
A computer-supported cooperative problem solving environment for examining communication effectiveness,"The authors' long term goal is to improve computer-supported cooperative problem solving. In order to address this problem, a prototype interface that is designed to investigate effective group problem solving skills has been built. The special interface is based on a communication competency model which assumes that group effectiveness depends upon the performance of competencies (or skills) that aid groups in solving problems. Five task-achievement competencies are selected: establishment of operating procedures; analysis of the group problem; establishment of criteria; generation of alternative solutions; and evaluation of solutions. Special online tools are built to support and correspond to each of the communication competencies. From the authors' study of successful vs. unsuccessful groups using the interface, it is found that effective computer-supported cooperative problem solving is positively related to the use of some of the online tools.",
From code comprehension model to tool capabilities,"A major portion of the maintenance effort is spent trying to understand existing software. If we can learn more about how programmers understand code successfully, we can build better tools to support this understanding process. An effective maintenance tool must help in code comprehension and support the code understanding process. We present an integrated comprehension model and a technique for developing detailed tool capability requirements.",
Teaching computer algorithms and data structures to students in engineering and the physical sciences,"The author describes a new three credit-hour course at the Colorado School of Mines (CSM), MACS 410: Scientific Programming in C. This one-semester course is targeted for students in engineering or the physical sciences who have finished the CSM core courses in computing and not expect to either major or minor in CS. The purpose of the class is to teach the fundamentals of scientific computing, bring students up to speed in the C programming language, and introduce them to UNIX, and available software tools and techniques. Instruction relies on two novel techniques which are expected to be applicable to other colleges: (1) MACS 410 is taught as a laboratory course with in-class exercises on UNIX workstations, and (2) it uses the XTANGO X-11 based algorithm animation program for interactive computer-based instruction.",
On the Convergence of the Em Algorithm,The EM algorithm is a popular iterative method for finding the maximum likelihood estimate when the likelihood function is either non-analytical or its functional form is too difficult to maximize directly. In this paper we analyze the convergence properties of the EM algorithm. By representing the E step in a Taylor series with remainder we obtain a derivation of region of convergence and asymptotic convergence rates for a specified complete data space. These results can help one tailor the choice of complete data space so as to achieve an optimal tradeoff between ease of implementation and rapid convergence of the EM algorithm.,
,,
Secrecy Enhancement via Public Discussion,"(X, Y, Z) is an ensemble of independent random triples, each distributed according to some probability distribution p(x, y, z). Two legitimate users, Px having X and Py having Y, communicate in order to agree on a joint key while keeping it almost unknown to an eavesdropper Pz who knows Z. Communication is conducted over a noiseless channel according to a predetermined protocol. P2 hears all transmissions over the channel and knows the protocol used. We show: (1) The legitimate communicators can agree on the secret if and only if they can find one using just two messages. (2) There are cases where a secret can be found, but one message does not suffice. (3) Similar results hold whether the legitimate communicators are required to agree on the secret with probability one or just with high probability.","Probability distribution,
Access protocols,
Entropy,
Capacity planning,
Sufficient conditions,
Computer science"
"Migrating multi-threaded, shared objects","The BirliX operating system migration mechanism is type-independent, can deal with multithreaded shared objects, is transparent for applications, and can be used by applications to implement arbitrary migration policies. An overview of the BirliX concepts and architecture is given to give an understanding the environment of the migration mechanism. As migration in BirliX heavily depends on the checkpoint and recovery mechanisms, these fault-tolerance mechanisms are discussed. The current implementation of the migration mechanism is described. Some pitfalls during implementation are described, and the performance of the current implementation is presented.",
"Comments on ITS: ""The integrated TIGER series of electron/photon transport codes-Version 3.0"" by J.A. Halbleib et al., ""CEPXS/ONELD Version 2.0: a discrete ordinates code packaging for general one-dimensional coupled electron-photon transport"" by L.J. Lorence, Jr., and ""Recent MCNP developments"" by J.S. Bendricks and J.F. Briesmeister","Comments are offered on the three above-titled papers (ibid., vol.39, no.4, Aug. 1992). Regarding the first paper (p.1025-30), it is pointed out that a continuous-energy adjoint Monte Carlo code is available for electron transport, namely, the NOVICE code. The second paper (p.1031-4) gave performance information for a suite of 25 sample problems run on several mainframes and workstations. Performance data are given by the commenter for the same problems run on personal computers. Regarding the third paper (p.1035-40), the commenter points out that the three codes indicated there as available through the Radiation Shielding Information Center have PC versions.",
Fast rehashing in PRAM emulations,"In PRAM emulations, universal hashing is a well-known method for distributing the address space among memory modules. However, if the memory access patterns of an application often result in high module congestion, it is necessary to rehash by choosing another hash function and redistributing data on the fly. For the case of linear hash functions h(x) - ax mod m, we present an algorithm to rehash an address space of size m on a p processor PRAM emulation in time O(m/p + log p). The algorithm requires O(log m) words of local storage per processor.","Phase change random access memory,
Emulation,
Parallel machines,
Partitioning algorithms,
Application software,
Contracts,
Noise measurement,
Computer science,
Parallel algorithms,
Algorithm design and analysis"
Stochastic Adaptive Control of Multiple Delay Systems,"In this paper we consider the indirect adaptive minimum variance control for multiple delay systems based on a projected extended least squares algorithm. We establish its stability, self-optimizing and self-tuning properties, and rates of convergence.",
Executive support systems for executive teams in organizations in high-velocity environments,One approach to generating guidelines for executive support systems (ESSs) is to review the management and executive literature. Such a review can point to areas in which communication and information technologies can logically aid managers and executives. This approach is taken with emphasis on the work of executives and executive teams in small organizations in high velocity environments. Executive teams in such organizations resolve specific paradoxes in their strategic decision-making processes. Seven different types of communication and information technologies are used to design and build systems to support executive teams resolving these paradoxes.,
NP trees and Carnap's modal logic,"We consider problems and complexity classes definable by interdependent queries to an oracle in NP. How the queries depend on each other is specified by a directed graph G. We first study the class of problems where G is a general dag and show that this class coincides with /spl Delta//sub 2//sup P/. We then consider the class where G is a tree. Our main result states that this class is identical to P/sup NP/ [O(log n)], the class of problems solvable in polynomial time with a logarithmic number of queries to an oracle in NP. Using this result we show that the following problems are all P/sup NP/[O(logn)] complete: validity-checking of formulas in Carnap's modal logic, checking whether a formula is almost surely valid over finite structures in modal logics K, T, and S4, and checking whether a formula belongs to the stable set of beliefs generated by a propositional theory.",
The case for interpretive structural modelling as a technique for enhancing electronic meeting system support,"The author describes the use of PRISM, a GSS (group support systems) tool based on the principles of ISM (interpretive structural modeling), using four representative case studies. Each case illustrates the pitfalls associated with generating ideas through simple brainstorming and nominal group techniques, typical of prevailing GSS tools. The strengths associated with ISM are discussed, revealing the potential benefits it offers to the development of more robust GSS tools. The case studies presented show how ISM can overcome the weaknesses inherent in less-structured problem-solving methods, such as Kepner-Tregoe, Porter's strategic business planning methodology, and Cooper's new product method, all of which make assumptions about the problem that is to be solved.",
A new horizon for sorting on mesh architectures,The author introduces the use of data duplication in massively parallel architectures as a tool for improving the running time of the basic data movement operations. He demonstrates its use by presenting two algorithms for sorting N items on mesh architectures of square root N* square root N processors. The first algorithm has an O(N/sup 1/3/ log N) running time and requires the use of O(N/sup 2/3/) memory locations per processor. The second has an O((N log N)/sup 1/3/) running time and requires the use of O(N/sup 2/3//log/sup 1/3/N) memory locations per processor and multiple broadcasting buses.,
Throughput analysis of simple closed timed Petri net models,"It is shown that for some classes of closed timed Petri net models the steady-state behavior can be determined on the basis of structural properties only (i.e., without reachability analysis), using the concept of throughput and simple rules of operational analysis. Throughput analysis is based on the average values of firing times rather than firing time distribution functions, so the same approach can be used for a variety of net models. Bounded as well as unbounded (but ergodic) net models can be analyzed by the proposed approach.",
Resource-driven resource location,"A general solution for locating resources within a local area network using multicasting is presented. The basic idea is to map resource attributes to multicast addresses so that a machine joins a multicast address group only if it has the corresponding resource attribute. Servers on each machine dynamically join and leave multicast addresses as the resources on the machine change. Clients seeking information send a message to the corresponding address where, in the ideal case, a machine receives a request only when it contains the requested information about the resource. The approach is to build a platform on which queries for distributed information can be efficiently carried out. The authors use a general resource query language that can be used to request information about resources using one or more resource attributes. The key idea is that the resource location process is driven by the resource request, as the query itself is mapped to an underlying multicast address for delivery. The mechanism worked well in initial performance testing.",
Hyper-navigation in virtual buildings,"The virtual reality (VR) user interface style allows the user to manipulate virtual objects in a 3D environment. A software architecture which guides users in virtual worlds is introduced. The architecture is based on the concept of task-oriented agents which support users in acting within a virtual environment (VE). These agents use an application independent toolbox, the hyper-renderer, to retrieve information that is calculated during the rendering process. A virtual building is used to implement various prototypes in order to evaluate this approach.",
Visual interface for retrieval of electronic-formed books,"The authors address visual interface and virtual manipulation for full text management. Their objective is to investigate the retrieval/reference mechanism of computer-readable full texts as if paper-form books were being manipulated directly in the real world. This mechanism is derived basically from the object-linking facility of hypersystems. Of course, the facility must be applicable to the manipulation of a great deal of electronic-formed books, like the traditional information retrieval systems, through hypersystems are suitable to only private filing applications.",
Experiments in distributed constraint satisfaction,"A novel taxonomy is developed to describe solution strategies for distributed constraint satisfaction problems, and the preliminary results of computational experiments are presented.",
Analysis of burstiness and jitter in multimedia communications,"Examines burstiness and jitter in multimedia communications. The authors assume that the synchronization process is adaptive and the traffic stream can be divided into smaller synchronization units. They model the traffic in a synchronization unit with two parameters, and define jitter with the delay experienced by the first packet in a synchronization unit as the target delay. They then obtain results on the relationship between burstiness and jitter, and on the upper bounds of burstiness and jitter.",
The minimum reservation rate problem in digital audio/video systems,"The minimum reservation rate problem arises in distributed systems for handling digital audio and video data. The problem is to find the minimum rate at which data must be reserved on a shared storage system in order to provide continuous buffered play-back of a variable-rate output schedule. The problem is equivalent to the minimum output rate: given input rates during various time periods, find the minimum output rate under which the buffer never overflows. The authors present an O(n log n) randomized algorithm and an O(n log n log log n) deterministic one.",
Numerical analysis of distortion of chirp pulse waves propagated through turbulent media,"Attention is paid to a chirp radar system and the mean pulse intensity of received pulse waves distorted by the ionospheric turbulence is analyzed. The analysis is based on the two frequency moment equation in which the multiple scattering due to inhomogeneous turbulent media is precisely introduced. It is shown through some quantitative analyses that a chirp radar system is not susceptible to the ionospheric turbulence in view of mean pulse intensity distortion as compared with the system without pulse compression technique. As a result, the chirp radar system may be useful for sensing a target in strong turbulent media with high resolution accuracy.",
"An Autonomous Agent Architecture for Integrating ""Unconscious"" and ""Conscious"", Reasoned Behaviors",,
Fully-digital testability of a high-speed conversion system,"Purely-digital techniques that can be used to analyze The Performance Of A High-speed On-chip Reconfigurable Conversion System are described. The proposed techniques make use of an unconventional digital-to-analog-analog-to-digital testing loop, and therefore do not require external analog resources. This is verified by simulations performed on a dedicated test model.",
Dynamic mutation testing in integrated regression analysis,"A new method of integrated regression analysis is proposed. Its core is the clustering, a method for automatic identification of program modifications. Clustering is used to formulate a hypothesis about the existence of a fault in the modified program, and to guide the process of testing this hypothesis. It is postulated that static and dynamic program analysis be used for that purpose. Specifically, the authors introduce dynamic mutation testing (DMT), an experimental technique for testing the fault hypothesis. DMT estimates the sensitivity of the test-induced program state to reveal the postulated fault in the modified program. If all tests pass and are found to have a high sensitivity, the fault hypothesis can be rejected at a high level of confidence.",
A Game-Playing Fuzzy Logic Controller for Semi-Active Suspensions,"The idea of controlling physical systems with artificially-intelligent control methods has great appeal, and has been investigated heavily in the past. At the very least, they offer the chance to control effectively systems that are highly nonlinear and/or time-varying. This paper describes attempts to fuse game-playing theory and binary-decision-tree pattern recognition methods to build a fuzzy logic parametric controller for a semi-active suspension system. The goal of the controller is to minimize (or defend against) the maximum possible transfer of road interaction forces to the vehicle. Simulation results show that the resulting system can provide the desired control actions to handle smoothly the irregularities in the road profile and the many nonlinearities inherent in the suspension system.",
Generation of technical illustration from description of machines,"Technical illustrations (TI) are always drawn in any assembly manual. This means that a TI is more informative than instruction in assembly tasks. Without TI, we have to read assembly instructions, it is difficult to infer a correct assembling procedure, if they explain several types of assembly relations. Even a novice can assemble or disassemble mechanical parts by only seeing a TI. But the order of assembly/disassembly is not uniquely obtained from a TI, knowledge on assembling operation will limit the order to plausible one. An assembly task is successfully divided into several easier assembly tasks than the original one. This means that a TI is composed of a set of TIs which are small and easy subassembly tasks.",
Design and performance of tree-structured vector quantizers,"This paper considers optimal vector quantizers which minimize the expected distortion subject to a cost such as the number of leaves (storage cost), the leaf entropy (lossless encoding rate), the expected depth (average quantization time), or the maximum depth (maximum quantization time). It analyzes the heuristic of successive partitioning, and develops a class of strategies subsuming most of those used in the past. Experimental results show that these strategies are more efficient than existing methods, and achieve comparable or better compression. The relationship among different cost functions is considered and ways of combining multiple cost constraints are proposed.",
The genericity theorem and the notion of parametricity in the polymorphic lambda -calculus,"The authors focus on how polymorphic functions, which may take types as inputs, depend on types. These functions are generally understood to have an essentially constant meaning, in all models, on input types. It is shown how the proof theory of the polymorphic lambda -calculus suggests a clear syntactic description of this phenomenon. Under a reasonable condition, it is shown that identity of two polymorphic functions on a single type implies identity of the functions (equivalently, every type is a generic input).",
Shape from photomotion,"A new technique called shape from photomotion is introduced. It uses a series of 2-D Lambertian images, generated by moving a light source around a scene, to recover the depth map. In each of the images, the object in the scene remains at a fixed position and the only variable is the light source direction. The movement of the light source causes a change in the intensity of any given point in the image. The change in intensity is what enables recovery of the unknown parameter, the depth map, since it remains constant in each of the input images. The authors' method differs from photometric stereo in the sense that the shape estimate is not only computed for each light source orientation, but also gradually refined by photomotion.",
Multimedia lessons for electromagnetic education,"The authors discuss some problems encountered in the development of a computer-based curriculum and present features of the interactive video lessons developed by the CAEME Center. These lessons were developed using the QUEST authoring software and are run on IBM-compatible PCs. It is shown that, in addition to the multimedia information and instructions, the lessons evaluate students' understanding and keep record of their scores for instructor use. The lessons developed by CAEME integrate multimedia information from videos, audio, software simulation, and animated graphics with multimedia instructions including tutorials and quizzes.",
Evaluation Of Three Approaches To Parallel Logic Simulation On A Distributed Memory Multiprocessor,,
A blackboard architecture for intelligent assistance in software maintenance,"System design recovery and impact analysis are critical phases in the process of software maintenance. It is argued that the interdependence of abstraction recovery tools and application domains plays a key role in providing intelligent assistance in software maintenance, and the use of a blackboard model to address the issue of knowledge sources integration is advocated. A software maintenance expert sytem (SMES) based on a blackboard architecture has been developed to evaluate the approach. Explicit links between specification, design and implementation objects have been represented in the blackboard working memory, as well as the design decisions in the abstraction recovery process. These links are then used in the software evolution process to support impact analysis.","Computer architecture,
Software maintenance,
Application software,
Software systems,
Software engineering,
Programming profession,
Cognitive science,
Educational institutions,
Mathematics,
System analysis and design"
Performance analysis of a new bandwidth balancing mechanism under the presence of erasure nodes,"The no-slot-wasting bandwidth balancing (NSW BWB) recently proposed for dual-bus architectures provides throughput fairness and arbitrary bandwidth distribution without wasting channel slots. The performance of two variations of NSW BWB in the presence of erasure nodes and under one or multiple priority classes of traffic is studied by simulation. For both variations, the effect of the erasure mode locations on the throughputs of the various stations, as well as priority classes of traffic, is examined, and the performance of NSW BWB is compared with the corresponding performance of the bandwidth-balancing mechanism of the distributed queue dual bus. The simulation results reveal some very interesting properties for the first of the two NSW BWB variations that are used to derive analytic estimates of its throughput performance in the general case of arbitrary number of stations and arbitrary location of erasure nodes.",
Mixed spanning trees: a technique for performance-driven routing,"Presents a new strategy for performance-driven global routing. This strategy focuses on the creation of spanning trees whose properties are under the control of the designer. The authors use it to construct a spanning tree with simultaneous, provable performance guarantees on total length, single-source shortest path length, and bottleneck path length. For rectilinear problems on n terminals in the plane, such a tree can be constructed in O(n log n) time.",
Structuring data parallelism using categorical data types,"Data parallelism is a powerful approach to parallel computation, particularly when it is used with complex data types. Categorical data types are extensions of abstract data types that structure computations in a way that is useful for parallel implementation. In particular, they decompose the search for good algorithms on a data type into subproblems, all homomorphisms can be implemented by a single recursive, and often parallel, schema, and they are equipped with an equational system that can be used for software development by transformation.",
An executable software project management model by beta-distributed stochastic Petri nets,"This paper proposes a new software project time and cost management model using a beta-distributed stochastic Petri nets (BSPN), which is an integrated model of PERT and Petri nets. A beta-distributed transition, from PERT, is adapted for modeling the uncertainty of time and cost of a software project. Structural properties of the project are analyzed from structure of the BSPN. Behavioral characteristics of the project, such as time and cost, are analyzed using a chronological reachability graph of BSPN.",
MIS research in the 1980's: shifting points of work and reference,"A prior study by the authors on management information systems (MISs) is updated to include development in the 1980s. It is found that MIS continues to emerge from the foundations of these reference disciplines, i.e., computer science, management science, and organization science. The MIS literature in the core journals approximately doubled from the first half of the decade to the second. The relationship of MIS to the foundational field of organization science remains an issue, as research published in MIS journals is little referenced in the core journals of organization science. A closer relationship between these two fields is predicted to develop during the 1990s.",
A copy network with shared buffers for large multicast ATM switches,"A new architecture for the copy network which is an integral part of multicast asynchronous transfer mode (ATM) switches is proposed. The new architecture makes use of the property that the Broadcast Banyan Network (BBN) is non-blocking if the active inputs are cyclically concentrated and the outputs are monotone. In the new architecture, by employing a token ring reservation scheme, the outputs of the copy network are reserved before a multicast cell is replicated. By the new copy principle, the number of copies requested by a multicast call is not limited by the size of the copy network, so that very large multicast switches can be configured in a modular fashion. The sequence of cells is preserved in the new structure. Though physically separated, buffers within the copy network are completely shared, so that the throughput can reach 100%, and the cell delay and the cell loss probability can be made very small.",
Integration of relational databases in a multidatabase system based on schema enrichment,"The authors describe a framework for an object-oriented modeling of meta information and its use for the integration of heterogeneous databases with the goal of their interoperation. The meta information consists of all types of information necessary to access and interoperate the participating databases. As part of the meta information, they model the common properties and differences of the various data models and concrete systems. Additionally, they also include information to semantically enhance the schemas of the participating databases providing the basis for a (semi-)automatic schema transformation. They describe the semantic richment of a relational schema using additional information deduced from its underlying entity-relationship design schema. The enhanced relational schemas may be automatically transformed into corresponding schemas in the common data model which in this case is the object-oriented model. Queries using the created object-oriented schema may be automatically translated into equivalent SQL queries for the original relational schema.",
Analysis of associative memory of multilayer feedback neural networks,"Based on the multilayer feedback BP neural network model obtained from a circuit analogue and an energy function, this paper proves the stability of the feedback BP network associative memory process. The proof of stability of the associative memory process of the feedback network is given and conclusions made.",
Isomorphisms of NP complete problems on random instances,"Polynomial isomorphisms are defined for NP-complete sets on random instances. Not only are polynomial-time computable and invertible bijections among complete sets considered, but also it is required that these bijections preserve distributions on random instances of these sets. Sufficient conditions for randomized decision problems to be polynomially isomorphic are shown. It is then proved that all the known average-case NP-complete problems under many-one reductions are polynomially isomorphic. These problems include the randomized tiling problem, the randomized halting problem, the randomized Post correspondence problem, and the randomized word problem for Thue systems.",
Optimal weights for autocorrelation sequences,"Weighting functions for autocorrelation sequences are discussed in most signal processing textbooks. The standard design method is to convolve a classic window with itself. This method guarantees non-negative power spectral estimates, but it leads to suboptimal performance. In this paper we will present approaches to designing optimal autocorrelation windows. The optimization problems were formulated both in terms of quadratic programming and linear programming.",
A repetitive fault tolerance model for parallel programs,"The authors propose a repetitive fault tolerance (RFT) model, which provides an environment for the systematic development of fault tolerant parallel programs. RFT programs can tolerate processor failures without sacrificing performance. The system gives an optimal performance when all the processors are working while continuing to work, though at a lower performance, when failure occurs. Also, the system works as long as there is at least one working processor. Thus, it not only provides a software solution to achieve a highly reliable parallel computation environment but also provides an elegant solution for constructing reliable nonrepairable systems. The model is applied to three examples to illustrate the construction procedure and to evaluate the performance of repetitive fault tolerant programs as well as to demonstrate the applicability of this model.",
Modeling a class of priority-based ATM communication switch designs,"Owing to its efficiency and flexibility, asynchronous transfer mode (ATM) has emerged as the most promising transfer technique for wide-area broadband telecommunications that provide text, image, voice, and video information services. The paper deals with the modeling of a class of ATM communication switch designs. Various buffering mechanisms are considered in the switch design to alleviate cell contentions. Analytical models for these design alternatives are developed for the case of a nonuniform, traffic pattern, the favorite load, which can reflect some typical ATM applications. Performance comparisons are also conducted for a number of design alternatives.",
A non-recursive method for solving the general discrete-time riccati equations related to the H∞ control problem,"In this paper we propose a non-recursive method for solving the general discrete-time algebraic Riccati equation related to the H∞, control problem (H∞-DARE). We have achieved this by casting the problem of solving a given H∞-DARE to the problem of solving an auxiliary continuous-time algebraic Riccati equation associated with the H∞ control problem (H∞-CARE) for which the well known non-recursive methods of solving are available. The advantages of our approach are: it reduces the computation involved in the recursive algorithms while giving much more accurate solutions, and it readily provides the properties of the general H∞-DARE.",
Programming multicomputers using shared objects,"Multiprocessors and multicomputers differ in important ways in terms of hardware and software. One kind of machine is hard to build but easy to program, and the other is easy to build but hard to program. We believe that by using shared objects as a programming paradigm, it is possible to combine the best properties of these two models. In this paper, we describe how it can be done. Our solution is based on having the programmer declare objects that can be potentially shared among processes on all machines in the system. These objects are passive-they are invoked by threads, but do not themselves contain internal threads. The shared objects act as though they are in a common shared memory (even though they are not), and can be accessed by all authorized processes by simply invoking their methods. Each method operates only on a single object.",
TRUMP-a fast reliable transport protocol for distributed systems,"Traditional transport protocols such as TCP and TP4 were not designed to be used in distributed systems; they also fail to support the high speeds and low error rates of current high speed networks such as FDDI. Various protocols, such as VMTP, RRDP, NET-BLT and XTP have suggested ways of supporting distributed systems and/or high speed networks. However, none of them have fully supported both distributed systems and high-speed networks. This paper outlines the structure of TRUMP, a transport protocol that meets most of the requirements for high speed networks and distributed systems, except for multicast, which is still being designed.",
An improved neural processing element using pulse coded weights,"A technique is presented to allow both inhibition and excitation weights to take place on the same input lines of pulse coded neural processing element (NPE). This is achieved by using different ranges of pulse duty cycles for excitation and inhibition. The pulse coded NPE contains blocks of neural type cells (NTC), a summation, a nonlinear threshold logic, and a learning block for adaptive weight feedback. Modifications on the neural-type cell are presented to achieve this as well as wider oscillation ranges. Simulation results verify the functions for each block. The results allow for adapting weights through sign changes leading to more flexibility in design and less power consumption. Along with its functional block-based structure, the NPE, as an artificial neuron, can be applied in many different configurations of neural networks. A layout for a configuration for a winner-take-all network was carried out and sent to MOSIS for IC fabrication.",
A nonlinear least squares approach to the numerical optimal control of non-holonomic systems,This paper gives a nonlinear least squares approach for numerically finding a trajectory to transfer a non-holonomic system from one configuration to another while satisfying given point-wise configuration constraints. A car-like robot is considered as an example. The car-like robot is kinematically constrained and is modelled as a 2D object translating and rotating in the horizontal plane. The configuration constraints correspond to obstacle-avoidance. A simple technique is used to set up an approximate nonlinear least squares problem that includes the various constraints. An elegant error analysis is devised to effectively deal with the approximations. Several illustrative examples are presented to demonstrate the effectiveness of the approach.,
Bridging the gap between digital circuits and microprocessors,"Most electrical and computer engineering students understand digital circuits and microprocessors, but fail to appreciate that a microprocessor is just a complex finite state machine. The authors present a three experiment sequence which takes the students from the design of a simple EEPROM-based finite state machine through a two-chip microsequencer to a 4-bit central processing unit (CPU).",
Integrated engineering workstation using the NeXT Step operating system,"The authors outline the progress and experiences to date on the development of an automated laboratory workstation configuration funded by the National Science Foundation Instrumentation and Laboratory Improvement Program, (NSF-USE-9051175). This workstation was developed at Southern Illinois University at Edwardsville using the NeXTStep Unix Mach-based object-oriented operating system. This networked workstation configuration is designed to increase efficiency of the laboratory sessions by automating the data acquisition process and permitting students to analyze data in laboratory session at the workstation. The automation, the ease of data acquisition, and the programmability have provided the students the time to explore and the opportunity to expand their horizon. The authors discuss types of experiments that lend themselves well to automation, review the network configuration and software, and describe both the positive and negative results with this approach.",
"Intelligent DSS in engineering, agriculture and environment: combining knowledge based systems with simulation and modeling","This paper contrasts decision support systems (DSS) combining knowledge based systems with simulation and modeling in three fields: engineering, agriculture and environment. Although each field is rich enough in both simulation modeling and expert supplied domain knowledge and the initial impression may be that a uniform approach is adequate, distinct differences between the requirements in each field can be seen. This is illustrated in the context of three principle examples from each field (a CAE system for plasma sprayed films, an irrigation support system, and an environmental impact assessment system). In passing from engineering to agriculture to environment, one sees a need for an increasing degree of freedom in structuring goals. By examining more carefully how agricultural and environmental DSSs operate, engineers may find insight into ways to enhance the user friendliness and human interactivity of engineering DSSs.",
Implementation and evaluation of relational algebra operations on the Connection Machine,"The authors describe the implementation and analysis of relational algebra (RA) operators on a single instruction multiple data computer, the Connection Machine. Several traditional algorithms for RA operations are parallelized and reevaluated in this environment.",
Normal and Abnormal Codes,,
On the rearrangeability of switching networks composed of digital symmetrical matrices,"This paper studies the rearrangeability of switching networks composed of digital symmetrical matrices (DSM networks). We describe an efficient rearrangement algorithm for rearrangeable DSM networks with O(r/sup 2/) time complexity, where r is the number of input (output) switches. We also show that r-1 is an upper bound an the number of existing connections that need to be rearranged in order to realize a connection request.",
Geometric characterization of series-parallel variable resistor networks,"The authors describe an efficient method for computing exact bounds on the operating conditions of series-parallel networks. The range of operating conditions for a series-parallel network of variable linear resistors, voltage sources, and current sources can be represented as a convex polygon in a Thevenin or Norton half plane. For a network with k variable elements, these polygons have at most 2k vertices. By introducing a class of infinite points, circuits with potentially infinite Thevenin resistance or Norton conductance can also be represented.",
Enforcing data dependencies in cooperative information systems,Interdependent data are data objects in a cooperative information environment that are related by mutual consistency requirements. A flexible framework for specifying the dependency requirements of interdependent data using data dependency descriptors is discussed. A mechanism called polytransactions is presented to automatically generate actions to restore the consistency between interdependent data. The design of two concurrency control mechanisms for concurrent execution of polytransactions is given. The first is a deadlock-free graph-locking mechanism and the second is a variant of multiversion timestamps with rollback that never rejects operations arriving out of timestamp order. A conceptual system architecture is outlined for the execution of polytransactions. The notion of a multidatabase monitor is discussed.,
An algorithm for generating n Huffman codes with a worst case of (n log/sub 2/ n+n log/sub 2/ log/sub 2/ n) comparisons,"The method is based on a Heapsort algorithm for sorting a sequence of n data elements with a worst case of (n log/sub 2/ n+n log/sub 2/ log/sub 2/ n) comparisons. The idea of heap restoring in the Heapsort algorithm is incorporated into the Huffman tree building process. The performance of the proposed algorithm in execution time is evaluated with a list of ordered, random, and reverse ordered data containing from 5000 to 500000 items.",
Average message overhead of replica control protocols,"Management of replicated data has received considerable attention in the last few years. Several replica control schemes have been proposed which work in the presence of both node and communication link failures. However, this resiliency to failure inflicts a performance penalty in terms of the communication overhead incurred. Though the issue of performance of these schemes, from the standpoint of availability of the system, has been well addressed, the issue of message overhead has been limited to the analysis of worst-case and best-case message bounds. In this paper, we compare several well-known replica management protocols and control schemes in terms of their average-case message overhead. We also consider the tradeoff between the message overhead and availability, and we define the system model considered. Analytical expressions are derived for five well-known replica control protocols. The results are discussed with numerical examples.",
Definition and application of metaclasses in an object-oriented database model,"The metalevel concepts for an object-oriented database model are presented. Usually, systems that include a metaclass concept are either only implicitly supporting the management of meta information, which restricts the application of this concept, or explicitly giving unrestricted access to manipulate metaclasses, which results in inconsistent states of the system. To make the explicit support more system-controlled, the metascheme is partitioned into two parts: the system view and the application view. Possible scheme level operations, the representation of methods and their implementation as a special kind of meta information, and a simple extension to the query algebra of the underlying object-oriented database system that allow users to query objects and metaobjects within a single algebra expression are described.",
Rule-driven EDIF reference solving,"The main features of a general reference solving system for EDIF (Electronic Design Interchange Format) applications are discussed. The solving process is rule-driven, in order to make it applicable to various versions of EDIF, and relies on a dual reduce-resolve method. In addition, the limits within which the system operates are investigated. It is noted that the system rule base can act as a model of the EDIF referencing schema. The system can therefore be used in assisting in the design of new EDIF versions. The reference subnet has been implemented for applications based on both EDIF Version 2 0 0 and Version 2 9 0.",
Experimental evidence for the power of random sampling in practical parallel algorithms,"Recent results in parallel algorithm theory have shown random sampling to be a powerful technique for achieving efficient bounds on the expected asymptotic running time of parallel algorithms for a number of important problems. The authors show experimentally that randomization is also a powerful practical technique in the design and implementation of parallel algorithms. Random sampling can be used to design parallel algorithms with fast expected run times, which meet or beat the run times of methods based on more conventional methods for a variety of benchmark tests. The constant factors of proportionality in the run times are small, and, most importantly, the expected work (and hence running time) avoids worst cases due to input distribution. They justify the approach through experimental results obtained on a Connection Machine CM-2 for a specific problem, namely, segment intersection reporting, and explore the effect of varying the parameters of the method.",
The high performance computing and communications initiative in the US,"Summary form only given, as follows. In the future, people will collaborate in real time and share virtual reality environments. In addition, very large databases will be monitored by knowbots with sufficient intelligence to present meaningful information as moving objects in an interactive environment. The high performance computing and communications initiative (HPCC) was started to support research that will lead to dramatic improvements for the future computing environment. The National Science Foundation (NSF) supports a number of science and technology centers and manages two large-scale networking programs.<>",
A comparison of three switching schemes in isotropic networks with noisy channels,"Previous work on analyzing three switching schemes for isotropic networks, namely single hop and two cut-through communication schemes (with and without error checking by intermediate nodes), is extended. Each scheme is modeled by a discrete Markov chain. It is shown how the performance of the communication schemes depends on path length (n), load on the network ( lambda ), and the error rate (p). As expected, the cut-through schemes perform much better than the single hop when the communication load is light, but as the load increases, the cut-through schemes deteriorate more rapidly, until they are comparable. In fact, when the load approaches saturation ( lambda is close to 1-p), the cut-through schemes are actually worse than the single-hop schemes. The schemes with checking always outperform those without, but each node must perform more work in checking the correctness of the packets passing through. The time delay becomes infinite when the throughput approaches 1-p. The solutions are expressed as simple formulas and/or algorithms for each scheme.",
On the complexity of global computation in the presence of link failures: the general case,"The paper presents Omega (m log n) and Omega (mn) message lower bounds on the problem of computing a global sensitive function in bidirectional networks with link failures (i.e., dynamically changing topology), where n and m are the total number of nodes and links in the network. Then Omega (m log n) lower bound is under the assumption that n is a-priori known to the nodes, while the second bound is for the case in which such knowledge is not available . A global sensitive function of n variables is a function that may not be computed without the knowledge of the values of all the n variables (e.g. maximum, sum, etc.). Thus, computing such a function at one node of a distributed network requires this node to communicate with every other node in the network. Though lower bounds higher than Omega (m) messages are known for this problem in the context of link failures, none holds for dense bidirectional networks. Moreover, the authors are not aware of any other non-trivial lower bound higher than Omega (m) for dense bidirectional networks.",
The Parallel State Processor,"The Parallel State Processor (PSP) is intended as a design concept of the basic engine in large scale multiprocessors. Rather than switching between threads, PSP maintains a basic processor state which is itself a parallel conjunction of fetch and decode along multiple threads as well as the synchronization which occurs when operands are passed between them. This view gives rise to the possibility of an intelligent parallel state, i.e., one which dynamically maximizes the lifetime of the threads it comprises by having them provide one another with the arguments they require over time. We present experimental data verifying that such behavior can be observed in actual code.",
A variable structure neural network model and its applications,"The paper presents a neural network model called variable structure neural network model (VSNNM), also named improved multilayer perceptron (IMLP). In view of the back propagation algorithm (BPA), it is a time-consuming algorithm and its learning time is about O(n/sup 3/). In contrast to BPA, the speed of the learning algorithm proposed is much faster. Taking XOR for example, the speed of the learning algorithm is about 30 times faster than BPA. Moreover, hard limiters as the activation functions of neurons and only integer connection weights are used in VSNNM. Both the number of hidden layers and the number of hidden neurons in each hidden layer are variable, along with the demands of problems, but they are always kept minimum. Thus, this will greatly facilitate actual hardware implementation of training VSNNM. Hence, considering its speed and the number of neurons, the VSNNM is a successful attempt.",
ALIAS environment: A design tool for application specific arrays,"We present a methodology for synthesis of application specific arrays for matrix computations. The system, called ALIAS (algorithms into arrays synthesizer), is an interactive design environment facilitating automated mapping between matrix algorithms and hardware implementations. Our method, which incorporates and integrates ideas from past studies and new transformational notations, provides a basis for the efficient design of useful arrays. ALIAS consists of three main modules: MAP (matrix algorithm parser), DIP (display interface program), and DM (descriptor manipulator). MAP takes inputs which are the single-assignment equivalents of matrix algorithms and produces descriptors for the dependency graphs. DIP displays the MMG (multi-mesh graph) structure to the interactive user. DER module then applies drivers which are essentially a set of transformation functions to the descriptors in an attempt to derive the hardware implementations of the algorithm.",
DEVE: An expert system approach to hardware design verification,"Introduces a knowledge-based approach to hardware verification. A Prolog-based expert system, DEVE, has been developed for hardware design verification. A formal hardware description language for the implementation and for the specification is the input to the verification system. The verification is achieved by interpreting the specification to invoke proper domain specific methods on the implementation model and by reasoning from first principles. This expert system approach to hardware verification integrates formal and domain specific methods in a knowledge-based environment. DEVE attempts to provide a verification tool in a knowledge-based framework by guiding the theorem-proving component provided by the Prolog interpreter with domain specific knowledge and methods.",
New architecture to reduce I/O bottlenecks in high-performance systems,"Reviews large-scale application input/output requirements that are driving the need for high-performance distributed hierarchical storage. The focus is on evolving, high-performance, network-based storage-system architectures. The authors discuss some ideas about paradigm shifts that provide perspective on what is happening in system architectures; they outline, using examples, application storage and I/O requirements; they review relevant historical trends in storage-system architecture and their limitations; and they outline the IEEE Mass Storage Reference Model, focusing on the experience and issues in the use of network-connected devices and third-part protocol architectures to reduce the overall I/O bottleneck in distributed system environments.",
An Update on the Gigabit Network Testbeds,,
Parallel garbage collection and graph reducer,"We investigate the problem of parallel evaluation of functional programs. We have developed a novel approach to deal with sharing in graph reduction. Share nodes are introduced to explicitly handle sharing. By using share nodes, we have a garbage collection method that is on-the-fly (real time), parallel, distributed, and incremental. In our parallel graph reducer, copying can be done in parallel to make an exponential growth of program tree nodes. Since each node represents a simple operation, the growth of program trees is a natural distribution of computation work. Load balancing becomes very easy and can be done automatically. A simulator is implemented to simulate a tree structured parallel computer to run our graph reducer. Examples such as parallel matrix addition and multiplication are tested.",
Temporal analysis for hard real-time scheduling,The authors present an analysis technique for time driven scheduling based on the timing requirements of tasks. The analysis results in the establishment of a set of temporal relations between pairs of tasks based on a nonpreemptive scheduling model. The relationships can be used effectively to reduce the average complexity of scheduling these tasks. They also serve as a basis for selective preemption policies for scheduling by providing an early test for infeasibility. Examples and simulation results are presented to confirm the usefulness of temporal analysis as a phase prior to scheduling.,
Formal support for software maintenance,"In this paper we combine a variation of the CAPS model with an extended version of Prolog based upon the stable model semantics of logic programming [GEL]. We believe this to be the first paper presenting such a combination. In order to combine the CAPS model with the extended Prolog, we first implement a subset of the PSDL language in Prolog. We show the significance of the combination through an example prototype of a problem originally suggested by Lehman (1990). The resulting model provides a general framework for developing prototypes capable of determining when they are in need of adaptive maintenance.",
Minisymposium: the heterogeneous computing challenge,,
From trace graphs to modular delay-insensitive circuits,"The problem of synthesizing modular delay-insensitive circuits specified by a class of trace structures is considered. First, the notion of trace graphs is introduced for the purpose of facilitating the description of the relevant trace structures. Then, a theoretical framework within which the verification problem can be precisely formulated is established. It is shown how the dynamic behavior of a modular network may be derived from the specification of its component modules. The objective of this approach is to prove the correctness of the synthesis algorithm rather than verifying particular asynchronous circuits.",
A Direct Geometrical Method for Bounding the Error Exponent for Specific Families of Channel Codes Part II: The Confining Region Lower Bound for Block Codes,"The introduction of a confining region that divides the channel output space in two disjoint parts attains the same effect as the Gallager's exponent, but gives much mope insight into the behaviour of channel codes. Moreover, the bounds obtained are always tight at low code rates (for optimal codes they are always tight).",
CASE data interchange format (CDIF) standards: introduction and evaluation,"Mechanisms for integrating CASE tools are reported, and players in CASE standards development are identified. The author provides a detailed review of the CASE data interchange format (CDIF), one of the most mature CASE standards, and compares it with other relevant CASE standards. Issues involved in adopting CDIF are presented. The current status and future development of CDIF are discussed.",
Parallel implementations of exclusion joins,"This paper examines the parallel processing of exclusion join in a shared-nothing multiprocessor environment. First, a parallel hash-based exclusion join algorithm is presented. Unlike the case of equijoin, this algorithm does not work correctly in the presence of nulls in the join attributes. One solution is to restrict the hash-on attributes to non-nullable fields. However, this can lead to the well known data skew problem. If the number of tuples containing null values in their join attributes is small, an alternative is to replicate those tuples to all processors. Otherwise, we can consider a range partitioning algorithm where those tuples are only sent to a small subset of the processors. The hash-based algorithm usually outperforms the range partitioning algorithm except when the number of tuples containing null values in their join attributes is large or when the data is highly skewed.",
Hopf bifurcation and Hopf hopping in recurrent nets,"Some aspects of the learning dynamics of recurrent neural networks are discussed. It is shown that as a two-unit fully recurrent network is trained to oscillate, the learning process brings the network to a point where a small change in any one of the weights can push the network through a Hopf bifurcation to create stable oscillation. As learning continues, the network indeed bifurcates to create the stable limit cycle. The limit cycle is soon destroyed and recreated several times, with the limit cycle phase becoming more dominant each time. As a result of this 'Hopf-hopping' phenomenon, it is very difficult to assess how close the network is to learning the desired periodic behavior. Eigenvalue analysis shows that the limit cycles in the later stage are more robust than the limit cycles in the earlier stage. It is shown which weights are more critical in order for the network to maintain periodic behavior.",
Efficient Support for Sparse-Group Multicast Routing,,
Discrete-time cellular neural network for thinning: A compound synthesis,"The authors depict a novel thinning method by using a discrete-time cellular neural network. By extracting the inherent topographical properties, namely the midpoints of every line segment of the line image, thinning is shown to be attainable without a clumsy 7-neighbor test and stopping condition check. Circuit simplication is achieved by eliminating the usage of time-variant templates, and thus the only control signal in the network is the system clock. Overall performance of the thinning system is evaluated and is compared with previous studies.",
B***-tree: a family of efficient data packaging multiway trees,"Presents the B***-tree, a data organization method which improves the storage utilization of the conventional B*-tree by 20%-50%. The B***-tree uses a special node data structure that eliminates some of the I/O overhead incurred during building the index. Moreover, an adaptation of the B***-tree in distributed memory multiprocessors is discussed. This structure guarantees 100% storage utilization, and incurs a tolerable message passing overhead, solely dependent on the branching factor of the tree.",
Via Minimization in channel Routing by Layout Modification,,
C-testable systolic arrays,A reconfigurable cell model for C-testability of systolic arrays is presented. With this model each systolic array is reconfigurable to a set of C-testable orthogonal iterative systolic arrays (OISAs). The time complexity of a systolic array is determined from the time complexity of its corresponding OISAs. The C-testable time complexities of some known systolic arrays are presented.,
Pinhole Fan Beam Circular Ring Single Photon Tomography Using Multi-detector Crystal Array,,
An inference browser to verify knowledge bases,"The authors previously suggested a graph-aided inference browser in which the knowledge engineers may easily verify the knowledge bases by consulting the sequence of inferring steps. In the suggested inference browser, however, the knowledge engineers themselves keep trying to find the error in the knowledge bases by checking if the displayed inferring sequence faces the undesirable situation. This error-detecting process may be slow and not very accurate as the size of the knowledge base becomes very large. The authors present an extended version of the graph-aided inference browser in which the error detecting process is automatically done. As compared to the previous graph-aided inference browser, the presented inference browser involves one additional module, called an automatic verification module, which detects and analyzes the erroneous situation during the inferring process and corrects the associated errors in the knowledge base.",
On Asymptotic Optimality of a Sliding Window Variation of Lempel-Ziv Codes,"Ziv and Lempel proposed two important universal coding algorithms in 1977 and 1978 [1, 2]. While the second algorithm called LZ78 has been sufficiently analyzed in the literature, the first LZ77 has not yet. LZ77 parses input data into a sequence of phrases, each of which is the longest match in a fixed-sized sliding window which consists of the previously encoded M symbols. Each phrase is replaced by a pointer to denote the longest match in the Window. Then a window slides to just before the next symbol to be encoded, and so on. In this paper, we modify the algorithm of LZ77 to restrict pointers to starting only at the boundary of a previously parsed phrase in a window, although the number of parsed phrase should increase more than those in LZ77, the amount of bits needed to encode pointers is considerably reduced since the number of possible positions to be encoded is much smaller. Then we show that for any stationary finite state source, the modified LZ77 code is asymptotically optimal with the convergence rate O(log log M/ log M) where M is the size of a sliding window.",
A computational model of proprioceptive maps,"The authors developed a computational model of proprioceptive somatosensory cortex. A model arm controlled by three pairs of muscle groups moves in a 3D space. The muscle length end tension determined by randomly generated neuronal input to the muscles was presented to the network as a proprioceptive input. The network, consisting of two layers of units, with arm layer of 12 length and tension inputs and SI layer of 20/spl times/20 laterally connected units, distributed activation competitively. Trained with a variant of Hebb-type learning, the network developed feature maps of muscle length and tension, and a spatial map of hand position by encoding the interrelationships between muscle lengths. Thus, the network learned to capture the mechanical constraints of the model arm. These results can be viewed as testable predictions for future experimental studies.",
PROTEAN: A tool for automated protocol analysis,"A program which performs an automated analysis of a protocol specification is discussed. The input is a protocol specified formally using the systems of communicating machines (SCMs) model and the output is a system and/or global reachability graph, together with any protocol errors which were discovered. The program, called PROTEAN analyzes the protocol for errors such as deadlock and nonexecutable transitions. The SCM model uses a combination of finite state machines and variables, which may be local to a single machine or shared by two or more machines. The current implementation of the model is limited to two-machine protocols. An analysis of a simple data link protocol is included to illustrate the use of the SCM automated model.",
Learning regular and irregular examples separately,"Oka and Yoshida (1992) proposed GLLL, a hybrid neural network architecture-of a global and a local learning module, and demonstrated its high accuracy and efficiency. In this paper the authors analyze learning in GLLL directing their attention to separation of examples between the two modules. The authors' findings are: 1) regular and irregular examples are distinguished and learned separately by the two modules; 2) learning progresses in three stages, and overgeneralization occurs in the second stage; 3) outputs for highly unusual inputs are produced as if they are members of regular examples. These findings fit qualitatively human learning data reported by Marcus et al. (1990) and Pinker (1991).",
Totally unconstrained handwritten numeral recognition via fuzzy graphs,"The performance of a novel recognition system which uses fuzzy constrained character graph models (FCCGMs) is investigated for totally unconstrained and handwritten numeral recognition. The system was tested on 1812 unnormalized samples. The reliability, recognition, substitution error, and rejection rates of the system were 97.1%, 90.7%, 2.9%, and 6.4%, respectively.",
Exploring the design space of a superscalar implementation,"Instruction set architecture, processor implementation, compiler, performance, and cost all influence the design of a superscalar implementation of a pipelined processor. The authors focus on processor implementation and performance by presenting a methodology to explore the superscalar implementation design space. After the parameters in the design space have been identified, this methodology is applied to the Intel 80960CA instruction set architecture and compiler to produce performance curves to obtain performance differences of various implementation features. For a given performance range, regions of the design space which do not satisfy the performance requirements are discarded, and regions of the design space which do satisfy the performance requirements need to be examined further. The performance curves serve as a guide to reducing the design space.",
An adaptive variable structure control for fast time-varying unknown plants,"In this paper, a combination of adaptive control and variable structure control methodology is proposed to solve the general fast time-varying plants with totally unstructured parameters. We show that the control scheme will work only under the assumptions of known order, relative degree, high frequency gain sign and minimum-phase property. In contrast to the conventional approaches where the variable structure design is applied mainly to the adaptation of some traditional parameters /spl Theta/ by using the knowledge of unknown bounds on control parameters, a new adaptation scheme for control parameters incorporating the variable structure concept is given. Owing to this new scheme, we forsake the standard requirement of the upper bounds on some unknown parameters, which is frequently adopted in the field of robust linear MRAC using variable structure design. It is shown that without any persistent excitation, the tracking error will converge to zero in finite time for relative degree one plants and to a small residual set exponentially (whose size depends on a design parameter) for plants with any higher relative degree.",
3D visualization of fuzzy shapes using multichannel MR images,"The authors describe a method for an accurate extraction image of cerebral soft tissues from MR images in order to realize accurate diagnosis. With MRI it is possible to observe different soft tissues images of an anatomical section using different pulse sequences. However, it is difficult to 3D visualize one soft tissue with fuzzy shapes from MR images. To avoid this difficulty the authors used a combination of multichannel MR images, a fuzzy c-means clustering, and an object connectivity-check. Using volume rendering the authors could visualize a 3D extraction image of the brain and tumor.",
Experimental evaluation of output-based partition testing for expert systems,"Although a host of testing methods have been proposed for expert systems, little work has been done to compare effectiveness of these methods. The authors present an analysis of various parameters that govern the effectiveness of output based partition testing strategies for heuristic classification expert systems.",
Software and hardware support for workstation-based supercomputing,"The presented research has two main objectives: (1) to investigate the limitations of communications techniques used in current workstations-based systems and to identify a set of requirements that must be satisfied to achieve workstation-based supercomputing; and (2) to use these requirements to develop software and hardware support that makes workstation-based supercomputing possible. The performance of two applications, the LU factorization of dense matrices and the calculation of the fast Fourier transform, on two platforms, The iPSC/860 supercomputer and a cluster of general-purpose workstations, is used in the analysis to identify the limitations of current workstation clusters and to show that if these limitations are overcome, the clusters can provide comparable performance to that offered by an expensive supercomputer.",
