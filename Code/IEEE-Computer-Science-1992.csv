Title,Abstract,Keywords
"Fuzzy basis functions, universal approximation, and orthogonal least-squares learning","Fuzzy systems are represented as series expansions of fuzzy basis functions which are algebraic superpositions of fuzzy membership functions. Using the Stone-Weierstrass theorem, it is proved that linear combinations of the fuzzy basis functions are capable of uniformly approximating any real continuous function on a compact set to arbitrary accuracy. Based on the fuzzy basis function representations, an orthogonal least-squares (OLS) learning algorithm is developed for designing fuzzy systems based on given input-output pairs; then, the OLS algorithm is used to select significant fuzzy basis functions which are used to construct the final fuzzy system. The fuzzy basis function expansion is used to approximate a controller for the nonlinear ball and beam system, and the simulation results show that the control performance is improved by incorporating some common-sense fuzzy control rules.","Fuzzy systems,
Fuzzy sets,
Fuzzy neural networks,
Humans,
Fuzzy control,
Nonlinear control systems,
Neural networks,
Computer science,
Polynomials,
System testing"
Numerical potential field techniques for robot path planning,"An approach to robot path planning that consists of incrementally building a graph connecting the local minima of a potential field defined in the robot's configuration space and concurrently searching this graph until a goal configuration is attained is proposed. Unlike the so-called global path planning methods, this approach does not require an expensive computation step before the search for a path can actually start, and it searches a graph that is usually much smaller than the graph searched by the so-called local methods. A collection of effective techniques to implement this approach is described. They are based on the use of multiscale pyramids of bitmap arrays for representing both the robot's workspace and configuration space. This distributed representation makes it possible to construct potential fields numerically, rather than analytically. A path planner based on these techniques has been implemented. Experiments with this planner show that it is both very fast and capable of handling many degrees of freedom.","Path planning,
Orbital robotics,
Manipulators,
Joining processes,
Robot motion,
Motion planning,
Mobile robots,
Military computing,
Computational Intelligence Society,
Computer science"
Active Messages: A Mechanism for Integrated Communication and Computation,"The design challenge for large-scale multiprocessors is (1) to minimize communication overhead, (2) allow communication to overlap computation, and (3) coordinate the two without sacrificing processor cost/performance. We show that existing message passing multiprocessors have unnecessarily high communication costs. Research prototypes of message driven machines demonstrate low communication overhead, but poor processor cost/performance. We introduce a simple communication mechanism, Active Messages, show that it is intrinsic to both architectures, allows cost effective use of the hardware, and offers tremendous flexibility. Implementations on nCUBE/2 and CM-5 are described and evaluated using a split-phase shared-memory extension to C, Split-C. We further show that active messages are sufficient to implement the dynamically scheduled languages for which message driven machines were designed. With this mechanism, latency tolerance becomes a programming/compiling concern. Hardware support for active messages is desirable and we outline a range of enhancements to mainstream processors.","Hardware,
Costs,
Delay,
Permission,
Prototypes,
Algorithm design and analysis,
Computer science,
Large scale integration,
Processor scheduling,
Dynamic scheduling"
Planning optimal grasps,The authors address the problem of planning optimal grasps. Two general optimality criteria that consider the total finger force and the maximum finger force are introduced and discussed. Their formalization using various metrics on a space of generalized forces is detailed. The geometric interpretation of the two criteria leads to an efficient planning algorithm. An example of its use in a robotic environment equipped with two-jaw and three-jaw is described.,"Grippers,
Robots,
Fingers,
Extraterrestrial measurements,
Orbital robotics,
Actuators,
Manipulators,
Grasping,
Assembly systems,
Computer science"
Relative neighborhood graphs and their relatives,"Results of neighborhood graphs are surveyed. Properties, bounds on the size, algorithms, and variants of the neighborhood graphs are discussed. Numerous applications including computational morphology, spatial analysis, pattern classification, and databases for computer vision are described.","Application software,
Computer vision,
Morphology,
Bibliographies,
Computer science,
Shape,
Computer applications,
Pattern analysis,
Computational geometry,
Biology computing"
Spawn: a distributed computational economy,"The authors have designed and implemented an open, market-based computational system called Spawn. The Spawn system utilizes idle computational resources in a distributed network of heterogeneous computer workstations. It supports both coarse-grain concurrent applications and the remote execution of many independent tasks. Using concurrent Monte Carlo simulations as prototypical applications, the authors explore issues of fairness in resource distribution, currency as a form of priority, price equilibria, the dynamics of transients, and scaling to large systems. In addition to serving the practical goal of harnessing idle processor time in a computer network, Spawn has proven to be a valuable experimental workbench for studying computational markets and their dynamics.",
The detection of fault-prone programs,"The use of the statistical technique of discriminant analysis as a tool for the detection of fault-prone programs is explored. A principal-components procedure was employed to reduce simple multicollinear complexity metrics to uncorrelated measures on orthogonal complexity domains. These uncorrelated measures were then used to classify programs into alternate groups, depending on the metric values of the program. The criterion variable for group determination was a quality measure of faults or changes made to the programs. The discriminant analysis was conducted on two distinct data sets from large commercial systems. The basic discriminant model was constructed from deliberately biased data to magnify differences in metric values between the discriminant groups. The technique was successful in classifying programs with a relatively low error rate. While the use of linear regression models has produced models of limited value, this procedure shows great promise for use in the detection of program modules with potential for faults.","Fault detection,
Software quality,
Software measurement,
Computer errors,
Predictive models,
Software metrics,
Time measurement,
Computer science,
Error analysis,
Linear regression"
Designing an on-demand multimedia service,"A quantitative study of techniques for designing a high-performance multiuser multimedia on-demand information service is presented. The problem of maintaining continuity of playback of each media stream in the presence of multiple subscriber requests is formulated, and admission control algorithms that permit a multimedia server to satisfy the maximum number of subscribers simultaneously are presented. A feedback technique in which a multimedia service uses lightweight messages called feedback units that are transmitted back to it by subscribers' mediaphones to detect asynchrony among them and steer them back to synchrony thereafter is presented. The feedback technique guarantees synchronous playback of media streams transmitted by the multimedia server to subscribers over metropolitan-area networks.","Streaming media,
Network servers,
Information retrieval,
Motion pictures,
Computer science,
B-ISDN,
Optical arrays,
Optical devices,
Bandwidth,
Costs"
An updating algorithm for subspace tracking,"In certain signal processing applications it is required to compute the null space of a matrix whose rows are samples of a signal with p components. The usual tool for doing this is the singular value decomposition. However, the singular value decomposition has the drawback that it requires O(p/sup 3/) operations to recompute when a new sample arrives. It is shown that a different decomposition, called the URV decomposition, is equally effective in exhibiting the null space and can be updated in O(p/sup 2/) time. The updating technique can be run on a linear array of p processors in O(p) time.",
Augmented reality: an application of heads-up display technology to manual manufacturing processes,"The authors describe the design and prototyping steps they have taken toward the implementation of a heads-up, see-through, head-mounted display (HUDset). Combined with head position sensing and a real world registration system, this technology allows a computer-produced diagram to be superimposed and stabilized on a specific position on a real-world object. Successful development of the HUDset technology will enable cost reductions and efficiency improvements in many of the human-involved operations in aircraft manufacturing, by eliminating templates, formboard diagrams, and other masking devices.","Augmented reality,
Two dimensional displays,
Manuals,
Manufacturing processes,
Aircraft manufacture,
Robotics and automation,
Virtual reality,
Robotic assembly,
Aircraft propulsion,
Production facilities"
Analysis of a fluid approximation to flow control dynamics,"The authors consider a flow control mechanism that dynamically regulates the rate of data flow into a network based on feedback information about the network state. Such mechanisms have been introduced in a variety of networks, and have been advocated for future high-speed networks. The authors first model the flow control mechanism by a discrete-space stochastic process and define appropriate performance measures for transient and steady-state regimes. However, the model does not appear to be analytically tractable, and the authors study it through simulation. They then simplify it to a continuous-space deterministic (or fluid) model for which closed-form solutions can be derived easily. It is found that the analytical results for the fluid model agree well with the simulation results obtained using the discrete-space model. Both models explicitly consider delay of the feedback information, thus making them relevant for high-speed networks.",
Applying case-based reasoning to autoclave loading,"Clavier, a case-based reasoning system that determines the placement of parts made of composite materials in an autoclave, is described. The heating rate of all parts put in an autoclave must be controlled carefully, but their number, shape, and placement can cause significant nonlocal variations. Clavier provides interactive support, using cases to propose load configurations and multiload plans. One of its advantages is that it learns, becoming more competent as it acquires new cases. Clavier's structure and results from evaluations of Clavier as an application and as a case-based reasoning research tool are discussed.",
Current-mode analog fuzzy hardware with voltage input interface and normalization locked loop,"A voltage-input current-output membership function circuit (MFC) and a normalization locked loop (NLL) are proposed. They are useful building blocks for current-mode analog fuzzy hardware. The voltage-input current-output MFC consists of two-source-coupled-type operational transconductance amplifiers (OTAs). The MFC is used in the input parts of the analog fuzzy hardware system. The fuzzy hardware system can execute the singleton fuzzy control algorithm. In the algorithm, the weighted average operation is processed. When the weighted average operation is directly realized by analog circuits, a divider must be implemented. The NLL circuit, which can process the weighted average operation without the divider, is implemented using a one-source-coupled OTA. The proposed circuits were designed by using 2- mu m CMOS design rules and their operations were confirmed using SPICE simulations.","Hardware,
Voltage,
Fuzzy systems,
Fuzzy control,
Transconductance,
Operational amplifiers,
Analog circuits,
SPICE,
Circuit simulation"
Environment evolution: the Prism model of changes,"A software development environment supports a complex network of items of at least the following major types: people, policies, laws, resources, processes and results. Such items may need to be changed on an on-going basis. The authors have designed in the Prism project a model of changes and two supporting change-related environment infrastructures with the following key features: separation of changes to the described items from the changes to the environmental facilities encapsulating these items; a facility, called the dependency structure, for describing various items and their interdependencies, and for identifying the items affected by a given change; a facility, called the change structure for classifying, recording, and analyzing change-related data and for making qualitative judgments of the consequences of a change; identification of the many distinct properties of a change; and a built-in mechanism for providing feedback. The author's approach to the problem of change and its rationale is described.","Programming,
Environmental management,
Complex networks,
Data analysis,
Mechanical factors,
Feedback,
Project management,
Engineering management,
Councils,
Computer science"
Penetration state transition analysis: A rule-based intrusion detection approach,"A new approach to representing computer penetrations is introduced called penetration state transition analysis. This approach models penetrations as a series of state transitions described in terms of signature actions and state descriptions. State transition diagrams are written to correspond to the states of an actual computer system, and these diagrams form the basis of a rule-based expert system for detecting penetrations, referred to as STAT.","Intrusion detection,
Expert systems,
Computer security,
Data security,
Data analysis,
Postal services,
Computer science,
Research and development,
Software tools,
Real time systems"
Some Problems In Perspective System Theory And Its Application To Machine Vision,,"Machine vision,
Computer vision,
Time varying systems,
Humans,
Motion estimation,
Visual system,
Image sequences,
Shape,
US Department of Energy,
Lenses"
What's in a set of points? (straight line fitting),"The problem of fitting a straight line to a planar set of points is reconsidered. A parameter space computational approach capable of fitting one or more lines to a set of points is presented. The suggested algorithm handles errors in both coordinates of the data points, even when the error variances vary between coordinates and among points and can be readily made robust to outliers. The algorithm is quite general and allows line fitting according to several useful optimality criteria to be performed within a single computational framework. It is observed that certain extensions of the Hough transform can be turned to be equivalent to well-known M estimators, thus allowing computationally efficient approximate M estimation.","Robustness,
Least squares approximation,
Least squares methods,
Computer vision,
Pollution measurement,
Computer errors,
Computer science,
Machine intelligence,
Feature extraction,
Digital images"
Building the business case for group support technology,"As groupwork gains recognition, emerging group support technologies raise questions about the merits of these systems relative to group performance and return on investment. Business case variables of efficiency, quality, effectiveness, customer satisfaction and decision-making are useful in measuring the potential contribution that group support technologies offer. The author presents findings from a recent field study that used business case concepts as its design approach. He explores the infrastructure development requirements for building a business case study. Such a framework is useful to business decision-makers and researchers interested in the deployment of these technologies in complex business environments.","Computer aided software engineering,
Investments,
Companies,
Performance gain,
Customer satisfaction,
Buildings,
Collaboration,
Decision support systems,
Acoustic scattering,
Financial management"
Adaptive routing in mesh-connected networks,"It is shown that wormhole routing in mesh-connected networks can be deadlock free and adaptive without the addition of channels to the basic topology. Several partially adaptive routing algorithms for 2-D and 3-D meshes are described and simulated for a variety of conditions. Simulations of policies for selecting input channels show that transmitting extra information in the header flits can reduce communication latencies at high network throughputs. Simulations of policies for selecting output channels show that avoiding turns reduces latencies at high throughputs. Unrestricted nonminimal routing is found to reduce latencies slightly at low throughputs but increase latencies significantly at high throughputs. For nonuniform traffic patterns, a partially adaptive routing algorithm performs better than a nonadaptive one.",
Slot allocation strategies for TDMA protocols in multihop packet radio networks,"The authors derive an upper bound of the minimum time division multiple access (TDMA) frame length of any collision-free node assignment protocol in a packet radio network in which a node has multiple reception capacity. They also derive the optimum TDMA frame length for any fully connected network with large reception capacity. When the total number of nodes in the network is unknown, a heuristics to generate a TDMA protocol with frame length within some upper bound is presented for any network with large reception capacity.","Time division multiple access,
Intelligent networks,
Spread spectrum communication,
Packet radio networks,
Access protocols,
Upper bound,
Radio network,
Computer networks,
Computer vision,
Computer science education"
The decoupling of generalized state-space systems via state feedback,"The input-output decoupling problem of generalized state-space systems (GSS) via proportional state feedback is studied. The following three major issues are resolved: the necessary and sufficient conditions for the problem to have a solution, the general analytical expressions of the controller matrices, and the general analytical expressions of the diagonal elements of the closed-loop system. It is concluded that the approach presented seems to be a quite powerful tool for solving several feedback design problems for GSS systems. Using this method, problems such as decoupling and simultaneous pole assignment and decoupling via output feedback are successfully studied.","State feedback,
Control systems,
Proportional control,
Feedback control,
Control theory,
Polynomials,
Computer science,
PD control,
Sufficient conditions"
On the fault tolerance of some popular bounded-degree networks,"The authors analyze the fault-tolerance properties of several bounded-degree networks that are commonly used for parallel computation. Among other things, they show that an N-node butterfly containing N/sup 1- epsilon / worst-case faults (for any constant epsilon >0) can emulate a fault-free butterfly of the same size with only constant slowdown. Similar results are proved for the shuffle-exchange graph. Hence, these networks become the first connected bounded-degree networks known to be able to sustain more than a constant number of worst-case faults without suffering more than a constant-factor slowdown in performance. They also show that an N-node butterfly whose nodes fail with some constant probability p can emulate a fault-free version of itself with a slowdown of 2/sup O(log* N)/, which is a very slowly increasing function of N. The proofs of these results combine the technique of redundant computation with new algorithms for routing packets around faults in hypercubic networks. Techniques for reconfiguring hypercubic networks around faults that do not rely on redundant computation are also presented. These techniques tolerate fewer faults but are more widely applicable since they can be used with other networks such as binary trees and meshes of trees.","Fault tolerance,
Computer networks,
Computer science,
Mathematics,
National electric code,
Routing,
Contracts,
Laboratories,
Concurrent computing,
Binary trees"
Communication on noisy channels: a coding theorem for computation,"Communication is critical to distributed computing, parallel computing, or any situation in which automata interact-hence its significance as a resource in computation. In view of the likelihood of errors occurring in a lengthy interaction, it is desirable to incorporate this possibility in the model of communication. The author relates the noisy channel and the standard (noise less channel) complexities of a communication problem by establishing a 'two-way' or interactive analogue of Shanon's coding theorem: every noiseless channel protocol can be simulated by a private-coin noisy channel protocol whose time bound is proportional to the original (noiseless) time bound and inversely proportional to the capacity of the channel, while the protocol errs with vanishing probability. The method involves simulating the original protocol while implementing a hierarchical system of progress checks which ensure that errors of any magnitude in the simulation are, with high probability, rapidly eliminated.","Codes,
Protocols,
Distributed computing,
Parallel processing,
Automata,
Concurrent computing,
Communication standards,
Channel capacity,
Capacity planning,
Hierarchical systems"
Fuzzy neural controller,"The authors consider a fuzzy controller that processes fuzzy information. They discuss the model of the fuzzy controller, with fuzzy inputs for error and change in error, using a max-min neural network. A new learning algorithm, a modified delta rule, is derived. The generalization property of the neural net can be used to find a controller output for new fuzzy values of error and change in error. An example is presented showing the applicability of the fuzzy neural controller.",
Connectionist probability estimation in the DECIPHER speech recognition system,"The authors have previously demonstrated that feedforward networks can be used to estimate local output probabilities in hidden Markov model (HMM) speech recognition systems (Renals et al., 1991). These connectionist techniques are integrated into the DECIPHER system, with experiments being performed using the speaker-independent DARPA RM database. The results indicate that: connectionist probability estimation can improve performance of a context-independent maximum-likelihood-trained HMM system; performance of the connectionist system is close to what can be achieved using (context-dependent) HMM systems of much higher complexity; and mixing connectionist and maximum-likelihood estimates can improve the performance of the state-of-the-art context-independent HMM system.","Speech recognition,
Hidden Markov models,
Maximum likelihood estimation,
Transfer functions,
Feedforward systems,
State estimation,
Entropy,
Databases,
Parametric statistics,
Computer science"
Towards An Assembly Plan From Observation: Part II: Correction Of Motion parameters Based On Fact Contact Constraints,,"Robotic assembly,
Assembly systems,
Humans,
Face detection,
Data mining,
Machine vision,
Error correction,
Robot programming,
Equations,
Computer science"
Benchmarking the CM-5 multicomputer,"The authors study the performance of the CM-5 multiprocessor. They provide a number of benchmarks for its communication and computation performance. Many of the operations, like scans and global reduction, can be performed using special hardware available on the CM-5. These operations have been benchmarked. The authors also describe how to embed a mesh and a hypercube on a CM-5 architecture and provide timings for some mesh and hypercube communication primitives on the CM-5.",
Robust parsing for spoken language systems,"A recent extension to the MIT ATIS (Air Travel Information Service) system, which allows it to answer a question when a full linguistic analysis fails is described. Robust parsing is applied only after a full analysis has failed, and it involves the two stages of (1) parsing a set of phrases and clauses, and (2) gluing them together to obtain a single semantic frame encoding the full meaning of the sentence. In a recent evaluation, less than two-thirds of the sentences analyzed yielded a full parse, but the overwhelming majority of the remaining sentences were analyzed correctly by the robust parsing scheme. When text input was replaced by recognizer outputs, even though the recognizer produced greater than 50% sentence error rate, the drop in score (%correct-%incorrect) was only 10 percentage points. This indicates that most of the recognizer errors are harmless in terms of meaning analysis, as long as a robust mechanism for accounting for the parsable phrases is in place.","Robustness,
Natural languages,
Failure analysis,
Speech recognition,
History,
Speech analysis,
Cities and towns,
Laboratories,
Computer science,
Information analysis"
Progress in neural network-based vision for autonomous robot driving,"This paper describes recent improvements to the ALVINN system (Autonomous Land Vehicle In a Neural Network) for neural network based autonomous driving. The authors perviously (1991, 1992) reported a technique which allows an an artificial neural network to quickly learn to steer by watching a person drive. But the faster the network is trained, the less exposure it receives to novel or infrequent scenarios. For instance, during a typical four minute training run, the network sees few if any examples of passing cars. When a rare situation like this occurs during testing, its lack of coverage in the training set canresult in erratic driving. By modeling the appearance of infrequent scenarios and then using the model to augment the training set, one can teach the network to generalize to situations not explicitly represented in the live training data. Using this technique, a network trained over a two mile stretch of highway was able to drive autonomously for 21.2 miles at speeds of up to 55 miles/hour.","Intelligent networks,
Neural networks,
Robot vision systems,
Road transportation,
Artificial neural networks,
Remotely operated vehicles,
Layout,
Image resolution,
Computer science,
IP networks"
Methods for improved update performance of disk arrays,"A disk array is a set of disk drives (and controller) which can automatically recover data when one (or more) disk drives in the set fails. One method used by disk arrays to achieve high availability at lower cost than mirroring is a parity technique. The main drawback of such arrays are that they need four disk accesses to update a data block-two to read old data and parity, and two to write new data and parity. The authors describe four new methods to improve the update performance of disk arrays that use the parity technique from four accesses to three and, in some cases, to two. All the schemes sacrifice disk storage efficiency for improved update performance by relaxing the requirement that the modified data and parity blocks be written back into their original locations. The best technique, called 'floating parity track', achieves much improved update performance while using only 1% more disk space than traditional arrays.","Disk drives,
Costs,
Telephony,
Automatic control,
Availability,
Protection,
Robustness,
Computer crashes,
Writing"
Unfolding and retiming data-flow DSP programs for RISC multiprocessor scheduling,"Retiming and unfolding are two useful techniques which have been effectively applied in many fields. These two techniques are combined to solve the problem of rate-optimal scheduling for unit-time data flow graphs (DFGs). A rate-optimal retimeable graph is a DFG such that after a legal retiming a rate-optimal schedule can be obtained. For the case of unit-time DFG, which is applicable to RISC multiprocessors, the best known upper-bound for an unfolding factor which produces a rate-optimal retimeable DFG is improved, and it is shown that the result is the minimum possible unfolding factor for rate-optimal schedules. Moreover, for any unfolding factor, the corresponding minimum rate is given by a simple criterion. Since it is proved that the order of retiming and unfolding is irrelevant, efficient polynomial-time retiming algorithms are obtained.","Digital signal processing,
Reduced instruction set computing,
Processor scheduling,
Optimal scheduling,
Delay,
Chaos,
Computer science,
Law,
Legal factors,
Polynomials"
Shared memory vs. message passing in shared-memory multiprocessors,"It is argued that the choice between the shared-memory and message-passing models depends on two factors: the relative cost of communication and computation as implemented by the hardware, and the degree of load imbalance inherent in the application. Two representative applications are used to illustrate the performance advantages of each programming model on several different shared-memory machines, including the BBN Butterfly, Sequent Symmetry, Encore Multimax and Silicon Graphics Iris multiprocessors. It is shown that applications implemented in the shared-memory model perform better on the previous generation of multiprocessors, while applications implemented in the message-passing model perform better on modern multiprocessors. It is argued that both models have performance advantages, and that the factors that influence the choice of model may not be known at compile-time. As a compromise solution, the authors propose an alternative programming model, which has the load balancing properties of the shared-memory model and the locality properties of the message-passing model, and show that this new model performs better than the other two alternatives.","Message passing,
Hardware,
Samarium,
Computer science,
Costs,
Switches,
Computational modeling,
Concurrent computing,
Application software,
Processor scheduling"
A parallel execution method for minimizing distributed query response time,"Performance studies show that traditional semi-join processing methods are sometimes inefficient because of the storage and processing overhead. To remedy this problem, a new semi-join processing method, called one-shot semi-join execution is proposed. This method allows parallel generation of all the semi-join projections, parallel transmission of all the semi-join projections, and parallel execution of all the semi-joins. The authors apply this method to optimize the response time for processing distributed queries. A response time model is established, which considers both data transmission time and local processing time. Based on this model, an efficient query processing algorithm is developed and analyzed.","Delay,
Costs,
Query processing,
Computer science,
Optimization methods,
Relational databases,
Data communication,
Database systems,
Marine vehicles,
Councils"
Using visualization tools to understand concurrency,"A visualization tool that provides an aggregate view of execution through a graph of events called the causality graph, which is suitable for systems with hundreds or thousands of processors, coarse-grained parallelism, and for a language that makes communication and synchronization explicit, is discussed. The methods for computing causality graphs and stepping through an execution with causality graphs are described. The properties of the abstraction algorithms and super nodes, the subgraphs in causality graphs, are also discussed.",
Active tactile sensing by robotic fingers based on minimum-external-sensor-realization,"The authors discuss active tactile sensing for detecting a contact point between a multifingered robot hand and an unknown object. They define the concept of actively sensible meaning that an active sensing motion can be planned for a sensing event. Assuming more than two sensing events, conditional-minimum-external-sensor-realization is defined, where it is shown that it is possible to reduce the number of external sensors with a well-planned sensing algorithm. Based on these definitions, an active sensing algorithm for detecting the contact point with minimum-external-sensor-realization is proposed. This approach remedies several disadvantages found in conventional approaches. The approach was tested through experiments using a single-finger model with a fingertip tactile sensor.",
"A document segmentation, classification and recognition system","A discussion is given on a document segmentation, classification and recognition system for automatically reading daily-received office documents that have complex layout structures, such as multiple columns and mixed-mode contents of texts, graphics and half-tone pictures. First, the block segmentation employs a two-step run-length smoothing algorithm for decomposing any document into single-mode blocks. Next, based on clustering rules the block classification classifies each block into one of text, horizontal or vertical lines, graphics, and pictures. The text block is separated into isolated characters using projection profiles, and which are translated into ASCII codes through a font- and size-independent character recognition subsystem. Logo pictures discriminated from half-tone pictures are identified and converted into symbolic words. The experimental results show that the proposed system is capable of correctly reading different styles of mixed-mode printed documents.",
Fundamental data movement algorithms for reconfigurable meshes,A number of data movement algorithms for the two-dimensional reconfigurable mesh are presented. These include computing the prefix sum of a binary sequence and computing the prefix maxima of a sequence of real numbers. These algorithms lead to a fast algorithm to sort a sequence of n reals in O(log n/log m) time on a reconfigurable mesh of size mn*n with 3,"Parallel machines,
Sorting,
Broadcasting,
Concurrent computing,
Very large scale integration,
Arithmetic,
Computer science,
Multiprocessor interconnection networks,
Binary sequences,
Parallel algorithms"
Fuzzy semantics and fuzzy constraint networks,"After reviewing the notion of crisp constraint networks and their relationship to semantics in classical logic, the authors define fuzzy constraint networks and their relationship to fuzzy logic. Then they introduce Khayyam, a fuzzy constrained-based programming language which implements much of Zadeh's PRUF formalism. In Khayyam, any sentence in the first-order fuzzy predicate calculus is a well-formed constrained statement. Finally, using Khayyam to address an equipment selection application, the expressive power of constraint-based languages is illustrated.","Fuzzy logic,
Logic programming,
Computer languages,
Calculus"
A novel approach to integrate computer exercises into teaching of utility-related applications of power electronics,"The author presents a novel approach to integrating computer exercises into the teaching of utility-related applications of power electronics. First, it is argued that the various emerging high-power applications of power electronics should be included in the power engineering curriculum. Based on a survey of available software packages, two royalty-free programs which are best suited for this purpose are compared. By means of a detailed example of a computer exercise, it is shown how the use of computer simulation in homework problems, laboratory exercises, and group projects can make the education of these important topics more effective and exciting for both the students and the instructor.","Power engineering computing,
Application software,
Power electronics,
Power engineering,
Software packages,
Home computing,
Computer simulation,
Laboratories,
Computer science education,
Educational programs"
Tiling a polygon with rectangles,"The authors study the problem of tiling a simple polygon of surface n with rectangles of given types (tiles). They present a linear time algorithm for deciding if a polygon can be tiled with 1 * m and k * 1 tiles (and giving a tiling when it exists), and a quadratic algorithm for the same problem when the tile types are m * k and k * m.",Tiles
Clustering with competing self-organizing maps,"Competing self-organizing maps are used to cluster data. Because maps are more complicated than single stereotypes, this clustering is different from k-means clustering in that the proper number of clusters will be discovered. This discovery process for the number of clusters is studied and compared to k-means clustering. Also, because self-organizing maps are probabilistic algorithms, the frequency of a clustering outcome is used as a measure of the validity of the clustering.","Self organizing feature maps,
Neurons,
Neural networks,
Clustering algorithms,
Iterative algorithms,
Computer science,
Frequency measurement,
Clustering methods,
Convergence,
Hebbian theory"
A performance comparison of the Rete and TREAT algorithms for testing database rule conditions,"The authors present the results of a simulation comparing the performance of the two most widely used production rule condition testing algorithms, Rete and TREAT, in the context of a database rule system. The results show that TREAT almost always outperforms Rete. TREAT requires less storage than Rete, and is less sensitive to optimization decisions than Rete. Based on these results, it is concluded that TREAT is the preferred algorithm for testing join conditions of database rules. Since Rete does outperform TREAT in some cases, this study suggests a next step which would be to develop a hybrid version of Rete and TREAT with an optimizer that would decide which strategy to use based on the rule definition and statistics about the data and update patterns.","System testing,
Production systems,
Design optimization,
Context modeling,
Relational databases,
Statistical analysis,
Process design,
Computer science,
Military computing,
Application software"
Optimal codes for correcting single errors and detecting adjacent errors,"Optimal codes that correct single errors and detect double errors within nibbles of power of two length are presented. For each n, a code of length n with the largest possible dimension which corrects single errors and detects double adjacent errors is presented. The problem of constructing optimal codes which correct single errors and detect double adjacent errors within nibbles of length l is discussed.","Error correction codes,
Parity check codes,
Reflective binary codes,
Space vehicles,
Linear code,
Hydrogen,
Computer science"
Asynchronous unison,Unbounded and bounded designs of asynchronous unison systems are discussed. It is shown that both systems are stabilizing in the sense that their steady state behaviors do not depend on their initial states. The systems can therefore tolerate memory and reconfiguration faults that may yield them in arbitrary states. It is also shown that unison systems are useful in designing multiphase systems.,"Clocks,
Steady-state,
Computer science,
Synchronization,
Fault tolerant systems"
Integrating security in a group oriented distributed system,"A distributed security architecture is proposed for incorporation into group oriented distributed systems, and in particular, into the Isis distributed programming toolkit. The primary goal of the architecture is to make common group-oriented abstractions robust in hostile settings in order to facilitate the construction of high-performance distributed applications that can tolerate both component failure and malicious attacks. These abstractions include process groups and causal group multicast. A delegation and access control scheme is also proposed for use in group-oriented systems. The focus is on the security architecture; particular cryptosystems and key exchange protocols are not emphasized.","Robustness,
Computer science,
Communication system security,
NASA,
Fault tolerance,
Network servers,
Protection,
Computer architecture,
Intersymbol interference,
Access control"
Effects of software changes on module cohesion,"Program slices are used to model module cohesion. For the authors purposes, a slice is a projection of program text that includes only the data tokens relevant to one output. The authors define six cohesion metrics in terms of these slices, and evaluate the effects of classes of module changes on these metrics. They find that the effects on cohesion metrics are notably more predictable when the changes result from adding code rather than from moving code.",
Reliable broadcasting in faulty hypercube computers,"A nonredundant broadcasting algorithm for faulty hypercube computers is proposed. The concept of unsafe nodes is introduced to identify those nonfaulty nodes that will cause a detour or backtracking because of their proximity to faulty nodes. It is assumed that each healthy node, safe or unsafe, knows the status of all the neighboring nodes. The broadcasting is optimal, meaning that a message is sent to each node via a Hamming distance path if the broadcasting is initiated from a safe node. It is also shown that when the source node is unsafe and there is an adjacent safe node, then the broadcasting can be achieved with only one more time step than the fault-free case.","Broadcasting,
Hypercubes,
Fault tolerance,
Casting,
Computer science,
Reliability engineering,
Fault diagnosis,
Hamming distance,
Tree data structures"
Adding a new dimension to the teaching of audience analysis: cultural awareness,The rationale behind teaching native English speakers to be sensitive to the cultural differences they will find when they communicate with nonnative speakers in the classroom and in the professional marketplace is considered. A teaching strategy that technical writing instructors can use in their classrooms to foster cultural awareness is described in detail. It is concluded that such an educational strategy is important for a future in which interaction with multicultural colleagues becomes inevitable and essential for business success.,"Education,
Cultural differences,
Writing,
Power generation economics,
Global communication,
Books,
Natural languages,
Companies,
Business communication,
Communication industry"
Comparing images using the Hausdorff distance under translation,"Efficient algorithms are provided for computing the Hausdorff distance between a binary image and all possible relative positions (translations) of a model, or a portion of that model. The computation is in many ways similar to binary correlation. However, it is more tolerant of perturbations in the locations of points because it measures proximity rather than exact superposition.","Shape measurement,
Computer science,
Q measurement,
Quantum computing,
Pattern recognition,
Pixel,
Scholarships,
Graphics,
Machine vision,
Nearest neighbor searches"
"Performance of a six-legged planetary rover: power, positioning, and autonomous walking","The authors quantify several performance metrics for the Ambler, a six-legged robot configured for autonomous traversal of Mars-like terrain. They present power consumption measures for walking on sandy terrain and for vertical lifts at different velocities. They document the accuracy of a novel dead reckoning approach, and analyze the accuracy. They describe the results of autonomous walking experiments in terms of terrain traversed, walking speed, number of instructions executed and endurance.",
New signal-space orthonormal bases via the metaplectic transform,"The discretization of the metaplectic transform (MT) is considered, and it is shown that it can lead to completely new orthonormal bases (ONBs) for the signal space of square integrable functions. Two new classes of bases, the scale-and-shear bases and the translation-and-shear bases, are derived to demonstrate the discretization process. Besides generalizing the current methods of generating time-frequency-concentrated ONBs, MT bases possess extra degrees of freedom that can be used to match a wider variety of signals.",
Multi-sensor based AUV with distributed vehicle management architecture,"The authors introduce a project to build a multisensor-based autonomous underwater vehicle (AUV) named the Twin-Burger, which is the newest vehicle of the Institute of Industrial Science, the University of Tokyo. The Twin-Burger is being designed as a versatile testbed on which the techniques as represented by software architectures can be implemented and tested. The first in-water experiment is expected in 1992. The distributed vehicle management architecture is proposed as a software architecture for the Twin-Burger. The architecture is being developed to approach the most critical problem in the distributed system, that is, how to manage heterogeneous software modules in a homogeneous structure. Performance of the software developed for this management system will be tested using a multipurpose environment simulator.","Software testing,
Remotely operated vehicles,
Underwater vehicles,
Software architecture,
Computer architecture,
Software development management,
Mobile robots,
Software performance,
Environmental management,
System testing"
A novel approach for subcube allocation in hypercube multiprocessors,"A novel approach for dynamic subcube allocation in hypercube multiprocessors which supports a multiuser environment is proposed. A dynamic binary tree with nodes labeled by a binary reflected gray code is used for processor allocation along with two arrays of free lists. The time complexities for both allocation and deallocation are shown to be linear-orders of magnitude improvement over the existing exponential and even superexponential algorithms. A best-fit strategy, the proposed scheme does not excessively fragment the hypercube, unlike some existing strategies. In addition, static optimality is guaranteed. The performance of the proposed scheme is compared on such parameters as average delay in honouring a request, average allocation time, and average deallocation time against some existing schemes, demonstrating its effectiveness.","Hypercubes,
Reflective binary codes,
Binary trees,
Delay effects,
Prototypes,
Topology,
Operating systems,
Computer science"
On the randomized complexity of volume and diameter,"The authors give an O(n/sup 7/log/sup 2/n) randomised algorithm to approximate the volume of a convex body, and an O(n/sup 6/log n) algorithm to sample a point from the uniform distribution over a convex body. For convex polytopes the algorithm runs in O(n/sup 7/log/sup 4/n) steps. Several tools are developed that may be interesting on their own. They extend results of Sinclair-Jerrum (1988) and the authors (1990) on the mixing rate of Markov chains from finite to arbitrary Markov chains. They describe an algorithm to integrate a function with respect to the stationary distribution of a general Markov chain. They also analyze the mixing rate of various random walks on convex bodies, in particular the random walk with steps from the uniform distribution over a unit ball. In several previous positive and negative results, the problem of computing the diameter of a convex body behaved similarly as the volume problem. In contrast to this, they show that there is no polynomial randomized algorithm to compute the diameter within a factor of n/sup 1/4/.","Polynomials,
Algorithm design and analysis,
Random variables,
Microwave integrated circuits,
Approximation algorithms"
Review and Unification of Reduced Order Force Control Methods,"In this paper, we compare some of the recent methods developed for simultaneous position and force control of a single a-link constrained robot manipulator. Mathematical models of the constrained manipulator are introduced and the advantages and disadvantages of the associated control formulations are discussed. The similarities between each of the proposed formulations are also highlighted. Finally, a transformation is presented which generalizes the methods of decompling force from the position dynamics.","Force control,
Robot kinematics,
Tellurium,
Integrated circuit modeling,
Orbital robotics,
Stability,
Tracking loops,
Feedback,
Gravity,
Friction"
A complete parametrization of 2D nonseparable orthonormal wavelets,The problem of constructing compactly supported orthonormal multidimensional (k-D) nonseparable wavelets is considered. A complete solution to the problem of parametrizing all possible two-dimensional (2-D) wavelets having arbitrary degree of regularity is given. These results can be seen as a generalization of the Daubechies (1988) wavelets in two dimensions and go beyond those specific examples constructed by other workers in the field. Previous work on the multidimensional version of the problem does not provide a complete parametrization useful for generating all wavelets of interest.,"Finite impulse response filter,
Wavelet analysis,
Multiresolution analysis,
Polynomials,
Reflection,
Equations,
Multidimensional systems,
Transfer functions,
Computer science,
Circuits"
Type-specific coherence protocols for distributed shared memory,The concept of a structured distributed shared memory in which memory units are objects is introduced. The coherence of object replicas is maintained by type-specific coherence protocols that are based on the semantics of operations on objects. The aim is to reduce message traffic and operation latency in many common situations. The protocols subsume traditional distributed shared memory protocols based on the read/write model.,
A continuous media communication service and its implementation,"Continuous media (CM) traffic often requires more network throughput and more stringent delay bounds than conventional discrete media traffic. At the same time, transmission requirements of CM traffic can usually be estimated more accurately, both in terms of the resources required for transmission and the time at which the next transmission request will occur. A data transport service that uses these considerations to provide a richer and more efficient service to CM traffic than message-based transport services is discussed, and a prototype implementation is described. The service is evaluated via simulation experiments, which indicate that this service can often utilize network resources more efficiently for the transmission of CM traffic than message-based services.","Telecommunication traffic,
Computer science,
Traffic control,
Computer displays,
Timing,
Prototypes,
Message service,
Computer networks,
Workstations,
Data communication"
Route Planning For Mobile Robots Amidst Moving Obstacles,,"Mobile robots,
Orbital robotics,
Motion planning,
Roads,
Information science,
Art,
Path planning,
Algorithm design and analysis,
Space stations,
Topology"
Parsing graphs representing two dimensional figures,"Generalized two dimensional context free grammars an extension of context free grammars to two dimensions, is described. This extension is a generalization of Tomita's two dimensional context free grammars (M. Tomita, 1989), and better fits into the families of graph grammars described by Crimi (1990) Relation Grammars and by Flasinski (1988) edNLC Grammars, Figure Grammars are particularly useful for applications such as handwritten mathematical expressions. A two dimensional extension of the Cocke-Kasami-Younger parser for context-free languages is used to parse figures using these grammars.","Production,
Computer science,
Multidimensional systems,
Mars,
Terminology"
On performance measurements of TCP/IP and its device driver,"A performance measurement of the processing overhead of TCP/IP on personal computers interconnected by Ethernet is given. In this measurement of the processing overhead comes from TCP and the Ethernet device driver. For TCP, a large portion of the overhead comes from the checksum computation. Almost all overhead of the lower layer comes from moving data from the main memory to the Ethernet card. Hence, if the bus speed can be increased and the TCP checksum can be performed by hardware, the processing overhead generated from TCP/IP and lower layers can be greatly reduced. The results presented shed light on designing communication protocols on personal computers.","TCPIP,
Protocols,
Microcomputers,
Ethernet networks,
Computer networks,
Hardware,
Performance evaluation,
Mathematical model,
Personal communication networks,
Computer science"
Real-time Descartes: a real-time specification language,"Real-time Descartes is a formal language for specifying real-time software, which is an extension of the executable Descartes specification language. Many formal specification techniques have been proposed to conceptualize real-world semantics of the inherently complex nature of real-time systems. Descartes as one of the specification languages based on the functional model has the advantages of easy constructibility and comprehensibility. Real-time Descartes makes effective use of the advantages of the finite state machine (FSM) model, the assertional model, and the process model while overcoming the disadvantages of the functional model. Easy constructibility and comprehensibility of Real-time Descartes will lessen the burden from software developers and reduce the understanding gap among participants.","Specification languages,
Switches,
Upper bound,
Computer science,
Formal languages,
Formal specifications,
Real time systems,
Automata,
Tree data structures,
Shape"
Lower bounds on the competitive ratio for mobile user tracking and distributed job scheduling,"The authors prove a lower bound of Omega (log n/log log n) on the competitive ratio of any (deterministic or randomised) distributed algorithm for solving the mobile user problem on certain networks of n processors. The lower bound holds for various networks, including the hypercube, any network with sufficiently large girth, and any highly expanding graph. A similar Omega (log n/log log n) lower bound is proved for the competitive ratio of the maximum job delay of any distributed algorithm for solving a distributed scheduling problem on any of these networks. The proofs combine combinatorial techniques with tools from linear algebra and harmonic analysis and apply, in particular, a generalization of the vertex isoperimetric problem on the hypercube, which may be of independent interest.","Distributed algorithms,
Hypercubes,
Processor scheduling,
Mathematics,
Computer science,
Communication networks,
Gas insulated transmission lines,
Linear algebra,
Harmonic analysis,
Distributed computing"
"Problem domain, structural and logical abstractions in reverse engineering","Reverse engineering abstractions are considered. Three kinds of abstractions are identified: problem domain, structural, and logical. Problem domain abstractions correspond to concepts from a program's application area. Structural abstractions are used to eliminate implementation details and redundant information. Logical abstractions are properties that can be logically derived from code. A method for generating functional specifications is described, which incorporates the abstraction techniques. It has been applied to a variety of COBOL programs and been found to generate natural abstract program descriptions. The authors describe work in progress, including the construction of an analysis tool that will be used to help verify the approach and to assess its complexity and computational requirements.","Reverse engineering,
Software engineering,
Laboratories,
Computer science,
Application software,
Information analysis,
Terminology,
Programming profession,
Specification languages,
Data mining"
Two new techniques for compiled multi-delay simulation,"Two techniques for compiled multidelay simulation are presented. One is event-driven and the other is based on the concept of levelized compiled simulation. Experimental results are presented which show a significant performance improvement for compiled event-driven simulation over interpreted event-driven simulation, although this improvement is somewhat less than would normally be expected. An analysis of both the compiled and interpretive simulators that supports the experimental data is presented. The effects of caching and locality of reference are presented for the compiled event-driven simulator. The performance enhancements for the non-event-driven technique are substantial, but this technique has the disadvantage of generating an enormous amount of code for some circuits. Suggestions for future research are also presented.","Discrete event simulation,
Circuit simulation,
Computational modeling,
Delay,
Computer simulation,
Computer science,
Analytical models,
Timing,
Logic,
Microelectronics"
The science of making ERORS: what error tolerance implies for capacity in neural networks,"Discusses the development of formal protocols for handling error tolerance which allow a precise determination of the computational gains that may be expected. The error protocols are illustrated in the framework of a densely interconnected neural network architecture (with associative memory the putative application), and rigorous calculations of capacity ar shown. Explicit capacities are also derived for the case of feedforward neural network configurations.","Intelligent networks,
Neural networks,
Neurons,
Associative memory,
Computer networks,
Recurrent neural networks,
Protocols,
Military computing,
Computer architecture,
Memory architecture"
Information technology and the new organization,"How can one understand the diverse changes that information technology can cause in organizations? The authors argue that many of these changes can be explained in terms of three orders of effects of decreasing costs for any technology: substitution of the new technology for the old, increased demand for the function the technology provides, and the evolution of new technology-intensive structures. This framework is used to organize many familiar examples of information technology effects, and to predict the continued evolution of new organizations. For instance, the argument suggests the increasing importance of 'buying' rather than 'making' and of organizational 'adhocracies' rather than traditional hierarchies. Strategic implications of these changes are noted, and speculative predictions about more radical organizational structures are also included.","Information technology,
Computer networks,
Computer industry,
Transportation,
Cost function,
Insurance,
Production facilities,
Steam engines,
Economies of scale,
Communication networks"
Assembling polyhedra with single translations,"The problem of partitioning an assembly of polyhedral objects into two subassemblies that can be separated arises in assembly planning. The authors describe an algorithm to compute the set of all translations separating two polyhedra with n vertices in O(n/sup 4/) steps and show that this is optimal. Given an assembly of k polyhedra with a total of n vertices, an extension of this algorithm identifies a valid translation and removable subassembly in O(k/sup 2/n/sup 4/) steps if one exists. Based on the second algorithm, a polynomial time method for finding a complete assembly sequence consisting of single translations is derived. An implementation incorporates several changes to achieve better average-case performances. Experimental results obtained for composite objects consisting of isothetic polyhedra are described.","Robotic assembly,
Polynomials,
Manufacturing,
Laboratories,
Computer science,
Partitioning algorithms,
Costs"
Route Planning And Navigation System For An Autonomous Land Vehicle,,
Design of piecewise-linear Markov maps generating white chaos: an inverse problem of dynamical systems,"Discusses the design of a discrete dynamical system generating chaos with a white spectrum. This chaos is referred to as white chaos. The results on the design of a piecewise-linear Markov map generating white chaos are summarized. For any number of subintervals of maps, maps always exist if the rank of the incident matrix is equal to 1. However, no piecewise linear Markov map whose incident matrix's rank is equal to 1 can generate white chaos whose higher-order power spectra are also uniform. (2) The following conjecture is obtained. The number of subintervals of maps is not less than two times as many as the rank of the incident matrix. Several concrete examples are included.","Piecewise linear techniques,
Chaos,
Inverse problems,
Chaotic communication,
Extraterrestrial measurements,
Design engineering,
Statistics,
Power measurement,
Density measurement,
Computer science"
Restrictions of P-fuzzy switching functions,A P-fuzzy switching function is a meaningful class of fuzzy switching functions that is representable by a logic formula consisting of prime implicants. A restriction of a P-fuzzy switching function is a mapping of the restricted domain within a finite subset of,"Fuzzy logic,
Humans,
Sufficient conditions"
"Fault-tolerant embeddings of rings, meshes, and tori in hypercubes","The authors study the ability of the hypercube to implement algorithms with ring, mesh, and torus communication patterns when the hypercube contains faults. The primary result is a fault-free embedding of the longest possible ring into an n-cube with at most (n-h(n)) even faulty nodes and (n-h(n)) odd faulty nodes, where h(n) is a function such that h(n)=O( square root n log n). Given the above bounds on the parities of the faults, the result obtained improved upon previous results both in the number of faults that are tolerated and in the length of the ring that is embedded. In addition, the result leads to improved bounds for fault-free embeddings of meshes and tori into faulty hypercubes.","Fault tolerance,
Hypercubes,
Concurrent computing,
Embedded computing,
Image processing,
Binary trees,
Poles and towers,
Computer science,
Parallel algorithms"
Communicating with virtual paths and virtual channels (ATM networks),"The authors give several examples of virtual path and virtual channel use for different types of communication, and then compare the two mechanisms. For most types of communication, both virtual path and virtual channel connections are more-or-less equally capable. However, for relatively high bandwidth communication involving more than five to ten participants, virtual path connections can more efficiently support some interconnection patterns. In general, the authors believe that both connection types are desirable and both should be extended to the client by network providers.","Asynchronous transfer mode,
Virtual colonoscopy,
Transmitters,
Routing,
Laboratories,
Computer science,
Bandwidth,
Multimedia communication,
Broadcasting,
Monitoring"
On the second eigenvalue and linear expansion of regular graphs,"The authors investigate the relation between the second eigen-value and the linear expansion of regular graphs. The spectral method is the best currently known technique to prove lower bounds on the expansion. He improves this technique by showing that the expansion coefficient of linear-sized subsets of a k-regular graph G is at least k/2(1- square root max(0,1-/sub lambda 1(G)2//sup 4k-4/))/sup -/ , where lambda /sub 1/(G) is the second largest eigenvalue of the graph. In particular, the linear expansion of Ramanujan graphs, which have the property that the second largest eigenvalue is at most 2 square root k-1, is at least (k/2)/sup -/. This improves upon the best previously known lower bound of 3(k-2)/8. For any integer k such that k-1 is prime, he explicitly constructs an infinite family of k-regular graphs G/sub n/ on n vertices whose linear expansion is k/2 and such that lambda /sub 1/(G/sub n/)","Eigenvalues and eigenfunctions,
Graph theory,
Contracts,
Laboratories,
Computer science,
Concurrent computing,
Complexity theory,
Sorting,
Circuits,
Polynomials"
A supplementary compensator for reliable stabilization with passive redundancy,"A problem of reliable stabilization with passive redundancy is considered. An interconnection-type supplementary compensator is presented which corresponds to a new type of resulting total control system. The reliable stabilizability due to it is equivalent to the strong stabilizability of C/sub 1/, which is indispensable in this new problem. Moreover, if C/sub 1/ is strongly stabilizable, there exists an interconnection-type supplementary compensator which solves the reliable control problem, i.e., it can simultaneously achieve both reliable stability with passive redundancy and the resulting total compensator with an arbitrary transfer function.","Redundancy,
Control systems,
Stability,
Transfer functions"
HABSI: an expert system to reconstruct crime scene based on bloodstain interpretations,"The authors present a new way to reconstruct a crime scene by using modern technology. They select bloodstain evidence which is based on Mark theory as the approach. Mark theory relates to the gathering, analyzing, and inferencing of physical evidence. The crime scene is reconstructed using the expert system HABSI, which uses a heuristic approach to bloodstain interpretation. EXSYS was used as an expert system shell to develop the system. The knowledge and the rule base are described. The goal was to represent the concept and implementation of fuzzy set theory to aid in the problem of reconstructing the crime scene. The prototype meets the initial requirements. Iterative refinements of the knowledge base through knowledge acquisition, knowledge representation, knowledge programming, and knowledge testing were conducted until user expectations were met.","Expert systems,
Layout,
Blood,
Couplings,
Fuzzy logic,
Modems,
Humans,
Information management,
Computer science,
Joining processes"
An application of qualitative risk analysis to computer security for the commercial sector,"Computer security is emerging as the business risk of the 1990s for many organizations operating in the commercial sector. Unlike military, government, defense and financial organizations, the mid- to low-risk commercial sector does not have well-developed security procedures. However, owing to the very different security needs of the commercial sector, it is inappropriate to apply the procedures used by high-risk organizations. The characteristic system security concerns of the commercial sector, are identified, some solutions are suggested, and a structured and systematic approach to security assessment in the form of a qualitative approach to security risk analysis is investigated.","Application software,
Risk analysis,
Computer security,
Business,
Military computing,
Computer science,
Government,
Data security,
Computer crime,
Defense industry"
Charles Babbage as an algorithmic thinker,"While the career of the Charles Babbage (1791-1871) shows a remarkable range of interests, strong threads bind together several of the principal ones: algorithmic thinking, with intimate links to algebra and to semiotics. The links connect especially his mathematical researches in functional equations with his work on mathematical tables and on calculating machines, but they are evident also in some of his social and industrial concerns. Evidence is presented to show that Babbage was consciously aware of at least some of these links. Attention to them casts light upon his achievements.","Mathematics,
Algebra,
Equations,
Neural networks,
Electronic switching systems,
Engineering profession,
History,
Algorithm design and analysis,
Humans"
A computational analysis of Girard's translation and LC,"J.-Y. Girard's (1992) new translation from classical to constructive logic is explained. A compatible continuation-passing-style (CPS) translation is given and converted to a C-rewriting machine evaluator for control-operator programs and a set of reduction/computation rules sufficient to represent the evaluator. It is found necessary to add one reduction rule to M. Felleisen's (Ph.D. thesis, Indiana Univ., 1987) calculus (evaluation under lambda -abstraction). This reduction rule arises from a modified call-by-name CPS-translation. Turning to Girard's new classical logic LC, an intuitionistic term-extraction procedure is provided for it, producing CPS functional programs. Using the syntactic properties of this language, it is possible to give simple proofs for the evidence properties of LC. This work sheds light on the design space of CPS-translations and extends the relation between control-operator languages and classical logic.","Calculus,
Logic programming,
Logic design,
Concrete,
Lighting control,
Equations,
Control systems"
Education for sustainability: a report card on engineering,"The results of a study undertaken to determine how much engineering students learn about the way technology influences human life, society, and nature and to what extent the knowledge is used to adjust engineering methods and approaches to achieve a greater compatibility with these contexts are presented. The results suggest that the next generation of engineers is not in a good position to make a significant contribution to the development of a more sustainable way of life by substantially reducing negative impacts. The implementation of a technology policy and research strategy designed to explore the possibilities of preventive engineering that could lead to healthier social and natural ecologies, a stronger economy, more jobs, and a more sustainable way of life is discussed, and examples of such implementations are presented.","Humans,
Engineering profession,
Environmental factors,
Costs,
Productivity,
Societies,
Councils,
Ecosystems,
Knowledge engineering,
Laboratories"
Techniques for reducing hardware requirement of self checking combinational circuits,"The authors present two methods that can be used to reduce the hardware requirement for a self checking implementation of a given combinational function. They give examples to show that these give very significant reduction over the traditional SFS implementation. They believe that by careful use of such optimizations, the size of self checking implementations can be brought down within acceptable limits for use in practice.","Hardware,
Combinational circuits,
Cost function,
Design methodology,
Circuit faults,
Computer science,
Design optimization,
Sequential circuits,
Control systems,
Integrated circuit interconnections"
HALO: an efficient global placement strategy for standard cells,"A standard cell placement procedure that is based on an efficient global placement strategy, called HALO (hierarchical alternating liner ordering), is proposed. This method generates a global 2D placement of circuit modules by hierarchical application of linear ordering in an alternating direction. The HALO global placement procedure is followed by a detailed placement procedure which consists of row assignment, feed-through cell assignment and intrarow cell assignment steps. Experimental results on two benchmark circuits, primary1 and primary2, consisting of 752 and 2907 cells, have shown decreases of the half-perimeter routing lengths by 7% and 24%, respectively, compared with the best available results obtained so far. Total CPU time, including the subsequent detailed placement, was less than half that of previously published work.",
Learning 3D-shape perception with local linear maps,The authors consider the task of learning to extract 3D shape information about complex objects from monocular gray level pixel images. It is shown that this task can be efficiently solved by a network architecture of local linear maps. Very little preprocessing is necessary. No prior identification of salient object features or their image coordinates is required. The approach was demonstrated by training a network to identify the posture of a simulated robot hand with 10 joints from its image. Results are presented that show how the achieved accuracy depended on network size and the number of available training examples. Experiments are also reported on combining several networks. The robustness of the recognition process is discussed.,"Data mining,
Robot kinematics,
Vectors,
Pixel,
Artificial neural networks,
Information science,
Robustness,
Lighting,
Computational geometry,
Information geometry"
Testing for linear errors in nonlinear computer programs,"This paper provides an approach to test nonlinear functions in computer programs, whether this function is used for control flow, such as a predicate inequality or equality constraint, or is given as an input-output relationship. This approach will obtain test data to detect linear errors in the given nonlinear function. An error-space criterion previously given by Zeil will be utilized, and a necessary and sufficient condition for the test data will be specified to guarantee the satisfaction of this criterion. This leads to a simple and efficient method to select test data which satisfies that condition; only (n+2) tests are required, where n is the number of input variables. An analysis will be given to show that this simple approach can be very effective in detecting nonlinear errors as well.","Computer errors,
Software testing,
Sufficient conditions,
Computer science,
Input variables,
Machinery,
Cost function"
SPMD execution of programs with dynamic data structures on distributed memory machines,"A combination of language features and compilation techniques that permits SPMD (single-program multiple-data) execution of programs with pointer-based dynamic data structures is presented. The Distributed Dynamic Pascal (DDP) language, which supports the construction and manipulation of local as well as distributed data structures, is described. The compiler techniques developed translate a sequential DDP program for SPMD execution in which all processors are provided with the same program but each processor executes only that part of the program which operates on the elements of the distributed data structures local to the processor. Therefore, the parallelism implicit in a sequential program is exploited. An approach for implementing pointers that is based on the generation of names for the nodes in a dynamic data structure is presented. The name-based strategy makes possible the dynamic distribution of data structures among the processors as well as the traversal of distributed data structures without interprocessor communication.","Data structures,
Program processors,
Parallel processing,
Computer science,
Memory architecture,
Costs,
Programming profession,
Software performance,
Application software,
Runtime"
A mildly exponential approximation algorithm for the permanent,"An approximation algorithm for the permanent of an n*n 0,1-matrix is presented. The algorithm is shown to have worst-case time complexity exp (0(n/sup 1/2/ log/sup 2/ n)). Asymptotically, this represents a considerable improvement over the best existing algorithm, which has worst-case time complexity of the form e/sup theta (n)/.","Approximation algorithms,
Computer science,
Bipartite graph,
Mathematics,
NP-hard problem,
Turing machines,
Polynomials,
Random variables,
Monte Carlo methods"
Image data compression using counterpropagation network,"The counterpropagation network functions as a statistically optimal self-adapting look-up table. When using this network for image data compression the Kohonen network generates a series of vector class indices with the input of subimages that come from the orthogonally divided pictorial image. These indices along with the weight vectors of the outstar network which has learned the vectors associated with the classes can be stored for reconstruction of the original image. The learning of intermediate forms of vector classes, the compression process, and the results, such as the compression ratios and the distortion ratios with respect to the target data, the compression unit, and the restored image, are discussed.","Data compression,
Image coding,
Vector quantization,
Artificial neural networks,
Organizing,
Computer science,
Electronic mail,
Transfer functions,
Table lookup,
Image reconstruction"
An Integrated Method for Planning Smooth Collision-Free Trajectories for Robot Arms,,"Trajectory,
Manipulators,
Orbital robotics,
Path planning,
Motion planning,
Robot motion,
Robot sensing systems,
Kinematics,
Switches,
Cost function"
COSY data acquisition system for physical experiments,"A three-level data processing and acquisition system is being developed. Signals from various detector arrangements are digitized and preprocessed by CAMAC, FASTBUS, and VME modules. A multiprocessor system based on VMEbus is used for event building, data recording, and buffered data transfer to the host computer. All crates are connected by parallel VICbus. For this, an intelligent CAMAC rate controller with VICbus is under development. Microcomputer-based VME modules are equipped with CPUs of the 680X0 family, working under the OS-9 real-time operating system. The data acquisition system is mainly based on commercially available modules.",
Memory architecture support for the SIMD construction of a Gaussian pyramid,"A memory system is introduced for the efficient construction of a Gaussian pyramid. The memory system consists of an address calculating circuit, an address routing circuit, a data routing circuit, a memory module selection circuit, and 2/sup n/+1 memory modules. The memory system provides parallel access to 2/sup n/ image points whose patterns are a block, a row, or a column, where the interval of the block or column is one and the interval of the row is one or two. The performance of a generic SIMD (single-instruction multiple-data) processor using the proposed memory system is compared with that of one using an interleaved memory system for the recursive construction of a Gaussian pyramid.","Memory architecture,
Circuits,
Routing,
Low pass filters,
Motion analysis,
Image motion analysis,
Image texture analysis,
Image edge detection,
Computer science,
Computer science education"
A Continuous Approach To Robot Motion Planning With Many Degrees Of Freedom,,"Robot motion,
Motion planning,
Manipulators,
Path planning,
Shape,
Arm,
Technology planning,
Computer science,
Artificial intelligence,
NASA"
Architecture and performance of the DELPHI trigger system,"The authors describe in detail the basic concepts of the design, the composition of the data flow, and the tools developed to monitor the trigger in real time. The results of the trigger performance in terms of efficiencies achieved during the first two and a half years of operation in the LEP (Large Electron Positron Collider) machine are also shown. So far, a total of approximately 10/sup 6/ hadronic Z/sup 0/s have been collected from 21 million recorded events. The DELPHI trigger system provides an efficiency nearly 100% over the covered solid angle for all particles and physical channels. The system has also proved to be stable despite very different beam conditions. This is a consequence of the high redundancy provided by the different detectors for all e/sup +/e/sup -/ final state processes, which also ensures a method for calculating the absolute trigger efficiencies using data only.",
PISCES: a tool for predicting software testability,"Before a program can fail, a software fault must be executed, that execution must alter the data state, and the incorrect data state must propagate to state that results directly in an incorrect output. This paper describes a tool called PISCES (developed by Reliable Software Technologies Corporation) for predicting the probability that faults in a particular program location will accomplish all three of these steps causing program failure. PISCES is a tool that is used during software verification and validation to predict a program's testability.","Software tools,
Software testing,
Genetic mutations,
Instruments,
State estimation,
Computer science,
Educational institutions,
Yield estimation"
Iterative TIN generation from digital evaluation models,"A technique for producing a triangulated irregular network (TIN) from a digital elevation model (DEM) is described. The overall goal is to produce an approximate terrain description that preserves the major topographic features using a greatly reduced set of points selected from the original DEM. The TIN generation process is iterative; at each iteration, areas in the DEM that lie outside of a user-supplied error tolerance in the TIN are identified, and points are chosen from the DEM to more accurately model these areas. Point selection involves the computation of the difference between the actual DEM and an approximate DEM. This approximate DEM is calculated by interpolating elevation points from the TIN.","Tin,
Digital elevation models,
Surface topography,
Contracts,
Terrain mapping,
Laboratories,
Computer science,
Interpolation,
Aerospace electronics,
Research and development"
Central repository data models for cleanroom systems development,An integrated cleanroom systems engineering environment must have at its foundation an effective central repository. The authors describe the cleanroom systems development process (CSDP) and discuss the necessary development information to be stored in the repository. Detailed data models for box structure requirements and design information are presented. They then discuss the use of the central repository in the cleanroom development process with supporting CASE tools. The paper concludes with future research directions for a improved cleanroom repository.,"Data models,
Computer aided software engineering,
Systems engineering and theory,
Software systems,
Automatic control,
Information systems,
Educational institutions,
Environmental management,
Computer architecture,
Hardware"
Outsourcing assistance with computer system selection: a success factors model,"The outsourcing of IS expertise to supplement in-house resources is a widespread and growing practice This paper describes the empirical investigation of characteristics of clients and external consultants, and of their interactions, which influence consultant engagement success when selecting a computer system. The study model is tested through (1) a pilot case study, (2) cross-case analysis of five firms and (3) a survey of clients and consultants involved in 49 computerization projects. Path analysis suggests (1) clients and consultants have similar influence on the level of client involvement, (2) the relationship between the client and the consultant is the key to success, and (3) while no direct effect of involvement on success is identified, the indirect effect of involvement through relations is large.","Outsourcing,
Information systems,
Predictive models,
Computer science,
Testing,
Hydrogen,
Quality assurance,
Feedback,
Costs"
Inference of letter-phoneme correspondences by delimiting and dynamic time warping techniques,"An algorithm for inferring correspondences between letters and phonemes from a large set of word spellings and their associated phonemic forms is described. The algorithm uses two techniques to infer correspondences: delimiting and dynamic time warping (DTW). The first technique delimits the part of the word spelling and pronunciation that cannot be aligned with the existing set of correspondences. The second technique derives correspondences from the delimited part of that word. The inferred correspondences are evaluated in terms of translation performance tested with unseen words, proper names and novel words. The translation performance is compared with those obtained using the manually driven correspondences as the benchmark. Nonparametric statistical tests are used to establish whether the performances of inferred correspondences are significantly different from the manually derived correspondences.","Inference algorithms,
Computer science,
Benchmark testing,
Performance evaluation,
Speech,
Dictionaries,
Computational efficiency,
Euclidean distance"
Coding for compression in full-text retrieval systems,"Witten, Bell and Nevill (see ibid., p.23, 1991) have described compression models for use in full-text retrieval systems. The authors discuss other coding methods for use with the same models, and give results that show their scheme yielding virtually identical compression, and decoding more than forty times faster. One of the main features of their implementation is the complete absence of arithmetic coding; this, in part, is the reason for the high speed. The implementation is also particularly suited to slow devices such as CD-ROM, in that the answering of a query requires one disk access for each term in the query and one disk access for each answer. All words and numbers are indexed, and there are no stop words. They have built two compressed databases.","Databases,
Arithmetic,
Indexing,
Information retrieval,
Computer science,
Decoding,
Law,
Legal factors,
Huffman coding,
CD-ROMs"
Asymmetric Parallel Boltzmann Machines are Belief Networks,,
An Effective Timing-Driven Placement Algorithm For Macro Cells,,"Timing,
Delay estimation,
Integrated circuit interconnections,
Routing,
Delay effects,
Circuit optimization,
Wire,
Very large scale integration,
Clocks,
Computer science"
A characterization framework for visual languages,"The general goal of this research is to facilitate the development of visual language environments for the class of visual languages that are based on graph models. The approach the authors take relies on a conceptual framework to define general model components and behaviors; any particular language is defined by selecting and enhancing components and behaviors within the framework. The objective is to provide a system, based on the conceptual framework, in which the language designer defines a data model in conjunction with a distinct, but related, representation of the model. The language specific modules of the resulting visual language system are generated from the specification. These language modules can be viewed as system independent abstract data types which are placed into a fixed system environment. This work enables the visual language developer to easily experiment with different aspects of a visual language. It also provides a basis for the development of, and experimentation with, mechanisms used to support the use of complex visual languages and their environments. The authors address the issue of usability and language complexity by providing support for the development of mechanisms such as visual abstraction hierarchies, multiple views, multiple windows, language component filtering, etc.",
On robust Schur property of discrete-time polynomials,"Markov-like parameters have been defined for a discrete-time polynomial recently and a new method of Schur stability analysis of such polynomials has been established in the space of such parameters. These results are generalized for the Schur invariance property, and the maximum allowable variation in the associated parameters is obtained via evaluating some corner points. The result presented gives a quick qualitative measure of stability robustness of discrete-time polynomials.","Robustness,
Polynomials,
Robust stability,
Stability analysis,
Stability criteria,
Symmetric matrices,
Testing,
Computer science,
Automatic control,
Tellurium"
Distribution + persistence = global virtual memory,"The Distributed Systems Group at the University of New South Wales is constructing a distributed operating system based on global virtual memory (GVM). The system combines local and remote storage into a single large virtual address space. This provides a uniform method for naming and accessing objects regardless of their location, removes the distinction between persistent and transient data, and simplifies the migration of data and processes. The GVM system uses conventional computing nodes connected to specialised network interfaces. A fault-tolerant migration and replication protocol keeps the system operational and consistent in case of network errors or node crashes. Password capabilities are used to control access to the GVM.","Protection,
Hardware,
Access protocols,
Operating systems,
Broadcasting,
Computer science,
Australia,
Computer interfaces,
Computer networks,
Network interfaces"
Fault Detection In Intelligent Material,,"Fault detection,
Materials handling,
Manufacturing automation,
Production facilities,
Costs,
Computer aided manufacturing,
Computer integrated manufacturing,
Intelligent sensors,
Real time systems,
Manufacturing processes"
Distributed consensus in semi-synchronous systems,"The Distributed consensus problem assumes that all processors in the system have some initial values; the goal is to make all non-faulty processors agree on one of these values. This paper investigates the time needed to reach consensus in a partially synchronous model with omission failures. In this model, the processors have no direct knowledge about time, but the time between consecutive steps of each processor is always between two known constants c/sub 1/ and c/sub 2/; the ratio C=/sup c2///sub c1/ measures the timing uncertainty in the system. Moreover, messages are delivered within time d. This paper provides an improved protocol for the above problem. When the majority of the processors are fault-free, the protocol achieves consensus in time 3( phi +1)d+Cd, where phi is the actual number of faults in a specific execution of the protocol. This allows an increase in efficiency up to 25% over the existing protocol which requires time 4( phi +1)d+Cd.","Protocols,
Timing,
Clocks,
Measurement uncertainty,
Computer science,
Time measurement,
Real time systems,
Computer crashes,
Delay"
The morphological structure of images,"The authors investigate the use of mathematical morphology to construct scale-spaces. These scale-spaces are based on differential equations, which are solved by morphological operators, describing the evolution of images in scale-space.","Gaussian processes,
Convolution,
Morphology,
Differential equations,
Laplace equations,
Mathematics,
Computer science,
Smoothing methods,
Kernel,
Computer vision"
Output Tracking Control of Nonlinear Systems with Weakly Non-minimum Phase,"This paper is concerned with the problem of designing a robust output tracking controller for MIMO nonlinear systems with weakly non-minimum phase. Based on our system formulation, control plants with uncertainties and/or with actuator dynamics fall into the class under consideration. Under some mild assumptions, it is shown that the overall states and the tracking errors are uniformly bounded. Furthermore, the tracking errors converge to a small residual set.","Nonlinear control systems,
Control systems,
Nonlinear systems,
Uncertainty,
Robust control,
Nonlinear dynamical systems,
State feedback,
Linear feedback control systems,
Aircraft,
Actuators"
On the distributed subcube-allocation strategies in the hypercube multiprocessor systems,"The authors propose a novel system framework for the design of distributed job-scheduling and subcube-allocation strategies in hypercube multiprocessor/multicomputer systems. A generalized-lattice ordering scheme is proposed for processors. An elegant system information structure, the subcube identification table (SIT), is proposed for efficient distribution, retrieval, and update of free-subcube information. Locations of free subcubes can be determined by any node through direct lookup of its SIT. A novel interprocessor communication mechanism called the sync-broadcast is presented for SIT update/construction, and for resolving contention between subcube-requests for consistent allocation/deallocation of subcubes. Different job scheduling schemes can be easily implemented based on the proposed scheme.","Hypercubes,
Multiprocessing systems,
Processor scheduling,
Application software,
Computer science,
Information retrieval,
Computer architecture,
Concurrent computing,
Computational modeling,
System performance"
A proposal of fault-checking fuzzy control,The effects of faults in fuzzy control systems are examined and are shown not to be negligible. A fault-detecting method that increases the fault tolerance characteristics of fuzzy control systems is proposed. Simulation results show the validity of the proposed fault-checking method for all kinds of faults considered.,"Proposals,
Fuzzy control,
Fault detection,
Control systems,
Fuzzy systems,
Niobium,
Zirconium,
Indium tin oxide,
Computer science,
Fault tolerant systems"
The reuse of software design and software architecture,"In this paper, a method is presented for the reuse of software designs and software architectures. A software design refers to the abstractions and mechanisms that provide the behavior a system or a component requires. A software architecture refers to the organizational structure of a software system or a component. According to this method, a software design can be represented in terms of extended data-flow graphs (EDFGs) and formal specifications. The graphs and the specifications can be organized into a hierarchical structure, representing different levels of abstraction. Such a structure can be easily understood, modified, reconstructed, aiming at varieties of design targets.","Software design,
Software architecture,
Software systems,
Formal specifications"
Semantic issues in the design of languages for debugging,"Some of the inherently difficult issues that will be faced by a designer of any imperative debugging language are surveyed. A powerful debugging language called GDL (General-purpose Debugging Language) is outlined, the particular set of mechanisms included in GDL is justified, and the issue of minimality of this set is addressed. The focus is especially on the semantic issues that arise when the language's mechanisms are combined, in short, the issue of being well-integrated. It is noted that GDL's mechanisms are well-integrated, but some mechanisms are rather inefficient for many debugging applications. However, in expanding GDL's mechanisms for such applications, new semantic problems arise. It is shown how these semantic problems can be avoided by following certain coding conventions.","Debugging,
Hardware,
Computer science,
Handicapped aids,
Natural languages,
Vehicles,
Packaging,
Virtual machining"
A signed hypergraph model of constrained via minimization,"The author proposes a use of the notion of hypergraphs to describe the general constrained via minimization (CVM) problem. He shows that the formulation of the general CVM by means of hypergraphs turns out to be surprisingly simple and general. In the case of two-layer routing, a signed hypergraph model is introduced. On the basis of this model, the author develops a fast (linear-time) heuristic and obtains promising results; he also presents two methods of modeling multiway splits by graphs, producing better results than all the previous methods.","Minimization,
Routing,
Wire,
Integrated circuit layout,
Very large scale integration,
Computer science,
Printed circuits,
Multichip modules,
Pins,
Circuit synthesis"
An optimization algorithm for determining the compatibility coefficients of relaxation labeling processes,"The problem of determining compatibility coefficients for relaxation labeling processes has received considerable attention and a number of different methods have been suggested. The authors propose a method developed within an optimization framework. After formulating the problem of determining the coefficients as a nonlinear programming problem, they develop a gradient-descent algorithm for solving it. Results on an application of relaxation processes are given.","Labeling,
Computer science,
Optimization methods,
Iterative algorithms,
Machine vision,
Training data,
Linear programming,
Bibliographies,
Probability distribution,
Measurement standards"
Worst Case Performance Analysis of Linear Systems with Jumps with Applications to Sampled-Data Systems,"In this paper, we consider a continuous-time linear system with finite jumps at discrete instants of time. An iterative method to compute the L2-induced norm of a linear system with jumps is presented. Each iteration requires solving an algebraic Riccati equation. We also show that a linear feedback interconnection of a continuous-time finite dimensional linear time- invariant (FDLTI) plant and a discrete-time finite dimensional linear Shift-invariant (FDLSI) controller can be represented as a linear system with jumps. This leads to an iterative method to compute the L2-induced norm of a sampled-data system.","Performance analysis,
Linear systems,
Riccati equations,
Control system synthesis,
Control systems,
Iterative methods,
Feedback,
Signal synthesis,
Sun,
Robust stability"
World model representations for mobile robots,"World Model is a key component of any intelligent machine. The modeling system must be able to adequately model the complexity of objects in the environment and it must contain enough structure to allow the low level sensory data to map to the model during the robot operations. The world model builds its representation of the environment based on the data returned by the sensory system of the robot. However, the environment is not static and cannot always be constrained. There is much uncertainty in the world. The representation needs to be able to deal with the uncertainties and update its internal structures. This paper evaluates several world models suitable for mobile robot applications.","Mobile robots,
Solid modeling,
Intelligent sensors,
Robot sensing systems,
Uncertainty,
Shape,
Intelligent robots,
Control system synthesis,
Geometry,
Computer science"
IPL: the InterBase Parallel Language,"IPL is a declarative distributed language designed to support application level programming in the InterBase project. This paper presents the IPL language and shows how it support flexible transactions, mixed transactions, time-constrained transactions and other features. Besides its transaction-oriented features, IPL can be used as a general purpose distributed programming language.",
On serializability of distributed nested transactions,"A model of nested transactions in distributed database systems is presented. The modeling approach is based on conflict serializability extended to accommodate multilevel transactions. Based on these definitions, serialization graph testing for nested transactions is discussed. Three concurrency control algorithms and proofs of their correctness are presented. The algorithms are an adaptation of serialization graph testing, an adaptation of the timestamp ordering protocol, and a variation of an optimistic protocol presented by H.T. Kung and J.T. Robinson (1981).","Concurrency control,
Concurrent computing,
History,
Protocols,
Testing,
Computer science,
Database systems,
System recovery,
Scheduling algorithm"
A network level fractional channel to support guaranteed real-time communication,"A network-level abstraction called phi -channel that supports the requirements of real-time applications is proposed. A phi -channel represents a simplex, end-to-end communication channel between a source and a destination. The channel is characterized by a set of specific performance parameters associated with its traffic, namely packet maximum end-to-end delay and the maximum number of packets that can be sent over that delay. The primary attribute supported by the phi -channel is on-time reliability. The basic scheme used to verify the feasibility of accepting a phi -channel, and the run-time support to guarantee its performance are described. The results of a simulation experiment implementing the basic functionalities of the proposed scheme are presented.","Resource management,
Delay,
Bit rate,
Circuits,
Computer science,
Communication channels,
Runtime,
Computational modeling,
Real time systems,
Teleconferencing"
An object-oriented toolkit for constructing specification editors,"The authors discuss Spectacle, an object-oriented library of software components designed for constructing language-based, graphical, specification editors. Spectacle provides the programmer with a basic toolkit for building an X-Window editor: minimal knowledge of both C++ and the X-Window graphical environment is assumed. The editing tools that are derived from Spectacle can be implemented as stand-alone editors are integrated into larger-scale software development environments. Spectacle editors are syntax-directed and menu driven. The authors outline the basic structure of the library and examine each software component separately. The user-interface model provided by Spectacle is described. Two example prototype editors are presented.","Formal specifications,
Specification languages,
Typesetting,
Application software,
Software tools,
Computer science,
Programming,
Large-scale systems,
Software libraries,
Software design"
The synthesis of circuits with a specified natural frequency given a set of linear devices,"A circuit composed of elements taken from a range of linear devices has a set of possible natural frequencies. Two techniques for synthesizing circuits with any permitted natural frequency within the possible range are given. The first technique uses six of each device type, ideal transformers, and ideal wire. The second requires only two devices plus ideal transformers and ideal wire. Conditions for zero power flow among the devices used in the synthesis are given.",
Axiomatizable classes of finite models and definability of linear order,"It may happen that a first order formula with two free variables over a signature defines a linear order of some finite structure of the signature. Then, naturally, this finite structure is rigid, i.e. admits the single (trivial) automorphism. Also, the class of all the finite structures such that the formula defines a linear order on any of them, is finitely axiomatizable in the class of all finite structures (of the signature). It is shown that the inverse is not true, i.e. that there exists a finitely axiomatizable class of rigid finite structures, such that no first-order formula defines a linear order on all the structures of the class. To illustrate possible applications of the result in finite model theory, it is shown that Y. Gurevich's (1984) result that E.W. Beth's (1953) definability theorem fails for finite models is an immediate corollary.",
Randomized geometric algorithms and pseudo-random generators,"The so called randomized incremental algorithms in computational geometry can be thought of as a generalization of Quicksort to higher dimensional geometric problems. They all construct the geometric complex in the given problem, such as a Voronoi diagram or a convex polytope, by adding the objects in the input set, one at a time, in a random order. The author shows that the expected running times of most of the randomized incremental algorithms in computational geometry do not change (up to a constant factor), when the sequence of additions is not truly random but is instead generated using only O(log n) random bits. The pseudo-random generator used is a generalization of the well known linear congruential generator.",
A dynamic cardiac SPECT computer simulation,"A computer simulation was developed to investigate the effects that cardiac motion, time-varying tracer activity, and differences in relative attenuation between the blood and extravascular (tissue) activity regions have on kinetic modeling using dynamic SPECT (single photon emission computed tomography) imaging. The projection/reconstruction process did not introduce significant errors in the fitted parameters. The blood and tissue activity curves showed little difference for various heart rates >5 BPM for 10 s scans. If the blood region of interest was contaminated by tissue, then both the forward (k/sub 21/) and back (k/sub 12/) exchange increased depending on the amount of contamination. Spillover of tissue activity into the blood region due to cardiac motion increased f/sub v/ but had little effect on k/sub 21/ and k/sub 12/. Nonuniform attenuation changed k/sub 21/ and f/sub v/ significantly (>32% change). Only the parameters f/sub v/ and k/sub 21/ were dependent on the relative attenuation difference between the blood and tissue activity regions.",
Statistical Reference Chip-Code Designs for Lpi Enhancement in Ds/ss Communication Systems,,"Delta modulation,
Radiometry,
Military communication,
Land mobile radio,
Computer simulation,
Space vector pulse width modulation,
Signal design,
Narrowband,
Spread spectrum communication,
Mobile communication"
A magnetic neural network utilizing universal arithmetic modules for pulse-train signal processing,"The authors consider two types of magnetic neural network architecture based on pulse-train signal processing with high reliability. One is realized by neuron units and synapse units, both of which use only a universal arithmetic module (UAM) having adder, multiplier, and delay (memory) functions all in one unit. This architecture thus results in an extremely homogeneous implementation. The other is realized by dividing the function of the UAM into a neuron unit and a synapse unit. The neuron unit provides functions of nonlinear adder and memory by using the properties of the magnetic core such as pulse storage, integration, and nonlinearity.",
Client-network interaction in a real-time communication environment,"A model for client-network interaction developed for the Tenet real-time protocol suite is presented. The model includes new mechanisms for the establishment and runtime management of real-time connections. By improving the information exchanged between the network and the clients, the model makes it possible to reduce the complexity of and the time required to establish a real-time connection, and increases the network utilization. A class of real-time communication service that supports adaptive quality of service is introduced, in order to enhance the ability of the network to deal with congestion situations.",
Efficient use of parallelism in intermediate level vision tasks,"The primary task of intermediate level vision (ILV) is to take the output of low level vision, which is typically a subset of pixels from the original image array, and to generate a representation of image content which is appropriate for symbolic manipulations at a higher level. These tasks, e.g. boundary detection, various types of segmentation or the computation of attributes of image components, involve operations on individual pixels, sets of pixels with a common label or on entities extracted from the raw pixel data, such as orientation of lines or distance between pairs of parallel lines. A class of tasks which operate on individual pixels or sets of pixels is described, problems which are raised in parallel implementations of this class of tasks are considered, and solutions are suggested.",
Printed antennas - New research frontiers,,
A formal approach for security evaluation,"The authors discuss security issues and consider the extent to which internal relations among entities in a system should be taken into account when carrying out security analysis. They present a concrete and flexible security model expressed in terms of the internal relations in the system, rather than abstract state machines. Based on this model, security analysis can be carried out by decomposing the analysis of the whole system into analyses of subsets of the relations, and the security property of the whole system can be derived by composition of these secure relation subsets.",
Support tool and strategy for type error correction with polymorphic types,"The authors focus on strongly typed functional programming languages with polymorphic types, type inference facilities, and higher-order functions, i.e. functional programming languages whose type checkers infer types in programs including polymorphic types and higher-order functions types from the context before execution programs. They examine effective approaches to support type error corrections in these languages and two approaches to support them, following a general framework for debugging. Using these two approaches as case studies, systematic debugging processes based on the general framework for debugging are developed.",
A note on the instance complexity of pseudorandom sets,"The relationship between the notion of pseudorandomness and the notion of hard instances is investigated. It is proved that if A is random (or pseudorandom), then most instances to A are hard instances (or, respectively, have nontrivial instance complexity). These results are used to show that if one-way functions that are secure against polynomial-size circuits exist, then an NP-hard problem A must have a nonsparse core of which all instances have nontrivial instance complexity.",
Hyper model management systems,"Studies the integration of model management and hypertext systems to produce a hyper model management system (HMMS). Model management systems (MMS) constitute a class of software that is designed to support the construction, storage, retrieval, and use of models in the context of decision support systems. Hypertext systems allow users to split information into data fragments which the user can browse to find information by taking nonlinear paths in computer based texts. Such environments can be readily provided for the subtask of model management by hypertext systems. The different kinds of model knowledge can be captured within different types of hypertext nodes and the relationships among these can be maintained by hypertext links. The authors describe some aspects of model management where hypertext can have a significant impact. However, plain hypertext is ineffective in dealing with the dynamic nature of information in model management tasks where data is revised, models executed, and reports are created on-the-fly. Dynamic domains require dynamic hypertexts. The authors also study the requirements for dynamic hypertexts. These can be satisfied within the class of generalized hypertext systems by using special hypertext nodes and links. The authors explore different architectures to integrate MMS and hypertext systems to obtain HMMSs.",
Neural network models for illusory contour perception,A physiologically motivated model of illusory contour perception is examined by simulating a neural network architecture that was tested with gray-level images. The results indicate that a model that combines a bottom-up feature aggregation strategy with recurrent processing is best suited for describing this type of perceptual completion.,
"The single event upset response of the Analog Devices, ADSP2100A, digital signal processor","The authors present the results of a radiation evaluation program carried out on the ADSP2100A, which is a single-chip microprocessor optimized for 12.5 MIPS digital signal processing. Single event upset/latch-up (SEU/SEL) testing using Californium-252 was the primary aim of this program; however, accelerator heavy-ion and proton SEU/SEL data as well as total ionizing dose data are also presented. Californium-252 SEU testing covered both 12. 5- mu m and 21.3- mu m epitaxial layer DSPs, whereas only the 12.5- mu m type was tested with heavy ions and protons. Heavy-ion SEU testing covered the LET (linear energy transfer) range of 3.4 to 79.2 MeV/(mg/cm/sup 2/) and SEU testing covered the proton energies of 200, 500 and 800 MeV. A total ionizing dose rate of 64.0 rd(Si)/min was used for the cobalt-60 testing. The hardware design and software used are described and details of the various tests and test facilities are given. The authors report on the use of the SEU data for the calculation of expected in-orbit upset rates using the CREME suite of programs.",
Using SOMs as feature extractors for speech recognition,"The authors demonstrate that the self-organizing maps (SOMs) of Kohonen can be used as speech feature extractors that are able to take temporal context into account. They have investigated two alternatives for using SOMs as such feature extractors, one based on tracing the location of highest activity on a SOM, the other on integrating the activity of the whole SOM for a period of time. The experiments indicated that an improvement is achievable by using these methods.","Feature extraction,
Speech recognition,
Clustering algorithms,
Self organizing feature maps,
Hidden Markov models,
Data mining,
Laboratories,
Computer science,
Artificial neural networks,
Pattern recognition"
"TRAMP, the next generation data acquisition system for RTP","The Rijnhuizen Tokamak Project (RTP) is a medium-sized tokamak experiment that requires a very reliable data-acquisition system due to its pulsed nature. Analyzing the limitations of an existing CAMAC-based data-acquisition system showed that a substantial increase of performance and flexibility could best be obtained by the construction of an entirely new system. This system, called TRAMP (transient recorder and Amoeba multiprocessor), is based on tailor-made transient recorders with a multiprocessor computer system in VME running Amoeba. The performance of TRAMP exceeds the performance of the CAMAC system by a factor of four. Plans to increase flexibility and performance are presented.",
A simple assertional proof system for real-time systems,"A simple proof system for a real-time system model similar to that of timed I/O automata is presented. By introducing state variables indicating the last event occurrence time and event deadline time, one can express real-time properties in terms of traditional safety and progress assertions (e.g. invariant, unless, and leads-to) which are interpreted in the standard way. As a result, one can prove them using traditional proof rules (with weak fairness assumptions being replaced by finite upper bound timing assumptions). Unlike other approaches, one does not use a current time variable. The proof system is illustrated on a real-time mutual exclusion algorithm. The authors have also applied it to examples from the timed I/O automata literature.",
The complexity of the Hajos calculus,"The Hajos construction is a simple, nondeterministic procedure for generating the class of graphs that are not 3-colorable. A.J. Mansfield and D.J.A. Welsh have posed the problem of proving whether or not there exists a polynomial-size Hajos construction for every non-3-colorable graph. The main result of this paper is a proof that the Hajos calculus is polynomially-bounded if and only if extended Frege proof systems are polynomially bounded. This result links an open problem in graph theory to an important open problem in the complexity of propositional proof systems. In addition, the authors establish an exponential lower bound for a strong subsystem of the Hajos calculus. Lastly, they discuss an interesting graph-theoretical consequence of this result.",
A connectionist approach to predict antenatal outcome,"This article describes te construction and structure of an anificial neural network (A for the prognosis of antenatal state. The results obtained had been compared with those of the prognostic module of the expert system NST-EXPERT and with those obtained by the perinatologists colaborating in the validation study of the latter. The ANN presented here has proved to be an adequate method to accomplish the prognostic paner recognition task. For this reason, a hybrid system incorporating the A techniques to manage the neonatal prognosis and the original diagnosis ad therapeutic modules of the expert system NST-EXPERT is proposed.",
Improved layer assignment for packaging multichip modules,"The layer assignment problem plays an important role in packaging multichip modules, since the number of layers is directly related to the cost of the final product. In this paper, the authors propose a new model for the problem and a heuristic layer assignment algorithm based on the new model. The experimental results presented show that the solution provided by the algorithm is close to the lower bound.",
A novel application of pyrolysis-gas chromatography to the differentiation of photocopiers,"A Curie point pyrolyser, a dual wide-bore capillary column gas chromatograph equipped with dual FIDs, and a personal computer were connected online. The differentiation of photocopier toners was based both on the comparison of retention indices and on conventional pattern recognition. A data library is also being compiled with most of the standard samples available in Taiwan. The results demonstrated that the technique was useful for the differentiation of photocopying toners and that the computer-assisted library search based on the comparison of retention indices was a powerful approach to locating suspect photocopying machines.",
Video Compression and Noise Reduction Using Transform/Subband Coding and Adaptive Amplitude Modulation,"This article presents the basic ideas behind transform and subband representations of a signal. Although transform and subband representations appear to be different, in fact, they are equivalent. This theoretical relationship gives useful insights into the design of video processing and compression systems. An application of this result to the design of an adaptive amplitude modulation/demodulation (AM/DM) system for noise reduction of images is described. Also discussed is the AM noise-reduction technique for additive noise, and a method is presented to reduce the AM side information by exploiting the transform representation of an image.",
Scalar program performance on multiple-instruction-issue processors with a limited number of registers,"The performance of multiple-instruction-issue processors with variable register file sizes is examined for a set of scalar programs. The authors make several important observations. First, multiple-instruction-issue processors can perform effectively without a large number of registers. In fact, the register files of many existing architectures (16-32 registers) are capable of sustaining a high instruction execution rate. Second, even for small register files (8-12 registers), substantial performance gains can be obtained by increasing the issue rate of a processor. In general, the percentage increase in performance achieved by increasing the issue rate is relatively constant for all register file sizes. Finally, code transformations designed for multiple-instruction-issue processors are found to be effective for all register file sizes; however, for small register files, the performance improvement is limited due to the excessive spill code introduced by the transformations.",
Deterministic scanning and hybrid algorithms for fast decoding of IFS (iterated function system) encoded image sets,"Deterministic algorithms for decoding IFS (iterated function system) sets involve determining all the IFS (dynamic) descendants of seed pixels. Realistic algorithms require pruning of previously encountered pixels on the descendant tree. Timing data are reported for the random iteration algorithm, and for three new deterministic algorithms: the scanning algorithm; the stack algorithm; and a hybrid combination. Decoded timing data indicate the superiority of the pruned hybrid algorithm.",
A simple perfect hashing method for static sets,"Perfect hashing refers to hashing without collisions. There are a number of methods proposed in the literature for determining perfect hashing functions for a given key set. Direct perfect hashing methods are those which do not involve auxiliary table lookup. This paper proposes a direct perfect hashing method using random functions. This method is shown to be as good as any other in performance, and simple to use.","Table lookup,
Computer science,
Data structures,
Information retrieval,
Sorting"
Supercomputers-modeling reality,"The mathematical modeling capabilities of supercomputers and the possibilities they open up for scientific research are explored. The need for teraflop machines and progress in that direction are discussed. Some modeling applications are described. These include internal combustion engines, semiconductor crystal growth, electromagnetic simulation and design, molecular biology, imaging, geology, meteorology, ocean services, and turbulence.",
A continuation method for emission tomography,"The authors offer a framework, deterministic annealing (DA), in which two important technical problems are addressed. One of these problems is associated with the minimization of objective functions composed of both binary and continuous variables. The second concerns local minima. The DA method offers a principled and efficient means of handling the problems associated with mixed continuous and binary variable objectives. The application of the DA method results in a sequence of objective functions (defined only on the continuous variables) whose sequence of solutions approaches that of the original mixed variable objective function. The sequence is indexed by a control parameter ( beta ). At each beta , a standard descent optimization algorithm is used to find a solution that is then used as an initial condition for the next setting of beta . The energy functions at low beta are smooth approximations of the energy functions at higher beta . Consequently, it is easier to minimize the energy functions at low beta and then track the minimum through the variation of beta .",
Authenticating multicast Internet electronic mail messages using a bidirectional MAC is insecure,"The 1988 version of the message encryption and authentication procedures for Internet electronic mail makes use of bidirectional MAC (BMAC). When used for multicast electronic mail it is important that this BMAC act as a one-way function. It is shown that it is not a one-way function, which means that the BMAC technique should not be used for authenticating multicast messages.",
People who live in an on-line virtual world,"When designing a human interface of a computer-mediated communication, it is important to take a socio-behavioral approach for understanding the nature of the communication. This study was conducted to investigate the users' social and behavioral characteristics in an online virtual world.",
A model of human approach to describing algorithms using diagrams,"A model of the human approach to describing algorithms is developed by analyzing algorithm descriptions by humans using pen and paper. The authors consider algorithms which are described by drawing data objects on paper and demonstrating a sequence of actions on the data. The model formalizes the abstractness, visibility, and referenceability of objects in the workspace; the 'natural' ways of deterministically and nondeterministically selecting objects; and a wide range of actions for manipulating objects including conditional, condition-based repetition, and parallel actions. The steps of an algorithm for finding a minimum spanning tree are formalized in the proposed model.","Humans,
Concrete,
Algorithm design and analysis,
Computer languages,
Computer science,
Filtering,
Parallel processing,
Tree graphs"
Steering the maintenance costs: an exploration of the maintenance construct,"Maintenance is a natural and necessary part of the system life-cycle and its costs. It is important to control where time and money are spent and what kind of maintenance is performed. Systems maintenance personnel must keep their eye on the potential uses of information technology for competitive purposes in order to classify existing systems projects. For this purpose it is necessary to be able to measure both maintenance, the efforts and costs, and the quality factor maintainability. Such measuring facilitates planning and steering the maintenance work in information systems organizations. The authors present a framework for evaluating software quality in organizations. They combine structure, readability, size, numbers of errors and complexity metrics, and some process attribute metrics to measure maintainability. The collected values are stored in a metric database, from where periodic reports are written. Availability to measurements offers means for the organization to distribute their information systems resources to more profitable objects and to be in control of the maintenance costs, i.e. coordination and reuse of the newly found resources.",
A Cad-based System For Automated Inspection Of Machined Parts,,
The Ignatius environment: supporting the design and development of expert-system user interfaces,"The Ignatius user interface management system, with which designers can create user interfaces for conversational and model-based expert systems, is discussed. Because conversational and model-based expert systems require different approaches to user interface management, Ignatius consists of two separate but communicating tools: the surface interaction manager and the session discourse manager. The interaction manager represents user interface components as objects with attributes. The discourse manager manages the discourse structures of conversational expert systems, structures traditionally regarded as side effects of problem solving. Ignatius was tested by building a user interface to the Antibody Analysis Advisor (A/sup 3/), a conversational expert system that helps laboratory technicians choose analysis techniques for finding antibodies in blood samples. The surface interaction objects, session discourse structure, and an example execution in A/sup 3/ are described.",
Analysing aerial photographs with ADAM,"The use of the advanced distributed associative memory (ADAM) in the analysis of features in infrared line scan imagery is described. An ADAM neural network maps an input vector or image to an output vector or image. The ADAM neural network is capable of recognizing features in aerial images using a deterministic noniterative training algorithm. A novel form of weight update allowing a weighted training procedure and a binary runtime system to increase the classification success of ADAM is presented. The results of segmenting urban and field areas, as well as road identification, are discussed.",
Efficient area optimization for multi-level spiral floorplans,"An algorithm for solving the area optimization problem for multilevel spiral/slicing floorplans is presented. It is shown that in the worst case, there are exponentially many useful implementations for a multilevel spiral floorplan. The reasons why this does not happen very often are also shown. The experimental data suggest that in most cases, the area optimization problem of multilevel spiral/slicing floorplans can be solved in O(n/sup 2/ log n) time and O(n/sup 2/) space, where n is the number of basic rectangles of the floorplans.",
A connectionist approach for thresholding,"Thresholding is a necessary and useful step in many applications of image processing. The general process of thresholding is first to select several gray levels, or thresholds, then use these values to classify the pixels into several subranges. Previous methods for selecting thresholds are usually designed based on assumed distributions of pixels or some sort of heuristics. It is difficult to apply any of these methods when the domain of images is changed. There is a need for seeking a more flexible and robust technique in such situation. The paper presents a connectionist approach for learning and selecting thresholds by using the Kohonen algorithm which is an unsupervised neural network. The approach is able to find thresholds for classifying images without a teacher. Experimental results show that the approach is promising.",
"Distributed algorithms for shortest-path, deadlock-free routing and broadcasting in Fibonacci cubes","Distributed routing and broadcasting algorithms for the Fibonacci cube are presented. The routing algorithm is shown to find shortest and deadlock-free paths. Two communication models are considered for the broadcasting. It is shown that the all-port broadcasting algorithm is optimal in terms of minimized routing steps. An upper bound is obtained for the one-port broadcasting algorithm, which is shown to be optimal for certain cases. The time complexities of the all- and one-port broadcasting algorithms are examined.",
Improved lower bounds for Shellsort,"The authors give improved lower bounds for Shellsort based on a new and relatively simple proof idea. The lower bounds obtained are both stronger and more general than the previously known bounds. In particular, they hold for nonmonotone increment sequences and adaptive Shellsort algorithms, as well as for some recently proposed variations of Shellsort.",
Analysis of thinning algorithms,"Uses a combinatorial approach to analyse the differences of thinning algorithms among iteration and sub-iteration, thinning by coordinate and by edges of patterns. The authors also propose a serial model thinning algorithm in which the skeletons only consist of three types of points: connected points, end-points, and hole-points.",
An optimized reconfigurable architecture for transputer networks,"This paper presents the architecture of a fully reconfigurable distributed memory computing system. It is assumed that the processors communicate via message passing on an application specific regular network of degree four. To realize any network of this class, they use a special multistage Clos network which is built up by a minimal number of equal sized switches. These switches can be configured to realize any connection between input and output ports. To map a network onto the architecture, the process graph has to be partitioned into a number of subsets. The authors prove that the number of external edges between the subsets can be bounded. For that reason, it is possible to minimize the number of links and switches in the architecture without losing the ability to realize any regular network of degree four. Moreover, any user specific network can be mapped efficiently on the architecture. The practical relevance of this work was shown by the realization of the architecture by Parsytec. Their largest system has 320 processors.",
Implementation and evaluation of a parallel text searcher for very large text databases,"The Utah Retrieval System Architecture (URSA) was initially developed in 1981 developed as an alternative to central-processor-based information retrieval systems. It combined distributed processing and a windowed user interface with a hardware-based search server combined with using document surrogates such as partially-inverted files. The authors have now started the development and testing of a medium-scale (about 10 gigabyte) parallel backend search server to demonstrate its operation and to gather data on the use of such a backend processor in actual operation, including information about query complexity and arrival rates. This searcher, based on a hardware-augmented RISC processor, builds on their experience developing and operating the custom VLSI FSA-based search engine. The use of a programmable processor allows the easy implementation of complex search patterns, such as numeric range matching, while the special hardware augmentation provides considerably better performance than would be available from a standard RISC processor server.",
Understanding three-view drawings based on heuristics,"A system that reconstructs 3D models from hand-drawn three-view drawings represented by binary images is described. The authors lay main stress on the description of a heuristics directed reconstruction algorithm. The proposed algorithm performs a combinatorial search based on the face decision strategy along with two heuristics aiming at simulating the human's understanding way of interpretation. One is for finding a good sequence of search nodes, and the other for finding more natural scenes earlier than unusual ones.",
Interactive computer modules for undergraduate chemical engineering instruction,"The goal of the computer modules component of the project 'A Focus on Developing Innovative Engineers', funded by the National Science Foundation, is to develop a complete set of interactive computer modules for courses in the undergraduate chemical engineering curriculum, where each computer module reinforces one of the key course concepts. The modules are developed by a team consisting of faculty as technical advisor, an undergraduate student programmer, and a postdoctoral research fellow serving as supervisor and master programmer. After development, the modules are tested by undergraduate students at the University of Michigan and by external faculty, before general distribution. Modules for the Introduction to Chemical Engineering course have been tested and distributed, and modules are currently being tested in the Fluids/Transport, Separations, and Chemical Reactor Design courses. The modules prepared to date are outlined.",
Fault-tolerant multi-destination routing in hypercube multicomputers,"Multicast algorithms for faulty hypercube multicomputers are discussed. Two types of algorithms are proposed. Type I algorithms have the following features: they are distributed, in the sense that the same algorithm is implemented in all involved nodes and based on local information only; they can always find shortest paths from the source to all destinations whenever such exist; and they are easy to implement in hardware. The algorithms deal with nodes faults only, and they cannot deliver messages to those destinations that can be reached through some longer paths. Type II algorithms deal with both link faults and node faults. They can deliver messages to all reachable destinations if the total number of faults is less than the dimension of the hypercube. However, these algorithms are not easy to implement in hardware.","Fault tolerance,
Routing,
Hypercubes,
Multicast algorithms,
Unicast,
Broadcasting,
Hardware,
Computer science,
Liver,
Very large scale integration"
Two Pattern Learning Algorithms Using Dynamical Systems,,
A method of diagnosing logical faults in combinational circuits,"The authors propose a method of diagnosing any logical fault in combinational circuits. The basic idea of the method has been obtained from an observation that only an error generated on one of the fault-nets propagates often to the primary outputs under a given test though more than one fault-net exist in the circuit under test. In this method, the fault-nets are located through a repetition of deducing candidates for each individual fault-net under the assumption of single fault-net and ascertaining which is the real one by probing. Probing internal nets is done only for finding the real fault-nets from these candidates. Consequently, it becomes possible to greatly decrease the number of probed nets. Preliminary experimental results show that fault locations are almost completely identified by probing 20% of the nets at most.",
Analysis and recognition of alphanumeric handprints by parts,"An advanced hierarchical model has been proposed to produce a more effective character recognizer based on the probability of occurrence of the patterns. New definitions such as crucial parts, efficiency ratios, degree of confusion, similar character pairs, etc. have also been given to facilitate pattern analysis and character recognition. Using these definitions, computer algorithms have been developed to recognize the characters by parts, including halves, quarters, and sixths. The recognition rates have been analyzed and compared with those obtained from subjective experiments. Based on the results of both computer and human experiments, a detailed analysis of the crucial parts and the Canadian standard alphanumeric character set has been made revealing some interesting fundamental characteristics of these handprint models. The results should be useful for pattern analysis and recognition, character understanding, handwriting education, and human-computer communication.",
On the duality between routing and scheduling systems with finite buffer space,"A duality property is established between scheduling the routing problems associated with a set of parallel queues. This allows determination of the optimal policy for either system, once it is determined for its dual system. In systems with no buffer at the controller the critical requirement is that the scheduling policy is preemptive; when there is buffer space dedicated to the controller, the crucial assumption is that both routing and scheduling policies should be non-idling.",
A constructive algorithm for spectral factorization of parahermitian polynomial matrices,"Presents a constructive algorithm for spectral factorization of 2D parahermitian positive definite polynomial matrices. Such an algorithm is expected to be useful in many problems in multidimensional signal and system theory. While earlier solutions to the problem in the mathematical literature deal with existence type results, the present algorithm is also believed to provide an elementary proof of the most nontrivial fact that a factorization of a specific type can always be carried out. An example illustrating the main aspects of the algorithm is included.",
Partially shared variables and hierarchical shared memory multiprocessor architectures,"Latency and synchronization overheads have been identified as two fundamental problems in large-scale shared memory multiprocessors. The notion of partial sharing of variables is introduced, and architectures based on hierarchical memories which exploit this notion of partial sharing to reduce the latency and synchronization overheads significantly are suggested. A particular class of architectures, the tree structure, hierarchical memory multiprocessor architectures (THMMs), is examined by suggesting an implementation and considering the execution and the performance of several well-known applications such as matrix multiplication, solution of partial differential equations, solution of linear recurrence relations, barrier synchronization, and reduction operations. Speedup and cost figures for these examples are compared when executing on the THMM and on a conventional memory multiprocessor.",
A VLSI-chip for a hardware-accelerator for the simplex-method,"A hardware realization of the simplex method, the central method of linear programming, a presented. the algorithm is customized for numerical stability (arithmetics) as well as hardware proximity. The resulting hardware is based on a parallel architecture with up to eight processing units, employing standard floating point units (FPUs), RAMs, and custom VLSI chips. It has been designed for use in an IBM PC/AT environment.",
Parallel mean field annealing neural network for solving traveling salesman problem,"The authors propose a parallel mean field annealing (MFA) algorithm and a new energy function for finding traveling salesman optimal tours. The proposed parallel MFA neural network has the advantages of a simplified energy function, and that it converges more rapidly to an optimal solution. The experimental results showed that the parallel MFA and the new energy function can generate the optimal solution.",
Numerical performances of autoregressive spectrum estimators based on three-term recurrences,"The numerical performance of two fast algorithms for estimating the power spectral density of an autoregressive process is studied. The algorithms perform similarly to the Burg algorithm, but require only two-thirds as many multiplications as the most efficient implementation of the Burg algorithm. This allows the high resolution associated with the Burg algorithm to be obtained using many fewer computations. One algorithm is the deterministic form of the split lattice algorithm adjoined to the split Levinson recursions; however, its resolution is relatively poor. The other algorithm corrects a bias in the first algorithm, and has resolution similar to the Burg algorithm.",
Hyper Petersen network: a fault-tolerant multiprocessor topology,"The authors propose and analyze a new hypercube-like topology, called the hyper Petersen (HP) network, which is constructed from the cartesian product of a binary hypercube and the Petersen graph. The properties of HP topology include regularity, high degree of symmetry and connectivity, and small diameter. For example, an n-dimensional HP network with N=1.25*2/sup n/ nodes is a regular graph having degree delta =n, node-connectivity kappa =n, and diameter d=n-1, whereas a binary hypercube graph with the same diameter covers only 2/sup n-1/ nodes, each of degree (n-1). Thus the HP topology covers 2.5 times extra nodes at the cost of increasing the degree by one. Again with the same degree and connectivity, the diameter of HP network is one less than that of a hypercube, yet having 1.25 times larger packing density. Furthermore, various topologies such as meshes, trees, and twisted hypercubes can be embedded on the HP topology.",
Performance evaluation of the Rekursiv object oriented computer,"The Linn Rekursiv is an object-oriented computer. An implementation of the persistent programming language PS-algol has been developed for it. Experiences with this implementation have shown certain drawbacks of its modified Harvard architecture for the implementation of persistent object-oriented languages. The general problems of implementing such languages and how the Rekursiv is intended to help are discussed. Data are presented on the relative performances of the Rekursiv and other processors executing PS-algol in 3 areas: procedure calls, list processing and array access, and conclusions are drawn as to which are the more and less valuable features of its architecture.",
Verification of the general position assumption in the practice of stereovision,In feature-based stereo analysis the use of restrictive knowledge-based assumptions constrains effectively the processes of interpreting and matching image features. Among these assumptions the general position assumption plays a significant role and is employed in many approaches. But working with complex scenes shows that this assumption is quite often violated for some parts of the scene. The paper proposes an active stereovision approach which completes automatically the reconstruction of a given scene and avoids thereby special views and errors in the interpretation and matching of image features.,
System Level Specification and Synthesis,,
Particle simulation on heterogeneous distributed supercomputers,"The authors describe the implementation and performance of a three dimensional particle simulation distributed between a Thinking Machines CM-2 and a Cray Y-MP. These are connected by a combination of two high-speed networks; a high performance parallel interface (HIPPI) and an optical network (Ultra Net). This is the first application to use this configuration at NASA Ames Research Center. The authors describe their experience implementing and using the application and report the results of several timing measurements. They show that the distribution of applications across disparate supercomputing platforms is feasible and has reasonable performance. In addition, several practical aspects of the computing environment are discussed.",
An approach for fairness improvement in DQDB networks,"The authors discuss an approach for fairness improvement in distributed queue dual bus (DQDB) network, which is a draft standard for IEEE 802.6 metropolitan area network (MAN). The DQDB medium access mechanism may be unfair for some realistic situations where both throughput and delay are dependent upon the geographic location of each node in the network. The authors analyze the asymmetric access property of DQDB and propose an approach called reservation capacity priority control (RCPC), which is both more efficient and fair for sending the segments. The RCPC allows the system to operate more uniformly and has a high degree of fairness in bandwidth sharing. The simulation results show that RCPC approach is more fair than bandwidth balancing mechanism under all traffic conditions.",
Feasibility of Ultrawideband Radar,,
Minimizing Total Wire Length By Flipping Modules,,
Let's PARTY: Process Algebra With Real-time From York,"There are many real-time process algebras, but they invariably make restrictive assumptions about representable behavior, or do not have proof theory for a suitably large class of behaviours. We introduce the Process Algebra with Real-Time from York (PARTY), which uses a simple yet powerful, intuitive and general model of real-time behavior. A real-time process interacts with its environment by instantaneous actions. There is no restriction on the tame between successive events, and internal action is hidden. The equivalence of recursively defined finite state processes is decidable, and a program has been written. for analyzing PARTY processes.",
Hyperweave: a fault-tolerant expandable interconnection network,"Hyperweave, a novel hierarchical, expandable interconnection network, is presented. Its topology is an improvement over the earlier proposed extended hypercube topology. Hyperweave has better node fault-tolerance, a greater number of disjoint paths between any two nodes, and a larger bisection width than the extended hypercube. A message-routing algorithm is presented, and an embedding of the extended hypercube on the Hyperweave is shown.","Fault tolerance,
Multiprocessor interconnection networks,
Hypercubes,
Network topology,
Computer science,
Parallel architectures,
Hardware,
Memory architecture,
Mesh networks"
Arden-architecture development environment,"Software supports, such as compiler and simulation tools, are increasingly crucial for architecture development. A flexible system called Arden is being developed to help evolve efficient architectures. Arden combines a retargetable compiler with a back-end simulation tool which provides quantitative information for making a good decision in architecture designs. User-oriented specification for the code generator has simplified the machine descriptions and requires only 31 rules in describing DLX architecture. An experimental bottom-up matching algorithm which reduces the pattern matching to a numerical computation problem and improves the space complexity is presented.",
A model for address-oriented software and hardware,"Introduces the concept of 'address-oriented software', which is software that assigns particular meaning to the values of memory addresses. Such software is often not well supported by the services of the operating system in which it operates. The authors provide some examples of address-oriented algorithms, and propose a general model of the operations they use, called 'address management', which they intend to use as the basis of a new operating system. They derive a hardware model from their formal model, and suggest implementation techniques. A partial implementation of their hardware model is an integral part of the ARM 600 processor, currently in development.",
Supporting the information mesh,"A model for the role of the network in a distributed computing environment that will necessarily require abstractions in the operating system has been developed. This model is based on information that is long lived and widely distributed. It assumes that interesting information can be distributed around the world, and survives outside any particular application, application toolkit, or programming language runtime system. Within the information mesh, computations or activities will take place in one of three forms: one in which the focus of attention is changed, but the application remains the same; one in which the focus changes, and the application itself must also change; and a third that is less specific, more global, e.g., searching. In the cases of such global operations, one may need to limit the scope of terms of the mesh, since these are operations over regions of the mesh. It is important to include links and a native form of link shadow in each operating system, if the workstation running that operating system is to allow the user to collaborate in the information mesh.",
Optimum Steiner tree generation,Several phases of the VLSI design process use rectilinear Steiner spanning trees in estimating wire length. Since the problem is NP-complete heuristics form the major portion of the collection of algorithms for this problem. Exact solutions are rare and very few have even been implemented. Thus they seem not to be practical. The authors first reduce the feasible solution space so that exact solutions are possible. Then they develop two branch and bound algorithms which achieve exact solutions. Distributing the computation between processors and parallel computation methods are currently being tested in an attempt to extend the size of the problems which can be actually solved.,
Decentralized H norm bounding control for discrete-time systems,"This paper presents the design of a decentralized control scheme, which not only stabilizes the system, but also guarantees disturbince attenuation as measured by the H norm. The results rely on the existence of the solution to the state-feedback H norm bounding problem, as well as a solution of a certain modified discrete algebraic Riccati equation.",
Optimizing Transient Antenna Response,,
Aggregation in model-based reasoning using prime models: a preliminary report,"The paper presents how domain models can be aggregated into intermediate levels, each of which can be realized as an instance of a corresponding abstract prime model. One advantage of model aggregations is its ability to reason from first principles at different levels of decomposition. This is especially desirable when dealing with large and complex physical systems.",
Robust box bounds: throughput guarantees for closed multiclass queueing networks with minimal stochastic assumptions,"To use queuing theory to analyze real systems such as computer communications networks, one makes assumptions that are, strictly speaking, untrue. The authors provide an exact analysis for cases with greatly relaxed assumptions. Service times can have general increasing failure rate distributions, different by class even at FIFO nodes. Routing can be arbitrary, including dependencies along the route, provided the number of visits to each node is a random variable. Only the mean service time and mean visit rates at nodes need be specified. A lower throughput bound is found which gives a minimum guaranteed throughput for each class; together with the familiar multiclass asymptotic upper bounds they give a convex feasible region in a multidimensional throughput space. A detailed analysis is given for systems with FIFO and infinite-server nodes, and the extension to processor-sharing nodes is described. The results can be reinterpreted as a set of bounds on the separate throughputs. This is equivalent to a circumscribed rectangular region called the robust box bounds.",
Assessment of support for program understanding,"Discusses tools for program understanding during the software maintenance phase. The program understanding is crucial to successful maintenance, but it is still poorly supported by analysis-oriented tools. In the light of cognitive studies for program understanding, the authors assess the existing tools for program understanding, and suggest an approach which facilitates the understanding of complex code during maintenance via the chunking process. During this process programmers recognize the abstract function or meaning of groups of statements and then piece together these chunks to form even larger chunks until the entire code is understood and mapped out. Chunking support can be effective as part of a maintenance toolkit. It lets maintenance personnel control code abstraction and ask many semantic questions about chunks and their relationship to other parts of the code.",
Evaluation of image resolution in X-wave imaging system,"A novel pulse-echo imaging system based on X-wave nondiffracting transmission and reception is described. In the theoretical model of this system a position-dependent filter has been used for pulse generation and subsequently for processing of the received echoes. In practice, the system can be implemented using an annular array transducer and a filter bank. The point spread function (PSF) of the imaging system has been derived. The PSF has an asteroid shape with branches extending to infinity. To reduce the effects of branches and improve image resolution, a space-invariant restoration filter is used. The performance of the imaging system, for broadband as well as for bandlimited X-waves, and the restoration process are evaluated by computer simulations. Simulation results indicate that the system is capable of providing high resolution, large depth of field images.",
A Russian meteor burst communication experiment and measurement-prediction comparison,"Meteor radar measurements performed in Kazan, Russia, in early April 1992, and forward scatter measurements on the Moscow-to-Kazan meteor burst link performed in May 1992, are presented. These measurements are used to demonstrate the prediction accuracy possible with three meteor burst computer models: a Monte Carlo model and two volume integration models. The Monte Carlo method predicted the backscatter and forward scatter more accurately than the other models.",
A global synchronization algorithm for the Intel iPSC/860,"Precisely synchronizing the processors of a distributed memory multicomputer provides them with a common baseline from which time can be measured. This amounts to providing the processors with a global clock. This work investigates a global processor synchronization algorithm for the Intel iPSC/860. Previous work has shown that for certain communication problems, such as the one-to-all broadcast and the complete exchange, the most effective use of the iPSC/860 interconnection network is obtained only when communicating pairs of processors are suitably synchronized. For other communication problems, such as the shift operation, global processor synchronization ensures the most effective use of the communication network. This work presents an algorithm that synchronizes processors more closely than the synchronization primitive by Intel. This new synchronization algorithm is used as the basis of an efficient implementation of the shift operation.",
Promoting the use of an object-oriented software development methodology by merging structured and object-oriented analysis methods,The author discusses factors that are partially responsible for the gap between the state of the art and the state of the practice for object-oriented software development methods. The focus is on identifying factors that inhibit the speed of adoption of object-oriented software development techniques and on discussing methods of addressing these inhibiting factors. A methodology is presented that is designed to decrease the resistance to change by integrating traditional and object-oriented analysis techniques.,
Extracting spinal cord contours from transaxial MR images using computer vision techniques,"Computer vision techniques were applied to finding spinal cord contours in MR (magnetic resonance) images of the lumbar spine. For each slice, the method starts with an approximate spinal cord center supplied by the user. A search was then made for significant edges by moving outwards along 16 equally spaced radii. Edges were interpolated on radii for which no significant gradient existed. The contour was smoothed by adjusting the position of each edge with respect to the edges found on neighboring radii. The results of the experiments are reported. The research demonstrates that it is feasible to use a fairly simple image processing algorithm on a personal computer to automatically extract the spinel cord contours from transaxial MR images.",
Automatic Synthesis of FMS System Design Models from System Requirements,,
Evaluation of Forge: an interactive parallelization tool,"The evaluation of Forge used five typical NAS applications. Analysis of the results revealed three critical areas in need of improvement. First, if tools parallelize loops without performing machine-specific optimizations, performance can be significantly degraded. For highly vectorized codes, the degradation is the most severe. Second, to help user find false dependencies, tool messages should be understandable by application scientists. Query facilities for variable usage and definition should be provided. To guide parallelization, tools must estimate granularity and overhead. Third, the benchmarks contain a large number of small to medium size loops which limit the maximum speedup obtainable by parallelization. Worse yet, they all contain serial loops whose bounds are proportional to problem size. When the size of these loops is large, the speedup can be independent of problem size. Merely converting sequential programs cannot satisfy NAS needs; one must support the design and implementation of parallel algorithms. Finally, issues in creating a future NAS parallel programming environment are discussed.",
IASCE: an intelligent assistant to software cost estimation,"A CASE (computer-aided software design) tool called IASCE has been developed to help the project manager estimate a proposed project cost. This tool collects accurate data from current software so that researchers can explore new software models and metrics. IASCE also supports multiple software cost estimation models and their corresponding metrics, tractable for project management control, feedback, and learning activities. In addition, IASCE provides for the establishment of project-specific cost models and corporate metrics for the models, permits tracing of these models and metrics throughout the software life cycle via feedback and post mortem evaluation, and offers a mechanism for long-range improvements of software cost estimation. It can be tailored to a specific software development environment.",
A measure of fault-tolerance for distributed networks,"The authors consider probabilistic networks having links that are perfectly reliable but nodes that fail randomly and independently with known probabilities. They define a fault-tolerance measure of such network that is directly affected by the choice of its underlying graph and the location of its node-components. A state of the network is tolerant if the currently operating nodes comprise a connected subnetwork. The probability of the network being in a tolerant state is the fault-tolerance (FT) measure of the network. The authors are concerned with the design of globally-best tolerant networks, that maximize FT for any given set of node-operating probabilities. They study this measure of fault-tolerance by developing combinatorial tools and by determining the optimal networks in both 'sparse' and 'dense' classes.",
Efficient construction of catastrophic patterns for VLSI reconfigurable arrays with bidirectional links,"Patterns of faults that are catastrophic for regular architectures, particularly the systolic arrays, have been studied. For a given link configuration, there are many fault patterns which are catastrophic. Among those, there is a particular fault pattern, called the reference fault pattern, which is crucial for the development of testing techniques; furthermore, the efficiency of any testing algorithm can be further improved in the presence of efficient algorithms for constructing the reference fault pattern. The authors develop a new algorithm for the construction of the reference fault pattern for VLSI reconfigurable arrays in which the links are bidirectional. The complexity of the new algorithm is O(kN) which is a significant improvement over the existing O(N/sup 2/) algorithm, where k is the number of bypass links, and N is the length of the largest bypass link.",
On languages with very high information content,It is shown that any language in ESPACE that is bounded truth-table reducible in polynomial time to a set with very high space-bounded Kolmogorov complexity must be bounded truth-table reducible in polynomial time to a sparse set.,
"Linear-Time Motion Planning for Two Square, Movable Obstacles in a Grid Environment",,
Modeling and simulation of the SDC data collection chip,"A description is presented of modeling and simulation of the data collection chip (DCC) design for the Solenoidal Detector Collaboration (SDC). Models of the DCC written in Verilog and VHDL are described, and results are presented. The models have been simulated to study queue depth requirements and to compare control feedback alternatives. Insight into the management of models and simulation tools is given. Finally, techniques useful in the design process for data acquisition systems are discussed.",
CPW-FED Slot-Oscillators for Power Combining Applications,"We have combined integrated circuit antenna technology with microwave oscillator design to build an active slot-oscillator. The design is planar, does not require via holes and is compatible with monolithic transistor technology. The coplanar-waveguide (CPW-fed) antenna impedance is calculated using a full-wave analysis technique. Slot-oscillators were built at 7 GHz, 13 GHz and 22 GHz and the predicted oscillation frequencies agree well with experiments. The design is easily scaled to millimeter-wave frequencies and can be extended to power combining arrays.",
Achieving Goals Through Interaction With Sensors And Actuators,,
Knowledge-based support for scientific programming,"The author considers how knowledge-based tools can support scientific computing, with a focus on the support of code generation. Scientific computing traditionally is carried out by mathematical modelers who write their own Fortran programs. As faster machines and new architectures make more complex problems computationally feasible, programming becomes more cost effective. Scientific computing comprises a variety of activities including model formulation, coding, and interpretation. The SINAPSE program synthesis system illustrates the use of knowledge-based techniques in model solution. SINAPSE is designed to be part of a problem-solving environment for forward modeling that includes several additional scientific programming activities. SINAPSE generates code by applying refinements and optimizing transformations, first producing an algorithm description and then an array-based, high-level language program before generating target code. SINAPSE generates implementations targeted toward a specified architecture.",
Exploiting Locality to Provide Adaptive Routing of Real-Time Flows in Global Internets: Abstract,,
On generalized diameters of interconnection networks,"The authors study the generalized diameters for many existing networks for parallel computations, such as trees, hypercubes, meshes and butterflies. The generalized diameter, called the i-ameter and denoted by d/sub i/(G), of a graph G=(V,E) is the length of the shortest Steiner tree that can be established between any i nodes in G. This generalized notion of diameter allows the computation of the communication cost for any number of nodes, in a given network. Exact values of the i-ameter are computed for complete binary trees and the k-ary trees. For other networks, exact values of i-ameter are given for smaller values of i, and bounds are given for higher values.",
Prediction of software reliability using feedforward and recurrent neural nets,"The authors present an adaptive modeling approach based on connectionist networks and demonstrate how both feedforward and recurrent networks and various training regimes can be applied to predict software reliability. They make an empirical comparison between this new approach and five well-known software reliability growth prediction models using data sets from 14 different software projects. The results presented suggest that connectionist networks adapt well to different data sets and exhibit better overall long-term predictive accuracy than the analytic models. This observation is true not only for the aggregate data, but for each individual item of data as well. The connectionist approach offers a distinct advantage for software reliability modeling in that the model development is automatic if one uses a training algorithm such as the cascade correlation. Two important characteristics of connectionist models are easy construction of appropriate models and good adaptability towards different data sets (i.e., different software projects).","Software reliability,
Recurrent neural networks,
Predictive models,
Accuracy,
Software testing,
Time measurement,
History,
Neural networks,
Computer science,
Aggregates"
A neuro-expert system architecture with application to alarm processing in a power system control centre,"A generic neuro-expert system architecture which can overcome difficulties faced by stand-alone expert systems and artificial neural networks is proposed. It can be applied in various problem domains, such as engineering and fault diagnosis, which require problem decomposition. It is recommended for use in real-time systems. The neuro-expert system architecture can be used at different levels of a power system hierarchy for alarm interpretation and fault diagnosis.",
A CASE environment for parallel programming,"The Linda program builder (LPB), a computer-assisted software engineering (CASE) tool for explicit programming, is presented. It isolates much of the administrative effort in constructing parallel programs, and maintains a program-describing database. This database feeds information to the compiler for optimization, to a visualizer for enhanced program visualization, and to other tools in the environment. The LPB is a window-oriented, menu-based, user-friendly system which provides coordination frameworks for program construction. It also represents an alternative approach to high-level programming languages.",
New algorithms for the FFT computation of symmetric and translational complex conjugate sequences,"A previously proposed algorithm for the FFT (fast Fourier transform) computation of real symmetric and antisymmetric sequences reduced the N-point symmetric FFT computation to a N/4-point complex FFT computation, but the postprocessing involved division by sin(2 pi k/N). For large size N, this may cause stability problems. An algorithm is presented which overcomes the problem for real symmetric and antisymmetric data sequences. A similar algorithm is given for the translational complex conjugate symmetric data sequence.",
A Network Simulation of Thalamic Circuit Operations in Selective Attention,"The ability of a thalamic circuit to process information selectively from a spatial location was investigated in neural network models. Starting with the known general structure of the thalamic circuit, we considered three variations of the projections from the inhibitory cells of the reticular nucleus onto the cells of the pulvinar nucleus of the dorsal thalamus. The three circuits were modeled as systems of difference equations, and their operations were simulated by computer-based numerical integration. In all three circuits, when input from a target location was slightly larger than the input from neighboring locations, the time evolution of principal (relay) cell outputs showed substantial selective enhancement at the target location compared with neighboring locations. The selective enhancement effect was produced not only on ascending inputs but also on descending cortical inputs. Simulations separating the lateral inhibitory and feedback-enhancement components of the circuits suggested that the feedback-enhancement component substantially magnified the ability of lateral inhibition to produce a target/surround difference.",
Rattlesnake: A Network for Real-Time Multimedia Communications,,
Variable precision representation for efficient VQ codebook storage,"In vector quantization (VQ) with fast search techniques, the storage available limits the number of codevectors used in VQ. Variable precision representation (VPR) is a simple codebook compression scheme. VPR for each vector y stores the number e(y), the number of leading bits which are zero in all elements, and avoids storing those leading bits. When storing the difference of codevectors in a binary tree structured VQ codebook, VPR can save from 24% to 44% in storage. Storing the codevector difference removes the redundancy between similar codevectors. Also as the mean square error of the VQ encoder is lowered, on the average, the difference becomes smaller and yields to better compression. To process vectors in VPR format, the operator uses a bit-serial, element-parallel scheme to evaluate the inner product. The operator's throughput can be increased by replicating its core.",
Parallel radix 4 FFT algorithms on an eight-neighbor processor array,Hardware algorithms for one-dimensional fast Fourier transform (FFT) computation on an 8-neighbor processor array are presented. These algorithms achieve high-speed FFT computation by combining the radix 4 butterfly computation with the communication capabilities of the 8-neighbor processor array. Three algorithms are considered. Two data mapping methods and algorithms are shown: the algorithm for similarity allocation and the algorithm for superposition allocation. The radix 4 and the radix 2 FFT algorithms are compared and evaluated.,
High-speed Image Processor For The Extraction Of 3-D Depth Information From Image Sequence,,
Recovery of Close-to-Nominal Pre-Fault Performance Using the Pseudo-Inverse/Eigenstructure Assignment Method,"A method for recovering close-to-nominal pre-fault performance of a dynamical system is presented. This method, based on the pseudo-inverse of the control matrix and the eigenstructure method of design, is not iterative and therefore should prove quite useful for on-line control restructuring applications. The method presented here guarantees stability of the closed loop restructured system.",
"Construction and parameterization of all static and dynamic H/sub 2/-optimal state feedback solutions, optimal fixed modes and fixed decoupling zeros","The authors consider an H/sub 2/ optimization problem via state feedback. The problems dealt with are of general singular type which have a left invertible transfer matrix function from the control input to the controlled output. This class subsumes the regular H/sub 2/ optimization problems. The authors construct and parameterize all the static and dynamic H/sub 2/ optimal state feedback solutions. Moreover, all the eigenvalues of an optimal closed-loop system are characterized. All optimal closed-loop systems share a set of eigenvalues called the optimal fixed modes. Every H/sub 2/ optimal controller must assign among the closed-loop eigenvalues the set of optimal fixed modes. This set of optimal fixed modes includes a set of optimal fixed decoupling zeros which shows the minimum absolutely necessary number and locations of pole-zero cancellations present in any H/sub 2/ optimal design. It is shown that both the sets of optimal fixed modes and optimal fixed decoupling zeros do not vary depending upon whether the static or the dynamic controllers are used.",
Scalability analysis of partitioning strategies for finite element graphs: a summary of results,"The authors present a scalability analysis of three partitioning strategies, namely striped partitioning, binary decomposition, and scattered decomposition. The analysis is performed using the Isoefficiency metric, which helps in predicting the performances of these schemes on a range of processors and architectures. The performance of each of these schemes is related to the various problem characteristics such as mesh geometry and density. Isoefficiencies are presented for hypercube and mesh connected architectures. Theoretical results are verified through simulations.",
An integrated approach to fault tolerance,"Describes Manetho, an experimental protocol system, whose goal is to explore the extent to which transparent fault tolerance can be added to long-running distributed applications. Transparent techniques are attractive because they can automatically add fault tolerance to existing applications that were written without consideration for reliability. Previous techniques for providing transparent fault-tolerance relied on rollback-recovery. However, rollback recovery is not appropriate for server processes where the lack of service during rollback is intolerable. Furthermore, rollback-recovery assumes that a process can be restarted on any available host. As a result, extended downtime cannot be tolerated for example in file servers, which have to run on the host where the disks reside. Manetho solves these problems with an integrated approach by using process replication for server processes and rollback-recovery for client processes.",
On the complexity of two circle strongly connecting problems,"Given n demand points in the plane, the circle strongly connecting problem (CSCP) is to locate n circles in the plane, each with its center in a different demand point, and determine the radius of each circle such that the corresponding digraph G=(V, E), in which a vertex nu /sub 1/ in V stands for the point p/sub i/, and a directed edge ( nu /sub i/, nu /sub j/) in E, if and only if p/sub j/ located within the circle of p/sub i/, is strongly connected, and the sum of the radii of these n circles is minimal. The constrained circle strongly connecting problem is similar to the CSCP except that the points are given in the plane with a set of obstacles and a directed edge ( nu /sub i/, nu /sub j/) in E, if and only if p/sub j/ is located within the circle of p/sub i/ and no obstacles exist between them. It is proven that both these geometric problems are NP-hard. An O(n log n) approximation algorithm that can produce a solution no greater than twice an optimal one is also proposed.",
Splitting And Merging: An Approach To Disjunctive Concept Acquisition,,
A model for dataflow computations: result sharing and its performance evaluation,While the dataflow model of computation is a popular way to model concurrent processing it ignores the potential for fast and efficient problem solving which is possible with the reuse of past computational results (result sharing). The concurrent processing and result sharing aspects in problem solving have been integrated into a unified scheme called concurrent processing with result sharing (CPRS) model (1987). In the current paper the CPRS model and the notion of CPRS decomposition based on problem dynamics are presented. The feasibility of the model is demonstrated by developing a dynamic dataflow architecture called the CPRS architecture. A simulation study of this architecture is used to evaluate its performance for solving realistic applications.,"Computational modeling,
Problem-solving,
Computer architecture,
Concurrent computing,
Time sharing computer systems,
Application software,
Dynamic programming,
Circuit simulation,
Computer simulation,
Large-scale systems"
Path planning: an approach based on connecting all the minimizers and maximizers of a potential function,An improved potential-based method for robot path planning is developed by connecting all the local minima and local maxima of the potential function defined in the configuration space of the robot. The authors construct an adjacency graph of the local minima and maxima of the potential function. An edge connecting a local minimum and a local maximum has an associated pair of perturbations which gives a way of moving between them. The method is based on the stability theory of dynamical systems. The usefulness of the method was demonstrated on a two-dimensional piano mover's problem with three degrees of freedom.,
Neural networks applied to the collagenous disease Osteogenesis imperfecta,"Osteogenesis imperfecta is a serious disease which causes bones to be abnormally brittle, and thus, easily broken. It occurs when there is a mutation in the primary sequence of type I collagen. It varies in clinical representation including lethal and non-lethal forms. Severity of the disease appears to be dependent on the type of mutation in the genes COL1A1 and COL1A2. In an attempt to understand the clinical phenotypes of Osteogenesis imperfecta, the authors began an examination of the tertiary structure and primary sequence of collagen type I. The primary sequence of collagen type I was examined to look for neighborhood differences which might lead to specific phenotypes of the disease. Simple patterns were derived and tested. Representation schemes for use with a neural network were found and tested to try to discern the difference between the simplest classification of lethal and non-lethal clinical phenotypes.",
A framework for process maintenance (software),"The authors present a framework, called the process cycle, which can assist in supporting and controlling process maintenance. The process cycle incorporates engineering management, performance, and improvement of processes by human agents subjected to desirable goals and policy constraints. Process maintenance is supported by incorporating feedback cycles so that processes, goals, and policies can be assessed and improved. In particular the authors address the identification of the reasons why processes change, the overall process change process, and the issue of policy improvement. Furthermore, they assess the applicability of the process cycle framework by relating it to current process maintenance practices. It is pointed out that an implication of using the process cycle for process maintenance is that there is a clear logical separation of concern in the various roles played by people, tools used, activities carried out, goals, and policies specified.",
Layout algorithms for DFD processors,Presents two algorithms that are useful for integration into CASE tools that support data flow diagrams (DFDs). They provide the means to relieve the user of the tedious task of making layout decisions by automating some of these decisions. The automatic layout algorithm yields to achieve a neat layout of the objects in a data flow diagram. The incremental placement algorithm adopts the layout algorithm and find its place in application like the replacement of a process object in a diagram with its child diagram.,
Detection of multiple faults in CMOS circuits using a behavioral approach,"Presents an approach for the detection of multiple stuck-open (SOP) and stuck-on (SON) faults in CMOS combinational logic circuits. It is proved that multiple SON and SOP faults do not mask each other. This is achieved using a behavioral analysis in which the maskable fault patterns are proved to be impossible. New testing approaches are proposed. Testing is implemented using a combination of two-pattern test sequences as well as universal test sets, as proposed in previous papers by different authors.",
Escaping the disk bottleneck in fast transaction processing,"An approach to avoiding the disk access bottleneck for transaction processing applications is described. The approach is based on the use of primary copy replication, and takes advantage of recent hardware advances such as inexpensive high-speed CPUs and networks, and uninterruptable power supplies. In addition to improving response time, the architecture increases overall availability and reliability. The work described is in a preliminary stage. The overall architecture and its motivation are discussed. File system techniques in the context of transaction processing are reported.",
An approach to multilanguage persistent type system,"One important concept established through research of persistent programming languages is orthogonal persistence. The techniques so far proposed for this concept are, however, limited to single language systems. This paper proposes a systematic method to achieve orthogonal persistence in a multilanguage system by combining a technique for higher-order remote procedure calls and a mechanism of orthogonal persistence in a single language system. The proposed method can be used to develop a multilanguage persistent type system, where any data of any types including higher-order functions can persist and can later be used from a different language. The necessary data conversion between languages is transparent to the user. In addition to an effective algorithm to implement a multilanguage persistent system, the authors system has rigorous type discipline and formal properties that enable them to show that multilanguage sharing preserves the intended semantics of persistent data.",
Lower bounds on the depth of monotone arithmetic computations,"Consider an arithmetic expression of length n involving only the operations (+,*) and non-negative constants. The authors prove lower bounds on the depth of any binary computation tree over the same set of operations and constants that computes such an expression. In their main result they exhibit a family of arithmetic expressions that requires computation trees of depth at least 1.5 log/sub 2/n-O(1). The authors also consider the family of arithmetic expressions defined by alternating 5-3 trees. For this family they show a tight bound of 5/(log/sub 2/15)log/sub 2/n+O(1) on the depth of any computation tree. This is the best known tight bound for any family of arithmetic expressions.",
Computational science experiences on the Intel Touchstone DELTA supercomputer,"Argonne National Laboratory's involvement in the Concurrent Supercomputing Consortium-the consortium that owns and operates the Touchstone DELTA System-has been motivated primarily by the need to make high-performance computing resources available to its computer science research groups and to those researchers using large-scale computation in their scientific work. Since early May 1991, when the Touchstone DELTA System (DELTA) was first installed at Caltech, Argonne has been actively using it to investigate a variety of scientific problems. In the present work, the author describes some experiences and progress in global climate modeling, computational biophysics, and computational quantum chemistry. He also draws some conclusions regarding the usability of machines like the DELTA.",
Context driven call: principles,"Context driven call (CDC), which allows the user to squeeze from the distributed system as much parallelism as possible, but without using new language constructions and without developing special parallel algorithms, is proposed. CDC is based on the client/server model, but the server can perform operations on client's behalf in parallel with the operations done by the client itself. The central abstraction in CDC is the remote object, which is a capsule with two elements: object state and object value. Permitting a weak dependency between the local and the remote object values, CDC provide more parallelism. By supporting strong object state consistency, it ensures proper concurrency control. The CDC application is a priori divided into two parts: a client, which is an executable program, and the corresponding application stub pool (ASP), which is a library. ASP consists of stubs that perform remote operations on the client's behalf. Compiling the ASP on the server's machine and loading it in bind time to the server, the client is able to customize the server for its own requirements.","Object oriented modeling,
Application specific processors,
Parallel processing,
Parallel algorithms,
Servers,
Informatics,
Bismuth,
Computer science,
Concurrency control,
Libraries"
The object-oriented advantage in prototyping a remote file system,"The authors have prototyped a remote file system for the Choices object-oriented operating system that permits the caching strategy to be user selectable on a per file basis. Choices provides a convenient object-oriented toolkit for building file systems, which they employed, reusing code whenever possible. The client provides the driving force in the architecture. The server maintains a small cache, fulfills requests, and performs callbacks. The client supports both whole file caching and block caching. Only the client needs to be aware of the type of caching being used for a particular file. Different clients can provide different caching strategies at the same time but the data within a client it is kept consistent. The server and client cooperate to maintain the consistency of the file system via callbacks. Because of the object-oriented architecture of the Choices file system they were able to prototype the system in approximately 6 weeks. There was a significant amount of code reuse.",
Static representation of speech dynamics for isolated word recognition,"A static model (SM) in the form of a single vector is proposed to represent the temporal properties of a sequence of speech feature vectors. In contrast to a hidden Markov model which captures the conditional probabilities of state transitions of consecutive observations x/sup to //sub t/ and x/sup to //sub t+1/ over time, an SM captures their average joint probabilities of belonging to a pair of phonetic classes omega /sub i/ and omega /sub j/ without any Markovian assumption. SM is tested with isolated words derived from the TIMIT database as well as artificially created words. The vocabulary is a subset of TIMIT consisting of 21 words derived from the two 'sa' sentences spoken by 420 speakers. The artificial vocabulary of 10 words is designed to study the limitations of SM. Experimental results indicate that apart from a rather mild limitation of SM in handling a certain type of vocabulary, SM actually performs better than baselined continuous hidden Markov models (CHMM) in terms of recognition rate as far as isolated word recognition is concerned, and it takes only 60% of the time needed by CHMM in recognition.",
The expressive power of multi-parent creation in monotonic access control models,"Formal demonstration of equivalence or nonequivalence of different security models helps identify the fundamental constructs and principles in such models. The authors demonstrate the nonequivalence of two monotonic access control models that differ only in the creation operation for new subjects and/or objects; in particular, they show that single-parent creation is less expressive than multi-parent creation in monotonic models. The paper also demonstrates that in nonmonotonic models, multi-parent creation can be reduced to single-parent creation, thereby neutralizing the difference in expressive power. The nonequivalence proof is carried out on an abstract access control model, following which the results are interpreted in standard formulations. In particular, they apply the results to demonstrate nonequivalence of the schematic protection model (SPM) and the extended schematic protection model (ESPM). They also show how the results apply to the typed access matrix model (TAM).",
Optimal group diagnosis procedures for VLSI/WSI array architectures,"Addresses the problem of partitioning VLSI/WSI (wafer scale integration) array architectures into disjoint maximal diagnosis blocks (MDBs) and finding an optical group diagnosis policy for testing and locating faulty elements (modules) in these MDBs. The optimization criterion is to minimize the accumulated diagnosis cost in deriving a feasible reconfiguration solution. The technique for partitioning an array is based on the parallel partition approach. The problem of finding an optimal group diagnosis procedure is modeled as a (t+1)-ary decision tree, where t is the size of an MDB. Instead of dealing with a (t+1)-ary decision tree directly, the problem is further reduced to that of handling a binary decision tree or a block-walking representation. Properties related to the group diagnosis procedures and binary decision trees are derived. Simulation results are provided to further support the effectiveness of the proposed approach over other approaches.",
"Integrated computer-aided software engineering (CASE): adoption, implementation, and impacts","The introduction of integrated computer-aided software engineering (CASE) is beginning to have significant impact on business and information systems organizations. With integrated CASE, IS organizations can develop better quality systems faster to support critical business processes and to assist the development and marketing of information-intensive products and services. The paper first describes a technical architecture for integrated CASE. Then, an innovation process model is proposed to provide explanations and strategies for the adoption, selection, adaptation, implementation, and impacts of integrated CASE. Future research and development on integrated CASE are discussed.",
Transversality theorem: a useful tool for establishing genericity,"It is demonstrated, by way of examples in linear algebra and control, optimization, and geometry, that the transversality theorem of differential topology is a very useful tool for establishing the genericity of a property which is dependent on a finite number of real parameters and which is expressible using a system of nonlinear equations. Some of the results derived are nontrivial to establish by direct means without resorting to the use of the transversality theorem.",
Discrete neural networks and fingerprint identification,"The author has developed a general method for discretization of feedforward neural networks and has empirically demonstrated the usefulness of the method by successfully applying it to the nontrivial task of fingerprint identification. Surprisingly, the discrete neural network (DNN) developed in this way demanded just 4 b for the table representation of the sigmoid function, and only 6 b for the representation of the matching discrete solution. It is clearly shown that there is no significant difference in the performance on the test set between the real neural network and the DNN. Thus, it is concluded that the discretization methods proposed have shown themselves to be realistic.",
The benefits of service rebalancing,"Service rebalancing, which provides a way to determine an efficient division of effort between a client and its server, is introduced. Decisions concerning this division of labor are made at runtime rather than at design time. Evaluating the current environment in which the client and server are executing and moving mode between client and server based on this evaluation can enhance the performance of client/server programs. The advantages of service rebalancing include the elimination of a static division between client and server, on-the-fly updating of modules, load balancing, sharing of common code between multiple clients, and the enforcement of neatly modularized programming. Some of the problems and issues related to service rebalancing, including equanimity and the current status of the work, are discussed.",
CADDY: a highly integrated environment to support conceptual database design,"The authors describe the development of the computer-aided software engineering (CASE) environment CADDY (computer-aided design of nontraditional databases), which offers an integrated set of tools for specifying, analyzing, and prototyping a database application on a conceptual level. The development process consisted of a sequence of development steps, where each step corresponded to one of five main tasks. These five tasks are described. Remaining questions about the CADDY environment are discussed.",
Polarization Characteristics of Bianisotropic Materials,,
Manipulabilities Of Serial-parallel Manipulator Systems,,
Operational construction of integrity constraints,"Shows that data and knowledge base integrity constraints can be regarded as queries. This allows the author to use his visual query language Vizla for the construction of constraints in an operational style. The primary tool for this is the Vizla filter, which lets through only those elements of a set that satisfy a filter predicate. The main contribution of the paper is a method of using filter predicates as constraints, but fuzzy integrity constraints are also considered.",
The Lambda time slot permuter: a bit-controlled time slot permuter,"The authors formulated a general method for constructing time slot permuters from spatial permutation networks. Using the method, they constructed a new time slot permuter, the Lambda time-slot permuter. The Lambda time slot permuter is obtained from the bit-controlled, self-routing permutation network, the Lambda network. While the Lambda time slot permuter requires more hardware than the time slot permuter based on the Benes network described by S.V. Ramanan et al. (1990), its control is very simple. In the Lambda time slot permuter, a single bit from the destination tag in the first of a pair of time slots entering an exchange element is used as the control bit so that the switch setting can be done before the second time slot arrives; thus, it is possible that the switch setting does not incur any delay. The Lambda time slot permuter is suitable for a class of applications where on-the-fly control of the time slot permuter is important, and is especially efficient for a pipelined operation.",
Robust Linear Quadratic Designs with Respect to Parameter Uncertainty,"We derive a linear quadratic regulator which is robust to parametric uncertainty, by using the overbounding method of Petersen and Hollot. The resulting controller is determined from the solution of a single modified Riccati equation. We show that when applied to a structural system, the controller gains add robustness by minimizing the potential energy of uncertain stiffness elements, and minimizing the rate of dissipation of energy through uncertain damping elements. We are also considering a worst-case disturbance in the direction of the uncertainty. Finally, we prove that we have increased performance robustness with the robust LQR when compared to a mismatched LQR design where we design the controller on the nominal system, but apply it to the actual uncertain system.",
ACTA: a comprehensive transaction framework for extended transactions,"Summary form only given. Although powerful, the transaction model adopted in traditional database systems is found lacking in functionality and performance when used for new applications, such as CAD/CAM, and design environments. Various extensions to traditional transaction model have been proposed to address these drawbacks. In order to analyze these ad hoc extensions and in search for a good implementation support for the new applications, the authors have developed a comprehensive transaction framework, called ACTA. ACTA characterizes the semantics of interactions in terms of different types of dependences between transactions and in terms of transactions' effects on objects.<>",
Interpolative robot control with the nested network approach,"A nested network method is presented for learning functions of high dimensions. The method, which is derived from the split-and-merge algorithm, creates a representation at multiple levels of coarseness from randomly distributed learning samples, and thus exhibits both fast and accurate learning. It is applied to learning the inverse kinematics in a three-degree-of-freedom pick-and-place problem. Without the need for building a model of the environment, the preprocessed sensor data is mapped onto joint displacements that must move the robot manipulator to the target object. Learning samples are obtained without a model of the manipulator. Instead the mapping from joint motion to camera motion is measured and taught directly to the nested network. A nested network method based on search trees adapts in real-time and reaches a grasping precision of up to 1-mm in only three steps.",
Protecting replicated objects against media failures,"Presents a replication control protocol that provides excellent data availabilities while guaranteeing that all writes to the object are recorded in at least two replicas. The protocol, robust dynamic voting (RDV) accepts reads and writes as long as at least replicas remain available. The replicated object remains inaccessible until either the two last available replicas recover or one of the two last available replicas can collect the votes of a majority of replicas. The authors evaluate the read and write availabilities of replicated data objects managed by the RDV protocol and compare them with those of replicated objects managed by majority consensus voting, dynamic voting and hybrid dynamic voting protocols. They show that RDV can provide extra protection against media failures with no significant loss of availability.",
IBC: A Working Tool for Robust Parametric Identification,In this paper. we explore the utility of Information-Based Complexity (IBC) for control-oriented robust parametric identification in the presence of noisy data. In addition. we show that a number of IBC algorithms and their associated worst-case errors are computable by means of vertex optimization.,
A connectionist approach to text-phonemics translation using syntactic neural networks,"A self-organizing connectionist scheme for text-phonemics translation, capable of conversion in either direction, is described. It consists of two cross-coupled syntactic neural networks, one acting as a parser in one symbol domain and the other as a generator in the other domain. No prior alignment of graphemes with phonemes is necessary-only presentation of whole-word orthographic-phonemic pairs. Results are presented for English text-to-phonemics translation and vice versa, with the system trained on a sample of up to 2000 word pairs and tested both on the training set and an equal-sized disjoint test set. Translation accuracy is assessed as a function of language-sample size and of network size, and performance is compared with that of other connectionist text-to-speech systems. Although not currently competitive with traditional, rule-based techniques, the connectionist approach is considerably less labor-intensive.",
A high level framework for developing DSS workbenches,"The term 'DSS workbench' (DSSW) is open to wide interpretations. Though the author fully subscribes to the view that such diversity is healthy, enriching and highly desirable during the early stages of concept formulation, he also believes that it is critical to have higher level frameworks for organizing and integrating the diverse thoughts, and for making judicious choices regarding research priorities and directions. In the interest of addressing this need, this paper examines the design space of DSS workbenches, presents a high level framework for building them, and discusses its implications.",
Determining longest common subsequences of two sequences on a linear array of processors,This paper presents special-purpose linear array processor architecture for determining longest common subsequences (LCS) of two sequences. The algorithm uses systolic and pipelined architectures suitable for VLSI implementation. The algorithms are also suitable for implementation on parallel machines. The author first develops a 'greedy' algorithm to determine some of the LCS and then proposes a generalization to determine all LCS of the given pair of sequences. Earlier hardware algorithms were concerned with determining only the length of LCS or the edit distance of two sequences.,
"CAL and CAD Software for Microwave Education, Engineering and Related Applications","A program package called ""Electromagnetic Waves"" in seven parts has been developed. It is intended for computer aided learning (CAL) with widely making use of animated graphics of fields and waves which are simulated during the study.",
Fault-tolerant concurrent branch and bound algorithms derived from program verification,"One approach for providing fault tolerance is through examining the behavior and properties of the application and deriving executable assertions that detect faults. This paper focuses on transforming the assertions of a verification proof of a program to executable assertions. These executable assertions may be embedded in the program to create a fault-tolerant program. It is also shown how the natural redundancy of the program variables can be used to reduce the number of executable assertions needed. While this approach has been applied to the sequential programming environment, the distributed programming environment presents special challenges. The authors discuss the application of concurrent programming axiomatic proof systems to generate executable assertions in a distributed environment using distributed branch and bound as a model problem.","Fault tolerance,
Testing,
Fault detection,
Computer science,
Redundancy,
Performance evaluation,
Programming environments,
Runtime environment,
Message passing,
Sun"
Performance Evaluation of Integrated Services Dqdb and Fddi Networks,,
Robust shape analysis using multistrategy learning,"This paper describes how to integrate subsymbolic and symbolic processes in order to create high-performance shape analysis systems. The specific methodology introduced integrates morphological processing and machine learning techniques such as genetic algorithms (GAs) and empirical inductive generalization. The optimal operators (defined as variable morphological structuring elements) evolved by GAs are used to derive discriminant feature vectors, which are then used by empirical inductive learning to generate rule-based class description in disjunctive normal form. The rule-based descriptions are finally optimized by removing small disjuncts in order to enhance the robustness of the shape analysis system. Experimental results are presented to illustrate the feasibility of the methodology for discriminating among classes of arbitrarily shaped objects, for learning the concepts of convexity and concavity, and for building robust recognition methods.",
Learning capabilities of recurrent neural networks,"The author relates the power of recurrent neural networks to those of other conventional models of computation like Turing machines and finite automata, and proves results about their learning capabilities. Specifically, it is shown that (a) probabilistic recurrent networks and probabilistic Turing machine models are equivalent; (b) probabilistic recurrent networks with bounded error probabilities are not more powerful than deterministic finite automata: (c) deterministic recurrent networks have the capability of learning P-complete language problems; and (d) restricting the weight-threshold relationship in deterministic recurrent networks may allow the network to learn only weaker classes of languages.",
A Modularized Approach To CIM Education,,
"Comments, with reply, on ""Extensions to SQL for historical databases"" by N.L. Sarda","The commenters point out that the author of the above-titled paper (see ibid., vol.2, p.220-30, 1990) failed to acknowledge their contemporary publications of almost identical results and the subsequent, comprehensive refinement of this work. The author replies that he did not have access to their publications. He indicates some differences between their work and his.",
Centralized surveillance of high risk births,"Ultrasonography and cardiotocography are the most widely used diagnostic tools for evaluating foetal stress. We aim to integrate both in a versatile, obstetric monitoring system giving immediate access to processed numerical and alphanumeric data, graphs and images. System resource and task management will be carried out at the top level by a task-sequencing expert system that will enable/disable monitoring, signal processing and display functions, and distribute them among the patients, in accordance with hierarchical task and diagnostic protocol schemes.",
Amplification of the functional closure operation,A novel type of closure on the set of all finitary operations on a finite universe is introduced. It is known that the traditional closure generates a continuum structure of closed sets. The problem of which closures admit only finitely many closed sets is studied.,
Sensitivity and Complementary Sensitivity Integrals Applied to a Class of Ill-Conditioned Plants,"We consider a standard robust performance problem for two input, two output diagonal systems. By using the classical sensitivity integral together with an analogous result for the complementary sensitivity function, we derive an upper bound that the plant condition number must satisfy if robust performance is to be achievable. The upper bound is given in terms of the weighting functions used to represent the design specifications.",
The Time-constrained Barrier Synchronizer and its Applications in Parallel Systems,"A barrier synchronizer, allowing processors to participate dynamically by letting them register their intent to participate within a timeout period, is presented. The synchronizer allows some applications - like software combining and highly concurrent queue operations - to be implemented in a rather unconventional but highly efficient manner. The barrier synchronizer generates successive time windows, allowing requests within the same window to be combined, thus ensuring a more-or-less fixed latency for the Fetch-and-Op primitive.","Application software,
Computer science,
Registers,
Delay"
Decidable problems in shallow equational theories,"Results for syntactic theories are generalized to shallow theories. The main technique used is the computation by ordered completion techniques of conservative extensions of the starting shallow presentation which are, respectively, ground convergent, syntactic, and cycle-syntactic. In all cases, the property that variables occur at depth at most one appears to be crucial. shallow theories thus emerge as a fundamental nontrivial, union-closed subclass of equational theories for which all important questions are decidable.",
CCHIME: a cache coherent hybrid interconnected memory extension,This paper presents a hybrid shared memory architecture which combines the scalability of a multistage interconnection network with the contention reduction benefits of coherent caches. The authors achieve this by replacing the memory modules and final stages of a multistage interconnection network with clusters of coherent caches. The performance of Cache Coherent Hybrid Interconnected Memory Extension (CCHIME) is evaluated by analyzing the results of extensive simulations of the network and coherent cache clusters. These results indicate that the CCHIME architecture can achieve lower memory access latencies and higher throughputs than typical multistage interconnection networks.,
Maximum and minimum matchings for series-parallel networks,"Series-parallel networks are often used as models for electric circuits. The authors use series-parallel graphs to represent series-parallel networks. Since, there are many different graph representations for a series-parallel networks, they are interested in studying maximum matching in different graph representations of a single network. The number of edges in a maximum matching of G is called the edge independence number of G ad denoted by beta (G). For a network N, the maximum matching number, beta (N), is defined to be max( beta (G(N))) where G(N) is a graph representation for N. The minimum matching number, beta *(N), is defined to be min( beta (G(N))). The authors present linear time algorithms to compute beta (N) and beta *(N) for any series-parallel network N.",
Electromagnetic Interactions with Cementious Materials,,
"Reversible Agents Need Robots Waste Bits To See, Talk, And Achieve?",,
User Response Time Optimization in a Metropolitan Area Network a Concept,,
"References, local variables and operational reasoning","A.R. Meyer and K. Sieber (Proc. 15th ACM. Symp. on Principles of Programming Languages, 1988, p.191-208) gave a series of examples of programs that are operationally equivalent (according to the intended semantics of block-structured Algol-like programs) but are not given equivalent denotations in traditional denotational semantics. They propose various modifications to the denotational semantics that solve some of these discrepancies, but not all. The present authors approach the same problem, but from an operational rather than a denotational perspective. They present the first-order part of a new logic for reasoning about programs, and they use this logic to prove the equivalence of the Meyer-Sieber examples.",
An object-based approach to the specification of applications for office support systems,"The design of a specification methodology for office systems is described. In particular, the authors discuss the desired properties of a computational model upon which a specification methodology for office systems should be based. An overview of ABSL, a specification language that they developed, is presented. The central concept in ABSL is an object which is the principal mechanism for representing the data and computations. The design of ABSL is based on the formal theory of the actor model. The actor model is chosen because not only it captures the abstract power of object-orientation paradigm, but provides as well a mathematically precise abstract machine for analysis of asynchronous and concurrent computations.",
Learning probabilities for causal networks,"The author presents an unsupervised method to learn probabilities of random events. Learning is done by letting variables adaptively respond to positive and negative environmental stimuli. The basic learning rule is applied to learn prior and conditional probabilities for causal networks. By combining with a stochastic factor, this method is extended to learn probabilities of hidden causations, a type of event important in modeling causal relationships. In contrast to many existing neural network learning paradigms, probabilistic knowledge learned by this method is independent of any particular type of task. This method is especially suited for acquiring and updating knowledge in systems based on traditional artificial intelligence representation techniques.","Neural networks,
Stochastic processes,
Artificial intelligence,
Backpropagation,
Inference mechanisms,
Probability,
Computer science,
Marine vehicles,
Artificial neural networks,
Bayesian methods"
A divide and conquer approach to shortest paths in planar layered digraphs,"The authors give efficient parallel algorithms to compute shortest-paths in planar layered digraphs. They show that these digraphs admit special kinds of separators, called one-way separators, which allow paths in the graph to cross them only once. They use these separators to give divide-and-conquer solutions to the problem of finding the shortest paths. They first give a simple algorithm that works on the CREW (concurrent-read exclusive-write) PRAM (parallel random-across machine) model and computes the shortest path between any two vertices of an n-node planar layered diagraph in time O(log/sup 3/ n) using n/log n processors. A CRCW (concurrent-read concurrent-write) version of this algorithm runs in O(log/sup 2/ n log log n) time and uses O(n/log log n) processors. The authors then improve the time bound to O(log/sup 2/ n) on the CREW model and O(log n log log n) on the CRCW model. The processor bounds still remain n log n for the CREW model and n/log log n for the CRCW model.",
Shortest m-watchmen routes for histograms: the minmax case,"The authors consider the problem of computing an optimum set of watchmen routes in a histogram. A watchman, in the terminology of art galleries, is a mobile guard and in this version one wants to minimize the length of the longest route in the solution. The authors give an O(n/sup 2/ log n) time algorithm to compute the MinMax optimum set of m watchmen in a histogram polygon.",
Fusing of immunoscintigraphy SPECT with CT or MRI for improved multimodality image interpretation,"Correlation of PET or SPECT functional with CT or MRI anatomic transaxial images often enhances the information available on these studies. Careful registration of images from two types of studies may be used to identify a structure containing to a PET or SPECT abnormality or to evaluate the functional or metabolic characteristics of an abnormal or normal structure. CTSPECT or PET image registration has been applied to brain imaging for metabolic and cerebral perfusion studies [13], more recently, to Ga-67 imaging of the chest [4], as well as to CT-SPECT correlation in cancer patients undergoing immunoscintigraphy [57]. We have applied an image registration technique to correlate CT or MRI of the abdomen and chest with SPECT images obtained after the administration of tumor-directed radiolabeled monoclonal antibodies. Correlation of PET or SPECT functional with CT or MRI anatomic transaxial images often enhances the information available on these studies. Careful registration of images from two types of studies may be used to identify a structure containing to a PET or SPECT abnormality or to evaluate the functional or metabolic characteristics of an attempt to improve our interpretation of these imaging studies.",
Variable-rate coding for meteor-burst communication using punctured convolutional codes,"Meteor-burst (MB) communication is an attractive means of beyond line of sight radio communication for many applications. Error control coding provides powerful means for addressing problems posed by the uneven distribution of received power observed with the MB channel. The author considers the use of variable-rate punctured convolutional codes for implementing an adaptive transmission scheme for MB communication. The scheme has been subjected to experimental verification by simulation. The validity of the approach is confirmed: for a given target bit error rate, a substantial improvement in throughput is observed with the adaptive scheme as compared to a fixed coding rate scheme.",
Retrofits to BWR safety and nonsafety systems using digital technology,"The history of safety-related and non-safety-related control systems designed into GE boiling water reactor (BWR) nuclear power stations is reviewed. Design limitations and parts availability for these older designs indicate the need to provide system replacements. Two contemporary digital product lines developed and offered by GE-Nuclear Energy provide system replacements. NUMAC is the safety-related product line and the GE Fanuc product line is used for non-safety-related applications. The resolution of issues encountered in the implementation of digital products in BWR systems such as application, qualification, and operator interface is discussed. The application of GE Fanuc equipment to the non-safety-related recirculation flow control system of a BWR-3 type reactor is discussed in some detail.",
A software environment for programming distributed memory machines,"For efficiency, multiprocessor local memory machines work mostly on the message passing principle, and therefore are programmed using the framework of communicating sequential processes. This programming should be easy to do, and this ease obviously requires an adequate software environment. One such environment, ADAM, is the main topic of the paper. Especially important and time consuming in the development cycle of a distributed application is the debugging phase. Therefore among the tools provided by the ADAM environment, those dedicated to debugging have been emphasized. The most interesting are: a centralized simulator-debugger at the level of the language; a tool based upon traces that enables to see the communication that took place during an execution. The most original part of this work consists of debugging mechanisms dedicated to communication.",
Conditions for a Cayley Coset Graph to Be Simple,,
An Approach To Portable Parallel Programs,,
A feature selection method for multi-class-set classification,A versatile technique for set-feature selection from class features without any prior knowledge for multi-class-set classification is presented. A class set is a group of classes in which the patterns represented with class features can be classified with a existing classifier. The features used to classify patterns between classes within a class set are referred to as class features and the ones used to classify patterns between class sets as set features. A set-feature set is produced from class-feature sets under the criterion of minimizing the encounter zones between class sets in set-feature space. The performance of this technique was illustrated with an experiment on the understanding of circuit diagrams.,
Saliency mapping in associative vision machine,"A very effective measure of saliency, proposed by A. Sha'ashua and S. Ullman (1988), is based on curve length, continuity, and smoothness. Implemented as an iterative process to reduce complexity, it still takes 0.5 s/iteration on the Connection Machine. The authors present an associative algorithm more than three orders of magnitude faster when executed on the ARTVM (Associative Real Time Vision Machine). This is a classical associative architecture, adapted for vision and modular VLSI, that requires a very modest hardware complement (<100 chips).",
Numerical calculation of temperature field for the case of simple convection model in autoclave,"A numerical study of temperature field for the case of 8.5-L autoclave, filled with water, is performed using the iteration method. The natural convection in liquid is assumed to be steady, axisymmetric and laminar. Two thermal steady states of the vessel are considered, with weak cooling and with intense heat exchange between the surroundings and the baffle region. For both states, almost identical local temperatures under the plunger (350 degrees C) and under the bottom of the vessel (390 degrees C) are achieved. The results show several common features for both thermal states. The velocity of water flow is several times higher in the upper than in the lower zone, and a strong concentration of isotherms exists in the interzone region. The radial and axial temperature gradients become greater when additional cooling is applied to the vessel.",
A Study on Physiological Parameter Estimation Accuracy for Tracer Kinetic Modeling with Posttron Emission Tomography (PET),"Tracer kinetic modeling with Positron Emission Tomography requires measurements of the time-activity curves in both plasma (PTAC) and tissue to estimate physiological parameters. Ideally, this PTAC should be the tracer local capillary plasma time-activity curve (CPTAC). However, due to the inaccessibility of direct measurement of CPTAC, the arterial plasma time-activity curve (APTAC) is usually used to replace CPTAC. The range of physiological parameter estimation errors caused by this replacement is not clear yet. In this paper, CPTAC is derived from the APTAC measurement and a 4-compartment PTAC model [2]. This CPTAC is then used to study the effects of using APTAC to replace CPTAC and APTAC measurement errors on the estimation of the physiological parameter. The results show that using APTAC directly in parameter estimation can cause considerable biases and increase the uncertainty of parameter estimation.",
An Interdisciplinary Case Study Program for Technology Students,,
Solving a nonlinear two-point boundary value problem,A two-point boundary value problem (TP-BVP) occurs during the process of solving a single differential equation or a set of differential equations whose solution has to satisfy both the given initial and final boundary conditions. The author shows that zeroing the discrepancy function is the crucial step in solving nonlinear TP-BVPs and uses M.P. Kennedy and L.O. Chua's (1988) neural network model to solve this problem. The advantages of this approach include its suitability for VLSI implementation.,
Fault-tolerant CSP,"In a network of communicating processes performing a distributed computation, one can replicate some or all of the communicating processes on different nodes to increase successful probability of the distributed computation against node failures. The authors use communicating sequential process (CSP) to express this scheme by appropriately translating the commands which communicate with replicated processes. In order to make the translation scheme simple and easy to implement, the order of the replicas are deterministic.",
XDL-the process modelling language for PVC-M,"PVC-M is a process-oriented configuration management system which recognizes (i) loose coupling between data and process models and (ii) the diversity of requirements by software developers and design methodologies that they adopt. The data and process models in PVC-M may communicate: information and control can be passed back and forth between the two. The object-oriented paradigm seems to provide a framework that can facilitate a clean integration of data and process models. The author discusses XDL, PVC-M's dynamically object-oriented process modeling language. XDL can be used to model several real-time, concurrent systems. The base language, SDL, supports nondeterminism.",
Self-checking against formal specifications,"The authors use an algebraic technique of formally specifying a module that implements an abstract data type, with a C/sup ++/ implementation. An explicit mapping from implementation states to abstract values is added to the C/sup ++/ code. The form of specification allows mechanical checking of desirable properties such as consistency and completeness, particularly when operations are added incrementally to the data type. During unit testing, the specification serves as a test oracle. Any variance between computed and specified values is automatically detected. When the module is made part of some application, the checking can be removed, or may remain in place for further validating the implementation. The specification, executed by rewriting, can be thought of as itself an implementation with maximum design diversity, and the validation as a form of multiversion-programming comparison.",
Effect of initial system on homotopy methods for the H/sub 2/ reduced order model problem,"The effects of different initial systems on the efficiency of homotopy methods for solving the H/sub 2/ reduced order model problem was considered. Two major strategies for improving the efficiency are examined. One strategy, which involves solving the initial problem, usually leads to better results, but there is no known method to solve the initial problem for all or a majority of the initial systems. Another strategy, which considers constructing the initial system such that its eigenvalues resemble the eigenvalues of the final system, in some cases is more efficient. Also, a hybrid that combines the two previous strategies is considered. Finally, it is shown by an example that an unwise choice of the initial system can lead to a very inefficient algorithm.",
Is SIMD enough for scientific and engineering applications on massively parallel computers?,"Some basic issues involved in matching an application to a distributed memory parallel machine are addressed. In particular, data communication and processor synchronization as they relate to MIMD (multiple instruction-multiple data) and SIMD (single-instruction-multiple data) architectures are discussed. To illustrate the differences, the authors describe the implementation and performance of several engineering and scientific applications that have been coded for both kinds of machines. They find that many problems are well suited to both architectures. However, when the natural parallelism in a simulation requires a loose synchronization between processors, the MIMD paradigm offers a greater programming flexibility than SIMD.",
Network design and performance for a massively parallel SIMD system,"It is shown that a nearest neighbor communication network can be complimented with a log-diameter multistage network to handle different communications patterns. This is especially useful when the pattern of data movement is not uniform. The designed network is evaluated for two cases: a dense case with many processing elements communicating and a sparse case. For 32-b data, the algorithm for computing partial sums of an array improves by 2.7 times with the multistage interconnection network. In a sparse random case, the number of cycles taken to communicate 32 b is 4000 (with 10% of the nodes communicating). Thus, it is concluded that a network like a multistage omega network is very useful for SIMD (single-instruction multiple-data) massively parallel machines. This is especially true if the machine is to be used for applications where long distance and nonuniform routing patterns are needed.",
Flexible circuit simulation with mixed-domain and mixed-mode applications,"Flexible circuit simulation through user-defined enhancements of traditional circuit analysis algorithms is presented. In particular, enhancements of the DC transfer curve analysis are used for mixed-domain simulation as required in analysis of self-heating effects of GaAs devices while enhancements of time-domain analysis are used for simulation of mixed analog-digital circuits at different levels of abstraction.",
"Overview of the Scalable Coherent Interface, IEEE STD 1596 (SCI)","The Scalable Coherent Interface (SCI) standard defines a new generation of interconnection that spans the full range from supercomputer memory 'bus' to campus-wide network. SCI provides bus-like services and a shared-memory software model while using an underlying packet protocol on many independent communication links. Initially these links are 1 GByte/s (wires) and 1 GBit/s (fiber), but the protocol scales well to future faster or lower-cost technologies. The interconnect may use switches, meshes, and rings. The SCI distributed-shared-memory model is simple and versatile, enabling a smooth integration of highly parallel multiprocessors, workstations, personal computers, input/output, networking, and data acquisition.",
Cell height reduction by routing over-the-cells,"The authors apply the concept of over-the-cell routing to the global routing problem in leaf cell synthesis. A cell layout is divided into 5 routing regions in the model. The global routing problem can be formulated to route those critical net segments over the diffusions or the middle channel such that the overall cell height is minimum. The routing of transmission gates has been a problem because it produces a cyclic constraint in the middle channel. A new routing pattern is proposed which is cyclic free for transmission gate connections. In this approach, tree patterns are generated for each net. Then, the global routing is modeled and solved as an integer linear programming problem. Finally, the detailed routing of the cell layout is completed. All the cell benchmarks were solved in very short time. In comparison with previous results, the approach produced denser layouts.",
The categorical framework of open systems,"One of the major challenges facing today's computer scientists is developing a computer system for an autonomous mobile robot which constantly interacts with its environment, updates its knowledge based including the world model, and carries out tasks specified by humans. This kind of computer system, which is capable of updating its database dynamically and grows along with new components without damaging its integrity, is called an open system. Due to the massive influx of input data the system has to perform computations concurrently. And also human users should be able to interact with the system in the object-oriented fashion. Hence an open system can be described as an object-oriented concurrent system which can accommodate new components. The most fundamental elements of the open system are objects and processes: an object is a human-oriented concept in that humans think of the real world in terms of objects, whereas a process is machine-oriented. A category is introduced as the mathematical model for the system, and objects and processes are precisely defined in the categorical framework.",
High Performance Interconnection Between High Data Rate Networks,,
Application of a modified H- psi method in three-dimensional eddy-current problems,Magnetic field intensity H and scalar magnetic potential psi are used directly in the analysis and computation of 3D eddy-current fields. A functional for H and psi is used. Results show that this method can be used to solve 3D eddy-current fields with greatly reduced computer storage.,
Pseudo-inverse with increasing threshold: an error-recovery pattern recognition algorithm,"A pseudo-inverse algorithm with an increasing threshold value for pattern recognition is presented. This method is particularly useful when the original matrix is not a square matrix. The algorithm and its implementation are studied. Using English capital letters as samples, the error-recovery capability of the proposed algorithm is observed to be better than that of the fixed threshold algorithm. Noisy patterns with 20% errors, i.e., 12 in Hamming distance, can be recognized using this approach.",
Time-variant AR spectral estimation in the study of vasovagal syncope,"The AutoRegressive (AR) spectral estimation is implemented in a recursive way with a forgetting factor w both in the classical RLS form, with a constant w value, and in the Fortescue variant with w changing with time, according to the changing characteristics of the signals. The time-variant AR algorithm is here employed, in the study of heart rate and blood pressure variability signals obtained during syncope episodes. The spectral parameters (LF, HF powers, LF/HF ratio), which are able to quantify the sympatho-vagal balance in the assessing of the heart rate and blood pressure values, are evaluated on a beat-to-beat basis, in order to obtain more information about the role played by the autonomie nervous system during these episodes.",
Applications of visualisation within British Telecom,"The subject of visualisation includes any technique which utilises interactive visual displays as the main means of imparting information to a user. It includes the already widely available numerical data visualisation techniques used in many scientific and engineering fields, together with aspects from newer areas such as telepresence and virtual reality. The improving performance and reducing cost of computer-based graphical systems and the availability of linking telecommunications systems of high bandwidth, all support a trend towards visual working in fields outside of science or engineering. This paper looks at work started in British Telecom in this area, to support information handling activities and to explore future telecommunications service possibilities.",
Generalized compressed tree machines,"Parallel machines interconnecting up to thousands of processors have been proposed and recently built. One of the earliest and the most prominent one is a complete binary tree machine. The authors propose a family of tree machines called generalized compressed tree machines. Generalized compressed tree machines may, in general, be viewed as a derivative of the complete binary tree networks.",
Building network-based interactive media,"It is pointed out that the design of a network-based interactive multimedia application depends on the characteristics of the network, the modes of user interaction and the media types that will be used. Careful selection of these elements in the design process is needed to create successful applications. The characteristics of network-based interactive media applications interact to provide various qualities of service to the user. Several examples of previously built network-based interactive multimedia systems are presented, including a kiosk-based system delivering information about a trade show, a system delivering world news and electronic mail and a system assisting doctors during childbirth.",
Thrifty Technology Mapping With Rich Libraries,"Technology mapping is used during logic synthesis to bind a circuit description to a given library of cells. The mapping process is divided into the phases of decomposition, matching and covering. We have developed a method of matching which is functional in nature, as opposed to the usual structural approach. The new matching technique allows the use of very large libraries. New techniques for decomposition and covering are also described. For circuits with fanout, we propose several heuristics for determining when to share and when to duplicate logic. These heuristics are quantitatively compared using a set of benchmark circuits.",
Authors' reply to comments on 'Pole and zero estimation in linear circuits' by P.E. Gray and J.K. Matchett,"A comment by P.E. Gray and J.K. Matchett (see ibid., vol.38, p.1404, Nov. 1991) on the above-titled paper (see ibid., vol.36, pp.838-845, June 1989) appeared with an errata for the paper, which was mistitled as a reply to their comment. A response to the comment is given here, supporting the accuracy of the pole-zero estimation method that occasioned the comment.",
An algebraic approach to the manipulation of complex objects,"The authors present an algebra (LOA) for complex objects, which has been developed within LOGIDATA+, a national project funded by the Italian National Research Council, as an internal language in a prototype system for the management of extended relational databases with complex object types. The object algebra is a set-oriented manipulation language that plays in the object oriented DBMS the same role as the relational algebra in a relational system. That is providing efficient access to mass storage structures and simplifying query optimization. The algebra refers to a data model that includes structured data types and object identity, thus allowing both classes of objects and value-based relations. The algebra has required extension of the semantics of operators with respect to the nested relation model, and to introduce additional operators for type conversion and OID invention. The paper also briefly discusses the implementation of the primitives of the object algebra in the prototype by means of the operators of the relational algebra.",
Stochastic Petri Nets For Knowledge Representation And Reasoning,,
Historical efforts on R&M integration into engineering curricula,"The author describes what the US Air Force has done to achieve improved R&M (reliability and maintainability). The Air Force has been vitally interested in all graduate engineers becoming knowledgeable of R&M so they will be able to readily include R&M in their designs. It is pointed out that R&M must be designed into new systems as they evolve through the complete design process, and not be attempted as an extra addition or afterthought. Only by having the designer be proficient in the principles and tools of R&M can the final design be successful. The only way for all the designers to have the knowledge of R&M is to include R&M in the design courses within the academic environment. It is noted that the time is here for R&M education to be included in every engineer's education. This does not imply that the education must be increased, or that some items must be eliminated to make room for the R&M principles in design. What is implied is that the measurement of the design is not adequate until the success of the design (R&M) is determined.",
Searching with a lie using only comparison questions,"S.M. Ulam (Adventures of Mathematician Scribner, New York, 1976) presented the following problem. If one person picks a number from one to one million and the other person could ask yes or no questions, how many questions would be required to find the number with certainty if the opponent were allowed to lie once or twice. J. Spencer (Mathematics Magazine vol.57, no.2, 1984) found that by using a weight balancing strategy, if nc' are allowed. However, it will be shown that, by using a somewhat modified algorithm, if n",
A new algorithm for pattern recognition of voices,"An algorithm is developed to distinguish between the speech of male and female. A simple hardware device is devised to implement the algorithm. Various techniques, such as fast Fourier transform (FFT), threshold crossings (TCs), threshold crossings of the derivative of the signal, and sine-wave crossings are used to distinguish between the voices. These techniques are analyzed and compared. The results show that the sine-wave crossings technique is simple to implement, does not need normalization or differentiation of the signal to remove its DC component, and can be used for real time (online) analysis.",
EFRM-based detection and extraction of ridge and valley features in grey level images,Describes a method for locating and extracting ridge and valley (and hence line) features in grey level images. A representation of the image known as the extended facet region model (EFRM) is first formed. The primary grouping constraint in this process is the orientation of patches in the image intensity surface. Inspection of geometric relationships between entities in the EFRM leads to the identification of ridge and valley structures and the subsequent placement of extracted line paths. The structures have knowledge of the local topological form of the image.,
"XFace, an X tool for presenting multivariate data, and its use with software metrics","XFace is a tool for displaying on X devices multivariate data as graphical images called Flury-Riedwyl faces. The tool allows the user to map variables to facial features such as eye size, slant, and position; pupil size and position; eyebrow curvature, density, and position; hair color and line; mouth curvature and size; face line; and nose shape. Symmetric faces support up to 17 variables and asymmetric faces support up to 34 variables. The menu-driven tool was developed in C and uses X Windows with Athena Widgets for portability. The system was developed to display software metrics. A manager may map each module's metrics to a face so that a quick scan determines modules with characteristics that vary from the project norm and which may require attention.",
A synchronization scheme for distributed multimedia information systems,"The authors propose a synchronization scheme for distributed multimedia information systems. The scheme consists of two layer synchronization: inter-stream synchronization and intra-stream synchronization. The inter-stream synchronization layer provides a temporal relationship between media and presents media to the user in the required synchronization fashion. The intra-stream synchronization provides functionality to establish and maintain individual medium connections with some specified synchronization characteristics. The proposed scheme can provide synchronization of media with arbitrary temporal relationships which could be originated from one or more sources on the network. Synchronization is also maintained in the event of user interaction, such as to pause and resume a multi-stream presentation.",
IP addressing and routing in a local wireless network,"IP is the basic protocol in the Internet. The authors explore a variety of possibilities to adapt the wireless environment to that of IP. They describe the requirements and show how these can be accommodated by using the existing IP. At the heart of the problem is the lack of a capability in the current IP routing services to track topological changes. Several alternatives are described, each making use of a different combination of the addressing and routing features offered by IP. The alternatives are compared. The tradeoffs among these alternatives are explored.",
Requirements specification for a real-time embedded expert system for rapid prototyping,"Several commercial expert system shells provide knowledge engineers with the capability of developing expert system applications, but are not able to meet the size constraints or provide the run-time performance needed to address problems associated with delivery of embedded real-time applications. In addition, there is no provision to provide deliverable code in Ada, a requirement for many US DoD systems. The embedded consultant project addresses these issues by knowledge-base size reduction by means of code optimization techniques, and by an inference engine, written in Ada, designed for real-time applications. A new rapid prototyping approach for real-time applications is described. The methodology is based on the reuse of existing software components. The approach, and the significance of the work are discussed.",
Experience at the Massachusetts Institute of Technology (MIT) Laboratory for Computer Science,"The author describes MIT and its Laboratory for Computer Science. He argues that with programming on several hundred advanced workstations and several multiprocessor systems, with construction of hardware prototypes, with industrial partnerships for the construction of systems too ambitious for the Laboratory facilities, and with analytical and theoretical work throughout, the MIT Laboratory for Computer Science is truly a dynamic and inspiring place.",
An expert system for radiological images,"We present an expert system developed to confirm or to assess the presence of a pathology on the basis of morphological data, coming from radiological images. This system is based on object oriented programming. The basis of this system is a lingustic description of the radiological image referred as feature image. We can recognise three different levels of use. The first from a real image to some possible pathologies, the second from some pathologies to a possible expected image, the third, a consultation level on the anatomical region considered. We have tested the system on images of the thorax.",
Neural Network Construction Of Boolean Function Used In Process Control,,
Dynamic testing and diagnostics of digitizing signal analyzers,"A dynamic testing method for evaluating the effective bit number of digitizing signal analyzers is presented. This technique is valid when, owing to particular working conditions, only a limited number of digitizing signal analyzer sampling points can be collected. In such a case existing test methodologies can present problems. The proposed method is based on a regression algorithm and, by employing one and a half periods of the sinewave test signal, requires very short computation time. After a summary of the existing test methodologies, the performance and limits of the method proposed are analyzed. To demonstrate the applicability of the method, preliminary simulation results for several devices and data relative to one particular digitizer are reported.",
Perspectives on massively parallel computation,"The areas of algorithms applications, architectures, and system software are discussed with reference to massively parallel computation.",
Optimistic make (software design),"The notion of encapsulations is introduced as the basic construct used to support optimistic make (a software tool). The authors describe the implementation of optimistic make in the V-System on a collection of SUN workstations. Statistics measured from this implementation are used to synthesize a workload for a discrete-event simulation, and to validate the simulation's results. The simulation shows a speedup distribution over pessimistic make with a median of 1.72 and a mean of 8.28. The speedup distribution is strongly dependent on the ratio between the target out-of-date times and the command execution times. With faster machines the median of the speedup distribution grows to 5.1, and then decreases again.",
Hierarchical message dissemination in very large WANs,A hierarchical broadcasting technique in very large arbitrary networks which achieves near optimal cost and time measures is proposed. The network is partitioned into hierarchical clusters which are interconnected with each other through gate nodes. The approach is based on using a fully distributed minimum spanning tree algorithm within the gate-node network while achieving time optimal broadcasting within the local clusters by formulating the problem as finding maximum matching in constrained bipartite graphs. Extensive simulation results are presented which show the tradeoff between the two conflicting performance criteria.,
The MetaMP approach to parallel programming,"The authors are researching techniques for the programming of large-scale parallel machines for scientific computation. They use an intermediate-level language, MetaMP, that sits between High Performance Fortran (HPF) and low-level message passing. They are developing an efficient set of primitives in the intermediate language and are investigating compilation methods that can semi-automatically reason about parallel programs. The focus is on distributed memory hardware. The work has many similarities with HPF efforts although their approach is aimed at shorter-term solutions. They plan to keep the programmer centrally involved in the development and optimization of the parallel program.",
"A CMOS Resistive-fuse Processor for 2-D Image Acquisition, Smoothing, and Segmentation","An integrated CMOS resistive-fuse processor capable of smoothing out noise while preserving the edges of a 3232 image is described. An on-chip photo-transistor imager converts the optical image into electrical currents. The design of a single-pixel processing element using resistive fuses is described. The processed output is read out using a row decoder and a column MUX. Operating from a single 5-V supply, the chip typically dissipates only 10 mW.",
An Efficient Systolic Architecture For Qmf Filter Bank Trees,,
IEEE P1232 AI-ESTATE: the standard for test related AI applications takes shape,"In February 1990, the IEEE approved Project Authorization Request (PAR) 1232, authorizing the IEEE SCC-20 (ATLAS) Committee to begin development of a new test standard, AI-ESTATE. AI-ESTATE stands for the artificial intelligence-expert system tie to automatic test equipment. The author defines AI-ESTATE and discusses its background, long-term goals, and architecture, its current status, and the committee's plan of action for continuing development of the standard. AI-ESTATE will define the interfaces between any test related reasoning system, its users, target test equipment, and external knowledge bases and databases. AI-ESTATE will also define several test related knowledge bases and databases, including fault trees and information flow models.",
An accurate measuring system for VTR magnetic track,,
IEEE Transactions on Software Engineering,,
A path-oriented matrix-based knowledge representation system,"Most AI search/representation techniques are oriented toward an infinite domain of objects and arbitrary relations among them. In reality much of what needs to be represented in AI can be expressed using a finite domain and unary or binary predicates. Well-known vector- and matrix-based representations can efficiently represent finite domains and unary/binary predicates, and allow effective extraction of path information by generalized transitive closure/path matrix computations. In order to avoid space limitations in this approach, a set of abstract sparse matrix data types was developed along with a set of operations on them. This representation forms the basis of an intelligent information tool for representing and manipulating relational data. The tool is being used in developing a system that helps flight crews cope with in-flight malfunctions.",
Reviewing recovery-management under real-time requirements in distributed systems,"Dependencies between computations may lead to unpredictable behaviour of the commit/abort protocols possibly contradicting given real-time requirements. Moreover, it is even possible that the protocols do not terminate. By using redundant dependency storing and by restricting concurrency without isolating computations from each other efficient commit/abort protocols can be provided. Obviously, there exists an alternative to the isolation of computations in distributed real-time systems which allows more concurrency between computations.",
A semi-custom multi-channel preamplifier integrated circuit for spaceborne nuclear instrumentation,"A monolithic eight-channel preamplifier for spaceborne nuclear instrumentation is being developed using a semicustom application specific integrated circuit (ASIC) based on bipolar tile-array technology. This general-purpose charge-sensitive bipolar octal preamplifier (BOP) was designed using a complementary current mirror approach so that it would be useful for amplifying both positive-going and negative-going input pulses while consuming low to moderate power. The input stages use a common-collector/common-base topology for good bandwidth and slew characteristics. The output stages use power devices configured as class AB and are capable of driving 50- Omega loads. Each of the eight channels can be biased or enabled separately. The design is implemented with dielectrically isolated, vertical geometry transistors. Such devices are inherently radiation-hard and have PNP transistors whose performance is superior to that of the lateral geometry types. The availability of dielectrically isolated topologies allows such devices to be usable in an environment where total dosages can be as high as 1 Mrad. Computer simulations of the BOP in various configurations show that design requirements were met.",
Design of an integrated query and manipulation notation for database languages,"A common task in data intensive applications is to locate a group of items and then manipulate them, e.g. to give a bonus to all of the employees in a department. Conventional relational query languages like SQL provide facilities for such manipulation-queries, but are not smoothly integrated with a programming language and lack computational power. It has been argued that comprehensions, a construct found in some languages, are a good query notation for database programming languages. An extension to comprehensions is proposed that permits the data to be manipulated by side-effect in addition to being queried. These side-effecting queries are computationally powerful and smoothly integrated into a database programming language, unlike conventional relational query languages. Furthermore side-effecting comprehensions are concise and some may be automatically optimized.",
Competitive learning in asynchronous pulse density integrated circuits,The authors introduce a MOS circuit for the integrated implementation of pulse-coded competitive learning. They describe an autoadaptive synapse circuit for a pulse-coded competitive learning rule. The specific focus is upon an adaptive synapse cell which combines a capacitive analog storage element with subthreshold adaptation circuitry. The adaptation circuitry is designed to compensate for nonlinear device transconductance in the subthreshold operating region. The simulation results presented verify circuit operation in a 2-input-3-output competitive network. Accurate clustering of random training data was demonstrated.,
H suboptimal controller design via transfer recovery,An approach based on observer theory to obtain H suboptimal controllers is presented in this paper. An H/LTR output feedback design procedure is shown to consist of one H state feedback design and one frequency-shaped state estimator design.,
