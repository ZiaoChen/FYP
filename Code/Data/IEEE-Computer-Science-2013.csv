Title,Abstract,Keywords
An Overview of Recent Progress in the Study of Distributed Multi-Agent Coordination,"This paper reviews some main results and progress in distributed multi-agent coordination, focusing on papers published in major control systems and robotics journals since 2006. Distributed coordination of multiple vehicles, including unmanned aerial vehicles, unmanned ground vehicles, and unmanned underwater vehicles, has been a very active research subject studied extensively by the systems and control community. The recent results in this area are categorized into several directions, such as consensus, formation control, optimization, and estimation. After the review, a short discussion section is included to summarize the existing research and to propose several promising research directions along with some open problems that are deemed important for further investigations.","Delay effects,
Network topology,
Heuristic algorithms,
Vehicle dynamics,
Vehicles,
Algorithm design and analysis,
Delay"
Speech recognition with deep recurrent neural networks,"Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score.","Speech recognition,
Recurrent neural networks,
Training,
Vectors,
Acoustics,
Noise"
A survey of energy-efficient wireless communications,"Reducing energy consumption in wireless communications has attracted increasing attention recently. Advanced physical layer techniques such as multiple-input multiple-output (MIMO) and orthogonal frequency division multiplexing (OFDM), cognitive radio, network coding, cooperative communication, etc.; new network architectures such as heterogeneous networks, distributed antennas, multi-hop cellulars, etc.; as well as radio and network resource management schemes such as various cross-layer optimization algorithms, dynamic power saving, multiple radio access technologies coordination, etc. have been proposed to address this issue. In this article, we overview these technologies and present the state-of-the-art on each aspect. Some challenges that need to be solved in the area are also described.","Energy consumption,
Quality of service,
Wireless communication,
Resource management,
MIMO,
Delays"
A Survey on Human Activity Recognition using Wearable Sensors,"Providing accurate and opportune information on people's activities and behaviors is one of the most important tasks in pervasive computing. Innumerable applications can be visualized, for instance, in medical, security, entertainment, and tactical scenarios. Despite human activity recognition (HAR) being an active field for more than a decade, there are still key aspects that, if addressed, would constitute a significant turn in the way people interact with mobile devices. This paper surveys the state of the art in HAR based on wearable sensors. A general architecture is first presented along with a description of the main components of any HAR system. We also propose a two-level taxonomy in accordance to the learning approach (either supervised or semi-supervised) and the response time (either offline or online). Then, the principal issues and challenges are discussed, as well as the main solutions to each one of them. Twenty eight systems are qualitatively evaluated in terms of recognition performance, energy consumption, obtrusiveness, and flexibility, among others. Finally, we present some open problems and ideas that, due to their high relevance, should be addressed in future research.","Feature extraction,
Accelerometers,
Pervasive computing,
Wearable sensors"
Enhanced Computer Vision With Microsoft Kinect Sensor: A Review,"With the invention of the low-cost Microsoft Kinect sensor, high-resolution depth and visual (RGB) sensing has become available for widespread use. The complementary nature of the depth and visual information provided by the Kinect sensor opens up new opportunities to solve fundamental problems in computer vision. This paper presents a comprehensive review of recent Kinect-based computer vision algorithms and applications. The reviewed approaches are classified according to the type of vision problems that can be addressed or enhanced by means of the Kinect sensor. The covered topics include preprocessing, object tracking and recognition, human activity analysis, hand gesture analysis, and indoor 3-D mapping. For each category of methods, we outline their main algorithmic contributions and summarize their advantages/differences compared to their RGB counterparts. Finally, we give an overview of the challenges in this field and future research trends. This paper is expected to serve as a tutorial and source of references for Kinect-based computer vision researchers.","Computer vision,
Data integration,
Sensors,
Algorithm design and analysis,
Cameras,
Object recognition,
Feature extraction"
Deformable Medical Image Registration: A Survey,"Deformable image registration is a fundamental task in medical image processing. Among its most important applications, one may cite: 1) multi-modality fusion, where information acquired by different imaging devices or protocols is fused to facilitate diagnosis and treatment planning; 2) longitudinal studies, where temporal structural or anatomical changes are investigated; and 3) population modeling and statistical atlases used to study normal anatomical variability. In this paper, we attempt to give an overview of deformable registration methods, putting emphasis on the most recent advances in the domain. Additional emphasis has been given to techniques applied to medical images. In order to study image registration methods in depth, their main components are identified and studied independently. The most recent techniques are presented in a systematic fashion. The contribution of this paper is to provide an extensive account of registration techniques in a systematic manner.","Deformable models,
Mathematical model,
Biomedical imaging,
Linear programming,
Computational modeling,
Image registration,
Topology"
Decentralized Charging Control of Large Populations of Plug-in Electric Vehicles,"This paper develops a strategy to coordinate the charging of autonomous plug-in electric vehicles (PEVs) using concepts from non-cooperative games. The foundation of the paper is a model that assumes PEVs are cost-minimizing and weakly coupled via a common electricity price. At a Nash equilibrium, each PEV reacts optimally with respect to a commonly observed charging trajectory that is the average of all PEV strategies. This average is given by the solution of a fixed point problem in the limit of infinite population size. The ideal solution minimizes electricity generation costs by scheduling PEV demand to fill the overnight non-PEV demand “valley”. The paper's central theoretical result is a proof of the existence of a unique Nash equilibrium that almost satisfies that ideal. This result is accompanied by a decentralized computational algorithm and a proof that the algorithm converges to the Nash equilibrium in the infinite system limit. Several numerical examples are used to illustrate the performance of the solution strategy for finite populations. The examples demonstrate that convergence to the Nash equilibrium occurs very quickly over a broad range of parameters, and suggest this method could be useful in situations where frequent communication with PEVs is not possible. The method is useful in applications where fully centralized control is not possible, but where optimal or near-optimal charging patterns are essential to system operation.","Nash equilibrium,
Games,
Electricity,
Trajectory,
Convergence,
Vehicles,
Cost function"
Nonlocally Centralized Sparse Representation for Image Restoration,"Sparse representation models code an image patch as a linear combination of a few atoms chosen out from an over-complete dictionary, and they have shown promising results in various image restoration applications. However, due to the degradation of the observed image (e.g., noisy, blurred, and/or down-sampled), the sparse representations by conventional models may not be accurate enough for a faithful reconstruction of the original image. To improve the performance of sparse representation-based image restoration, in this paper the concept of sparse coding noise is introduced, and the goal of image restoration turns to how to suppress the sparse coding noise. To this end, we exploit the image nonlocal self-similarity to obtain good estimates of the sparse coding coefficients of the original image, and then centralize the sparse coding coefficients of the observed image to those estimates. The so-called nonlocally centralized sparse representation (NCSR) model is as simple as the standard sparse representation model, while our extensive experiments on various types of image restoration problems, including denoising, deblurring and super-resolution, validate the generality and state-of-the-art performance of the proposed NCSR algorithm.","Dictionaries,
Encoding,
Image restoration,
Estimation,
Image coding,
Principal component analysis,
Image reconstruction"
Mobile Data Offloading: How Much Can WiFi Deliver?,"This paper presents a quantitative study on the performance of 3G mobile data offloading through WiFi networks. We recruited 97 iPhone users from metropolitan areas and collected statistics on their WiFi connectivity during a two-and-a-half-week period in February 2010. Our trace-driven simulation using the acquired whole-day traces indicates that WiFi already offloads about 65% of the total mobile data traffic and saves 55% of battery power without using any delayed transmission. If data transfers can be delayed with some deadline until users enter a WiFi zone, substantial gains can be achieved only when the deadline is fairly larger than tens of minutes. With 100-s delays, the achievable gain is less than only 2%-3%, whereas with 1 h or longer deadlines, traffic and energy saving gains increase beyond 29% and 20%, respectively. These results are in contrast to the substantial gain (20%-33%) reported by the existing work even for 100-s delayed transmission using traces taken from transit buses or war-driving. In addition, a distribution model-based simulator and a theoretical framework that enable analytical studies of the average performance of offloading are proposed. These tools are useful for network providers to obtain a rough estimate on the average performance of offloading for a given WiFi deployment condition.","IEEE 802.11 Standards,
Mobile communication,
Delay,
Servers,
Cities and towns,
Mobile computing"
Efficiency Resource Allocation for Device-to-Device Underlay Communication Systems: A Reverse Iterative Combinatorial Auction Based Approach,"Peer-to-peer communication has been recently considered as a popular issue for local area services. An innovative resource allocation scheme is proposed to improve the performance of mobile peer-to-peer, i.e., device-to-device (D2D), communications as an underlay in the downlink (DL) cellular networks. To optimize the system sum rate over the resource sharing of both D2D and cellular modes, we introduce a reverse iterative combinatorial auction as the allocation mechanism. In the auction, all the spectrum resources are considered as a set of resource units, which as bidders compete to obtain business while the packages of the D2D pairs are auctioned off as goods in each auction round. We first formulate the valuation of each resource unit, as a basis of the proposed auction. And then a detailed non-monotonic descending price auction algorithm is explained depending on the utility function that accounts for the channel gain from D2D and the costs for the system. Further, we prove that the proposed auction-based scheme is cheat-proof, and converges in a finite number of iteration rounds. We explain non-monotonicity in the price update process and show lower complexity compared to a traditional combinatorial allocation. The simulation results demonstrate that the algorithm efficiently leads to a good performance on the system sum rate.","Resource management,
Interference,
Receivers,
Cost accounting,
Games,
Power control,
Downlink"
A Mobile Virtual Environment game approach for improving student learning performance in integrated science classes in Hong Kong International Schools,"Previous research has highlighted the potential benefits of mobile devices and digital games for educational purposes. However, few studies have evaluated the use of mobile games in class, especially regarding science education in the Hong Kong context. This paper presents some details of a preliminary implementation of learning activities employing a popular Mobile Virtual Environment Game, Minecraft, in a Hong Kong international secondary school Integrated Science class. Indications are that the introduction of the mobile virtual environment game may indeed contribute to learning improvements and some other enhanced “soft” outcomes. Possible implications of the findings and future research are considered.",
Discrete Signal Processing on Graphs,"In social settings, individuals interact through webs of relationships. Each individual is a node in a complex network (or graph) of interdependencies and generates data, lots of data. We label the data by its source, or formally stated, we index the data by the nodes of the graph. The resulting signals (data indexed by the nodes) are far removed from time or image signals indexed by well ordered time samples or pixels. DSP, discrete signal processing, provides a comprehensive, elegant, and efficient methodology to describe, represent, transform, analyze, process, or synthesize these well ordered time or image signals. This paper extends to signals on graphs DSP and its basic tenets, including filters, convolution, z-transform, impulse response, spectral representation, Fourier transform, frequency response, and illustrates DSP on graphs by classifying blogs, linear predicting and compressing data from irregularly located weather stations, or predicting behavior of customers of a mobile service provider.","Fourier transforms,
Laplace equations,
Graphical models,
Digital signal processing,
Manifolds"
A Survey on Ambient-Assisted Living Tools for Older Adults,"In recent years, we have witnessed a rapid surge in assisted living technologies due to a rapidly aging society. The aging population, the increasing cost of formal health care, the caregiver burden, and the importance that the individuals place on living independently, all motivate development of innovative-assisted living technologies for safe and independent aging. In this survey, we will summarize the emergence of `ambient-assisted living” (AAL) tools for older adults based on ambient intelligence paradigm. We will summarize the state-of-the-art AAL technologies, tools, and techniques, and we will look at current and future challenges.","Intelligent sensors,
Hidden Markov models,
Robots,
Biomedical monitoring,
Smart homes,
Humans"
Data Center Network Virtualization: A Survey,"With the growth of data volumes and variety of Internet applications, data centers (DCs) have become an efficient and promising infrastructure for supporting data storage, and providing the platform for the deployment of diversified network services and applications (e.g., video streaming, cloud computing). These applications and services often impose multifarious resource demands (storage, compute power, bandwidth, latency) on the underlying infrastructure. Existing data center architectures lack the flexibility to effectively support these applications, which results in poor support of QoS, deployability, manageability, and defence against security attacks. Data center network virtualization is a promising solution to address these problems. Virtualized data centers are envisioned to provide better management flexibility, lower cost, scalability, better resources utilization, and energy efficiency. In this paper, we present a survey of the current state-of-the-art in data center networks virtualization, and provide a detailed comparison of the surveyed proposals. We discuss the key research challenges for future research and point out some potential directions for tackling the problems related to data center design.",
Compressed Sensing Off the Grid,"This paper investigates the problem of estimating the frequency components of a mixture of s complex sinusoids from a random subset of n regularly spaced samples. Unlike previous work in compressed sensing, the frequencies are not assumed to lie on a grid, but can assume any values in the normalized frequency domain [0, 1]. An atomic norm minimization approach is proposed to exactly recover the unobserved samples and identify the unknown frequencies, which is then reformulated as an exact semidefinite program. Even with this continuous dictionary, it is shown that O(slog s log n) random samples are sufficient to guarantee exact frequency localization with high probability, provided the frequencies are well separated. Extensive numerical experiments are performed to illustrate the effectiveness of the proposed method.","Atomic clocks,
Compressed sensing,
Minimization,
Dictionaries,
Polynomials,
Vectors,
Sparse matrices"
"Looking at Vehicles on the Road: A Survey of Vision-Based Vehicle Detection, Tracking, and Behavior Analysis","This paper provides a review of the literature in on-road vision-based vehicle detection, tracking, and behavior understanding. Over the past decade, vision-based surround perception has progressed from its infancy into maturity. We provide a survey of recent works in the literature, placing vision-based vehicle detection in the context of sensor-based on-road surround analysis. We detail advances in vehicle detection, discussing monocular, stereo vision, and active sensor-vision fusion for on-road vehicle detection. We discuss vision-based vehicle tracking in the monocular and stereo-vision domains, analyzing filtering, estimation, and dynamical models. We discuss the nascent branch of intelligent vehicles research concerned with utilizing spatiotemporal measurements, trajectories, and various features to characterize on-road behavior. We provide a discussion on the state of the art, detail common performance metrics and benchmarks, and provide perspective on future research directions in the field.","Computer vision,
Intelligent vehicles,
Machine learning,
Object detection,
Object tracking"
Visual-Textual Joint Relevance Learning for Tag-Based Social Image Search,"Due to the popularity of social media websites, extensive research efforts have been dedicated to tag-based social image search. Both visual information and tags have been investigated in the research field. However, most existing methods use tags and visual characteristics either separately or sequentially in order to estimate the relevance of images. In this paper, we propose an approach that simultaneously utilizes both visual and textual information to estimate the relevance of user tagged images. The relevance estimation is determined with a hypergraph learning approach. In this method, a social image hypergraph is constructed, where vertices represent images and hyperedges represent visual or textual terms. Learning is achieved with use of a set of pseudo-positive images, where the weights of hyperedges are updated throughout the learning process. In this way, the impact of different tags and visual words can be automatically modulated. Comparative results of the experiments conducted on a dataset including 370+images are presented, which demonstrate the effectiveness of the proposed approach.",
Online Object Tracking With Sparse Prototypes,"Online object tracking is a challenging problem as it entails learning an effective model to account for appearance change caused by intrinsic and extrinsic factors. In this paper, we propose a novel online object tracking algorithm with sparse prototypes, which exploits both classic principal component analysis (PCA) algorithms with recent sparse representation schemes for learning effective appearance models. We introduce l1 regularization into the PCA reconstruction, and develop a novel algorithm to represent an object by sparse prototypes that account explicitly for data and noise. For tracking, objects are represented by the sparse prototypes learned online with update. In order to reduce tracking drift, we present a method that takes occlusion and motion blur into account rather than simply includes image observations for model update. Both qualitative and quantitative evaluations on challenging image sequences demonstrate that the proposed tracking algorithm performs favorably against several state-of-the-art methods.","Vectors,
Target tracking,
Principal component analysis,
Prototypes,
Noise,
Robustness"
Power Loss Minimization in Distribution System Using Network Reconfiguration in the Presence of Distributed Generation,This paper presents a new method to solve the network reconfiguration problem in the presence of distributed generation (DG) with an objective of minimizing real power loss and improving voltage profile in distribution system. A meta heuristic Harmony Search Algorithm (HSA) is used to simultaneously reconfigure and identify the optimal locations for installation of DG units in a distribution network. Sensitivity analysis is used to identify optimal location s for installation of DG units. Different scenarios of DG placement and reconfiguration of network are considered to study the performance of the proposed method. The constraints of voltage and branch current carrying capacity are included in the evaluation of the objective function. The method has been tested on 33-bus and 69-bus radial distribution systems at three different load levels to demonstrate the performance and effectiveness of the proposed method. The results obtained are encouraging.,"Vectors,
Optimization,
Minimization,
Distributed power generation,
Heuristic algorithms,
Reactive power,
Sensitivity"
A Survey of Indoor Inertial Positioning Systems for Pedestrians,"With the continual miniaturisation of sensors and processing nodes, Pedestrian Dead Reckoning (PDR) systems are becoming feasible options for indoor tracking. These use inertial and other sensors, often combined with domain-specific knowledge about walking, to track user movements. There is currently a wealth of relevant literature spread across different research communities. In this survey, a taxonomy of modern PDRs is developed and used to contextualise the contributions from different areas. Techniques for step detection, characterisation, inertial navigation and step-and-heading-based dead-reckoning are reviewed and compared. Techniques that incorporate building maps through particle filters are analysed, along with hybrid systems that use absolute position fixes to correct dead-reckoning output. In addition, consideration is given to the possibility of using smartphones as PDR sensing devices. The survey concludes that PDR techniques alone can offer good short- to medium- term tracking under certain circumstances, but that regular absolute position fixes from partner systems will be needed to ensure long-term operation and to cope with unexpected behaviours. It concludes by identifying a detailed list of challenges for PDR researchers.","Wearable computers,
Sensor systems,
Dead reckoning,
Navigation,
Legged locomotion"
Candidate Indistinguishability Obfuscation and Functional Encryption for all Circuits,"In this work, we study indistinguishability obfuscation and functional encryption for general circuits: Indistinguishability obfuscation requires that given any two equivalent circuits C0 and C1 of similar size, the obfuscations of C0 and C1 should be computationally indistinguishable. In functional encryption, cipher texts encrypt inputs x and keys are issued for circuits C. Using the key SKC to decrypt a cipher text CTx = Enc(x), yields the value C(x) but does not reveal anything else about x. Furthermore, no collusion of secret key holders should be able to learn anything more than the union of what they can each learn individually. We give constructions for indistinguishability obfuscation and functional encryption that supports all polynomial-size circuits. We accomplish this goal in three steps: - (1) We describe a candidate construction for indistinguishability obfuscation for NC1 circuits. The security of this construction is based on a new algebraic hardness assumption. The candidate and assumption use a simplified variant of multilinear maps, which we call Multilinear Jigsaw Puzzles. (2) We show how to use indistinguishability obfuscation for NC1 together with Fully Homomorphic Encryption (with decryption in NC1) to achieve indistinguishability obfuscation for all circuits. (3) Finally, we show how to use indistinguishability obfuscation for circuits, public-key encryption, and non-interactive zero knowledge to achieve functional encryption for all circuits. The functional encryption scheme we construct also enjoys succinct cipher texts, which enables several other applications.",
Particle Swarm Optimization With an Aging Leader and Challengers,"In nature, almost every organism ages and has a limited lifespan. Aging has been explored by biologists to be an important mechanism for maintaining diversity. In a social animal colony, aging makes the old leader of the colony become weak, providing opportunities for the other individuals to challenge the leadership position. Inspired by this natural phenomenon, this paper transplants the aging mechanism to particle swarm optimization (PSO) and proposes a PSO with an aging leader and challengers (ALC-PSO). ALC-PSO is designed to overcome the problem of premature convergence without significantly impairing the fast-converging feature of PSO. It is characterized by assigning the leader of the swarm with a growing age and a lifespan, and allowing the other individuals to challenge the leadership when the leader becomes aged. The lifespan of the leader is adaptively tuned according to the leader's leading power. If a leader shows strong leading power, it lives longer to attract the swarm toward better positions. Otherwise, if a leader fails to improve the swarm and gets old, new particles emerge to challenge and claim the leadership, which brings in diversity. In this way, the concept “aging” in ALC-PSO actually serves as a challenging mechanism for promoting a suitable leader to lead the swarm. The algorithm is experimentally validated on 17 benchmark functions. Its high performance is confirmed by comparing with eight popular PSO variants.",
Quantitative Analysis of Human-Model Agreement in Visual Saliency Modeling: A Comparative Study,"Visual attention is a process that enables biological and machine vision systems to select the most relevant regions from a scene. Relevance is determined by two components: 1) top-down factors driven by task and 2) bottom-up factors that highlight image regions that are different from their surroundings. The latter are often referred to as “visual saliency.” Modeling bottom-up visual saliency has been the subject of numerous research efforts during the past 20 years, with many successful applications in computer vision and robotics. Available models have been tested with different datasets (e.g., synthetic psychological search arrays, natural images or videos) using different evaluation scores (e.g., search slopes, comparison to human eye tracking) and parameter settings. This has made direct comparison of models difficult. Here, we perform an exhaustive comparison of 35 state-of-the-art saliency models over 54 challenging synthetic patterns, three natural image datasets, and two video datasets, using three evaluation scores. We find that although model rankings vary, some models consistently perform better. Analysis of datasets reveals that existing datasets are highly center-biased, which influences some of the evaluation scores. Computational complexity analysis shows that some models are very fast, yet yield competitive eye movement prediction accuracy. Different models often have common easy/difficult stimuli. Furthermore, several concerns in visual saliency modeling, eye movement datasets, and evaluation scores are discussed and insights for future work are provided. Our study allows one to assess the state-of-the-art, helps to organizing this rapidly growing field, and sets a unified comparison framework for gauging future efforts, similar to the PASCAL VOC challenge in the object recognition and detection domains.","Videos,
Humans,
Visualization,
Computational modeling,
Predictive models,
Analytical models,
Government"
Transmit Antenna Selection for Security Enhancement in MIMO Wiretap Channels,"We propose and analyze transmit antenna selection (TAS) to enhance physical layer security in a wiretap channel with NA antennas at the transmitter, NB antennas at the receiver, and NE antennas at the eavesdropper. We focus on the practical scenario where the transmitter does not have any channel state information (CSI) of the eavesdropper's channel. The transmitter selects a single antenna that maximizes the instantaneous signal-to-noise ratio (SNR) at the receiver. The receiver and the eavesdropper employ either maximal-ratio combining (MRC) or selection combining (SC) to combine the received signals. For the proposed protocols, we derive new closed-form expressions for the probability of non-zero secrecy capacity. We consider Nakagami-m fading with non-identical fading parameters of the main channel, mB, and of the eavesdropper's channel, mE. Next, we derive new closed-form expressions for the exact secrecy outage probability, based on which the ε-outage secrecy capacity is characterized. Based on the exact expressions, we derive the asymptotic secrecy outage probability which accurately reveals the secrecy diversity order and the secrecy array gain. We confirm that the proposed protocols achieve identical secrecy diversity orders of NANBmB. An interesting conclusion is reached that this diversity order is independent of NE and mE. Furthermore, we prove that under the proposed protocols, the secrecy outage probability and the ε-outage secrecy capacity improve with increasing NA.",
The Evolution of MAC Protocols in Wireless Sensor Networks: A Survey,"Wireless Sensor Networks (WSNs) have become a leading solution in many important applications such as intrusion detection, target tracking, industrial automation, smart building and so on. Typically, a WSN consists of a large number of small, low-cost sensor nodes that are distributed in the target area for collecting data of interest. For a WSN to provide high throughput in an energy-efficient way, designing an efficient Medium Access Control (MAC) protocol is of paramount importance because the MAC layer coordinates nodes' access to the shared wireless medium. To show the evolution of WSN MAC protocols, this article surveys the latest progresses in WSN MAC protocol designs over the period 2002-2011. In the early development stages, designers were mostly concerned with energy efficiency because sensor nodes are usually limited in power supply. Recently, new protocols are being developed to provide multi-task support and efficient delivery of bursty traffic. Therefore, research attention has turned back to throughput and delay. This article details the evolution of WSN MAC protocols in four categories: asynchronous, synchronous, frame-slotted, and multichannel. These designs are evaluated in terms of energy efficiency, data delivery performance, and overhead needed to maintain a protocol's mechanisms. With extensive analysis of the protocols many future directions are stated at the end of this survey. The performance of different classes of protocols could be substantially improved in future designs by taking into consideration the recent advances in technologies and application demands.",
Semi-Global Leader-Following Consensus of Linear Multi-Agent Systems With Input Saturation via Low Gain Feedback,"This paper investigates the problem of leader-following consensus of a linear multi-agent system on a switching network. The input of each agent is subject to saturation. Low gain feedback based distributed consensus protocols are developed. It is established that, under the assumptions that each agent is asymptotically null controllable with bounded controls and that the network is connected or jointly connected, semi-global leader-following consensus of the multi-agent system can be achieved. Numerical examples are presented to illustrate this result.",
Mobileflow: Toward software-defined mobile networks,"Mobile carrier networks follow an architecture where network elements and their interfaces are defined in detail through standardization, but provide limited ways to develop new network features once deployed. In recent years we have witnessed rapid growth in over-the-top mobile applications and a 10-fold increase in subscriber traffic while ground-breaking network innovation took a back seat. We argue that carrier networks can benefit from advances in computer science and pertinent technology trends by incorporating a new way of thinking in their current toolbox. This article introduces a blueprint for implementing current as well as future network architectures based on a software-defined networking approach. Our architecture enables operators to capitalize on a flow-based forwarding model and fosters a rich environment for innovation inside the mobile network. In this article, we validate this concept in our wireless network research laboratory, demonstrate the programmability and flexibility of the architecture, and provide implementation and experimentation details.","Mobile communication,
Mobile computing,
Control systems,
Wireless communication,
IP networks,
Technological innovation"
Improving deep neural networks for LVCSR using rectified linear units and dropout,"Recently, pre-trained deep neural networks (DNNs) have outperformed traditional acoustic models based on Gaussian mixture models (GMMs) on a variety of large vocabulary speech recognition benchmarks. Deep neural nets have also achieved excellent results on various computer vision tasks using a random “dropout” procedure that drastically improves generalization error by randomly omitting a fraction of the hidden units in all layers. Since dropout helps avoid over-fitting, it has also been successful on a small-scale phone recognition task using larger neural nets. However, training deep neural net acoustic models for large vocabulary speech recognition takes a very long time and dropout is likely to only increase training time. Neural networks with rectified linear unit (ReLU) non-linearities have been highly successful for computer vision tasks and proved faster to train than standard sigmoid units, sometimes also improving discriminative performance. In this work, we show on a 50-hour English Broadcast News task that modified deep neural networks using ReLUs trained with dropout during frame level training provide an 4.2% relative improvement over a DNN trained with sigmoid units, and a 14.4% relative improvement over a strong GMM/HMM system. We were able to obtain our results with minimal human hyper-parameter tuning using publicly available Bayesian optimization code.","Training,
Optimization,
Neural networks,
Bayes methods,
Speech recognition,
Acoustics,
Hidden Markov models"
Moving Object Detection by Detecting Contiguous Outliers in the Low-Rank Representation,"Object detection is a fundamental step for automated video analysis in many vision applications. Object detection in a video is usually performed by object detectors or background subtraction techniques. Often, an object detector requires manually labeled examples to train a binary classifier, while background subtraction needs a training sequence that contains no objects to build a background model. To automate the analysis, object detection without a separate training phase becomes a critical task. People have tried to tackle this task by using motion information. But existing motion-based methods are usually limited when coping with complex scenarios such as nonrigid motion and dynamic background. In this paper, we show that the above challenges can be addressed in a unified framework named DEtecting Contiguous Outliers in the LOw-rank Representation (DECOLOR). This formulation integrates object detection and background learning into a single process of optimization, which can be solved by an alternating algorithm efficiently. We explain the relations between DECOLOR and other sparsity-based methods. Experiments on both simulated data and real sequences demonstrate that DECOLOR outperforms the state-of-the-art approaches and it can work effectively on a wide range of complex scenarios.","Motion segmentation,
Object detection,
Cameras,
Computer vision,
Estimation,
Computational modeling,
Hidden Markov models"
Enabling Effective Programming and Flexible Management of Efficient Body Sensor Network Applications,"Wireless body sensor networks (BSNs) possess enormous potential for changing people's daily lives. They can enhance many human-centered application domains such as m-Health, sport and wellness, and human-centered applications that involve physical/virtual social interactions. However, there are still challenging issues that limit their wide diffusion in real life: primarily, the programming complexity of these systems, due to the lack of high-level software abstractions, and the hardware constraints of wearable devices. In contrast with low-level programming and general-purpose middleware, domain-specific frameworks are an emerging programming paradigm designed to fulfill the lack of suitable BSN programming support with proper abstraction layers. This paper analyzes the most important requirements for an effective BSN-specific software framework, enabling efficient signal-processing applications. Specifically, we present signal processing in node environment (SPINE), an open-source programming framework, designed to support rapid and flexible prototyping and management of BSN applications. We describe how SPINE efficiently addresses the identified requirements while providing performance analysis on the most common hardware/software sensor platforms. We also report a few high-impact BSN applications that have been entirely implemented using SPINE to demonstrate practical examples of its effectiveness and flexibility. This development experience has notably led to the definition of a SPINE-based design methodology for BSN applications. Finally, lessons learned from the development of such applications and from feedback received by the SPINE community are discussed.","Programming,
Software,
Biomedical monitoring,
Monitoring,
Hardware,
Body sensor networks"
A Review of Power Decoupling Techniques for Microinverters With Three Different Decoupling Capacitor Locations in PV Systems,"The reliability of the microinverter is a very important feature that will determine the reliability of the ac-module photovoltaic (PV) system. Recently, many topologies and techniques have been proposed to improve its reliability. This paper presents a thorough study for different power decoupling techniques in single-phase microinverters for grid-tie PV applications. These power decoupling techniques are categorized into three groups in terms of the decoupling capacitor locations: 1) PV-side decoupling; 2) dc-link decoupling; and 3) ac-side decoupling. Various techniques and topologies are presented, compared, and scrutinized in scope of the size of decoupling capacitor, efficiency, and control complexity. Also, a systematic performance comparison is presented for potential power decoupling topologies and techniques.","Capacitors,
Topology,
Inverters,
Capacitance,
Photovoltaic systems"
Spectrum Assignment in Cognitive Radio Networks: A Comprehensive Survey,"Cognitive radio (CR) has emerged as a promising technology to exploit the unused portions of spectrum in an opportunistic manner. The fixed spectrum allocation of governmental agencies results in unused portions of spectrum, which are called ""spectrum holes"" or ""white spaces"". CR technology overcomes this issue, allowing devices to sense the spectrum for unused portions and use the most suitable ones, according to some pre-defined criteria. Spectrum assignment is a key mechanism that limits the interference between CR devices and licensed users, enabling a more efficient usage of the wireless spectrum. Interference is a key factor that limits the performance in wireless networks. The scope of this work is to give an overview of the problem of spectrum assignment in cognitive radio networks, presenting the state-of-the-art proposals that have appeared in the literature, analyzing the criteria for selecting the most suitable portion of the spectrum and showing the most common approaches and techniques used to solve the spectrum assignment problem. Finally, an analysis of the techniques and approaches is presented, discussing also the open issues for future research in this area.","Interference,
Cognitive radio,
Wireless networks,
Bandwidth,
Standards,
Sensors"
Generalized Composite Kernel Framework for Hyperspectral Image Classification,"This paper presents a new framework for the development of generalized composite kernel machines for hyperspectral image classification. We construct a new family of generalized composite kernels which exhibit great flexibility when combining the spectral and the spatial information contained in the hyperspectral data, without any weight parameters. The classifier adopted in this work is the multinomial logistic regression, and the spatial information is modeled from extended multiattribute profiles. In order to illustrate the good performance of the proposed framework, support vector machines are also used for evaluation purposes. Our experimental results with real hyperspectral images collected by the National Aeronautics and Space Administration Jet Propulsion Laboratory's Airborne Visible/Infrared Imaging Spectrometer and the Reflective Optics Spectrographic Imaging System indicate that the proposed framework leads to state-of-the-art classification performance in complex analysis scenarios.","Kernel,
Hyperspectral imaging,
Training,
Logistics,
Support vector machines,
Educational institutions"
Dynamical Movement Primitives: Learning Attractor Models for Motor Behaviors,"Nonlinear dynamical systems have been used in many disciplines to model complex behaviors, including biological motor control, robotics, perception, economics, traffic prediction, and neuroscience. While often the unexpected emergent behavior of nonlinear systems is the focus of investigations, it is of equal importance to create goal-directed behavior (e.g., stable locomotion from a system of coupled oscillators under perceptual guidance). Modeling goal-directed behavior with nonlinear systems is, however, rather difficult due to the parameter sensitivity of these systems, their complex phase transitions in response to subtle parameter changes, and the difficulty of analyzing and predicting their long-term behavior; intuition and time-consuming parameter tuning play a major role. This letter presents and reviews dynamical movement primitives, a line of research for modeling attractor behaviors of autonomous nonlinear dynamical systems with the help of statistical learning techniques. The essence of our approach is to start with a simple dynamical system, such as a set of linear differential equations, and transform those into a weakly nonlinear system with prescribed attractor dynamics by means of a learnable autonomous forcing term. Both point attractors and limit cycle attractors of almost arbitrary complexity can be generated. We explain the design principle of our approach and evaluate its properties in several example applications in motor control and robotics.",
Direct Adaptive Neural Control for a Class of Uncertain Nonaffine Nonlinear Systems Based on Disturbance Observer,"In this paper, the direct adaptive neural control is proposed for a class of uncertain nonaffine nonlinear systems with unknown nonsymmetric input saturation. Based on the implicit function theorem and mean value theorem, both state feedback and output feedback direct adaptive controls are developed using neural networks (NNs) and a disturbance observer. A compounded disturbance is defined to take into account of the effect of the unknown external disturbance, the unknown nonsymmetric input saturation, and the approximation error of NN. Then, a disturbance observer is developed to estimate the unknown compounded disturbance, and it is established that the estimate error converges to a compact set if appropriate observer design parameters are chosen. Both state feedback and output feedback direct adaptive controls can guarantee semiglobal uniform boundedness of the closed-loop system signals as rigorously proved by Lyapunov analysis. Numerical simulation results are presented to illustrate the effectiveness of the proposed direct adaptive neural control techniques.",
Dependable Demand Response Management in the Smart Grid: A Stackelberg Game Approach,"Demand Response Management (DRM) is a key component in the smart grid to effectively reduce power generation costs and user bills. However, it has been an open issue to address the DRM problem in a network of multiple utility companies and consumers where every entity is concerned about maximizing its own benefit. In this paper, we propose a Stackelberg game between utility companies and end-users to maximize the revenue of each utility company and the payoff of each user. We derive analytical results for the Stackelberg equilibrium of the game and prove that a unique solution exists. We develop a distributed algorithm which converges to the equilibrium with only local information available for both utility companies and end-users. Though DRM helps to facilitate the reliability of power supply, the smart grid can be succeptible to privacy and security issues because of communication links between the utility companies and the consumers. We study the impact of an attacker who can manipulate the price information from the utility companies. We also propose a scheme based on the concept of shared reserve power to improve the grid reliability and ensure its dependability.",
Demand-Side Management via Distributed Energy Generation and Storage Optimization,"Demand-side management, together with the integration of distributed energy generation and storage, are considered increasingly essential elements for implementing the smart grid concept and balancing massive energy production from renewable sources. We focus on a smart grid in which the demand-side comprises traditional users as well as users owning some kind of distributed energy sources and/or energy storage devices. By means of a day-ahead optimization process regulated by an independent central unit, the latter users intend to reduce their monetary energy expense by producing or storing energy rather than just purchasing their energy needs from the grid. In this paper, we formulate the resulting grid optimization problem as a noncooperative game and analyze the existence of optimal strategies. Furthermore, we present a distributed algorithm to be run on the users' smart meters, which provides the optimal production and/or storage strategies, while preserving the privacy of the users and minimizing the required signaling with the central unit. Finally, the proposed day-ahead optimization is tested in a realistic situation.","Production,
Optimization,
Energy storage,
Games,
Smart grids,
Vectors,
Aggregates"
FC-PACO-RM: A Parallel Method for Service Composition Optimal-Selection in Cloud Manufacturing System,"In order to realize the full-scale sharing, free circulation and transaction, and on-demand-use of manufacturing resource and capabilities in modern enterprise systems (ES), Cloud manufacturing (CMfg) as a new service-oriented manufacturing paradigm has been proposed recently. Compared with cloud computing, the services that are managed in CMfg include not only computational and software resource and capability service, but also various manufacturing resources and capability service. These various dynamic services make ES more powerful and to be a higher-level extension of traditional services. Thus, as a key issue for the implementation of CMfg-based ES, service composition optimal-selection (SCOS) is becoming very important. SCOS is a typical NP-hard problem with the characteristics of dynamic and uncertainty. Solving large scale SCOS problem with numerous constraints in CMfg by using the traditional methods might be inefficient. To overcome this shortcoming, the formulation of SCOS in CMfg with multiple objectives and constraints is investigated first, and then a novel parallel intelligent algorithm, namely full connection based parallel adaptive chaos optimization with reflex migration (FC-PACO-RM) is developed. In the algorithm, roulette wheel selection and adaptive chaos optimization are introduced for search purpose, while full-connection parallelization in island model and new reflex migration way are also developed for efficient decision. To validate the performance of FC-PACO-RM, comparisons with 3 serial algorithms and 7 typical parallel methods are conducted in three typical cases. The results demonstrate the effectiveness of the proposed method for addressing complex SCOS in CMfg.",
How to Construct Polar Codes,"A method for efficiently constructing polar codes is presented and analyzed. Although polar codes are explicitly defined, straightforward construction is intractable since the resulting polar bit-channels have an output alphabet that grows exponentially with the code length. Thus, the core problem that needs to be solved is that of faithfully approximating a bit-channel with an intractably large alphabet by another channel having a manageable alphabet size. We devise two approximation methods which “sandwich” the original bit-channel between a degraded and an upgraded version thereof. Both approximations can be efficiently computed and turn out to be extremely close in practice. We also provide theoretical analysis of our construction algorithms, proving that for any fixed ε > 0 and all sufficiently large code lengths n, polar codes whose rate is within ε of channel capacity can be constructed in time and space that are both linear in n.","Approximation methods,
Quantization (signal),
Approximation algorithms,
Decoding,
Kernel,
Complexity theory,
Convolutional codes"
Robust odometry estimation for RGB-D cameras,"The goal of our work is to provide a fast and accurate method to estimate the camera motion from RGB-D images. Our approach registers two consecutive RGB-D frames directly upon each other by minimizing the photometric error. We estimate the camera motion using non-linear minimization in combination with a coarse-to-fine scheme. To allow for noise and outliers in the image data, we propose to use a robust error function that reduces the influence of large residuals. Furthermore, our formulation allows for the inclusion of a motion model which can be based on prior knowledge, temporal filtering, or additional sensors like an IMU. Our method is attractive for robots with limited computational resources as it runs in real-time on a single CPU core and has a small, constant memory footprint. In an extensive set of experiments carried out both on a benchmark dataset and synthetic data, we demonstrate that our approach is more accurate and robust than previous methods. We provide our software under an open source license.","Robustness,
Licenses,
Software,
Sensors,
Octrees,
Convergence,
Jacobian matrices"
A Survey on OFDM-Based Elastic Core Optical Networking,"Orthogonal frequency-division multiplexing (OFDM) is a modulation technology that has been widely adopted in many new and emerging broadband wireless and wireline communication systems. Due to its capability to transmit a high-speed data stream using multiple spectral-overlapped lower-speed subcarriers, OFDM technology offers superior advantages of high spectrum efficiency, robustness against inter-carrier and inter-symbol interference, adaptability to server channel conditions, etc. In recent years, there have been intensive studies on optical OFDM (O-OFDM) transmission technologies, and it is considered a promising technology for future ultra-high-speed optical transmission. Based on O-OFDM technology, a novel elastic optical network architecture with immense flexibility and scalability in spectrum allocation and data rate accommodation could be built to support diverse services and the rapid growth of Internet traffic in the future. In this paper, we present a comprehensive survey on OFDM-based elastic optical network technologies, including basic principles of OFDM, O-OFDM technologies, the architectures of OFDM-based elastic core optical networks, and related key enabling technologies. The main advantages and issues of OFDM-based elastic core optical networks that are under research are also discussed.","OFDM,
Optical transmitters,
Optical receivers,
Signal detection,
Optical imaging,
Passive optical networks"
Compressed Sensing Signal and Data Acquisition in Wireless Sensor Networks and Internet of Things,"The emerging compressed sensing (CS) theory can significantly reduce the number of sampling points that directly corresponds to the volume of data collected, which means that part of the redundant data is never acquired. It makes it possible to create standalone and net-centric applications with fewer resources required in Internet of Things (IoT). CS-based signal and information acquisition/compression paradigm combines the nonlinear reconstruction algorithm and random sampling on a sparse basis that provides a promising approach to compress signal and data in information systems. This paper investigates how CS can provide new insights into data sampling and acquisition in wireless sensor networks and IoT. First, we briefly introduce the CS theory with respect to the sampling and transmission coordination during the network lifetime through providing a compressed sampling process with low computation costs. Then, a CS-based framework is proposed for IoT, in which the end nodes measure, transmit, and store the sampled data in the framework. Then, an efficient cluster-sparse reconstruction algorithm is proposed for in-network compression aiming at more accurate data reconstruction and lower energy efficiency. Performance is evaluated with respect to network size using datasets acquired by a real-life deployment.","Compressed sensing,
Wireless sensor networks,
Data acquisition,
Sparse matrices,
Information systems"
A Survey on Security Threats and Detection Techniques in Cognitive Radio Networks,"With the rapid proliferation of new technologies and services in the wireless domain, spectrum scarcity has become a major concern. The allocation of the Industrial, Medical and Scientific (ISM) band has enabled the explosion of new technologies (e.g. Wi-Fi) due to its licence-exempt characteristic. The widespread adoption of Wi-Fi technology, combined with the rapid penetration of smart phones running popular user services (e.g. social online networks) has overcrowded substantially the ISM band. On the other hand, according to a number of recent reports, several parts of the static allocated licensed bands are under-utilized. This has brought up the idea of the opportunistic use of these bands through the, so-called, cognitive radios and cognitive radio networks. Cognitive radios have enabled the opportunity to transmit in several licensed bands without causing harmful interference to licensed users. Along with the realization of cognitive radios, new security threats have been raised. Adversaries can exploit several vulnerabilities of this new technology and cause severe performance degradation. Security threats are mainly related to two fundamental characteristics of cognitive radios: cognitive capability, and reconfigurability. Threats related to the cognitive capability include attacks launched by adversaries that mimic primary transmitters, and transmission of false observations related to spectrum sensing. Reconfiguration can be exploited by attackers through the use of malicious code installed in cognitive radios. Furthermore, as cognitive radio networks are wireless in nature, they face all classic threats present in the conventional wireless networks. The scope of this work is to give an overview of the security threats and challenges that cognitive radios and cognitive radio networks face, along with the current state-of-the-art to detect the corresponding attacks. In addition, future challenges are addressed.","Sensors,
Security,
Cognitive radio,
Communication system security,
Wireless sensor networks,
Transmitters"
Multiagent-Based Distributed-Energy-Resource Management for Intelligent Microgrids,"Microgrid is a combination of distributed generators, storage systems, and controllable loads connected to low-voltage network that can operate either in grid-connected or in island mode. High penetration of power at distribution level creates such multiple microgrids. This paper proposes a two-level architecture for distributed-energy-resource management for multiple microgrids using multiagent systems. In order to match the buyers and sellers in the energy market, symmetrical assignment problem based on naíve auction algorithm is used. The developed mechanism allows the pool members such as generation agents, load agents, auction agents, grid agents, and storage agents to participate in market. Three different scenarios are identified based on the supply-demand mismatch among the participating microgrids. At the end of this paper, two case studies are presented with two and four interconnected microgrids participating in the market. Simulation results clearly indicate that the agent-based management is effective in resource management among multiple microgrids economically and profitably.","Generators,
Intelligent agents,
Computer architecture,
Programming,
Control systems,
Energy resources,
Contracts"
Comparison of Parallel Genetic Algorithm and Particle Swarm Optimization for Real-Time UAV Path Planning,"The development of autonomous unmanned aerial vehicles (UAVs) is of high interest to many governmental and military organizations around the world. An essential aspect of UAV autonomy is the ability for automatic path planning. In this paper, we use the genetic algorithm (GA) and the particle swarm optimization algorithm (PSO) to cope with the complexity of the problem and compute feasible and quasi-optimal trajectories for fixed wing UAVs in a complex 3D environment, while considering the dynamic properties of the vehicle. The characteristics of the optimal path are represented in the form of a multiobjective cost function that we developed. The paths produced are composed of line segments, circular arcs and vertical helices. We reduce the execution time of our solutions by using the “single-program, multiple-data” parallel programming paradigm and we achieve real-time performance on standard commercial off-the-shelf multicore CPUs. After achieving a quasi-linear speedup of 7.3 on 8 cores and an execution time of 10 s for both algorithms, we conclude that by using a parallel implementation on standard multicore CPUs, real-time path planning for UAVs is possible. Moreover, our rigorous comparison of the two algorithms shows, with statistical significance, that the GA produces superior trajectories to the PSO.",
Bayesian Saliency via Low and Mid Level Cues,"Visual saliency detection is a challenging problem in computer vision, but one of great importance and numerous applications. In this paper, we propose a novel model for bottom-up saliency within the Bayesian framework by exploiting low and mid level cues. In contrast to most existing methods that operate directly on low level cues, we propose an algorithm in which a coarse saliency region is first obtained via a convex hull of interest points. We also analyze the saliency information with mid level visual cues via superpixels. We present a Laplacian sparse subspace clustering method to group superpixels with local features, and analyze the results with respect to the coarse saliency region to compute the prior saliency map. We use the low level visual cues based on the convex hull to compute the observation likelihood, thereby facilitating inference of Bayesian saliency at each pixel. Extensive experiments on a large data set show that our Bayesian saliency model performs favorably against the state-of-the-art algorithms.",
Modular Multilevel Inverter with New Modulation Method and Its Application to Photovoltaic Grid-Connected Generator,"This paper proposed an improved phase disposition pulse width modulation (PDPWM) for a modular multilevel inverter which is used for Photovoltaic grid connection. This new modulation method is based on selective virtual loop mapping, to achieve dynamic capacitor voltage balance without the help of an extra compensation signal. The concept of virtual submodule (VSM) is first established, and by changing the loop mapping relationships between the VSMs and the real submodules, the voltages of the upper/lower arm's capacitors can be well balanced. This method does not requiring sorting voltages from highest to lowest, and just identifies the MIN and MAX capacitor voltage's index which makes it suitable for a modular multilevel converter with a large number of submodules in one arm. Compared to carrier phase-shifted PWM (CPSPWM), this method is more easily to be realized in field-programmable gate array and has much stronger dynamic regulation ability, and is conducive to the control of circulating current. Its feasibility and validity have been verified by simulations and experiments.","Capacitors,
Pulse width modulation,
Voltage control,
Inverters,
Indexes,
Sorting"
Deep convolutional neural networks for LVCSR,"Convolutional Neural Networks (CNNs) are an alternative type of neural network that can be used to reduce spectral variations and model spectral correlations which exist in signals. Since speech signals exhibit both of these properties, CNNs are a more effective model for speech compared to Deep Neural Networks (DNNs). In this paper, we explore applying CNNs to large vocabulary speech tasks. First, we determine the appropriate architecture to make CNNs effective compared to DNNs for LVCSR tasks. Specifically, we focus on how many convolutional layers are needed, what is the optimal number of hidden units, what is the best pooling strategy, and the best input feature type for CNNs. We then explore the behavior of neural network features extracted from CNNs on a variety of LVCSR tasks, comparing CNNs to DNNs and GMMs. We find that CNNs offer between a 13-30% relative improvement over GMMs, and a 4-12% relative improvement over DNNs, on a 400-hr Broadcast News and 300-hr Switchboard task.","Hidden Markov models,
Speech,
Training,
Convolution,
Neural networks,
Speech recognition,
Acoustics"
Security and Privacy in Cloud Computing,"Recent advances have given rise to the popularity and success of cloud computing. However, when outsourcing the data and business application to a third party causes the security and privacy issues to become a critical concern. Throughout the study at hand, the authors obtain a common goal to provide a comprehensive review of the existing security and privacy issues in cloud environments. We have identified five most representative security and privacy attributes (i.e., confidentiality, integrity, availability, accountability, and privacy-preservability). Beginning with these attributes, we present the relationships among them, the vulnerabilities that may be exploited by attackers, the threat models, as well as existing defense strategies in a cloud scenario. Future research directions are previously determined for each attribute.","Network security,
Cloud computing,
Privacy,
Trust management,
Computational modeling,
Biological system modeling,
Outsourcing"
A Grid-Based Evolutionary Algorithm for Many-Objective Optimization,"Balancing convergence and diversity plays a key role in evolutionary multiobjective optimization (EMO). Most current EMO algorithms perform well on problems with two or three objectives, but encounter difficulties in their scalability to many-objective optimization. This paper proposes a grid-based evolutionary algorithm (GrEA) to solve many-objective optimization problems. Our aim is to exploit the potential of the grid-based approach to strengthen the selection pressure toward the optimal direction while maintaining an extensive and uniform distribution among solutions. To this end, two concepts-grid dominance and grid difference-are introduced to determine the mutual relationship of individuals in a grid environment. Three grid-based criteria, i.e., grid ranking, grid crowding distance, and grid coordinate point distance, are incorporated into the fitness of individuals to distinguish them in both the mating and environmental selection processes. Moreover, a fitness adjustment strategy is developed by adaptively punishing individuals based on the neighborhood and grid dominance relations in order to avoid partial overcrowding as well as guide the search toward different directions in the archive. Six state-of-the-art EMO algorithms are selected as the peer algorithms to validate GrEA. A series of extensive experiments is conducted on 52 instances of nine test problems taken from three test suites. The experimental results show the effectiveness and competitiveness of the proposed GrEA in balancing convergence and diversity. The solution set obtained by GrEA can achieve a better coverage of the Pareto front than that obtained by other algorithms on most of the tested problems. Additionally, a parametric study reveals interesting insights of the division parameter in a grid and also indicates useful values for problems with different characteristics.","Optimization,
Sociology,
Statistics,
Convergence,
Evolutionary computation,
Vectors,
Measurement"
Consensus Based Approach for Economic Dispatch Problem in a Smart Grid,"Economic dispatch problem (EDP) is an important class of optimization problems in the smart grid, which aims at minimizing the total cost when generating certain amount of power. In this work, a novel consensus based algorithm is proposed to solve EDP in a distributed fashion. The quadratic convex cost functions are assumed in the problem formulation, and the strongly connected communication topology is sufficient for the information exchange. Unlike centralized approaches, the proposed algorithm enables generators to collectively learn the mismatch between demand and total amount of power generation. The estimated mismatch is then used as a feedback mechanism to adjust current power generation by each generator. With a tactical initial setup, eventually, all generators can automatically minimize the total cost in a collective sense.","Generators,
Power generation,
Eigenvalues and eigenfunctions,
Smart grids,
Cost function,
Algorithm design and analysis,
Distributed algorithms"
A Review of the Application of Multiobjective Evolutionary Fuzzy Systems: Current Status and Further Directions,"Over the past few decades, fuzzy systems have been widely used in several application fields, thanks to their ability to model complex systems. The design of fuzzy systems has been successfully performed by applying evolutionary and, in particular, genetic algorithms, and recently, this approach has been extended by using multiobjective evolutionary algorithms, which can consider multiple conflicting objectives, instead of a single one. The hybridization between multiobjective evolutionary algorithms and fuzzy systems is currently known as multiobjective evolutionary fuzzy systems. This paper presents an overview of multiobjective evolutionary fuzzy systems, describing the main contributions on this field and providing a two-level taxonomy of the existing proposals, in order to outline a well-established framework that could help researchers who work on significant further developments. Finally, some considerations of recent trends and potential research directions are presented.","Tuning,
Accuracy,
Fuzzy systems,
Taxonomy,
Association rules,
Pragmatics"
Average Rate of Downlink Heterogeneous Cellular Networks over Generalized Fading Channels: A Stochastic Geometry Approach,"In this paper, we introduce an analytical framework to compute the average rate of downlink heterogeneous cellular networks. The framework leverages recent application of stochastic geometry to other-cell interference modeling and analysis. The heterogeneous cellular network is modeled as the superposition of many tiers of Base Stations (BSs) having different transmit power, density, path-loss exponent, fading parameters and distribution, and unequal biasing for flexible tier association. A long-term averaged maximum biased-received-power tier association is considered. The positions of the BSs in each tier are modeled as points of an independent Poisson Point Process (PPP). Under these assumptions, we introduce a new analytical methodology to evaluate the average rate, which avoids the computation of the Coverage Probability (Pcov) and needs only the Moment Generating Function (MGF) of the aggregate interference at the probe mobile terminal. The distinguishable characteristic of our analytical methodology consists in providing a tractable and numerically efficient framework that is applicable to general fading distributions, including composite fading channels with small- and mid-scale fluctuations. In addition, our method can efficiently handle correlated Log-Normal shadowing with little increase of the computational complexity. The proposed MGF-based approach needs the computation of either a single or a two-fold numerical integral, thus reducing the complexity of Pcov-based frameworks, which require, for general fading distributions, the computation of a four-fold integral.","Fading,
Computational modeling,
Interference,
Mathematical model,
Analytical models,
Downlink,
Numerical models"
Adaptive Dynamic Surface Control for Formations of Autonomous Surface Vehicles With Uncertain Dynamics,"In this brief, we consider the formation control problem of underactuated autonomous surface vehicles (ASVs) moving in a leader-follower formation, in the presence of uncertainties and ocean disturbances. A robust adaptive formation controller is developed by employing neural network and dynamic surface control technique. The stability of the design is proven via Lyapunov analysis where semiglobal uniform ultimate boundedness of the closed-loop signals is guaranteed. The advantages of the proposed formation controller are that: first, the proposed method only uses the measurements of line-of-sight range and angle by local sensors, no other information about the leader is required for control implementation; second, the developed neural formation controller is able to capture the vehicle dynamics without exact information of coriolis and centripetal force, hydrodynamic damping and disturbances from the environment. Comparative analysis with a model-based approach is given to demonstrate the effectiveness of the proposed method.",
Robust real-time visual odometry for dense RGB-D mapping,"This paper describes extensions to the Kintinuous [1] algorithm for spatially extended KinectFusion, incorporating the following additions: (i) the integration of multiple 6DOF camera odometry estimation methods for robust tracking; (ii) a novel GPU-based implementation of an existing dense RGB-D visual odometry algorithm; (iii) advanced fused realtime surface coloring. These extensions are validated with extensive experimental results, both quantitative and qualitative, demonstrating the ability to build dense fully colored models of spatially extended environments for robotics and virtual reality applications while remaining robust against scenes with challenging sets of geometric and visual features.","Cameras,
Iterative closest point algorithm,
Graphics processing units,
Image color analysis,
Instruction sets,
Visualization,
Color"
Design of Optimal Sparse Feedback Gains via the Alternating Direction Method of Multipliers,"We design sparse and block sparse feedback gains that minimize the variance amplification (i.e., the H2 norm) of distributed systems. Our approach consists of two steps. First, we identify sparsity patterns of feedback gains by incorporating sparsity-promoting penalty functions into the optimal control problem, where the added terms penalize the number of communication links in the distributed controller. Second, we optimize feedback gains subject to structural constraints determined by the identified sparsity patterns. In the first step, the sparsity structure of feedback gains is identified using the alternating direction method of multipliers, which is a powerful algorithm well-suited to large optimization problems. This method alternates between promoting the sparsity of the controller and optimizing the closed-loop performance, which allows us to exploit the structure of the corresponding objective functions. In particular, we take advantage of the separability of the sparsity-promoting penalty functions to decompose the minimization problem into sub-problems that can be solved analytically. Several examples are provided to illustrate the effectiveness of the developed approach.","optimal control,
closed loop systems,
distributed control,
feedback,
minimisation"
Extreme Learning Machines [Trends & Controversies],"This special issue includes eight original works that detail the further developments of ELMs in theories, applications, and hardware implementation. In ""Representational Learning with ELMs for Big Data,"" Liyanaarachchi Lekamalage Chamara Kasun, Hongming Zhou, Guang-Bin Huang, and Chi Man Vong propose using the ELM as an auto-encoder for learning feature representations using singular values. In ""A Secure and Practical Mechanism for Outsourcing ELMs in Cloud Computing,"" Jiarun Lin, Jianping Yin, Zhiping Cai, Qiang Liu, Kuan Li, and Victor C.M. Leung propose a method for handling large data applications by outsourcing to the cloud that would dramatically reduce ELM training time. In ""ELM-Guided Memetic Computation for Vehicle Routing,"" Liang Feng, Yew-Soon Ong, and Meng-Hiot Lim consider the ELM as an engine for automating the encapsulation of knowledge memes from past problem-solving experiences. In ""ELMVIS: A Nonlinear Visualization Technique Using Random Permutations and ELMs,"" Anton Akusok, Amaury Lendasse, Rui Nian, and Yoan Miche propose an ELM method for data visualization based on random permutations to map original data and their corresponding visualization points. In ""Combining ELMs with Random Projections,"" Paolo Gastaldo, Rodolfo Zunino, Erik Cambria, and Sergio Decherchi analyze the relationships between ELM feature-mapping schemas and the paradigm of random projections. In ""Reduced ELMs for Causal Relation Extraction from Unstructured Text,"" Xuefeng Yang and Kezhi Mao propose combining ELMs with neuron selection to optimize the neural network architecture and improve the ELM ensemble's computational efficiency. In ""A System for Signature Verification Based on Horizontal and Vertical Components in Hand Gestures,"" Beom-Seok Oh, Jehyoung Jeon, Kar-Ann Toh, Andrew Beng Jin Teoh, and Jaihie Kim propose a novel paradigm for hand signature biometry for touchless applications without the need for handheld devices. Finally, in ""An Adaptive and Iterative Online Sequential ELM-Based Multi-Degree-of-Freedom Gesture Recognition System,"" Hanchao Yu, Yiqiang Chen, Junfa Liu, and Guang-Bin Huang propose an online sequential ELM-based efficient gesture recognition algorithm for touchless human-machine interaction.","Special issues and sections,
Learning systems,
Nonhomogeneous media,
Data visualization,
Biological neural networks,
Big data,
Adaptive learning,
Machine learning,
Artificial intelligence,
Gesture recognition"
Fast \ell_{1}-Minimization Algorithms for Robust Face Recognition,"l 1-minimization refers to finding the minimum l1-norm solution to an underdetermined linear system \mbib=A\mbix. Under certain conditions as described in compressive sensing theory, the minimum l1-norm solution is also the sparsest solution. In this paper, we study the speed and scalability of its algorithms. In particular, we focus on the numerical implementation of a sparsity-based classification framework in robust face recognition, where sparse representation is sought to recover human identities from high-dimensional facial images that may be corrupted by illumination, facial disguise, and pose variation. Although the underlying numerical problem is a linear program, traditional algorithms are known to suffer poor scalability for large-scale applications. We investigate a new solution based on a classical convex optimization framework, known as augmented Lagrangian methods. We conduct extensive experiments to validate and compare its performance against several popular l1-minimization solvers, including interior-point method, Homotopy, FISTA, SESOP-PCD, approximate message passing, and TFOCS. To aid peer evaluation, the code for all the algorithms has been made publicly available.",
A Survey of Social-Based Routing in Delay Tolerant Networks: Positive and Negative Social Effects,"Delay tolerant networks (DTNs) may lack continuous network connectivity. Routing in DTNs is thus challenging since it must handle network partitioning, long delays, and dynamic topology in such networks. In recent years, social-based approaches, which attempt to exploit social behaviors of DTN nodes to make better routing decision, have drawn tremendous interests in DTN routing design. In this article, we summarize the social properties in DTNs, and provide a survey of recent social-based DTN routing approaches. To improve routing performance, these methods either take advantages of positive social characteristics such as community and friendship to assist packet forwarding or consider negative social characteristics such as selfishness. We conclude by discussing some open issues and challenges in social-based approaches regarding the design of DTN routing protocols.",
Registration of 3D Point Clouds and Meshes: A Survey from Rigid to Nonrigid,"Three-dimensional surface registration transforms multiple three-dimensional data sets into the same coordinate system so as to align overlapping components of these sets. Recent surveys have covered different aspects of either rigid or nonrigid registration, but seldom discuss them as a whole. Our study serves two purposes: 1) To give a comprehensive survey of both types of registration, focusing on three-dimensional point clouds and meshes and 2) to provide a better understanding of registration from the perspective of data fitting. Registration is closely related to data fitting in which it comprises three core interwoven components: model selection, correspondences and constraints, and optimization. Study of these components 1) provides a basis for comparison of the novelties of different techniques, 2) reveals the similarity of rigid and nonrigid registration in terms of problem representations, and 3) shows how overfitting arises in nonrigid registration and the reasons for increasing interest in intrinsic techniques. We further summarize some practical issues of registration which include initializations and evaluations, and discuss some of our own observations, insights and foreseeable research trends.","Optimization,
Data models,
Bones,
Joints,
Vectors,
Mathematical model"
WILL: Wireless Indoor Localization without Site Survey,"Indoor localization is of great importance for a range of pervasive applications, attracting many research efforts in the past two decades. Most radio-based solutions require a process of site survey, in which radio signatures are collected and stored for further comparison and matching. Site survey involves intensive costs on manpower and time. In this work, we study unexploited RF signal characteristics and leverage user motions to construct radio floor plan that is previously obtained by site survey. On this basis, we design WILL, an indoor localization approach based on off-the-shelf WiFi infrastructure and mobile phones. WILL is deployed in a real building covering over 1600 m2, and its deployment is easy and rapid since site survey is no longer needed. The experiment results show that WILL achieves competitive performance comparing with traditional approaches.","Databases,
Wireless communication,
IEEE 802.11 Standards,
Wireless sensor networks,
Mobile handsets,
Accelerometers,
Buildings"
A Study on Magnetic Field Repeater in Wireless Power Transfer,"It is shown that the distance of wireless power transfer is significantly increased by placing intermediate resonators (repeaters) between transmitter and receiver. The guidelines are provided to use the repeaters effectively. We first briefly review how the repeaters enhance the transfer distance. Next, the aspect of resonant frequency splitting is studied separately both for even and odd numbers of repeaters. The transferred power, efficiency, and output impedance phase are evaluated for each repeater configuration. These provide the guidelines to select the optimum repeater positions and numbers. We also propose and study a new kind of repeater which can be placed (biased) even in the vicinity of transmitter or receiver. This increases the flexibility in choosing the repeater position. The net effect of such biased repeater is approximately doubling the effective coupling coefficient between transmitter and receiver. Experimental results are provided to prove the concepts.","Repeaters,
Resonant frequency,
Couplings,
Transmitters,
Receivers,
Q factor,
Propagation losses"
Discovering Discriminative Graphlets for Aerial Image Categories Recognition,"Recognizing aerial image categories is useful for scene annotation and surveillance. Local features have been demonstrated to be robust to image transformations, including occlusions and clutters. However, the geometric property of an aerial image (i.e., the topology and relative displacement of local features), which is key to discriminating aerial image categories, cannot be effectively represented by state-of-the-art generic visual descriptors. To solve this problem, we propose a recognition model that mines graphlets from aerial images, where graphlets are small connected subgraphs reflecting both the geometric property and color/texture distribution of an aerial image. More specifically, each aerial image is decomposed into a set of basic components (e.g., road and playground) and a region adjacency graph (RAG) is accordingly constructed to model their spatial interactions. Aerial image categories recognition can subsequently be casted as RAG-to-RAG matching. Based on graph theory, RAG-to-RAG matching is conducted by comparing all their respective graphlets. Because the number of graphlets is huge, we derive a manifold embedding algorithm to measure different-sized graphlets, after which we select graphlets that have highly discriminative and low redundancy topologies. Through quantizing the selected graphlets from each aerial image into a feature vector, we use support vector machine to discriminate aerial image categories. Experimental results indicate that our method outperforms several state-of-the-art object/scene recognition models, and the visualized graphlets indicate that the discriminative patterns are discovered by our proposed approach.",
Granular Computing: Perspectives and Challenges,"Granular computing, as a new and rapidly growing paradigm of information processing, has attracted many researchers and practitioners. Granular computing is an umbrella term to cover any theories, methodologies, techniques, and tools that make use of information granules in complex problem solving. The aim of this paper is to review foundations and schools of research and to elaborate on current developments in granular computing research. We first review some basic notions of granular computing. Classification and descriptions of various schools of research in granular computing are given. We also present and identify some research directions in granular computing.","Fuzzy sets,
Hospitals,
Sections,
Educational institutions,
Problem-solving,
Information processing"
Global Energy Scenario and Impact of Power Electronics in 21st Century,"Power electronics technology has gained significant maturity after several decades of dynamic evolution of power semiconductor devices, converters, pulse width modulation (PWM) techniques, electrical machines, motor drives, advanced control, and simulation techniques. According to the estimate of the Electric Power Research Institute, roughly 70% of electrical energy in the USA now flows through power electronics, which will eventually grow to 100%. In the 21st century, we expect to see the tremendous impact of power electronics not only in global industrialization and general energy systems, but also in energy saving, renewable energy systems, and electric/hybrid vehicles. The resulting impact in mitigating climate change problems is expected to be enormous. This paper, in the beginning, will discuss the global energy scenario, climate change problems, and the methods of their mitigation. Then, it will discuss the impact of power electronics in energy saving, renewable energy systems, bulk energy storage, and electric/hybrid vehicles. Finally, it will review several example applications before coming to conclusion and future prognosis.","Power electronics,
USA Councils,
Meteorology,
Electricity,
Ice,
Standards,
Fossil fuels"
Dynamic Service Provisioning in Elastic Optical Networks With Hybrid Single-/Multi-Path Routing,"Empowered by the optical orthogonal frequency-division multiplexing (O-OFDM) technology, flexible online service provisioning can be realized with dynamic routing, modulation, and spectrum assignment (RMSA). In this paper, we propose several online service provisioning algorithms that incorporate dynamic RMSA with a hybrid single-/multi-path routing (HSMR) scheme. We investigate two types of HSMR schemes, namely HSMR using online path computation (HSMR-OPC) and HSMR using fixed path sets (HSMR-FPS). Moreover, for HSMR-FPS, we analyze several path selection policies to optimize the design. We evaluate the proposed algorithms with numerical simulations using a Poisson traffic model and two mesh network topologies. The simulation results have demonstrated that the proposed HSMR schemes can effectively reduce the bandwidth blocking probability (BBP) of dynamic RMSA, as compared to two benchmark algorithms that use single-path routing and split spectrum. Our simulation results suggest that HSMR-OPC can achieve the lowest BBP among all HSMR schemes. This is attributed to the fact that HSMR-OPC optimizes routing paths for each request on the fly with considerations of both bandwidth utilizations and lengths of links. Our simulation results also indicate that the HSMR-FPS scheme that use the largest slots-over-square-of-hops first path-selection policy obtains the lowest BBP among all HSMR-FPS schemes. We then investigate the proposed algorithms' impacts on other network performance metrics, including network throughput and network bandwidth fragmentation ratio. To the best of our knowledge, this is the first attempt to consider dynamic RMSA based on both online path computation and offline path computation with various path selection policies for multipath provisioning in O-OFDM networks.",
Fast-Predictive Optimal Control of NPC Multilevel Converters,"The development of high-processing-capability microprocessors allows the implementation of new digital control methods for neutral-point-clamped (NPC) multilevel converter in power-electronic applications. This paper presents a new predictive digital control method for multilevel converters, called “fast predictive.” This method computes the optimal vector using the NPC three-phase multilevel dynamic model equations just once in each control cycle, while current predictive methods need 27 calculations. The closest vector to the optimal vector is found by minimizing the distance between each one of the 27 available vectors to the optimal vector. Space vector modulation could be also used. The obtained performance is similar to the predictive optimal control that uses the converter model to find all the 27 responses of the multilevel and then searches for the vector that minimizes control errors. Relative to predictive optimal control, the fast predictive improves digital processing speed by at least 150% in multilevel converters with 27 vectors. This speed improvement would allow multilevel converters with five or higher number of levels (125 instead of 27 vectors) to be controlled using the same sampling frequency of the three-level inverter. The fast-predictive controller is used in a multilevel rectifier with near-unity power factor to enforce the ac currents. Fast predictive control is also used in the rectifier dc voltage to reduce sensitivity of the dc voltage to dc load disturbances. The simulation and experimental results show that the fast-predictive controller is able to control the ac currents of a three-phase multilevel rectifier, achieving nearly 1.5% total harmonic distortion while balancing the capacitors' dc voltages. The use of predictive control to regulate the dc voltage shows an improvement of approximately 7% compared to a proportional-integral controller.","Vectors,
Mathematical model,
Voltage control,
Predictive control,
Equations,
Rectifiers,
Predictive models"
A Comparative Study of Different Physics-Based NBTI Models,"Different physics-based negative bias temperature instability (NBTI) models as proposed in the literature are reviewed, and the predictive capability of these models is benchmarked against experimental data. Models that focus exclusively on hole trapping in gate-insulator-process-related preexisting traps are found to be inconsistent with direct experimental evidence of interface trap generation. Models that focus exclusively on interface trap generation are incapable of predicting ultrafast measurement data. Models that assume strong correlation between interface trap generation and hole trapping in switching hole traps cannot simultaneously predict long-time dc stress, recovery, and ac stress and cannot estimate gate insulator process impact. Uncorrelated contributions from generation and recovery of interface traps, together with hole trapping and detrapping in preexisting and newly generated bulk insulator traps, are invoked to comprehensively predict dc stress and recovery, ac duty cycle and frequency, and gate insulator process impact of NBTI. The reaction-diffusion model can accurately predict generation and recovery of interface traps for different devices and experimental conditions. Hole trapping/detrapping is modeled using a two-level energy well model.","Stress,
Predictive models,
Stress measurement,
Logic gates,
Time measurement,
Insulators,
Pollution measurement"
Effect of Coupling Between Multiple Transmitters or Multiple Receivers on Wireless Power Transfer,"The operation of wireless power transfer systems with multiple transmitters (TXs) or receivers (RXs) is investigated. With multiple TXs or RXs in a limited space, couplings occur between TXs or between RXs. The frequency conditions for maximum efficiency and power transfer under such couplings are proposed. Effective resonant frequency of the TXs or the RXs is changed due to such couplings, and driving and/or resonant frequencies should therefore be adjusted accordingly. The amount and type of the required adjustments are provided. The efficiencies in these conditions are discussed. These concepts are supported by experiments with couplings between TXs or between RXs. Using the proposed frequency adjustments, 51-65-W power is transferred with 45%-57% efficiency, even with very low coupling coefficients of 0.025-0.063 from TX to RX. This improvement is significant compared to the unadjusted cases where less than 4 W is transferred with only 5%-33% efficiency.","Receivers,
Transmitters,
Resonant frequency,
Couplings,
Coils,
Impedance,
Wireless communication"
Fast and Accurate Matrix Completion via Truncated Nuclear Norm Regularization,"Recovering a large matrix from a small subset of its entries is a challenging problem arising in many real applications, such as image inpainting and recommender systems. Many existing approaches formulate this problem as a general low-rank matrix approximation problem. Since the rank operator is nonconvex and discontinuous, most of the recent theoretical studies use the nuclear norm as a convex relaxation. One major limitation of the existing approaches based on nuclear norm minimization is that all the singular values are simultaneously minimized, and thus the rank may not be well approximated in practice. In this paper, we propose to achieve a better approximation to the rank of matrix by truncated nuclear norm, which is given by the nuclear norm subtracted by the sum of the largest few singular values. In addition, we develop a novel matrix completion algorithm by minimizing the Truncated Nuclear Norm. We further develop three efficient iterative procedures, TNNR-ADMM, TNNR-APGL, and TNNR-ADMMAP, to solve the optimization problem. TNNR-ADMM utilizes the alternating direction method of multipliers (ADMM), while TNNR-AGPL applies the accelerated proximal gradient line search method (APGL) for the final optimization. For TNNR-ADMMAP, we make use of an adaptive penalty according to a novel update rule for ADMM to achieve a faster convergence rate. Our empirical study shows encouraging results of the proposed algorithms in comparison to the state-of-the-art matrix completion algorithms on both synthetic and real visual datasets.",
Benchmarking HEp-2 Cells Classification Methods,"In this paper, we report on the first edition of the HEp-2 Cells Classification contest, held at the 2012 edition of the International Conference on Pattern Recognition, and focused on indirect immunofluorescence (IIF) image analysis. The IIF methodology is used to detect autoimmune diseases by searching for antibodies in the patient serum but, unfortunately, it is still a subjective method that depends too heavily on the experience and expertise of the physician. This has been the motivation behind the recent initial developments of computer aided diagnosis systems in this field. The contest aimed to bring together researchers interested in the performance evaluation of algorithms for IIF image analysis: 28 different recognition systems able to automatically recognize the staining pattern of cells within IIF images were tested on the same undisclosed dataset. In particular, the dataset takes into account the six staining patterns that occur most frequently in the daily diagnostic practice: centromere, nucleolar, homogeneous, fine speckled, coarse speckled, and cytoplasmic. In the paper, we briefly describe all the submitted methods, analyze the obtained results, and discuss the design choices conditioning the performance of each method.","Feature extraction,
Medical services,
Pattern recognition,
Medical diagnostic imaging,
Support vector machines,
Benchmark testing"
Three Fingerprints of Memristor,"This paper illustrates that for a device to be a memristor it should exhibit three characteristic fingerprints: 1) When driven by a bipolar periodic signal the device must exhibit a “pinched hysteresis loop” in the voltage-current plane, assuming the response is periodic. 2) Starting from some critical frequency, the hysteresis lobe area should decrease monotonically as the excitation frequency increases, and 3) the pinched hysteresis loop should shrink to a single-valued function when the frequency tends to infinity. Examples of memristors exhibiting these three fingerprints, along with non-memristors exhibiting only a subset of these fingerprints are also presented. In addition, two different types of pinched hysteresis loops; the transversal (self-crossing) and the non-transversal (tangential) loops exhibited by memristors are also discussed with its identification criterion.","memristors,
hysteresis"
A Review on Distributed Application Processing Frameworks in Smart Mobile Devices for Mobile Cloud Computing,"The latest developments in mobile devices technology have made smartphones as the future computing and service access devices. Users expect to run computational intensive applications on Smart Mobile Devices (SMDs) in the same way as powerful stationary computers. However in spite of all the advancements in recent years, SMDs are still low potential computing devices, which are constrained by CPU potentials, memory capacity and battery life time. Mobile Cloud Computing (MCC) is the latest practical solution for alleviating this incapacitation by extending the services and resources of computational clouds to SMDs on demand basis. In MCC, application offloading is ascertained as a software level solution for augmenting application processing capabilities of SMDs. The current offloading algorithms offload computational intensive applications to remote servers by employing different cloud models. A challenging aspect of such algorithms is the establishment of distributed application processing platform at runtime which requires additional computing resources on SMDs. This paper reviews existing Distributed Application Processing Frameworks (DAPFs) for SMDs in MCC domain. The objective is to highlight issues and challenges to existing DAPFs in developing, implementing, and executing computational intensive mobile applications within MCC domain. It proposes thematic taxonomy of current DAPFs, reviews current offloading frameworks by using thematic taxonomy and analyzes the implications and critical aspects of current offloading frameworks. Further, it investigates commonalities and deviations in such frameworks on the basis significant parameters such as offloading scope, migration granularity, partitioning approach, and migration pattern. Finally, we put forward open research issues in distributed application processing for MCC that remain to be addressed.",
A Review of Fuzzy Cognitive Maps Research During the Last Decade,"This survey makes a review of the most recent applications and trends on fuzzy cognitive maps (FCMs) over the past decade. FCMs are inference networks, using cyclic digraphs, for knowledge representation and reasoning. Over the past decade, FCMs have gained considerable research interest and are widely used to analyze causal complex systems, which have originated from the combination of fuzzy logic and neural networks. FCMs have been applied in diverse application domains, such as computer science, engineering, environmental sciences, behavioral sciences, medicine, business, information systems, and information technology. Their dynamic characteristics and learning capabilities make them essential for a number of tasks such as modeling, analysis, decision making, forecast, etc. Overall, this paper summarizes the current state of knowledge of the topic of FCMs. It creates an understanding of the topic for the reader by discussing the findings presented in recent research papers. A survey on FCM studies concentrated on FCM applications on diverse scientific areas, where the FCMs emerged with a high degree of applicability, has also been done during the past ten years.",
A Single-Stage Microinverter Without Using Eletrolytic Capacitors,"This paper presents a new microinverter topology that is intended for single-phase grid-connected PV systems. The proposed microinverter topology is based on a flyback converter, where an extra switch is added to separate the decoupling capacitor from the PV Module, which allows for a high voltage and voltage ripples across its terminals. This results in reducing the power decoupling required capacitance. In this manner, long life-time low power density film capacitors can be used instead of life-time limited high power density electrolytic capacitors, resulting in remarkable increase of microinverter's lifespan. The main advantages of the proposed topology are summarized as: 1) eliminating the double-frequency power ripple using a small film capacitor; 2) using long lifetime film capacitors, which will improve the reliability of the inverter; and 3) requiring no additional circuitry to manage the transformer leakage energy. A 100-W microinverter prototype was built to verify the proposed topology. Experimental results show that the proposed topology and its control scheme can realize the power decoupling, while maintaining very good conversion efficiency numbers.","Capacitors,
Topology,
Switches,
Capacitance,
Inverters,
Inductance,
Stress"
Cloud-enabled wireless body area networks for pervasive healthcare,"With the support of mobile cloud computing, wireless body area networks can be significantly enhanced for massive deployment of pervasive healthcare applications. However, several technical issues and challenges are associated with the integration of WBANs and MCC. In this article, we study a cloud-enabled WBAN architecture and its applications in pervasive healthcare systems. We highlight the methodologies for transmitting vital sign data to the cloud by using energy-efficient routing, cloud resource allocation, semantic interactions, and data security mechanisms.","Body area networks,
Cloud computing,
Mobile communication,
Pervasive computing,
Semantics,
Biomedical monitoring,
Servers"
On the Design of Artificial-Noise-Aided Secure Multi-Antenna Transmission in Slow Fading Channels,"In this paper, we investigate the design of artificial-noise-aided secure multi-antenna transmission in slow fading channels. The primary design concerns include the transmit power allocation and the rate parameters of the wiretap code. We consider two scenarios with different complexity levels: 1) the design parameters are chosen to be fixed for all transmissions; and 2) they are adaptively adjusted based on the instantaneous channel feedback from the intended receiver. In both scenarios, we provide explicit design solutions for achieving the maximal throughput subject to a secrecy constraint, given by a maximum allowable secrecy outage probability. We then derive accurate approximations for the maximal throughput in both scenarios in the high signal-to-noise ratio region, and give new insights into the additional power cost for achieving a higher security level while maintaining a specified target throughput. In the end, the throughput gain of adaptive transmission over non-adaptive transmission is also quantified and analyzed.",
Hyperspectral Image Classification Based on Structured Sparse Logistic Regression and Three-Dimensional Wavelet Texture Features,"Hyperspectral remote sensing imagery contains rich information on spectral and spatial distributions of distinct surface materials. Owing to its numerous and continuous spectral bands, hyperspectral data enable more accurate and reliable material classification than using panchromatic or multispectral imagery. However, high-dimensional spectral features and limited number of available training samples have caused some difficulties in the classification, such as overfitting in learning, noise sensitiveness, overloaded computation, and lack of meaningful physical interpretability. In this paper, we propose a hyperspectral feature extraction and pixel classification method based on structured sparse logistic regression and 3-D discrete wavelet transform (3D-DWT) texture features. The 3D-DWT decomposes a hyperspectral data cube at different scales, frequencies, and orientations, during which the hyperspectral data cube is considered as a whole tensor instead of adapting the data to a vector or matrix. This allows the capture of geometrical and statistical spectral-spatial structures. After the feature extraction step, sparse representation/modeling is applied for data analysis and processing via sparse regularized optimization, which selects a small subset of the original feature variables to model the data for regression and classification purpose. A linear structured sparse logistic regression model is proposed to simultaneously select the discriminant features from the pool of 3D-DWT texture features and learn the coefficients of the linear classifier, in which the prior knowledge about feature structure can be mapped into the various sparsity-inducing norms such as lasso, group, and sparse group lasso. Furthermore, to overcome the limitation of linear models, we extended the linear sparse model to nonlinear classification by partitioning the feature space into subspaces of linearly separable samples. The advantages of our methods are validated on the real hyperspectral remote sensing data sets.",
Does Wireless Sensor Network Scale? A Measurement Study on GreenOrbs,"Sensor networks are deemed suitable for large-scale deployments in the wild for a variety of applications. In spite of the remarkable efforts the community put to build the sensor systems, an essential question still remains unclear at the system level, motivating us to explore the answer from a point of real-world deployment view. Does the wireless sensor network really scale? We present findings from a large-scale operating sensor network system, GreenOrbs, with up to 330 nodes deployed in the forest. We instrument such an operating network throughout the protocol stack and present observations across layers in the network. Based on our findings from the system measurement, we propose and make initial efforts to validate three conjectures that give potential guidelines for future designs of large-scale sensor networks. 1) A small portion of nodes bottlenecks the entire network, and most of the existing network indicators may not accurately capture them. 2) The network dynamics mainly come from the inherent concurrency of network operations instead of environment changes. 3) The environment, although the dynamics are not as significant as we assumed, has an unpredictable impact on the sensor network. We suggest that an event-based routing structure can be trained and thus better adapted to the wild environment when building a large-scale sensor network.",
Software Engineering in Industrial Automation: State-of-the-Art Review,"This paper presents one perspective on recent developments related to software engineering in the industrial automation sector that spans from manufacturing factory automation to process control systems and energy automation systems. The survey's methodology is based on the classic SWEBOK reference document that comprehensively defines the taxonomy of software engineering domain. This is mixed with classic automation artefacts, such as the set of the most influential international standards and dominating industrial practices. The survey focuses mainly on research publications which are believed to be representative of advanced industrial practices as well.",
Towards Scaling Up Classification-Based Speech Separation,"Formulating speech separation as a binary classification problem has been shown to be effective. While good separation performance is achieved in matched test conditions using kernel support vector machines (SVMs), separation in unmatched conditions involving new speakers and environments remains a big challenge. A simple yet effective method to cope with the mismatch is to include many different acoustic conditions into the training set. However, large-scale training is almost intractable for kernel machines due to computational complexity. To enable training on relatively large datasets, we propose to learn more linearly separable and discriminative features from raw acoustic features and train linear SVMs, which are much easier and faster to train than kernel SVMs. For feature learning, we employ standard pre-trained deep neural networks (DNNs). The proposed DNN-SVM system is trained on a variety of acoustic conditions within a reasonable amount of time. Experiments on various test mixtures demonstrate good generalization to unseen speakers and background noises.",
Nuzzer: A Large-Scale Device-Free Passive Localization System for Wireless Environments,"The widespread usage of WLANs and mobile devices has fostered the interest in localization systems for wireless environments. The majority of research in the context of wireless-based localization systems has focused on device-based active localization, in which devices are attached to tracked entities. Recently, device-free passive localization (DfP) has been proposed where the tracked entity is neither required to carry devices nor to participate actively in the localization process. Previous studies have focused on small areas and/or controlled environments. In this paper, we present the design, implementation, and analysis of Nuzzer, a large-scale DfP localization system, which tracks entities in real environments, rich in multipath. We first present probabilistic techniques for DfP localization of a single entity and evaluate their performance both analytically and in typical office buildings. Our results show that Nuzzer gives location estimates with less than 2-meters median distance error. We then give an algorithm for estimating the number of entities in an area of interest and localizing them into coarse-grained zones to enhance the scalability of the system. This indicates the suitability of Nuzzer to a large number of application domains.","Mathematical model,
Vectors,
Equations,
Histograms,
Wireless communication,
Accuracy,
Probabilistic logic"
Differential Evolution With Ranking-Based Mutation Operators,"Differential evolution (DE) has been proven to be one of the most powerful global numerical optimization algorithms in the evolutionary algorithm family. The core operator of DE is the differential mutation operator. Generally, the parents in the mutation operator are randomly chosen from the current population. In nature, good species always contain good information, and hence, they have more chance to be utilized to guide other species. Inspired by this phenomenon, in this paper, we propose the ranking-based mutation operators for the DE algorithm, where some of the parents in the mutation operators are proportionally selected according to their rankings in the current population. The higher ranking a parent obtains, the more opportunity it will be selected. In order to evaluate the influence of our proposed ranking-based mutation operators on DE, our approach is compared with the jDE algorithm, which is a highly competitive DE variant with self-adaptive parameters, with different mutation operators. In addition, the proposed ranking-based mutation operators are also integrated into other advanced DE variants to verify the effect on them. Experimental results indicate that our proposed ranking-based mutation operators are able to enhance the performance of the original DE algorithm and the advanced DE algorithms.",
Impact of Pointing Errors on the Performance of Mixed RF/FSO Dual-Hop Transmission Systems,"In this work, the performance analysis of a dual-hop relay transmission system composed of asymmetric radio-frequency (RF)/free-space optical (FSO) links with pointing errors is presented. More specifically, we build on the system model presented in to derive new exact closed-form expressions for the cumulative distribution function, probability density function, moment generating function, and moments of the end-to-end signal-to-noise ratio in terms of the Meijer's G function. We then capitalize on these results to offer new exact closed-form expressions for the higher-order amount of fading, average error rate for binary and M-ary modulation schemes, and the ergodic capacity, all in terms of Meijer's G functions. Our new analytical results were also verified via computer-based Monte-Carlo simulation results.",
SVNE: Survivable Virtual Network Embedding Algorithms for Network Virtualization,"Network virtualization can offer more flexibility and better manageability for the future Internet by allowing multiple heterogeneous virtual networks (VN) to coexist on a shared infrastructure provider (InP) network. A major challenge in this respect is the VN embedding problem that deals with the efficient mapping of virtual resources on InP network resources. Previous research focused on heuristic algorithms for the VN embedding problem assuming that the InP network remains operational at all times. In this paper, we remove this assumption by formulating the survivable virtual network embedding (SVNE) problem. We then develop a pro-active, and a hybrid policy heuristic to solve it, and a baseline policy heuristic to compare to. The hybrid policy is based on a fast re-routing strategy and utilizes a pre-reserved quota for backup on each physical link. Our evaluation results show that our proposed heuristics for SVNE outperform the baseline heuristic in terms of long term business profit for the InP, acceptance ratio, bandwidth efficiency, and response time.",
Supervised and Unsupervised Speech Enhancement Using Nonnegative Matrix Factorization,"Reducing the interference noise in a monaural noisy speech signal has been a challenging task for many years. Compared to traditional unsupervised speech enhancement methods, e.g., Wiener filtering, supervised approaches, such as algorithms based on hidden Markov models (HMM), lead to higher-quality enhanced speech signals. However, the main practical difficulty of these approaches is that for each noise type a model is required to be trained a priori. In this paper, we investigate a new class of supervised speech denoising algorithms using nonnegative matrix factorization (NMF). We propose a novel speech enhancement method that is based on a Bayesian formulation of NMF (BNMF). To circumvent the mismatch problem between the training and testing stages, we propose two solutions. First, we use an HMM in combination with BNMF (BNMF-HMM) to derive a minimum mean square error (MMSE) estimator for the speech signal with no information about the underlying noise type. Second, we suggest a scheme to learn the required noise BNMF model online, which is then used to develop an unsupervised speech enhancement system. Extensive experiments are carried out to investigate the performance of the proposed methods under different conditions. Moreover, we compare the performance of the developed algorithms with state-of-the-art speech enhancement schemes using various objective measures. Our simulations show that the proposed BNMF-based methods outperform the competing algorithms substantially.",
To offload or not to offload? The bandwidth and energy costs of mobile cloud computing,"The cloud seems to be an excellent companion of mobile systems, to alleviate battery consumption on smartphones and to backup user's data on-the-fly. Indeed, many recent works focus on frameworks that enable mobile computation offloading to software clones of smartphones on the cloud and on designing cloud-based backup systems for the data stored in our devices. Both mobile computation offloading and data backup involve communication between the real devices and the cloud. This communication does certainly not come for free. It costs in terms of bandwidth (the traffic overhead to communicate with the cloud) and in terms of energy (computation and use of network interfaces on the device). In this work we study the fmobile software/data backupseasibility of both mobile computation offloading and mobile software/data backups in real-life scenarios. In our study we assume an architecture where each real device is associated to a software clone on the cloud. We consider two types of clones: The off-clone, whose purpose is to support computation offloading, and the back-clone, which comes to use when a restore of user's data and apps is needed. We give a precise evaluation of the feasibility and costs of both off-clones and back-clones in terms of bandwidth and energy consumption on the real device. We achieve this through measurements done on a real testbed of 11 Android smartphones and an equal number of software clones running on the Amazon EC2 public cloud. The smartphones have been used as the primary mobile by the participants for the whole experiment duration.","Smart phones,
Mobile communication,
Cloning,
IEEE 802.11 Standards,
Batteries,
Software,
Bandwidth"
Meshworm: A Peristaltic Soft Robot With Antagonistic Nickel Titanium Coil Actuators,"This paper presents the complete development and analysis of a soft robotic platform that exhibits peristaltic locomotion. The design principle is based on the antagonistic arrangement of circular and longitudinal muscle groups of Oligochaetes. Sequential antagonistic motion is achieved in a flexible braided mesh-tube structure using a nickel titanium (NiTi) coil actuators wrapped in a spiral pattern around the circumference. An enhanced theoretical model of the NiTi coil spring describes the combination of martensite deformation and spring elasticity as a function of geometry. A numerical model of the mesh structures reveals how peristaltic actuation induces robust locomotion and details the deformation by the contraction of circumferential NiTi actuators. Several peristaltic locomotion modes are modeled, tested, and compared on the basis of speed. Utilizing additional NiTi coils placed longitudinally, steering capabilities are incorporated. Proprioceptive potentiometers sense segment contraction, which enables the development of closed-loop controllers. Several appropriate control algorithms are designed and experimentally compared based on locomotion speed and energy consumption. The entire mechanical structure is made of flexible mesh materials and can withstand significant external impact during operation. This approach allows a completely soft robotic platform by employing a flexible control unit and energy sources.","Springs,
Coils,
Actuators,
Robots,
Annealing,
Wires,
Mathematical model"
A Free and Fast Three-Dimensional/Two-Dimensional Solar Cell Simulator Featuring Conductive Boundary and Quasi-Neutrality Approximations,"Details of Quokka, which is a freely available fast 3-D solar cell simulation tool, are presented. Simplifications to the full set of charge carrier transport equations, i.e., quasi-neutrality and conductive boundaries, result in a model that is computationally inexpensive without a loss of generality. Details on the freely available finite volume implementation in MATLAB are given, which shows computation times on the order of seconds to minutes for a full I-V curve sweep on a conventional personal computer. As an application example, the validity of popular analytical models of partial rear contact cells is verified under varying conditions. Consequently, it is observed that significant errors can occur if these analytical models are used to derive local recombination properties from effective lifetime measurements of test structures.",
Analysis of Internal Quantum Efficiency and Current Injection Efficiency in III-Nitride Light-Emitting Diodes,"Current injection efficiency and internal quantum efficiency (IQE) in InGaN quantum well (QW) based light emitting diodes (LEDs) are investigated. The analysis is based on current continuity relation for drift and diffusion carrier transport across the QW-barrier systems. A self-consistent 6-band k ·p method is used to calculate the band structure for InGaN QW structure. Carrier-photon rate equations are utilized to describe radiative and non-radiative recombination in the QW and the barrier regions, carrier transport and capture time, and thermionic emission leading to carrier leakage out of the QW. Our model indicates that the IQE in the conventional 24-Å In0.28Ga0.72 N -GaN QW structure reaches its peak at low injection current density and reduces gradually with further increase in current due to the large thermionic carrier leakage. The efficiency droop phenomenon at high current density in III-nitride LEDs is thus consistent with the high-driving-current induced quenching in current injection efficiency predicted by our model. The effects of the monomolecular recombination coefficient, Auger recombination coefficient and GaN hole mobility on the current injection efficiency and IQE are studied. Structures combining InGaN QW with thin larger energy bandgap barriers such as AlxGa1-xN, lattice-matched AlxIn1-xN, and lattice-matched AlxInyGa1-x-y N have been analyzed to improve current injection efficiency and thus minimize droop at high current injection in III-nitride LEDs. Effect of the thickness of the larger energy bandgap barriers (AlGaN, AlInN and AlInGaN) on injection efficiency and IQE are investigated. The use of thin AlGaN barriers shows slight reduction of quenching of the injection efficiency as the current density increases. The use of thin lattice-matched AlInN or AlInGaN barriers shows significant suppression of efficiency-droop in nitride LEDs.","Radiative recombination,
Light emitting diodes,
Gallium nitride,
Charge carrier processes,
Photonic band gap,
Solid state lighting,
Current density"
Energy-Optimal Mobile Cloud Computing under Stochastic Wireless Channel,"This paper provides a theoretical framework of energy-optimal mobile cloud computing under stochastic wireless channel. Our objective is to conserve energy for the mobile device, by optimally executing mobile applications in the mobile device (i.e., mobile execution) or offloading to the cloud (i.e., cloud execution). One can, in the former case sequentially reconfigure the CPU frequency; or in the latter case dynamically vary the data transmission rate to the cloud, in response to the stochastic channel condition. We formulate both scheduling problems as constrained optimization problems, and obtain closed-form solutions for optimal scheduling policies. Furthermore, for the energy-optimal execution strategy of applications with small output data (e.g., CloudAV), we derive a threshold policy, which states that the data consumption rate, defined as the ratio between the data size (L) and the delay constraint (T), is compared to a threshold which depends on both the energy consumption model and the wireless channel model. Finally, numerical results suggest that a significant amount of energy can be saved for the mobile device by optimally offloading mobile applications to the cloud in some cases. Our theoretical framework and numerical investigations will shed lights on system implementation of mobile cloud computing under stochastic wireless channel.","Mobile communication,
Mobile handsets,
Clocks,
Energy consumption,
Wireless communication,
Cloning,
Optimal scheduling"
Robust Synchronization of Uncertain Linear Multi-Agent Systems,"This paper deals with robust synchronization of uncertain multi-agent networks. Given a network with for each of the agents identical nominal linear dynamics, we allow uncertainty in the form of additive perturbations of the transfer matrices of the nominal dynamics. The perturbations are assumed to be stable and bounded in H∞-norm by some a priori given desired tolerance. We derive state space formulas for observer based dynamic protocols that achieve synchronization for all perturbations bounded by this desired tolerance. It is shown that a protocol achieves robust synchronization if and only if each controller from a related finite set of feedback controllers robustly stabilizes a given, single linear system. Our protocols are expressed in terms of real symmetric solutions of certain algebraic Riccati equations and inequalities, and also involve weighting factors that depend on the eigenvalues of the graph Laplacian. For undirected network graphs we show that within the class of such dynamic protocols, a guaranteed achievable tolerance can be obtained that is proportional to the quotient of the second smallest and the largest eigenvalue of the Laplacian. We also extend our results to additive nonlinear perturbations with L2-gain bounded by a given tolerance.",
Optimal Home Energy Management Under Dynamic Electrical and Thermal Constraints,"The optimization of energy consumption, with consequent costs reduction, is one of the main challenges in present and future smart grids. Of course, this has to occur keeping the living comfort for the end-user unchanged. In this work, an approach based on the mixed-integer linear programming paradigm, which is able to provide an optimal solution in terms of tasks power consumption and management of renewable resources, is developed. The proposed algorithm yields an optimal task scheduling under dynamic electrical constraints, while simultaneously ensuring the thermal comfort according to the user needs. On purpose, a suitable thermal model based on heat-pump usage has been considered in the framework. Some computer simulations using real data have been performed, and obtained results confirm the efficiency and robustness of the algorithm, also in terms of achievable cost savings.",
Present Status and Future Trends in Electric Vehicle Propulsion Technologies,"In this paper, the current status and the requirements of primary electric propulsion components-the battery, the electric motors, and the power electronics system-are reviewed. The future trends in the electric propulsion systems, battery charging, and the types of power trains are presented. Possible future electric vehicle powertrain systems based on lithium air battery and plug-in fuel cell vehicles are also discussed.","Batteries,
Propulsion,
Hybrid electric vehicles,
Electric vehicles,
Electric motors"
CSI-Based Indoor Localization,"Indoor positioning systems have received increasing attention for supporting location-based services in indoor environments. WiFi-based indoor localization has been attractive due to its open access and low cost properties. However, the distance estimation based on received signal strength indicator (RSSI) is easily affected by the temporal and spatial variance due to the multipath effect, which contributes to most of the estimation errors in current systems. In this work, we analyze this effect across the physical layer and account for the undesirable RSSI readings being reported. We explore the frequency diversity of the subcarriers in orthogonal frequency division multiplexing systems and propose a novel approach called FILA, which leverages the channel state information (CSI) to build a propagation model and a fingerprinting system at the receiver. We implement the FILA system on commercial 802.11 NICs, and then evaluate its performance in different typical indoor scenarios. The experimental results show that the accuracy and latency of distance calculation can be significantly enhanced by using CSI. Moreover, FILA can significantly improve the localization accuracy compared with the corresponding RSSI approach.",
A Survey on Intrabody Communications for Body Area Network Applications,"The rapid increase in healthcare demand has seen novel developments in health monitoring technologies, such as the body area networks (BAN) paradigm. BAN technology envisions a network of continuously operating sensors, which measure critical physical and physiological parameters e.g., mobility, heart rate, and glucose levels. Wireless connectivity in BAN technology is key to its success as it grants portability and flexibility to the user. While radio frequency (RF) wireless technology has been successfully deployed in most BAN implementations, they consume a lot of battery power, are susceptible to electromagnetic interference and have security issues. Intrabody communication (IBC) is an alternative wireless communication technology which uses the human body as the signal propagation medium. IBC has characteristics that could naturally address the issues with RF for BAN technology. This survey examines the on-going research in this area and highlights IBC core fundamentals, current mathematical models of the human body, IBC transceiver designs, and the remaining research challenges to be addressed. IBC has exciting prospects for making BAN technologies more practical in the future.","Integrated circuit modeling,
Biological system modeling,
Electrodes,
Couplings,
Wireless communication,
Radio frequency,
Dispersion"
A Parameterization Approach for Enhancing PV Model Accuracy,"Reliable and accurate photovoltaic (PV) models are essential for simulation of PV power systems. A solar cell is typically represented by a single diode equivalent circuit. The circuit parameters need to be estimated accurately to get an accurate model. However, one circuit parameter was assumed because of the limited information provided by commercial manufacturing datasheets, and thus the model accuracy is affected. This paper proposes a parameterization approach for PV models to improve modeling accuracy and reduce implementation complexity. It develops a method to accurately estimate circuit parameters, and thus improving the overall accuracy, relying only on the points provided by all commercial modules datasheet. The proposed modeling approach results in two simplified models demonstrating the advantage of fast simulation. The effectiveness of the modeling approach is thoroughly evaluated by comparing the simulation results with experimental data of solar modules made of mono-crystalline, multi-crystalline, and thin film.","Mathematical model,
Integrated circuit modeling,
Resistance,
Equations,
Accuracy,
Computational modeling,
Upper bound"
"Gearing resource-poor mobile devices with powerful clouds: architectures, challenges, and applications","Mobile cloud computing, with its promise to meet the urgent need for richer applications and services of resource-constrained mobile devices, is emerging as a new computing paradigm and has recently attracted significant attention. However, there is no clear definition and no well defined scope for mobile cloud computing due to commercial hype, and diverse ways of combining cloud computing and mobile applications. This article makes the first attempt to present a survey of mobile cloud computing from the perspective of its intended usages. Specifically, we introduce three common mobile cloud architectures and classify comprehensive existing work into two fundamental categories: computation offloading and capability extending. Considering the energy bottleneck and user context of mobile devices, we discuss the research challenges and opportunities of introducing cloud computing to assist mobile devices, including energy-efficient interactions, virtual machine migration overhead, privacy, and security. Moreover, we demonstrate three real-world applications enabled by mobile cloud computing, in order to stimulate further discussion and development of this emerging field.","Mobile handsets,
Cloud computing,
Mobile communication,
Computer architecture,
Batteries,
Ad hoc networks,
Computational modeling"
Enabling Seamless Wireless Power Delivery in Dynamic Environments,"Effective means of delivering wireless power to volumes of spaces will enable users the freedom and mobility to seamlessly power and recharge their devices in an unencumbered fashion. This has particular importance for consumer electronic, medical, and industrial applications, where usage models focus on unstructured and dynamic environments. However, existing wireless power technology falls short of this vision. Inductive charging solutions are limited to near-contact distances and require a docking station or precise placement for effective operation. Far-field wireless power techniques allow much greater range, but require complicated tracking systems to maintain a line-of-sight connection for high-efficiency power delivery to mobile applications. Recent work using magnetically coupled resonators (MCRs) for wireless power delivery has shown a promising intersection between range (on the order of a meter), efficiency (over 80%), and delivered power (up to tens of watts). However, unpredictable loads rapidly change system operating points, and changes in position disrupt system efficiency, which affects the ultimate usability of these systems. Dynamic adaptation to these changes in operating conditions and power transfer range is a critical capability in developing a fully functional and versatile wireless power solution. This paper provides an overview of methods used to adapt to variations in range, orientation, and load using both wideband and fixed-frequency techniques.","Wireless communication,
Power transmission,
Adaptive systems,
Resonance,
Rectifiers,
Magnetic resonance,
Magnetic couplings"
Superpixel Classification Based Optic Disc and Optic Cup Segmentation for Glaucoma Screening,"Glaucoma is a chronic eye disease that leads to vision loss. As it cannot be cured, detecting the disease in time is important. Current tests using intraocular pressure (IOP) are not sensitive enough for population based glaucoma screening. Optic nerve head assessment in retinal fundus images is both more promising and superior. This paper proposes optic disc and optic cup segmentation using superpixel classification for glaucoma screening. In optic disc segmentation, histograms, and center surround statistics are used to classify each superpixel as disc or non-disc. A self-assessment reliability score is computed to evaluate the quality of the automated optic disc segmentation. For optic cup segmentation, in addition to the histograms and center surround statistics, the location information is also included into the feature space to boost the performance. The proposed segmentation methods have been evaluated in a database of 650 images with optic disc and optic cup boundaries manually marked by trained professionals. Experimental results show an average overlapping error of 9.5% and 24.1% in optic disc and optic cup segmentation, respectively. The results also show an increase in overlapping error as the reliability score is reduced, which justifies the effectiveness of the self-assessment. The segmented optic disc and optic cup are then used to compute the cup to disc ratio for glaucoma screening. Our proposed method achieves areas under curve of 0.800 and 0.822 in two data sets, which is higher than other methods. The methods can be used for segmentation and glaucoma screening. The self-assessment will be used as an indicator of cases with large errors and enhance the clinical deployment of the automatic segmentation and screening.","Optical imaging,
Image segmentation,
Adaptive optics,
Optical sensors,
Histograms,
Deformable models,
Image color analysis"
Atomic Norm Denoising With Applications to Line Spectral Estimation,"Motivated by recent work on atomic norms in inverse problems, we propose a new approach to line spectral estimation that provides theoretical guarantees for the mean-squared-error (MSE) performance in the presence of noise and without knowledge of the model order. We propose an abstract theory of denoising with atomic norms and specialize this theory to provide a convex optimization problem for estimating the frequencies and phases of a mixture of complex exponentials. We show that the associated convex optimization problem can be solved in polynomial time via semidefinite programming (SDP). We also show that the SDP can be approximated by an l1-regularized least-squares problem that achieves nearly the same error rate as the SDP but can scale to much larger problems. We compare both SDP and l1-based approaches with classical line spectral analysis methods and demonstrate that the SDP outperforms the l1 optimization which outperforms MUSIC, Cadzow's, and Matrix Pencil approaches in terms of MSE over a wide range of signal-to-noise ratios.","Noise reduction,
Estimation,
Noise,
Atomic clocks,
Abstracts,
Polynomials,
Frequency estimation"
Convergence of MANET and WSN in IoT Urban Scenarios,"Ubiquitous smart environments, equipped with low-cost and easy-deployable wireless sensor networks (WSNs) and widespread mobile ad hoc networks (MANETs), are opening brand new opportunities in wide-scale urban monitoring. Indeed, MANET and WSN convergence paves the way for the development of brand new Internet of Things (IoT) communication platforms with a high potential for a wide range of applications in different domains. Urban data collection, i.e., the harvesting of monitoring data sensed by a large number of collaborating sensors, is a challenging task because of many open technical issues, from typical WSN limitations (bandwidth, energy, delivery time, etc.) to the lack of widespread WSN data collection standards, needed for practical deployment in existing and upcoming IoT scenarios. In particular, effective collection is crucial for classes of smart city services that require a timely delivery of urgent data such as environmental monitoring, homeland security, and city surveillance. After surveying the existing WSN interoperability efforts for urban sensing, this paper proposes an original solution to integrate and opportunistically exploit MANET overlays, impromptu, and collaboratively formed over WSNs, to boost urban data harvesting in IoT. Overlays are used to dynamically differentiate and fasten the delivery of urgent sensed data over low-latency MANET paths by integrating with latest emergent standards/specifications for WSN data collection. The reported experimental results show the feasibility and effectiveness (e.g., limited coordination overhead) of the proposed solution.",
D-ADMM: A Communication-Efficient Distributed Algorithm for Separable Optimization,"We propose a distributed algorithm, named Distributed Alternating Direction Method of Multipliers (D-ADMM), for solving separable optimization problems in networks of interconnected nodes or agents. In a separable optimization problem there is a private cost function and a private constraint set at each node. The goal is to minimize the sum of all the cost functions, constraining the solution to be in the intersection of all the constraint sets. D-ADMM is proven to converge when the network is bipartite or when all the functions are strongly convex, although in practice, convergence is observed even when these conditions are not met. We use D-ADMM to solve the following problems from signal processing and control: average consensus, compressed sensing, and support vector machines. Our simulations show that D-ADMM requires less communications than state-of-the-art algorithms to achieve a given accuracy level. Algorithms with low communication requirements are important, for example, in sensor networks, where sensors are typically battery-operated and communicating is the most energy consuming operation.","Distributed algorithms,
Convergence,
Image color analysis,
Cost function,
Algorithm design and analysis,
Color"
Feature Selection for Multimedia Analysis by Sharing Information Among Multiple Tasks,"While much progress has been made to multi-task classification and subspace learning, multi-task feature selection has long been largely unaddressed. In this paper, we propose a new multi-task feature selection algorithm and apply it to multimedia (e.g., video and image) analysis. Instead of evaluating the importance of each feature individually, our algorithm selects features in a batch mode, by which the feature correlation is considered. While feature selection has received much research attention, less effort has been made on improving the performance of feature selection by leveraging the shared knowledge from multiple related tasks. Our algorithm builds upon the assumption that different related tasks have common structures. Multiple feature selection functions of different tasks are simultaneously learned in a joint framework, which enables our algorithm to utilize the common knowledge of multiple tasks as supplementary information to facilitate decision making. An efficient iterative algorithm is proposed to optimize it, whose convergence is guaranteed. Experiments on different databases have demonstrated the effectiveness of the proposed algorithm.","Multimedia communication,
Algorithm design and analysis,
Linear programming,
Training data,
Support vector machines,
Convergence,
Databases"
General Framework to Histogram-Shifting-Based Reversible Data Hiding,"Histogram shifting (HS) is a useful technique of reversible data hiding (RDH). With HS-based RDH, high capacity and low distortion can be achieved efficiently. In this paper, we revisit the HS technique and present a general framework to construct HS-based RDH. By the proposed framework, one can get a RDH algorithm by simply designing the so-called shifting and embedding functions. Moreover, by taking specific shifting and embedding functions, we show that several RDH algorithms reported in the literature are special cases of this general construction. In addition, two novel and efficient RDH algorithms are also introduced to further demonstrate the universality and applicability of our framework. It is expected that more efficient RDH algorithms can be devised according to the proposed framework by carefully designing the shifting and embedding functions.","Histograms,
Data mining,
Nickel,
Zinc,
Algorithm design and analysis,
Image coding,
Image restoration"
T-Finder: A Recommender System for Finding Passengers and Vacant Taxis,"This paper presents a recommender system for both taxi drivers and people expecting to take a taxi, using the knowledge of 1) passengers' mobility patterns and 2) taxi drivers' picking-up/dropping-off behaviors learned from the GPS trajectories of taxicabs. First, this recommender system provides taxi drivers with some locations and the routes to these locations, toward which they are more likely to pick up passengers quickly (during the routes or in these locations) and maximize the profit of the next trip. Second, it recommends people with some locations (within a walking distance) where they can easily find vacant taxis. In our method, we learn the above-mentioned knowledge (represented by probabilities) from GPS trajectories of taxis. Then, we feed the knowledge into a probabilistic model that estimates the profit of the candidate locations for a particular driver based on where and when the driver requests the recommendation. We build our system using historical trajectories generated by over 12,000 taxis during 110 days and validate the system with extensive evaluations including in-the-field user studies.","Vehicles,
Roads,
Trajectory,
Global Positioning System,
Recommender systems,
Probability,
Silicon"
"M
-Matrix Strategies for Pinning-Controlled Leader-Following Consensus in Multiagent Systems With Nonlinear Dynamics","This paper considers the leader-following consensus problem for multiagent systems with inherent nonlinear dynamics. Some M-matrix strategies are developed to address several challenging issues in the pinning control of multiagent systems by using algebraic graph theory and the properties of nonnegative matrices. It is shown that second-order leader-following consensus in a nonlinear multiagent system can be reached if the virtual leader has a directed path to every follower and a derived quantity is greater than a positive threshold. In particular, this paper analytically proves that leader-following consensus may be easier to be achieved by pinning more agents or increasing the pinning feedback gains. A selective pinning scheme is then proposed for nonlinear multiagent systems with directed network topologies. Numerical results are given to verify the theoretical analysis.",
An Integrated Design Framework of Fault-Tolerant Wireless Networked Control Systems for Industrial Automatic Control Applications,"In this paper, a design framework of fault-tolerant wireless networked control systems (NCSs) is developed for industrial automation applications. The main objective is to achieve an integrated parameterization and design of the communication protocols, the control and fault diagnosis algorithms aiming at meeting high real-time requirements in industrial applications. To illustrate the design framework, a laboratory wireless fault-tolerant NCS platform is presented.","Data communication,
Sensors,
Cascading style sheets,
Observers,
Fault tolerance,
Fault tolerant systems,
Real time systems"
Cloud-Based Software Platform for Big Data Analytics in Smart Grids,"This article focuses on a scalable software platform for the Smart Grid cyber-physical system using cloud technologies. Dynamic Demand Response (D2R) is a challenge-application to perform intelligent demand-side management and relieve peak load in Smart Power Grids. The platform offers an adaptive information integration pipeline for ingesting dynamic data; a secure repository for researchers to share knowledge; scalable machine-learning models trained over massive datasets for agile demand forecasting; and a portal for visualizing consumption patterns, and validated at the University of Southern California's campus microgrid. The article examines the role of clouds and their tradeoffs for use in the Smart Grid Cyber-Physical Sagileystem.",
Optimal Scheduling and Power Allocation for Two-Hop Energy Harvesting Communication Systems,"Energy harvesting (EH) has recently emerged as a promising technique for green communications. To realize its potential, communication protocols need to be redesigned to combat the randomness of the harvested energy. In this paper, we investigate how to apply relaying to improve the short-term performance of EH communication systems. With an EH source and a non-EH half-duplex relay, we consider two different design objectives: 1) short-term throughput maximization; and 2) transmission completion time minimization. Both problems are joint time scheduling and power allocation problems, rendered quite challenging by the half-duplex constraint at the relay. A key finding is that directional water-filling (DWF), which is the optimal power allocation algorithm for the single-hop EH system, can serve as guideline for the design of two-hop communication systems, as it not only determines the value of the optimal performance, but also forms the basis to derive optimal solutions for both design problems. Based on a relaxed energy profile along with the DWF algorithm, we derive key properties of the optimal solutions for both problems and thereafter propose efficient algorithms. Simulation results will show that both time scheduling and power allocation optimizations are necessary in two-hop EH communication systems.","Relays,
Resource management,
Energy harvesting,
Communication systems,
Throughput,
Optimal scheduling,
Minimization"
Development of a SiC JFET-Based Six-Pack Power Module for a Fully Integrated Inverter,"In this paper, a fully integrated silicon carbide (SiC)-based six-pack power module is designed and developed. With 1200-V, 100-A module rating, each switching element is composed of four paralleled SiC junction gate field-effect transistors (JFETs) with two antiparallel SiC Schottky barrier diodes. The stability of the module assembly processes is confirmed with 1000 cycles of -40°C to +200°C thermal shock tests with 1.3°C/s temperature change. The static characteristics of the module are evaluated and the results show 55 mΩ on-state resistance of the phase leg at 200°C junction temperature. For switching performances, the experiments demonstrate that while utilizing a 650-V voltage and 60-A current, the module switching loss decreases as the junction temperature increases up to 150°C. The test setup over a large temperature range is also described. Meanwhile, the shoot-through influenced by the SiC JFET internal capacitance as well as package parasitic inductances are discussed. Additionally, a liquid cooled three-phase inverter with 22.9 cm × 22.4 cm × 7.1 cm volume and 3.53-kg weight, based on this power module, is designed and developed for electric vehicle and hybrid electric vehicle applications. A conversion efficiency of 98.5% is achieved at 10 kHz switching frequency at 5 kW output power. The inverter is evaluated with coolant temperature up to 95°C successfully.","JFETs,
Silicon carbide,
Switches,
Inductance,
Logic gates,
Multichip modules,
Temperature measurement"
Efficient Approaches for Modeling and Simulating Photovoltaic Power Systems,"Modeling and simulation of photovoltaic (PV) power systems have become increasingly important with wide acceptance and integration of solar energy in modern electric grids. The transcendental nonlinear equations describing the PV generator, which are coupled with the detailed switching models of the power electronic converters, generally result in slow and inefficient simulations, especially when long-term analyses are required. This paper focuses on simple and efficient modeling approaches that are suitable for long-term and large PV system analyses. This study provides a simplified PV-cell model and its parameterization, guaranteeing that the I-V characteristic curves pass through the typical points given in manufacturers' datasheets. Furthermore, several power interface models are provided for fast simulation purpose. A classical two-stage power processing system with intermediate dc link used as a string inverter, as well as a single-stage conversion unit used in distributed module-dedicated PV applications, are taken as application examples. The generalized modeling approach is thoroughly evaluated by comparing the simulation results with the experimental data of a practical 2.4-kW grid-tied PV solar unit. The proposed methodology is shown to have advantages over conventional modeling approaches to simulate long-term grid-tied operation.","Integrated circuit modeling,
Mathematical model,
Computational modeling,
Photovoltaic systems,
Power systems,
Inverters"
"600-V Normally Off
SiN
x
/AlGaN/GaN MIS-HEMT With Large Gate Swing and Low Current Collapse","In this letter, 600-V normally-OFF SiNx/AlGaN/GaN metal-insulator-semiconductor high-electron-mobility transistor (MIS-HEMT) is reported. Normally-OFF operation and low OFF-state gate leakage are obtained by using fluorine plasma ion implantation in conjunction with the adoption of a 17-nm SiNx thin film grown by plasma-enhanced chemical vapor deposition as the gate insulator. The normally-OFF MIS-HEMT exhibits a threshold voltage of +3.6 V, a drive current of 430 mA/mm at a gate bias of 14 V, a specific ON-resistance of 2.1 mΩ·cm2 and an OFF-state breakdown voltage of 604 V at a drain leakage current of 1 μA/mm with VGS=0 V, and the substrate grounded. Effective current collapse suppression is obtained by AlN/SiNx passivation as proved by high-speed pulsed I-V and low-speed high-voltage switching measurement results.",
Demand Response Management via Real-Time Electricity Price Control in Smart Grids,"This paper proposes a real-time pricing scheme that reduces the peak-to-average load ratio through demand response management in smart grid systems. The proposed scheme solves a two-stage optimization problem. On one hand, each user reacts to prices announced by the retailer and maximizes its payoff, which is the difference between its quality-of-usage and the payment to the retailer. On the other hand, the retailer designs the real-time prices in response to the forecasted user reactions to maximize its profit. In particular, each user computes its optimal energy consumption either in closed forms or through an efficient iterative algorithm as a function of the prices. At the retailer side, we develop a Simulated-Annealing-based Price Control (SAPC) algorithm to solve the non-convex price optimization problem. In terms of practical implementation, the users and the retailer interact with each other via a limited number of message exchanges to find the optimal prices. By doing so, the retailer can overcome the uncertainty of users' responses, and users can determine their energy usage based on the actual prices to be used. Our simulation results show that the proposed real-time pricing scheme can effectively shave the energy usage peaks, reduce the retailer's cost, and improve the payoffs of the users.","smart power grids,
demand forecasting,
demand side management,
energy consumption,
iterative methods,
optimisation,
pricing"
Achieving Maximum Energy-Efficiency in Multi-Relay OFDMA Cellular Networks: A Fractional Programming Approach,"In this paper, the joint power and subcarrier allocation problem is solved in the context of maximizing the energy-efficiency (EE) of a multi-user, multi-relay orthogonal frequency division multiple access (OFDMA) cellular network, where the objective function is formulated as the ratio of the spectral-efficiency (SE) over the total power dissipation. It is proven that the fractional programming problem considered is quasi-concave so that Dinkelbach's method may be employed for finding the optimal solution at a low complexity. This method solves the above-mentioned master problem by solving a series of parameterized concave secondary problems. These secondary problems are solved using a dual decomposition approach, where each secondary problem is further decomposed into a number of similar subproblems. The impact of various system parameters on the attainable EE and SE of the system employing both EE maximization (EEM) and SE maximization (SEM) algorithms is characterized. In particular, it is observed that increasing the number of relays for a range of cell sizes, although marginally increases the attainable SE, reduces the EE significantly. It is noted that the highest SE and EE are achieved, when the relays are placed closer to the BS to take advantage of the resultant line-of-sight link. Furthermore, increasing both the number of available subcarriers and the number of active user equipment (UE) increases both the EE and the total SE of the system as a benefit of the increased frequency and multi-user diversity, respectively. Finally, it is demonstrated that as expected, increasing the available power tends to improve the SE, when using the SEM algorithm. By contrast, given a sufficiently high available power, the EEM algorithm attains the maximum achievable EE and a suboptimal SE.",
Robust Adaptive Position Mooring Control for Marine Vessels,"In this paper, robust adaptive control with dynamic control allocation is proposed for the positioning of marine vessels equipped with a thruster assisted mooring system, in the presence of parametric uncertainties, unknown disturbances and input nonlinearities. Using neural network approximation and variable structure based techniques in combination with backstepping and Lyapunov synthesis, the positioning control is developed to handle the uncertainties, input saturation and dead-zone characteristics of the mooring lines and thrusters. Full state feedback with all states measurable and output feedback using high gain observer to estimate unmeasurable states are considered. Dynamic control allocation is presented for actuation of the position mooring system. Under the proposed robust adaptive control, semi-global uniform boundedness of the closed-loop signals are guaranteed. Numerical simulations are carried out to show the effectiveness of the proposed control.",
"From Model, Signal to Knowledge: A Data-Driven Perspective of Fault Detection and Diagnosis","This review paper is to give a full picture of fault detection and diagnosis (FDD) in complex systems from the perspective of data processing. As a matter of fact, an FDD system is a data-processing system on the basis of information redundancy, in which the data and human's understanding of the data are two fundamental elements. Human's understanding may be an explicit input-output model representing the relationship among the system's variables. It may also be represented as knowledge implicitly (e.g., the connection weights of a neural network). Therefore, FDD is done through some kind of modeling, signal processing, and intelligence computation. In this paper, a variety of FDD techniques are reviewed within the unified data-processing framework to give a full picture of FDD and achieve a new level of understanding. According to the types of data and how the data are processed, the FDD methods are classified into three categories: model-based online data-driven methods, signal-based methods, and knowledge-based history data-driven methods. An outlook to the possible evolution of FDD in industrial automation, including the hybrid FDD and the emerging networked FDD, are also presented to reveal the future development direction in this field.","Data models,
Observers,
Redundancy,
Fault diagnosis,
Knowledge based systems,
Analytical models,
Fault detection"
Consensus in Multi-Agent Systems With Second-Order Dynamics and Sampled Data,"This paper studies second-order consensus in multi-agent systems with sampled position and velocity data. A distributed linear consensus protocol with second-order dynamics is first designed, where both sampled position and velocity data are utilized. A necessary and sufficient condition based on the sampling period, the coupling gains, and the spectra of the Laplacian matrix, is established for reaching consensus of the system in this setting. It is found that second-order consensus in such a multi-agent system can be achieved by appropriately choosing the sampling period determined by a polynomial with order three. In particular, second-order consensus cannot be reached for a sufficiently large sampling period while it can be reached for a sufficiently small one under some conditions. Then, the coupling gains are carefully designed under the given network structure and the sampling period. Furthermore, the consensus regions are characterized for the spectra of the Laplacian matrix. On the other hand, second-order consensus in delayed undirected networks with sampled position and velocity data is then discussed. A necessary and sufficient condition is also given, by which appropriate sampling period can be chosen to achieve consensus in multi-agent systems. Finally, simulation examples are given to verify and illustrate the theoretical analysis.","Multiagent systems,
Laplace equations,
Sampled data systems,
Eigenvalues and eigenfunctions,
Protocols,
Graph theory"
Efficient Classification for Additive Kernel SVMs,"We show that a class of nonlinear kernel SVMs admits approximate classifiers with runtime and memory complexity that is independent of the number of support vectors. This class of kernels, which we refer to as additive kernels, includes widely used kernels for histogram-based image comparison like intersection and chi-squared kernels. Additive kernel SVMs can offer significant improvements in accuracy over linear SVMs on a wide variety of tasks while having the same runtime, making them practical for large-scale recognition or real-time detection tasks. We present experiments on a variety of datasets, including the INRIA person, Daimler-Chrysler pedestrians, UIUC Cars, Caltech-101, MNIST, and USPS digits, to demonstrate the effectiveness of our method for efficient evaluation of SVMs with additive kernels. Since its introduction, our method has become integral to various state-of-the-art systems for PASCAL VOC object detection/image classification, ImageNet Challenge, TRECVID, etc. The techniques we propose can also be applied to settings where evaluation of weighted additive kernels is required, which include kernelized versions of PCA, LDA, regression, k-means, as well as speeding up the inner loop of SVM classifier training algorithms.","Kernel,
Additives,
Histograms,
Support vector machines,
Complexity theory,
Piecewise linear approximation,
Training"
Networked Control With State Reset and Quantized Measurements: Observer-Based Case,"Quantization has been an important research area for a long time for networked control systems. This paper addresses the problem of a reset state observer (RSO)-based control (RSOC) for linear systems using quantized measurements. According to the characteristic of the logarithmic quantizer, an RSOC is presented based on the standard one to suppress sensor quantization effects. By using the Lyapunov approach, the closed-loop system is still asymptotically stable when the reset technique is introduced. The observer and controller gains of the closed-loop systems are obtained via solving linear matrix inequalities. At last, a numerical example is given to illustrate the effectiveness of the proposed results.",
View-Based Discriminative Probabilistic Modeling for 3D Object Retrieval and Recognition,"In view-based 3D object retrieval and recognition, each object is described by multiple views. A central problem is how to estimate the distance between two objects. Most conventional methods integrate the distances of view pairs across two objects as an estimation of their distance. In this paper, we propose a discriminative probabilistic object modeling approach. It builds probabilistic models for each object based on the distribution of its views, and the distance between two objects is defined as the upper bound of the Kullback-Leibler divergence of the corresponding probabilistic models. 3D object retrieval and recognition is accomplished based on the distance measures. We first learn models for each object by the adaptation from a set of global models with a maximum likelihood principle. A further adaption step is then performed to enhance the discriminative ability of the models. We conduct experiments on the ETH 3D object dataset, the National Taiwan University 3D model dataset, and the Princeton Shape Benchmark. We compare our approach with different methods, and experimental results demonstrate the superiority of our approach.",
An 8-Channel Scalable EEG Acquisition SoC With Patient-Specific Seizure Classification and Recording Processor,"An 8-channel scalable EEG acquisition SoC is presented to continuously detect and record patient-specific seizure onset activities from scalp EEG. The SoC integrates 8 high-dynamic range Analog Front-End (AFE) channels, a machine-learning seizure classification processor and a 64 KB SRAM. The classification processor exploits the Distributed Quad-LUT filter architecture to minimize the area while also minimizing the overhead in power × delay . The AFE employs a Chopper-Stabilized Capacitive Coupled Instrumentation Amplifier to show NEF of 5.1 and noise RTI of 0.91 μVrms for 0.5-100 Hz bandwidth. The classification processor adopts a support-vector machine as a classifier, with a GBW controller that gives real-time gain and bandwidth feedback to AFE to maintain accuracy. The SoC is verified with the Children's Hospital Boston-MIT EEG database as well as with rapid eye blink pattern detection test. The SoC is implemented in 0.18 μm 1P6M CMOS process occupying 25 mm2, and it shows an accuracy of 84.4% in eye blink classification test, at 2.03 μJ/classification energy efficiency. The 64 KB on chip memory can store up to 120 seconds of raw EEG data.",
Automatic patch generation learned from human-written patches,"Patch generation is an essential software maintenance task because most software systems inevitably have bugs that need to be fixed. Unfortunately, human resources are often insufficient to fix all reported and known bugs. To address this issue, several automated patch generation techniques have been proposed. In particular, a genetic-programming-based patch generation technique, GenProg, proposed by Weimer et al., has shown promising results. However, these techniques can generate nonsensical patches due to the randomness of their mutation operations. To address this limitation, we propose a novel patch generation approach, Pattern-based Automatic program Repair (Par), using fix patterns learned from existing human-written patches. We manually inspected more than 60,000 human-written patches and found there are several common fix patterns. Our approach leverages these fix patterns to generate program patches automatically. We experimentally evaluated Par on 119 real bugs. In addition, a user study involving 89 students and 164 developers confirmed that patches generated by our approach are more acceptable than those generated by GenProg. Par successfully generated patches for 27 out of 119 bugs, while GenProg was successful for only 16 bugs.","Fault location,
Computer bugs,
Context,
Semantics,
Manuals,
Arrays,
Maintenance engineering"
"Kernel-Based Learning for Statistical Signal Processing in Cognitive Radio Networks: Theoretical Foundations, Example Applications, and Future Directions","Kernel-based learning (KBL) methods have recently become prevalent in many engineering applications, notably in signal processing and communications. The increased interest is mainly driven by the practical need of being able to develop efficient nonlinear algorithms, which can obtain significant performance improvements over their linear counterparts at the price of generally higher computational complexity. In this article, an overview of applying various KBL methods to statistical signal processing-related open issues in cognitive radio networks (CRNs) is presented. It is demonstrated that KBL methods provide a powerful set of tools for CRNs and enable rigorous formulation and effective solutions to both long-standing and emerging design problems.","Machine learning,
Learning systems,
Kernel,
Cognitive radio,
Signal processing algorithms,
Nonlinear algorithms"
Learning Sparsifying Transforms,"The sparsity of signals and images in a certain transform domain or dictionary has been exploited in many applications in signal and image processing. Analytical sparsifying transforms such as Wavelets and DCT have been widely used in compression standards. Recently, synthesis sparsifying dictionaries that are directly adapted to the data have become popular especially in applications such as image denoising, inpainting, and medical image reconstruction. While there has been extensive research on learning synthesis dictionaries and some recent work on learning analysis dictionaries, the idea of learning sparsifying transforms has received no attention. In this work, we propose novel problem formulations for learning sparsifying transforms from data. The proposed alternating minimization algorithms give rise to well-conditioned square transforms. We show the superiority of our approach over analytical sparsifying transforms such as the DCT for signal and image representation. We also show promising performance in signal denoising using the learnt sparsifying transforms. The proposed approach is much faster than previous approaches involving learnt synthesis, or analysis dictionaries.",
Design principles for highly efficient quadrupeds and implementation on the MIT Cheetah robot,"In this paper, we introduce the design principles for highly efficient legged robots and the implementation of the principles on the MIT Cheetah robot. Three major energy loss modes during locomotion are heat losses through the actuators, losses through the transmission, and the interaction losses that includes all losses of the system interacting with the environment. We propose four design principles that minimize these losses: employment of high torque density motors, low impedance transmission, energy regenerative electronics and a design architecture that minimizes the leg inertia. We present the design features of the MIT cheetah robot as an embodiment of these principles. The resulting cost of transport (COT) is 0.51 during 2.3 m/s running, which rivals running animals in the same scale.","Brushless motors,
Torque,
Legged locomotion,
Permanent magnet motors,
Synchronous motors,
Actuators"
Spatial-Temporal Opportunity Detection for Spectrum-Heterogeneous Cognitive Radio Networks: Two-Dimensional Sensing,"This paper investigates the issue of spatial-temporal opportunity detection for spectrum-heterogeneous cognitive radio networks, where at a given time secondary users (SUs) at different locations may experience different spectrum access opportunities. Most prior studies address either spatial or temporal sensing in isolation and explicitly or implicitly assume that all SUs share the same spectrum opportunity. However, this assumption is not realistic and the traditional non-cooperative sensing (NCS) and cooperative sensing (CS) schemes are not very effective in a more realistic setting considering the heterogeneous spectrum availability among SUs. We define new performance metrics to guide the spatial-temporal opportunity detection and propose a two-dimensional sensing (TDS) framework to improve the opportunity detection performance, which exploits correlations in time and space simultaneously by effectively fusing sensing results in a spatial-temporal sensing window. Furthermore, in terms of maximum interference constrained transmission power (MICTP), we classify the spatial opportunities for SUs into three groups: black, grey, and white, and propose a TDS-based distributed power control scheme to further improve the spectrum utilization by exploiting both grey and white spectrum opportunities. The effectiveness of the proposed scheme is demonstrated through in-depth numerical simulations under a variety of scenarios.","Sensors,
Joints,
Interference,
Sensitivity,
Receivers,
Probability"
A Novel Scheme for Key Performance Indicator Prediction and Diagnosis With Application to an Industrial Hot Strip Mill,"In this paper, a data-driven scheme of key performance indicator (KPI) prediction and diagnosis is developed for complex industrial processes. For static processes, a KPI prediction and diagnosis approach is proposed in order to improve the prediction performance. In comparison with the standard partial least squares (PLS) method, the alternative approach significantly simplifies the computation procedure. By means of a data-driven realization of the so-called left coprime factorization (LCF) of a process, efficient KPI prediction, and diagnosis algorithms are developed for dynamic processes, respectively, with and without measurable KPIs. The proposed KPI prediction and diagnosis scheme is finally applied to an industrial hot strip mill, and the results demonstrate the effectiveness of the proposed scheme.","Data models,
Prediction algorithms,
Monitoring,
Performance evaluation,
Fault diagnosis"
Utility Optimal Scheduling in Energy-Harvesting Networks,"In this paper, we show how to achieve close-to-optimal utility performance in energy-harvesting networks with only finite capacity energy storage devices. In these networks, nodes are capable of harvesting energy from the environment. The amount of energy that can be harvested is time-varying and evolves according to some probability law. We develop an online algorithm, called the Energy-limited Scheduling Algorithm (ESA), which jointly manages the energy and makes power allocation decisions for packet transmissions. ESA only has to keep track of the amount of energy left at the network nodes and does not require any knowledge of the harvestable energy process. We show that ESA achieves a utility that is within O(ε) of the optimal, for any ε > 0, while ensuring that the network congestion and the required capacity of the energy storage devices are deterministically upper-bounded by bounds of size O(1/ε). We then also develop the Modified-ESA (MESA) algorithm to achieve the same O(ε) close-to-utility performance, with the average network congestion and the required capacity of the energy storage devices being only O([log(1/ε)]2), which is close to the theoretical lower bound O(log(1/ε)).",
Visual Traffic Jam Analysis Based on Trajectory Data,"In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.",
T-Drive: Enhancing Driving Directions with Taxi Drivers' Intelligence,"This paper presents a smart driving direction system leveraging the intelligence of experienced drivers. In this system, GPS-equipped taxis are employed as mobile sensors probing the traffic rhythm of a city and taxi drivers' intelligence in choosing driving directions in the physical world. We propose a time-dependent landmark graph to model the dynamic traffic pattern as well as the intelligence of experienced drivers so as to provide a user with the practically fastest route to a given destination at a given departure time. Then, a Variance-Entropy-Based Clustering approach is devised to estimate the distribution of travel time between two landmarks in different time slots. Based on this graph, we design a two-stage routing algorithm to compute the practically fastest and customized route for end users. We build our system based on a real-world trajectory data set generated by over 33,000 taxis in a period of three months, and evaluate the system by conducting both synthetic experiments and in-the-field evaluations. As a result, 60-70 percent of the routes suggested by our method are faster than the competing methods, and 20 percent of the routes share the same results. On average, 50 percent of our routes are at least 20 percent faster than the competing approaches.",
Graph-Regularized Low-Rank Representation for Destriping of Hyperspectral Images,"Hyperspectral image destriping is a challenging and promising theme in remote sensing. Striping noise is a ubiquitous phenomenon in hyperspectral imagery, which may severely degrade the visual quality. A variety of methods have been proposed to effectively alleviate the effects of the striping noise. However, most of them fail to take full advantage of the high spectral correlation between the observation subimages in distinct bands and consider the local manifold structure of the hyperspectral data space. In order to remedy this drawback, in this paper, a novel graph-regularized low-rank representation (LRR) destriping algorithm is proposed by incorporating the LRR technique. To obtain desired destriping performance, two sides of performing destriping are included: 1) To exploit the high spectral correlation between the observation subimages in distinct bands, the technique of LRR is first utilized for destriping, and 2) to preserve the intrinsic local structure of the original hyperspectral data, the graph regularizer is incorporated in the objective function. The experimental results and quantitative analysis demonstrate that the proposed method can both remove striping noise and achieve cleaner and higher contrast reconstructed results.","Noise,
Hyperspectral imaging,
Correlation,
Manifolds,
Robustness,
Noise reduction"
Speech Synthesis Based on Hidden Markov Models,"This paper gives a general overview of hidden Markov model (HMM)-based speech synthesis, which has recently been demonstrated to be very effective in synthesizing speech. The main advantage of this approach is its flexibility in changing speaker identities, emotions, and speaking styles. This paper also discusses the relation between the HMM-based approach and the more conventional unit-selection approach that has dominated over the last decades. Finally, advanced techniques for future developments are described.",
Maximum Torque per Ampere (MTPA) Control of an IPM Machine Based on Signal Injection Considering Inductance Saturation,"The aim of this study was to develop a new method to operate an interior permanent magnet synchronous machine (IPMSM) on the maximum torque per ampere (MTPA) condition. The characteristics of the MTPA condition were analyzed and the MTPA condition was derived based on the input electric power. The proposed method injects a small current signal used for tracking the MTPA operating point along with the fundamental current for torque generation. This method does not require any machine parameters or premade lookup table. The frequency of the injected signal is several hundred hertz, and the performance of the MTPA tracking is almost free from load torque disturbance. The feasibility of the proposed method was verified under various operating conditions with computer simulation and testing with an 11 kW IPMSM drive system.",
Geographic Image Retrieval Using Local Invariant Features,"This paper investigates local invariant features for geographic (overhead) image retrieval. Local features are particularly well suited for the newer generations of aerial and satellite imagery whose increased spatial resolution, often just tens of centimeters per pixel, allows a greater range of objects and spatial patterns to be recognized than ever before. Local invariant features have been successfully applied to a broad range of computer vision problems and, as such, are receiving increased attention from the remote sensing community particularly for challenging tasks such as detection and classification. We perform an extensive evaluation of local invariant features for image retrieval of land-use/land-cover (LULC) classes in high-resolution aerial imagery. We report on the effects of a number of design parameters on a bag-of-visual-words (BOVW) representation including saliency- versus grid-based local feature extraction, the size of the visual codebook, the clustering algorithm used to create the codebook, and the dissimilarity measure used to compare the BOVW representations. We also perform comparisons with standard features such as color and texture. The performance is quantitatively evaluated using a first-of-its-kind LULC ground truth data set which will be made publicly available to other researchers. In addition to reporting on the effects of the core design parameters, we also describe interesting findings such as the performance-efficiency tradeoffs that are possible through the appropriate pairings of different-sized codebooks and dissimilarity measures. While the focus is on image retrieval, we expect our insights to be informative for other applications such as detection and classification.",
Multi-Feature Fusion via Hierarchical Regression for Multimedia Analysis,"Multimedia data are usually represented by multiple features. In this paper, we propose a new algorithm, namely Multi-feature Learning via Hierarchical Regression for multimedia semantics understanding, where two issues are considered. First, labeling large amount of training data is labor-intensive. It is meaningful to effectively leverage unlabeled data to facilitate multimedia semantics understanding. Second, given that multimedia data can be represented by multiple features, it is advantageous to develop an algorithm which combines evidence obtained from different features to infer reliable multimedia semantic concept classifiers. We design a hierarchical regression model to exploit the information derived from each type of feature, which is then collaboratively fused to obtain a multimedia semantic concept classifier. Both label information and data distribution of different features representing multimedia data are considered. The algorithm can be applied to a wide range of multimedia applications and experiments are conducted on video data for video concept annotation and action recognition. Using Trecvid and CareMedia video datasets, the experimental results show that it is beneficial to combine multiple features. The performance of the proposed algorithm is remarkable when only a small amount of labeled training data are available.","Multimedia communication,
Algorithm design and analysis,
Streaming media,
Training data,
Training,
Manifolds,
Semantics"
Sparse Representation Classifier Steered Discriminative Projection With Applications to Face Recognition,"A sparse representation-based classifier (SRC) is developed and shows great potential for real-world face recognition. This paper presents a dimensionality reduction method that fits SRC well. SRC adopts a class reconstruction residual-based decision rule, we use it as a criterion to steer the design of a feature extraction method. The method is thus called the SRC steered discriminative projection (SRC-DP). SRC-DP maximizes the ratio of between-class reconstruction residual to within-class reconstruction residual in the projected space and thus enables SRC to achieve better performance. SRC-DP provides low-dimensional representation of human faces to make the SRC-based face recognition system more efficient. Experiments are done on the AR, the extended Yale B, and PIE face image databases, and results demonstrate the proposed method is more effective than other feature extraction methods based on the SRC.",
Wireless Architectures for Heterogeneous Sensing in Smart Home Applications: Concepts and Real Implementation,"Application of wireless technologies in the smart home is dealt with by pointing out advantages and limitations of available approaches for the solution of heterogeneous and coexisting problems related to the distributed monitoring of the home and the inhabitants. Some hot challenges facing the exploitation of noninvasive wireless devices for user behavior monitoring are then addressed and the application fields of smart power management and elderly people monitoring are chosen as representative cases where the estimation of user activities improves the potential of location-aware services in the smart home. The problem of user localization is considered with great care to minimize the invasiveness of the monitoring system. Wireless architectures are reviewed and discussed as flexible and transparent tools toward the paradigm of a totally automatic/autonomic environment. With respect to available state-of-the-art solutions, our proposed architecture is based also on existing wireless devices and exploits, in an opportunistic way, the characteristics of wireless signals to estimate the presence, the movements, and the behaviors of inhabitants, reducing the system complexity and costs. Selected and representative examples from real implementations are presented to give some insight on state-of-the-art solutions also envisaging possible future trends.","Wireless sensor networks,
Wireless communication,
Smart homes,
Home automation,
Computer architecture,
Intelligent sensors,
Wireless networks"
Transmit Solutions for MIMO Wiretap Channels using Alternating Optimization,"This paper considers transmit optimization in multi-input multi-output (MIMO) wiretap channels, wherein we aim at maximizing the secrecy capacity or rate of an MIMO channel overheard by one or multiple eavesdroppers. Such optimization problems are nonconvex, and appear to be difficult especially in the multi-eavesdropper scenario. In this paper, we propose an alternating optimization (AO) approach to tackle these secrecy optimization problems. We first consider the secrecy capacity maximization (SCM) problem in the single eavesdropper scenario. An AO algorithm is derived through a judicious SCM reformulation. The algorithm conducts some kind of reweighting and water-filling in an alternating fashion, and thus is computationally efficient to implement. We also prove that the AO algorithm is guaranteed to converge to a Karush-Kuhn-Tucker (KKT) point of the SCM problem. Then, we turn our attention to the multiple eavesdropper scenario, where the artificial noise (AN)-aided secrecy rate maximization (SRM) problem is considered. Although the AN-aided SRM problem has a more complex problem structure than the previous SCM, we show that AO can be extended to deal with the former, wherein the problem is handled by solving convex problems in an alternating fashion. Again, the resulting AO method is proven to have KKT point convergence guarantee. For fast implementation, a custom-designed AO algorithm based on smoothing and projected gradient is also derived. The secrecy rate performance and computational efficiency of the proposed algorithms are demonstrated by simulations.","MIMO,
Optimization,
Receivers,
Transmitters,
Convergence,
Algorithm design and analysis,
Tin"
Pairwise Prediction-Error Expansion for Efficient Reversible Data Hiding,"In prediction-error expansion (PEE) based reversible data hiding, better exploiting image redundancy usually leads to a superior performance. However, the correlations among prediction-errors are not considered and utilized in current PEE based methods. Specifically, in PEE, the prediction-errors are modified individually in data embedding. In this paper, to better exploit these correlations, instead of utilizing prediction-errors individually, we propose to consider every two adjacent prediction-errors jointly to generate a sequence consisting of prediction-error pairs. Then, based on the sequence and the resulting 2D prediction-error histogram, a more efficient embedding strategy, namely, pairwise PEE, can be designed to achieve an improved performance. The superiority of our method is verified through extensive experiments.",
Hessian Regularized Support Vector Machines for Mobile Image Annotation on the Cloud,"With the rapid development of the cloud computing and mobile service, users expect a better experience through multimedia computing, such as automatic or semi-automatic personal image and video organization and intelligent user interface. These functions heavily depend on the success of image understanding, and thus large-scale image annotation has received intensive attention in recent years. The collaboration between mobile and cloud opens a new avenue for image annotation, because the heavy computation can be transferred to the cloud for immediately responding user actions. In this paper, we present a scheme for image annotation on the cloud, which transmits mobile images compressed by Hamming compressed sensing to the cloud and conducts semantic annotation through a novel Hessian regularized support vector machine on the cloud. We carefully explained the rationality of Hessian regularization for encoding the local geometry of the compact support of the marginal distribution and proved that Hessian regularized support vector machine in the reproducing kernel Hilbert space is equivalent to conduct Hessian regularized support vector machine in the space spanned by the principal components of the kernel principal component analysis. We conducted experiments on the PASCAL VOC'07 dataset and demonstrated the effectiveness of Hessian regularized support vector machine for large-scale image annotation.","Support vector machines,
Mobile communication,
Cloud computing,
Image coding,
Compressed sensing,
Manifolds,
Clustering algorithms"
An Efficient Genetic Algorithm for Maximum Coverage Deployment in Wireless Sensor Networks,"Sensor networks have a lot of applications such as battlefield surveillance, environmental monitoring, and industrial diagnostics. Coverage is one of the most important performance metrics for sensor networks since it reflects how well a sensor field is monitored. In this paper, we introduce the maximum coverage deployment problem in wireless sensor networks and analyze the properties of the problem and its solution space. Random deployment is the simplest way to deploy sensor nodes but may cause unbalanced deployment and therefore, we need a more intelligent way for sensor deployment. We found that the phenotype space of the problem is a quotient space of the genotype space in a mathematical view. Based on this property, we propose an efficient genetic algorithm using a novel normalization method. A Monte Carlo method is adopted to design an efficient evaluation function, and its computation time is decreased without loss of solution quality using a method that starts from a small number of random samples and gradually increases the number for subsequent generations. The proposed genetic algorithms could be further improved by combining with a well-designed local search. The performance of the proposed genetic algorithm is shown by a comparative experimental study. When compared with random deployment and existing methods, our genetic algorithm was not only about twice faster, but also showed significant performance improvement in quality.","wireless sensor networks,
genetic algorithms,
Monte Carlo methods,
sensor placement"
Real-Time Object Tracking Via Online Discriminative Feature Selection,"Most tracking-by-detection algorithms train discriminative classifiers to separate target objects from their surrounding background. In this setting, noisy samples are likely to be included when they are not properly sampled, thereby causing visual drift. The multiple instance learning (MIL) paradigm has been recently applied to alleviate this problem. However, important prior information of instance labels and the most correct positive instance (i.e., the tracking result in the current frame) can be exploited using a novel formulation much simpler than an MIL approach. In this paper, we show that integrating such prior information into a supervised learning algorithm can handle visual drift more effectively and efficiently than the existing MIL tracker. We present an online discriminative feature selection algorithm that optimizes the objective function in the steepest ascent direction with respect to the positive samples while in the steepest descent direction with respect to the negative ones. Therefore, the trained classifier directly couples its score with the importance of samples, leading to a more robust and efficient tracker. Numerous experimental evaluations with state-of-the-art algorithms on challenging sequences demonstrate the merits of the proposed algorithm.","Object tracking,
Feature extraction,
Noise measurement,
Supervised learning,
Linear programming,
Robustness"
"High-Quality Interface in
Al
2
O
3
/GaN/GaN/AlGaN/GaN
MIS Structures With In Situ Pre-Gate Plasma Nitridation","We report an in situ low-damage pre-gate treatment technology in an atomic layer deposition (ALD) system prior to the ALD- Al2O3 deposition, to realize high-quality Al2O3/III-nitride (III-N) interface. The technology effectively removes the poor quality native oxide on the III-N surface while forming an ultrathin monocrystal-like nitridation interlayer (NIL) between Al2O3 and III-N surface. With the pre-gate treatment technology, high-performance Al2O3(NIL)/GaN/AlGaN/GaN metal-insulator-semiconductor high-electron-mobility transistors are demonstrated, exhibiting well-behaved electrical characteristics including suppressed gate leakage current, a small subthreshold slope of ~64 mV/dec, and a small hysteresis of ~0.09 V.",
A Hybrid BCI System Combining P300 and SSVEP and Its Application to Wheelchair Control,"In this paper, a hybrid brain-computer interface (BCI) system combining P300 and steady-state visual evoked potential (SSVEP) is proposed to improve the performance of asynchronous control. The four groups of flickering buttons were set in the graphical user interface. Each group contained one large button in the center and eight small buttons around it, all of which flashed at a fixed frequency (e.g., 7.5 Hz) to evoke SSVEP. At the same time, the four large buttons of the four groups were intensified through shape and color changes in a random order to produce P300 potential. During the control state, the user focused on a desired group of buttons (target buttons) to evoke P300 potential and SSVEP, simultaneously. Discrimination between the control and idle states was based on the detection of both P300 and SSVEP on the same group of buttons. As an application, this method was used to produce a “go/stop” command in real-time wheelchair control. Several experiments were conducted, and data analysis results showed that combining P300 potential and SSVEP significantly improved the performance of the BCI system in terms of detection accuracy and response time.","Electroencephalography,
Wheelchairs,
Graphical user interfaces,
Brain modeling"
On Secrecy Rate of the Generalized Artificial-Noise Assisted Secure Beamforming for Wiretap Channels,"In this paper we consider the secure transmission with multiple-input, single-output, single-antenna eavesdropper (MISOSE) in fast fading channels where the transmitter knows perfect legitimate channel state information but only the statistics of the eavesdropper's channel. For the MISOSE channels, the artificial noise assisted beamforming proposed by Goel and Negi is a promising technique, where the artificial noise is imposed on the null space of the legitimate channel to disrupt the eavesdropper's reception. Here we propose a generalized artificial noise scheme which allows the injection of the artificial noise to the legitimate channel. Although the generalized artificial noise may cause the leakage of artificial noise at the legitimate receiver, the secrecy rate can still be improved since the covariance matrix of it is more flexible than the heuristic one selected by Goel and Negi. To fully characterize the proposed scheme, we investigate the optimization of its secrecy rate. We first derive the conditions under which the beamformers of the message bearing signal and the generalized artificial noise being the same is optimal. Based on this choice, the complicated secrecy rate optimization problem over the covariance matrices of the message-bearing signal and the generalized artificial noise can be reduced to a much simpler power allocation problem. We also develop an efficient algorithm to solve this non-convex power allocation problem. Numerical results show that our generalized artificial noise scheme outperforms Goel and Negi's heuristic selection, especially in the near eavesdropper settings. In particular, with the aid of the proposed scheme, the regime with non-zero secrecy rate is enlarged, which can significantly improve the connectivity of the network.","Optimization,
Covariance matrices,
Resource management,
Array signal processing,
Signal to noise ratio,
Transmitters"
MPC-Based Appliance Scheduling for Residential Building Energy Management Controller,"This paper proposes an appliance scheduling scheme for residential building energy management controllers, by taking advantage of the time-varying retail pricing enabled by the two-way communication infrastructure of the smart grid. Finite-horizon scheduling optimization problems are formulated to exploit operational flexibilities of thermal and non-thermal appliances using a model predictive control (MPC) method which incorporates both forecasts and newly updated information. For thermal appliance scheduling, the thermal mass of the building, which serves as thermal storage, is integrated into the optimization problem by modeling the thermodynamics of rooms in a building as constraints. Within the comfort range modeled by the predicted mean vote (PMV) index, thermal appliances are scheduled smartly together with thermal mass storage to hedge against high prices and make use of low-price time periods. For non-thermal appliance scheduling, in which delay and/or power consumption flexibilities are available, operation dependence of inter-appliance and intra-appliance is modeled to further exploit the price variation. Simulation results show that customers have notable energy cost savings on their electricity bills with time-varying pricing. The impact of customers' preferences of appliances usage on energy cost savings is also evaluated.","Home appliances,
Buildings,
Optimization,
Delays,
Thermodynamics,
Power demand,
Electricity"
"Building Energy Management: Integrated Control of Active and Passive Heating, Cooling, Lighting, Shading, and Ventilation Systems","Buildings account for nearly 40% of global energy consumption. About 40% and 15% of that are consumed, respectively, by HVAC and lighting. These energy uses can be reduced by integrated control of active and passive sources of heating, cooling, lighting, shading and ventilation. However, rigorous studies of such control strategies are lacking since computationally tractable models are not available. In this paper, a novel formulation capturing key interactions of the above building functions is established to minimize the total daily energy cost. To obtain effective integrated strategies in a timely manner, a methodology that combines stochastic dynamic programming (DP) and the rollout technique is developed within the price-based coordination framework. For easy implementation, DP-derived heuristic rules are developed to coordinate shading blinds and natural ventilation, with simplified optimization strategies for HVAC and lighting systems. Numerical simulation results show that these strategies are scalable, and can effectively reduce energy costs and improve human comfort.","Buildings,
Ventilation,
Humidity,
Heat transfer,
Atmospheric modeling,
Centralized control"
A Scalable Three-Step Approach for Demand Side Management of Plug-in Hybrid Vehicles,"In this paper, we present a scalable approach for DSM (demand side management) of PHEVs (plug-in hybrid electric vehicles). Essentially, our approach consists of three steps: aggregation, optimization, and control. In the aggregation step, individual PHEV charging constraints are aggregated upwards in a tree structure. In the optimization step, the aggregated constraints are used for scalable computation of a collective charging plan, which minimizes costs for electricity supply. In the real-time control step, this charging plan is used to create an incentive signal for all PHEVs, determined by a market-based priority scheme. These three steps are executed iteratively to cope with uncertainty and dynamism. In simulation experiments, the proposed three-step approach is benchmarked against classic, fully centralized approaches. Results show that our approach is able to charge PHEVs with comparable quality to optimal, centrally computed charging plans, while significantly improving scalability.","Batteries,
Vectors,
Electricity,
Optimization,
Scalability,
Smart grids,
Linear programming"
Secondary control of microgrids based on distributed cooperative control of multi-agent systems,"This study proposes a secondary voltage and frequency control scheme based on the distributed cooperative control of multi-agent systems. The proposed secondary control is implemented through a communication network with one-way communication links. The required communication network is modelled by a directed graph (digraph). The proposed secondary control is fully distributed such that each distributed generator only requires its own information and the information of its neighbours on the communication digraph. Thus, the requirements for a central controller and complex communication network are obviated, and the system reliability is improved. The simulation results verify the effectiveness of the proposed secondary control for a microgrid test system.","telecommunication networks,
directed graphs,
distributed power generation,
frequency control,
multi-agent systems,
power distribution control,
power distribution reliability"
On the Synergistic Benefits of Alternating CSIT for the MISO Broadcast Channel,"The degrees of freedom (DoFs) of the two-user multiple-input single-output (MISO) broadcast channel (BC) are studied under the assumption that the form, Ii, i=1, 2, of the channel state information at the transmitter (CSIT) for each user's channel can be either perfect (P), delayed (D), or not available (N), i.e., I1,I2 ∈ {P,N,D} , and therefore, the overall CSIT can alternate between the nine resulting states I1I2. The fraction of time associated with CSIT state I1I2 is denoted by the parameter λI1I2 and it is assumed throughout that λI1I2 = λI2I1, i.e., λPN = λNP, λPD=λDP, λDN=λND . Under this assumption of symmetry, the main contribution of this paper is a complete characterization of the DoF region of the two-user MISO BC with alternating CSIT. Surprisingly, the DoF region is found to depend only on the marginal probabilities (λP, λD,λN) = (ΣI2 λPI2, ΣI2 λDI2, ΣI2 λNI2), I2 ∈ {P, D, N}, which represent the fraction of time that any given user (e.g., user 1) is associated with perfect, delayed, or no CSIT, respectively. As a consequence, the DoF region with all nine CSIT states, D(λI1I2:I1,I2 ∈ {P,D,N}) , is the same as the DoF region with only three CSIT states D(λPP, λDD, λNN), under the same marginal distribution of CSIT states, i.e., (λPP, λDD,λNN)=(λP,λD,λN). The sum-DoF value can be expressed as DoF=min([(4+2λP)/3], 1+λP+λD), from which one can uniquely identify the minimum required marginal CSIT fractions to achieve any target DoF value as (λP,λD)min=([3/2] DoF-2,1- [1/2] DoF) when DoF ∈ [[4/3],2] and (λP,λD)min=(0,(DoF-1)+) when DoF ∈ [0, [4/3]). The results highlight the synergistic benefits of alternating CSIT and the tradeoffs between various forms of CSIT for any given DoF value. Partial results are also presented for the multiuser MISO BC with M transmit antennas and K single antenna users. For this problem, the minimum amount of perfect CSIT required per user to achieve the maximum DoFs of min(M,K) is characterized. By the minimum amount of CSIT per user, we refer to the minimum fraction of time that the transmitter has access to perfect and instantaneous CSIT from a user. Through a novel converse proof and an achievable scheme, it is shown that the minimum fraction of time perfect CSIT is required per user in order to achieve the DoF of min(M,K) is given by min(M,K)/K.","Transmitting antennas,
Receiving antennas,
Encoding,
Channel state information,
Delays"
Voltage-Triggered Ultrafast Phase Transition in Vanadium Dioxide Switches,"Electrically driven metal-insulator transition (MIT) in vanadium dioxide (VO2) is of interest in emerging memory devices, neural computation, and high-speed electronics. We report on the fabrication of out-of-plane VO2 metal-insulator-metal structures and reproducible high-speed switching measurements in these two-terminal devices. We have observed a clear correlation between the electrically driven on/off current ratio and the thermally induced resistance change during MIT. It is also found that sharp MIT could be triggered by the external voltage pulses within 2 ns at room temperature and the achieved on/ off ratio is greater than two orders of magnitude with good endurance.","Switches,
Resistance,
Current measurement,
Electrical resistance measurement,
Temperature measurement,
Electrodes,
Pulse measurements"
Spectral Hashing With Semantically Consistent Graph for Image Indexing,"The ability of fast similarity search in a large-scale dataset is of great importance to many multimedia applications. Semantic hashing is a promising way to accelerate similarity search, which designs compact binary codes for a large number of images so that semantically similar images are mapped to close codes. Retrieving similar neighbors is then simply accomplished by retrieving images that have codes within a small Hamming distance of the code of the query. Among various hashing approaches, spectral hashing (SH) has shown promising performance by learning the binary codes with a spectral graph partitioning method. However, the Euclidean distance is usually used to construct the graph Laplacian in SH, which may not reflect the inherent distribution of the data. Therefore, in this paper, we propose a method to directly optimize the graph Laplacian. The learned graph, which can better represent similarity between samples, is then applied to SH for effective binary code learning. Meanwhile, our approach, unlike metric learning, can automatically determine the scale factor during the optimization. Extensive experiments are conducted on publicly available datasets and the comparison results demonstrate the effectiveness of our approach.","Measurement,
Binary codes,
Laplace equations,
Databases,
Semantics,
Hamming distance,
Complexity theory"
Stability Enhancement of Decentralized Inverter Control Through Wireless Communications in Microgrids,"Decentralized inverter control is essential in distributed generation (DG) microgrids for low deployment/operation cost and high reliability. However, decentralized inverter control suffers from a limited system stability mainly because of the lack of communications among different inverters. In this paper, we investigate stability enhancement of the droop based decentralized inverter control in microgrids. Specifically, we propose a power sharing based control strategy which incorporates the information of the total real and reactive power generation of all DG units. The information is acquired by a wireless network (such as a WiFi, ZigBee, and/or cellular communication network) in a decentralized manner. Based on the desired power sharing of each DG unit and the acquired information of total generation, additional control terms are added to the traditional droop controller. We evaluate the performance of the proposed control strategy based on small-signal stability analysis. As timely communication may not be established for a microgrid with low-cost wireless communication devices, two kinds of analytical models are developed with respect to negligible and nonnegligible communication delays, respectively. Extensive numerical results are presented to demonstrate the system stability under the proposed control strategy with respect to different.","Inverters,
Voltage control,
Microgrids,
Stability analysis,
Power system stability,
Reactive power,
Delay"
Short-Term Traffic Flow Forecasting: An Experimental Comparison of Time-Series Analysis and Supervised Learning,"The literature on short-term traffic flow forecasting has undergone great development recently. Many works, describing a wide variety of different approaches, which very often share similar features and ideas, have been published. However, publications presenting new prediction algorithms usually employ different settings, data sets, and performance measurements, making it difficult to infer a clear picture of the advantages and limitations of each model. The aim of this paper is twofold. First, we review existing approaches to short-term traffic flow forecasting methods under the common view of probabilistic graphical models, presenting an extensive experimental comparison, which proposes a common baseline for their performance analysis and provides the infrastructure to operate on a publicly available data set. Second, we present two new support vector regression models, which are specifically devised to benefit from typical traffic flow seasonality and are shown to represent an interesting compromise between prediction accuracy and computational efficiency. The SARIMA model coupled with a Kalman filter is the most accurate model; however, the proposed seasonal support vector regressor turns out to be highly competitive when performing forecasts during the most congested periods.","Forecasting,
Predictive models,
Time series analysis,
Graphical models,
Data models,
Computational modeling,
Training"
Adaptive Learning in Tracking Control Based on the Dual Critic Network Design,"In this paper, we present a new adaptive dynamic programming approach by integrating a reference network that provides an internal goal representation to help the systems learning and optimization. Specifically, we build the reference network on top of the critic network to form a dual critic network design that contains the detailed internal goal representation to help approximate the value function. This internal goal signal, working as the reinforcement signal for the critic network in our design, is adaptively generated by the reference network and can also be adjusted automatically. In this way, we provide an alternative choice rather than crafting the reinforcement signal manually from prior knowledge. In this paper, we adopt the online action-dependent heuristic dynamic programming (ADHDP) design and provide the detailed design of the dual critic network structure. Detailed Lyapunov stability analysis for our proposed approach is presented to support the proposed structure from a theoretical point of view. Furthermore, we also develop a virtual reality platform to demonstrate the real-time simulation of our approach under different disturbance situations. The overall adaptive learning performance has been tested on two tracking control benchmarks with a tracking filter. For comparative studies, we also present the tracking performance with the typical ADHDP, and the simulation results justify the improved performance with our approach.","Vectors,
Dynamic programming,
Erbium,
Adaptive systems,
Nickel,
Optimization,
Lyapunov methods"
Total Ionizing Dose Effects in MOS and Low-Dose-Rate-Sensitive Linear-Bipolar Devices,"An overview is presented of total ionizing dose (TID) effects in MOS and bipolar devices from a historical perspective, focusing primarily on work presented at the annual IEEE Nuclear and Space Radiation Effects Conference (NSREC). From the founding of the IEEE NSREC in 1964 until ~1976, foundational work led to the discovery of TID effects in MOS devices, the characterization of basic charge transport and trapping processes in SiO2, and the development of the first generations of metal-gate radiation-hardened MOS technologies. From ~1977 until ~1985, significant progress was made in the understanding of critical defects and impurities that limit the radiation response of MOS devices. These include O vacancies in SiO2, dangling Si bonds at the Si/SiO2 interface, and hydrogen. In addition, radiation-hardened Si-gate CMOS technologies were developed. From ~1986 until ~1997, a significant focus was placed on understanding postirradiation effects in MOS devices and implementing hardness assurance test methods to qualify devices for use in space systems. Enhanced low-dose-rate sensitivity (ELDRS) was discovered and investigated in linear bipolar devices and integrated circuits. From ~1998 until the present, an increasing focus has been placed on theoretical studies enabled by rapidly advancing computational capabilities, modeling and simulation, effects in ultra-thin oxides and alternative dielectrics to SiO2, and in developing a comprehensive model of ELDRS.","Logic gates,
Radiation effects,
Silicon,
Charge carrier processes,
MOS capacitors,
Integrated circuit modeling"
Hardware Design of Smart Home Energy Management System With Dynamic Price Response,"The smart grid initiative and electricity market operation drive the development known as demand-side management or controllable load. Home energy management has received increasing interest due to the significant amount of loads in the residential sector. This paper presents a hardware design of smart home energy management system (SHEMS) with the applications of communication, sensing technology, and machine learning algorithm. With the proposed design, consumers can easily achieve a real-time, price-responsive control strategy for residential home loads such as electrical water heater (EWH), heating, ventilation, and air conditioning (HVAC), electrical vehicle (EV), dishwasher, washing machine, and dryer. Also, consumers may interact with suppliers or load serving entities (LSEs) to facilitate the load management at the supplier side. Further, SHEMS is designed with sensors to detect human activities and then a machine learning algorithm is applied to intelligently help consumers reduce total payment on electricity without or with little consumer involvement. Finally, simulation and experiment results are presented based on an actual SHEMS prototype to verify the hardware system.",
A Novel Framework for the Design of Change-Detection Systems for Very-High-Resolution Remote Sensing Images,"This paper addresses change detection in multitemporal remote sensing images. After a review of the main techniques developed in remote sensing for the analysis of multitemporal data, the attention is focused on the challenging problem of change detection in very-high-resolution (VHR) multispectral images. In this context, we propose a framework that aims at defining a top-down approach to the design of the architecture of novel change-detection systems for multitemporal VHR images. The proposed framework explicitly models the presence of different radiometric changes on the basis of the properties of multitemporal images, extracts the semantic meaning of radiometric changes, identifies changes of interest with strategies designed on the basis of the specific application, and takes advantage of the intrinsic multiscale/multilevel properties of the objects and the high spatial correlation between pixels in a neighborhood. This framework defines guidelines for the development of a new generation of change-detection methods that can properly analyze multitemporal VHR images taking into account the intrinsic complexity associated with these data. In order to illustrate the use of the proposed framework, a real change-detection problem has been considered, which is described by a pair of VHR multispectral images acquired by the QuickBird satellite on the city of Trento, Italy. The proposed framework has been used for defining a system for change detection in the two images. Experimental results confirm the effectiveness of the developed system and the usefulness of the proposed framework.",
An Inpainting-Assisted Reversible Steganographic Scheme Using a Histogram Shifting Mechanism,"In this paper, we propose a novel prediction-based reversible steganographic scheme based on image inpainting. First, reference pixels are chosen adaptively according to the distribution characteristics of the image content. Then, the image inpainting technique based on partial differential equations is introduced to generate a prediction image that has similar structural and geometric information as the cover image. Finally, by using the two selected groups of peak points and zero points, the histogram of the prediction error is shifted to embed the secret bits reversibly. Since the same reference pixels can be exploited in the extraction procedure, the embedded secret bits can be extracted from the stego image correctly, and the cover image can be restored losslessly. Through the use of the adaptive strategy for choosing reference pixels and the inpainting predictor, the prediction accuracy is high, and more embeddable pixels are acquired. Thus, the proposed scheme provides a greater embedding rate and better visual quality compared with recently reported methods.",
SpiNNaker: A 1-W 18-Core System-on-Chip for Massively-Parallel Neural Network Simulation,"The modelling of large systems of spiking neurons is computationally very demanding in terms of processing power and communication. SpiNNaker - Spiking Neural Network architecture - is a massively parallel computer system designed to provide a cost-effective and flexible simulator for neuroscience experiments. It can model up to a billion neurons and a trillion synapses in biological real time. The basic building block is the SpiNNaker Chip Multiprocessor (CMP), which is a custom-designed globally asynchronous locally synchronous (GALS) system with 18 ARM968 processor nodes residing in synchronous islands, surrounded by a lightweight, packet-switched asynchronous communications infrastructure. In this paper, we review the design requirements for its very demanding target application, the SpiNNaker micro-architecture and its implementation issues. We also evaluate the SpiNNaker CMP, which contains 100 million transistors in a 102-mm2 die, provides a peak performance of 3.96 GIPS, and has a peak power consumption of 1 W when all processor cores operate at the nominal frequency of 180 MHz. SpiNNaker chips are fully operational and meet their power and performance requirements.","Computational modeling,
Neurons,
Biological system modeling,
Brain modeling,
System-on-chip,
Hardware"
Asymptotic Interference Alignment for Optimal Repair of MDS Codes in Distributed Storage,"The high repair bandwidth cost of (n,k) maximum distance separable (MDS) erasure codes has motivated a new class of codes that can reduce repair bandwidth over that of conventional MDS codes. In this paper, we address (n,k,d) exact repair MDS codes, which allow for any single failed node to be repaired exactly with access to any arbitrary set of d survivor nodes. We show the existence of exact repair MDS codes that achieve minimum repair bandwidth (matching the cut-set lower bound) for arbitrary admissible (n,k,d), i.e., k ≤ d ≤ n-1. Moreover, we extend our results to show the optimality of our codes for multiple-node failure scenarios in which an arbitrary set of r ≤ n-k failed nodes needs to repaired. Our approach is based on asymptotic interference alignment proposed by Cadambe and Jafar. As a byproduct, we also characterize the capacity of a class of multisource nonmulticast networks.","Maintenance engineering,
Bandwidth,
Interference,
Systematics,
Vectors,
Linear code"
MOEA/D-ACO: A Multiobjective Evolutionary Algorithm Using Decomposition and AntColony,"Combining ant colony optimization (ACO) and the multiobjective evolutionary algorithm (EA) based on decomposition (MOEA/D), this paper proposes a multiobjective EA, i.e., MOEA/D-ACO. Following other MOEA/D-like algorithms, MOEA/D-ACO decomposes a multiobjective optimization problem into a number of single-objective optimization problems. Each ant (i.e., agent) is responsible for solving one subproblem. All the ants are divided into a few groups, and each ant has several neighboring ants. An ant group maintains a pheromone matrix, and an individual ant has a heuristic information matrix. During the search, each ant also records the best solution found so far for its subproblem. To construct a new solution, an ant combines information from its group's pheromone matrix, its own heuristic information matrix, and its current solution. An ant checks the new solutions constructed by itself and its neighbors, and updates its current solution if it has found a better one in terms of its own objective. Extensive experiments have been conducted in this paper to study and compare MOEA/D-ACO with other algorithms on two sets of test problems. On the multiobjective 0-1 knapsack problem, MOEA/D-ACO outperforms the MOEA/D with conventional genetic operators and local search on all the nine test instances. We also demonstrate that the heuristic information matrices in MOEA/D-ACO are crucial to the good performance of MOEA/D-ACO for the knapsack problem. On the biobjective traveling salesman problem, MOEA/D-ACO performs much better than the BicriterionAnt on all the 12 test instances. We also evaluate the effects of grouping, neighborhood, and the location information of current solutions on the performance of MOEA/D-ACO. The work in this paper shows that reactive search optimization scheme, i.e., the “learning while optimizing” principle, is effective in improving multiobjective optimization algorithms.","Vectors,
Optimization,
Evolutionary computation,
Search problems,
Indexes,
Educational institutions,
Cities and towns"
Optimizing Electric Vehicle Charging: A Customer's Perspective,"Electric vehicles (EVs) are considered to be a promising solution for current gas shortage and emission problems. To maximize the benefits of using EVs, regulated and optimized charging control needs to be provided by load aggregators for connected vehicles. An EV charging network is a typical cyber-physical system, which includes a power grid and a large number of EVs and aggregators that collect information and control the charging procedure. In this paper, we studied EV charging scheduling problems from a customer's perspective by jointly considering the aggregator's revenue and customers' demands and costs. We considered two charging scenarios: static and dynamic. In the static charging scenario, customers' charging demands are provided to the aggregator in advance; however, in the dynamic charging scenario, an EV may come and leave at any time, which is not known to the aggregator in advance. We present linear programming (LP)-based optimal schemes for the static problems and effective heuristic algorithms for the dynamic problems. The dynamic scenario is more realistic; however, the solutions to the static problems can be used to show potential revenue gains and cost savings that can be brought by regulated charging and, thus, can serve as a benchmark for performance evaluation. It has been shown by extensive simulation results based on real electricity price and load data that significant revenue gains and cost savings can be achieved by optimal charging scheduling compared with an unregulated baseline approach, and moreover, the proposed dynamic charging scheduling schemes provide close-to-optimal solutions.","System-on-chip,
Vehicles,
Heuristic algorithms,
Dynamic scheduling,
Batteries,
Electricity,
Vehicle dynamics"
Fast speaker adaptation of hybrid NN/HMM model for speech recognition based on discriminative learning of speaker code,"In this paper, we propose a new fast speaker adaptation method for the hybrid NN-HMM speech recognition model. The adaptation method depends on a joint learning of a large generic adaptation neural network for all speakers as well as multiple small speaker codes (one per speaker). The joint training method uses all training data along with speaker labels to update adaptation NN weights and speaker codes based on the standard back-propagation algorithm. In this way, the learned adaptation NN is capable of transforming each speaker features into a generic speaker-independent feature space when a small speaker code is given. Adaptation to a new speaker can be simply done by learning a new speaker code using the same back-propagation algorithm without changing any NN weights. In this method, a separate speaker code is learned for each speaker while the large adaptation NN is learned from the whole training set. The main advantage of this method is that the size of speaker codes is very small. As a result, it is possible to conduct a very fast adaptation of the hybrid NN/HMM model for each speaker based on only a small amount of adaptation data (i.e., just a few utterances). Experimental results on TIMIT have shown that it can achieve over 10% relative reduction in phone error rate by using only seven utterances for adaptation.",
Gaussian Bare-Bones Differential Evolution,"Differential evolution (DE) is a well-known algorithm for global optimization over continuous search spaces. However, choosing the optimal control parameters is a challenging task because they are problem oriented. In order to minimize the effects of the control parameters, a Gaussian bare-bones DE (GBDE) and its modified version (MGBDE) are proposed which are almost parameter free. To verify the performance of our approaches, 30 benchmark functions and two real-world problems are utilized. Conducted experiments indicate that the MGBDE performs significantly better than, or at least comparable to, several state-of-the-art DE variants and some existing bare-bones algorithms.","Vectors,
Sociology,
Statistics,
Convergence,
Benchmark testing,
Optimization,
Gaussian distribution"
Modeling Graphene in the Finite-Difference Time-Domain Method Using a Surface Boundary Condition,"An effective approach for finite-difference time-domain modeling of graphene as a conducting sheet is proposed. First, we present a new technique for implementing a conducting surface boundary condition in the FDTD method; then, the dispersive surface conductivity of graphene is imposed. Numerical examples are presented to show the stability, accuracy, applicability, and advantages of the proposed approach. Validation is achieved by comparison with existing analytic methods.","surface conductivity,
finite difference time-domain analysis,
graphene"
Person Re-Identification by Regularized Smoothing KISS Metric Learning,"With the rapid development of the intelligent video surveillance (IVS), person re-identification, which is a difficult yet unavoidable problem in video surveillance, has received increasing attention in recent years. That is because computer capacity has shown remarkable progress and the task of person re-identification plays a critical role in video surveillance systems. In short, person re-identification aims to find an individual again that has been observed over different cameras. It has been reported that KISS metric learning has obtained the state of the art performance for person re-identification on the VIPeR dataset . However, given a small size training set, the estimation to the inverse of a covariance matrix is not stable and thus the resulting performance can be poor. In this paper, we present regularized smoothing KISS metric learning (RS-KISS) by seamlessly integrating smoothing and regularization techniques for robustly estimating covariance matrices. RS-KISS is superior to KISS, because RS-KISS can enlarge the underestimated small eigenvalues and can reduce the overestimated large eigenvalues of the estimated covariance matrix in an effective way. By providing additional data, we can obtain a more robust model by RS-KISS. However, retraining RS-KISS on all the available examples in a straightforward way is time consuming, so we introduce incremental learning to RS-KISS. We thoroughly conduct experiments on the VIPeR dataset and verify that 1) RS-KISS completely beats all available results for person re-identification and 2) incremental RS-KISS performs as well as RS-KISS but reduces the computational cost significantly.",
Ideal ratio mask estimation using deep neural networks for robust speech recognition,"We propose a feature enhancement algorithm to improve robust automatic speech recognition (ASR). The algorithm estimates a smoothed ideal ratio mask (IRM) in the Mel frequency domain using deep neural networks and a set of time-frequency unit level features that has previously been used to estimate the ideal binary mask. The estimated IRM is used to filter out noise from a noisy Mel spectrogram before performing cepstral feature extraction for ASR. On the noisy subset of the Aurora-4 robust ASR corpus, the proposed enhancement obtains a relative improvement of over 38% in terms of word error rates using ASR models trained in clean conditions, and an improvement of over 14% when the models are trained using the multi-condition training data. In terms of instantaneous SNR estimation performance, the proposed system obtains a mean absolute error of less than 4 dB in most frequency channels.","Speech,
Signal to noise ratio,
Feature extraction,
Speech recognition,
Estimation,
Robustness"
Optimization of Switching Losses and Capacitor Voltage Ripple Using Model Predictive Control of a Cascaded H-Bridge Multilevel StatCom,This paper further develops a model predictive control (MPC) scheme which is able to exploit the large number of redundant switching states available in a multilevel H-bridge StatCom (H-StatCom). The new sections of the scheme provide optimized methods to tradeoff the harmonic performance with converter switching losses and capacitor voltage ripple. Varying the pulse placement within the modulation scheme and modifying the heuristic model of the voltage balancing characteristics allows the MPC scheme to achieve superior performance to that of the industry standard phase shifted carrier modulation technique. The effects of capacitor voltage ripple on the lifetime of the capacitors are also investigated. It is shown that the MPC scheme can reduce capacitor voltage ripple and increase capacitor lifetime. Simulation and experimental results are presented that confirm the correct operation of the control and modulation strategies.,"Switches,
Capacitors,
Voltage control,
Voltage measurement,
Harmonic analysis,
Switching loss,
Pulse width modulation"
Iterative Learning Control With Mixed Constraints for Point-to-Point Tracking,"Iterative learning control (ILC) is concerned with tracking a reference trajectory defined over a finite time duration, and is applied to systems which perform this action repeatedly. However, in many application domains the output is not critical at all points over the task duration. In this paper the facility to track an arbitrary subset of points is therefore introduced, and the additional flexibility this brings is used to address other control objectives in the framework of iterative learning. These comprise hard and soft constraints involving the system input, output and states. Experimental results using a robotic arm confirm that embedding constraints in the ILC framework leads to superior performance than can be obtained using standard ILC and an a priori specified reference.",
On the Jamming Power Allocation for Secure Amplify-and-Forward Relaying via Cooperative Jamming,"In this paper, we investigate secure communications in two-hop wireless relaying networks with one eavesdropper. To prevent the eavesdropper from intercepting the source message, the destination sends an intended jamming noise to the relay, which is referred to as cooperative jamming. This jamming noise helps protecting the source message from being captured reliably at the eavesdropper, while the destination cancels its self-intended noise. According to the channel information available at the destination, we derive three jamming power allocation strategies to minimize the outage probability of the secrecy rate. In addition, we derive analytic results quantifying the jamming power consumption of the proposed allocation methods.","Jamming,
Signal to noise ratio,
Relays,
Resource management,
Approximation methods,
Power demand"
"Sensing as a Service: Challenges, Solutions and Future Directions","Sensors on (or attached to) mobile phones can enable attractive sensing applications in different domains, such as environmental monitoring, social networking, healthcare, transportation, etc. We introduce a new concept, sensing as a service (S2aaS), i.e., providing sensing services using mobile phones via a cloud computing system. An S2aaS cloud needs to meet the following requirements: 1) it must be able to support various mobile phone sensing applications on different smartphone platforms; 2) it must be energy-efficient; and 3) it must have effective incentive mechanisms that can be used to attract mobile users to participate in sensing activities. In this vision paper, we identify unique challenges of designing and implementing an S2aaS cloud, review existing systems and methods, present viable solutions, and point out future research directions.","smart phones,
computerised instrumentation,
mobile computing,
sensors"
High-Performance Normally-Off {\rm Al}_{2}{\rm O}_{3}/{\rm GaN} MOSFET Using a Wet Etching-Based Gate Recess Technique,"This letter reports a normally-OFF Al2O3/GaN gate-recessed MOSFET using a low-damage digital recess technique featuring multiple cycles of plasma oxidation and wet oxide removal process. The wet etching process eliminates the damage induced by plasma bombardment induced in conventional inductively coupled plasma dry etching process so that good surface morphology and high interface quality could be achieved. The fully recessed Al2O3/GaN MOSFET delivers true enhancement-mode operation with a threshold voltage of +1.7 V. The maximum output current density is 528 mA/mm at a positive gate bias of 8 V. A peak field-effect mobility of 251 cm2/V·s is obtained, indicating high-quality Al2O3/GaN interface.",
Effective Multiple Feature Hashing for Large-Scale Near-Duplicate Video Retrieval,"Near-duplicate video retrieval (NDVR) has recently attracted much research attention due to the exponential growth of online videos. It has many applications, such as copyright protection, automatic video tagging and online video monitoring. Many existing approaches use only a single feature to represent a video for NDVR. However, a single feature is often insufficient to characterize the video content. Moreover, while the accuracy is the main concern in previous literatures, the scalability of NDVR algorithms for large scale video datasets has been rarely addressed. In this paper, we present a novel approach-Multiple Feature Hashing (MFH) to tackle both the accuracy and the scalability issues of NDVR. MFH preserves the local structural information of each individual feature and also globally considers the local structures for all the features to learn a group of hash functions to map the video keyframes into the Hamming space and generate a series of binary codes to represent the video dataset. We evaluate our approach on a public video dataset and a large scale video dataset consisting of 132,647 videos collected from YouTube by ourselves. This dataset has been released (http://itee.uq.edu.au/shenht/UQ_VIDEO/). The experimental results show that the proposed method outperforms the state-of-the-art techniques in both accuracy and efficiency.",
Cloning Physically Unclonable Functions,"As system security demands continue to evolve, Physically Unclonable Functions (PUFs) are a promising solution for secure storage on Integrated Circuits (ICs). SRAM PUFs are among the most popular types of PUFs, since they require no additional circuitry and can be implemented with on-die memories such as caches and data memory that are readily available on both ASICs and FPGAs. This work demonstrates that SRAM PUFs are not well suited as PUFs, as they do not meet several requirements that constitute an ideal PUF. The compact nature of SRAM, standard interconnects and resiliency to environmental effects make SRAM PUFs particularly easy to clone. We consider several ways in which SRAM PUFs can be characterized and demonstrate a Focused Ion Beam circuit edit with which we were able to produce a physical clone of our Proof-of-Concept SRAM PUF implementation. As a result of the circuit edit, when challenged, the physical clone produced an identical physical response to the original device. To the best of our knowledge, this is the first work in which a physical clone of a Physically Unclonable Function was produced.","Cloning,
Integrated circuits,
SRAM cells,
Transistors,
Security,
Arrays"
Enhanced Fireworks Algorithm,"In this paper, we present an improved version of the recently developed Fireworks Algorithm (FWA) based on several modifications. A comprehensive study on the operators of conventional FWA revealed that the algorithm works surprisingly well on benchmark functions which have their optimum at the origin of the search space. However, when being applied on shifted functions, the quality of the results of conventional FWA deteriorates severely and worsens with increasing shift values, i.e., with increasing distance between function optimum and origin of the search space. Moreover, compared to other metaheuristic optimization algorithms, FWA has high computational cost per iteration. In order to tackle these limitations, we present five major improvements of FWA: (i) a new minimal explosion amplitude check, (ii) a new operator for generating explosion sparks, (iii) a new mapping strategy for sparks which are out of the search space, (iv) a new operator for generating Gaussian sparks, and (v) a new operator for selecting the population for the next iteration. The resulting algorithm is called Enhanced Fireworks Algorithm (EFWA). Experimental evaluation on twelve benchmark functions with different shift values shows that EFWA outperforms conventional FWA in terms of convergence capabilities, while reducing the runtime significantly.",
Real-Time Power Balancing Via Decentralized Coordinated Home Energy Scheduling,"It is anticipated that an uncoordinated operation of individual home energy management (HEM) systems in a neighborhood would have a rebound effect on the aggregate demand profile. To address this issue, this paper proposes a coordinated home energy management (CoHEM) architecture in which distributed HEM units collaborate with each other in order to keep the demand and supply balanced in their neighborhood. Assuming the energy requests by customers are random in time, we formulate the proposed CoHEM design as a multi-stage stochastic optimization problem. We propose novel models to describe the deferrable appliance load [e.g., plug-in (hybrid) electric vehicles (PHEV)], and apply approximation and decomposition techniques to handle the considered design problem in a decentralized fashion. The developed decentralized CoHEM algorithm allow the customers to locally compute their scheduling solutions using domestic user information and with message exchange between their neighbors only. Extensive simulation results demonstrate that the proposed CoHEM architecture can effectively improve real-time power balancing. Extensions to joint power procurement and real-time CoHEM scheduling are also presented.",
Understanding user behavior in online social networks: a survey,"Currently, online social networks such as Facebook, Twitter, Google+, LinkedIn, and Foursquare have become extremely popular all over the world and play a significant role in people¿s daily lives. People access OSNs using both traditional desktop PCs and new emerging mobile devices. With more than one billion users worldwide, OSNs are a new venue of innovation with many challenging research problems. In this survey, we aim to give a comprehensive review of state-of-the-art research related to user behavior in OSNs from several perspectives. First, we discuss social connectivity and interaction among users. Also, we investigate traffic activity from a network perspective. Moreover, as mobile devices become a commodity, we pay attention to the characteristics of social behaviors in mobile environments. Last but not least, we review malicious behaviors of OSN users, and discuss several solutions to detect misbehaving users. Our survey serves the important roles of both providing a systematic exploration of existing research highlights and triggering various potentially significant research in these topics.",
Activity Discovery and Activity Recognition: A New Partnership,"Activity recognition has received increasing attention from the machine learning community. Of particular interest is the ability to recognize activities in real time from streaming data, but this presents a number of challenges not faced by traditional offline approaches. Among these challenges is handling the large amount of data that does not belong to a predefined class. In this paper, we describe a method by which activity discovery can be used to identify behavioral patterns in observational data. Discovering patterns in the data that does not belong to a predefined class aids in understanding this data and segmenting it into learnable classes. We demonstrate that activity discovery not only sheds light on behavioral patterns, but it can also boost the performance of recognition algorithms. We introduce this partnership between activity discovery and online activity recognition in the context of the CASAS smart home project and validate our approach using CASAS data sets.",
Atrial Fibrillation Detection Using an iPhone 4S,"Atrial fibrillation (AF) affects three to five million Americans and is associated with significant morbidity and mortality. Existing methods to diagnose this paroxysmal arrhythmia are cumbersome and/or expensive. We hypothesized that an iPhone 4S can be used to detect AF based on its ability to record a pulsatile photoplethysmogram signal from a fingertip using the built-in camera lens. To investigate the capability of the iPhone 4S for AF detection, we first used two databases, the MIT-BIH AF and normal sinus rhythm (NSR) to derive discriminatory threshold values between two rhythms. Both databases include RR time series originating from 250 Hz sampled ECG recordings. We rescaled the RR time series to 30 Hz so that the RR time series resolution is 1/30 (s) which is equivalent to the resolution from an iPhone 4S. We investigated three statistical methods consisting of the root mean square of successive differences (RMSSD), the Shannon entropy (ShE) and the sample entropy (SampE), which have been proved to be useful tools for AF assessment. Using 64-beat segments from the MIT-BIH databases, we found the beat-to-beat accuracy value of 0.9405, 0.9300, and 0.9614 for RMSSD, ShE, and SampE, respectively. Using an iPhone 4S, we collected 2-min pulsatile time series from 25 prospectively recruited subjects with AF pre- and postelectrical cardioversion. Using derived threshold values of RMSSD, ShE and SampE from the MIT-BIH databases, we found the beat-to-beat accuracy of 0.9844, 0.8494, and 0.9522, respectively. It should be recognized that for clinical applications, the most relevant objective is to detect the presence of AF in the data. Using this criterion, we achieved an accuracy of 100% for both the MIT-BIH AF and iPhone 4S databases.","Databases,
Time series analysis,
Entropy,
Atrial fibrillation,
Monitoring,
Cameras,
Accuracy"
Stochastic Performance Analysis of a Wireless Finite-State Markov Channel,"Wireless networks are expected to support a diverse range of quality of service requirements and traffic characteristics. This paper undertakes stochastic performance analysis of a wireless finite-state Markov channel (FSMC) by using stochastic network calculus. Particularly, delay and backlog upper bounds are derived directly based on the analytical principle behind stochastic network calculus. Both the single user and multi-user cases are considered. For the multi-user case, two channel sharing methods among eligible users are studied, i.e., the even sharing and exclusive use methods. In the former, the channel service rate is evenly divided among eligible users, whereas in the latter, it is exclusively used by a user randomly selected from the eligible users. When studying the exclusive use method, the problem that the state space increases exponentially with the user number is addressed using a novel approach. The essential idea of this approach is to construct a new Markov modulation process from the channel state process. In the new process, the multi-user effect is equivalently manifested by its transition and steady-state probabilities, and the state space size remains unchanged even with the increase of the user number. This significantly reduces the complexity in computing the derived backlog and delay bounds. The presented analysis is validated through comparison between analytical and simulation results.","Delay,
Calculus,
Markov processes,
Performance analysis,
Wireless networks"
Image Processing Using Smooth Ordering of its Patches,"We propose an image processing scheme based on reordering of its patches. For a given corrupted image, we extract all patches with overlaps, refer to these as coordinates in high-dimensional space, and order them such that they are chained in the “shortest possible path,” essentially solving the traveling salesman problem. The obtained ordering applied to the corrupted image implies a permutation of the image pixels to what should be a regular signal. This enables us to obtain good recovery of the clean image by applying relatively simple one-dimensional smoothing operations (such as filtering or interpolation) to the reordered set of pixels. We explore the use of the proposed approach to image denoising and inpainting, and show promising results in both cases.","travelling salesman problems,
image denoising,
interpolation,
smoothing methods"
Berkeley MHAD: A comprehensive Multimodal Human Action Database,"Over the years, a large number of methods have been proposed to analyze human pose and motion information from images, videos, and recently from depth data. Most methods, however, have been evaluated on datasets that were too specific to each application, limited to a particular modality, and more importantly, captured under unknown conditions. To address these issues, we introduce the Berkeley Multimodal Human Action Database (MHAD) consisting of temporally synchronized and geometrically calibrated data from an optical motion capture system, multi-baseline stereo cameras from multiple views, depth sensors, accelerometers and microphones. This controlled multimodal dataset provides researchers an inclusive testbed to develop and benchmark new algorithms across multiple modalities under known capture conditions in various research domains. To demonstrate possible use of MHAD for action recognition, we compare results using the popular Bag-of-Words algorithm adapted to each modality independently with the results of various combinations of modalities using the Multiple Kernel Learning. Our comparative results show that multimodal analysis of human motion yields better action recognition rates than unimodal analysis.",
SymFET: A Proposed Symmetric Graphene Tunneling Field-Effect Transistor,"In this paper, an analytical model for calculating the channel potential and current-voltage characteristics in a symmetric tunneling field-effect transistor (SymFET) is presented. The current in a SymFET flows by tunneling from an n-type graphene layer to a p-type graphene layer. A large current peak occurs when the Dirac points are aligned at a particular drain-to-source bias VDS . Our model shows that the current of the SymFET is very weakly dependent on temperature. The resonant current peak is controlled by chemical doping and applied gate bias. The on/off ratio increases with graphene coherence length and doping. The symmetric resonant peak is a good candidate for high-speed analog applications and can enable digital logic similar to the BiSFET. Our analytical model also offers the benefit of permitting simple analysis of features such as the full-width at half-maximum (FWHM) of the resonant peak and higher order harmonics of the nonlinear current. The SymFET takes advantage of the perfect symmetry of the band structure of 2-D graphene, a feature that is not present in conventional semiconductors.","Graphene,
Tunneling,
Logic gates,
Doping,
Quantum capacitance,
Insulators"
FreeLoc: Calibration-free crowdsourced indoor localization,"Many indoor localization techniques that rely on RF signals from wireless Access Points have been proposed in the last decade. In recent years, research on crowdsourced (also known as “Organic”) Wi-Fi fingerprint positioning systems has been attracting much attention. This participatory approach introduces new challenges that no previously proposed techniques have taken into account. This paper proposes “FreeLoc”, an efficient localization method addressing three major technical issues posed in crowdsourcing based systems. Our novel solution facilitates 1) extracting accurate fingerprint values from short RSS measurement times 2) calibration-free positioning across different devices and 3) maintaining a single fingerprint for each location in a radio map, irrespective of any number of uploaded data sets for a given location. Through experiments using four different smartphones, we evaluate our new indoor positioning method. The experimental results confirm that the proposed scheme provides consistent localization accuracy in an environment where the device heterogeneity and the multiple surveyor problems exist.","IEEE 802.11 Standards,
Accuracy,
Buildings,
Servers,
Databases,
Antenna measurements,
Calibration"
Land-Use Classification Using Taxi GPS Traces,"Detailed land use, which is difficult to obtain, is an integral part of urban planning. Currently, GPS traces of vehicles are becoming readily available. It conveys human mobility and activity information, which can be closely related to the land use of a region. This paper discusses the potential use of taxi traces for urban land-use classification, particularly for recognizing the social function of urban land by using one year's trace data from 4000 taxis. First, we found that pick-up/set-down dynamics, extracted from taxi traces, exhibited clear patterns corresponding to the land-use classes of these regions. Second, with six features designed to characterize the pick-up/set-down pattern, land-use classes of regions could be recognized. Classification results using the best combination of features achieved a recognition accuracy of 95%. Third, the classification results also highlighted regions that changed land-use class from one to another, and such land-use class transition dynamics of regions revealed unusual real-world social events. Moreover, the pick-up/set-down dynamics could further reflect to what extent each region is used as a certain class.",
Saliency Detection by Multiple-Instance Learning,"Saliency detection has been a hot topic in recent years. Its popularity is mainly because of its theoretical meaning for explaining human attention and applicable aims in segmentation, recognition, etc. Nevertheless, traditional algorithms are mostly based on unsupervised techniques, which have limited learning ability. The obtained saliency map is also inconsistent with many properties of human behavior. In order to overcome the challenges of inability and inconsistency, this paper presents a framework based on multiple-instance learning. Low-, mid-, and high-level features are incorporated in the detection procedure, and the learning ability enables it robust to noise. Experiments on a data set containing 1000 images demonstrate the effectiveness of the proposed framework. Its applicability is shown in the context of a seam carving application.","Image color analysis,
Feature extraction,
Training,
Humans,
Visualization,
Image segmentation,
Biological system modeling"
"Azimuthal Turing Patterns, Bright and Dark Cavity Solitons in Kerr Combs Generated With Whispering-Gallery-Mode Resonators","We investigate the formation of cavity solitons in crystalline whispering-gallery-mode disk resonators that are pumped in different dispersion regimes. In the Fourier domain, these dissipative structures correspond to specific types of mode-locked Kerr optical frequency combs. Depending on the sign of the second-order chromatic dispersion and on the pumping conditions, we show that either bright or dark cavity solitons can emerge, and we show that these two regimes are associated with characteristic spectral signatures that can be discriminated experimentally. We use the Lugiato-Lefever spatiotemporal formalism to investigate the temporal dynamics leading to the formation of these azimuthal solitons, as well as the emergence of Turing patterns. The theoretical results are in excellent agreement with experimental measurements that are obtained using calcium and magnesium fluoride disk resonators pumped near 1550 nm.",
A framework for truthful online auctions in cloud computing with heterogeneous user demands,"The paradigm of cloud computing has spontaneously prompted a wide interest in market-based resource allocation mechanisms by which a cloud provider aims at efficiently allocating cloud resources among potential users. Among these mechanisms, auction-style pricing policies, as they can effectively reflect the underlying trends in demand and supply for the computing resources, have attracted a research interest recently. This paper conducts the first work on a framework for truthful online cloud auctions where users with heterogeneous demands could come and leave on the fly. Our framework desirably supports a variety of design requirements, including (1) dynamic design for timely reflecting fluctuation of supply-demand relations, (2) joint design for supporting the heterogeneous user demands, and (3) truthful design for discouraging bidders from cheating behaviors. Concretely speaking, we first design a novel bidding language, wherein users' heterogeneous demands are generalized to regulated and consistent forms. Besides, building on top of our bidding language we propose COCA, an incentive-Compatible (truthful) Online Cloud Auction mechanism based on two proposed guidelines. Our theoretical analysis shows that the worst-case performance of COCA can be well-bounded. Further, in simulations the performance of COCA is seen to be comparable to the well-known off-line Vickrey-Clarke-Groves (VCG) mechanism [11].",
Hyperspectral Imagery Restoration Using Nonlocal Spectral-Spatial Structured Sparse Representation With Noise Estimation,"Noise reduction is an active research area in image processing due to its importance in improving the quality of image for object detection and classification. In this paper, we develop a sparse representation based noise reduction method for hyperspectral imagery, which is dependent on the assumption that the non-noise component in an observed signal can be sparsely decomposed over a redundant dictionary while the noise component does not have this property. The main contribution of the paper is in the introduction of nonlocal similarity and spectral-spatial structure of hyperspectral imagery into sparse representation. Non-locality means the self-similarity of image, by which a whole image can be partitioned into some groups containing similar patches. The similar patches in each group are sparsely represented with a shared subset of atoms in a dictionary making true signal and noise more easily separated. Sparse representation with spectral-spatial structure can exploit spectral and spatial joint correlations of hyperspectral imagery by using 3-D blocks instead of 2-D patches for sparse coding, which also makes true signal and noise more distinguished. Moreover, hyperspectral imagery has both signal-independent and signal-dependent noises, so a mixed Poisson and Gaussian noise model is used. In order to make sparse representation be insensitive to the various noise distribution in different blocks, a variance-stabilizing transformation (VST) is used to make their variance comparable. The advantages of the proposed methods are validated on both synthetic and real hyperspectral remote sensing data sets.","Noise reduction,
Dictionaries,
Correlation,
Hyperspectral imaging,
Gaussian noise,
Image restoration"
"Mobile Social Networks: Architectures, Social Properties, and Key Research Challenges","Mobile social networks (MSNs) are mobile communication systems focusing not only on the behaviour but also on the social needs of the users. In a broader view all mobile systems used by people in their everyday lives can be characterized as MSNs, since all interactions taking place follow social rather than random patterns. Whether the deployed communication system takes into account the social background of the underlying network, depends on its form and capabilities. This article presents a review of the relevant work published in MSNs. Initially the basic architectures and components are summarized. Then the basic social properties of the network, as found in the key literature, are extensively examined. These properties are the main source of inspiration for new MSN protocols and applications, especially for non centralized systems. Finally the key research problems and the open issues in the area are presented, including future applications and privacy concerns.",
Infrared Patch-Image Model for Small Target Detection in a Single Image,"The robust detection of small targets is one of the key techniques in infrared search and tracking applications. A novel small target detection method in a single infrared image is proposed in this paper. Initially, the traditional infrared image model is generalized to a new infrared patch-image model using local patch construction. Then, because of the non-local self-correlation property of the infrared background image, based on the new model small target detection is formulated as an optimization problem of recovering low-rank and sparse matrices, which is effectively solved using stable principle component pursuit. Finally, a simple adaptive segmentation method is used to segment the target image and the segmentation result can be refined by post-processing. Extensive synthetic and real data experiments show that under different clutter backgrounds the proposed method not only works more stably for different target sizes and signal-to-clutter ratio values, but also has better detection performance compared with conventional baseline methods.",
Multi-Agent Systems with Dynamical Topologies: Consensus and Applications,"It is well known that a multi-agent system (MAS) is a specific system consisting of multiple interacting autonomous agents. Consensus or synchronization, as one of the typical collective behaviors, is ubiquitous in nature. Over the last decades, consensus has been widely investigated in various disciplines, including mathematics, physics, biology, engineering, and social sciences. In particular, consensus of MAS with dynamical topology is an emerging new topic motivated by many real-world applications, such as wireless communication and sensor networks. However, the collective behavior of MAS with dynamical topology is very complex and cannot be easily analyzed by the traditional approaches. To resolve the issue of dynamical topology, various techniques and methods have been developed in the last decade. This paper aims to review the main advances in the consensus of MAS with dynamical topology, including several fundamental models and the corresponding methods. The main purpose is to promote this emerging topic on multi-agent systems, with emphasis on the interdisciplinary interest from the circuits and systems engineering communities.","Multi-agent systems,
Network topolgy,
Robot sensing systems,
Heuristic algorithms,
Biological system modeling,
Integrated circuit modeling,
Synchronization"
Using Class Imbalance Learning for Software Defect Prediction,"To facilitate software testing, and save testing costs, a wide range of machine learning methods have been studied to predict defects in software modules. Unfortunately, the imbalanced nature of this type of data increases the learning difficulty of such a task. Class imbalance learning specializes in tackling classification problems with imbalanced distributions, which could be helpful for defect prediction, but has not been investigated in depth so far. In this paper, we study the issue of if and how class imbalance learning methods can benefit software defect prediction with the aim of finding better solutions. We investigate different types of class imbalance learning methods, including resampling techniques, threshold moving, and ensemble algorithms. Among those methods we studied, AdaBoost.NC shows the best overall performance in terms of the measures including balance, G-mean, and Area Under the Curve (AUC). To further improve the performance of the algorithm, and facilitate its use in software defect prediction, we propose a dynamic version of AdaBoost.NC, which adjusts its parameter automatically during training. Without the need to pre-define any parameters, it is shown to be more effective and efficient than the original AdaBoost.NC.","Learning systems,
Software,
Training,
Prediction algorithms,
Measurement,
Software algorithms,
Niobium"
Smart Meter Privacy: A Theoretical Framework,"The solutions offered to-date for end-user privacy in smart meter measurements, a well-known challenge in the smart grid, have been tied to specific technologies such as batteries or assumptions on data usage without quantifying the loss of benefit (utility) that results from any such approach. Using tools from information theory and a hidden Markov model for the measurements, a new framework is presented that abstracts both the privacy and the utility requirements of smart meter data. This leads to a novel privacy-utility tradeoff problem with minimal assumptions that is tractable. For a stationary Gaussian model of the electricity load, it is shown that for a desired mean-square distortion (utility) measure between the measured and revealed data, the optimal privacy-preserving solution: i) exploits the presence of high-power but less private appliance spectra as implicit distortion noise, and ii) filters out frequency components with lower power relative to a distortion threshold; this approach encompasses many previously proposed approaches to smart meter privacy.","Home appliances,
Hidden Markov models,
Privacy,
Data privacy,
Load modeling,
Distortion measurement,
Batteries"
Learning to Distribute Vocabulary Indexing for Scalable Visual Search,"In recent years, there is an ever-increasing research focus on Bag-of-Words based near duplicate visual search paradigm with inverted indexing. One fundamental yet unexploited challenge is how to maintain the large indexing structures within a single server subject to its memory constraint, which is extremely hard to scale up to millions or even billions of images. In this paper, we propose to parallelize the near duplicate visual search architecture to index millions of images over multiple servers, including the distribution of both visual vocabulary and the corresponding indexing structure. We optimize the distribution of vocabulary indexing from a machine learning perspective, which provides a “memory light” search paradigm that leverages the computational power across multiple servers to reduce the search latency. Especially, our solution addresses two essential issues: “What to distribute” and “How to distribute”. “What to distribute” is addressed by a “lossy” vocabulary Boosting, which discards both frequent and indiscriminating words prior to distribution. “How to distribute” is addressed by learning an optimal distribution function, which maximizes the uniformity of assigning the words of a given query to multiple servers. We validate the distributed vocabulary indexing scheme in a real world location search system over 10 million landmark images. Comparing to the state-of-the-art alternatives of single-server search [5], [6], [16] and distributed search [23], our scheme has yielded a significant gain of about 200% speedup at comparable precision by distributing only 5% words. We also report excellent robustness even when partial servers crash.",
Transfer defect learning,"Many software defect prediction approaches have been proposed and most are effective in within-project prediction settings. However, for new projects or projects with limited training data, it is desirable to learn a prediction model by using sufficient training data from existing source projects and then apply the model to some target projects (cross-project defect prediction). Unfortunately, the performance of cross-project defect prediction is generally poor, largely because of feature distribution differences between the source and target projects. In this paper, we apply a state-of-the-art transfer learning approach, TCA, to make feature distributions in source and target projects similar. In addition, we propose a novel transfer defect learning approach, TCA+, by extending TCA. Our experimental results for eight open-source projects show that TCA+ significantly improves cross-project prediction performance.",
Optimal Strategies for Communication and Remote Estimation With an Energy Harvesting Sensor,"We consider a remote estimation problem with an energy harvesting sensor and a remote estimator. The sensor observes the state of a discrete-time source which may be a finite state Markov chain or a multidimensional linear Gaussian system. It harvests energy from its environment (say, for example, through a solar cell) and uses this energy for the purpose of communicating with the estimator. Due to randomness of the energy available for communication, the sensor may not be able to communicate all of the time. The sensor may also want to save its energy for future communications. The estimator relies on messages communicated by the sensor to produce real-time estimates of the source state. We consider the problem of finding a communication scheduling strategy for the sensor and an estimation strategy for the estimator that jointly minimizes the expected sum of communication and distortion costs over a finite time horizon. Our goal of joint optimization leads to a decentralized decision-making problem. By viewing the problem from the estimator's perspective, we obtain a dynamic programming characterization for the decentralized decision-making problem that involves optimization over functions. Under some symmetry assumptions on the source statistics and the distortion metric, we show that an optimal communication strategy is described by easily computable thresholds and that the optimal estimate is a simple function of the most recently received sensor observation.",
Minimizing charging delay in wireless rechargeable sensor networks,"As a pioneering experimental platform of wireless rechargeable sensor networks, the Wireless Identification and Sensing Platform (WISP) is an open-source platform that integrates sensing and computation capabilities to the traditional RFID tags. Different from traditional tags, a RFID-based wireless rechargeable sensor node needs to charge its onboard energy storage above a threshold in order to power its sensing, computation and communication components. Consequently, such charging delay imposes a unique design challenge for deploying wireless rechargeable sensor networks. In this paper, we tackle this problem by planning the optimal movement strategy of the RFID reader, such that the time to charge all nodes in the network above their energy threshold is minimized. We first propose an optimal solution using the linear programming method. To further reduce the computational complexity, we then introduce a heuristic solution with a provable approximation ratio of (1 + θ)/(1 - ε) by discretizing the charging power on a two-dimensional space. Through extensive evaluations, we demonstrate that our design outperforms the set-cover-based design by an average of 24.7% while the computational complexity is O((N/ε)2).","Delays,
Wireless sensor networks,
Wireless communication,
Robot sensing systems,
Merging,
Radiofrequency identification"
An Effective Artificial Bee Colony Algorithm for a Real-World Hybrid Flowshop Problem in Steelmaking Process,"This paper aims to provide a solution method for the real-world hybrid flowshop scheduling problem resulting from a steelmaking process, which has important applications in modern iron and steel industry. We first present a mixed integer mathematic model based on a comprehensive investigation. Then, we develop a heuristic method and two improvement procedures for a given schedule based on the problem-specific characteristics. Finally, we propose an effective artificial bee colony (ABC) algorithm with the job-permutation-based representation for solving the scheduling problem. The proposed ABC algorithm incorporates the heuristic and improvement procedures as well as new characteristics including a neighboring solution generation method and two enhanced strategies. To evaluate the proposed algorithm, we present several adaptations of other well-known and recent metaheuristics to the problem and conduct a serial of experiments with the instances generated according to real-world production process. The results show that the proposed ABC algorithm is more effective than all other adaptations after comprehensive computational comparisons and statistical analysis.",
EV/PHEV Bidirectional Charger Assessment for V2G Reactive Power Operation,"This paper presents a summary of the available single-phase ac-dc topologies used for EV/PHEV, level-1 and -2 on-board charging and for providing reactive power support to the utility grid. It presents the design motives of single-phase on-board chargers in detail and makes a classification of the chargers based on their future vehicle-to-grid usage. The pros and cons of each different ac-dc topology are discussed to shed light on their suitability for reactive power support. This paper also presents and analyzes the differences between charging-only operation and capacitive reactive power operation that results in increased demand from the dc-link capacitor (more charge/discharge cycles and increased second harmonic ripple current). Moreover, battery state of charge is spared from losses during reactive power operation, but converter output power must be limited below its rated power rating to have the same stress on the dc-link capacitor.",
Very Short-Term Load Forecasting: Wavelet Neural Networks With Data Pre-Filtering,"Very short-term load forecasting predicts the loads 1 h into the future in 5-min steps in a moving window manner based on real-time data collected. Effective forecasting is important in area generation control and resource dispatch. It is however difficult in view of the noisy data collection process and complicated load features. This paper presents a method of wavelet neural networks with data pre-filtering. The key idea is to use a spike filtering technique to detect spikes in load data and correct them. Wavelet decomposition is then used to decompose the filtered loads into multiple components at different frequencies, separate neural networks are applied to capture the features of individual components, and results of neural networks are then combined to form the final forecasts. To perform moving forecasts, 12 dedicated wavelet neural networks are used based on test results. Numerical testing demonstrates the effects of data pre-filtering and the accuracy of wavelet neural networks based on a data set from ISO New England.","Neural networks,
Wavelet transforms,
Training,
Load forecasting,
Real time systems,
Forecasting,
ISO"
Simultaneous quantification of flow and tissue velocities based on multi-angle plane wave imaging,"A quantitative angle-independent 2-D modality for flow and tissue imaging based on multi-angle plane wave acquisition was evaluated. Simulations of realistic flow in a carotid artery bifurcation were used to assess the accuracy of the vector Doppler (VD) technique. Reduction in root mean square deviation from 27 cm/s to 6 cm/s and 7 cm/s to 2 cm/s was found for the lateral (vx) and axial (vz) velocity components, respectively, when the ensemble size was increased from 8 to 50. Simulations of a Couette flow phantom (vmax = 2.7 cm/s) gave promising results for imaging of slowly moving tissue, with root mean square deviation of 4.4 mm/s and 1.6 mm/s for the x- and z-components, respectively. A packet acquisition scheme providing both B-mode and vector Doppler RF data was implemented on a research scanner, and beamforming and further post-processing was done offline. In vivo results of healthy volunteers were in accordance with simulations and gave promising results for flow and tissue vector velocity imaging. The technique was also tested in patients with carotid artery disease. Using the high ensemble vector Doppler technique, blood flow through stenoses and secondary flow patterns were better visualized than in ordinary color Doppler. Additionally, the full velocity spectrum could be obtained retrospectively for arbitrary points in the image.","phantoms,
bifurcation,
biomedical ultrasonics,
blood vessels,
Couette flow,
diseases,
Doppler measurement,
haemodynamics,
pattern formation"
A Survey of Wireless Path Loss Prediction and Coverage Mapping Methods,"In this paper we provide a thorough and up to date survey of path loss prediction methods, spanning more than 60 years of fairly continuous research. These methods take a variety of approaches to modeling the signal attenuation between wireless transceivers: purely theoretical models, empirically fitted (often statistical) models, deterministic ray-optical models, and measurement-directed methods. Our work here extends and updates excellent, but now dated prior surveys of this important field. We provide a new taxonomy for reasoning about the similarities and differences of the many approaches and provide a brief but complete overview of the various methods as well as describing insights into future directions for research in this area.","Computational modeling,
Predictive models,
Interference,
Fading channels,
Transmitting antennas,
Receiving antennas"
ECG Signal Quality During Arrhythmia and Its Application to False Alarm Reduction,"An automated algorithm to assess electrocardiogram (ECG) quality for both normal and abnormal rhythms is presented for false arrhythmia alarm suppression of intensive care unit (ICU) monitors. A particular focus is given to the quality assessment of a wide variety of arrhythmias. Data from three databases were used: the Physionet Challenge 2011 dataset, the MIT-BIH arrhythmia database, and the MIMIC II database. The quality of more than 33 000 single-lead 10 s ECG segments were manually assessed and another 12 000 bad-quality single-lead ECG segments were generated using the Physionet noise stress test database. Signal quality indices (SQIs) were derived from the ECGs segments and used as the inputs to a support vector machine classifier with a Gaussian kernel. This classifier was trained to estimate the quality of an ECG segment. Classification accuracies of up to 99% on the training and test set were obtained for normal sinus rhythm and up to 95% for arrhythmias, although performance varied greatly depending on the type of rhythm. Additionally, the association between 4050 ICU alarms from the MIMIC II database and the signal quality, as evaluated by the classifier, was studied. Results suggest that the SQIs should be rhythm specific and that the classifier should be trained for each rhythm call independently. This would require a substantially increased set of labeled data in order to train an accurate algorithm.","Electrocardiography,
Training,
Heart beat,
Databases,
Support vector machines,
Noise,
MIMICs"
Second-Order Consensus Seeking in Multi-Agent Systems With Nonlinear Dynamics Over Random Switching Directed Networks,"This paper discusses the second-order local consensus problem for multi-agent systems with nonlinear dynamics over dynamically switching random directed networks. By applying the orthogonal decomposition method, the state vector of resulted error dynamical system can be decomposed as two transversal components, one of which evolves along the consensus manifold and the other evolves transversally with the consensus manifold. Several sufficient conditions for reaching almost surely second-order local consensus are derived for the cases of time-delay-free coupling and time-delay coupling, respectively. For the case of time-delay-free coupling, we find that if there exists one directed spanning tree in the network which corresponds to the fixed time-averaged topology and the switching rate of the dynamic network is not more than a critical value which is also estimated analytically, then second-order dynamical consensus can be guaranteed for the choice of suitable parameters. For the case of time-delay coupling, we not only prove that under some assumptions, the second-order consensus can be reached exponentially, but also give an analytical estimation of the upper bounds of convergence rate and the switching rate. Finally, numerical simulations are provided to illustrate the feasibility and effectiveness of the obtained theoretical results.","switching networks,
convergence,
nonlinear network analysis,
numerical analysis"
Feature Ensemble Plus Sample Selection: Domain Adaptation for Sentiment Classification,"Domain adaptation problems often arise often in the field of sentiment classification. Here, the feature ensemble plus sample selection (SS-FE) approach is proposed, which takes labeling and instance adaptation into account. A feature ensemble (FE) model is first proposed to learn a new labeling function in a feature reweighting manner. Furthermore, a PCA-based sample selection (PCA-SS) method is proposed as an aid to FE. Experimental results show that the proposed SS-FE approach could gain significant improvements, compared to FE or PCA-SS, because of its comprehensive consideration of both labeling adaptation and instance adaptation.","Classification,
Natural language processing,
Adaptation models,
Principal component analysis,
Intelligent systems,
Computational linguistics,
Text analysis"
Capacitor Voltage Regulation in Single-DC-Source Cascaded H-Bridge Multilevel Converters Using Phase-Shift Modulation,"Cascaded H-bridge multilevel power electronic converters generally require several dc sources. An alternative option is to replace all the separate dc sources feeding the H-bridge cells with capacitors, leaving only one H-bridge cell with a real dc voltage source. This will yield a cost-effective converter. However, the required capacitor voltage balancing is challenging. In this paper, using the phase-shift modulation approach, a new control method for cascaded H-bridge multilevel converters fed with only one independent dc source is presented. The proposed method has a wide voltage regulation range for the replacement capacitors in the H-bridge cells. Experimental and simulation results support the proposed control method.",
Homing spread: Community home-based multi-copy routing in mobile social networks,"A mobile social network (MSN) is a special delay tolerant network (DTN) composed of mobile nodes with social characteristics. Mobile nodes in MSNs generally visit community homes frequently, while other locations are visited less frequently. We propose a novel zero-knowledge MSN routing algorithm, homing spread (HS). The community homes have a higher priority to spread messages into the network. Theoretical analysis shows that the proposed algorithm can spread a given number of message copies in an optimal way when the inter-meeting times between any two nodes and between a node and a community home follow exponential distributions. We also calculate the expected delivery delay of HS. In addition, extensive simulations are conducted. Results show that community homes are important factors in efficient message spreading. By using homes to spread messages faster, HS achieves a better performance than existing zero-knowledge MSN routing algorithms, including Epidemic, with a given number of copies, and Spray&Wait.","Delays,
Probability density function,
Communities,
Mobile nodes,
Routing"
Completion of a Truncated Attenuation Image From the Attenuated PET Emission Data,"Positron emission tomographs (PETs) are currently almost exclusively designed as hybrid systems. The current standard is the PET/CT combination, while prototype PET/MRI systems are being studied by several research groups. One problem in these systems is that the transaxial field-of-view of the second system is smaller than that of the PET camera and does not provide complete attenuation data. Because this second system provides the image for PET attenuation and scatter correction, the smaller FOV causes truncation of the attenuation map, producing bias in the attenuation corrected activity image. In this paper, we propose a maximum-a-posteriori algorithm for estimating the missing part of the attenuation map from the PET emission data. The method is evaluated on five artificially truncated 18F-FDG PET/CT studies, where it reduced the error on the reconstructed PET activities from 20% to less than 7%. The results on a PET/MRI patient study with 18F-FDG are presented as well.",
Interconnection Framework for mHealth and Remote Monitoring Based on the Internet of Things,"Communication and information access defines the basis to reach a personalized health end-to-end framework. Personalized health capability is limited to the available data from the patient. The data is usually dynamic and incomplete. Therefore, it presents a critical issue for mining, analysis and trending. For that reason, this work presents an interconnection framework for mobile Health (mHealth) based on the Internet of Things. It makes continuous and remote vital sign monitoring feasible and introduces technological innovations for empowering health monitors and patient devices with Internet capabilities. It also allows patient monitoring and supervision by remote centers, and personal platforms such as tablets. In terms of hardware it offers a gateway and a personal clinical device used for the wireless transmission of continuous vital signs through 6LoWPAN, and patient identification through RFID. In terms of software, this interconnection framework presents a novel protocol, called YOAPY, for an efficient, secure, and scalable integration of the sensors deployed in the patient's personal environment. This paper presents the architecture and evaluates its capability to provide continuous monitoring, ubiquitous connectivity, extended device integration, reliability, and security and privacy support. The proposed interconnection framework and the proposed protocol for the sensors have been exhaustively evaluated in the framework of the AIRE project, which is focused on patients with breathing problem. This evaluates for the proposed protocol the data aggregation mechanism level, Round-Trip delay Time, impact of the distance, and the impact of the security. It has been concluded that secure continuous monitoring is feasible with the use of the proposed {YOAPY}} aggregation mechanisms and the capabilities from the proposed interconnection framework.","Monitoring,
Medical services,
Protocols,
Sensors,
Security,
Biomedical monitoring,
Internet"
A Carrier-Based PWM Strategy With the Offset Voltage Injection for Single-Phase Three-Level Neutral-Point-Clamped Converters,"Single-phase three-level neutral point clamped (NPC) converters are widely applied in high-speed railway electrical traction drive systems. A significant problem related to the single-phase three-level NPC converters is the fluctuation of the neutral-point voltage. In this paper, a capacitor voltage balancing technique is proposed that injects an offset voltage into the sinusoidal modulating signals of the conventional carrier-based pulsewidth modulation (CBPWM) method. Furthermore, when the injected offset voltage is maximized, it cannot only balance the dc-link capacitors voltages, but also reduce switching losses. Theoretical analysis has shown that both methods can control the neutral point voltage effectively, but the neutral point voltage controller in the CBPWM with maximum offset voltage injection (CBPWM-MOVI) has a faster dynamic response. It was observed that the high-order harmonics frequencies of the line current are centered around the twice switching frequency in the CBPWM with the offset voltage injection (CBPWM-OVI) but are centered around the switching frequency in the CBPWM-MOVI. And also, the CBPWM-MOVI has switching commutations number at least 25% below that of the CBPWM-OVI in one modulating signal period. The performances of the two strategies were verified by simulation and experimental tests.","Switches,
Voltage control,
Capacitors,
Pulse width modulation,
Switching frequency,
Insulated gate bipolar transistors,
Switching circuits"
Automated Abdominal Multi-Organ Segmentation With Subject-Specific Atlas Generation,"A robust automated segmentation of abdominal organs can be crucial for computer aided diagnosis and laparoscopic surgery assistance. Many existing methods are specialized to the segmentation of individual organs and struggle to deal with the variability of the shape and position of abdominal organs. We present a general, fully-automated method for multi-organ segmentation of abdominal computed tomography (CT) scans. The method is based on a hierarchical atlas registration and weighting scheme that generates target specific priors from an atlas database by combining aspects from multi-atlas registration and patch-based segmentation, two widely used methods in brain segmentation. The final segmentation is obtained by applying an automatically learned intensity model in a graph-cuts optimization step, incorporating high-level spatial knowledge. The proposed approach allows to deal with high inter-subject variation while being flexible enough to be applied to different organs. We have evaluated the segmentation on a database of 150 manually segmented CT images. The achieved results compare well to state-of-the-art methods, that are usually tailored to more specific questions, with Dice overlap values of 94%, 93%, 70%, and 92% for liver, kidneys, pancreas, and spleen, respectively.","Image segmentation,
Probabilistic logic,
Computed tomography,
Indexes,
Liver,
Kidney"
A Novel Reversible Data Hiding Scheme Based on Two-Dimensional Difference-Histogram Modification,"In this paper, based on two-dimensional difference- histogram modification, a novel reversible data hiding (RDH) scheme is proposed by using difference-pair-mapping (DPM). First, by considering each pixel-pair and its context, a sequence consisting of pairs of difference values is computed. Then, a two-dimensional difference-histogram is generated by counting the frequency of the resulting difference-pairs. Finally, reversible data embedding is implemented according to a specifically designed DPM. Here, the DPM is an injective mapping defined on difference-pairs. It is a natural extension of expansion embedding and shifting techniques used in current histogram-based RDH methods. By the proposed approach, compared with the conventional one-dimensional difference-histogram and one-dimensional prediction-error-histogram-based RDH methods, the image redundancy can be better exploited and an improved embedding performance is achieved. Moreover, a pixel-pair-selection strategy is also adopted to priorly use the pixel-pairs located in smooth image regions to embed data. This can further enhance the embedding performance. Experimental results demonstrate that the proposed scheme outperforms some state-of-the-art RDH works.","Histograms,
Noise measurement,
Context,
Image quality,
Data mining,
Redundancy,
Correlation"
Efficiency-Oriented Optimal Design of the LLC Resonant Converter Based on Peak Gain Placement,"The LLC resonant converter topology is widely used in dc-dc converter applications due to its advantages in achieving high efficiency and high power density. However, due to the complexity in the analysis, the converter lacks a clear design guideline on the selection of resonant tank parameters. In this paper, an optimization method is developed based on the operation mode analysis and peak gain placement. Following this approach, the converter can minimize the conduction loss while maintaining the required gain range. A 400-W, 400-V output and 25-38 V input LLC converter is built using the proposed method, which achieves above 98% peak efficiency. As a comparison, the conventional searching method is used to reselect the LLC parameters for the same specifications, and the experimental results show that the optimal design has better performance.",
Model Predictive Control of Voltages in Active Distribution Networks,"This paper presents a centralized control scheme to regulate distribution network voltages in the presence of high penetration of distributed generation. The approach is inspired of Model Predictive Control in order to compensate for modeling inaccuracies and measurement noise. The control actions, calculated from a multi-step optimization, are updated and corrected by real-time measurements. The proposed controller uses a linear model to predict the behavior of the system and the optimization is solved using quadratic programming. The proposed corrective control has been tested in a 11-kV distribution network including 75 nodes and hosting 22 distributed generating units.",
Edge-Directed Single-Image Super-Resolution Via Adaptive Gradient Magnitude Self-Interpolation,"Super-resolution from a single image plays an important role in many computer vision systems. However, it is still a challenging task, especially in preserving local edge structures. To construct high-resolution images while preserving the sharp edges, an effective edge-directed super-resolution method is presented in this paper. An adaptive self-interpolation algorithm is first proposed to estimate a sharp high-resolution gradient field directly from the input low-resolution image. The obtained high-resolution gradient is then regarded as a gradient constraint or an edge-preserving constraint to reconstruct the high-resolution image. Extensive results have shown both qualitatively and quantitatively that the proposed method can produce convincing super-resolution images containing complex and sharp features, as compared with the other state-of-the-art super-resolution algorithms.",
Semisupervised Self-Learning for Hyperspectral Image Classification,"Remotely sensed hyperspectral imaging allows for the detailed analysis of the surface of the Earth using advanced imaging instruments which can produce high-dimensional images with hundreds of spectral bands. Supervised hyperspectral image classification is a difficult task due to the unbalance between the high dimensionality of the data and the limited availability of labeled training samples in real analysis scenarios. While the collection of labeled samples is generally difficult, expensive, and time-consuming, unlabeled samples can be generated in a much easier way. This observation has fostered the idea of adopting semisupervised learning techniques in hyperspectral image classification. The main assumption of such techniques is that the new (unlabeled) training samples can be obtained from a (limited) set of available labeled samples without significant effort/cost. In this paper, we develop a new approach for semisupervised learning which adapts available active learning methods (in which a trained expert actively selects unlabeled samples) to a self-learning framework in which the machine learning algorithm itself selects the most useful and informative unlabeled samples for classification purposes. In this way, the labels of the selected pixels are estimated by the classifier itself, with the advantage that no extra cost is required for labeling the selected pixels using this machine-machine framework when compared with traditional machine-human active learning. The proposed approach is illustrated with two different classifiers: multinomial logistic regression and a probabilistic pixelwise support vector machine. Our experimental results with real hyperspectral images collected by the National Aeronautics and Space Administration Jet Propulsion Laboratory's Airborne Visible-Infrared Imaging Spectrometer and the Reflective Optics Spectrographic Imaging System indicate that the use of self-learning represents an effective and promising strategy in the context of hyperspectral image classification.",
Blind Compressive Sensing Dynamic MRI,"We propose a novel blind compressive sensing (BCS) frame work to recover dynamic magnetic resonance images from undersampled measurements. This scheme models the dynamic signal as a sparse linear combination of temporal basis functions, chosen from a large dictionary. In contrast to classical compressed sensing, the BCS scheme simultaneously estimates the dictionary and the sparse coefficients from the undersampled measurements. Apart from the sparsity of the coefficients, the key difference of the BCS scheme with current low rank methods is the nonorthogonal nature of the dictionary basis functions. Since the number of degrees-of-freedom of the BCS model is smaller than that of the low-rank methods, it provides improved reconstructions at high acceleration rates. We formulate the reconstruction as a constrained optimization problem; the objective function is the linear combination of a data consistency term and sparsity promoting l1 prior of the coefficients. The Frobenius norm dictionary constraint is used to avoid scale ambiguity. We introduce a simple and efficient majorize-minimize algorithm, which decouples the original criterion into three simpler subproblems. An alternating minimization strategy is used, where we cycle through the minimization of three simpler problems. This algorithm is seen to be considerably faster than approaches that alternates between sparse coding and dictionary estimation, as well as the extension of K-SVD dictionary learning scheme. The use of the l1 penalty and Frobenius norm dictionary constraint enables the attenuation of insignificant basis functions compared to the l0 norm and column norm constraint assumed in most dictionary learning algorithms; this is especially important since the number of basis functions that can be reliably estimated is restricted by the available measurements. We also observe that the proposed scheme is more robust to local minima compared to K-SVD method, which relies on greedy sparse coding. Our phase transition experiments demonstrate that the BCS scheme provides much better recovery rates than classical Fourier-based CS schemes, while being only marginally worse than the dictionary aware setting. Since the overhead in additionally estimating the dictionary is low, this method can be very useful in dynamic magnetic resonance imaging applications, where the signal is not sparse in known dictionaries. We demonstrate the utility of the BCS scheme in accelerating contrast enhanced dynamic data. We observe superior reconstruction performance with the BCS scheme in comparison to existing low rank and compressed sensing schemes.","Dictionaries,
Magnetic resonance imaging,
Compressed sensing,
Image reconstruction,
Optimization,
Acceleration"
Video Stream Quality Impacts Viewer Behavior: Inferring Causality Using Quasi-Experimental Designs,"The distribution of videos over the Internet is drastically transforming how media is consumed and monetized. Content providers, such as media outlets and video subscription services, would like to ensure that their videos do not fail, start up quickly, and play without interruptions. In return for their investment in video stream quality, content providers expect less viewer abandonment, more viewer engagement, and a greater fraction of repeat viewers, resulting in greater revenues. The key question for a content provider or a content delivery network (CDN) is whether and to what extent changes in video quality can cause changes in viewer behavior. Our work is the first to establish a causal relationship between video quality and viewer behavior, taking a step beyond purely correlational studies. To establish causality, we use Quasi-Experimental Designs, a novel technique adapted from the medical and social sciences. We study the impact of video stream quality on viewer behavior in a scientific data-driven manner by using extensive traces from Akamai's streaming network that include 23 million views from 6.7 million unique viewers. We show that viewers start to abandon a video if it takes more than 2 s to start up, with each incremental delay of 1 s resulting in a 5.8% increase in the abandonment rate. Furthermore, we show that a moderate amount of interruptions can decrease the average play time of a viewer by a significant amount. A viewer who experiences a rebuffer delay equal to 1% of the video duration plays 5% less of the video in comparison to a similar viewer who experienced no rebuffering. Finally, we show that a viewer who experienced failure is 2.32% less likely to revisit the same site within a week than a similar viewer who did not experience a failure.","Streaming media,
Media,
Correlation,
Delays,
Servers,
Internet"
Design and Coordination Kinematics of an Insertable Robotic Effectors Platform for Single-Port Access Surgery,"Single port access surgery (SPAS) presents surgeons with added challenges that require new surgical tools and surgical assistance systems with unique capabilities. To address these challenges, we designed and constructed a new insertable robotic end-effectors platform (IREP) for SPAS. The IREP can be inserted through a Ø15 mm trocar into the abdomen and it uses 21 actuated joints for controlling two dexterous arms and a stereo-vision module. Each dexterous arm has a hybrid mechanical architecture comprised of a two-segment continuum robot, a parallelogram mechanism for improved dual-arm triangulation, and a distal wrist for improved dexterity during suturing. The IREP is unique because of the combination of continuum arms with active and passive segments with rigid parallel kinematics mechanisms. This paper presents the clinical motivation, design considerations, kinematics, statics, and mechanical design of the IREP. The kinematics of coordination between the parallelogram mechanisms and the continuum arms is presented using the pseudo-rigid-body model of the beam representing the passive segment of each snake arm. Kinematic and static simulations and preliminary experiment results are presented in support of our design choices.",
Toward Ubiquitous Healthcare Services With a Novel Efficient Cloud Platform,"Ubiquitous healthcare services are becoming more and more popular, especially under the urgent demand of the global aging issue. Cloud computing owns the pervasive and on-demand service-oriented natures, which can fit the characteristics of healthcare services very well. However, the abilities in dealing with multimodal, heterogeneous, and nonstationary physiological signals to provide persistent personalized services, meanwhile keeping high concurrent online analysis for public, are challenges to the general cloud. In this paper, we proposed a private cloud platform architecture which includes six layers according to the specific requirements. This platform utilizes message queue as a cloud engine, and each layer thereby achieves relative independence by this loosely coupled means of communications with publish/subscribe mechanism. Furthermore, a plug-in algorithm framework is also presented, and massive semistructure or unstructured medical data are accessed adaptively by this cloud architecture. As the testing results showing, this proposed cloud platform, with robust, stable, and efficient features, can satisfy high concurrent requests from ubiquitous healthcare services.","Cloud computing,
Medical services,
Algorithm design and analysis,
Computer architecture,
Data mining,
Distributed databases"
Outage Performance Study of Cognitive Relay Networks with Imperfect Channel Knowledge,"This letter presents the outage performance analysis for a cognitive relay network (CRN) with imperfect channel knowledge estimations. Under the condition of imperfect channel state information (CSI) estimations of interference links between primary and secondary systems, especially the links from both secondary transmitter and secondary relays to primary users, the exact outage probability is derived over Rayleigh fading channels and is verified through simulations. The simulation results show that: 1) increasing the number of relays is an effective approach to mitigate the outage performance degradation caused by the imperfect CSI; 2) the imperfect CSI of the secondary transmitter-primary user (PU) link has a greater impact on the outage performance than that of the secondary relay-PU link.","Relays,
Interference,
Channel estimation,
Estimation,
Signal to noise ratio,
Knowledge engineering,
Fading"
Improving Dictionary Learning: Multiple Dictionary Updates and Coefficient Reuse,"In this letter, we propose two improvements of the MOD and K-SVD dictionary learning algorithms, by modifying the two main parts of these algorithms-the dictionary update and the sparse coding stages. Our first contribution is a different dictionary-update stage that aims at finding both the dictionary and the representations while keeping the supports intact. The second contribution suggests to leverage the known representations from the previous sparse-coding in the quest for the updated representations. We demonstrate these two ideas in practice and show how they lead to faster training and better quality outcome.",
A Low-Complexity ECG Feature Extraction Algorithm for Mobile Healthcare Applications,"This paper introduces a low-complexity algorithm for the extraction of the fiducial points from the electrocardiogram (ECG). The application area we consider is that of remote cardiovascular monitoring, where continuous sensing and processing takes place in low-power, computationally constrained devices, thus the power consumption and complexity of the processing algorithms should remain at a minimum level. Under this context, we choose to employ the discrete wavelet transform (DWT) with the Haar function being the mother wavelet, as our principal analysis method. From the modulus-maxima analysis on the DWT coefficients, an approximation of the ECG fiducial points is extracted. These initial findings are complimented with a refinement stage, based on the time-domain morphological properties of the ECG, which alleviates the decreased temporal resolution of the DWT. The resulting algorithm is a hybrid scheme of time- and frequency-domain signal processing. Feature extraction results from 27 ECG signals from QTDB were tested against manual annotations and used to compare our approach against the state-of-the art ECG delineators. In addition, 450 signals from the 15-lead PTBDB are used to evaluate the obtained performance against the CSE tolerance limits. Our findings indicate that all but one CSE limits are satisfied. This level of performance combined with a complexity analysis, where the upper bound of the proposed algorithm, in terms of arithmetic operations, is calculated as 2.423N+214 additions and 1.093N+12 multiplications for N ≤ 861 or 2.553N+102 additions and 1.093N+10 multiplications for N > 861 (N being the number of input samples), reveals that the proposed method achieves an ideal tradeoff between computational complexity and performance, a key requirement in remote cardiovascular disease monitoring systems.",
Object discovery in 3D scenes via shape analysis,"We present a method for discovering object models from 3D meshes of indoor environments. Our algorithm first decomposes the scene into a set of candidate mesh segments and then ranks each segment according to its “objectness” - a quality that distinguishes objects from clutter. To do so, we propose five intrinsic shape measures: compactness, symmetry, smoothness, and local and global convexity. We additionally propose a recurrence measure, codifying the intuition that frequently occurring geometries are more likely to correspond to complete objects. We evaluate our method in both supervised and unsupervised regimes on a dataset of 58 indoor scenes collected using an Open Source implementation of Kinect Fusion [1]. We show that our approach can reliably and efficiently distinguish objects from clutter, with Average Precision score of .92. We make our dataset available to the public.",
AMES-Cloud: A Framework of Adaptive Mobile Video Streaming and Efficient Social Video Sharing in the Clouds,"While demands on video traffic over mobile networks have been souring, the wireless link capacity cannot keep up with the traffic demand. The gap between the traffic demand and the link capacity, along with time-varying link conditions, results in poor service quality of video streaming over mobile networks such as long buffering time and intermittent disruptions. Leveraging the cloud computing technology, we propose a new mobile video streaming framework, dubbed AMES-Cloud, which has two main parts: adaptive mobile video streaming (AMoV) and efficient social video sharing (ESoV). AMoV and ESoV construct a private agent to provide video streaming services efficiently for each mobile user. For a given user, AMoV lets her private agent adaptively adjust her streaming flow with a scalable video coding technique based on the feedback of link quality. Likewise, ESoV monitors the social network interactions among mobile users, and their private agents try to prefetch video content in advance. We implement a prototype of the AMES-Cloud framework to demonstrate its performance. It is shown that the private agents in the clouds can effectively provide the adaptive streaming, and perform video sharing (i.e., prefetching) based on the social network analysis.","Streaming media,
Mobile communication,
Cloud computing,
Static VAr compensators,
Mobile computing,
Servers,
Prefetching"
High-Order Terminal Sliding-Mode Observer for Parameter Estimation of a Permanent-Magnet Synchronous Motor,"This paper proposes a terminal sliding-mode (TSM) observer for estimating the immeasurable mechanical parameters of permanent-magnet synchronous motors (PMSMs) used for complex mechanical systems. The observer can track the system states in finite time with high steady-state precision. A TSM control strategy is designed to guarantee the global finite-time stability of the observer and, meanwhile, to estimate the mechanical parameters of the PMSM. A novel second-order sliding-mode algorithm is designed to soften the switching control signal of the observer. The effect of the equivalent low-pass filter can be properly controlled in the algorithm based on requirements. The smooth signal of the TSM observer is directly used for the parameter estimation. The experimental results in a practical CNC machine tool are provided to demonstrate the effectiveness of the proposed method.",
On the Study of Outage Performance for Cognitive Relay Networks (CRN) with the Nth Best-Relay Selection in Rayleigh-fading Channels,"Relay selection is an effective way to achieve considerable performance gains in cognitive relay networks (CRN). In practice, the best relay may not always be selected, thus the study of the small Nth best relay selection will be very beneficial for CRN design. In this paper, performance analysis for underlay cognitive decode-and-forward relay networks with the small Nth best-relay selection scheme is studied over independent and identically distributed (i.i.d.) Rayleigh fading channels. Closed-form expression for the exact outage probability is derived, which can be used to evaluate the impact of the relay selection scheme, the number of relays, the interference power constraint and the transmit power limit on the outage performance. The theoretical analysis is validated by Monte-Carlo simulations. The results show that both the relay selection scheme and the number of relays have great impact on the outage performance of cognitive relay networks.",
Video-Based Human Behavior Understanding: A Survey,"Understanding human behaviors is a challenging problem in computer vision that has recently seen important advances. Human behavior understanding combines image and signal processing, feature extraction, machine learning, and 3-D geometry. Application scenarios range from surveillance to indexing and retrieval, from patient care to industrial safety and sports analysis. Given the broad set of techniques used in video-based behavior understanding and the fast progress in this area, in this paper we organize and survey the corresponding literature, define unambiguous key terms, and discuss links among fundamental building blocks ranging from human detection to action and interaction recognition. The advantages and the drawbacks of the methods are critically discussed, providing a comprehensive coverage of key aspects of video-based human behavior understanding, available datasets for experimentation and comparisons, and important open research issues.","Behavioral science,
Computer vision,
Feature extraction,
Hidden Markov models,
Support vector machines"
An Agent-Based Approach to Virtual Power Plants of Wind Power Generators and Electric Vehicles,"Wind power is gaining in significance as an important renewable source of clean energy. However, due to their inherent uncertainty, wind generators are often unable to participate in the forward electricity markets like the more predictable and controllable conventional generators. Given this, virtual power plants (VPPs) are being advocated as a solution for increasing the reliability of such intermittent renewable sources. In this paper, we take this idea further by considering VPPs as coalitions of wind generators and electric vehicles, where wind generators seek to use electric vehicles (EVs) as a storage medium to overcome the vagaries of generation. Using electric vehicles in this manner has the advantage that, since the number of EVs is increasing rapidly, no initial investment in dedicated storage is needed. In more detail, we first formally model the VPP and then, through an operational model based on linear programming, we show how the supply to the Grid and storage in the EV batteries can be scheduled to increase the profit of the VPP, while also paying for the storage using a novel scheme. The feasibility of our approach is examined through a realistic case-study, using real wind power generation data, corresponding electricity market prices and electric vehicles' characteristics.","Batteries,
Electricity,
Wind power generation,
Electric vehicles,
Generators,
Wind farms,
Vectors"
Understanding the Characteristics of Internet Short Video Sharing: A YouTube-Based Measurement Study,"Established in 2005, YouTube has become the most successful Internet website providing a new generation of short video sharing service. Today, YouTube alone consumes as much bandwidth as did the entire Internet in year 2000 . Understanding the features of YouTube and similar video sharing sites is thus crucial to their sustainable development and to network traffic engineering. In this paper, using traces crawled in a 1.5-year span (from February 2007 to September 2008), we present an in-depth and systematic measurement study on the characteristics of YouTube videos. We find that YouTube videos have noticeably different statistics compared to traditional streaming videos, ranging from length, access pattern, to their active life span. The series of datasets also allow us to identify the growth trend of this fast evolving Internet site, which has seldom been explored before. We also look closely at the social networking aspect of YouTube, as this is a key driving force toward its success. In particular, we find that the links to related videos generated by uploaders' choices form a small-world network. This suggests that the videos have strong correlations with each other, and creates opportunities for developing novel caching and peer-to-peer distribution schemes to efficiently deliver videos to end users.",
Game Theory for Network Security,"As networks become ubiquitous in people's lives, users depend on networks a lot for sufficient communication and convenient information access. However, networks suffer from security issues. Network security becomes a challenging topic since numerous new network attacks have appeared increasingly sophisticated and caused vast loss to network resources. Game theoretic approaches have been introduced as a useful tool to handle those tricky network attacks. In this paper, we review the existing game-theory based solutions for network security problems, classifying their application scenarios under two categories, attack-defense analysis and security measurement. Moreover, we present a brief view of the game models in those solutions and summarize them into two categories, cooperative game models and non-cooperative game models with the latter category consisting of subcategories. In addition to the introduction to the state of the art, we discuss the limitations of those game theoretic approaches and propose future research directions.","Game theory,
Monitoring,
Bayesian methods,
Access control,
Computer crime"
Perceptual Video Coding Based on SSIM-Inspired Divisive Normalization,"We propose a perceptual video coding framework based on the divisive normalization scheme, which is found to be an effective approach to model the perceptual sensitivity of biological vision, but has not been fully exploited in the context of video coding. At the macroblock (MB) level, we derive the normalization factors based on the structural similarity (SSIM) index as an attempt to transform the discrete cosine transform domain frame residuals to a perceptually uniform space. We further develop an MB level perceptual mode selection scheme and a frame level global quantization matrix optimization method. Extensive simulations and subjective tests verify that, compared with the H.264/AVC video coding standard, the proposed method can achieve significant gain in terms of rate-SSIM performance and provide better visual quality.","Video coding,
Quantization,
Discrete cosine transforms,
Indexes,
Optimized production technology"
Simultaneous Facial Feature Tracking and Facial Expression Recognition,"The tracking and recognition of facial activities from images or videos have attracted great attention in computer vision field. Facial activities are characterized by three levels. First, in the bottom level, facial feature points around each facial component, i.e., eyebrow, mouth, etc., capture the detailed face shape information. Second, in the middle level, facial action units, defined in the facial action coding system, represent the contraction of a specific set of facial muscles, i.e., lid tightener, eyebrow raiser, etc. Finally, in the top level, six prototypical facial expressions represent the global facial muscle movement and are commonly used to describe the human emotion states. In contrast to the mainstream approaches, which usually only focus on one or two levels of facial activities, and track (or recognize) them separately, this paper introduces a unified probabilistic framework based on the dynamic Bayesian network to simultaneously and coherently represent the facial evolvement in different levels, their interactions and their observations. Advanced machine learning methods are introduced to learn the model based on both training data and subjective prior knowledge. Given the model and the measurements of facial motions, all three levels of facial activities are simultaneously recognized through a probabilistic inference. Extensive experiments are performed to illustrate the feasibility and effectiveness of the proposed model on all three level facial activities.","Facial features,
Gold,
Face recognition,
Mouth,
Face,
Modeling,
Shape"
Generalized Epidemic Mean-Field Model for Spreading Processes Over Multilayer Complex Networks,"Mean-field deterministic epidemic models have been successful in uncovering several important dynamic properties of stochastic epidemic spreading processes over complex networks. In particular, individual-based epidemic models isolate the impact of the network topology on spreading dynamics. In this paper, the existing models are generalized to develop a class of models that includes the spreading process in multilayer complex networks. We provide a detailed description of the stochastic process at the agent level where the agents interact through different layers, each represented by a graph. The set of differential equations that describes the time evolution of the state occupancy probabilities has an exponentially growing state-space size in terms of the number of the agents. Based on a mean-field type approximation, we developed a set of nonlinear differential equations that has linearly growing state-space size. We find that the latter system, referred to as the generalized epidemic mean-field (GEMF) model, has a simple structure characterized by the elements of the adjacency matrices of the network layers and the Laplacian matrices of the transition rate graphs. Finally, we present several examples of epidemic models, including spreading of virus and information in computer networks and spreading of multiple pathogens in a host population .","Curing,
Mathematical model,
Computational modeling,
Markov processes,
Nonhomogeneous media,
Network topology,
Approximation methods"
Probabilistic Model of Payment Cost Minimization Considering Wind Power and Its Uncertainty,"The penetration of wind energy sources to power systems has significantly increased in recent years. With variable and uncertain wind power output, the payment and market-clearing price (MCP) may vary in different cases. In this paper, a methodology to quantitatively model the payment cost minimization (PCM) considering the effects of wind power from a probabilistic viewpoint is presented. The autoregressive moving average (ARMA) method with normal distribution of wind forecast error is used to model a time series of wind speed. Based on the wind turbine power curve, the probability distribution of wind power output can be obtained. Then, Monte Carlo simulation (MCS) is used to produce random samples of wind speed, and the genetic algorithm is applied to solve PCM for each sample. The proposed methodology and its solution are verified with simulation studies of two sample systems. The probabilistic distribution results can give consumers an overview of how much they should pay in a probabilistic sense. Further, the simulation results can serve as a lookup table to provide useful input for more refined unit commitment, and also provide a benchmark for future research works on PCM considering wind power.","Phase change materials,
Wind power generation,
Wind speed,
Autoregressive processes,
Genetic algorithms,
Generators,
Probabilistic logic"
An All-DC Offshore Wind Farm With Series-Connected Turbines: An Alternative to the Classical Parallel AC Model?,"In this paper, the concept of an all-dc wind park with series-connected turbines is investigated as an alternative to the classical ac parallel or radial wind park. This paper presents a literature overview of all-dc wind park concepts with series connection. A three-phase conversion system with permanent magnet machine, ac-ac converter, high-frequency transformer, and diode bridge rectifier is suggested in this paper for the series connection of dc turbines. The dc series park with the suggested conversion system is compared in terms of losses, cost, and reliability to the state-of-the-art park configuration which is the ac radial park with HVDC transmission. It is found that the dc series park becomes comparable with the ac radial design for high ratings of the dc turbines. Furthermore, the comparison shows that emphasis must be put on reducing the losses in the conversion system of the dc turbine and, particularly, the ac-ac converter. Therefore, the efficiency of the ac-ac converter is compared for three different topologies: the direct matrix converter, the indirect matrix converter, and the conventional back-to-back converter. The direct matrix converter is found to be the most efficient, suitable for the suggested conversion system.","Wind turbines,
Wind farms,
Reliability,
Generators,
Switches,
Topology"
Noncooperative and Cooperative Optimization of Distributed Energy Generation and Storage in the Demand-Side of the Smart Grid,"The electric energy distribution infrastructure is undergoing a startling technological evolution with the development of the smart grid concept, which allows more interaction between the supply- and the demand-side of the network and results in a great optimization potential. In this paper, we focus on a smart grid in which the demand-side comprises traditional users as well as users owning some kind of distributed energy source and/or energy storage device. By means of a day-ahead demand-side management mechanism regulated through an independent central unit, the latter users are interested in reducing their monetary expense by producing or storing energy rather than just purchasing their energy needs from the grid. Using a general energy pricing model, we tackle the grid optimization design from two different perspectives: a user-oriented optimization and an holistic-based design. In the former case, we optimize each user individually by formulating the grid optimization problem as a noncooperative game, whose solution analysis is addressed building on the theory of variational inequalities. In the latter case, we focus instead on the joint optimization of the whole system, allowing some cooperation among the users. For both formulations, we devise distributed and iterative algorithms providing the optimal production/storage strategies of the users, along with their convergence properties. Among all, the proposed algorithms preserve the users' privacy and require very limited signaling with the central unit.","Smart grids,
Optimization,
Energy consumption,
Energy storage,
Games,
Production,
Pricing"
A Self-Learning Approach to Single Image Super-Resolution,"Learning-based approaches for image super-resolution (SR) have attracted the attention from researchers in the past few years. In this paper, we present a novel self-learning approach for SR. In our proposed framework, we advance support vector regression (SVR) with image sparse representation, which offers excellent generalization in modeling the relationship between images and their associated SR versions. Unlike most prior SR methods, our proposed framework does not require the collection of training low and high-resolution image data in advance, and we do not assume the reoccurrence (or self-similarity) of image patches within an image or across image scales. With theoretical supports of Bayes decision theory, we verify that our SR framework learns and selects the optimal SVR model when producing an SR image, which results in the minimum SR reconstruction error. We evaluate our method on a variety of images, and obtain very promising SR results. In most cases, our method quantitatively and qualitatively outperforms bicubic interpolation and state-of-the-art learning-based SR approaches.",
On Projection Matrix Optimization for Compressive Sensing Systems,"This paper considers the problem of designing the projection matrix
Φ
for a compressive sensing (CS) system in which the dictionary
Ψ
is assumed to be given. The optimal projection matrix design is formulated in terms of finding those
Φ
such that the Frobenius norm of the difference between the Gram matrix of the equivalent dictionary
ΦΨ
and the identity matrix is minimized. A class of the solutions is derived in a closed-form, which is a generalization of the existing results. More interestingly, it is revealed that this solution set is characterized by an arbitrary orthonormal matrix. This freedom is then used to further enhance the performance of the CS system by minimizing the coherence between the atoms of the equivalent dictionary. An alternating minimization-based algorithm is proposed for solving the corresponding minimization problem. Experiments are carried out and simulations show that the projection matrix obtained by the proposed approach significantly improves the signal recovery accuracy of the CS system and outperforms those by existing algorithms.","Sensors,
Dictionaries,
Coherence,
Signal processing,
Accuracy,
Vectors,
Compressed sensing"
Rate Gain Region and Design Tradeoffs for Full-Duplex Wireless Communications,"In this paper, we analytically study the regime in which practical full-duplex systems can achieve larger rates than an equivalent half-duplex systems. The key challenge in practical full-duplex systems is uncancelled self-interference signal, which is caused by a combination of hardware and implementation imperfections. Thus, we first present a signal model which captures the effect of significant impairments such as oscillator phase noise, low-noise amplifier noise figure, mixer noise, and analog-to-digital converter quantization noise. Using the detailed signal model, we study the rate gain region, which is defined as the region of received signal-of-interest strength where full-duplex systems outperform half-duplex systems in terms of achievable rate. The rate gain region is derived as a piecewise linear approximation in log-domain, and numerical results show that the approximation closely matches the exact region. Our analysis shows that when phase noise dominates mixer and quantization noise, full-duplex systems can use either active analog cancellation or baseband digital cancellation to achieve near-identical rate gain regions. Finally, as a design example, we numerically investigate the full-duplex system performance and rate gain region in typical indoor environments for practical wireless applications.","radiofrequency interference,
indoor radio,
interference suppression,
low noise amplifiers,
oscillators,
quantisation (signal),
radio networks"
Radiation Effects in SiGe Technology,"Silicon-Germanium (SiGe) technology effectively merges the desirable attributes of conventional silicon-based CMOS manufacturing (high integration levels, at high yield and low cost) with the extreme levels of transistor performance attainable in classical III-V heterojunction bipolar transistors (HBTs). SiGe technology joins together on-die high-speed bandgap-engineered SiGe HBTs with conventional Si CMOS to form SiGe BiCMOS technology, including all the requisite RF passive elements and multi-level thick-Al metalization required for high-speed circuit design. Such an silicon-based integrated circuit technology platform presents designers with an ideal division of labor for realizing optimal solutions to many performance-constrained mixed-signal (analog + digital + RF) systems. The unique bandgap-engineered features of SiGe HBTs enable several key merits with respect to operation across a wide variety of so-called “extreme environments”, potentially with little or no process modification, ultimately providing compelling advantages at the circuit and system level, across a wide class of envisioned commercial and defense applications. Here we give an overview of this interesting field, focusing primarily on the intersection of SiGe HBTs, and circuits built from them, with radiation-intense environments such as space.",
Temporal Event Sequence Simplification,"Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.","Complexity theory,
Electronic medical records,
Data mining,
Data visualization,
Market research"
The Feasibility Conditions for Interference Alignment in MIMO Networks,"Interference alignment (IA) has attracted great attention in the last few years for its breakthrough performance in interference networks. However, despite the numerous works dedicated to IA, the feasibility conditions of IA remains unclear for most network topologies. The IA feasibility analysis is challenging as the IA constraints are sets of high-degree polynomials, for which no systematic tool to analyze the solvability conditions exists. In this work, by developing a new mathematical framework that maps the solvability of sets of polynomial equations to the linear independence of their first-order terms, we propose a sufficient condition that applies to MIMO interference networks with general configurations. We have further proved that this sufficient condition coincides with the necessary conditions under a wide range of configurations. These results further consolidate the theoretical basis of IA.","Polynomials,
Interference,
MIMO,
Antennas,
Vectors,
Systematics"
Age estimation from face images: Human vs. machine performance,"There has been a growing interest in automatic age estimation from facial images due to a variety of potential applications in law enforcement, security control, and human-computer interaction. However, despite advances in automatic age estimation, it remains a challenging problem. This is because the face aging process is determined not only by intrinsic factors, e.g. genetic factors, but also by extrinsic factors, e.g. lifestyle, expression, and environment. As a result, different people with the same age can have quite different appearances due to different rates of facial aging. We propose a hierarchical approach for automatic age estimation, and provide an analysis of how aging influences individual facial components. Experimental results on the FG-NET, MORPH Album2, and PCSO databases show that eyes and nose are more informative than the other facial components in automatic age estimation. We also study the ability of humans to estimate age using data collected via crowdsourcing, and show that the cumulative score (CS) within 5-year mean absolute error (MAE) of our method is better than the age estimates provided by humans.","Face,
Estimation,
Databases,
Aging,
Feature extraction,
Accuracy,
Image color analysis"
REpeating Pattern Extraction Technique (REPET): A Simple Method for Music/Voice Separation,"Repetition is a core principle in music. Many musical pieces are characterized by an underlying repeating structure over which varying elements are superimposed. This is especially true for pop songs where a singer often overlays varying vocals on a repeating accompaniment. On this basis, we present the REpeating Pattern Extraction Technique (REPET), a novel and simple approach for separating the repeating “background” from the non-repeating “foreground” in a mixture. The basic idea is to identify the periodically repeating segments in the audio, compare them to a repeating segment model derived from them, and extract the repeating patterns via time-frequency masking. Experiments on data sets of 1,000 song clips and 14 full-track real-world songs showed that this method can be successfully applied for music/voice separation, competing with two recent state-of-the-art approaches. Further experiments showed that REPET can also be used as a preprocessor to pitch detection algorithms to improve melody extraction.","Hidden Markov models,
Spectrogram,
Music,
Estimation,
Adaptation models,
Speech,
Speech processing"
Deadlock-Free Control of Automated Manufacturing Systems With Flexible Routes and Assembly Operations Using Petri Nets,"In the context of automated manufacturing systems (AMS), Petri nets are widely adopted to solve the modeling, analysis, and control problems. So far, nearly all known approaches to liveness enforcing supervisory control investigate AMS with either flexible routes or assembly operations, whereas little work investigates them with both. In this paper, we propose a novel class of systems, which can well deal with both features so as to facilitate the control of more complex AMS. Using structural analysis, we show that liveness of their Petri net model can be attributed to the absence of undermarked siphons, which is realizable by synthesizing a proper supervisory controller. Moreover, an efficient method is developed and verified via AMS examples.","Assembly,
System recovery,
Petri nets,
Electromyography,
Educational institutions,
Vectors,
Production"
Mobile Health: Revolutionizing Healthcare Through Transdisciplinary Research,"Mobile health (mHealth) seeks to improve individuals' health and well-being by continuously monitoring their status, rapidly diagnosing medical conditions, recognizing behaviors, and delivering just-in-time interventions, all in the user's natural mobile environment. The Web extra at http://youtu.be/o2mieSywutY is an audio interview in which Santosh Kumar, Wendy Nilsen, and Mani Srivastava discuss the path toward realizing mobile health systems.",
Mechanism of PEALD-Grown AlN Passivation for AlGaN/GaN HEMTs: Compensation of Interface Traps by Polarization Charges,"The physical mechanism of passivation of AlGaN/GaN HEMTs by AlN thin film prepared with plasma-enhanced atomic layer deposition (PEALD) is investigated by characterizing Ni- Al2O3/AlN-GaN/AlGaN/GaN metal-insulator-semiconductor (MIS) diodes. The dielectric stack Al2O3/AlN (13/2 nm) exhibits similar capability in suppressing the current collapse in AlGaN/GaN HEMTs as the 4-nm PEALD-AlN thin film used in our previous work but delivers much lower vertical leakage to facilitate the capacitance-voltage characterizations. Exceptionally large negative bias (<; -8 V) is required to deplete the 2-D electron gas in the MIS diode's C-V measurement. By virtue of quasi-static C-V characterization, it is revealed that positive fixed charges of ~ 3.2 × 1013 e/cm2 are introduced by the PEALD-AlN. The positive fixed charges are suggested to be polarization charges in the monocrystal-like PEALD-AlN. They can effectively compensate the high-density slow-response acceptor-like interface traps, resulting in effective suppression of current collapse.","Gallium nitride,
HEMTs,
MODFETs,
Aluminum oxide,
Aluminum gallium nitride,
Schottky diodes,
Passivation"
Automatic Detection of Optic Disc Based on PCA and Mathematical Morphology,"The algorithm proposed in this paper allows to automatically segment the optic disc from a fundus image. The goal is to facilitate the early detection of certain pathologies and to fully automate the process so as to avoid specialist intervention. The method proposed for the extraction of the optic disc contour is mainly based on mathematical morphology along with principal component analysis (PCA). It makes use of different operations such as generalized distance function (GDF), a variant of the watershed transformation, the stochastic watershed, and geodesic transformations. The input of the segmentation method is obtained through PCA. The purpose of using PCA is to achieve the grey-scale image that better represents the original RGB image. The implemented algorithm has been validated on five public databases obtaining promising results. The average values obtained (a Jaccard's and Dice's coefficients of 0.8200 and 0.8932, respectively, an accuracy of 0.9947, and a true positive and false positive fractions of 0.9275 and 0.0036) demonstrate that this method is a robust tool for the automatic segmentation of the optic disc. Moreover, it is fairly reliable since it works properly on databases with a large degree of variability and improves the results of other state-of-the-art methods.",
A Novel Piezoelectric Strain Sensor for Simultaneous Damping and Tracking Control of a High-Speed Nanopositioner,"This paper presents a novel piezoelectric strain sensor for damping and accurate tracking control of a high-speed nanopositioning stage. Piezoelectric sensors have the benefit of simple interface circuitry, low cost, high sensitivity, and high bandwidth. Although piezoelectric sensors have been successfully used as vibration sensors in smart structures, complications arise when they are used in a feedback loop for tracking. As piezoelectric strain sensors exhibit a capacitive source impedance, a high-pass filter is created, typically with a cut-off frequency of 1 to 10 Hz. This filter can cause significant errors and destabilize a tracking control system. Here, we overcome this problem by using a low-frequency bypass technique to replace the low-frequency component of the strain measurement with an estimate based on the open-loop system. Once the low-frequency filter is accounted for, any standard control system can be applied. In this paper, an analog integral resonant controller together with an integral tracking controller are implemented on a flexure-guided nanopositioner. The resulting closed-loop bandwidth is experimentally demonstrated to be 1.86 kHz. The nanopositioner is installed in an Atomic Force Microscope to obtain open- and closed-loop images at line rates of 40 and 78 Hz. Images recorded in closed loop show a significant improvement due to the elimination of nonlinearity.","Strain,
Nanopositioning,
Frequency measurement,
Displacement measurement,
Strain measurement,
Voltage measurement,
Damping"
Coherent Plane Wave Compounding for Very High Frame Rate Ultrasonography of Rapidly Moving Targets,"Coherent plane wave compounding is a promising technique for achieving very high frame rate imaging without compromising image quality or penetration. However, this approach relies on the hypothesis that the imaged object is not moving during the compounded scan sequence, which is not the case in cardiovascular imaging. This work investigates the effect of tissue motion on retrospective transmit focusing in coherent compounded plane wave imaging (PWI). Two compound scan sequences were studied based on a linear and alternating sequence of tilted plane waves, with different timing characteristics. Simulation studies revealed potentially severe degradations in the retrospective focusing process, where both radial and lateral resolution was reduced, lateral shifts of the imaged medium were introduced, and losses in signal-to-noise ratio (SNR) were inferred. For myocardial imaging, physiological tissue displacements were on the order of half a wavelength, leading to SNR losses up to 35 dB, and reductions of contrast by 40 dB. No significant difference was observed between the different tilt sequences. A motion compensation technique based on cross-correlation was introduced, which significantly recovered the losses in SNR and contrast for physiological tissue velocities. Worst case losses in SNR and contrast were recovered by 35 dB and 27-35 dB, respectively. The effects of motion were demonstrated in vivo when imaging a rat heart. Using PWI, very high frame rates up to 463 fps were achieved at high image quality, but a motion correction scheme was then required.",
On discovery of gathering patterns from trajectories,"The increasing pervasiveness of location-acquisition technologies has enabled collection of huge amount of trajectories for almost any kind of moving objects. Discovering useful patterns from their movement behaviours can convey valuable knowledge to a variety of critical applications. In this light, we propose a novel concept, called gathering, which is a trajectory pattern modelling various group incidents such as celebrations, parades, protests, traffic jams and so on. A key observation is that these incidents typically involve large congregations of individuals, which form durable and stable areas with high density. Since the process of discovering gathering patterns over large-scale trajectory databases can be quite lengthy, we further develop a set of well thought out techniques to improve the performance. These techniques, including effective indexing structures, fast pattern detection algorithms implemented with bit vectors, and incremental algorithms for handling new trajectory arrivals, collectively constitute an efficient solution for this challenging task. Finally, the effectiveness of the proposed concepts and the efficiency of the approaches are validated by extensive experiments based on a real taxicab trajectory dataset.","Trajectory,
Databases,
Clustering algorithms,
Shape,
Vectors,
Complexity theory,
Educational institutions"
Virtual Instrument Systems in Reality (VISIR) for Remote Wiring and Measurement of Electronic Circuits on Breadboard,"This paper reports on a state-of-the-art remote laboratory project called Virtual Instrument Systems in Reality (VISIR). VISIR allows wiring and measuring of electronic circuits remotely on a virtual workbench that replicates physical circuit breadboards. The wiring mechanism is developed by means of a relay switching matrix connected to a PCI eXtensions for Instrumentation (PXI) instrumentation platform. The entire equipment is controlled by LabVIEW server software, in addition to a measurement server software that protects the equipment from hazard connections by verifying input circuit designs, sent by students, before being executed. This paper addresses other approaches such as remote labs based on Data Acquisition Cards (DAQs), NetLab, and RemotElectLab, comparing them with VISIR in order to emphasize its singularity. Topics discussed are as follows: the technical description, software, operation cycle, features, and provided services. In addition, the feedback received by students at several universities and the encountered drawbacks along with the proposed solutions are highlighted. The paper finally addresses the ongoing and future challenges within the VISIR community including its integration with Learning Management Systems (LMSs) and iLab Shared Architecture (ISA), its new hardware version release that is based on LAN eXtensions for Instrumentation (LXI), and its new open platform version that supports federated access.","Computer science education,
Computer aided instruction,
Electronic learning,
Distance learning,
Remote laboratories,
Electronic circuits"
Bayesian Compressive Sensing Approaches for the Reconstruction of Two-Dimensional Sparse Scatterers Under TE Illuminations,"In this paper, the reconstruction of sparse scatterers under multiview transverse-electric illumination is dealt with. Starting from a probabilistic formulation of the “inverse source” problem, two Bayesian compressive sensing approaches are introduced. The former is a suitable extension of the single-task method presented earlier for the transverse-magnetic scalar case, while the other exploits an innovative multitask implementation to take into account the relationships among the “contrast currents” at the different probing views. Representative numerical results are discussed to assess, also comparatively, the numerical efficiency, the accuracy, and the robustness of the proposed approaches.","Bayes methods,
Microwave imaging,
Compressed sensing,
Probabilistic logic,
Inverse problems"
A Probabilistic Patch-Based Label Fusion Model for Multi-Atlas Segmentation With Registration Refinement: Application to Cardiac MR Images,"The evaluation of ventricular function is important for the diagnosis of cardiovascular diseases. It typically involves measurement of the left ventricular (LV) mass and LV cavity volume. Manual delineation of the myocardial contours is time-consuming and dependent on the subjective experience of the expert observer. In this paper, a multi-atlas method is proposed for cardiac magnetic resonance (MR) image segmentation. The proposed method is novel in two aspects. First, it formulates a patch-based label fusion model in a Bayesian framework. Second, it improves image registration accuracy by utilizing label information, which leads to improvement of segmentation accuracy. The proposed method was evaluated on a cardiac MR image set of 28 subjects. The average Dice overlap metric of our segmentation is 0.92 for the LV cavity, 0.89 for the right ventricular cavity and 0.82 for the myocardium. The results show that the proposed method is able to provide accurate information for clinical diagnosis.",
Beyond Text QA: Multimedia Answer Generation by Harvesting Web Information,"Community question answering (cQA) services have gained popularity over the past years. It not only allows community members to post and answer questions but also enables general users to seek information from a comprehensive set of well-answered questions. However, existing cQA forums usually provide only textual answers, which are not informative enough for many questions. In this paper, we propose a scheme that is able to enrich textual answers in cQA with appropriate media data. Our scheme consists of three components: answer medium selection, query generation for multimedia search, and multimedia data selection and presentation. This approach automatically determines which type of media information should be added for a textual answer. It then automatically collects data from the web to enrich the answer. By processing a large set of QA pairs and adding them to a pool, our approach can enable a novel multimedia question answering (MMQA) approach as users can find multimedia answers by matching their questions with those in the pool. Different from a lot of MMQA research efforts that attempt to directly answer questions with image and video data, our approach is built based on community-contributed textual answers and thus it is able to deal with more complex questions. We have conducted extensive experiments on a multi-source QA dataset. The results demonstrate the effectiveness of our approach.","Multimedia communication,
Streaming media,
Media,
Communities,
Educational institutions,
Humans"
Effect of Intrusion Detection and Response on Reliability of Cyber Physical Systems,"In this paper we analyze the effect of intrusion detection and response on the reliability of a cyber physical system (CPS) comprising sensors, actuators, control units, and physical objects for controlling and protecting a physical infrastructure. We develop a probability model based on stochastic Petri nets to describe the behavior of the CPS in the presence of both malicious nodes exhibiting a range of attacker behaviors, and an intrusion detection and response system (IDRS) for detecting and responding to malicious events at runtime. Our results indicate that adjusting detection and response strength in response to attacker strength and behavior detected can significantly improve the reliability of the CPS. We report numerical data for a CPS subject to persistent, random and insidious attacks with physical interpretations given.","Intrusion detection,
Mobile nodes,
Reliability,
Sensor phenomena and characterization"
Differential Evolution With Neighborhood and Direction Information for Numerical Optimization,"Differential evolution (DE) is a simple and powerful population-based evolutionary algorithm, successfully used in various scientific and engineering fields. Although DE has been studied by many researchers, the neighborhood and direction information is not fully and simultaneously exploited in the designing of DE. In order to alleviate this drawback and enhance the performance of DE, we first introduce two novel operators, namely, the neighbor guided selection scheme for parents involved in mutation and the direction induced mutation strategy, to fully exploit the neighborhood and direction information of the population, respectively. By synergizing these two operators, a simple and effective DE framework, which is referred to as the neighborhood and direction information based DE (NDi-DE), is then proposed for enhancing the performance of DE. This way, NDi-DE not only utilizes the information of neighboring individuals to exploit the regions of minima and accelerate convergence but also incorporates the direction information to prevent an individual from entering an undesired region and move to a promising area. Consequently, a good balance between exploration and exploitation can be achieved. In order to test the effectiveness of NDi-DE, the proposed framework is applied to the original DE algorithms, as well as several state-of-the-art DE variants. Experimental results show that NDi-DE is an effective framework to enhance the performance of most of the DE algorithms studied.",
Deep learning for robust feature generation in audiovisual emotion recognition,"Automatic emotion recognition systems predict high-level affective content from low-level human-centered signal cues. These systems have seen great improvements in classification accuracy, due in part to advances in feature selection methods. However, many of these feature selection methods capture only linear relationships between features or alternatively require the use of labeled data. In this paper we focus on deep learning techniques, which can overcome these limitations by explicitly capturing complex non-linear feature interactions in multimodal data. We propose and evaluate a suite of Deep Belief Network models, and demonstrate that these models show improvement in emotion classification performance over baselines that do not employ deep learning. This suggests that the learned high-order non-linear relationships are effective for emotion recognition.","Emotion recognition,
Speech,
Accuracy,
Speech processing,
Speech recognition,
Training,
Acoustics"
Second-Order Locally Dynamical Consensus of Multiagent Systems With Arbitrarily Fast Switching Directed Topologies,"This paper is mainly concerned with the analysis of the second-order locally dynamical consensus of multiagent systems with nonlinear dynamics in the directed networks with arbitrarily fast switching topologies. In our designed framework, the time-varying network topology is constant in each time interval and then randomly jumps to another topology when certain occasional events occur at some random moments. In addition, we further assume that the dwell time of each topology is unknown in advance and the corresponding adjacency weighted matrix is not necessarily nonnegative due to the probable existence of deteriorated communication channels in the underlying interaction network. By the orthogonal decomposition method, the state vector of the resultant error dynamical system can be further decomposed as two transversal components, one of which evolves along the consensus manifold and the other evolves transversally with the consensus manifold. Then, by introducing the generalized matrix measure and by applying the tools of contraction and circle analysis, the second-order locally dynamical consensus of multiagent systems with arbitrarily fast switching directed topologies is theoretically investigated in detail, and some easily verified sufficient conditions are also presented. It is shown that, under sufficiently large coupling strengths, the random switchings can be effectively tolerated and the consensus can be achieved for all agents in the network. Finally, numerical simulation examples are also provided to demonstrate the feasibility and effectiveness of the obtained theoretical results.","Time-varying systems,
Network topology,
Numerical simulation,
Multi-agent systems"
Stochastic Optimal Controller Design for Uncertain Nonlinear Networked Control System via Neuro Dynamic Programming,"The stochastic optimal controller design for the nonlinear networked control system (NNCS) with uncertain system dynamics is a challenging problem due to the presence of both system nonlinearities and communication network imperfections, such as random delays and packet losses, which are not unknown a priori. In the recent literature, neuro dynamic programming (NDP) techniques, based on value and policy iterations, have been widely reported to solve the optimal control of general affine nonlinear systems. However, for realtime control, value and policy iterations-based methodology are not suitable and time-based NDP techniques are preferred. In addition, output feedback-based controller designs are preferred for implementation. Therefore, in this paper, a novel NNCS representation incorporating the system uncertainties and network imperfections is introduced first by using input and output measurements for facilitating output feedback. Then, an online neural network (NN) identifier is introduced to estimate the control coefficient matrix, which is subsequently utilized for the controller design. Subsequently, the critic and action NNs are employed along with the NN identifier to determine the forward-in-time, time-based stochastic optimal control of NNCS without using value and policy iterations. Here, the value function and control inputs are updated once a sampling instant. By using novel NN weight update laws, Lyapunov theory is used to show that all the closed-loop signals and NN weights are uniformly ultimately bounded in the mean while the approximated control input converges close to its target value with time. Simulation results are included to show the effectiveness of the proposed scheme.","Artificial neural networks,
Delay,
Packet loss,
Optimal control,
Communication networks,
Dynamic programming"
"An Empirical Study of Communication Infrastructures Towards the Smart Grid: Design, Implementation, and Evaluation","The smart grid features ubiquitous interconnections of power equipments to enable two-way flows of electricity and information for various intelligent power management applications, such as accurate relay protection and timely demand response. To fulfill such pervasive equipment interconnects, a full-fledged communication infrastructure is of great importance in the smart grid. There have been extensive works on disparate layouts of communication infrastructures in the smart grid by surveying feasible wired or wireless communication technologies, such as power line communications and cellular networks. Nevertheless, towards an operable, cost-efficient and backward-compatible communication solution, more comprehensive and practical understandings are still urgently needed regarding communication requirements, applicable protocols, and system performance. Through such comprehensive understandings, we are prone to answer a fundamental question, how to design, implement and integrate communication infrastructures with power systems. In this paper, we address this issue in a case study of a smart grid demonstration project, the Future Renewable Electric Energy Delivery and Management (FREEDM) systems. By investigating communication scenarios, we first clarify communication requirements implied in FREEDM use cases. Then, we adopt a predominant protocol framework, Distributed Network Protocol 3.0 over TCP/IP (DNP3 over TCP/IP), to practically establish connections between electric devices for data exchanges in a small-scale FREEDM system setting, Green Hub. Within the real-setting testbed, we measure the message delivery performance of the DNP3-based communication infrastructure. Our results reveal that diverse timing requirements of message deliveries are arguably primary concerns in a way that dominates viabilities of protocols or schemes in the communication infrastructure of the smart grid. Accordingly, although DNP3 over TCP/IP is widely considered as a smart grid communication solution, it cannot satisfy communication requirements in some time-critical scenarios, such as relay protections, which claim a further optimization on the protocol efficiency of DNP3.","Smart grids,
Green products,
Protocols,
IP networks,
Renewable energy resources,
Timing,
Real-time systems"
Minimization of Transmission Loss in Meshed AC/DC Grids With VSC-MTDC Networks,"The paper considers the optimal power flow (OPF) of a meshed AC/DC power transmission network with voltage source converter based multi-terminal DC (VSC-MTDC) networks. The OPF problem is formulated to minimize the transmission loss of the whole AC/DC network with two different VSC control strategies considered, constant DC voltage control (master-slave control) and DC voltage droop control. In addition, Grid Code compliance of wind farms is also embedded in the OPF formulation. The presented OPF is evaluated and demonstrated in the paper by two example meshed AC/DC power systems.",
Stochastic Testing Method for Transistor-Level Uncertainty Quantification Based on Generalized Polynomial Chaos,"Uncertainties have become a major concern in integrated circuit design. In order to avoid the huge number of repeated simulations in conventional Monte Carlo flows, this paper presents an intrusive spectral simulator for statistical circuit analysis. Our simulator employs the recently developed generalized polynomial chaos expansion to perform uncertainty quantification of nonlinear transistor circuits with both Gaussian and non-Gaussian random parameters. We modify the nonintrusive stochastic collocation (SC) method and develop an intrusive variant called stochastic testing (ST) method. Compared with the popular intrusive stochastic Galerkin (SG) method, the coupled deterministic equations resulting from our proposed ST method can be solved in a decoupled manner at each time point. At the same time, ST requires fewer samples and allows more flexible time step size controls than directly using a nonintrusive SC solver. These two properties make ST more efficient than SG and than existing SC methods, and more suitable for time-domain circuit simulation. Simulation results of several digital, analog and RF circuits are reported. Since our algorithm is based on generic mathematical models, the proposed ST algorithm can be applied to many other engineering problems.",
Analysis of DC-Link Voltage Controls in Three-Phase Four-Wire Hybrid Active Power Filters,"This paper investigates different dc-link voltage control strategies in a three-phase four-wire LC coupling hybrid active power filter (LC -HAPF) for reactive power compensation. By using direct current (current reference) pulsewidth modulation (PWM) control method, to achieve dc-link voltage self-charging function during LC -HAPF start-up process, the dc-link voltage control signal feedback as reactive current component is more effective than the traditional method as an active current component. However, when the LC-HAPF is performing dynamic reactive power compensation, this dc-link voltage control scheme will influence the reactive power compensation, and thus, makes the LC-HAPF lack of success to carry out dynamic reactive power compensation. In this paper, a novel dc-link voltage control scheme for LC-HAPF is proposed so that the dc-link voltage control with start-up self-charging process can be obtained as well as providing dynamic reactive power compensation. Representative simulation and experimental results of the three-phase four-wire center-spilt LC-HAPF are presented to verify all deductions, and also show the effectiveness of the proposed dc-link voltage control scheme in dynamic reactive power compensation.","Reactive power,
Voltage control,
Active filters,
Power system dynamics,
Harmonic analysis,
Power harmonic filters"
Stochastic circuits for real-time image-processing applications,"Real-time image-processing applications impose severe design constraints in terms of area and power. Examples of interest include retinal implants for vision restoration and on-the-fly feature extraction. This work addresses the design of image-processing circuits using stochastic computing techniques. We show how stochastic circuits can be integrated at the pixel level with image sensors, thus supporting efficient real-time (pre)processing of images. We present the design of several representative circuits, which demonstrate that stochastic designs can be significantly smaller, faster, more power-efficient, and more noise-tolerant than conventional ones. Furthermore, the stochastic designs naturally produce images with progressive quality improvement.",
"Design, Modeling, and FPAA-Based Control of a High-Speed Atomic Force Microscope Nanopositioner","An XYZ nanopositioner is designed for fast the atomic force microscopy. The first resonant modes of the device are measured at 8.8, 8.9, and 48.4 kHz along the X-, Y-, and Z-axes, respectively, which are in close agreement to the finite-element simulations. The measured travel ranges of the lateral and vertical axes are 6.5 μm × 6.6 μm and 4.2 μm, respectively. Actuating the nanopositioner at frequencies beyond 1% of the first resonance of the lateral axes causes mechanical vibrations that result in degradation of the images generated. In order to improve the lateral scanning bandwidth, controllers are designed using the integral resonant control methodology to damp the resonant modes of the nanopositioner and to enable fast actuation. Due to the large bandwidth of the designed nanopositioner, a field programmable analog array is used for analog implementation of the controllers. High-resolution images are successfully generated at 200-Hz line rate with 200×200 pixel resolution in closed loop.","Nanopositioning,
Resonant frequency,
Actuators,
Force,
Bandwidth,
Mathematical model,
Atomic force microscopy"
eTime: Energy-efficient transmission between cloud and mobile devices,"Mobile cloud computing, promising to extend the capabilities of resource-constrained mobile devices, is emerging as a new computing paradigm which has fostered a wide range of exciting applications. In this new paradigm, efficient data transmission between the cloud and mobile devices becomes essential. This, however, is highly unreliable and unpredictable due to several uncontrollable factors, particularly the instability and intermittency of wireless connections, fluctuation of communication bandwidth, and user mobility. Consequently, this puts a heavy burden on the energy consumption of mobile devices. Confirmed by our experiments, significantly more energy is consumed during “bad” connectivity. Inspired by the feasibility to schedule data transmissions for prefetching-friendly or delay-tolerant applications, in this paper, we present eTime, a novel Energy-efficient data Transmission strategy between cloud and Mobile dEvices, based on Lyapunov optimization. It aggressively and adaptively seizes the timing of good connectivity to prefetch frequently used data while deferring delay-tolerant data in bad connectivity. To cope with the randomness and unpredictability of wireless connectivity, eTime only relies on the current status information to make a global energy-delay tradeoff decision. Our evaluations from both trace-driven simulation and realworld implementation show that eTime can be applied to various popular applications while achieving 20%-35% energy saving.","Bandwidth,
Energy consumption,
IEEE 802.11 Standards,
Smart phones,
Data communication,
Mobile communication"
Integrated Optimal Formation Control of Multiple Unmanned Aerial Vehicles,"In this paper, we investigate the formation control of multiple unmanned aerial vehicles (UAVs), specifically unmanned aircraft, in an obstacle-laden environment. The main contribution of this paper is to integrate the formation control, trajectory tracking, and obstacle/collision avoidance into one unified optimal control framework. A nonquadratic avoidance cost is innovatively constructed via an inverse optimal control approach, which leads to an analytical, distributed, and optimal formation control law. The stability and optimality of the closed-loop system are proven. In addition, the proposed optimal control law is dependent only on the information from the local neighbors, rather than all UAVs' information. Simulation of multiple UAVs' formation flying demonstrates the effectiveness of the integrated optimal control design with desired behaviors including formation flying, trajectory tracking, and obstacle/collision avoidance.",
The Resilience of WDM Networks to Probabilistic Geographical Failures,"Telecommunications networks, and in particular optical WDM networks, are vulnerable to large-scale failures in their physical infrastructure, resulting from physical attacks (such as an electromagnetic pulse attack) or natural disasters (such as solar flares, earthquakes, and floods). Such events happen at specific geographical locations and disrupt specific parts of the network, but their effects cannot be determined exactly in advance. Therefore, we provide a unified framework to model network vulnerability when the event has a probabilistic nature, defined by an arbitrary probability density function. Our framework captures scenarios with a number of simultaneous attacks, when network components consist of several dependent subcomponents, and in which either a 1+1 or a 1:1 protection plan is in place. We use computational geometric tools to provide efficient algorithms to identify vulnerable points within the network under various metrics. Then, we obtain numerical results for specific backbone networks, demonstrating the applicability of our algorithms to real-world scenarios. Our novel approach allows to identify locations that require additional protection efforts (e.g., equipment shielding). Overall, the paper demonstrates that using computational geometric techniques can significantly contribute to our understanding of network resilience.","Probabilistic logic,
Approximation algorithms,
Reliability,
Optical fiber networks,
Educational institutions,
Heuristic algorithms,
Compounds"
Cuffless Differential Blood Pressure Estimation Using Smart Phones,"Smart phones today have become increasingly popular with the general public for their diverse functionalities such as navigation, social networking, and multimedia facilities. These phones are equipped with high-end processors, high-resolution cameras, and built-in sensors such as accelerometer, orientation-sensor, and light-sensor. According to comScore survey, 26.2% of U.S. adults use smart phones in their daily lives. Motivated by this statistic and the diverse capability of smart phones, we focus on utilizing them for biomedical applications. We present a new application of the smart phone with its built-in camera and microphone replacing the traditional stethoscope and cuff-based measurement technique, to quantify vital signs such as heart rate and blood pressure. We propose two differential blood pressure estimating techniques using the heartbeat and pulse data. The first method uses two smart phones whereas the second method replaces one of the phones with a customized external microphone. We estimate the systolic and diastolic pressure in the two techniques by computing the pulse pressure and the stroke volume from the data recorded. By comparing the estimated blood pressure values with those measured using a commercial blood pressure meter, we obtained encouraging results of 95-100% accuracy.",
Low-Voltage Bulk-Driven Operational Amplifier With Improved Transconductance,This paper presents two low-voltage bulk-driven amplifier input stages with enhanced transconductance. The idea is to introduce auxiliary differential pairs into a conventional bulk-driven stage to boost its transconductance. A low-voltage cascode biasing circuitry based on EKV models is also employed to ensure proper operation of the proposed input stages. An operational amplifier is then implemented with the proposed input stages and biasing circuits as its core building blocks and including a modified low-voltage class AB output amplifier to guarantee rail-to-rail output voltage range. The overall amplifier was implemented in a 0.35 μm n-well CMOS process using 1-V power supply. The measurement results show significant improvement in the performance of the operational amplifier compared to prior arts.,"Transconductance,
Logic gates,
MOSFETs,
Noise,
Power supplies,
Threshold voltage"
Real-Time Multiple Sound Source Localization and Counting Using a Circular Microphone Array,"In this work, a multiple sound source localization and counting method is presented, that imposes relaxed sparsity constraints on the source signals. A uniform circular microphone array is used to overcome the ambiguities of linear arrays, however the underlying concepts (sparse component analysis and matching pursuit-based operation on the histogram of estimates) are applicable to any microphone array topology. Our method is based on detecting time-frequency (TF) zones where one source is dominant over the others. Using appropriately selected TF components in these “single-source” zones, the proposed method jointly estimates the number of active sources and their corresponding directions of arrival (DOAs) by applying a matching pursuit-based approach to the histogram of DOA estimates. The method is shown to have excellent performance for DOA estimation and source counting, and to be highly suitable for real-time applications due to its low complexity. Through simulations (in various signal-to-noise ratio conditions and reverberant environments) and real environment experiments, we indicate that our method outperforms other state-of-the-art DOA and source counting methods in terms of accuracy, while being significantly more efficient in terms of computational complexity.",
On the Outage Performance of Full-Duplex Selective Decode-and-Forward Relaying,"We evaluate the outage performance in a three-terminal full-duplex relay channel that adopts a selective decode-and-forward protocol, taking relay self-interference into account. Previous work focused on coverage extension scenarios where direct source-destination transmissions are neglected or considered as interference. In this work, we account for the relay self-interference, and exploit the cooperative diversity offered by the independently fading source/relay message replicas that arrive at the destination. We present an approximate, yet accurate, closed-form expression for the end-to-end outage probability that captures their joint effect. With the derived expression in hand, we propose a relay transmit power optimization scheme that only requires the relay knowledge of channel statistics. Finally, we corroborate our analysis with simulations.","Relays,
Interference,
Optimization,
Probability,
Decoding,
Switches,
Eigenvalues and eigenfunctions"
MIMO Wiretap Channels: Secure Transmission Using Transmit Antenna Selection and Receive Generalized Selection Combining,"We propose and analyze transmit antenna selection with receive generalized selection combining (TAS/GSC) for physical layer security enhancement in multiple-input multiple-output wiretap channels. In this protocol, a single antenna out of NA antennas is selected at the transmitter and LB antennas out of NB antennas are combined at the legitimate receiver. We characterize the physical layer secrecy of TAS/GSC via our new closed-form expressions for the exact and the asymptotic secrecy outage probability. We demonstrate that the maximum secrecy outage diversity gain of NA NB is achieved.","Transmitting antennas,
Receiving antennas,
Signal to noise ratio,
Niobium,
MIMO,
Diversity methods"
Naturalness Preserved Enhancement Algorithm for Non-Uniform Illumination Images,"Image enhancement plays an important role in image processing and analysis. Among various enhancement algorithms, Retinex-based algorithms can efficiently enhance details and have been widely adopted. Since Retinex-based algorithms regard illumination removal as a default preference and fail to limit the range of reflectance, the naturalness of non-uniform illumination images cannot be effectively preserved. However, naturalness is essential for image enhancement to achieve pleasing perceptual quality. In order to preserve naturalness while enhancing details, we propose an enhancement algorithm for non-uniform illumination images. In general, this paper makes the following three major contributions. First, a lightness-order-error measure is proposed to access naturalness preservation objectively. Second, a bright-pass filter is proposed to decompose an image into reflectance and illumination, which, respectively, determine the details and the naturalness of the image. Third, we propose a bi-log transformation, which is utilized to map the illumination to make a balance between details and naturalness. Experimental results demonstrate that the proposed algorithm can not only enhance the details but also preserve the naturalness for non-uniform illumination images.","reflectivity,
filtering theory,
image enhancement,
lighting"
Optimal Power Allocation for Hybrid Overlay/Underlay Spectrum Sharing in Multiband Cognitive Radio Networks,"In this paper, we consider power allocation in multiband cognitive radio (CR) networks, where multiple secondary users (SUs) transmit via a common relay and compete for the transmit power of the relay. We employ a hybrid overlay/underlay spectrum sharing scheme, allowing the SU to adapt its way of accessing the licensed spectrum to the status of the primary user (PU). If the PU is detected to be idle at the selected channel, the SU works in an overlay mode; else, it works in spectrum underlay. In addition, an auction-based power-allocation scheme is proposed to solve power competition of multiple SUs. For the SU working in spectrum overlay, the relay allocates the power in proportion to its payment without additional constraints; for the SU in spectrum underlay, its own transmit power and that of the relay are upper bounded for the quality of service (QoS) of the PU. Then, the convergence of the proposed auction algorithm and the outage probability of secondary transmissions is theoretically analyzed. Finally, the performance of the proposed scheme is verified by the simulation results.","Relays,
Resource management,
Games,
Hybrid power systems,
Sensors,
Interference,
Quality of service"
Multi-Attribute Partitioning of Power Networks Based on Electrical Distance,"Identifying coherent sub-graphs in networks is important in many applications. In power systems, large systems are divided into areas and zones to aid in planning and control applications. But not every partitioning is equally good for all applications; different applications have different goals, or attributes, against which solutions should be evaluated. This paper presents a hybrid method that combines a conventional graph partitioning algorithm with an evolutionary algorithm to partition a power network to optimize a multi-attribute objective function based on electrical distances, cluster sizes, the number of clusters, and cluster connectedness. Results for the IEEE RTS-96 show that clusters produced by this method can be used to identify buses with dynamically coherent voltage angles, without the need for dynamic simulation. Application of the method to the IEEE 118-bus and a 2383-bus case indicates that when a network is well partitioned into zones, intra-zone transactions have less impact on power flows outside of the zone; i.e., good partitioning reduces loop flows. This property is particularly useful for power system applications where ensuring deliverability is important, such as transmission planning or determination of synchronous reserve zones.","power transmission planning,
evolutionary computation,
graph theory,
IEEE standards,
load flow"
"Vibrotactile Display: Perception, Technology, and Applications","This paper reviews the technology and applications of vibrotactile display, an effective information transfer modality for the emerging area of haptic media. Our emphasis is on summarizing foundational knowledge in this area and providing implementation guidelines for application designers who do not yet have a background in haptics. Specifically, we explain the relevant human vibrotactile perceptual capabilities, detail the main types of commercial vibrotactile actuators, and describe how to build both monolithic and localized vibrotactile displays. We then identify exemplary vibrotactile display systems in application areas ranging from the presentation of physical object properties to broadcasting vibrotactile media content.","Haptic interfaces,
Vibrations,
Rendering (computer graphics),
Human factors"
Minimizing flow completion times in data centers,"For provisioning large-scale online applications such as web search, social networks and advertisement systems, data centers face extreme challenges in providing low latency for short flows (that result from end-user actions) and high throughput for background flows (that are needed to maintain data consistency and structure across massively distributed systems). We propose L2DCT, a practical data center transport protocol that targets a reduction in flow completion times for short flows by approximating the Least Attained Service (LAS) scheduling discipline, without requiring any changes in application software or router hardware, and without adversely affecting the long flows. L2DCT can co-exist with TCP and works by adapting flow rates to the extent of network congestion inferred via Explicit Congestion Notification (ECN) marking, a feature widely supported by the installed router base. Though L2DCT is deadline unaware, our results indicate that, for typical data center traffic patterns and deadlines and over a wide range of traffic load, its deadline miss rate is consistently smaller compared to existing deadline-driven data center transport protocols. L2DCT reduces the mean flow completion time by up to 50% over DCTCP and by up to 95% over TCP. In addition, it reduces the completion for 99th percentile flows by 37% over DCTCP. We present the design and analysis of L2DCT, evaluate its performance, and discuss an implementation built upon standard Linux protocol stack.","Throughput,
Transport protocols,
Bandwidth,
Oscillators,
Hardware,
Routing protocols"
LIONS: An AWGR-Based Low-Latency Optical Switch for High-Performance Computing and Data Centers,"This paper discusses the architecture of an arrayed waveguide grating router (AWGR)-based low-latency interconnect optical network switch called LIONS, and its different loopback buffering schemes. A proof of concept is demonstrated with a 4 × 4 experimental testbed. A simulator was developed to model the LIONS architecture and was validated by comparing experimentally obtained statistics such as average end-to-end latency with the results produced by the simulator. Considering the complexity and cost in implementing loopback buffers in LIONS, we propose an all-optical negative acknowledgement (AO-NACK) architecture in order to remove the need for loopback buffers. Simulation results for LIONS with AO-NACK architecture and distributed loopback buffer architecture are compared with the performance of the flattened butterfly electrical switching network.",
Rotation Invariant Localization of Duplicated Image Regions Based on Zernike Moments,"This paper proposes a forensic technique to localize duplicated image regions based on Zernike moments of small image blocks. We exploit rotation invariance properties to reliably unveil duplicated regions after arbitrary rotations. We devise a novel block matching procedure based on locality sensitive hashing and reduce false positives by examining the moments' phase. A massive experimental test setup benchmarks our algorithm against state-of-the-art methods under various perspectives, examining both pixel-level localization and image-level detection performance. By taking signal characteristics into account and distinguishing between “textured” and “smooth” duplicated regions, we find that the proposed method outperforms prior art in particular when duplicated regions are smooth. Experiments indicate high robustness against JPEG compression, blurring, additive white Gaussian noise, and moderate scaling.","Vectors,
Customer relationship management,
Feature extraction,
Robustness,
Detectors,
Forensics,
Digital images"
Multicriteria Optimal Sizing of Photovoltaic-Wind Turbine Grid Connected Systems,"Power generation systems (PGSs) based on hybrid renewable energy are one of the promising solutions for future distributed generation systems. Among different configurations, hybrid photovoltaic-wind turbine (PV-WT) grid connected PGSs are the most adopted for their good performance. However, due to the complexity of the system, the optimal balance between these two energy sources requires particular attention to achieve a good engineering solution. This paper deals with the optimal sizing of PV-WT by adopting different multicriteria decision analysis (MCDA) optimization approaches. Sensitivity of MCDA algorithms has been analyzed, by considering different weighting criteria techniques with different fluctuation scenarios of wind speed and solar radiation profiles, thus highlighting advantages and drawbacks of the proposed optimal sizing approaches. The following study could be assumed as a powerful roadmap for decision makers, analysts, and policy makers.",
Large-Scale Measurement and Characterization of Cellular Machine-to-Machine Traffic,"Cellular network-based machine-to-machine (M2M) communication is fast becoming a market-changing force for a wide spectrum of businesses and applications such as telematics, smart metering, point-of-sale terminals, and home security and automation systems. In this paper, we aim to answer the following important question: Does traffic generated by M2M devices impose new requirements and challenges for cellular network design and management? To answer this question, we take a first look at the characteristics of M2M traffic and compare it to traditional smartphone traffic. We have conducted our measurement analysis using a week-long traffic trace collected from a tier-1 cellular network in the US. We characterize M2M traffic from a wide range of perspectives, including temporal dynamics, device mobility, application usage, and network performance. Our experimental results show that M2M traffic exhibits significantly different patterns than smartphone traffic in multiple aspects. For instance, M2M devices have a much larger ratio of uplink-to-downlink traffic volume, their traffic typically exhibits different diurnal patterns, they are more likely to generate synchronized traffic resulting in bursty aggregate traffic volumes, and are less mobile compared to smartphones. On the other hand, we also find that M2M devices are generally competing with smartphones for network resources in co-located geographical regions. These and other findings suggest that better protocol design, more careful spectrum allocation, and modified pricing schemes may be needed to accommodate the rise of M2M devices.",
ConSub: Incentive-Based Content Subscribing in Selfish Opportunistic Mobile Networks,"Recently, content-based publish/subscribe (pub/sub) services have become a significant research field in opportunistic mobile networks (OppNets). Pub/sub is an asynchronous messaging paradigm, in which content transmissions are guided by the interest. Since selfish behavior is common in reality, nodes often behave selfishly with an aim to maximize their own utilities without considering performance of other nodes. Therefore, how to encourage nodes to collect, store and share network content efficiently is one of the key challenges under this paradigm. In this paper, we propose an incentive-based pub/sub scheme, called ConSub, for OppNets. In ConSub, Tit-For-Tat (TFT) mechanism is employed to deal with selfish behavior. ConSub also implements a content exchange protocol between two interacting node, thus encouraging them to play as businessmen and carry contents to satisfy each other's interest. Specifically, the exchange order is determined by the content utility, which is calculated by contact probability and cooperation level between the current node and its neighbors subscribing to the interest. Extensive realistic trace-driven simulation results show that ConSub is superior to existing schemes in terms of delivered packets and transmission hops with reasonable transmission cost.",
Cyberentity Security in the Internet of Things,"A proposed Internet of Things system architecture offers a solution to the broad array of challenges researchers face in terms of general system security, network security, and application security.","Computer security,
Sensors,
Internet of Things,
Computer architecture,
Privacy,
Wireless sensor networks"
Synchrophasor Estimators Accuracy: A Comparative Analysis,"The real-time high-accuracy measurement of waveform phasors is one of the many open challenges that need to be addressed in future smart grids. In this paper, the accuracy of four recently proposed synchrophasor estimators is analyzed and compared with the well-known one-cycle discrete Fourier transform estimator under the effect of static frequency offsets, amplitude modulation, phase modulation, harmonic distortion, and wideband noise. Two of the considered techniques track the phasor variations through finite-difference equations that estimate the first- and second-order derivatives of the phasor itself. The other two methods are instead based on a least squares estimation of the coefficients of the phasor Taylor's series expansion. The analysis reported in this paper covers the main scenarios described in the Standard IEEE C37.118.1-2011. In particular, the influence of different signal parameters on the total vector error (TVE) values is quantified and used to determine the maximum TVE increments associated with distinct parameters and the corresponding upper bounds.",
A Survey of Multi-Agent Trust Management Systems,"In open and dynamic multiagent systems (MASs), agents often need to rely on resources or services provided by other agents to accomplish their goals. During this process, agents are exposed to the risk of being exploited by others. These risks, if not mitigated, can cause serious breakdowns in the operation of MASs and threaten their long-term wellbeing. To protect agents from the uncertainty in the behavior of their interaction partners, the age-old mechanism of trust between human beings is re-contexted into MASs. The basic idea is to let agents self-police the MAS by rating each other on the basis of their observed behavior and basing future interaction decisions on such information. Over the past decade, a large number of trust management models were proposed. However, there is a lack of research effort in several key areas, which are critical to the success of trust management in MASs where human beings and agents coexist. The purpose of this paper is to give an overview of existing research in trust management in MASs. We analyze existing trust models from a game theoretic perspective to highlight the special implications of including human beings in an MAS, and propose a possible research agenda to advance the state of the art in this field.","Game theory,
Decision making,
Uncertainty,
Analytical models,
Context awareness,
Multi-agent systems,
Computational modeling,
Trust management"
Coordinated Control of a DG and Voltage Control Devices Using a Dynamic Programming Algorithm,"This paper presents a new control method, in which a distributed generator (DG) actively participates in steady-state voltage control, together with an under-load tap changer (ULTC) and shunt capacitors (Sh.Cs). In the conventional DG control method, the integration of DGs into a distribution power system increases the number of switching operations of the ULTC and the Sh.Cs. To solve this problem, this paper proposes that the DG output voltage be dispatched cooperatively with the operation of the ULTC and the Sh.Cs, based on load forecasts for one day in advance. The objective of the proposed method is to decrease the number of switching device operations, as well as to reduce the power loss in the distribution lines, while maintaining the grid voltage within the allowed range. The proposed method is designed and implemented with Matlab, using two different dynamic programming algorithms for a dispatchable and a nondispatchable DG, respectively. Simulation studies demonstrate that the objective can be achieved under various grid conditions, determined by factors such as the DG output power characteristics, the location of the DG-connected bus on the feeder, and the load profile of the feeder containing the DG.","Voltage control,
Reactive power,
Switches,
Heuristic algorithms,
Power generation,
Capacitors"
Practical Secure Communication for Integrating Wireless Sensor Networks Into the Internet of Things,"If a wireless sensor network (WSN) is integrated into the Internet as a part of the Internet of things (IoT), there will appear new security challenges, such as setup of a secure channel between a sensor node and an Internet host. In this paper, we propose a heterogeneous online and offline signcryption scheme to secure communication between a sensor node and an Internet host. We prove that this scheme is indistinguishable against adaptive chosen ciphertext attacks under the bilinear Diffie-Hellman inversion problem and existential unforgeability against adaptive chosen messages attacks under the q-strong Diffie-Hellman problem in the random oracle model. Our scheme has the following advantages. First, it achieves confidentiality, integrity, authentication, and non-repudiation in a logical single step. Second, it allows a sensor node in an identity-based cryptography to send a message to an Internet host in a public key infrastructure. Third, it splits the signcryption into two phases: i) offline phase; and ii) online phase. In the offline phase, most heavy computations are done without the knowledge of a message. In the online phase, only light computations are done when a message is available. Our scheme is very suitable to provide security solution for integrating WSN into the IoT.","wireless sensor networks,
Internet of Things,
public key cryptography,
telecommunication security"
A 94 GHz mm-Wave-to-Baseband Pulsed-Radar Transceiver with Applications in Imaging and Gesture Recognition,"High-resolution mm-wave array beamformers have applications in medical imaging, gesture recognition, and navigation. A scalable array architecture for 3D imaging is proposed in which single-element phase coherent transceiver (TRX) chips, with programmable TX pulse delay capability, are mounted on a common board to realize the array. This paper presents the design of the enabling TRX chip: a highly integrated 94 GHz phase-coherent pulsed-radar with on-chip antennas. The TRX achieves 10 GHz of frequency tuning range and 300 ps of contiguous pulse position control, enabling its usage in the large-array imager with time-domain TX beamforming. The TRX is capable of transmitting and receiving pulses down to 36 ps, translating to 30 GHz of bandwidth. Interferometric measurements show the TRX can obtain single-target range resolution better than 375 μm (limited by equipment). Based on delay measurements, the time of arrival rms error would be less than 1.3 ps which, if used in a 3D imaging array, leads to less than 0.36 mm of RMS error in voxel size and position.","Arrays,
Mixers,
Delays,
Transceivers,
Biomedical imaging,
Phase locked loops"
Learning deep physiological models of affect,"More than 15 years after the early studies in Affective Computing (AC), [1] the problem of detecting and modeling emotions in the context of human-computer interaction (HCI) remains complex and largely unexplored. The detection and modeling of emotion is, primarily, the study and use of artificial intelligence (AI) techniques for the construction of computational models of emotion. The key challenges one faces when attempting to model emotion [2] are inherent in the vague definitions and fuzzy boundaries of emotion, and in the modeling methodology followed. In this context, open research questions are still present in all key components of the modeling process. These include, first, the appropriateness of the modeling tool employed to map emotional manifestations and responses to annotated affective states; second, the processing of signals that express these manifestations (i.e., model input); and third, the way affective annotation (i.e., model output) is handled. This paper touches upon all three key components of an affective model (i.e., input, model, output) and introduces the use of deep learning (DL) [3], [4], [5] methodologies for affective modeling from multiple physiological signals.","Affective computing,
Physiology,
Emotion recognition,
Context modeling,
Artificial intelligence,
Human computer interaction"
Compression Artifact Reduction by Overlapped-Block Transform Coefficient Estimation With Block Similarity,"Block transform coded images usually suffer from annoying artifacts at low bit rates, caused by the coarse quantization of transform coefficients. In this paper, we propose a new method to reduce compression artifacts by the overlapped-block transform coefficient estimation from non-local blocks. In the proposed method, the discrete cosine transform coefficients of each block are estimated by adaptively fusing two prediction values based on their reliabilities. One prediction is the quantized values of coefficients decoded from the compressed bitstream, whose reliability is determined by quantization steps. The other prediction is the weighted average of the coefficients in nonlocal blocks, whose reliability depends on the variance of the coefficients in these blocks. The weights are used to distinguish the effectiveness of the coefficients in nonlocal blocks to predict original coefficients and are determined by block similarity in transform domain. To solve the optimization problem, the overlapped blocks are divided into several subsets. Each subset contains nonoverlapped blocks covering the whole image and is optimized independently. Therefore, the overall optimization is reduced to a set of sub-optimization problems, which can be easily solved. Finally, we provide a strategy for parameter selection based on the compression levels. Experimental results show that the proposed method can remarkably reduce compression artifacts and significantly improve both the subjective and objective qualities of block transform coded images.","Image coding,
Quantization (signal),
Noise,
Discrete cosine transforms,
Predictive models,
Transform coding"
Boundary Control of a Flexible Riser With the Application to Marine Installation,"This paper investigates the control problem of a marine riser installation system. The riser installation system consisting of a vessel, a flexible riser, and a subsea payload is modeled as a distributed parameter system with one partial differential equation and four ordinary differential equations. Based on Lyapunov's direct method, adaptive boundary control is proposed at the top and bottom boundaries of the riser to position the subsea payload to the desired set point and suppress the riser's vibration. With the proposed control, uniform boundedness of the steady-state error between the boundary payload and the desired position is achieved by suitably choosing the design parameters. Numerical simulations are presented for demonstrating the effectiveness of the proposed control.","Payloads,
Oceans,
Lyapunov methods,
Stability analysis,
Control design,
Boundary conditions,
Vibrations"
Feature-Based Image Patch Approximation for Lung Tissue Classification,"In this paper, we propose a new classification method for five categories of lung tissues in high-resolution computed tomography (HRCT) images, with feature-based image patch approximation. We design two new feature descriptors for higher feature descriptiveness, namely the rotation-invariant Gabor-local binary patterns (RGLBP) texture descriptor and multi-coordinate histogram of oriented gradients (MCHOG) gradient descriptor. Together with intensity features, each image patch is then labeled based on its feature approximation from reference image patches. And a new patch-adaptive sparse approximation (PASA) method is designed with the following main components: minimum discrepancy criteria for sparse-based classification, patch-specific adaptation for discriminative approximation, and feature-space weighting for distance computation. The patch-wise labelings are then accumulated as probabilistic estimations for region-level classification. The proposed method is evaluated on a publicly available ILD database, showing encouraging performance improvements over the state-of-the-arts.","Feature extraction,
Lungs,
Approximation methods,
Histograms,
Labeling,
Dictionaries,
Imaging"
4-Gbps Uncompressed Video Transmission over a 60-GHz Orbital Angular Momentum Wireless Channel,We demonstrate successful transmission of 4-Gbps uncompressed video over a 60-GHz orbital angular momentum (OAM) wireless channel. Matlab simulation was employed to support the experimental work and to generate the holographic masks used. Matlab coding is a unique approach which can produce any desired shape on copper or dielectric plates by mean of a commercial routing tool. We believe this is the first reported transmission of 4-Gbps uncompressed video over the 60-GHz OAM wireless channel. Good agreement was achieved between the simulated and measured results. Practical opportunities for multi-gigabit future wireless communications are available.,"Wireless communication,
Diffraction,
Spirals,
Extraterrestrial measurements,
Optimized production technology,
MATLAB,
Radio transmitters"
IVTURS: A Linguistic Fuzzy Rule-Based Classification System Based On a New Interval-Valued Fuzzy Reasoning Method With Tuning and Rule Selection,"Interval-valued fuzzy sets have been shown to be a useful tool to deal with the ignorance related to the definition of the linguistic labels. Specifically, they have been successfully applied to solve classification problems, performing simple modifications on the fuzzy reasoning method to work with this representation and making the classification based on a single number. In this paper, we present IVTURS, which is a new linguistic fuzzy rule-based classification method based on a new completely interval-valued fuzzy reasoning method. This inference process uses interval-valued restricted equivalence functions to increase the relevance of the rules in which the equivalence of the interval membership degrees of the patterns and the ideal membership degrees is greater, which is a desirable behavior. Furthermore, their parametrized construction allows the computation of the optimal function for each variable to be performed, which could involve a potential improvement in the system's behavior. Additionally, we combine this tuning of the equivalence with rule selection in order to decrease the complexity of the system. In this paper, we name our method IVTURS-FARC, since we use the FARC-HD method to accomplish the fuzzy rule learning process. The experimental study is developed in three steps in order to ascertain the quality of our new proposal. First, we determine both the essential role that interval-valued fuzzy sets play in the method and the need for the rule selection process. Next, we show the improvements achieved by IVTURS-FARC with respect to the tuning of the degree of ignorance when it is applied in both an isolated way and when combined with the tuning of the equivalence. Finally, the significance of IVTURS-FARC is further depicted by means of a comparison by which it is proved to outperform the results of FARC-HD and FURIA, which are two high performing fuzzy classification algorithms.","Pragmatics,
Tuning,
Fuzzy reasoning,
Fuzzy sets,
Proposals,
Accuracy,
Genetics"
Stabilization of Networked Multi-Input Systems With Channel Resource Allocation,"In this paper, we study the problem of state feedback stabilization of a linear time-invariant (LTI) discrete-time multi-input system with imperfect input channels. Each input channel is modeled in three different ways. First it is modeled as an ideal transmission system together with an additive norm bounded uncertainty, introducing a multiplicative uncertainty to the plant. Then it is modeled as an ideal transmission system together with a feedback norm bounded uncertainty, introducing a relative uncertainty to the plant. Finally it is modeled as an additive white Gaussian noise channel. For each of these models, we properly define the capacity of each channel whose sum yields the total capacity of all input channels. We aim at finding the least total channel capacity for stabilization. Different from the single-input case that is available in the literature and boils down to a typical H∞ or H2 optimal control problem, the multi-input case involves allocation of the total capacity among the input channels in addition to the design of the feedback controller. The overall process of channel resource allocation and the controller design can be considered as a case of channel-controller co-design which gives rise to modified nonconvex optimization problems. Surprisingly, the modified nonconvex optimization problems, though appear more complicated, can be solved analytically. The main results of this paper can be summarized into a universal theorem: The state feedback stabilization can be accomplished by the channel-controller co-design, if and only if the total input channel capacity is greater than the topological entropy of the open-loop system.","Channel models,
Uncertainty,
Channel capacity,
State feedback,
Quantization,
Entropy,
Signal to noise ratio"
Interconnected dynamic systems: An overview on distributed control,"Control problems such as multirobot control, distributed intelligence, swarm intelligence, distributed decision, distributed cognition, congestion control in networks, collective motion in biology, oscillator synchronization in physics, parallelization in optimization theory, distributed estimation, cooperative estimation, equilibria in economics, social interaction modeling, and game theory may be analyzed under the theory of interconnected dynamic systems. Those topics have several overlapping research communities; for that reason they are characterized by different definitions and a variety of approaches ranging from rigorous mathematical analysis to trial-and-error experimental study or emulation by observation of natural phenomena. The areas involved concern robotics, dynamic systems, computer science, signal theory, biology, economics, and mathematics. A shared taxonomy is missing; for example, dynamic systems can be identified in robots, agents, nodes, processors, and entities. An ensemble is called a group, network, platoon, swarm, team, and cluster, and the algorithms are defined as controllers, protocols, and dynamics. In the following, the term agent is used to denote the single dynamic system and network or collective the ensemble.","Laplace equations,
Eigenvalues and eigenfunctions,
Computer architecture,
Vectors,
Aerodynamics,
Heuristic algorithms,
Graph theory,
Decentralized control"
Decentralized Coordination of Energy Utilization for Residential Households in the Smart Grid,"In this paper, we investigate the minimization of the total energy cost of multiple residential households in a smart grid neighborhood sharing a load serving entity. Specifically, each household may have renewable generation, energy storage as well as inelastic and elastic energy loads, and the load serving entity attempts to coordinate the energy consumption of these households in order to minimize the total energy cost within this neighborhood. The renewable generation, the energy demand arrival, and the energy cost function are all stochastic processes and evolve according to some, possibly unknown, probabilistic laws. We develop an online control algorithm, called Lyapunov-based cost minimization algorithm (LCMA), which jointly considers the energy management and demand management decisions. LCMA only needs to keep track of the current values of the underlying stochastic processes without requiring any knowledge of their statistics. Moreover, a decentralized algorithm to implement LCMA is also developed, which can preserve the privacy of individual household owners. Numerical results based on real-world trace data show that our control algorithm can effectively reduce the total energy cost in the neighborhood.",
On-Device Mobile Visual Location Recognition by Integrating Vision and Inertial Sensors,"This paper deals with the problem of city scale on-device mobile visual location recognition by fusing the inertial sensors and computer vision techniques. The main contributions are as follows: Firstly, we design an efficient vector quantization strategy by combining the Transform Coding (TC) and Residual Vector Quantization (RVQ). Our method can compress a visual descriptor into only several bytes while providing reasonable searching accuracy, which makes the managing of city scale image database directly on mobile devices come true. Secondly, we integrate the information from inertial sensors into the Vector of Locally Aggregated Descriptors (VLAD) generation and image similarity evaluation processes. Our method is not only fast enough for on-device implementation, but it also can improve the location recognition accuracy obviously. Thirdly, we also release a set of 1.295 million geo-tagged street view images with the information from inertial sensors, as well as a difficult set of query images. These resources can be used as a new benchmark to facilitate further research in the area. Experimental results prove the validity of the proposed methods for on-device mobile visual location recognition applications.","visual databases,
computer vision,
geographic information systems,
image coding,
image recognition,
image retrieval,
inertial systems,
mobile computing,
transform coding,
vector quantisation"
Optimization of Distribution Network Incorporating Distributed Generators: An Integrated Approach,"Previous studies of distributed power and network focused only on the optimization of either the microgrid load dispatch or reconfiguration power loss. Micorgrid economic load dispatch approach normally does not support distribution network. Network reconfiguration usually does not take distributed generators into consideration. Thus, it is necessary to integrate these two sub-problems together in order to benefit the whole network. In this paper, an integrated solution that takes care of both microgrid load dispatch and network reconfiguration is proposed. The stochastic nature of wind, PV and load is taken into consideration. The forecasting of the wind, PV and load data are considered. The four bio-inspired optimization schemes are adopted to solve the problem. The results obtained have shown that the four optimization techniques are all capable of solving this problem. By using the integrated approach, microgrid can be incorporated into the network more effectively. The network can adjust itself more efficiently to allow utilization of the renewable energy resources.","wind power plants,
distributed power generation,
distribution networks,
load forecasting,
optimisation,
photovoltaic power systems,
power generation dispatch,
power generation economics"
Empirical Evaluation and New Design for Fighting Evolving Twitter Spammers,"To date, as one of the most popular online social networks (OSNs), Twitter is paying its dues as more and more spammers set their sights on this microblogging site. Twitter spammers can achieve their malicious goals such as sending spam, spreading malware, hosting botnet command and control (C&C) channels, and launching other underground illicit activities. Due to the significance and indispensability of detecting and suspending those spam accounts, many researchers along with the engineers at Twitter Inc. have devoted themselves to keeping Twitter as spam-free online communities. Most of the existing studies utilize machine learning techniques to detect Twitter spammers. “While the priest climbs a post, the devil climbs ten.” Twitter spammers are evolving to evade existing detection features. In this paper, we first make a comprehensive and empirical analysis of the evasion tactics utilized by Twitter spammers. We further design several new detection features to detect more Twitter spammers. In addition, to deeply understand the effectiveness and difficulties of using machine learning features to detect spammers, we analyze the robustness of 24 detection features that are commonly utilized in the literature as well as our proposed ones. Through our experiments, we show that our new designed features are much more effective to be used to detect (even evasive) Twitter spammers. According to our evaluation, while keeping an even lower false positive rate, the detection rate using our new feature set is also significantly higher than that of existing work. To the best of our knowledge, this work is the first empirical study and evaluation of the effect of evasion tactics utilized by Twitter spammers and is a valuable supplement to this line of research.","Twitter,
Feature extraction,
Robustness,
Semantics,
Detectors,
Crawlers"
Sum Rate Analysis of ZF Receivers in Distributed MIMO Systems,"The performance of single-cell distributed multiple-input multiple-output (D-MIMO) systems is not only affected by small-scale Rayleigh fading but also from large-scale fading and path-loss. In this paper, we elaborate on the sum rate of D-MIMO systems employing linear zero-forcing receivers, accounting for both large and small-scale fading effects, as well as spatial correlation at the transmit side. In particular, we consider the classical lognormal model and propose closed-form upper and lower bounds on the achievable sum rate. Using these bounds as a starting point, we pursue a ""large-system"" analysis and provide asymptotic expressions when the number of antennas at the base station (BS) grow large, and when the number of antennas at both ends grow large with a fixed and finite ratio. A detailed characterization in the asymptotically high and low signal to noise ratio regimes is also provided. An interesting observation from our results is that in order to maximize the sum rate, the RPs should be placed at unequal distances to the BS when they experience the same level of shadowing. The resulting closed-form expressions are compared with the corresponding results on MIMO optimal receivers.","MIMO,
Receivers,
Signal to noise ratio,
Shadow mapping,
Correlation,
Rayleigh channels"
PMSM sliding mode FPGA-based control for torque ripple reduction,"This paper presents a torque ripple reduction approach to the direct torque control of a permanent magnet synchronous motor, using a sliding mode control technique. A distinctive feature of this approach is that, by appropriately parameterizing and implementing the sliding mode controller, the discontinuous nature of the voltage source inverter may be directly incorporated into the design process. The key idea is to incorporate the benefits of the variable structure systems control design and the event-driven sequential control structures in order to raise the system's performance and control efficiency. A predictive sliding-mode controller has been developed, designed as finite-state automata, and implemented using a field-programmable gate array (FPGA). This new FPGA logic regarding torque and speed control has been developed, analyzed, and experimentally verified.","Vectors,
Switches,
Stators,
Inverters,
Torque,
Field programmable gate arrays"
Physical Layer Security in Cellular Networks: A Stochastic Geometry Approach,"This paper studies the information-theoretic secrecy performance in large-scale cellular networks based on a stochastic geometry framework. The locations of both base stations and mobile users are modeled as independent two-dimensional Poisson point processes. We consider two important features of cellular networks, namely, information exchange between base stations and cell association, to characterize their impact on the achievable secrecy rate of an arbitrary downlink transmission with a certain portion of the mobile users acting as potential eavesdroppers. In particular, tractable results are presented under diverse assumptions on the availability of eavesdroppers' location information at the serving base station, which captures the benefit from the exchange of the location information between base stations.","telecommunication security,
cellular radio,
geometry,
radio links,
stochastic processes"
Gallager B Decoder on Noisy Hardware,"Conventional communications theory assumes that the data transmission is noisy but the processing at the receiver is entirely error-free. Such assumptions may have to be revisited for advanced (silicon) technologies in which hardware failures are a major concern at the system-level. Hence, it is important to characterize the performance of a communication system with both noisy processing components and noisy data transmission. Coding systems based on low-density parity check (LDPC) codes are widely used for a variety of applications. In this paper, we focus on probabilistic analysis of the LDPC Gallager B decoder built out of faulty components. Using the density evolution technique, we find approximations for the optimal threshold of the decoder and the symbol error rate (SER) of the decoded sequence as functions of both the channel error rate and error rates of the decoder components, for both binary and non-binary regular LDPC codes. Furthermore, we study the convergence of the output SER and the decoding threshold of the decoder for different ranges of error rates. We verify our results using MATLAB simulations and hardware emulation of noisy decoders. Results presented in this paper can serve as systematic design guidelines in resource allocation for noisy decoders. Informed resource allocation is of particular relevance to emerging data storage and processing applications that need to maintain high levels of reliability despite hardware errors in advanced technologies.","Decoding,
Noise measurement,
Hardware,
Logic gates,
Iterative decoding,
Reliability"
Privacy preserving cloud data access with multi-authorities,"Cloud computing is a revolutionary computing paradigm which enables flexible, on-demand and low-cost usage of computing resources. Those advantages, ironically, are the causes of security and privacy problems, which emerge because the data owned by different users are stored in some cloud servers instead of under their own control. To deal with security problems, various schemes based on the Attribute-Based Encryption have been proposed recently. However, the privacy problem of cloud computing is yet to be solved. This paper presents an anonymous privilege control scheme AnonyControl to address not only the data privacy problem in a cloud storage, but also the user identity privacy issues in existing access control schemes. By using multiple authorities in cloud computing system, our proposed scheme achieves anonymous cloud data access and fine-grained privilege control. Our security proof and performance analysis shows that AnonyControl is both secure and efficient for cloud computing environment.","Encryption,
Servers,
Gold,
Cloud computing,
Public key,
Generators"
Decentralized Stochastic Control with Partial History Sharing: A Common Information Approach,"A general model of decentralized stochastic control called partial history sharing information structure is presented. In this model, at each step the controllers share part of their observation and control history with each other. This general model subsumes several existing models of information sharing as special cases. Based on the information commonly known to all the controllers, the decentralized problem is reformulated as an equivalent centralized problem from the perspective of a coordinator. The coordinator knows the common information and selects prescriptions that map each controller's local information to its control actions. The optimal control problem at the coordinator is shown to be a partially observable Markov decision process (POMDP) which is solved using techniques from Markov decision theory. This approach provides 1) structural results for optimal strategies and 2) a dynamic program for obtaining optimal strategies for all controllers in the original decentralized problem. Thus, this approach unifies the various ad-hoc approaches taken in the literature. In addition, the structural results on optimal control strategies obtained by the proposed approach cannot be obtained by the existing generic approach (the person-by-person approach) for obtaining structural results in decentralized problems; and the dynamic program obtained by the proposed approach is simpler than that obtained by the existing generic approach (the designer's approach) for obtaining dynamic programs in decentralized problems.","History,
Optimal control,
Dynamic programming,
Vectors,
Markov processes,
Protocols"
On reconfiguration-oriented approximate adder design and its application,"Approximate circuit designs allow us to tradeoff computation quality (e.g., accuracy) and computational effort (e.g., energy), by exploiting the inherent error-resilience of many applications. As the computation quality requirement of an application generally varies at runtime, it is preferable to be able to reconfigure approximate circuits to satisfy such needs and save unnecessary computational effort. In this paper, we present a reconfiguration-oriented design methodology for approximate circuits, and propose a reconfigurable approximate adder design that degrades computation quality gracefully. The proposed design methodology enables us to achieve better quality-effort tradeoff when compared to existing techniques, as demonstrated in the application of DCT computing.","Adders,
Accuracy,
Delays,
Discrete cosine transforms,
Hardware,
Erbium,
Vectors"
Radiation Effects in Flash Memories,"We review ionizing radiation effects in Flash memories, the current dominant technology in the commercial non-volatile memory market. A comprehensive discussion of total dose and single event effects results is presented, concerning both floating gate cells and peripheral circuitry. The latest developments, including new findings on the mechanism underlying upsets due to heavy ions and destructive events, are illustrated.","Logic gates,
Threshold voltage,
Flash memories,
Radiation effects,
Nonvolatile memory,
Programming,
Arrays"
Array Designs for Long-Distance Wireless Power Transmission: State-of-the-Art and Innovative Solutions,"The concept of long-range wireless power transmission (WPT) has been formulated shortly after the invention of high power microwave amplifiers. The promise of WPT, energy transfer over large distances without the need to deploy a wired electrical network, led to the development of landmark successful experiments, and provided the incentive for further research to increase the performances, efficiency, and robustness of these technological solutions. In this framework, the key-role and challenges in designing transmitting and receiving antenna arrays able to guarantee high-efficiency power transfer and cost-effective deployment for the WPT system has been soon acknowledged. Nevertheless, owing to its intrinsic complexity, the design of WPT arrays is still an open research field whose importance is growing as the possibility to transfer energy by means of electromagnetic waves gathers more and more interest from the applicative viewpoint. This paper is aimed at reviewing the array design approaches proposed in the state of the art for long-range wireless power transmission, highlighting the latest advances and innovative solutions as well as envisaging possible future trends of the research in this area.","Array antennas,
Wireless communication,
Radio frequency,
Power transmission,
Antenna arrays,
Receiving antennas,
Satellites"
A Survey on Mobility and Mobility-Aware MAC Protocols in Wireless Sensor Networks,"In wireless sensor networks nodes can be static or mobile, depending on the application requirements. Dealing with mobility can pose some formidable challenges in protocol design, particularly, at the link layer. These difficulties require mobility adaptation algorithms to localize mobile nodes and predict the quality of link that can be established with them. This paper surveys the current state-of-art in handling mobility. It first describes existing mobility models and patterns; and analyzes the challenges caused by mobility at the link layer. It then provides a comparative study of several mobility-aware MAC protocols.",
Sparse tensor discriminant analysis,"The classical linear discriminant analysis has undergone great development and has recently been extended to different cases. In this paper, a novel discriminant subspace learning method called sparse tensor discriminant analysis (STDA) is proposed, which further extends the recently presented multilinear discriminant analysis to a sparse case. Through introducing the L1 and L2 norms into the objective function of STDA, we can obtain multiple interrelated sparse discriminant subspaces for feature extraction. As there are no closed-form solutions, k-mode optimization technique and the L1 norm sparse regression are combined to iteratively learn the optimal sparse discriminant subspace along different modes of the tensors. Moreover, each non-zero element in each subspace is selected from the most important variables/factors, and thus STDA has the potential to perform better than other discriminant subspace methods. Extensive experiments on face databases (Yale, FERET, and CMU PIE face databases) and the Weizmann action database show that the proposed STDA algorithm demonstrates the most competitive performance against the compared tensor-based methods, particularly in small sample sizes.","tensors,
feature extraction,
iterative methods,
learning (artificial intelligence),
optimisation,
regression analysis"
Cloud-based robot grasping with the google object recognition engine,"Rapidly expanding internet resources and wireless networking have potential to liberate robots and automation systems from limited onboard computation, memory, and software. “Cloud Robotics” describes an approach that recognizes the wide availability of networking and incorporates open-source elements to greatly extend earlier concepts of “Online Robots” and “Networked Robots”. In this paper we consider how cloud-based data and computation can facilitate 3D robot grasping. We present a system architecture, implemented prototype, and initial experimental data for a cloud-based robot grasping system that incorporates a Willow Garage PR2 robot with onboard color and depth cameras, Google's proprietary object recognition engine, the Point Cloud Library (PCL) for pose estimation, Columbia University's GraspIt! toolkit and OpenRAVE for 3D grasping and our prior approach to sampling-based grasp analysis to address uncertainty in pose. We report data from experiments in recognition (a recall rate of 80% for the objects in our test set), pose estimation (failure rate under 14%), and grasping (failure rate under 23%) and initial results on recall and false positives in larger data sets using confidence measures.","Robots,
Object recognition,
Three-dimensional displays,
Servers,
Training,
Estimation,
Google"
Joint Base Station Association and Power Control via Benders' Decomposition,"Heterogeneous cellular network (Hetnets), where various classes of low power base stations (BS) are underlaid in a macro-cellular network, is a promising technique for future green communications. These new types of BSs can achieve substantial improvement in spectrum-efficiency and energy-efficiency via cell splitting. However, mobile stations perceive different channel gains to different base stations. Therefore, it is important to associate a mobile station with the right BS so as to achieve a good communication quality. Oftentimes, the already-challenging BS association problem is further complicated by the need of transmission power control, which is an essential component to manage co-channel interference in many wireless communications systems. Despite its importance, the joint BS association and power control (JBAPC) problem has remained largely unsolved, mainly due to its non-convex and combinatorial nature that makes the global optimal solution difficult to obtain. This paper aims to circumvent this difficulty by proposing a novel algorithm based on Benders' Decomposition to solve the non-convex JBAPC problem efficiently and optimally. In particular, we endeavor to maximize the system revenue and meanwhile associate every served mobile station with the right BS with the minimum total transmission power. We first propose a single-stage formulation that captures the two objectives simultaneously. The problem is then transformed in a way that can be efficiently solved using the proposed joint BS Association and poweR coNtrol algorithm (referred to as BARN) that is derived from classical Benders' Decomposition. Finally, we derive a closed-form analytical formula to characterize the effect of the termination criterion of the algorithm on the gap between the obtained solution and the optimal one. For practical implementation, we further propose an Accelerated BARN (A-BARN) algorithm that can significantly reduce the computational time. By carefully choosing the termination criterion, both BARN and A-BARN are guaranteed to converge to the global optimal solution.","Power control,
Base stations,
Optimization,
Interference,
Joints,
Mobile communication,
Algorithm design and analysis"
A Cluster-Based Differential Evolution Algorithm With External Archive for Optimization in Dynamic Environments,"This paper presents a Cluster-based Dynamic Differential Evolution with external Ar chive (CDDE_Ar) for global optimization in dynamic fitness landscape. The algorithm uses a multipopulation method where the entire population is partitioned into several clusters according to the spatial locations of the trial solutions. The clusters are evolved separately using a standard differential evolution algorithm. The number of clusters is an adaptive parameter, and its value is updated after a certain number of iterations. Accordingly, the total population is redistributed into a new number of clusters. In this way, a certain sharing of information occurs periodically during the optimization process. The performance of CDDE_Ar is compared with six state-of-the-art dynamic optimizers over the moving peaks benchmark problems and dynamic optimization problem (DOP) benchmarks generated with the generalized-dynamic-benchmark-generator system for the competition and special session on dynamic optimization held under the 2009 IEEE Congress on Evolutionary Computation. Experimental results indicate that CDDE_Ar can enjoy a statistically superior performance on a wide range of DOPs in comparison to some of the best known dynamic evolutionary optimizers.","Heuristic algorithms,
Clustering algorithms,
Sociology,
Statistics,
Vectors,
Optimization,
Partitioning algorithms"
"Joint Beamforming and Power Control in Coordinated Multicell: Max-Min Duality, Effective Network and Large System Transition","This paper studies joint beamforming and power control in a coordinated multicell downlink system that serves multiple users per cell to maximize the minimum weighted signal-to-interference-plus-noise ratio. The optimal solution and distributed algorithm with geometrically fast convergence rate are derived by employing the nonlinear Perron-Frobenius theory and the multicell network duality. The iterative algorithm, though operating in a distributed manner, still requires instantaneous power update within the coordinated cluster through the backhaul. The backhaul information exchange and message passing may become prohibitive with increasing number of transmit antennas and increasing number of users. In order to derive asymptotically optimal solution, random matrix theory is leveraged to design a distributed algorithm that only requires statistical information. The advantage of our approach is that there is no instantaneous power update through backhaul. Moreover, by using nonlinear Perron-Frobenius theory and random matrix theory, an effective primal network and an effective dual network are proposed to characterize and interpret the asymptotic solution.",
A Step Towards Developing Adaptive Robot-Mediated Intervention Architecture (ARIA) for Children With Autism,"Emerging technology, especially robotic technology, has been shown to be appealing to children with autism spectrum disorders (ASD). Such interest may be leveraged to provide repeatable, accurate and individualized intervention services to young children with ASD based on quantitative metrics. However, existing robot-mediated systems tend to have limited adaptive capability that may impact individualization. Our current work seeks to bridge this gap by developing an adaptive and individualized robot-mediated technology for children with ASD. The system is composed of a humanoid robot with its vision augmented by a network of cameras for real-time head tracking using a distributed architecture. Based on the cues from the child's head movement, the robot intelligently adapts itself in an individualized manner to generate prompts and reinforcements with potential to promote skills in the ASD core deficit area of early social orienting. The system was validated for feasibility, accuracy, and performance. Results from a pilot usability study involving six children with ASD and a control group of six typically developing (TD) children are presented.","Cameras,
Variable speed drives,
Humans,
Robot kinematics,
Robot vision systems,
Joints"
Robust map optimization using dynamic covariance scaling,"Developing the perfect SLAM front-end that produces graphs which are free of outliers is generally impossible due to perceptual aliasing. Therefore, optimization back-ends need to be able to deal with outliers resulting from an imperfect front-end. In this paper, we introduce dynamic covariance scaling, a novel approach for effective optimization of constraint networks under the presence of outliers. The key idea is to use a robust function that generalizes classical gating and dynamically rejects outliers without compromising convergence speed. We implemented and thoroughly evaluated our method on publicly available datasets. Compared to recently published state-of-the-art methods, we obtain a substantial speed up without increasing the number of variables in the optimization process. Our method can be easily integrated in almost any SLAM back-end.",
Soft-Switching DC/DC Converter With a Full ZVS Range and Reduced Output Filter for High-Voltage Applications,"A new soft-switching dc/dc converter, which can solve the drawbacks of existing phase-shifted full-bridge converters such as narrow zero-voltage-switching (ZVS) range, large circulating current, large duty-cycle loss, and a large output filter in high-voltage applications, is proposed in this paper. The proposed converter is composed of two symmetric half-bridge inverters that are placed in parallel on the primary side and are driven in a phase-shifting manner to regulate the output voltage. At the rectifier stage, two full-bridge rectifiers sharing two low-current-rating diodes are employed. This structure allows the proposed converter to have the advantages of a full ZVS range, no problems related to duty-cycle loss, no circulating current, and a significantly reduced output filter. In this paper, the circuit configuration, operation principle, and relevant analysis results of the proposed converters are presented. Experimental results on a prototype converter realized with the specification of 80-in plasma display panel sustain power module (320-385 Vdc input, 205 Vdc/5 A output) validate the theoretical analysis.","Zero voltage switching,
Inductors,
Rectifiers,
Stress,
Inductance,
Switches,
MOSFETs"
Deblurring and Sparse Unmixing for Hyperspectral Images,"The main aim of this paper is to study total variation (TV) regularization in deblurring and sparse unmixing of hyperspectral images. In the model, we also incorporate blurring operators for dealing with blurring effects, particularly blurring operators for hyperspectral imaging whose point spread functions are generally system dependent and formed from axial optical aberrations in the acquisition system. An alternating direction method is developed to solve the resulting optimization problem efficiently. According to the structure of the TV regularization and sparse unmixing in the model, the convergence of the alternating direction method can be guaranteed. Experimental results are reported to demonstrate the effectiveness of the TV and sparsity model and the efficiency of the proposed numerical scheme, and the method is compared to the recent Sparse Unmixing via variable Splitting Augmented Lagrangian and TV method by Iordache et al.","TV,
Hyperspectral imaging,
Matrix decomposition,
Optimization,
Numerical models,
Convergence"
A Survey on Multiobjective Evolutionary Algorithms for the Solution of the Portfolio Optimization Problem and Other Finance and Economics Applications,"The coinciding development of multiobjective evolutionary algorithms (MOEAs) and the emergence of complex problem formulation in the finance and economics areas has led to a mutual interest from both research communities. Since the 1990s, an increasing number of works have thus proposed the application of MOEAs to solve complex financial and economic problems, involving multiple objectives. This paper provides a survey on the state-of-the-art of research, reported in the specialized literature to date, related to this framework. The taxonomy chosen here makes a distinction between the (widely covered) portfolio optimization problem and the other applications in the field. In addition, potential paths for future research within this area are identified.","Optimization,
Evolutionary computation,
Economics,
Portfolios,
Biological system modeling,
Mathematical model,
Communities"
Environmental Monitoring Systems: A Review,"This review article discusses various techniques of environmental monitoring (EM) systems and what is required for the variations in hardware implementation and/or algorithmic logic. This review presents an overview of the existing state-of-the-art practices of environmental monitoring systems and is mainly focused on energy-efficient and low-cost environment monitoring systems. The following are some of the major factors that usually rule the development of EM systems, namely, energy efficiency, cost of the overall system, response time of the sensor module, good accuracy of the system, adequate signal-to-noise ratio, radio frequency interference/electromagnetic interference (RFI/EMI) rejection during varying atmospheric conditions and in inhomogeneous environments, a user friendly interface with the computer, and complexity of computation. The above concerns are also recognized by reference to research articles on environmental monitoring systems. Emphasis is on the necessity of robust systems that address all or most of the above mentioned criteria.","Electrodes,
Transducers,
Gas detectors,
Resistance"
Stability Analysis of Discrete-Time Systems With Quantized Feedback and Measurements,"This paper considers a quantized system with finite-level quantized input computed from quantized measurements (QIQM). The problem of globally asymptotic stability of QIQM system is transferred to the one of an equivalent system depending on a multiplier which is nonnegative and bounded. It is the focus of this paper to discuss the nonnegativity and boundness of the multiplier. A sufficient condition is given for the globally asymptotic stability of QIQM system. Note the main method used here is similar to the one used by Richter and Misawa, in which the uniform quantizer is employed. This paper is the extension of that work to the logarithmic quantization which is more advantage than the uniform one. A numerical simulation is presented at last to show the effectiveness of the main results and the advantage of logarithmic quantization compared to uniform quantization.",
Deformable Graph Matching,"Graph matching (GM) is a fundamental problem in computer science, and it has been successfully applied to many problems in computer vision. Although widely used, existing GM algorithms cannot incorporate global consistence among nodes, which is a natural constraint in computer vision problems. This paper proposes deformable graph matching (DGM), an extension of GM for matching graphs subject to global rigid and non-rigid geometric constraints. The key idea of this work is a new factorization of the pair-wise affinity matrix. This factorization decouples the affinity matrix into the local structure of each graph and the pair-wise affinity edges. Besides the ability to incorporate global geometric transformations, this factorization offers three more benefits. First, there is no need to compute the costly (in space and time) pair-wise affinity matrix. Second, it provides a unified view of many GM methods and extends the standard iterative closest point algorithm. Third, it allows to use the path-following optimization algorithm that leads to improved optimization strategies and matching performance. Experimental results on synthetic and real databases illustrate how DGM outperforms state-of-the-art algorithms for GM. The code is available at http://humansensing.cs.cmu.edu/fgm.","Iterative closest point algorithm,
Optimization,
Transmission line matrix methods,
Computer vision,
Approximation algorithms,
Linear programming,
Vectors"
Graph-Based Multi-Surface Segmentation of OCT Data Using Trained Hard and Soft Constraints,"Optical coherence tomography (OCT) is a well-established image modality in ophthalmology and used daily in the clinic. Automatic evaluation of such datasets requires an accurate segmentation of the retinal cell layers. However, due to the naturally low signal to noise ratio and the resulting bad image quality, this task remains challenging. We propose an automatic graph-based multi-surface segmentation algorithm that internally uses soft constraints to add prior information from a learned model. This improves the accuracy of the segmentation and increase the robustness to noise. Furthermore, we show that the graph size can be greatly reduced by applying a smart segmentation scheme. This allows the segmentation to be computed in seconds instead of minutes, without deteriorating the segmentation accuracy, making it ideal for a clinical setup. An extensive evaluation on 20 OCT datasets of healthy eyes was performed and showed a mean unsigned segmentation error of 3.05 ± 0.54 μm over all datasets when compared to the average observer, which is lower than the inter-observer variability. Similar performance was measured for the task of drusen segmentation, demonstrating the usefulness of using soft constraints as a tool to deal with pathologies.","Image segmentation,
Silicon,
Retina,
Computational modeling,
Pathology,
Training,
Biomedical imaging"
Propagation models for IEEE 802.15.6 standardization of implant communication in body area networks,"A body area network is a radio communication protocol for short-range, low-power, and highly reliable wireless communication for use on the surface, inside, or in the peripheral proximity of the human body. Combined with various biomedical sensors, BANs enable realtime collection and monitoring of physiological signals. Therefore, it is regarded as an important technology for the treatment and prevention of chronic diseases, and health monitoring of the elderly. The IEEE 802 LAN/MAN Standards Committee approved Task Group TG15.6 in December 2007. As a result of more than four years of effort, in February 2012, TG15.6 published the first international standard for BANs, IEEE Std 802.15.6. Throughout the development of this standard, ample collaboration between the standardization group and the research community was required. In particular, understanding the radio propagation mechanisms for BANs demanded the most research effort. Technical challenges were magnified for the case of implant communication because of the impossibility of conducting in-body measurements with human subjects. Therefore, research in this field had to make use of intricate computer simulations. This article outlines some of the research that has been done to obtain accurate propagation models supporting the standardization of implant communication in BANs. Current research to enhance the channel models of IEEE Std 802.15.6 through the use of ultra wideband signals for implantable devices along with physical measurements in animals is also presented.","Body area networks,
Solid modeling,
Biological system modeling,
IEEE 802.15 Standards,
Channel models,
Radio communication,
Protocols"
Fast visual odometry and mapping from RGB-D data,"An RGB-D camera is a sensor which outputs color and depth and information about the scene it observes. In this paper, we present a real-time visual odometry and mapping system for RGB-D cameras. The system runs at frequencies of 30Hz and higher in a single thread on a desktop CPU with no GPU acceleration required. We recover the unconstrained 6-DoF trajectory of a moving camera by aligning sparse features observed in the current RGB-D image against a model of previous features. The model is persistent and dynamically updated from new observations using a Kalman Filter. We formulate a novel uncertainty measure for sparse RGD-B features based on a Gaussian mixture model for the filtering stage. Our registration algorithm is capable of closing small-scale loops in indoor environments online without any additional SLAM back-end techniques.","Uncertainty,
Cameras,
Trajectory,
Data models,
Iterative closest point algorithm,
Visualization,
Robot vision systems"
Robot self-assembly by folding: A printed inchworm robot,"Printing and folding are fast and inexpensive methods for prototyping complex machines. Self-assembly of the folding step would expand the possibilities of this method to include applications where external manipulation is costly, such as micro-assembly, mass production, and space applications. This paper presents a method for self-folding of printed robots from two-dimensional materials based on shape memory polymers actuated by joule heating using embedded circuits. This method was shown to be capable of sequential folding, angle-controlled folds, slot-and-tab assembly, and mountain and valley folds. An inchworm robot was designed to demonstrate the merits of this technique. Upon the application of sufficient current, the robot was able to fold into its functional form with fold angle deviations within six degrees. This printed robot demonstrated locomotion at a speed of two millimeters per second.","Robots,
Polymers,
Heating,
Laser modes"
"Contingency Ranking With Respect to Overloads in Very Large Power Systems Taking Into Account Uncertainty, Preventive, and Corrective Actions","This paper deals with day-ahead security management with respect to a postulated set of contingencies, while taking into account uncertainties about the next day generation/load scenario. In order to help the system operator in decision making under uncertainty, we aim at ranking these contingencies into four clusters according to the type of control actions needed to cover the worst uncertainty pattern of each contingency with respect to branch overload. To this end we use a fixed point algorithm that loops over two main modules: a discrete bi-level program (BLV) that computes the worst-case scenario, and a special kind of security constrained optimal power flow (SCOPF) which computes optimal preventive/corrective actions to cover the worst-case. We rely on a DC grid model, as the large number of binary variables, the large size of the problem, and the stringent computational requirements preclude the use of existing mixed integer nonlinear programming (MINLP) solvers. Consequently we solve the SCOPF using a mixed integer linear programming (MILP) solver while the BLV is decomposed into a series of MILPs. We provide numerical results with our approach on a very large European system model with 9241 buses and 5126 contingencies.","power system security,
integer programming,
linear programming,
load flow,
power system management"
SCPL: Indoor device-free multi-subject counting and localization using radio signal strength,"Radio frequency based device-free passive (DfP) localization techniques have shown great potentials in localizing individual human subjects, without requiring them to carry any radio devices. In this study, we extend the DfP technique to count and localize multiple subjects in indoor environments. To address the impact of multipath on indoor radio signals, we adopt a fingerprinting based approach to infer subject locations from observed signal strengths through profiling the environment. When multiple subjects are present, our objective is to use the profiling data collected by a single subject to count and localize multiple subjects without any extra effort. In order to address the non-linearity of the impact of multiple subjects, we propose a successive cancellation based algorithm to iteratively determine the number of subjects. We model indoor human trajectories as a state transition process, exploit indoor human mobility constraints and integrate all information into a conditional random field (CRF) to simultaneously localize multiple subjects. As a result, we call the proposed algorithm SCPL - sequential counting, parallel localizing. We test SCPL with two different indoor settings, one with size 150 m2 and the other 400 m2. In each setting, we have four different subjects, walking around in the deployed areas, sometimes with overlapping trajectories. Through extensive experimental results, we show that SCPL can count the present subjects with 86% counting percentage when their trajectories are not completely overlapping. Our localization algorithms are also highly accurate, with an average localization error distance of 1.3 m.","Vectors,
Training data,
Trajectory,
Radio link,
Correlation,
Training,
Testing"
Coalitional Graph Games for Popular Content Distribution in Cognitive Radio VANETs,"Popular content distribution is one of the key services provided by vehicular ad hoc networks (VANETs), in which a popular file is broadcast by roadside units (RSUs) to the onboard units (OBUs) driving through a particular area. Due to fast speeds and deep fading, some file packets might be lost during the vehicle-to-roadside (V2R) broadcasting stage. In this paper, we propose a peer-to-peer (P2P) approach to allow the OBUs to exchange data and complement the missing packets. Specifically, we introduce a coalitional graph game to model the cooperation among OBUs and propose a coalition formation algorithm to implement the P2P approach. Moreover, cognitive radio (CR) is utilized for vehicle-to-vehicle (V2V) transmissions so that the P2P approach does not require additional bandwidth. Simulation results show that the proposed approach performs better under various conditions, relative to the noncooperative approach, in which the OBUs share no information and simply respond to any data request from other OBUs.","Games,
Heuristic algorithms,
Peer to peer computing,
Silicon,
Vehicles,
Protocols,
Cognitive radio"
Unsupervised Speech Activity Detection Using Voicing Measures and Perceptual Spectral Flux,"Effective speech activity detection (SAD) is a necessary first step for robust speech applications. In this letter, we propose a robust and unsupervised SAD solution that leverages four different speech voicing measures combined with a perceptual spectral flux feature, for audio-based surveillance and monitoring applications. Effectiveness of the proposed technique is evaluated and compared against several commonly adopted unsupervised SAD methods under simulated and actual harsh acoustic conditions with varying distortion levels. Experimental results indicate that the proposed SAD scheme is highly effective and provides superior and consistent performance across various noise types and distortion levels.","Speech,
Correlation,
Feature extraction,
Robustness,
Noise,
Noise measurement,
Hidden Markov models"
Ambient RF Energy Harvesting Sensor Device With Capacitor-Leakage-Aware Duty Cycle Control,"In this paper, we present a software control method that maximizes the sensing rate of wireless sensor networks (WSNs) that are solely powered by ambient RF power. Unlike all other energy harvesting WSN systems, RF-powered systems present new challenges for energy management. A WSN node repeatedly charges and discharges at short intervals, depending on the energy intake. Typically in energy harvesting systems, a capacitor is used for energy storage because of its efficient charge and discharge performance and infinite recharge cycles. When the charging time is too short, a node is more likely to experience an energy shortage. On the contrary, if it is too long, more energy is lost because of leakage in the capacitor. In this paper, we introduce an adaptive duty cycle control scheme optimized for RF energy harvesting. This method maximizes the sensing rate by taking into account the leakage problem, a factor that has never been previously studied in this context. Our control scheme improves the efficiency by aggregate evaluation of operation reliability and leakage reduction.","wireless sensor networks,
adaptive control,
energy harvesting,
reliability"
Adaptive Traffic Signal Control With Vehicular Ad hoc Networks,"In this paper, we propose to use vehicular ad hoc networks (VANETs) to collect and aggregate real-time speed and position information on individual vehicles to optimize signal control at traffic intersections. We first formulate the vehicular traffic signal control problem as a job scheduling problem on processors, with jobs corresponding to platoons of vehicles. Under the assumption that all jobs are of equal size, we give an online algorithm, referred to as the oldest job first (OJF) algorithm, to minimize the delay across the intersection. We prove that the OJF algorithm is 2-competitive, implying that the delay is less than or equal to twice the delay of an optimal offline schedule with perfect knowledge of the arrivals. We then show how a VANET can be used to group vehicles into approximately equal-sized platoons, which can then be scheduled using OJF. We call this the two-phase approach, where we first group the vehicular traffic into platoons and then apply the OJF algorithm, i.e., the oldest arrival first (OAF) algorithm. Our simulation results show that, under light and medium traffic loads, the OAF algorithm reduces the delays experienced by vehicles as they pass through the intersection, as compared with vehicle-actuated methods, Webster's method, and pretimed signal control methods. Under heavy vehicular traffic load, the OAF algorithm performs the same as the vehicle-actuated traffic method but still produces lower delays, as when compared with Webster's method and the pretimed signal control method.","Vehicles,
Vehicular ad hoc networks,
Schedules,
Scheduling,
Delay,
Scheduling algorithms"
Fast Acquisition and Reconstruction of Optical Coherence Tomography Images via Sparse Representation,"In this paper, we present a novel technique, based on compressive sensing principles, for reconstruction and enhancement of multi-dimensional image data. Our method is a major improvement and generalization of the multi-scale sparsity based tomographic denoising (MSBTD) algorithm we recently introduced for reducing speckle noise. Our new technique exhibits several advantages over MSBTD, including its capability to simultaneously reduce noise and interpolate missing data. Unlike MSBTD, our new method does not require an a priori high-quality image from the target imaging subject and thus offers the potential to shorten clinical imaging sessions. This novel image restoration method, which we termed sparsity based simultaneous denoising and interpolation (SBSDI), utilizes sparse representation dictionaries constructed from previously collected datasets. We tested the SBSDI algorithm on retinal spectral domain optical coherence tomography images captured in the clinic. Experiments showed that the SBSDI algorithm qualitatively and quantitatively outperforms other state-of-the-art methods.","Dictionaries,
Interpolation,
Image reconstruction,
Noise reduction,
Image resolution,
Training,
Tomography"
Reducing Features to Improve Code Change-Based Bug Prediction,"Machine learning classifiers have recently emerged as a way to predict the introduction of bugs in changes made to source code files. The classifier is first trained on software history, and then used to predict if an impending change causes a bug. Drawbacks of existing classifier-based bug prediction techniques are insufficient performance for practical use and slow prediction times due to a large number of machine learned features. This paper investigates multiple feature selection techniques that are generally applicable to classification-based bug prediction methods. The techniques discard less important features until optimal classification performance is reached. The total number of features used for training is substantially reduced, often to less than 10 percent of the original. The performance of Naive Bayes and Support Vector Machine (SVM) classifiers when using this technique is characterized on 11 software projects. Naive Bayes using feature selection provides significant improvement in buggy F-measure (21 percent improvement) over prior change classification bug prediction results (by the second and fourth authors [28]). The SVM's improvement in buggy F-measure is 9 percent. Interestingly, an analysis of performance for varying numbers of features shows that strong performance is achieved at even 1 percent of the original number of features.","Software,
Support vector machines,
History,
Machine learning,
Feature extraction,
Measurement,
Computer bugs"
Coordinated Beamforming for Multiuser MISO Interference Channel Under Rate Outage Constraints,"This paper studies the coordinated beamforming design problem for the multiple-input single-output (MISO) interference channel, assuming only channel distribution information (CDI) known to the transmitters. Under a given requirement on the rate outage probability for receivers, we aim to maximize the system utility (e.g., the weighted sum rate, weighted geometric mean rate, and the weighed harmonic mean rate) subject to the rate outage constraints and individual power constraints. The outage constraints, however, lead to a complicated, nonconvex structure for the considered beamforming design problem and render the optimization problem difficult to handle. Although this nonconvex optimization problem can be solved in an exhaustive search manner, this brute-force approach is only feasible when the number of transmitter-receiver pairs is small. For a system with a large number of transmitter-receiver pairs, computationally efficient alternatives are necessary. Hence, the focus of this paper is the design of such efficient approximation methods. In particular, by employing semidefinite relaxation (SDR) and first-order approximation techniques, we propose an efficient successive convex approximation (SCA) algorithm that provides high-quality approximate beamforming solutions via solving a sequence of convex approximation problems. The solution thus obtained is further shown to be a stationary point for the SDR of the original outage constrained beamforming design problem. Furthermore, we propose a distributed SCA algorithm where each transmitter optimizes its own beamformer using local CDI and information obtained from limited message exchange with the other transmitters. Our simulation results demonstrate that the proposed SCA algorithm and its distributed counterpart indeed converge, and promising performance can be achieved for all the considered system utilities.","Array signal processing,
Transmitters,
Signal processing algorithms,
Receivers,
Approximation methods,
Algorithm design and analysis,
Interference"
Petri Net-Based Optimal One-Wafer Scheduling of Single-Arm Multi-Cluster Tools in Semiconductor Manufacturing,"In operating a multi-cluster tool, it needs to coordinate the activities of multiple robots. Thus, it is very challenging to schedule it. This paper conducts a study on one-wafer cyclic scheduling for multi-cluster tools whose bottleneck cluster tool is process-bound. The system is modeled by a Petri net. With this model, conditions under which a one-wafer cyclic schedule exists are developed. Based on them, it is shown that, for any multi-cluster tool whose bottleneck cluster tool is process-bound, there is always a one-wafer cyclic schedule. Then, a method is presented to find the minimal cycle time and the optimal one-wafer cyclic schedule. It is computationally efficient. Illustrative examples are used to show the applications and effectiveness of the proposed method.","Scheduling,
Semiconductor device modeling,
Petri nets,
Semiconductor device manufacture,
Robots"
Spatial-Temporal Discriminant Analysis for ERP-Based Brain-Computer Interface,"Linear discriminant analysis (LDA) has been widely adopted to classify event-related potential (ERP) in brain-computer interface (BCI). Good classification performance of the ERP-based BCI usually requires sufficient data recordings for effective training of the LDA classifier, and hence a long system calibration time which however may depress the system practicability and cause the users resistance to the BCI system. In this study, we introduce a spatial-temporal discriminant analysis (STDA) to ERP classification. As a multiway extension of the LDA, the STDA method tries to maximize the discriminant information between target and nontarget classes through finding two projection matrices from spatial and temporal dimensions collaboratively, which reduces effectively the feature dimensionality in the discriminant analysis, and hence decreases significantly the number of required training samples. The proposed STDA method was validated with dataset II of the BCI Competition III and dataset recorded from our own experiments, and compared to the state-of-the-art algorithms for ERP classification. Online experiments were additionally implemented for the validation. The superior classification performance in using few training samples shows that the STDA is effective to reduce the system calibration time and improve the classification accuracy, thereby enhancing the practicability of ERP-based BCI.",
Multiobjective Binary Biogeography Based Optimization for Feature Selection Using Gene Expression Data,"Gene expression data play an important role in the development of efficient cancer diagnoses and classification. However, gene expression data are usually redundant and noisy, and only a subset of them present distinct profiles for different classes of samples. Thus, selecting high discriminative genes from gene expression data has become increasingly interesting in the field of bioinformatics. In this paper, a multi-objective biogeography based optimization method is proposed to select the small subset of informative gene relevant to the classification. In the proposed algorithm, firstly, the Fisher-Markov selector is used to choose the 60 top gene expression data. Secondly, to make biogeography based optimization suitable for the discrete problem, binary biogeography based optimization, as called BBBO, is proposed based on a binary migration model and a binary mutation model. Then, multi-objective binary biogeography based optimization, as we called MOBBBO, is proposed by integrating the non-dominated sorting method and the crowding distance method into the BBBO framework. Finally, the MOBBBO method is used for gene selection, and support vector machine is used as the classifier with the leave-one-out cross-validation method (LOOCV). In order to show the effective and efficiency of the algorithm, the proposed algorithm is tested on ten gene expression dataset benchmarks. Experimental results demonstrate that the proposed method is better or at least comparable with previous particle swarm optimization (PSO) algorithm and support vector machine (SVM) from literature when considering the quality of the solutions obtained.","Gene expression,
Optimization,
Support vector machines,
Algorithm design and analysis,
Classification algorithms,
Biogeography"
"A novel hybrid approach using wavelet, firefly algorithm, and fuzzy ARTMAP for day-ahead electricity price forecasting","This paper presents a novel hybrid intelligent algorithm utilizing a data filtering technique based on wavelet transform (WT), an optimization technique based on firefly (FF) algorithm, and a soft computing model based on fuzzy ARTMAP (FA) network in order to forecast day-ahead electricity prices in the Ontario market. A comprehensive comparative analysis with other soft computing and hybrid models shows a significant improvement in forecast error by more than 40% for daily and weekly price forecasts, through the application of a proposed hybrid WT+FF+FA model. Furthermore, low values obtained for the forecast mean square error (FMSE) and mean absolute error (MAE) indicate high degree of accuracy of the proposed model. Robustness of the proposed hybrid intelligent model is measured by using the statistical index (error variance). In addition, the good forecast performance and the rapid adaptability of the proposed hybrid WT+FF+FA model are also evaluated using the PJM market data.","Forecasting,
Wavelet transforms,
Optimization,
Computational modeling,
Multiresolution analysis,
Hidden Markov models"
Multimodal Optimization Using a Biobjective Differential Evolution Algorithm Enhanced With Mean Distance-Based Selection,"In contrast to the numerous research works that integrate a niching scheme with an existing single-objective evolutionary algorithm to perform multimodal optimization, a few approaches have recently been taken to recast multimodal optimization as a multiobjective optimization problem to be solved by modified multiobjective evolutionary algorithms. Following this promising avenue of research, we propose a novel biobjective formulation of the multimodal optimization problem and use differential evolution (DE) with nondominated sorting followed by hypervolume measure-based sorting to finally detect a set of solutions corresponding to multiple global and local optima of the function under test. Unlike the two earlier multiobjective approaches (biobjective multipopulation genetic algorithm and niching-based nondominated sorting genetic algorithm II), the proposed multimodal optimization with biobjective DE (MOBiDE) algorithm does not require the actual or estimated gradient of the multimodal function to form its second objective. Performance of MOBiDE is compared with eight state-of-the-art single-objective niching algorithms and two recently developed biobjective niching algorithms using a test suite of 14 basic and 15 composite multimodal problems. Experimental results supported by nonparametric statistical tests suggest that MOBiDE is able to provide better and more consistent performance over the existing well-known multimodal algorithms for majority of the test problems without incurring any serious computational burden.","Sociology,
Statistics,
Optimization,
Sorting,
Measurement,
Vectors,
Linear programming"
High-Voltage (600-V) Low-Leakage Low-Current-Collapse AlGaN/GaN HEMTs with AlN/SiNx Passivation,"An effective passivation technique that yields low off-state leakage and low current collapse simultaneously in high-voltage (600-V) AlGaN/GaN high-electron-mobility transistors (HEMTs) is reported in this letter. The passivation structure consists of an AlN/SiNx stack with 4-nm AlN deposited by plasma-enhanced atomic layer deposition and 50-nm SiNx deposited by PECVD. The AlN/ SiNx-passivated HEMTs with a gate-drain distance of 15 μm exhibit a high maximum drain current of 900 mA/mm, a low off-state current of 0.7 μA/mm at VDS = 600 V, and a steep subthreshold slope of 63 mV/dec. Compared with the static on-resistance of 1.3 mΩ·cm2, the dynamic on-resistance after high off-state drain bias stress at 650 V only increases to 2.1 mΩ·cm2. A high breakdown voltage of 632 V is achieved at a drain leakage current of 1 μA/mm .","HEMTs,
MODFETs,
Gallium nitride,
Aluminum gallium nitride,
Logic gates,
Passivation,
Stress"
Neural Network-Based Optimal Adaptive Output Feedback Control of a Helicopter UAV,"Helicopter unmanned aerial vehicles (UAVs) are widely used for both military and civilian operations. Because the helicopter UAVs are underactuated nonlinear mechanical systems, high-performance controller design for them presents a challenge. This paper introduces an optimal controller design via an output feedback for trajectory tracking of a helicopter UAV, using a neural network (NN). The output-feedback control system utilizes the backstepping methodology, employing kinematic and dynamic controllers and an NN observer. The online approximator-based dynamic controller learns the infinite-horizon Hamilton-Jacobi-Bellman equation in continuous time and calculates the corresponding optimal control input by minimizing a cost function, forward-in-time, without using the value and policy iterations. Optimal tracking is accomplished by using a single NN utilized for the cost function approximation. The overall closed-loop system stability is demonstrated using Lyapunov analysis. Finally, simulation results are provided to demonstrate the effectiveness of the proposed control design for trajectory tracking.","trajectory control,
adaptive control,
autonomous aerial vehicles,
closed loop systems,
continuous time systems,
control system synthesis,
feedback,
helicopters,
Lyapunov methods,
neurocontrollers,
nonlinear systems,
observers,
optimal control,
stability"
Mobile data gathering with Wireless Energy Replenishment in rechargeable sensor networks,"The emerging wireless energy transfer technology enables charging sensor batteries in a wireless sensor network (WSN) and maintaining perpetual operation of the network. Recent breakthrough in this area has opened up a new dimension to the design of sensor network protocols. In the meanwhile, mobile data gathering has been considered as an efficient alternative to data relaying in WSNs. However, time variation of recharging rates in wireless rechargeable sensor networks imposes a great challenge in obtaining an optimal data gathering strategy. In this paper, we propose a framework of joint Wireless Energy Replenishment and anchor-point based Mobile Data Gathering (WerMDG) in WSNs by considering various sources of energy consumption and time-varying nature of energy replenishment. To that end, we first determine the anchor point selection and the sequence to visit the anchor points. We then formulate the WerMDG problem into a network utility maximization problem which is constrained by flow conversation, energy balance, link and battery capacity and the bounded sojourn time of the mobile collector. Furthermore, we present a distributed algorithm composed of cross-layer data control, scheduling and routing subalgorithms for each sensor node, and sojourn time allocation subalgorithm for the mobile collector at different anchor points. Finally, we give extensive numerical results to verify the convergence of the proposed algorithm and the impact of utility weight on network performance.","Wireless sensor networks,
Batteries,
Mobile communication,
Optimization,
Robot sensing systems,
Wireless communication,
Distributed databases"
SciDB: A Database Management System for Applications with Complex Analytics,"A description and discussion of the SciDB database management system focuses on lessons learned, application areas, performance comparisons against other solutions, and additional approaches to managing data and complex analytics.","Arrays,
Data models,
Parallel processing,
File systems,
Database languages,
Analytical models,
Large Hadron Collider"
Mitigating Range Ambiguities in High-PRF SAR With OFDM Waveform Diversity,"Range-ambiguity suppression is a technical challenge for high-pulse-repetition-frequency (PRF) synthetic aperture radar (SAR). This letter proposes a practical approach to mitigate the range ambiguities in high-PRF SAR by using the orthogonal frequency-division multiplexing (OFDM) waveform diversity. The system scheme, waveform design, and range-ambiguity-to-signal-ratio performance are detailed. The approach eliminates the ambiguities, instead of just suppressing them like other techniques. The proposed OFDM chirp diverse waveform has a large time–bandwidth product. It is validated by computer-simulation results. Although OFDM radar has received much attention in recent years, there appears to be little work done in applying OFDM concepts to mitigate high-PRF radar range ambiguities, as is the subject of this letter.","OFDM,
Chirp,
Remote sensing,
Spaceborne radar,
Correlation,
Radar imaging"
DuRT: Dual RSSI Trend Based Localization for Wireless Sensor Networks,"Localization is a key issue in wireless sensor networks. The geographical location of sensors is important information that is required in sensor network operations such as target detection, monitoring, and rescue. These methods are classified into two categories, namely range-based and range-free. Range-based localizations achieve high location accuracy by using specific hardware or using absolute received signal strength indicator (RSSI) values, whereas range-free approaches obtain location estimates with lower accuracy. Because of the hardware and energy constraints in sensor networks, RSSI offers a convenient method to find the position of sensor nodes. However, in the presence of channel noise, fading, and attenuation, it is not possible to estimate the actual location. In this paper, we propose an RSSI-based localization scheme that considers the trend of RSSI values obtained from beacons to estimate the position of sensor nodes. Through applying polynomial modeling on the relationship between received RSSI and distance, we are able to locate the maximum RSSI point on the anchor trajectory. Using two such trajectories, the sensor position can be determined by calculating the intersection point of perpendiculars passing through the maximum RSSI point on each trajectory. In addition, we devised schemes to improve the localization method to perform under a variety of cases such as single trajectory, unavailability of RSSI trends, and so. The advantage of our scheme is that it does not rely on absolute RSSI values and hence, can be applied in dynamic environments. In simulations, we demonstrate that the proposed localization scheme achieves higher location accuracy compared with existing localization approaches.","wireless sensor networks,
direction-of-arrival estimation,
fading channels,
polynomials,
sensor placement"
SATS: Secure Average-Consensus-Based Time Synchronization in Wireless Sensor Networks,"It is important and challenging to achieve secure time synchronization in wireless sensor networks, which may be deployed in a hostile environment under various malicious attacks. The recently developed average-consensus-based time synchronization protocol (ATS) is a promising alternative as it does not depend on any reference node or network topology, which makes it robust to different kinds of attacks, e.g., denial-of-service, node destruction, etc. However, the in-network information fusion nature of average consensus makes the ATS vulnerable to the well-known message manipulation attacks. In this paper, we focus on how to defend the ATS protocol in wireless sensor networks under message manipulation attacks. We first investigate the impact of message manipulation attacks over ATS, and derive a necessary condition for ATS to converge. Then based on the obtained insights, we propose a novel adjusting parameter checking mechanism which exploits the two-hop neighboring information to dynamically constrain the attackers. We further incorporate all checking processes into the traditional ATS protocol to form a secure average-consensus-based time synchronization protocol (SATS). We prove that SATS guarantees the network time synchronization with an exponentially converging speed.","Synchronization,
Protocols,
Clocks,
Hardware,
Wireless sensor networks,
Computer crime,
Delays"
Improved Optimization Strategy for Irradiance Equalization in Dynamic Photovoltaic Arrays,"This paper proposes an improved strategy for the optimization of dynamic photovoltaic arrays (DPVAs) utilizing the “irradiance equalization” (IEq) reconfiguration strategy. This type of reconfigurable array is already very robust as it amalgamates the flexibility of dynamic reconfiguration with the averaging ability of total cross-tied array architecture. This paper identifies four areas to further increase the power yield and significantly reduce the time for a return on investment. Results indicate potential efficiency improvements of more than 10% in some cases, and between 4% and 10% across a number of random and abrupt shading conditions. As in any DPVA system, the proposed approaches require additional hardware and advanced control algorithms compared to a static PV array, but anyone implementing a dynamic array has already committed themselves to including the majority of this infrastructure. This investigation supports the idea of a fully dynamic IEq-DPVA with the ability to resize its array dimensions while implementing a rapid sorting algorithm based on information gathered using a novel precision irradiance profiling technique.","Computer architecture,
Microprocessors,
Standards,
Mathematical model,
Optimization,
Photovoltaic systems"
A Meet-in-the-Middle Algorithm for Fast Synthesis of Depth-Optimal Quantum Circuits,"We present an algorithm for computing depth-optimal decompositions of logical operations, leveraging a meet-in-the-middle technique to provide a significant speedup over simple brute force algorithms. As an illustration of our method, we implemented this algorithm and found factorizations of commonly used quantum logical operations into elementary gates in the Clifford+T set. In particular, we report a decomposition of the Toffoli gate over the set of Clifford and T gates. Our decomposition achieves a total T-depth of 3, thereby providing a 40% reduction over the previously best known decomposition for the Toffoli gate. Due to the size of the search space, the algorithm is only practical for small parameters, such as the number of qubits, and the number of gates in an optimal implementation.","Logic gates,
Silicon,
Quantum computing,
Approximation algorithms,
Force,
Fault tolerance,
Fault tolerant systems"
Experimental Analysis of Bound Handling Techniques in Particle Swarm Optimization,"Many practical optimization problems are constrained and have a bounded search space. In this paper, we propose and compare a wide variety of bound handling techniques for particle swarm optimization. By examining their performance on flat landscapes, we show that many bound handling techniques introduce significant search bias. Furthermore, we compare the performance of many bound handling techniques on a variety of test problems, demonstrating that the bound handling technique can have a major impact on the algorithm performance, and that the method recently proposed as the standard does not, in general, perform well.","Vectors,
Mirrors,
Particle swarm optimization,
Topology,
Benchmark testing,
Electronic mail,
Optimization"
Real-Time Posture Reconstruction for Microsoft Kinect,"The recent advancement of motion recognition using Microsoft Kinect stimulates many new ideas in motion capture and virtual reality applications. Utilizing a pattern recognition algorithm, Kinect can determine the positions of different body parts from the user. However, due to the use of a single-depth camera, recognition accuracy drops significantly when the parts are occluded. This hugely limits the usability of applications that involve interaction with external objects, such as sport training or exercising systems. The problem becomes more critical when Kinect incorrectly perceives body parts. This is because applications have limited information about the recognition correctness, and using those parts to synthesize body postures would result in serious visual artifacts. In this paper, we propose a new method to reconstruct valid movement from incomplete and noisy postures captured by Kinect. We first design a set of measurements that objectively evaluates the degree of reliability on each tracked body part. By incorporating the reliability estimation into a motion database query during run time, we obtain a set of similar postures that are kinematically valid. These postures are used to construct a latent space, which is known as the natural posture space in our system, with local principle component analysis. We finally apply frame-based optimization in the space to synthesize a new posture that closely resembles the true user posture while satisfying kinematic constraints. Experimental results show that our method can significantly improve the quality of the recognized posture under severely occluded environments, such as a person exercising with a basketball or moving in a small room.","Reliability,
Tracking,
Kinematics,
Principal component analysis,
Image reconstruction,
Databases,
Training"
Variable Switching Frequency PWM for Three-Phase Converters Based on Current Ripple Prediction,"Compared with the widely used constant switching frequency pulse-width-modulation (PWM) method, variable switching frequency PWM can benefit more because of the extra freedom. Based on the analytical expression of current ripple of three-phase converters, variable switching frequency control methods are proposed to satisfy different ripple requirements. Switching cycle
T
s
is updated in DSP in every interruption period based on the ripple requirement. Two methods are discussed in this paper. The first method is designed to arrange the current ripple peak value within a certain value and can reduce the equivalent switching frequency and electromagnetic interference (EMI) noise; the second method is designed to keep ripple current RMS value constant and reduce the EMI noise. Simulation and experimental results show that variable switching frequency control could improve the performance of EMI and efficiency without impairing the power quality.","Switching frequency,
Switches,
Vectors,
Pulse width modulation,
Equivalent circuits,
Electromagnetic interference"
Structural Texture Similarity Metrics for Image Analysis and Retrieval,"We develop new metrics for texture similarity that accounts for human visual perception and the stochastic nature of textures. The metrics rely entirely on local image statistics and allow substantial point-by-point deviations between textures that according to human judgment are essentially identical. The proposed metrics extend the ideas of structural similarity and are guided by research in texture analysis-synthesis. They are implemented using a steerable filter decomposition and incorporate a concise set of subband statistics, computed globally or in sliding windows. We conduct systematic tests to investigate metric performance in the context of “known-item search,” the retrieval of textures that are “identical” to the query texture. This eliminates the need for cumbersome subjective tests, thus enabling comparisons with human performance on a large database. Our experimental results indicate that the proposed metrics outperform peak signal-to-noise ratio (PSNR), structural similarity metric (SSIM) and its variations, as well as state-of-the-art texture classification metrics, using standard statistical measures.","Measurement,
Humans,
PSNR,
Gray-scale,
Correlation,
Databases,
Image coding"
A 100-Channel Hermetically Sealed Implantable Device for Chronic Wireless Neurosensing Applications,"A 100-channel fully implantable wireless broadband neural recording system was developed. It features 100 parallel broadband (0.1 Hz-7.8 kHz) neural recording channels, a medical grade 200 mAh Li-ion battery recharged inductively at 150 kHz , and data telemetry using 3.2 GHz to 3.8 GHz FSK modulated wireless link for 48 Mbps Manchester encoded data. All active electronics are hermetically sealed in a titanium enclosure with a sapphire window for electromagnetic transparency. A custom, high-density configuration of 100 individual hermetic feedthrough pins enable connection to an intracortical neural recording microelectrode array. A 100 MHz bandwidth custom receiver was built to remotely receive the FSK signal and achieved -77.7 dBm sensitivity with 10-8 BER at 48 Mbps data rate. ESD testing on all the electronic inputs and outputs has proven that the implantable device satisfies the HBM Class-1B ESD Standard. In addition, the evaluation of the worst-case charge density delivered to the tissue from each I/O pin verifies the patient safety of the device in the event of failure. Finally, the functionality and reliability of the complete device has been tested on-bench and further validated chronically in ongoing freely moving swine and monkey animal trials for more than one year to date.","Wireless communication,
Noise,
Application specific integrated circuits,
Wireless sensor networks,
Batteries,
Resistors,
Implants"
Smart Robust Resources Control in LV Network to Deal With Voltage Rise Issue,"Often voltage rise along low voltage (LV) networks limits their capacity to accommodate more renewable energy (RE) sources. This paper proposes a robust and effective approach to coordinate customers' resources and control voltage rise in LV networks, where photovoltaics (PVs) are considered as the RE sources. The proposed coordination algorithm includes both localized and distributed control strategies. The localized strategy determines the value of PV inverter active and reactive power, while the distributed strategy coordinates customers' energy storage units (ESUs). To verify the effectiveness of proposed approach, a typical residential LV network is used and simulated in the PSCAD-EMTC platform.","Renewable energy sources,
Energy storage,
Photovoltaic systems,
Voltage control"
Localization of Wireless Sensor Networks in the Wild: Pursuit of Ranging Quality,"Localization is a fundamental issue of wireless sensor networks that has been extensively studied in the literature. Our real-world experience from GreenOrbs, a sensor network system deployed in a forest, shows that localization in the wild remains very challenging due to various interfering factors. In this paper, we propose CDL, a Combined and Differentiated Localization approach for localization that exploits the strength of range-free approaches and range-based approaches using received signal strength indicator (RSSI). A critical observation is that ranging quality greatly impacts the overall localization accuracy. To achieve a better ranging quality, our method CDL incorporates virtual-hop localization, local filtration, and ranging-quality aware calibration. We have implemented and evaluated CDL by extensive real-world experiments in GreenOrbs and large-scale simulations. Our experimental and simulation results demonstrate that CDL outperforms current state-of-art localization approaches with a more accurate and consistent performance. For example, the average location error using CDL in GreenOrbs system is 2.9 m, while the previous best method SISR has an average error of 4.6 m.",
An Integrated Power Consumption Model for Distributed Systems,"In order to realize green ecosocieties, the total electric power consumption of computers and networks is required to be reduced. In applications on distributed systems, clients issue service requests to servers and then servers send replies to clients. Here, we discuss how much electric power a server consumes since the power consumption of a client is neglectable compared with a server. We classify applications into transaction- and communication-based ones. A server mainly consumes CPU resources to perform the transaction-based applications. On the other hand, a server consumes communication resources to transmit a large volume of data to a client in communication-based applications. In our previous studies, the power consumption laxity-based and extended power consumption-based algorithms are proposed to select one of servers so that the total power consumption of servers is reduced for transaction- and communication-based applications, respectively. However, most applications are mixed types, i.e., composed of both the transaction and communication processing modules. Hence, we consider the mixed types of applications in this paper. First, we integrate the power consumption models of transaction- and communication-based applications into a modified simple power consumption (MSPC) model of a server. Based on the MSPC model, we propose an algorithm to select one of servers for mixed types of applications so that the total power consumption of servers can be reduced. We show the power consumption of servers can be reduced in the algorithm through the simulation.","Power demand,
Client-server systems,
Algorithm design and analysis,
Peer to peer computing"
A Framework for Daily Activity Monitoring and Fall Detection Based on Surface Electromyography and Accelerometer Signals,"As an essential branch of context awareness, activity awareness, especially daily activity monitoring and fall detection, is important to healthcare for the elderly and patients with chronic diseases. In this paper, a framework for activity awareness using surface electromyography and accelerometer (ACC) signals is proposed. First, histogram negative entropy was employed to determine the start- and end-points of static and dynamic active segments. Then, the angle of each ACC axis was calculated to indicate body postures, which assisted with sorting dynamic activities into two categories: dynamic gait activities and dynamic transition ones, by judging whether the pre- and post-postures are both standing. Next, the dynamic gait activities were identified by the double-stream hidden Markov models. Besides, the dynamic transition activities were distinguished into normal transition activities and falls by resultant ACC amplitude. Finally, a continuous daily activity monitoring and fall detection scheme was performed with the recognition accuracy over 98%, demonstrating the excellent fall detection performance and the great feasibility of the proposed method in daily activities awareness.","Entropy,
Hidden Markov models,
Sensors,
Monitoring,
Thigh,
Histograms,
Muscles"
A Cascade MPC Control Structure for a PMSM With Speed Ripple Minimization,"This paper addresses the problem of reducing the impact of periodic disturbances arising from the current sensor offset error on the speed control of a permanent-magnet synchronous motor. The new results are based on a cascade model predictive control scheme with an embedded disturbance model. Supporting experimental results, where the per-unit model is used to improve numerical conditioning, are also given.","Steady-state,
Torque,
Frequency control,
Polynomials,
Velocity control,
Oscillators"
Limits of Reliable Communication with Low Probability of Detection on AWGN Channels,"We present a square root limit on the amount of information transmitted reliably and with low probability of detection (LPD) over additive white Gaussian noise (AWGN) channels. Specifically, if the transmitter has AWGN channels to an intended receiver and a warden, both with non-zero noise power, we prove that o(√n) bits can be sent from the transmitter to the receiver in n channel uses while lower-bounding α + β ≥ 1-ε for any ε > 0, where α and β respectively denote the warden's probabilities of a false alarm when the sender is not transmitting and a missed detection when the sender is transmitting. Moreover, in most practical scenarios, a lower bound on the noise power on the channel between the transmitter and the warden is known and O(√n) bits can be sent in n LPD channel uses. Conversely, attempting to transmit more than O(√n) bits either results in detection by the warden with probability one or a non-zero probability of decoding error at the receiver as n→∞.","Noise,
AWGN channels,
Decoding,
Entropy,
Vectors,
Reliability,
Testing"
Cluster Consensus in Discrete-Time Networks of Multiagents With Inter-Cluster Nonidentical Inputs,"In this paper, cluster consensus of multiagent systems is studied via inter-cluster nonidentical inputs. Here, we consider general graph topologies, which might be time-varying. The cluster consensus is defined by two aspects: intracluster synchronization, the state at which differences between each pair of agents in the same cluster converge to zero, and inter-cluster separation, the state at which agents in different clusters are separated. For intra-cluster synchronization, the concepts and theories of consensus, including the spanning trees, scramblingness, infinite stochastic matrix product, and Hajnal inequality, are extended. As a result, it is proved that if the graph has cluster spanning trees and all vertices self-linked, then the static linear system can realize intra-cluster synchronization. For the time-varying coupling cases, it is proved that if there exists T > 0 such that the union graph across any T-length time interval has cluster spanning trees and all graphs has all vertices self-linked, then the time-varying linear system can also realize intra-cluster synchronization. Under the assumption of common inter-cluster influence, a sort of inter-cluster nonidentical inputs are utilized to realize inter-cluster separation, such that each agent in the same cluster receives the same inputs and agents in different clusters have different inputs. In addition, the boundedness of the infinite sum of the inputs can guarantee the boundedness of the trajectory. As an application, we employ a modified non-Bayesian social learning model to illustrate the effectiveness of our results.","Synchronization,
Topology,
Linear matrix inequalities,
Vectors,
Network topology,
Time varying systems,
Linear systems"
RGB-D flow: Dense 3-D motion estimation using color and depth,"3-D motion estimation is a fundamental problem that has far-reaching implications in robotics. A scene flow formulation is attractive as it makes no assumptions about scene complexity, object rigidity, or camera motion. RGB-D cameras provide new information useful for computing dense 3-D flow in challenging scenes. In this work we show how to generalize two-frame variational 2-D flow algorithms to 3-D. We show that scene flow can be reliably computed using RGB-D data, overcoming depth noise and outperforming previous results on a variety of scenes. We apply dense 3-D flow to rigid motion segmentation.","Optical imaging,
Image color analysis,
Motion segmentation,
Computer vision,
Optical sensors,
Smoothing methods,
Robustness"
TW-k-means: Automated two-level variable weighting clustering algorithm for multiview data,"This paper proposes TW-k-means, an automated two-level variable weighting clustering algorithm for multiview data, which can simultaneously compute weights for views and individual variables. In this algorithm, a view weight is assigned to each view to identify the compactness of the view and a variable weight is also assigned to each variable in the view to identify the importance of the variable. Both view weights and variable weights are used in the distance function to determine the clusters of objects. In the new algorithm, two additional steps are added to the iterative k-means clustering process to automatically compute the view weights and the variable weights. We used two real-life data sets to investigate the properties of two types of weights in TW-k-means and investigated the difference between the weights of TW-k-means and the weights of the individual variable weighting method. The experiments have revealed the convergence property of the view weights in TW-k-means. We compared TW-k-means with five clustering algorithms on three real-life data sets and the results have shown that the TW-k-means algorithm significantly outperformed the other five clustering algorithms in four evaluation indices.","Clustering algorithms,
Partitioning algorithms,
Computational modeling,
Clustering methods,
Web pages,
Data models,
Algorithm design and analysis"
"Optimal Antenna Currents for Q, Superdirectivity, and Radiation Patterns Using Convex Optimization","The high Q-factor (low bandwidth) and low efficiency make the design of small antennas challenging. Here, convex optimization is used to determine current distributions that provide upper bounds on the antenna performance. Optimization formulations for maximal gain Q-factor quotient, minimal Q-factor for superdirectivity, and minimum Q for given far-fields are presented. The effects of antennas embedded in structures are also discussed. The results are illustrated for planar geometries.","Convex functions,
Q factor,
Dipole antennas,
Optimization,
Vectors,
Antenna radiation patterns"
Performance Analysis of Group Paging for Machine-Type Communications in LTE Networks,"Machine-type communication (MTC) is a crucial service for next-generation cellular networks. Mass access to the network by MTC devices may result in the overload of radio access networks (RANs) and degrade the service quality of human-to-human communication. Group paging is one of the mechanisms proposed to alleviate the RAN-overload problem. This paper presents an analytical model based on a recursive contending-users estimation (RCE) method proposed in the literature to derive the performance metrics of collision probability, access success probability, average access delay, statistics of preamble transmissions, statistics of access delay, and utilization of random-access opportunities (RAOs) for group paging with various combinations of group sizes and reserved radio resources in a paging access interval. The optimal group size and required RAOs are subsequently derived based on the given target access success probability. Numerical results demonstrate that the proposed model can accurately estimate the performance of group paging.",
Splat Feature Classification With Application to Retinal Hemorrhage Detection in Fundus Images,"A novel splat feature classification method is presented with application to retinal hemorrhage detection in fundus images. Reliable detection of retinal hemorrhages is important in the development of automated screening systems which can be translated into practice. Under our supervised approach, retinal color images are partitioned into nonoverlapping segments covering the entire image. Each segment, i.e., splat, contains pixels with similar color and spatial location. A set of features is extracted from each splat to describe its characteristics relative to its surroundings, employing responses from a variety of filter bank, interactions with neighboring splats, and shape and texture information. An optimal subset of splat features is selected by a filter approach followed by a wrapper approach. A classifier is trained with splat-based expert annotations and evaluated on the publicly available Messidor dataset. An area under the receiver operating characteristic curve of 0.96 is achieved at the splat level and 0.87 at the image level. While we are focused on retinal hemorrhage detection, our approach has potential to be applied to other object detection tasks.","Hemorrhaging,
Feature extraction,
Image color analysis,
Retina,
Training,
Standards,
Blood"
Machine Learning Techniques for Cooperative Spectrum Sensing in Cognitive Radio Networks,"We propose novel cooperative spectrum sensing (CSS) algorithms for cognitive radio (CR) networks based on machine learning techniques which are used for pattern classification. In this regard, unsupervised (e.g., K-means clustering and Gaussian mixture model (GMM)) and supervised (e.g., support vector machine (SVM) and weighted K-nearest-neighbor (KNN)) learning-based classification techniques are implemented for CSS. For a radio channel, the vector of the energy levels estimated at CR devices is treated as a feature vector and fed into a classifier to decide whether the channel is available or not. The classifier categorizes each feature vector into either of the two classes, namely, the ""channel available class"" and the ""channel unavailable class"". Prior to the online classification, the classifier needs to go through a training phase. For classification, the K-means clustering algorithm partitions the training feature vectors into K clusters, where each cluster corresponds to a combined state of primary users (PUs) and then the classifier determines the class the test energy vector belongs to. The GMM obtains a mixture of Gaussian density functions that well describes the training feature vectors. In the case of the SVM, the support vectors (i.e., a subset of training vectors which fully specify the decision function) are obtained by maximizing the margin between the separating hyperplane and the training feature vectors. Furthermore, the weighted KNN classification technique is proposed for CSS for which the weight of each feature vector is calculated by evaluating the area under the receiver operating characteristic (ROC) curve of that feature vector. The performance of each classification technique is quantified in terms of the average training time, the sample classification delay, and the ROC curve. Our comparative results clearly reveal that the proposed algorithms outperform the existing state-of-the-art CSS techniques.","Vectors,
Training,
Cascading style sheets,
Energy states,
Sensors,
Availability,
Support vector machines"
Generation of All-in-Focus Images by Noise-Robust Selective Fusion of Limited Depth-of-Field Images,"The limited depth-of-field of some cameras prevents them from capturing perfectly focused images when the imaged scene covers a large distance range. In order to compensate for this problem, image fusion has been exploited for combining images captured with different camera settings, thus yielding a higher quality all-in-focus image. Since most current approaches for image fusion rely on maximizing the spatial frequency of the composed image, the fusion process is sensitive to noise. In this paper, a new algorithm for computing the all-in-focus image from a sequence of images captured with a low depth-of-field camera is presented. The proposed approach adaptively fuses the different frames of the focus sequence in order to reduce noise while preserving image features. The algorithm consists of three stages: 1) focus measure; 2) selectivity measure; 3) and image fusion. An extensive set of experimental tests has been carried out in order to compare the proposed algorithm with state-of-the-art all-in-focus methods using both synthetic and real sequences. The obtained results show the advantages of the proposed scheme even for high levels of noise.","Noise,
Image fusion,
Noise measurement,
Cameras,
Frequency measurement,
Weight measurement,
Wavelet transforms"
Full-Wave Iterative Image Reconstruction in Photoacoustic Tomography With Acoustically Inhomogeneous Media,"Existing approaches to image reconstruction in photoacoustic computed tomography (PACT) with acoustically heterogeneous media are limited to weakly varying media, are computationally burdensome, and/or cannot effectively mitigate the effects of measurement data incompleteness and noise. In this work, we develop and investigate a discrete imaging model for PACT that is based on the exact photoacoustic (PA) wave equation and facilitates the circumvention of these limitations. A key contribution of the work is the establishment of a procedure to implement a matched forward and backprojection operator pair associated with the discrete imaging model, which permits application of a wide-range of modern image reconstruction algorithms that can mitigate the effects of data incompleteness and noise. The forward and backprojection operators are based on the k-space pseudospectral method for computing numerical solutions to the PA wave equation in the time domain. The developed reconstruction methodology is investigated by use of both computer-simulated and experimental PACT measurement data.","Image reconstruction,
Acoustics,
Mathematical model,
Vectors,
Reconstruction algorithms,
Computational modeling"
Lumbar Spine Segmentation Using a Statistical Multi-Vertebrae Anatomical Shape+Pose Model,"Segmentation of the spinal column from computed tomography (CT) images is a preprocessing step for a range of image-guided interventions. One intervention that would benefit from accurate segmentation is spinal needle injection. Previous spinal segmentation techniques have primarily focused on identification and separate segmentation of each vertebra. Recently, statistical multi-object shape models have been introduced to extract common statistical characteristics between several anatomies. These models can be used for segmentation purposes because they are robust, accurate, and computationally tractable. In this paper, we develop a statistical multi-vertebrae shape+pose model and propose a novel registration-based technique to segment the CT images of spine. The multi-vertebrae statistical model captures the variations in shape and pose simultaneously, which reduces the number of registration parameters. We validate our technique in terms of accuracy and robustness of multi-vertebrae segmentation of CT images acquired from lumbar vertebrae of 32 subjects. The mean error of the proposed technique is below 2 mm, which is sufficient for many spinal needle injection procedures, such as facet joint injections.","Shape,
Image segmentation,
Computed tomography,
Computational modeling,
Training,
Principal component analysis,
Joints"
Design of Testable Reversible Sequential Circuits,"In this paper, we propose the design of two vectors testable sequential circuits based on conservative logic gates. The proposed sequential circuits based on conservative logic gates outperform the sequential circuits implemented in classical gates in terms of testability. Any sequential circuit based on conservative logic gates can be tested for classical unidirectional stuck-at faults using only two test vectors. The two test vectors are all 1's, and all 0's. The designs of two vectors testable latches, master-slave flip-flops and double edge triggered (DET) flip-flops are presented. The importance of the proposed work lies in the fact that it provides the design of reversible sequential circuits completely testable for any stuck-at fault by only two test vectors, thereby eliminating the need for any type of scan-path access to internal memory cells. The reversible design of the DET flip-flop is proposed for the first time in the literature. We also showed the application of the proposed approach toward 100% fault coverage for single missing/additional cell defect in the quantum-dot cellular automata (QCA) layout of the Fredkin gate. We are also presenting a new conservative logic gate called multiplexer conservative QCA gate (MX-cqca) that is not reversible in nature but has similar properties as the Fredkin gate of working as 2:1 multiplexer. The proposed MX-cqca gate surpasses the Fredkin gate in terms of complexity (the number of majority voters), speed, and area.","Logic gates,
Latches,
Vectors,
Circuit faults,
Clocks,
Master-slave,
Sequential circuits"
Unified Optimization Framework for Multi-Static Radar Code Design Using Information-Theoretic Criteria,"In this paper, we study the problem of code design to improve the detection performance of multi-static radar in the presence of clutter (i.e., a signal-dependent interference). To this end, we briefly present a discrete-time formulation of the problem as well as the optimal detector in the presence of Gaussian clutter. Due to the lack of analytical expression for receiver operation characteristic (ROC), code design based on ROC is not feasible. Therefore, we consider several popular information-theoretic criteria including Bhattacharyya distance, Kullback-Leibler (KL) divergence, J-divergence, and mutual information (MI) as design metrics. The code optimization problems associated with different information-theoretic criteria are obtained and cast under a unified framework. We propose two general methods based on Majorization-Minimization to tackle the optimization problems in the framework. The first method provides optimal solutions via successive majorizations whereas the second one consists of a majorization step, a relaxation, and a synthesis stage. Moreover, derivations of the proposed methods are extended to tackle the code design problems with a peak-to-average ratio power (PAR) constraint. Using numerical investigations, a general analysis of the coded system performance, computational efficiency of the proposed methods, and the behavior of the information-theoretic criteria is provided.","Radar,
Clutter,
Receivers,
Optimization,
Measurement,
Vectors"
Real-Time Implementation of ANFIS Control for Renewable Interfacing Inverter in 3P4W Distribution Network,"Power electronics plays an important role in controlling the grid-connected renewable energy sources. This paper presents a novel adaptive neuro-fuzzy control approach for the renewable interfacing inverter. The main objective is to achieve smooth bidirectional power flow and nonlinear unbalanced load compensation simultaneously, where the conventional proportional-integral controller may fail due to the rapid change in the dynamics of the highly nonlinear system. The combined capability of neuro-fuzzy controller in handling the uncertainties and learning from the processes is proved to be advantageous while controlling the inverter under fluctuating operating conditions. The inverter is actively controlled to compensate the harmonics, reactive power, and the current imbalance of a three-phase four-wire (3P4W) nonlinear load with generated renewable power injection into the grid simultaneously. This enables the grid to always supply/absorb a balanced set of fundamental currents at unity power factor even in the presence of the 3P4W nonlinear unbalanced load at the point of common coupling. The proposed system is developed and simulated in MATLAB/SimPowerSystem environment under different operating conditions. The digital signal processing and control engineering-based laboratory experimental results are also provided to validate the proposed control approach.","Inverters,
Reactive power,
Voltage control,
Harmonic analysis,
Computer architecture,
Simulation,
Active filters"
Building Neuromorphic Circuits with Memristive Devices,"The rapid, exponential growth of modern electronics has brought about profound changes to our daily lives. However, maintaining the growth trend now faces significant challenges at both the fundamental and practical levels [1]. Possible solutions include More Moore?developing new, alternative device structures and materials while maintaining the same basic computer architecture, and More Than Moore?enabling alternative computing architectures and hybrid integration to achieve increased system functionality without trying to push the devices beyond limits. In particular, an increasing number of computing tasks today are related to handling large amounts of data, e.g. image processing as an example. Conventional von Neumann digital computers, with separate memory and processer units, become less and less efficient when large amount of data have to be moved around and processed quickly. Alternative approaches such as bio-inspired neuromorphic circuits, with distributed computing and localized storage in networks, become attractive options [2]?[6].","Memristors,
Neuromorphics,
Nanostructured materials,
Nanoscale devices,
Image processing,
Memory management,
Market research"
Controlled Sensing for Multihypothesis Testing,"The problem of multiple hypothesis testing with observation control is considered in both fixed sample size and sequential settings. In the fixed sample size setting, for binary hypothesis testing, the optimal exponent for the maximal error probability corresponds to the maximum Chernoff information over the choice of controls, and a pure stationary open-loop control policy is asymptotically optimal within the larger class of all causal control policies. For multihypothesis testing in the fixed sample size setting, lower and upper bounds on the optimal error exponent are derived. It is also shown through an example with three hypotheses that the optimal causal control policy can be strictly better than the optimal open-loop control policy. In the sequential setting, a test based on earlier work by Chernoff for binary hypothesis testing, is shown to be first-order asymptotically optimal for multihypothesis testing in a strong sense, using the notion of decision making risk in place of the overall probability of error. Another test is also designed to meet hard risk constrains while retaining asymptotic optimality. The role of past information and randomization in designing optimal control policies is discussed.","Testing,
Sensors,
Upper bound,
Minimization,
Educational institutions,
Aerospace electronics,
Error probability"
Fully Automatic Segmentation of the Proximal Femur Using Random Forest Regression Voting,"Extraction of bone contours from radiographs plays an important role in disease diagnosis, preoperative planning, and treatment analysis. We present a fully automatic method to accurately segment the proximal femur in anteroposterior pelvic radiographs. A number of candidate positions are produced by a global search with a detector. Each is then refined using a statistical shape model together with local detectors for each model point. Both global and local models use Random Forest regression to vote for the optimal positions, leading to robust and accurate results. The performance of the system is evaluated using a set of 839 images of mixed quality. We show that the local search significantly outperforms a range of alternative matching techniques, and that the fully automated system is able to achieve a mean point-to-curve error of less than 0.9 mm for 99% of all 839 images. To the best of our knowledge, this is the most accurate automatic method for segmenting the proximal femur in radiographs yet reported.","Detectors,
Shape,
Image segmentation,
Radio frequency,
Training,
Radiography,
Feature extraction"
Anomaly Detection via Online Oversampling Principal Component Analysis,"Anomaly detection has been an important research topic in data mining and machine learning. Many real-world applications such as intrusion or credit card fraud detection require an effective and efficient framework to identify deviated data instances. However, most anomaly detection methods are typically implemented in batch mode, and thus cannot be easily extended to large-scale problems without sacrificing computation and memory requirements. In this paper, we propose an online oversampling principal component analysis (osPCA) algorithm to address this problem, and we aim at detecting the presence of outliers from a large amount of data via an online updating technique. Unlike prior principal component analysis (PCA)-based approaches, we do not store the entire data matrix or covariance matrix, and thus our approach is especially of interest in online or large-scale problems. By oversampling the target instance and extracting the principal direction of the data, the proposed osPCA allows us to determine the anomaly of the target instance according to the variation of the resulting dominant eigenvector. Since our osPCA need not perform eigen analysis explicitly, the proposed framework is favored for online applications which have computation or memory limitations. Compared with the well-known power method for PCA and other popular anomaly detection algorithms, our experimental results verify the feasibility of our proposed method in terms of both accuracy and efficiency.","Principal component analysis,
Covariance matrix,
Memory management,
Data mining,
Eigenvalues and eigenfunctions,
Algorithm design and analysis,
Data models"
Learning Discriminative Key Poses for Action Recognition,"In this paper, we present a new approach for human action recognition based on key-pose selection and representation. Poses in video frames are described by the proposed extensive pyramidal features (EPFs), which include the Gabor, Gaussian, and wavelet pyramids. These features are able to encode the orientation, intensity, and contour information and therefore provide an informative representation of human poses. Due to the fact that not all poses in a sequence are discriminative and representative, we further utilize the AdaBoost algorithm to learn a subset of discriminative poses. Given the boosted poses for each video sequence, a new classifier named weighted local naive Bayes nearest neighbor is proposed for the final action classification, which is demonstrated to be more accurate and robust than other classifiers, e.g., support vector machine (SVM) and naive Bayes nearest neighbor. The proposed method is systematically evaluated on the KTH data set, the Weizmann data set, the multiview IXMAS data set, and the challenging HMDB51 data set. Experimental results manifest that our method outperforms the state-of-the-art techniques in terms of recognition rate.","Feature extraction,
Humans,
Video sequences,
Laplace equations,
Support vector machines,
Robustness,
Spatiotemporal phenomena"
Fast Algorithms and Performance Bounds for Sum Rate Maximization in Wireless Networks,"In this paper, we consider a wireless network where interference is treated as noise, and we study the nonconvex problem of sum rate maximization by power control. We focus on finding approximately optimal solutions that can be efficiently computed to this NP-hard problem by studying the solutions to two related problems, the sum rate maximization using a signal-to-interference-plus-noise ratio (SINR ) approximation and the max-min weighted SINR optimization. We show that these two problems are intimately connected, can be solved efficiently by algorithms with fast convergence and minimal parameter configuration, and can yield high-quality approximately optimal solutions to sum rate maximization in the low interference regime. As an application of these results, we analyze the connection-level stability of cross-layer utility maximization in the wireless network, where users arrive and depart randomly and are subject to congestion control, and the queue service rates at all the links are determined by the sum rate maximization problem. In particular, we determine the stability region when all the links solve the max-min weighted SINR problem, using instantaneous queue sizes as weights.","Power control,
Approximation methods,
Vectors,
Interference,
Approximation algorithms,
Iterative methods,
Optimization"
Co-Salient Object Detection From Multiple Images,"In this paper, we propose a novel method to discover co-salient objects from a group of images, which is modeled as a linear fusion of an intra-image saliency (IaIS) map and an inter-image saliency (IrIS) map. The first term is to measure the salient objects from each image using multiscale segmentation voting. The second term is designed to detect the co-salient objects from a group of images. To compute the IrIS map, we perform the pairwise similarity ranking based on an image pyramid representation. A minimum spanning tree is then constructed to determine the image matching order. For each region in an image, we design three types of visual descriptors, which are extracted from the local appearance, e.g., color, color co-occurrence and shape properties. The final region matching problem between the images is formulated as an assignment problem that can be optimized by linear programming. Experimental evaluation on a number of images demonstrates the good performance of the proposed method on co-salient object detection.","trees (mathematics),
feature extraction,
image fusion,
image matching,
image representation,
image segmentation,
linear programming,
object detection"
The Fano Resonance in Symmetry Broken Terahertz Metamaterials,"The spectral characteristic of a Fano resonance is a distinct and unique asymmetric line shape. It arises from the destructive interference between a bright continuum mode and a discrete dark mode. Metamaterials and plasmonics have facilitated the observation of Fano resonances in the realm of classical electrodynamics and have spurred intense interest to study and to exploit their peculiarities due their low loss and very sharp resonant features. Here, we survey the excitation of Fano resonance at terahertz frequencies by using asymmetric metamaterial structures. In particular, we discuss the high Q of Fano resonances, their sensitivity to the asymmetry parameter and potential applications. We believe that the manipulation of terahertz radiation by exploiting Fano resonances in terahertz metamaterials could usher in next-generation terahertz photonic devices for delay, storage, filtering, sensing, and nonlinear applications.",
A New Standby Structure Based on a Forward Converter Integrated With a Phase-Shift Full-Bridge Converter for Server Power Supplies,"This paper presents a new standby structure where a forward converter is integrated with a dc-dc phase-shift full-bridge (PSFB) converter for server power supplies. While a typical standby structure consists of an independent flyback converter, the proposed standby structure is integrated with one leg of the dc-dc PSFB converter. Its main advantages are that the voltage across a standby switch is clamped at the link voltage across the link capacitor and that the standby switch achieves zero-voltage switching over entire load range. The validity of the proposed standby structure is confirmed by the experimental results from 12 V/58 A for the dc-dc output prototype and 11.5 V/1.5 A for the standby output prototype.","Zero voltage switching,
Power supplies,
Switches,
Servers,
Flyback transformers,
Semiconductor diodes"
Tag recommendation in software information sites,"Nowadays, software engineers use a variety of online media to search and become informed of new and interesting technologies, and to learn from and help one another. We refer to these kinds of online media which help software engineers improve their performance in software development, maintenance and test processes as software information sites. It is common to see tags in software information sites and many sites allow users to tag various objects with their own words. Users increasingly use tags to describe the most important features of their posted contents or projects. In this paper, we propose TagCombine, an automatic tag recommendation method which analyzes objects in software information sites. TagCombine has 3 different components: 1. multilabel ranking component which considers tag recommendation as a multi-label learning problem; 2. similarity based ranking component which recommends tags from similar objects; 3. tag-term based ranking component which considers the relationship between different terms and tags, and recommends tags after analyzing the terms in the objects. We evaluate TagCombine on 2 software information sites, StackOverflow and Freecode, which contain 47,668 and 39,231 text documents, respectively, and 437 and 243 tags, respectively. Experiment results show that for StackOverflow, our TagCombine achieves recall@5 and recall@10 scores of 0.5964 and 0.7239, respectively; For Freecode, it achieves recall@5 and recall@10 scores of 0.6391 and 0.7773, respectively. Moreover, averaging over StackOverflow and Freecode results, we improve TagRec proposed by Al-Kofahi et al. by 22.65% and 14.95%, and the tag recommendation method proposed by Zangerle et al. by 18.5% and 7.35% for recall@5 and recall@10 scores.","Software,
Media,
Software algorithms,
Vectors,
Prediction algorithms,
Search problems,
Educational institutions"
Normally Off Single-Nanoribbon \hbox{Al}_{2} \hbox{O}_{3}\hbox{/GaN} MISFET,"A single-nanoribbon Al2O3/GaN metal-insulator-semiconductor field-effect transistor (MISFET) has been fabricated. The fabricated device exhibits normally off operation with a threshold voltage of 2.1 V. The device also exhibits superior performances such as a maximum drain current density of 1.51 A/mm, a maximum transconductance of 580 mS/mm, and a field-effect mobility of 293 cm2·V-1·s-1. This is because the electron concentration in the GaN channels can be increased due to the enhanced gate controllability, which, thus, effectively screens the field lines from the interface traps or the defects near the channels to improve the electron mobility in the channel. The nanoribbon Al2O3/GaN MISFET is a very promising candidate for high-performance normally off GaN FETs.","Gallium nitride,
Logic gates,
HEMTs,
MODFETs,
Aluminum gallium nitride,
Aluminum oxide,
MISFETs"
Privacy-Preserving Profile Matching for Proximity-Based Mobile Social Networking,"Proximity-based mobile social networking (PMSN) refers to the social interaction among physically proximate mobile users. The first step toward effective PMSN is for mobile users to choose whom to interact with. Profile matching refers to two users comparing their personal profiles and is promising for user selection in PMSN. It, however, conflicts with users' growing privacy concerns about disclosing their personal profiles to complete strangers. This paper tackles this open challenge by designing novel fine-grained private matching protocols. Our protocols enable two users to perform profile matching without disclosing any information about their profiles beyond the comparison result. In contrast to existing coarse-grained private matching schemes for PMSN, our protocols allow finer differentiation between PMSN users and can support a wide range of matching metrics at different privacy levels. The performance of our protocols is thoroughly analyzed and evaluated via real smartphone experiments.","Protocols,
Privacy,
Measurement,
Mobile communication,
Social network services,
Public key"
Learning Incoherent Dictionaries for Sparse Approximation Using Iterative Projections and Rotations,"This article deals with learning dictionaries for sparse approximation whose atoms are both adapted to a training set of signals and mutually incoherent. To meet this objective, we employ a dictionary learning scheme consisting of sparse approximation followed by dictionary update and we add to the latter a decorrelation step in order to reach a target mutual coherence level. This step is accomplished by an iterative projection method complemented by a rotation of the dictionary. Experiments on musical audio data and a comparison with the method of optimal coherence-constrained directions (MOCOD) and the incoherent K-SVD (INK-SVD) illustrate that the proposed algorithm can learn dictionaries that exhibit a low mutual coherence while providing a sparse approximation with better signal-to-noise ratio (SNR) than the benchmark techniques.","Dictionaries,
Approximation methods,
Coherence,
Approximation algorithms,
Atomic measurements,
Sparse matrices,
Educational institutions"
Latent Fingerprint Matching Using Descriptor-Based Hough Transform,"Identifying suspects based on impressions of fingers lifted from crime scenes (latent prints) is a routine procedure that is extremely important to forensics and law enforcement agencies. Latents are partial fingerprints that are usually smudgy, with small area and containing large distortion. Due to these characteristics, latents have a significantly smaller number of minutiae points compared to full (rolled or plain) fingerprints. The small number of minutiae and the noise characteristic of latents make it extremely difficult to automatically match latents to their mated full prints that are stored in law enforcement databases. Although a number of algorithms for matching full-to-full fingerprints have been published in the literature, they do not perform well on the latent-to-full matching problem. Further, they often rely on features that are not easy to extract from poor quality latents. In this paper, we propose a new fingerprint matching algorithm which is especially designed for matching latents. The proposed algorithm uses a robust alignment algorithm (descriptor-based Hough transform) to align fingerprints and measures similarity between fingerprints by considering both minutiae and orientation field information. To be consistent with the common practice in latent matching (i.e., only minutiae are marked by latent examiners), the orientation field is reconstructed from minutiae. Since the proposed algorithm relies only on manually marked minutiae, it can be easily used in law enforcement applications. Experimental results on two different latent databases (NIST SD27 and WVU latent databases) show that the proposed algorithm outperforms two well optimized commercial fingerprint matchers. Further, a fusion of the proposed algorithm and commercial fingerprint matchers leads to improved matching accuracy.","Databases,
Fingerprint recognition,
NIST,
Transforms,
Law enforcement,
Accuracy,
Educational institutions"
A Novel Technique for Optimal Feature Selection in Attribute Profiles Based on Genetic Algorithms,"Morphological and attribute profiles have been proven to be effective tools to fuse spectral and spatial information for classification of remote sensing data. A wide range of filters (i.e., number of levels in the profiles) is usually necessary in order to properly model the spatial information in a remote sensing scene. A dense sampling of the values of the parameters of the filters generates profiles that have both a very large dimensionality (leading to the Hughes phenomenon in classification) and a high redundancy. In this paper, a novel iterative technique based on genetic algorithms (GAs) is proposed to automatically optimize the selection of the optimal features from the profiles. The selection of the filtered images that compose the profile is performed by dividing them into three classes corresponding to high, medium, and low importance. We propose to measure the importance (modeled in terms of discriminative power in the classification task) using a random forest classifier, which provides a rank for each feature with its model. Only the set of images associated with the highest importance is selected, i.e., preserved for classification. The proposed technique is applied to the features labeled with medium importance, whereas the images with the lowest importance are removed from the profile. This method is employed to classify three hyperspectral data sets achieving significantly high classification accuracy values. A parallel computing implementation has been developed in order to significantly reduce the time required for the run of the GAs.","Biological cells,
Radio frequency,
Sociology,
Statistics,
Training,
Vegetation,
Hyperspectral imaging"
Normalized Feature Vectors: A Novel Alignment-Free Sequence Comparison Method Based on the Numbers of Adjacent Amino Acids,"Based on all kinds of adjacent amino acids (AAA), we map each protein primary sequence into a 400 by (L-1) matrix M. In addition, we further derive a normalized 400-tuple mathematical descriptors D, which is extracted from the primary protein sequences via singular values decomposition (SVD) of the matrix. The obtained 400-D normalized feature vectors (NFVs) further facilitate our quantitative analysis of protein sequences. Using the normalized representation of the primary protein sequences, we analyze the similarity for different sequences upon two data sets: 1) ND5 sequences from nine species and 2) transferrin sequences of 24 vertebrates. We also compared the results in this study with those from other related works. These two experiments illustrate that our proposed NFV-AAA approach does perform well in the field of similarity analysis of sequence.","Proteins,
Amino acids,
Vectors,
Feature extraction,
Bioinformatics,
Educational institutions"
Fuzzy Rules Interpolation for Sparse Fuzzy Rule-Based Systems Based on Interval Type-2 Gaussian Fuzzy Sets and Genetic Algorithms,"In this paper, we present a new method for fuzzy rules interpolation for sparse fuzzy rule-based systems based on interval type-2 Gaussian fuzzy sets and genetic algorithms. First, we present a method to deal with the interpolation of fuzzy rules based on interval type-2 Gaussian fuzzy sets. We also prove that the proposed method guarantees to produce normal interval type-2 Gaussian fuzzy sets. Then, we present a method to learn optimal interval type-2 Gaussian fuzzy sets for sparse fuzzy rule-based systems based on genetic algorithms. We also apply the proposed fuzzy rules interpolation method and the proposed learning method to deal with multivariate regression problems and time series prediction problems. The experimental results show that the proposed fuzzy rules interpolation method using the optimally learned interval type-2 Gaussian fuzzy sets gets higher average accuracy rates than the existing methods.","Fuzzy sets,
Interpolation,
Standards,
Genetic algorithms,
Time series analysis,
Learning systems,
Multivariate regression"
Distributed Sampling Rate Control for Rechargeable Sensor Nodes with Limited Battery Capacity,"Energy harvesting is a promising technology for extending the lifetime of battery-powered sensor networks. Due to time variations of harvested energy, one of the main challenging issues is to maximize the uninterrupted sampling rates of all sensor nodes, which represents the network performance. Most of existing works do not consider the limited capacity of rechargeable battery. In this paper, we are concerned with how to adaptively decide the sampling rate for each rechargeable sensor node with a limited battery capacity to maximize the overall network performance. To solve this problem, we firstly propose an adaptive Energy Allocation sCHeme (EACH) for each sensor node to manage its energy use in an efficient way. Then we develop a Distributed Sampling Rate Control (DSRC) algorithm to obtain the optimal sampling rate. Furthermore, an Improved adaptive Energy Allocation sCHeme (IEACH) is proposed to reduce the impact due to imprecise estimation of harvested energy. Extensive simulations using real experimental data obtained from Baseline Measurement System (BMS) of Solar Radiation Research Laboratory are conducted to demonstrate the efficiency of the proposed algorithms.","wireless sensor networks,
distributed algorithms,
distributed control,
energy harvesting,
secondary cells,
telecommunication control,
telecommunication power supplies"
A Family of Five-Weight Cyclic Codes and Their Weight Enumerators,"Cyclic codes are a subclass of linear codes and have applications in consumer electronics, data storage systems, and communication systems as they have efficient encoding and decoding algorithms. In this paper, a family of p-ary cyclic codes whose duals have three pairwise nonconjugate zeros is proposed. The weight distribution of this family of cyclic codes is determined. It turns out that the proposed cyclic codes have five nonzero weights.","Polynomials,
Mathematical model,
Educational institutions,
Linear codes,
Generators,
Cryptography"
Machine Learning with Brain Graphs: Predictive Modeling Approaches for Functional Imaging in Systems Neuroscience,"The observation and description of the living brain has attracted a lot of research over the past centuries. Many noninvasive imaging modalities have been developed, such as topographical techniques based on the electromagnetic field potential [i.e., electroencephalography (EEG) and magnetoencephalography (MEG)], and tomography approaches including positron emission tomography and magnetic resonance imaging (MRI). Here we will focus on functional MRI (fMRI) since it is widely deployed for clinical and cognitive neurosciences today, and it can reveal brain function due to neurovascular coupling (see ?From Brain Images to fMRI Time Series?). It has led to a much better understanding of brain function, including the description of brain areas with very specialized functions such as face recognition. These neuroscientific insights have been made possible by important methodological advances in MR physics, signal processing, and mathematical modeling.","Complex networks,
Learning systems,
Adaptation models,
Machine learning,
Predictive modeling,
Neuroscience,
Brain modeling,
Biomedical image processing,
Magnetoencephalography,
Electroencephalography"
Towards efficient search for activity trajectories,"The advances in location positioning and wireless communication technologies have led to a myriad of spatial trajectories representing the mobility of a variety of moving objects. While processing trajectory data with the focus of spatio-temporal features has been widely studied in the last decade, recent proliferation in location-based web applications (e.g., Foursquare, Facebook) has given rise to large amounts of trajectories associated with activity information, called activity trajectory. In this paper, we study the problem of efficient similarity search on activity trajectory database. Given a sequence of query locations, each associated with a set of desired activities, an activity trajectory similarity query (ATSQ) returns k trajectories that cover the query activities and yield the shortest minimum match distance. An order-sensitive activity trajectory similarity query (OATSQ) is also proposed to take into account the order of the query locations. To process the queries efficiently, we firstly develop a novel hybrid grid index, GAT, to organize the trajectory segments and activities hierarchically, which enables us to prune the search space by location proximity and activity containment simultaneously. In addition, we propose algorithms for efficient computation of the minimum match distance and minimum order-sensitive match distance, respectively. The results of our extensive empirical studies based on real online check-in datasets demonstrate that our proposed index and methods are capable of achieving superior performance and good scalability.","Trajectory,
Indexing,
Search problems,
Educational institutions,
Vocabulary"
Mechanisms of the Anatomically Correct Testbed Hand,"We have built an anatomically correct testbed (ACT) hand with the purpose of understanding the intrinsic biomechanical and control features in human hands that are critical for achieving robust, versatile, and dexterous movements, as well as rich object and world exploration. By mimicking the underlying mechanics and controls of the human hand in a hardware platform, our goal is to achieve previously unmatched grasping and manipulation skills. In this paper, the novel constituting mechanisms, unique muscle to joint relationships, and movement demonstrations of the thumb, index finger, middle finger, and wrist of the ACT Hand are presented. The grasping and manipulation abilities of the ACT Hand are also illustrated. The fully functional ACT Hand platform allows for the possibility to design and experiment with novel control algorithms leading to a deeper understanding of human dexterity.","Joints,
Bones,
Humans,
Robots,
Biomechanics,
Thumb,
Muscles"
On a Well-Conditioned Electric Field Integral Operator for Multiply Connected Geometries,"All known integral equation techniques for simulating scattering and radiation from arbitrarily shaped, perfect electrically conducting objects suffer from one or more of the following shortcomings: (i) they give rise to ill-conditioned systems when the frequency is low (ii) and/or when the discretization density is high, (iii) their applicability is limited to the quasi-static regime, (iv) they require a search for global topological loops, (v) they suffer from numerical cancellations in the solution when the frequency is very low. This work presents an equation that does not suffer from any of the above drawbacks when applied to smooth and closed objects. The new formulation is obtained starting from a Helmholtz decomposition of two discretizations of the electric field integral operator obtained by using RWGs and dual bases respectively. The new decomposition does not leverage Loop and Star/Tree basis functions, but projectors that derive from them. Following the decomposition, the two discretizations are combined in a Calderon-like fashion resulting in a new overall equation that is shown to exhibit self-regularizing properties without suffering from the limitations of existing formulations. Numerical results show the usefulness of the proposed method both for closed and open structures.","Electric breakdown,
Equations,
Vectors,
Surface impedance,
Matrix decomposition,
Standards,
Integral equations"
Censored Truncated Sequential Spectrum Sensing for Cognitive Radio Networks,"Reliable spectrum sensing is a key functionality of a cognitive radio network. Cooperative spectrum sensing improves the detection reliability of a cognitive radio system but also increases the system energy consumption which is a critical factor particularly for low-power wireless technologies. A censored truncated sequential spectrum sensing technique is considered as an energy-saving approach. To design the underlying sensing parameters, the maximum {average energy consumption per sensor} is minimized subject to a lower bounded global probability of detection and an upper bounded false alarm rate. This way both the interference to the primary user due to miss detection and the network throughput as a result of a low false alarm rate are controlled. {To solve this problem, it is assumed that the cognitive radios and fusion center are aware of their location and mutual channel properties.} We compare the performance of the proposed scheme with a fixed sample size censoring scheme under different scenarios and show that for low-power cognitive radios, censored truncated sequential sensing outperforms censoring. It is shown that as the sensing energy per sample of the cognitive radios increases, the energy efficiency of the censored truncated sequential approach grows significantly.","Sensors,
Cognitive radio,
Energy consumption,
Optimization,
Interference,
Analytical models,
Reliability"
A Protection Coordination Index for Evaluating Distributed Generation Impacts on Protection for Meshed Distribution Systems,"Depending on the capacity, type and location, distributed generation (DG) can have an impact on protection coordination of directional over-current relays for looped distribution systems. In this paper, a new index is proposed, “protection coordination index” (PCI), which can serve as an effective measure when planning the protection of meshed distribution systems with DG. A two-phase non-linear programming (NLP) optimization problem is proposed to determine the PCI by optimally calculating variations in the maximum DG penetration level with changes in the protection coordination time interval. Furthermore, the influence of connecting a DG at a certain location on the system PCIs is examined. The presented analysis is tested on the distribution section of the IEEE 14-bus and IEEE 30-bus systems. The PCI can serve as an efficient index for distribution system planners: (i) to determine the best DG candidate locations for utility owned DG and (ii) to evaluate the impact of a customer owned DG, considering distribution system protection.","Relays,
Indexes,
Optimization,
Short-circuit currents,
Mathematical model,
Circuit faults,
Impedance"
Antennas and Propagation for Body-Centric Wireless Communications at Millimeter-Wave Frequencies: A Review [Wireless Corner],"Body-centric wireless communications represent a well-established field of research, with many studies and applications developed in a range of frequencies that extend from 400 MHz up to 10 GHz. However, many advantages can be found in operating such systems at millimeter-wave frequencies. For example, compact antennas suitable for body-centric applications can be obtained together with other benefits, such as higher data rates and reduced interference and ""observability"". Meanwhile, numerical modeling of antennas and propagation at millimeter-wave frequencies represents a major challenge in terms of efficiency and accuracy. The aim of this paper is to provide a review of recent progresses and outstanding challenges in the field of body-centric communication at frequencies of 60 GHz and 94 GHz.","Millimeter wave communication,
Millimeter wave propagation,
Time-domain analysis,
Finite difference methods"
Analysis of the Pattern Tolerances in Linear Arrays With Arbitrary Amplitude Errors,"The analysis of the tolerances on the power pattern of an array of electromagnetic radiators having excitation amplitudes affected by random errors around the nominal values is addressed. Toward this end, an analytic strategy based on interval analysis is exploited to predict the bounds of the variations in the radiated power pattern in correspondence with difference models of the amplitude tolerances. Selected results are presented and discussed in a comparative fashion as well.","Indexes,
Antenna radiation patterns,
Optimization,
Tolerance analysis,
Phased arrays"
A Survey of Medium Access Mechanisms for Providing QoS in Ad-Hoc Networks,"In this survey we attempt to describe the Quality of Service (QoS) mechanisms employed by Medium Access Control (MAC) protocols designed for ad-hoc networks. We begin with background information: an overview of the related work, the definition of QoS and QoS-related metrics, a general description of contention-free and contention-based protocols for wireless networks, a discussion of issues affecting QoS provisioning in ad-hoc networks, as well as a novel classification of the QoS mechanisms. Then, each mechanism is briefly explained and implementation examples from different protocols are provided. Furthermore, a separate section is devoted to the completed and ongoing standardization work in the field. Afterwards, an extensive comparison of salient features, advantages and disadvantages of all described MAC mechanisms is given in order to guide future protocol designers. Finally, we comment on the most probable future research directions. Based on the presented survey, we observe that QoS provisioning is not only challenging but also a significant contemporary research problem. The protocol designs presented in the literature usually involve trade-offs between certain metrics, and currently there is no ideal solution which deals with all the issues affecting ad-hoc networks. Therefore, we trust that this survey will be of great help to designers of future QoS-aware protocols.","Quality of service,
Ad hoc networks,
Media Access Protocol,
Wireless communication,
Delays,
Media Access Protocol,
Classification"
Tunable Bandpass Filter Design Based on External Quality Factor Tuning and Multiple Mode Resonators for Wideband Applications,"In this paper, a tunable bandpass filter using cross-shaped multiple mode resonators (MMRs) and N:1 transformer based external quality factor tuning structures is proposed. The use of a cross-shaped MMR simplifies inter-resonators control while two Qe tuning structures are investigated and incorporated with the MMR to implement simultaneous center frequency agility and narrow and wide bandwidth tuning. Compared with traditional tunable filters, the proposed architecture requires less tuning elements and is easier to realize wideband and high-order tunable filters. Two examples (Filter I and II) are presented to validate the design. Both filters use a single MMR and six tuning elements to achieve a third-order wideband tunable filter. Filter I reports 58% center frequency tuning with constant bandwidth and 14%-64.4% fractional bandwidth (FBW) tuning when center frequency locates at 1 GHz. Filter II achieves larger frequency agility and wider FBW tuning of 82.9% and 95%, respectively, for the same bandwidth and center frequency of Filter I.","UHF resonators,
band-pass filters,
UHF filters"
Ultrasonic Imaging Transceiver Design for CMUT: A Three-Level 30-Vpp Pulse-Shaping Pulser With Improved Efficiency and a Noise-Optimized Receiver,"This paper demonstrates a four-channel transceiver chip for medical ultrasonic imaging, interfacing to the capacitive micromachined ultrasonic transducers (CMUTs). The high-voltage transmitter (Tx) uses a three-level pulse-shaping technique with charge recycling to improve the power efficiency. The design requires minimum off-chip components and is scalable for more channels. The receiver is implemented with a transimpedance amplifier (TIA) topology and is optimized for tradeoffs between noise, bandwidth, and power dissipation. The test chip is characterized with both acoustic and electrical measurements. Comparing the three-level pulser against traditional two-level pulsers, the measured Tx efficiency shows 56%, 50%, and 43% more acoustic power delivery with the same total power dissipation at 2.5, 3.3, and 5.0 MHz, respectively. The CMUT receiver achieves the lowest noise efficiency factor compared with that of the literature (2.1 compared to a previously reported lowest of 3.6, in units of mPA ·√(mW/Hz). In addition, the transceiver chip is tested as a complete system for medical ultrasound imaging applications, in experiments including Tx beamformation, pulse-echo channel response characterization, and ultrasonic Doppler flow rate detection.","Acoustics,
Noise,
Ultrasonic imaging,
Bandwidth,
Transmitters,
Transducers,
Transceivers"
Frequency Selective Surfaces for Beam-Switching Applications,"A novel design of a beam-switching antenna based on reconfigurable frequency selective surfaces (FSSs) is presented. The antenna is composed of a cylindrical FSS with PIN diodes and divided into six equal sectors by metallic sheets. Metallic cones at the top and bottom of the structure are used to create a directive beam. The antenna is fed by a simple dipole at its center. To switch the radiation pattern of the antenna, the diodes in one FSS-sector are set off to be transparent to the incident EM waves, whereas the diodes in other sectors are on to reflect the incident wave. The direction of the radiation pattern is defined by the off-state sector. In this design, the beam-switching is achieved with only one layer and minimum size of the cylindrical active FSS in order to decrease the number of active elements, and the amount of the power supply. The antenna can sweep the entire azimuth plane with 60° radiation beamwidth in six steps. The fabricated antenna prototype operates from 2.3 GHz to 3 GHz with maximum measured gain of 10 dBi and 3-dB beamwidth of 60°. This antenna can be used in the base station of the wireless communication systems.","Antenna radiation patterns,
Frequency selective surfaces,
Dipole antennas,
Antenna measurements,
Directive antennas,
Switches"
FPGA-Based Predictive Sliding Mode Controller of a Three-Phase Inverter,"This paper proposed a novel predictive variable-structure-switching-based current controller for a three-phase load driven by a power inverter. The design specifications are robustness to load electrical parameters, fast dynamic response, reduced switching frequency, and simple hardware implementation. In order to meet previous specifications, a sliding mode controller has been developed, which is designed as finite-state automata, and implemented with a field-programmable gate array (FPGA) device. The switching strategy implemented within the state transition diagram provides for a minimum number of switches by the three-phase inverter that is confirmed through simulation and experimental results. Its regulation using the proposed control law provides good transient response by the brushless ac motor control. However, this does not limit the wider applicability of the proposed controller that is suitable for different types of ac loads (rectifier and inverter) and ac motors (induction, synchronous, and reluctance). A new logical FPGA torque and speed controller is developed, analyzed, and experimentally verified.",
Stacked Switched Capacitor Energy Buffer Architecture,"Electrolytic capacitors are often used for energy buffering applications, including buffering between single-phase ac and dc. While these capacitors have high energy density compared to film and ceramic capacitors, their life is limited. This paper presents a stacked switched capacitor (SSC) energy buffer architecture and some of its topological embodiments, which when used with longer life film capacitors overcome this limitation while achieving effective energy densities comparable to electrolytic capacitors. The architectural approach is introduced along with design and control techniques. A prototype SSC energy buffer using film capacitors, designed for a 320 V dc bus and able to support a 135 W load, has been built and tested with a power factor correction circuit. It is shown that the SSC energy buffer can successfully replace limited-life electrolytic capacitors with much longer life film capacitors, while maintaining volume and efficiency at a comparable level.","Capacitors,
Switches,
Buffer storage,
Discharges (electric),
Switched capacitor circuits,
Switching circuits,
Prototypes"
Pinning Consensus in Networks of Multiagents via a Single Impulsive Controller,"In this paper, we discuss pinning consensus in networks of multiagents via impulsive controllers. In particular, we consider the case of using only one impulsive controller. We provide a sufficient condition to pin the network to a prescribed value. It is rigorously proven that in case the underlying graph of the network has spanning trees, the network can reach consensus on the prescribed value when the impulsive controller is imposed on the root with appropriate impulsive strength and impulse intervals. Interestingly, we find that the permissible range of the impulsive strength completely depends on the left eigenvector of the graph Laplacian corresponding to the zero eigenvalue and the pinning node we choose. The impulses can be very sparse, with the impulsive intervals being lower bounded. Examples with numerical simulations are also provided to illustrate the theoretical results.","trees (mathematics),
eigenvalues and eigenfunctions,
multi-agent systems"
Transcranial Current Brain Stimulation (tCS): Models and Technologies,"In this paper, we provide a broad overview of models and technologies pertaining to transcranial current brain stimulation (tCS), a family of related noninvasive techniques including direct current (tDCS), alternating current (tACS), and random noise current stimulation (tRNS). These techniques are based on the delivery of weak currents through the scalp (with electrode current intensity to area ratios of about 0.3-5 A/m2) at low frequencies (typically <; 1 kHz) resulting in weak electric fields in the brain (with amplitudes of about 0.2-2 V/m). Here we review the biophysics and simulation of noninvasive, current-controlled generation of electric fields in the human brain and the models for the interaction of these electric fields with neurons, including a survey of in vitro and in vivo related studies. Finally, we outline directions for future fundamental and technological research.","Electrodes,
Electric fields,
Brain models,
Conductivity,
Current density,
Scalp"
Smart Coordination of Energy Storage Units (ESUs) for Voltage and Loading Management in Distribution Networks,"This paper proposes a distributed control approach to coordinate multiple energy storage units (ESUs) to avoid violation of voltage and thermal constraints, which are some of the main power quality challenges for future distribution networks. ESUs usually are connected to a network through voltage source converters. In this paper, both ESU converters active and reactive power are used to deal with the above mentioned power quality issues. ESUs' reactive power is proposed to be used for voltage support, while the active power is to be utilized in managing network loading. Two typical distribution networks are used to apply the proposed method, and the simulated results are illustrated in this paper to show the effectiveness of this approach.","Loading,
Voltage control,
Reactive power,
Decentralized control,
Energy storage,
Sensitivity,
Mathematical model"
Error Performance of Multi-Antenna Receivers in a Poisson Field of Interferers: A Stochastic Geometry Approach,"In this paper, we introduce an analytical framework for performance analysis and design of Single-Input-Multiple-Output (SIMO) wireless systems in the presence of noise, fading, and radio frequency interference produced by randomly distributed active interferers surrounding an intended probe receiver. The framework leverages recent application of stochastic geometry and Poisson Point Processes (PPPs) theory to network interference modeling. To assess the impact of spatial dependence across multiple receive-antennas, three models of network interference are studied: i) the isotropic model, where all receive-antennas see interferers belonging to the same PPP; ii) the independent model, where each receive-antenna sees interferers belonging to an independent PPP; and iii) the mixture model, which is a superposition of isotropic and independent interferences. Depending on the fading distribution of the interferers, the Nakagami-m fading parameter of the probe link, and the number of receive-antennas, either exact or upper-bound formulas of the error probability averaged over noise, fading, and spatial interference are given. Our analysis shows that, depending on the interference model, performance can either improve or get worse with multiple antennas at the receiver. The proposed analytical methodology is applicable to single- and multi-PPPs interference environments.","Interference,
Receivers,
Fading,
Probes,
ISO,
Antennas,
Computational modeling"
Discriminative Nonnegative Spectral Clustering with Out-of-Sample Extension,"Data clustering is one of the fundamental research problems in data mining and machine learning. Most of the existing clustering methods, for example, normalized cut and (k)-means, have been suffering from the fact that their optimization processes normally lead to an NP-hard problem due to the discretization of the elements in the cluster indicator matrix. A practical way to cope with this problem is to relax this constraint to allow the elements to be continuous values. The eigenvalue decomposition can be applied to generate a continuous solution, which has to be further discretized. However, the continuous solution is probably mixing-signed. This result may cause it deviate severely from the true solution, which should be naturally nonnegative. In this paper, we propose a novel clustering algorithm, i.e., discriminative nonnegative spectral clustering, to explicitly impose an additional nonnegative constraint on the cluster indicator matrix to seek for a more interpretable solution. Moreover, we show an effective regularization term which is able to not only provide more useful discriminative information but also learn a mapping function to predict cluster labels for the out-of-sample test data. Extensive experiments on various data sets illustrate the superiority of our proposal compared to the state-of-the-art clustering algorithms.","Clustering algorithms,
Kernel,
Optimization,
Integrated circuits,
Eigenvalues and eigenfunctions,
Educational institutions,
Laplace equations"
Applications and Trends of High Performance Computing for Electric Power Systems: Focusing on Smart Grid,"Over the last 15 years, significant changes have occurred in the areas of electric power systems and high performance computing (HPC). HPC has seen the maturation of cluster computing, the advent of multi-core computing, the creation of grid and cloud computing, and the sudden rise of the graphics processing unit (GPU) for general purpose computing. These changes have also been coupled with the slow ending of Moore's law. Electric power systems have also undergone many changes including the introduction of the advanced metering infrastructure and other advanced technologies for data collection, the inclusion of renewable/distributed power generation, and the addition of electric vehicles as stochastic loads. Clear goals have also been set for the development of the smart grid-a unique cyber-physical system (CPS) that requires the interaction of the electric power system and HPC. As such, this work explores the many ways in which HPC will be used in the smart grid and its CPS in the future including real-time and off-line analysis, data mining/storage, intelligent coordination, security, simulation, and visualization.","Smart grids,
Reliability,
Real-time systems,
Graphics processing units,
Security"
Canadian Experiment for Soil Moisture in 2010 (CanEx-SM10): Overview and Preliminary Results,"The Canadian Experiment for Soil Moisture in 2010 (CanEx-SM10) was carried out in Saskatchewan, Canada, from 31 May to 16 June, 2010. Its main objective was to contribute to Soil Moisture and Ocean Salinity (SMOS) mission validation and the prelaunch assessment of the proposed Soil Moisture Active and Passive (SMAP) mission. During CanEx-SM10, SMOS data as well as other passive and active microwave measurements were collected by both airborne and satellite platforms. Ground-based measurements of soil (moisture, temperature, roughness, bulk density) and vegetation characteristics (leaf area index, biomass, vegetation height) were conducted close in time to the airborne and satellite acquisitions. Moreover, two ground-based in situ networks provided continuous measurements of meteorological conditions and soil moisture and soil temperature profiles. Two sites, each covering 33 km × 71 km (about two SMOS pixels) were selected in agricultural and boreal forested areas in order to provide contrasting soil and vegetation conditions. This paper describes the measurement strategy, provides an overview of the data sets, and presents preliminary results. Over the agricultural area, the airborne L-band brightness temperatures matched up well with the SMOS data (prototype 346). The radio frequency interference observed in both SMOS and the airborne L-band radiometer data exhibited spatial and temporal variability and polarization dependency. The temporal evolution of the SMOS soil moisture product (prototype 307) matched that observed with the ground data, but the absolute soil moisture estimates did not meet the accuracy requirements (0.04 m3/m3) of the SMOS mission. AMSR-E soil moisture estimates from the National Snow and Ice Data Center more closely reflected soil moisture measurements.","Soil moisture,
Soil measurements,
Temperature measurement,
Satellites,
Vegetation mapping,
Moisture measurement"
CAM: Cloud-Assisted Privacy Preserving Mobile Health Monitoring,"Cloud-assisted mobile health (mHealth) monitoring, which applies the prevailing mobile communications and cloud computing technologies to provide feedback decision support, has been considered as a revolutionary approach to improving the quality of healthcare service while lowering the healthcare cost. Unfortunately, it also poses a serious risk on both clients' privacy and intellectual property of monitoring service providers, which could deter the wide adoption of mHealth technology. This paper is to address this important problem and design a cloud-assisted privacy preserving mobile health monitoring system to protect the privacy of the involved parties and their data. Moreover, the outsourcing decryption technique and a newly proposed key private proxy reencryption are adapted to shift the computational complexity of the involved parties to the cloud without compromising clients' privacy and service providers' intellectual property. Finally, our security and performance analysis demonstrates the effectiveness of our proposed design.","Monitoring,
Cryptography,
Privacy,
Computer aided manufacturing,
Companies,
Medical services,
Vectors"
On the Vital Areas of Intrusion Detection Systems in Wireless Sensor Networks,"This paper surveys recently proposed works on Intrusion Detection Systems (IDS) in WSNs, and presents a comprehensive classification of various IDS approaches according to their employed detection techniques. The three main categories explored in this paper are anomaly detection, misuse detection, and specification-based detection protocols. We give a description of existing security attacks in WSNs and the corresponding proposed IDS protocols to tackle those attacks. We analyze the works with respect to the network structure of WSNs. In addition, we highlight various critical shortcomings that IDSs currently have and define future research tracks for IDSs in wireless sensor networks. Though a few restricted survey works on this topic have already been done, we feel that there is a great need of performing a detailed and comprehensive study on the vital aspects so that the IDS in WSN could be analyzed from all the `need-to-know' angles. Thus, the paper's main aim is to include the most recent advancements in this area as well as to predict the future course of research so that the general as well as expert readers could be greatly benefited.","Wireless sensor networks,
Intrusion detection,
Computer crime,
Monitoring,
Base stations,
Delays"
Bilinear Modeling of EMG Signals to Extract User-Independent Features for Multiuser Myoelectric Interface,"In this study, we propose a multiuser myoelectric interface that can easily adapt to novel users. When a user performs different motions (e.g., grasping and pinching), different electromyography (EMG) signals are measured. When different users perform the same motion (e.g., grasping), different EMG signals are also measured. Therefore, designing a myoelectric interface that can be used by multiple users to perform multiple motions is difficult. To cope with this problem, we propose for EMG signals a bilinear model that is composed of two linear factors:1) user dependent and 2) motion dependent. By decomposing the EMG signals into these two factors, the extracted motion-dependent factors can be used as user-independent features. We can construct a motion classifier on the extracted feature space to develop the multiuser interface. For novel users, the proposed adaptation method estimates the user-dependent factor through only a few interactions. The bilinear EMG model with the estimated user-dependent factor can extract the user-independent features from the novel user data. We applied our proposed method to a recognition task of five hand gestures for robotic hand control using four-channel EMG signals measured from subject forearms. Our method resulted in 73% accuracy, which was statistically significantly different from the accuracy of standard non-multiuser interfaces, as the result of a two-sample t-test at a significance level of 1%.","Electromyography,
Feature extraction,
Adaptation models,
Accuracy,
Support vector machines,
Data models,
Robots"
Denoising MR Spectroscopic Imaging Data With Low-Rank Approximations,"This paper addresses the denoising problem associated with magnetic resonance spectroscopic imaging (MRSI), where signal-to-noise ratio (SNR) has been a critical problem. A new scheme is proposed, which exploits two low-rank structures that exist in MRSI data, one due to partial separability and the other due to linear predictability. Denoising is performed by arranging the measured data in appropriate matrix forms (i.e., Casorati and Hankel) and applying low-rank approximations by singular value decomposition (SVD). The proposed method has been validated using simulated and experimental data, producing encouraging results. Specifically, the method can effectively denoise MRSI data in a wide range of SNR values while preserving spatial-spectral features. The method could prove useful for denoising MRSI data and other spatial-spectral and spatial-temporal imaging data as well.","Signal to noise ratio,
Noise reduction,
Approximation methods,
Noise measurement,
Data models,
Noise level"
Bad Data Injection Attack and Defense in Electricity Market Using Game Theory Study,"Applications of cyber technologies improve the quality of monitoring and decision making in smart grid. These cyber technologies are vulnerable to malicious attacks, and compromising them can have serious technical and economical problems. This paper specifies the effect of compromising each measurement on the price of electricity, so that the attacker is able to change the prices in the desired direction (increasing or decreasing). Attacking and defending all measurements are impossible for the attacker and defender, respectively. This situation is modeled as a zero-sum game between the attacker and defender. The game defines the proportion of times that the attacker and defender like to attack and defend different measurements, respectively. From the simulation results based on the PJM 5-Bus test system, we can show the effectiveness and properties of the studied game.","Transmission line measurements,
Games,
Smart grids,
Electricity,
Real-time systems,
Game theory,
Vectors"
GPU Computing for Parallel Local Search Metaheuristic Algorithms,"Local search metaheuristics (LSMs) are efficient methods for solving complex problems in science and industry. They allow significantly to reduce the size of the search space to be explored and the search time. Nevertheless, the resolution time remains prohibitive when dealing with large problem instances. Therefore, the use of GPU-based massively parallel computing is a major complementary way to speed up the search. However, GPU computing for LSMs is rarely investigated in the literature. In this paper, we introduce a new guideline for the design and implementation of effective LSMs on GPU. Very efficient approaches are proposed for CPU-GPU data transfer optimization, thread control, mapping of neighboring solutions to GPU threads, and memory management. These approaches have been experimented using four well-known combinatorial and continuous optimization problems and four GPU configurations. Compared to a CPU-based execution, accelerations up to \times 80 are reported for the large combinatorial problems and up to \times 240 for a continuous problem. Finally, extensive experiments demonstrate the strong potential of GPU-based LSMs compared to cluster or grid-based parallel architectures.","Graphics processing unit,
Instruction sets,
Encoding,
Optimization,
Computer architecture,
Parallel processing,
Search problems"
"Silicon Photonic Microring Links for High-Bandwidth-Density, Low-Power Chip I/O",Silicon photonic microrings have drawn interest in recent years as potential building blocks for high-bandwidth off-chip communication links. The authors analyze a terabit-per-second scale unamplified microring link based on current best-of-class devices. The analysis provides quantitative measures for the achievable energy efficiency and bandwidth density that could be realized within several years. The results highlight key device attributes that require significant advancement to realize sub-pJ/bit scale optical links.,
MRF-Based Deformable Registration and Ventilation Estimation of Lung CT,"Deformable image registration is an important tool in medical image analysis. In the case of lung computed tomography (CT) registration there are three major challenges: large motion of small features, sliding motions between organs, and changing image contrast due to compression. Recently, Markov random field (MRF)-based discrete optimization strategies have been proposed to overcome problems involved with continuous optimization for registration, in particular its susceptibility to local minima. However, to date the simplifications made to obtain tractable computational complexity reduced the registration accuracy. We address these challenges and preserve the potentially higher quality of discrete approaches with three novel contributions. First, we use an image-derived minimum spanning tree as a simplified graph structure, which copes well with the complex sliding motion and allows us to find the global optimum very efficiently. Second, a stochastic sampling approach for the similarity cost between images is introduced within a symmetric, diffeomorphic B-spline transformation model with diffusion regularization. The complexity is reduced by orders of magnitude and enables the minimization of much larger label spaces. In addition to the geometric transform labels, hyper-labels are introduced, which represent local intensity variations in this task, and allow for the direct estimation of lung ventilation. We validate the improvements in accuracy and performance on exhale-inhale CT volume pairs using a large number of expert landmarks.","Lungs,
Optimization,
Ventilation,
Splines (mathematics),
Computed tomography,
Accuracy,
Message passing"
KNN Matting,"This paper proposes to apply the nonlocal principle to general alpha matting for the simultaneous extraction of multiple image layers; each layer may have disjoint as well as coherent segments typical of foreground mattes in natural image matting. The estimated alphas also satisfy the summation constraint. As in nonlocal matting, our approach does not assume the local color-line model and does not require sophisticated sampling or learning strategies. On the other hand, our matting method generalizes well to any color or feature space in any dimension, any number of alphas and layers at a pixel beyond two, and comes with an arguably simpler implementation, which we have made publicly available. Our matting technique, aptly called KNN matting, capitalizes on the nonlocal principle by using K nearest neighbors (KNN) in matching nonlocal neighborhoods, and contributes a simple and fast algorithm that produces competitive results with sparse user markups. KNN matting has a closed-form solution that can leverage the preconditioned conjugate gradient method to produce an efficient implementation. Experimental evaluation on benchmark datasets indicates that our matting results are comparable to or of higher quality than state-of-the-art methods requiring more involved implementation. In this paper, we take the nonlocal principle beyond alpha estimation and extract overlapping image layers using the same Laplacian framework. Given the alpha value, our closed form solution can be elegantly generalized to solve the multilayer extraction problem. We perform qualitative and quantitative comparisons to demonstrate the accuracy of the extracted image layers.","Kernel,
Laplace equations,
Image color analysis,
Materials,
Vectors,
Mathematical model,
Image segmentation"
Evaluation of 600 V cascode GaN HEMT in device characterization and all-GaN-based LLC resonant converter,"In recent years, Si power MOSFET is approaching its performance limits, and Gallium Nitride (GaN) HEMT is getting mature. This paper evaluates the 600 V cascode GaN HEMT performance, and compares it with the state-of-the-art Si CoolMOS in LLC resonant converter. First, the static characterization of 600 V cascode GaN HEMT is described in different temperatures. The switching performance is tested by a double pulse tester to provide the turn-off loss reference to the design of LLC resonant converter. Second, a 400 V-12 V/300 W/1 MHz all-GaN-based converter with the 600 V cascode GaN HEMT is compared with a Si-based converter with the 600 V Si CoolMOS. The device output capacitance is a key factor in the design and loss analysis of LLC resonant converter. The design results show that the total GaN device loss of the all-GaN-based converter can be improved by 42% compared with the total Si device loss. Finally, both 400 V-12 V/300 W/1 MHz Si-based and GaN-based LLC resonant converter prototypes are tested and compared with waveforms and efficiency curves.","Gallium nitride,
HEMTs,
Silicon,
Capacitance,
Switches,
Logic gates,
MOSFET"
Toward Optimal Deployment of Cloud-Assisted Video Distribution Services,"For Internet video services, the high fluctuation of user demands in geographically distributed regions results in low resource utilizations of traditional content distribution network systems. Due to the capability of rapid and elastic resource provisioning, cloud computing emerges as a new paradigm to reshape the model of video distribution over the Internet, in which resources (such as bandwidth, storage) can be rented on demand from cloud data centers to meet volatile user demands. However, it is challenging for a video service provider (VSP) to optimally deploy its distribution infrastructure over multiple geo-distributed cloud data centers. A VSP needs to minimize the operational cost induced by the rentals of cloud resources without sacrificing user experience in all regions. The geographical diversity of cloud resource prices further makes the problem complicated. In this paper, we investigate the optimal deployment problem of cloud-assisted video distribution services and explore the best tradeoff between the operational cost and the user experience. We aim to pave the way for building the next-generation video cloud. Toward this objective, we first formulate the deployment problem into a min-cost network flow problem, which takes both the operational cost and the user experience into account. Then, we apply the Nash bargaining solution to solve the joint optimization problem efficiently and derive the optimal bandwidth provisioning strategy and optimal video placement strategy. In addition, we extend the algorithms to the online case and consider the scenario when peers participate into video distribution. Finally, we conduct extensive simulations to evaluate our algorithms in the realistic settings. Our results show that our proposed algorithms can achieve a good balance among multiple objectives and effectively optimize both operational cost and user experience.","video streaming,
bandwidth allocation,
cloud computing,
game theory,
multimedia systems"
TrPF: A Trajectory Privacy-Preserving Framework for Participatory Sensing,"The ubiquity of the various cheap embedded sensors on mobile devices, for example cameras, microphones, accelerometers, and so on, is enabling the emergence of participatory sensing applications. While participatory sensing can benefit the individuals and communities greatly, the collection and analysis of the participators' location and trajectory data may jeopardize their privacy. However, the existing proposals mostly focus on participators' location privacy, and few are done on participators' trajectory privacy. The effective analysis on trajectories that contain spatial-temporal history information will reveal participators' whereabouts and the relevant personal privacy. In this paper, we propose a trajectory privacy-preserving framework, named TrPF, for participatory sensing. Based on the framework, we improve the theoretical mix-zones model with considering the time factor from the perspective of graph theory. Finally, we analyze the threat models with different background knowledge and evaluate the effectiveness of our proposal on the basis of information entropy, and then compare the performance of our proposal with previous trajectory privacy protections. The analysis and simulation results prove that our proposal can protect participators' trajectories privacy effectively with lower information loss and costs than what is afforded by the other proposals.","Trajectory,
Privacy,
Sensors,
Data privacy,
Servers,
Proposals,
Graph theory"
Distributed Control of Coordinated Path Tracking for Networked Nonholonomic Mobile Vehicles,"This paper addresses the problem of coordinated path tracking for networked nonholonomic mobile vehicles, while building and keeping a desired formation. The control laws proposed are categorized into two envelopes by integrating individual path tracking and global virtual structure approaches. One is steering individual vehicles to track virtual vehicles moving along predefined paths, generated by a formation reference vehicle (FRV) of a time-varying desired virtual structure. The other is ensuring paths to be well tracked in order to build a geometric formation, through the distributed feedback law for path parameters related to the virtual vehicles, such that the physical vehicles are on the desired placements of the formation structure. Within this framework, geometric path tracking is achieved via nonlinear control theory, where an approaching angle is injected as a heading guidance design. The distributed feedback law is analyzed under communication constraints using algebraic graph theory. It is formally shown that the path tracking error of each vehicle is reduced to zero, and vehicles in the networked team globally asymptotically converge to a desired formation with equal path parameters. Simulation results illustrate the effectiveness of the proposed control design.",
Local Transform Features and Hybridization for Accurate Face and Human Detection,"We propose two novel local transform features: local gradient patterns (LGP) and binary histograms of oriented gradients (BHOG). LGP assigns one if the neighboring gradient of a given pixel is greater than its average of eight neighboring gradients and zero otherwise, which makes the local intensity variations along the edge components robust. BHOG assigns one if the histogram bin has a higher value than the average value of the total histogram bins, and zero otherwise, which makes the computation time fast due to no further postprocessing and SVM classification. We also propose a hybrid feature that combines several local transform features by means of the AdaBoost method, where the best feature having the lowest classification error is sequentially selected until we obtain the required classification performance. This hybridization makes face and human detection robust to global illumination changes by LBP, local intensity changes by LGP, and local pose changes by BHOG, which considerably improves detection performance. We apply the proposed features to face detection using the MIT+CMU and FDDB databases and human detection using the INRIA and Caltech databases. Our experimental results indicate that the proposed LGP and BHOG feature attain accurate detection performance and fast computation time, respectively, and the hybrid feature improves face and human detection performance considerably.","Transforms,
Face,
Feature extraction,
Histograms,
Humans,
Robustness,
Face recognition"
User Authentication Through Mouse Dynamics,"Behavior-based user authentication with pointing devices, such as mice or touchpads, has been gaining attention. As an emerging behavioral biometric, mouse dynamics aims to address the authentication problem by verifying computer users on the basis of their mouse operating styles. This paper presents a simple and efficient user authentication approach based on a fixed mouse-operation task. For each sample of the mouse-operation task, both traditional holistic features and newly defined procedural features are extracted for accurate and fine-grained characterization of a user's unique mouse behavior. Distance-measurement and eigenspace-transformation techniques are applied to obtain feature components for efficiently representing the original mouse feature space. Then a one-class learning algorithm is employed in the distance-based feature eigenspace for the authentication task. The approach is evaluated on a dataset of 5550 mouse-operation samples from 37 subjects. Extensive experimental results are included to demonstrate the efficacy of the proposed approach, which achieves a false-acceptance rate of 8.74%, and a false-rejection rate of 7.69% with a corresponding authentication time of 11.8 seconds. Two additional experiments are provided to compare the current approach with other approaches in the literature. Our dataset is publicly available to facilitate future research.","Computer peripherals,
Authentication,
Feature extraction,
Biometrics (access control),
Learning (artificial intelligence)"
Weighted Fuzzy Spiking Neural P Systems,"Spiking neural P systems (SN P systems) are a new class of computing models inspired by the neurophysiological behavior of biological spiking neurons. In order to make SN P systems capable of representing and processing fuzzy and uncertain knowledge, we propose a new class of spiking neural P systems in this paper called weighted fuzzy spiking neural P systems (WFSN P systems). New elements, including fuzzy truth value, certain factor, weighted fuzzy logic, output weight, threshold, new firing rule, and two types of neurons, are added to the original definition of SN P systems. This allows WFSN P systems to adequately characterize the features of weighted fuzzy production rules in a fuzzy rule-based system. Furthermore, a weighted fuzzy backward reasoning algorithm, based on WFSN P systems, is developed, which can accomplish dynamic fuzzy reasoning of a rule-based system more flexibly and intelligently. In addition, we compare the proposed WFSN P systems with other knowledge representation methods, such as fuzzy production rule, conceptual graph, and Petri nets, to demonstrate the features and advantages of the proposed techniques.",
Error Recovery in Cyberphysical Digital Microfluidic Biochips,"Droplet-based digital microfluidics technology has now come of age, and software-controlled biochips for healthcare applications are starting to emerge. However, today's digital microfluidic biochips suffer from the drawback that there is no feedback to the control software from the underlying hardware platform. Due to the lack of precision inherent in biochemical experiments, errors are likely during droplet manipulation; error recovery based on the repetition of experiments leads to wastage of expensive reagents and hard-to-prepare samples. By exploiting recent advances in the integration of optical detectors (sensors) into a digital microfluidics biochip, we present a physical-aware system reconfiguration technique that uses sensor data at intermediate checkpoints to dynamically reconfigure the biochip. A cyberphysical resynthesis technique is used to recompute electrode-actuation sequences, thereby deriving new schedules, module placement, and droplet routing pathways, with minimum impact on the time-to-response.","Electrodes,
Software,
Optical sensors,
Correlation,
Arrays,
System-on-a-chip"
Flip-Invariant SIFT for Copy and Object Detection,"Scale-invariant feature transform (SIFT) feature has been widely accepted as an effective local keypoint descriptor for its invariance to rotation, scale, and lighting changes in images. However, it is also well known that SIFT, which is derived from directionally sensitive gradient fields, is not flip invariant. In real-world applications, flip or flip-like transformations are commonly observed in images due to artificial flipping, opposite capturing viewpoint, or symmetric patterns of objects. This paper proposes a new descriptor, named flip-invariant SIFT (or F-SIFT), that preserves the original properties of SIFT while being tolerant to flips. F-SIFT starts by estimating the dominant curl of a local patch and then geometrically normalizes the patch by flipping before the computation of SIFT. We demonstrate the power of F-SIFT on three tasks: large-scale video copy detection, object recognition, and detection. In copy detection, a framework, which smartly indices the flip properties of F-SIFT for rapid filtering and weak geometric checking, is proposed. F-SIFT not only significantly improves the detection accuracy of SIFT, but also leads to a more than 50% savings in computational cost. In object recognition, we demonstrate the superiority of F-SIFT in dealing with flip transformation by comparing it to seven other descriptors. In object detection, we further show the ability of F-SIFT in describing symmetric objects. Consistent improvement across different kinds of keypoint detectors is observed for F-SIFT over the original SIFT.","Detectors,
Feature extraction,
Object detection,
Clocks,
Histograms,
Vectors,
Object recognition"
Intelligent Video Systems and Analytics: A Survey,"Recent technology and market trends have demanded the significant need for feasible solutions to video/camera systems and analytics. This paper provides a comprehensive account on theory and application of intelligent video systems and analytics. It highlights the video system architectures, tasks, and related analytic methods. It clearly demonstrates that the importance of the role that intelligent video systems and analytics play can be found in a variety of domains such as transportation and surveillance. Research directions are outlined with a focus on what is essential to achieve the goals of intelligent video systems and analytics.","Cameras,
Streaming media,
Artificial intelligence,
Real-time systems,
Surveillance,
Target tracking"
Additive White Gaussian Noise Level Estimation in SVD Domain for Images,"Accurate estimation of Gaussian noise level is of fundamental interest in a wide variety of vision and image processing applications as it is critical to the processing techniques that follow. In this paper, a new effective noise level estimation method is proposed on the basis of the study of singular values of noise-corrupted images. Two novel aspects of this paper address the major challenges in noise estimation: 1) the use of the tail of singular values for noise estimation to alleviate the influence of the signal on the data basis for the noise estimation process and 2) the addition of known noise to estimate the content-dependent parameter, so that the proposed scheme is adaptive to visual signals, thereby enabling a wider application scope of the proposed scheme. The analysis and experiment results demonstrate that the proposed algorithm can reliably infer noise levels and show robust behavior over a wide range of visual content and noise conditions, and that is outperforms relevant existing methods.","Estimation,
Noise level,
AWGN,
Standards,
Low pass filters,
Tin"
A New Method for Lower Bounds on the Running Time of Evolutionary Algorithms,"In this paper a new method for proving lower bounds on the expected running time of evolutionary algorithms (EAs) is presented. It is based on fitness-level partitions and an additional condition on transition probabilities between fitness levels. The method is versatile, intuitive, elegant, and very powerful. It yields exact or near-exact lower bounds for LO, OneMax, long k-paths, and all functions with a unique optimum. Most lower bounds are very general; they hold for all EAs that only use bit-flip mutation as variation operator, i.e., for all selection operators and population models. The lower bounds are stated with their dependence on the mutation rate. These results have very strong implications. They allow us to determine the optimal mutation-based algorithm for LO and OneMax, i.e., the algorithm that minimizes the expected number of fitness evaluations. This includes the choice of the optimal mutation rate.","Upper bound,
Algorithm design and analysis,
Evolutionary computation,
Optimization,
Partitioning algorithms,
Viscosity,
Polynomials"
Magnetostimulation Limits in Magnetic Particle Imaging,"For magnetic particle imaging (MPI), specific absorption rate (SAR) and more critically magnetostimulation (i.e., dB/dt) safety limits will determine the optimal scan parameters, such as the drive field strength and frequency. These parameters will impact the scanning speed, field-of-view (FOV) and signal-to-noise ratio in MPI. Understanding the potential safety hazards of the drive field is critical for scaling MPI for human use. In this work, we demonstrate that magnetostimulation is the primary magnetic safety consideration in MPI, and we describe the first human-subject magnetostimulation threshold experiments for MPI using homogeneous coils. Our experiments, performed on the arm and leg, indicate that magnetostimulation thresholds monotonically decrease with increasing frequency. Additionally, we show for the first time that a strong inverse correlation exists between the threshold and the body part size. The chronaxie time, on the other hand, did not vary with body part size. We conclude with an estimation of the magnetostimulation thresholds for a full-body MPI scanner: a mean asymptotic threshold of 14.3 mT-pp (peak-to-peak) with a mean chronaxie time of 289 μs, which correspond to a magnetostimulation threshold of about 15 mT-pp for frequencies between 25 and 50 kHz. These findings will have a great impact on the optimization of MPI parameters, especially in determining the number of partial FOVs required to cover a region of interest.","Magnetic resonance imaging,
Safety,
Coils,
Solenoids,
Muscles,
Signal to noise ratio"
General and Interval Type-2 Fuzzy Face-Space Approach to Emotion Recognition,"Facial expressions of a person representing similar emotion are not always unique. Naturally, the facial features of a subject taken from different instances of the same emotion have wide variations. In the presence of two or more facial features, the variation of the attributes together makes the emotion recognition problem more complicated. This variation is the main source of uncertainty in the emotion recognition problem, which has been addressed here in two steps using type-2 fuzzy sets. First a type-2 fuzzy face space is constructed with the background knowledge of facial features of different subjects for different emotions. Second, the emotion of an unknown facial expression is determined based on the consensus of the measured facial features with the fuzzy face space. Both interval and general type-2 fuzzy sets (GT2FS) have been used separately to model the fuzzy face space. The interval type-2 fuzzy set (IT2FS) involves primary membership functions for m facial features obtained from n-subjects, each having l-instances of facial expressions for a given emotion. The GT2FS in addition to employing the primary membership functions mentioned above also involves the secondary memberships for individual primary membership curve, which has been obtained here by formulating and solving an optimization problem. The optimization problem here attempts to minimize the difference between two decoded signals: the first one being the type-1 defuzzification of the average primary membership functions obtained from the n-subjects, while the second one refers to the type-2 defuzzified signal for a given primary membership function with secondary memberships as unknown. The uncertainty management policy adopted using GT2FS has resulted in a classification accuracy of 98.333% in comparison to 91.667% obtained by its interval type-2 counterpart. A small improvement (approximately 2.5%) in classification accuracy by IT2FS has been attained by pre-processing measurements using the well-known interval approach.","Uncertainty,
Emotion recognition,
Fuzzy sets,
Facial features,
Face,
Feature extraction,
Measurement uncertainty"
Local graph coloring and index coding,We present a novel upper bound for the optimal index coding rate. Our bound uses a graph theoretic quantity called the local chromatic number. We show how a good local coloring can be used to create a good index code. The local coloring is used as an alignment guide to assign index coding vectors from a general position MDS code. We further show that a natural LP relaxation yields an even stronger index code. Our bounds provably outperform the state of the art on index coding but at most by a constant factor.,"Indexes,
Color,
Interference,
Vectors,
Channel coding"
Real-World Neuroimaging Technologies,"Decades of heavy investment in laboratory-based brain imaging and neuroscience have led to foundational insights into how humans sense, perceive, and interact with the external world. However, it is argued that fundamental differences between laboratory-based and naturalistic human behavior may exist. Thus, it remains unclear how well the current knowledge of human brain function translates into the highly dynamic real world. While some demonstrated successes in real-world neurotechnologies are observed, particularly in the area of brain-computer interaction technologies, innovations and developments to date are limited to a small science and technology community. We posit that advancements in realworld neuroimaging tools for use by a broad-based workforce will dramatically enhance neurotechnology applications that have the potential to radically alter human-system interactions across all aspects of everyday life. We discuss the efforts of a joint government-academic-industry team to take an integrative, interdisciplinary, and multi-aspect approach to translate current technologies into devices that are truly fieldable across a range of environments. Results from initial work, described here, show promise for dramatic advances in the field that will rapidly enhance our ability to assess brain activity in real-world scenarios.","Neuroimaging,
Wearable sensors,
Electroencephalography,
Neuroscience,
Research and development,
Medical image processing,
Biomedical monitoring,
Maximum likelihood decoding,
Brain modeling,
Behavioral science,
Investments,
Brain-computer interfaces"
Modeling Cyber-Physical Vulnerability of the Smart Grid With Incomplete Information,"This paper addresses the attack modeling using vulnerability of information, communication and electric grid network. Vulnerability of electric grid with incomplete information has been analyzed using graph theory based approach. Vulnerability of information and communication (cyber) network has been modeled utilizing concepts of discovery, access, feasibility, communication speed and detection threat. Common attack vector based on vulnerability of cyber and physical system have been utilized to operate breakers associated with generating resources to model aurora-like event. Real time simulations for modified IEEE 14 bus test case system and graph theory analysis for IEEE 118 bus system have been presented. Test case results show the possible impact on smart grid caused by integrated cyber-physical attack.","Generators,
Relays,
Smart grids,
Topology,
Indexes,
Security"
Real-Time Scheduling of Distributed Resources,"We develop and analyze real-time scheduling algorithms for coordinated aggregation of deferrable loads and storage. These distributed resources offer flexibility that can enable the integration of renewable generation by reducing reserve costs. We present three scheduling policies: earliest deadline first (EDF), least laxity first (LLF), and receding horizon control (RHC). We offer a novel cost metric for RHC-based scheduling that explicitly accounts for reserve costs. We study the performance of these algorithms in the metrics of reserve energy and capacity through simulation studies. We conclude that the benefits of coordinated aggregation can be realized from modest levels of both deferrable load participation and flexibility.","Optimal scheduling,
Processor scheduling,
Resource management,
Real-time systems,
Load modeling,
Measurement"
From K-Means to Higher-Way Co-Clustering: Multilinear Decomposition With Sparse Latent Factors,"Co-clustering is a generalization of unsupervised clustering that has recently drawn renewed attention, driven by emerging data mining applications in diverse areas. Whereas clustering groups entire columns of a data matrix, co-clustering groups columns over select rows only, i.e., it simultaneously groups rows and columns. The concept generalizes to data “boxes” and higher-way tensors, for simultaneous grouping along multiple modes. Various co-clustering formulations have been proposed, but no workhorse analogous to K-means has emerged. This paper starts from K-means and shows how co-clustering can be formulated as a constrained multilinear decomposition with sparse latent factors. For three- and higher-way data, uniqueness of the multilinear decomposition implies that, unlike matrix co-clustering, it is possible to unravel a large number of possibly overlapping co-clusters. A basic multi-way co-clustering algorithm is proposed that exploits multilinearity using Lasso-type coordinate updates. Various line search schemes are then introduced to speed up convergence, and suitable modifications are proposed to deal with missing values. The imposition of latent sparsity pays a collateral dividend: it turns out that sequentially extracting one co-cluster at a time is almost optimal, hence the approach scales well for large datasets. The resulting algorithms are benchmarked against the state-of-art in pertinent simulations, and applied to measured data, including the ENRON e-mail corpus.","Vectors,
Arrays,
Signal processing algorithms,
Matrix decomposition,
Educational institutions,
Sparse matrices,
Convergence"
Subthreshold Behavior Models for Nanoscale Short-Channel Junctionless Cylindrical Surrounding-Gate MOSFETs,"With the exact solution of the 2-D Poisson's equation in cylindrical coordinates, analytical subthreshold behavior models for junctionless cylindrical surrounding-gate (JLCSG) MOSFETs are developed. Using these analytical models, subthreshold characteristics of JLCSG MOSFETs are investigated in terms of channel electrostatic potential distribution, subthreshold current, and subthreshold slope (SS). It is shown that the electrostatic potential distribution, subthreshold current, and SS predicted by the analytical models are in close agreement with 3-D numerical simulation results without the need of any fitting parameters. These analytical models not only provide useful physical insight into the subthreshold behaviors, but also offer basic design guideline for the nanoscale JLCSG MOSFETs.","Electric potential,
Electrostatics,
Analytical models,
MOSFET,
Mathematical model,
Subthreshold current"
Network Coding Meets Multimedia: A Review,"While every network node only relays messages in a traditional communication system, the recent network coding (NC) paradigm proposes to implement simple in-network processing with packet combinations in the nodes. NC extends the concept of “encoding” a message beyond source coding (for compression) and channel coding (for protection against errors and losses). It has been shown to increase network throughput compared to traditional networks implementation, to reduce delay and to provide robustness to transmission errors and network dynamics. These features are so appealing for multimedia applications that they have spurred a large research effort towards the development of multimedia-specific NC techniques. This paper reviews the recent work in NC for multimedia applications and focuses on the techniques that fill the gap between NC theory and practical applications. It outlines the benefits of NC and presents the open challenges in this area. The paper initially focuses on multimedia-specific aspects of network coding, in particular delay, in-network error control, and media-specific error control. These aspects permit to handle varying network conditions as well as client heterogeneity, which are critical to the design and deployment of multimedia systems. After introducing these general concepts, the paper reviews in detail two applications that lend themselves naturally to NC via the cooperation and broadcast models, namely peer-to-peer multimedia streaming and wireless networking.","Multimedia communication,
Peer to peer computing,
Network coding,
Delay,
Streaming media,
Wireless communication"
Privacy-preserving data aggregation without secure channel: Multivariate polynomial evaluation,"Much research has been conducted to securely outsource multiple parties' data aggregation to an untrusted aggregator without disclosing each individual's privately owned data, or to enable multiple parties to jointly aggregate their data while preserving privacy. However, those works either require secure pair-wise communication channels or suffer from high complexity. In this paper, we consider how an external aggregator or multiple parties can learn some algebraic statistics (e.g., sum, product) over participants' privately owned data while preserving the data privacy. We assume all channels are subject to eavesdropping attacks, and all the communications throughout the aggregation are open to others. We propose several protocols that successfully guarantee data privacy under this weak assumption while limiting both the communication and computation complexity of each participant to a small constant.","Protocols,
Computational modeling,
Polynomials,
Communication channels,
Complexity theory,
Cryptography"
SPRING: A Strategy-proof and Privacy preserving spectrum auction mechanism,"The problem of dynamic spectrum redistribution has been extensively studied in recent years. Auction is believed to be one of the most effective tools to solve this problem. A great number of strategy-proof auction mechanisms have been proposed to improve spectrum allocation efficiency by stimulating bidders to truthfully reveal their valuations of spectrum, which are the private information of bidders. However, none of these approaches protects bidders' privacy. In this paper, we present SPRING, which is the first Strategy-proof and PRivacy preservING spectrum auction mechanism. We not only rigorously prove the properties of SPRING, but also extensively evaluate its performance. Our evaluation results show that SPRING achieves good spectrum redistribution efficiency with low overhead.","Privacy,
Springs,
Resource management,
Encryption,
Cost accounting,
Interference"
Study of Random Dopant Fluctuation Induced Variability in the Raised-Ge-Source TFET,"The impact of random dopant fluctuations (RDF) on the performance of an optimized TFET design comprising a raised germanium (Ge) source region is investigated via 3-D TCAD simulation. The RDF within the source region results in degraded subthreshold swing and lower turn-on voltage for the raised-Ge-source TFET design. In addition, drain-induced barrier tunneling is mitigated with the raised source design. An optimized raised-Ge-source TFET is projected to provide for lower energy operation at frequencies up to 500 MHz when compared with an ideal MOSFET.","Resource description framework,
Tunneling,
Transistors,
MOSFET circuits,
Logic gates,
Semiconductor process modeling,
Doping"
APT: Accurate outdoor pedestrian tracking with smartphones,"This paper presents APT, a localization system for outdoor pedestrians with smartphones. APT performs better than the built-in GPS module of the smartphone in terms of accuracy. This is achieved by introducing a robust dead reckoning algorithm and an error-tolerant algorithm for map matching. When the user is walking with the smartphone, the dead reckoning algorithm monitors steps and walking direction in real time. It then reports new steps and turns to the map-matching algorithm. Based on updated information, this algorithm adjusts the user's location on a map in an error-tolerant manner. If location ambiguity among several routes occurs after adjustments, the GPS module is queried to help eliminate this ambiguity. Evaluations in practice show that the error of our system is less than 1/2 that of GPS.","Global Positioning System,
Dead reckoning,
Smart phones,
Acceleration,
Accuracy,
Gyroscopes,
Legged locomotion"
Updating Land-Cover Maps by Classification of Image Time Series: A Novel Change-Detection-Driven Transfer Learning Approach,"This paper proposes a novel change-detection-driven transfer learning (TL) approach to update land-cover maps by classifying remote-sensing images acquired on the same area at different times (i.e., image time series). The proposed approach requires that a reliable training set is available only for one of the images (i.e., the source domain) in the time series whereas it is not for another image to be classified (i.e., the target domain). Unlike other literature TL methods, no additional assumptions on either the similarity between class distributions or the presence of the same set of land-cover classes in the two domains are required. The proposed method aims at defining a reliable training set for the target domain, taking advantage of the already available knowledge on the source domain. This is done by applying an unsupervised-change-detection method to target and source domains and transferring class labels of detected unchanged training samples from the source to the target domain to initialize the target-domain training set. The training set is then optimized by a properly defined novel active learning (AL) procedure. At the early iterations of AL, priority in labeling is given to samples detected as being changed, whereas in the remaining ones, the most informative samples are selected from changed and unchanged unlabeled samples. Finally, the target image is classified. Experimental results show that transferring the class labels from the source domain to the target domain provides a reliable initial training set and that the priority rule for AL results in a fast convergence to the desired accuracy with respect to Standard AL.","Training,
Time series analysis,
Remote sensing,
Labeling,
Reliability,
Statistical distributions,
Accuracy"
Photonic-Assisted Microwave Channelizer With Improved Channel Characteristics Based on Spectrum-Controlled Stimulated Brillouin Scattering,"A photonic-assisted microwave channelizer with improved channel characteristics based on spectrum-controlled stimulated Brillouin scattering (SBS) is proposed and experimentally demonstrated. In the proposed system, N lightwaves from a laser array are multiplexed and then split into two paths. In the upper path, the lightwaves are modulated by a microwave signal with its frequency to be measured. In the lower path, for each lightwave, the wavelength is shifted to a specific shorter wavelength via carrier-suppressed single-sideband modulation and the spectrum is then shaped. The wavelength-shifted and spectrum-shaped lightwaves are used to pump a single-mode fiber to trigger SBS. Thanks to the SBS effect, multiple gain channels at the N wavelengths are generated. The channel profile of each channel, determined by the designed spectral shape of the pump source, is improved with a flat top and a reduced shape factor. The characteristics including the bandwidth, channel spacing, and channel profile can be controlled by adjusting the spectral shape of the pump source. A proof-of-concept experiment is performed. A microwave channelizer with a shape factor less than 2, a tunable channel bandwidth of 40, 60, or 90 MHz, and a tunable channel spacing of 50, 70, or 80 MHz, is demonstrated.","Scattering,
Bandwidth,
Microwave photonics,
Optical pumping,
Shape,
Microwave measurement"
Lightweight Sybil Attack Detection in MANETs,"Fully self-organized mobile ad hoc networks (MANETs) represent complex distributed systems that may also be part of a huge complex system, such as a complex system-of-systems used for crisis management operations. Due to the complex nature of MANETs and its resource constraint nodes, there has always been a need to develop lightweight security solutions. Since MANETs require a unique, distinct, and persistent identity per node in order for their security protocols to be viable, Sybil attacks pose a serious threat to such networks. A Sybil attacker can either create more than one identity on a single physical device in order to launch a coordinated attack on the network or can switch identities in order to weaken the detection process, thereby promoting lack of accountability in the network. In this research, we propose a lightweight scheme to detect the new identities of Sybil attackers without using centralized trusted third party or any extra hardware, such as directional antennae or a geographical positioning system. Through the help of extensive simulations and real-world testbed experiments, we are able to demonstrate that our proposed scheme detects Sybil identities with good accuracy even in the presence of mobility.","Mobile computing,
Security,
Mobile ad hoc networks,
Protocols,
Hardware,
Directive antennas"
On Credibility Estimation Tradeoffs in Assured Social Sensing,"Two goals of network science are to (i) uncover fundamental properties of phenomena modeled as networks, and to (ii) explore novel use of networks as models for a diverse range of systems and phenomena in order to improve our understanding of such systems and phenomena. This paper advances the latter direction by casting credibility estimation in social sensing applications as a network science problem, and by presenting a network model that helps understand the fundamental accuracy trade-offs of a credibility estimator. Social sensing refers to data collection scenarios, where observations are collected from (possibly unvetted) human sources. We call such observations claims to emphasize that we do not know whether or not they are factually correct. Predictable, scalable and robust estimation of both source reliability and claim correctness, given neither in advance, becomes a key challenge given the unvetted nature of sources and lack of means to verify their claims. In a previous conference publication, we proposed a maximum likelihood approach to jointly estimate both source reliability and claim correctness. We also derived confidence bounds to quantify the accuracy of such estimation. In this paper, we cast credibility estimation as a network science problem and offer systematic sensitivity analysis of the optimal estimator to understand its fundamental accuracy trade-offs as a function of an underlying network topology that describes key problem space parameters. It enables assured social sensing, where not only source reliability and claim correctness are estimated, but also the accuracy of such estimates is correctly predicted for the problem at hand.","Maximum likelihood estimation,
Sensors,
Reliability,
Accuracy,
Network topology,
Silicon"
Tunable Microwave and Sub-Terahertz Generation Based on Frequency Quadrupling Using a Single Polarization Modulator,"Frequency quadrupling for tunable microwave and sub-terahertz generation using a single polarization modulator (PolM) in a Sagnac loop without using an optical filter or a wideband microwave phase shifter is proposed and experimentally demonstrated. In the proposed system, a linearly polarized continuous wave from a tunable laser source (TLS) is split into two orthogonally polarized optical waves by a polarization beam splitter (PBS) and sent to the Sagnac loop traveling along the clockwise and counter-clockwise directions. A PolM to which a reference microwave signal is applied is incorporated in the loop. The PolM is a traveling-wave modulator, due to the velocity mismatch only the clockwise light wave is effectively modulated by the reference microwave signal, and the counter-clockwise light wave is not modulated. This is the key point that ensures the cancelation of the optical carrier without the need of an optical filter. Along the clockwise direction, the joint operation of the PolM, a polarization controller (PC), and a polarizer corresponds to a Mach-Zehnder modulator (MZM) with the bias point controlled to suppress the odd-order sidebands. The optical carrier is then suppressed by the counter-clockwise light wave at the polarizer. As a result, only two ±2nd-order sidebands are generated, which are applied to a photodetector (PD) to generate a microwave signal with a frequency that is four times that of the reference microwave signal. A theoretical analysis is developed, which is validated by an experiment. A frequency-quadrupled electrical signal with a large tunable range from 2.04 to 100 GHz is generated. The performance of the proposed system in terms of stability and phase noise is also evaluated.","Optical polarization,
Microwave theory and techniques,
Optical modulation,
Amplitude modulation,
Optical mixing,
Frequency modulation,
Clocks"
Exploring and Exploiting the Multilevel Parallelism Inside SSDs for Improved Performance and Endurance,"Given the multilevel internal SSD parallelism at the different four levels: channel-level, chip-level, die-level, and plane-level, how to exploit these levels of parallelism will directly and significantly impact the performance and endurance of SSDs, which is in turn primarily determined by three internal factors, namely, advanced commands, allocation schemes, and the priority order of exploiting the four levels of parallelism. In this paper, we analyze these internal factors to characterize their impacts, interplay, and parallelism for the purpose of performance and endurance enhancement of SSDs through an in-depth experimental study. We come to the following key conclusions: 1) Different advanced commands provided by Flash manufacturers exploit different levels of parallelism inside SSDs, where they can either improve or degrade the SSD performance and endurance depending on how they are used; 2) Different physical-page allocation schemes employ different advanced commands and exploit different levels of parallelism inside SSDs, giving rise to different performance and endurance impacts; 3) The priority order of using the four levels of parallelism has the most significant performance and endurance impact among the three internal factors. The optimal priority order of using the four levels of parallelism in SSDs is found to be: 1) the channel-level parallelism; 2) the die-level parallelism; 3) the plane-level parallelism; and 4) the chip-level parallelism.","Parallel processing,
Resource management,
Registers,
Dynamic scheduling,
Flash memory,
Writing,
Time factors"
Smart Cities Built on Resilient Cloud Computing and Secure Internet of Things,"Cloud Computing and Internet of Things (IoT) are currently two of the most popular ICT paradigms that are expected to shape the next era of computing. The convergence between cloud computing and IoT has become a hot topic over the last few years because of the benefits that IoT could have from the distributed nature of cloud computing infrastructures. This paper proposes a new platform for using cloud computing capacities for provision and support of ubiquitous connectivity and real-time applications and services for smart cities' needs. We present a framework for data procured from highly distributed, heterogeneous, decentralized, real and virtual devices (sensors, actuators, smart devices) that can be automatically managed, analyzed and controlled by distributed cloud-based services.",
Safe Driving in LA: Report from the Greatest Intervehicular Accident Detection Test Ever,"The UN Economic Commission's Statistics of Road Traffic Accidents report of 2011 shows that every year, about 150 000 human beings lose their lives on the roads of the western world. Although it is a common belief that this figure could shrink with the use of new sensor and communication technologies, unfortunately, none such systems have hit the road to date. Ideally, if such technologies were put into place, vehicles could be part of a vehicular ad hoc network (VANET) capable of spreading relevant information about dangerous events (e.g., car accidents) to all approaching drivers. However, all this is mainly supported by simulation studies, as no practical results have been published to date, revealing the effective performances of such systems at work. In this paper, we fill this gap, presenting a detailed description of the greatest experiments (a few thousand throughout the streets of Los Angeles), to date, ever performed with an accident warning system specifically devised for highway scenarios. In particular, among all the possible candidate schemes, we ran a few thousand experiments with the accident warning system algorithm that was proven to be optimal in terms of bandwidth usage and covered distance in realistic scenarios. Our experiments confirm what has been observed before in theory and simulation, i.e., the use of such a system can reduce, by as much as 40%, the amount of vehicles involved in highway pileups.","Vehicles,
Accidents,
Relays,
Alarm systems,
Roads"
"A Multiagent Modeling and Investigation of Smart Homes With Power Generation, Storage, and Trading Features","Smart homes, as active participants in a smart grid, may no longer be modeled by passive load curves; because their interactive communication and bidirectional power flow within the smart grid affects demand, generation, and electricity rates. To consider such dynamic environmental properties, we use a multiagent-system-based approach in which individual homes are autonomous agents making rational decisions to buy, sell, or store electricity based on their present and expected future amount of load, generation, and storage, accounting for the benefits each decision can offer. In the proposed scheme, home agents prioritize their decisions based on the expected utilities they provide. Smart homes' intention to minimize their electricity bills is in line with the grid's aim to flatten the total demand curve. With a set of case studies and sensitivity analyses, we show how the overall performance of the home agents converges-as an emergent behavior-to an equilibrium benefiting both the entities in different operational conditions and determines the situations in which conventional homes would benefit from purchasing their own local generation-storage systems.","Electricity,
Load modeling,
Smart grids,
Wind speed,
Smart homes,
Load management,
Mathematical model"
Dynamic Sampling Approach to Training Neural Networks for Multiclass Imbalance Classification,"Class imbalance learning tackles supervised learning problems where some classes have significantly more examples than others. Most of the existing research focused only on binary-class cases. In this paper, we study multiclass imbalance problems and propose a dynamic sampling method (DyS) for multilayer perceptrons (MLP). In DyS, for each epoch of the training process, every example is fed to the current MLP and then the probability of it being selected for training the MLP is estimated. DyS dynamically selects informative data to train the MLP. In order to evaluate DyS and understand its strength and weakness, comprehensive experimental studies have been carried out. Results on 20 multiclass imbalanced data sets show that DyS can outperform the compared methods, including pre-sample methods, active learning methods, cost-sensitive methods, and boosting-type methods.",
Enhancing Secrecy With Multi-Antenna Transmission in Wireless Ad Hoc Networks,"We study physical-layer security in wireless ad hoc networks and investigate two types of multi-antenna transmission schemes for providing secrecy enhancements. To establish secure transmission against malicious eavesdroppers, we consider the generation of artificial noise with either sectoring or beamforming. For both approaches, we provide a statistical characterization and tradeoff analysis of the outage performance of the legitimate communication and the eavesdropping links. We then investigate the network-wide secrecy throughput performance of both schemes in terms of the secrecy transmission capacity, and study the optimal power allocation between the information signal and the artificial noise. Our analysis indicates that, under transmit power optimization, the beamforming scheme outperforms the sectoring scheme, except for the case where the number of transmit antennas are sufficiently large. Our study also reveals some interesting differences between the optimal power allocation for the sectoring and beamforming schemes.",
Image and Video Restorations via Nonlocal Kernel Regression,"A nonlocal kernel regression (NL-KR) model is presented in this paper for various image and video restoration tasks. The proposed method exploits both the nonlocal self-similarity and local structural regularity properties in natural images. The nonlocal self-similarity is based on the observation that image patches tend to repeat themselves in natural images and videos, and the local structural regularity observes that image patches have regular structures where accurate estimation of pixel values via regression is possible. By unifying both properties explicitly, the proposed NL-KR framework is more robust in image estimation, and the algorithm is applicable to various image and video restoration tasks. In this paper, we apply the proposed model to image and video denoising, deblurring, and superresolution reconstruction. Extensive experimental results on both single images and realistic video sequences demonstrate that the proposed framework performs favorably with previous works both qualitatively and quantitatively.","Kernel,
Image restoration,
Estimation,
Vectors,
Redundancy,
Noise reduction,
Robustness"
A video game description language for model-based or interactive learning,"We propose a powerful new tool for conducting research on computational intelligence and games. `PyVGDL' is a simple, high-level description language for 2D video games, and the accompanying software library permits parsing and instantly playing those games. The streamlined design of the language is based on defining locations and dynamics for simple building blocks, and the interaction effects when such objects collide, all of which are provided in a rich ontology. It can be used to quickly design games, without needing to deal with control structures, and the concise language is also accessible to generative approaches. We show how the dynamics of many classical games can be generated from a few lines of PyVGDL. The main objective of these generated games is to serve as diverse benchmark problems for learning and planning algorithms; so we provide a collection of interfaces for different types of learning agents, with visual or abstract observations, from a global or first-person viewpoint. To demonstrate the library's usefulness in a broad range of learning scenarios, we show how to learn competent behaviors when a model of the game dynamics is available or when it is not, when full state information is given to the agent or just subjective observations, when learning is interactive or in batch-mode, and for a number of different learning algorithms, including reinforcement learning and evolutionary search.","Games,
Ontologies,
Avatars,
Libraries,
Syntactics,
Benchmark testing,
Visualization"
Fast Joint Detection-Estimation of Evoked Brain Activity in Event-Related fMRI Using a Variational Approach,"In standard within-subject analyses of event-related functional magnetic resonance imaging (fMRI) data, two steps are usually performed separately: detection of brain activity and estimation of the hemodynamic response. Because these two steps are inherently linked, we adopt the so-called region-based joint detection-estimation (JDE) framework that addresses this joint issue using a multivariate inference for detection and estimation. JDE is built by making use of a regional bilinear generative model of the BOLD response and constraining the parameter estimation by physiological priors using temporal and spatial information in a Markovian model. In contrast to previous works that use Markov Chain Monte Carlo (MCMC) techniques to sample the resulting intractable posterior distribution, we recast the JDE into a missing data framework and derive a variational expectation-maximization (VEM) algorithm for its inference. A variational approximation is used to approximate the Markovian model in the unsupervised spatially adaptive JDE inference, which allows automatic fine-tuning of spatial regularization parameters. It provides a new algorithm that exhibits interesting properties in terms of estimation error and computational cost compared to the previously used MCMC-based approach. Experiments on artificial and real data show that VEM-JDE is robust to model misspecification and provides computational gain while maintaining good performance in terms of activation detection and hemodynamic shape recovery.","Approximation methods,
Estimation,
Hidden Markov models,
Joints,
Computational modeling,
Data models,
Bayesian methods"
On the Effect of Bandwidth Fragmentation on Blocking Probability in Elastic Optical Networks,"In elastic optical networks (EONs), bandwidth fragmentation refers to the existence of non-aligned, isolated and small-sized blocks of contiguous subcarrier slots in the optical spectrum. As they are neither contiguous in the spectrum domain nor aligned along the routing paths, the network operator will have difficulty to use these slots for future connections. In this work, we analyze the effect of bandwidth fragmentation on the blocking probability in EONs. Our theoretical analysis indicates that two factors related to bandwidth fragmentation have effects on the blocking probability: 1) the extent that the available slot-blocks (i.e., blocks of contiguous slots) on different links are aligned on spectrum locations, and 2) the sizes of the available slot-blocks in links' spectra for future requests. When an EON's spectrum becomes more fragmented, the first factor actually reduces the blocking probability, while the second one increases the blocking probability. Their mixed effect determines the overall trend of how the blocking probability will change with bandwidth fragmentation. Our theoretical model can forecast this trend and reveal the relation among the blocking probability, bandwidth fragmentation, request bandwidth distribution, and spectrum utilization. We have also conducted numerical simulations to verify the theoretical analysis, and the simulation results exhibit similar trends as predicted by the theoretical model.","Bandwidth,
Optical fiber networks,
Market research,
Equations,
Mathematical model,
Numerical models,
Predictive models"
A Compressive Sensing Approach to Urban Traffic Estimation with Probe Vehicles,"Traffic estimation is crucial to a number of tasks such as traffic management and road engineering. We propose an approach for metropolitan-scale traffic estimation with probe vehicles that periodically send location and speed updates to a monitoring center. In our approach, we use the flow speed on a road link within a time slot to indicate the traffic condition of the road segment at the given time slot, which is approximated by the average value of probe speeds. By analyzing a large data set of two-year probe data collected from a fleet of around 4,000 taxis in Shanghai, China, we find that a set of probe data may contain a lot of spatiotemporal vacancies over both time and space. This raises a serious missing data problem for road traffic estimation, which results from the naturally uneven distribution of probe vehicles over both time and space. Through empirical study based on the data set of real probe data using principal component analysis (PCA), we have observed that there are hidden structures within the traffic conditions of a road network. Inspired by this observation, we propose a compressive sensing-based algorithm for solving the missing data problem, which exploits the hidden structures for computing estimates for road traffic conditions. Different from existing approaches, our algorithm does not rely on complicated traffic models, which usually require costly training with field study and large data sets. With extensive experiments based on the data set of real probe data, we demonstrate that our proposed algorithm performs significantly better than other completing algorithms, including KNN and MSSA. Surprisingly, our algorithm can achieve an estimate error of as low as 20 percent even when more than 80 percent of probe data are missing.","Probes,
Roads,
Vehicles,
Estimation,
Monitoring,
Compressed sensing,
Principal component analysis"
Retinal Microaneurysm Detection Through Local Rotating Cross-Section Profile Analysis,"A method for the automatic detection of microaneurysms (MAs) in color retinal images is proposed in this paper. The recognition of MAs is an essential step in the diagnosis and grading of diabetic retinopathy. The proposed method realizes MA detection through the analysis of directional cross-section profiles centered on the local maximum pixels of the preprocessed image. Peak detection is applied on each profile, and a set of attributes regarding the size, height, and shape of the peak are calculated subsequently. The statistical measures of these attribute values as the orientation of the cross-section changes constitute the feature set that is used in a naïve Bayes classification to exclude spurious candidates. We give a formula for the final score of the remaining candidates, which can be thresholded further for a binary output. The proposed method has been tested in the Retinopathy Online Challenge, where it proved to be competitive with the state-of-the-art approaches. We also present the experimental results for a private image set using the same classifier setup.","Retina,
Image segmentation,
Shape,
Feature extraction,
Noise,
Indexes,
Standards"
Dynamic Multilevel Priority Packet Scheduling Scheme for Wireless Sensor Network,"Scheduling different types of packets, such as real-time and non-real-time data packets, at sensor nodes with resource constraints in Wireless Sensor Networks (WSN) is of vital importance to reduce sensors' energy consumptions and end-to-end data transmission delays. Most of the existing packet-scheduling mechanisms of WSN use First Come First Served (FCFS), non-preemptive priority and preemptive priority scheduling algorithms. These algorithms incur a high processing overhead and long end-to-end data transmission delay due to the FCFS concept, starvation of high priority real-time data packets due to the transmission of a large data packet in non-preemptive priority scheduling, starvation of non-real-time data packets due to the probable continuous arrival of real-time data in preemptive priority scheduling, and improper allocation of data packets to queues in multilevel queue scheduling algorithms. Moreover, these algorithms are not dynamic to the changing requirements of WSN applications since their scheduling policies are predetermined. In this paper, we propose a Dynamic Multilevel Priority (DMP) packet scheduling scheme. In the proposed scheme, each node, except those at the last level of the virtual hierarchy in the zone-based topology of WSN, has three levels of priority queues. Real-time packets are placed into the highest-priority queue and can preempt data packets in other queues. Non-real-time packets are placed into two other queues based on a certain threshold of their estimated processing time. Leaf nodes have two queues for real-time and non-real-time data packets since they do not receive data from other nodes and thus, reduce end-to-end delay. We evaluate the performance of the proposed DMP packet scheduling scheme through simulations for real-time and non-real-time data. Simulation results illustrate that the DMP packet scheduling scheme outperforms conventional schemes in terms of average data waiting time and end-to-end delay.",
Modeling and Analysis of Printed-Circuit Tensor Impedance Surfaces,"Analysis of a printed-circuit tensor impedance surface (PCTIS) is presented. The surface consists of a periodic, subwavelength-patterned metallic cladding printed over a grounded dielectric substrate. First, the dispersion equation for an idealized tensor impedance boundary condition is derived by expressing the field in terms of TE and TM waves. A similar method is then used to find the dispersion equation of the PCTIS consisting of a tensor sheet impedance, which models the metallic cladding, over a grounded dielectric substrate. In addition, a method for extracting the tensor sheet impedance of a periodic, metallic cladding printed over a grounded dielectric substrate, is reported. It involves performing two normal-incidence scattering simulations using a full-wave electromagnetic solver. The method is strictly valid when the ground plane is sufficiently far from the metallic cladding to avoid evanescent-wave interactions. By combining the tensor sheet extraction method with the dispersion equation, the full dispersion characteristics of the PCTIS are analytically predicted in the homogenous limit. The results are verified through full-wave eigenmode simulations.","Impedance,
Tensile stress,
Mathematical model,
Surface impedance,
Equations,
Dispersion,
Surface waves"
On arbitrating the power-performance tradeoff in SaaS clouds,"In this paper, we present an analytical framework for characterizing and optimizing the power-performance tradeoff in Software-as-a-Service (SaaS) cloud platforms. Our objectives are two-fold: (1) We maximize the operating profit when serving heterogeneous SaaS applications with unpredictable user requests, and (2) we minimize the power consumption when processing user requests. To achieve these objectives, we take advantage of Lyapunov Optimization techniques to design and analyze an optimal control framework to make online decisions on request admission control, routing, and virtual machine (VMs) scheduling. In particular, our control framework can be flexibly extended to incorporate various design choices and practical requirements of a data-center in the cloud, such as enforcing a certain power budget for improving the performance (dollar) per watt. Our mathematical analyses and simulations have demonstrated both the optimality (in terms of a cost-effective power-performance tradeoff) and system stability (in terms of robustness and adaptivity to time-varying and bursty user requests) achieved by our proposed control framework.","Servers,
Power demand,
Throughput,
Admission control,
Routing,
Control systems,
Computational modeling"
Optimal Co-Segmentation of Tumor in PET-CT Images With Context Information,"Positron emission tomography (PET)-computed tomography (CT) images have been widely used in clinical practice for radiotherapy treatment planning of the radiotherapy. Many existing segmentation approaches only work for a single imaging modality, which suffer from the low spatial resolution in PET or low contrast in CT. In this work, we propose a novel method for the co-segmentation of the tumor in both PET and CT images, which makes use of advantages from each modality: the functionality information from PET and the anatomical structure information from CT. The approach formulates the segmentation problem as a minimization problem of a Markov random field model, which encodes the information from both modalities. The optimization is solved using a graph-cut based method. Two sub-graphs are constructed for the segmentation of the PET and the CT images, respectively. To achieve consistent results in two modalities, an adaptive context cost is enforced by adding context arcs between the two sub-graphs. An optimal solution can be obtained by solving a single maximum flow problem, which leads to simultaneous segmentation of the tumor volumes in both modalities. The proposed algorithm was validated in robust delineation of lung tumors on 23 PET-CT datasets and two head-and-neck cancer subjects. Both qualitative and quantitative results show significant improvement compared to the graph cut methods solely using PET or CT.","Computed tomography,
Positron emission tomography,
Tumors,
Image segmentation,
Context,
Lungs,
Computational modeling"
Grand Challenges in Mapping the Human Brain: NSF Workshop Report,"This report summarizes the outcomes of the NSF Workshop on Mapping and Engineering the Brain, held at Arlington, VA, during August 13-14, 2013. Three grand challenges were identified, including high spatiotemporal resolution neuroimaging, perturbation-based neuroimaging, and neuroimaging in naturalistic environments. It was highlighted that each grand challenge requires groundbreaking discoveries, enabling technologies, appropriate knowledge transfer, and multi- and transdisciplinary education and training for success.","Medical image processing,
Spatial resolution,
Electroencephalography,
Neuroimaging,
Brain modeling"
Wavelet-Based ECG Steganography for Protecting Patient Confidential Information in Point-of-Care Systems,"With the growing number of aging population and a significant portion of that suffering from cardiac diseases, it is conceivable that remote ECG patient monitoring systems are expected to be widely used as point-of-care (PoC) applications in hospitals around the world. Therefore, huge amount of ECG signal collected by body sensor networks from remote patients at homes will be transmitted along with other physiological readings such as blood pressure, temperature, glucose level, etc., and diagnosed by those remote patient monitoring systems. It is utterly important that patient confidentiality is protected while data are being transmitted over the public network as well as when they are stored in hospital servers used by remote monitoring systems. In this paper, a wavelet-based steganography technique has been introduced which combines encryption and scrambling technique to protect patient confidential data. The proposed method allows ECG signal to hide its corresponding patient confidential data and other physiological information thus guaranteeing the integration between ECG and the rest. To evaluate the effectiveness of the proposed technique on the ECG signal, two distortion measurement metrics have been used: the percentage residual difference and the wavelet weighted PRD. It is found that the proposed technique provides high-security protection for patients data with low (less than 1%) distortion and ECG data remain diagnosable after watermarking (i.e., hiding patient confidential data) and as well as after watermarks (i.e., hidden data) are removed from the watermarked data.","wavelet transforms,
body sensor networks,
cryptography,
diseases,
distortion measurement,
electrocardiography,
medical signal processing,
patient monitoring,
steganography,
watermarking"
Interference Graph-Based Resource-Sharing Schemes for Vehicular Networks,"This paper investigates the resource-sharing problem in vehicular networks, including both vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communication links. A novel underlaying resource-sharing communication mode for vehicular networks is proposed, in which different V2V and V2I communication links are permitted to access the same resources for their individual data transmission. To solve the resource-sharing problem in vehicular networks, we, for the first time, apply graph theory and propose the following two interference graph-based resource-sharing schemes: 1) the interference-aware graph-based resource-sharing scheme and 2) the interference-classified graph-based resource-sharing scheme. Compared with the traditional orthogonal communication mode in vehicular networks, the proposed two resource-sharing schemes express better network sum rate. The utility of the proposed V2V and V2I underlaying communication mode and the two proposed interference graph-based resource-sharing schemes are verified by simulations.",
Body Area Network Security: A Fuzzy Attribute-Based Signcryption Scheme,"Body Area Networks (BANs) are expected to play a major role in the field of patient-health monitoring in the near future. While it is vital to support secure BAN access to address the obvious safety and privacy concerns, it is equally important to maintain the elasticity of such security measures. For example, elasticity is required to ensure that first-aid personnel have access to critical information stored in a BAN in emergent situations. The inherent tradeoff between security and elasticity calls for the design of novel security mechanisms for BANs. In this paper, we develop the Fuzzy Attribute-Based Signcryption (FABSC), a novel security mechanism that makes a proper tradeoff between security and elasticity. FABSC leverages fuzzy Attribute-based encryption to enable data encryption, access control, and digital signature for a patient's medical information in a BAN. It combines digital signatures and encryption, and provides confidentiality, authenticity, unforgeability, and collusion resistance. We theoretically prove that FABSC is efficient and feasible. We also analyze its security level in practical BANs.","Medical services,
Encryption,
Permission,
Access control,
Elasticity"
A Planar WWAN/LTE Antenna for Portable Devices,"A Wireless Wide Area Network (WWAN) and Long Term Evolution (LTE) eight-band antenna for portable wireless devices is proposed, which consists of a direct-fed monopole with a chip inductor, a grounded strip, and a coupled-fed monopole with a distributed inductor. The fundamental modes of these three components form a low operating band from 0.66 to 1.03 GHz. The higher modes of the grounded strip and coupled-fed monopole create a high operating band from 1.7 to 2.87 GHz. Based on the 6-dB return loss, the two wide operating bands can be employed in LTE 700/GSM 850/900/1800/1900/UMTS/LTE 2300/2500 applications. The proposed antenna having dimensions 75\,\times\,10\,\times\,0.8 mm^3 is appropriate for the top edge of a tablet computer. A 200 \,\times\,260 mm ^2 copper plate, which is about the size of a 13-in screen plate, is used as the system ground plane.","Inductors,
Antenna measurements,
GSM,
Antenna radiation patterns,
Mobile handsets"
Automatic facial makeup detection with application in face recognition,"Facial makeup has the ability to alter the appearance of a person. Such an alteration can degrade the accuracy of automated face recognition systems, as well as that of meth-ods estimating age and beauty from faces. In this work, we design a method to automatically detect the presence of makeup in face images. The proposed algorithm extracts a feature vector that captures the shape, texture and color characteristics of the input face, and employs a classifier to determine the presence or absence of makeup. Besides extracting features from the entire face, the algorithm also considers portions of the face pertaining to the left eye, right eye, and mouth. Experiments on two datasets consisting of 151 subjects (600 images) and 125 subjects (154 images), respectively, suggest that makeup detection rates of up to 93.5% (at a false positive rate of 1%) can be obtained using the proposed approach. Further, an adaptive pre-processing scheme that exploits knowledge of the presence or absence of facial makeup to improve the matching accuracy of a face matcher is presented.",
Automated Cognitive Health Assessment Using Smart Home Monitoring of Complex Tasks,"One of the many services that intelligent systems can provide is the automated assessment of resident well-being. We hypothesize that the functional health of individuals, or ability of individuals to perform activities independently without assistance, can be estimated by tracking their activities using smart home technologies. In this paper, we introduce a machine-learning-based method to assess activity quality in smart homes. To validate our approach, we quantify activity quality for 179 volunteer participants who performed a complex, interweaved set of activities in our smart home apartment. We compare our automated assessment of task quality with direct observation scores. We also assess the ability of machine-learning techniques to predict the cognitive health of the participants based on these automated scores. We believe that this capability is an important step in understanding everyday functional health of individuals in their home environments.","Smart homes,
Sequential analysis,
Patient monitoring,
Dementia,
Machine learning,
Ubiquitous computing"
Time-Varying Spectrum Allocation Policies and Blocking Analysis in Flexible Optical Networks,"We consider the problem of serving traffic in a spectrum-flexible optical network, where the spectrum allocated to an end-to-end connection can change so as to adapt to the time-varying required transmission rate. In the proposed framework, each connection is assigned a route and is allocated a reference frequency over that route, using an appropriate Routing and Spectrum Allocation (RSA) algorithm, but the spectrum it utilizes around the reference frequency is allowed to expand and contract to match source rate fluctuations. We propose and analyze three spectrum expansion/contraction (SEC) policies for modifying the spectrum allocated to each connection. The first policy, named the Constant Spectrum Allocation (CSA) policy, allocates a number of spectrum slots for exclusive use by each connection. We also present two policies that enable the dynamic sharing of spectrum slots among connections, named the Dynamic High Expansion-Low Contraction (DHL) and the Dynamic Alternate Direction (DAD) policy. We give exact formulas for calculating the blocking probability for a connection and for the whole network under the CSA policy and provide corresponding approximate analyses under the DHL and DAD policies. We also present a simple iterative RSA algorithm that uses the developed blocking models so as to minimize the average blocking of the network.",
The YouTube Lens: Crowdsourced Personality Impressions and Audiovisual Analysis of Vlogs,"Despite an increasing interest in understanding human perception in social media through the automatic analysis of users' personality, existing attempts have explored user profiles and text blog data only. We approach the study of personality impressions in social media from the novel perspective of crowdsourced impressions, social attention, and audiovisual behavioral analysis on slices of conversational vlogs extracted from YouTube. Conversational vlogs are a unique case study to understand users in social media, as vloggers implicitly or explicitly share information about themselves that words, either written or spoken cannot convey. In addition, research in vlogs may become a fertile ground for the study of video interactions, as conversational video expands to innovative applications. In this work, we first investigate the feasibility of crowdsourcing personality impressions from vlogging as a way to obtain judgements from a variate audience that consumes social media video. Then, we explore how these personality impressions mediate the online video watching experience and relate to measures of attention in YouTube. Finally, we investigate on the use of automatic nonverbal cues as a suitable lens through which impressions are made, and we address the task of automatic prediction of vloggers' personality impressions using nonverbal cues and machine learning techniques. Our study, conducted on a dataset of 442 YouTube vlogs and 2210 annotations collected in Amazon's Mechanical Turk, provides new findings regarding the suitability of collecting personality impressions from crowdsourcing, the types of personality impressions that emerge through vlogging, their association with social attention, and the level of utilization of nonverbal cues in this particular setting. In addition, it constitutes a first attempt to address the task of automatic vlogger personality impression prediction using nonverbal cues, with promising results.",
ESWC: Efficient Scheduling for the Mobile Sink in Wireless Sensor Networks with Delay Constraint,"This paper exploits sink mobility to prolong the network lifetime in wireless sensor networks where the information delay caused by moving the sink should be bounded. Due to the combinational complexity of this problem, most previous proposals focus on heuristics and provable optimal algorithms remain unknown. In this paper, we build a unified framework for analyzing this joint sink mobility, routing, delay, and so on. We discuss the induced subproblems and present efficient solutions for them. Then, we generalize these solutions and propose a polynomial-time optimal algorithm for the origin problem. In simulations, we show the benefits of involving a mobile sink and the impact of network parameters (e.g., the number of sensors, the delay bound, etc.) on the network lifetime. Furthermore, we study the effects of different trajectories of the sink and provide important insights for designing mobility schemes in real-world mobile WNNs.",
Realization of a Special Class of Admittances with One Damper and One Inerter for Mechanical Control,"In this note, we investigate the realization problem of a special class of positive-real admittances, which is common in vehicle suspension designs. The number of inerters and dampers is restricted to one in each case and the number of the springs is arbitrary. To solve the problem, we first convert a previous result by to a more direct form. A necessary and sufficient condition for realizability is then derived and explicit circuit arrangements are provided by assuming that the three-port network consisting of only springs after extracting the damper and the inerter has a well-defined impedance. To remove the assumption on the existence of a well-defined impedance, a condition is established on the topological property of the n -port network without a well-defined impedance to obtain an equivalent class of such networks so that the realizability condition is derived with realization. By combining the conditions with and without a well-defined impedance, the final realization result is obtained.","Springs,
Impedance,
Shock absorbers,
Admittance,
Ports (Computers),
Optimal scheduling,
Educational institutions"
Detection and Analysis of Irregular Streaks in Dermoscopic Images of Skin Lesions,"Irregular streaks are important clues for Melanoma (a potentially fatal form of skin cancer) diagnosis using dermoscopy images. This paper extends our previous algorithm to identify the absence or presence of streaks in a skin lesions, by further analyzing the appearance of detected streak lines, and performing a three-way classification for streaks, Absent, Regular, and Irregular, in a pigmented skin lesion. In addition, the directional pattern of detected lines is analyzed to extract their orientation features in order to detect the underlying pattern. The method uses a graphical representation to model the geometric pattern of valid streaks and the distribution and coverage of the structure. Using these proposed features of the valid streaks along with the color and texture features of the entire lesion, an accuracy of 76.1% and weighted average area under ROC curve (AUC) of 85% is achieved for classifying dermoscopy images into streaks Absent, Regular, or Irregular on 945 images compiled from atlases and the internet without any exclusion criteria. This challenging dataset is the largest validation dataset for streaks detection and classification published to date. The data set has also been applied to the two-class sub-problems of Absent/Present classification (accuracy of 78.3% with AUC of 83.2%) and to Regular/Irregular classification (accuracy 83.6% with AUC of 88.9%). When the method was tested on a cleaned subset of 300 images randomly selected from the 945 images, the AUC increased to 91.8%, 93.2% and 90.9% for the Absent/Regular/Irregular, Absent/Present, and Regular/Irregular problems, respectively.","Lesions,
Feature extraction,
Malignant tumors,
Skin,
Reliability,
Cancer,
Image color analysis"
A Fuzzy Logic-Based System for Indoor Localization Using WiFi in Ambient Intelligent Environments,"Ambient intelligence is a new information paradigm, where people are empowered through a digital environment that is “aware” of their presence and context and is sensitive, adaptive, and responsive to their needs. Hence, one of the important requirements for ambient intelligent environments (AIEs) is the ability to localize the whereabouts of the user in the AIE to address her/his needs. In order to protect user privacy, the use of cameras is not desirable in AIEs, and hence, there is a need to rely on nonintrusive sensors. There are various localization means that are available for outdoor spaces such as those which rely on satellite signals triangulation. However, these outdoor localization means cannot be used in indoor environments. The majority of nonintrusive and noncamera-based indoor localization systems require the installation of extra hardware such as ultrasound emitters/antennas, radio-frequency identification (RFID) antennas, etc. In this paper, we propose a novel indoor localization system that is based on WiFi signals which are free to receive, and they are available in abundance in the majority of domestic spaces. However, free WiFi signals are noisy and uncertain, and their strengths and availability are continuously changing. Hence, we present a fuzzy logic-based system which employs free available WiFi signals to localize a given user in AIEs. The proposed system receives WiFi signals from a large number of existing WiFi access points (up to 170 access points), where no prior knowledge of the access points locations and the environment is required. The system employs an incremental lifelong learning approach to adjust its behavior to the varying and changing WiFi signals to provide a zero-cost localization system which can provide high accuracy in real-world living spaces. We have compared our system in both simulated and real environments with other relevant techniques in the literature, and we have found that our system outperforms the other systems in the offline learning process, whereas our system was the only system which is capable of performing online learning and adaptation. The proposed system was tested in real-world spaces from a living lab intelligent apartment (iSpace) to a town center apartment to a block of offices. In all these experiments, our system has been highly accurate in detecting the user in the given AIEs, and the system was able to adapt its behavior to changes in the AIE or the WiFi signals. We envisage that the proposed system will play an important role in AIEs, especially for privacy concerned situations like elderly care scenarios.","IEEE 802.11 Standards,
Fuzzy logic,
Hardware,
Noise,
Artificial intelligence,
Indoor environments,
Continuing professional development"
Markerless Motion Capture and Measurement of Hand Kinematics: Validation and Application to Home-Based Upper Limb Rehabilitation,"Dynamic movements of the hand, fingers, and thumb are difficult to measure due to the versatility and complexity of movement inherent in function. An innovative approach to measuring hand kinematics is proposed and validated. The proposed system utilizes the Microsoft Kinect and goes beyond gesture recognition to develop a validated measurement technique of finger kinematics. The proposed system adopted landmark definition (validated through ground truth estimation against assessors) and grip classification algorithms, including kinematic definitions (validated against a laboratory-based motion capture system). The results of the validation show 78% accuracy when identifying specific markerless landmarks. In addition, comparative data with a previously validated kinematic measurement technique show accuracy of MCP ± 10° (average absolute error (AAE) = 2.4°), PIP ± 12° (AAE = 4.8°), and DIP ± 11° (AAE = 4.8°). These results are notably better than clinically based alternative manual measurement techniques. The ability to measure hand movements, and therefore functional dexterity, without interfering with underlying composite movements, is the paramount objective to any bespoke measurement system. The proposed system is the first validated markerless measurement system using the Microsoft Kinect that is capable of measuring finger joint kinematics. It is suitable for home-based motion capture for the hand and, therefore, achieves this objective.",
Component-Based Representation in Automated Face Recognition,"This paper presents a framework for component-based face alignment and representation that demonstrates improvements in matching performance over the more common holistic approach to face alignment and representation. This work is motivated by recent evidence from the cognitive science community demonstrating the efficacy of component-based facial representations. The component-based framework presented in this paper consists of the following major steps: 1) landmark extraction using Active Shape Models (ASM), 2) alignment and cropping of components using Procrustes Analysis, 3) representation of components with Multiscale Local Binary Patterns (MLBP), 4) per-component measurement of facial similarity, and 5) fusion of per-component similarities. We demonstrate on three public datasets and an operational dataset consisting of face images of 8000 subjects, that the proposed component-based representation provides higher recognition accuracies over holistic-based representations. Additionally, we show that the proposed component-based representations: 1) are more robust to changes in facial pose, and 2) improve recognition accuracy on occluded face images in forensic scenarios.","Face,
Face recognition,
Feature extraction,
Humans,
Accuracy,
Cognitive science,
Educational institutions"
A Virtual Imaging Platform for Multi-Modality Medical Image Simulation,"This paper presents the Virtual Imaging Platform (VIP), a platform accessible at http://vip.creatis.insa-lyon.fr to facilitate the sharing of object models and medical image simulators, and to provide access to distributed computing and storage resources. A complete overview is presented, describing the ontologies designed to share models in a common repository, the workίow template used to integrate simulators, and the tools and strategies used to exploit computing and storage resources. Simulation results obtained in four image modalities and with different models show that VIP is versatile and robust enough to support large simulations. The platform currently has 200 registered users who consumed 33 years of CPU time in 2011.","Computational modeling,
Ontologies,
Biological system modeling,
Data models,
Image reconstruction,
Magnetic resonance imaging"
Design of Five-Phase Modular Flux-Switching Permanent-Magnet Machines for High Reliability Applications,"This paper proposes and designs a new five-phase modular flux-switching permanent-magnet (M-FSPM) machine for high reliability applications. The key is the new machine topology which incorporates the concept of fault-tolerant teeth (FTT) to provide the desired decoupling among phases. The electromagnetic performances of the newly designed M-FSPM machines having 18 and 19 rotor poles are quantitatively analyzed including the flux, back-EMF, cogging torque as well as unbalanced magnetic force (UMF). The results show that the proposed M-FSPM machine not only retains the merits of stator-PM machines and multiphase machines, but also offers lower cost and higher fault-tolerant capability. Especially, the 10/19-pole one incorporates the merits of symmetric back-EMF and reduced cogging torque, while suffers from UMF. Two experimental M-FSPM machines are designed and built for exemplification. Experimental results of the prototypes are given to confirm the validity of the proposed machines.","Fault tolerance,
Fault tolerant systems,
Stator windings,
Torque,
Rotors,
Topology"
Semi-Supervised Nonlinear Hashing Using Bootstrap Sequential Projection Learning,"In this paper, we study the effective semi-supervised hashing method under the framework of regularized learning-based hashing. A nonlinear hash function is introduced to capture the underlying relationship among data points. Thus, the dimensionality of the matrix for computation is not only independent from the dimensionality of the original data space but also much smaller than the one using linear hash function. To effectively deal with the error accumulated during converting the real-value embeddings into the binary code after relaxation, we propose a semi-supervised nonlinear hashing algorithm using bootstrap sequential projection learning which effectively corrects the errors by taking into account of all the previous learned bits holistically without incurring the extra computational overhead. Experimental results on the six benchmark data sets demonstrate that the presented method outperforms the state-of-the-art hashing algorithms at a large margin.",
Breaking the on-chip latency barrier using SMART,"As the number of on-chip cores increases, scalable on-chip topologies such as meshes inevitably add multiple hops in each network traversal. The best we can do right now is to design 1-cycle routers, such that the low-load network latency between a source and destination is equal to the number of routers + links (i.e. hops×2) between them. OS/compiler and cache coherence protocols designers often try to limit communication to within a few hops, since on-chip latency is critical for their scalability. In this work, we propose an on-chip network called SMART (Single-cycle Multi-hop Asynchronous Repeated Traversal) that aims to present a single-cycle data-path all the way from the source to the destination. We do not add any additional fast physical express links in the data-path; instead we drive the shared crossbars and links asynchronously up to multiple-hops within a single cycle. We design a router + link microarchitecture to achieve such a traversal, and a flow-control technique to arbitrate and setup multi-hop paths within a cycle. A place-and-routed design at 45nm achieves 11 hops within a 1GHz cycle for paths without turns (9 for paths with turns). We observe 5-8X reduction in low-load latencies across synthetic traffic patterns on an 8×8 CMP, compared to a baseline 1-cycle router. Full-system simulations with SPLASH-2 and PAR-SEC benchmarks demonstrate 27/52% and 20/59% reduction in runtime and EDP for Private/Shared L2 designs.",
Distributed Fusion of PHD Filters Via Exponential Mixture Densities,"In this paper, we consider the problem of Distributed Multi-sensor Multi-target Tracking (DMMT) for networked fusion systems. Many existing approaches for DMMT use multiple hypothesis tracking and track-to-track fusion. However, there are two difficulties with these approaches. First, the computational costs of these algorithms can scale factorially with the number of hypotheses. Second, consistent optimal fusion, which does not double count information, can only be guaranteed for highly constrained network architectures which largely undermine the benefits of distributed fusion. In this paper, we develop a consistent approach for DMMT by combining a generalized version of Covariance Intersection, based on Exponential Mixture Densities (EMDs), with Random Finite Sets (RFS). We first derive explicit formulae for the use of EMDs with RFSs. From this, we develop expressions for the probability hypothesis density filters. This approach supports DMMT in arbitrary network topologies through local communications and computations. We implement this approach using Sequential Monte Carlo techniques and demonstrate its performance in simulations.","Target tracking,
Signal processing algorithms,
Wireless sensor networks,
Filtering algorithms"
A Truthful Dynamic Workflow Scheduling Mechanism for Commercial Multicloud Environments,"The ultimate goal of cloud providers by providing resources is increasing their revenues. This goal leads to a selfish behavior that negatively affects the users of a commercial multicloud environment. In this paper, we introduce a pricing model and a truthful mechanism for scheduling single tasks considering two objectives: monetary cost and completion time. With respect to the social cost of the mechanism, i.e., minimizing the completion time and monetary cost, we extend the mechanism for dynamic scheduling of scientific workflows. We theoretically analyze the truthfulness and the efficiency of the mechanism and present extensive experimental results showing significant impact of the selfish behavior of the cloud providers on the efficiency of the whole system. The experiments conducted using real-world and synthetic workflow applications demonstrate that our solutions dominate in most cases the Pareto-optimal solutions estimated by two classical multiobjective evolutionary algorithms.","Dynamic scheduling,
Games,
Processor scheduling,
Heuristic algorithms,
Game theory,
Optimization"
Limited Feedback Design for Interference Alignment on MIMO Interference Networks With Heterogeneous Path Loss and Spatial Correlations,"Interference alignment is degree of freedom optimal on K
-user MIMO interference channels and many previous works have studied the transceiver designs. However, these works predominantly focus on networks with perfect channel state information at the transmitters and symmetrical interference topology. In this paper, we consider a limited feedback system with heterogeneous path loss and spatial correlations and investigate how the dynamics of the interference topology can be exploited to improve the feedback efficiency. We propose a novel spatial codebook design and perform dynamic quantization via bit allocations to adapt to the asymmetry of the interference topology. We bound the system throughput under the proposed dynamic scheme in terms of the transmit SNR, feedback bits, and the interference topology parameters. It is shown that when the number of feedback bits scales with SNR as C_{s}\cdot \log {\hbox{SNR}}+ {\cal O}(1)
, the sum degrees of freedom of the network are preserved. Moreover, the value of scaling coefficient C_{s}
can be significantly reduced in networks with asymmetric interference topology.","Interference,
MIMO,
Network topology,
Topology,
Correlation,
Throughput,
Quantization"
Decoding Children's Social Behavior,"We introduce a new problem domain for activity recognition: the analysis of children's social and communicative behaviors based on video and audio data. We specifically target interactions between children aged 1-2 years and an adult. Such interactions arise naturally in the diagnosis and treatment of developmental disorders such as autism. We introduce a new publicly-available dataset containing over 160 sessions of a 3-5 minute child-adult interaction. In each session, the adult examiner followed a semi-structured play interaction protocol which was designed to elicit a broad range of social behaviors. We identify the key technical challenges in analyzing these behaviors, and describe methods for decoding the interactions. We present experimental results that demonstrate the potential of the dataset to drive interesting research questions, and show preliminary results for multi-modal activity recognition.","Face,
Cameras,
Protocols,
Decoding,
Pediatrics,
Training,
Testing"
UWB CPW-Fed Fractal Patch Antenna With Band-Notched Function Employing Folded T-Shaped Element,"A compact coplanar waveguide (CPW) monopole antenna is presented, comprising a fractal radiating patch in which a folded T-shaped element (FTSE) is embedded. The impedance match of the antenna is determined by the number of fractal unit cells, and the FTSE provides the necessary band-notch functionality. The filtering property can be tuned finely by controlling of length of FTSE. Inclusion of a pair of rectangular notches in the ground plane is shown to extend the antenna's impedance bandwidth for ultrawideband (UWB) performance. The antenna's parameters were investigated to fully understand their affect on the antenna. Salient parameters obtained from this analysis enabled the optimization of the antenna's overall characteristics. Experimental and simulation results demonstrate that the antenna exhibits the desired VSWR level and radiation patterns across the entire UWB frequency range. The measured results showed the antenna operates over a frequency band between 2.94–11.17 GHz with fractional bandwidth of 117% for
VSWR≤2
, except at the notch band between 3.3–4.2 GHz. The antenna has dimensions of 14
×
18
×
1 mm
3
.",
Spatial Modulation and Space-Time Shift Keying: Optimal Performance at a Reduced Detection Complexity,"In this paper, we propose a comprehensive reduced-complexity detector both for hard-decision-aided as well as for the soft-decision-assisted Spatial Modulation (SM)/Space-Time Shift Keying (STSK). More explicitly, the detection of the SM scheme, which activates a single one out of M antennas to transmit a single LPSK/QAM symbol, may be carried out by detecting the antenna activation index m and the LPSK/QAM symbol st separately, so that the detection complexity may be reduced from the order of O(M · L) to the lower bound of O(M + log2 L). However, the QAM aided STSK hard detection proposed in [1] results in a performance loss. Furthermore, the Max-Log-MAP algorithm proposed for soft STSK detection in [2] only takes into account the maximum a posteriori probabilities, which also imposed a performance degradation. Therefore, in this paper, we propose a novel solution for hard-decision-aided SM/STSK detection, which retains its optimal performance, despite its reduced detection complexity, when either LPSK or LQAM is employed. Furthermore, we propose the reduced-complexity Approx-Log-MAP algorithm conceived for the soft-decision-aided SM/STSK detector, in order to replace the suboptimal Max-Log-MAP algorithm.","Indexes,
Antennas,
Quadrature amplitude modulation,
Complexity theory,
Detectors,
Phase shift keying,
Measurement"
Route Planning for Unmanned Aerial Vehicle (UAV) on the Sea Using Hybrid Differential Evolution and Quantum-Behaved Particle Swarm Optimization,"This paper presents a hybrid differential evolution (DE) with quantum-behaved particle swarm optimization (QPSO) for the unmanned aerial vehicle (UAV) route planning on the sea. The proposed method, denoted as DEQPSO, combines the DE algorithm with the QPSO algorithm in an attempt to further enhance the performance of both algorithms. The route planning for UAV on the sea is formulated as an optimization problem. A simple method of pretreatment to the terrain environment is proposed. A novel route planner for UAV is designed to generate a safe and flyable path in the presence of different threat environments based on the DEQPSO algorithm. To show the high performance of the proposed method, the DEQPSO algorithm is compared with the real-valued genetic algorithm, DE, standard particle swarm optimization (PSO), hybrid particle swarm with differential evolution operator, and QPSO in terms of the solution quality, robustness, and the convergence property. Experimental results demonstrate that the proposed method is capable of generating higher quality paths efficiently for UAV than any other tested optimization algorithms.","Unmanned aerial vehicles,
Particle swarm optimization,
Path planning"
Security and Privacy-Enhancing Multicloud Architectures,"Security challenges are still among the biggest obstacles when considering the adoption of cloud services. This triggered a lot of research activities, resulting in a quantity of proposals targeting the various cloud security threats. Alongside with these security issues, the cloud paradigm comes with a new set of unique features, which open the path toward novel security approaches, techniques, and architectures. This paper provides a survey on the achievable security merits by making use of multiple distinct clouds simultaneously. Various distinct architectures are introduced and discussed according to their security and privacy capabilities and prospects.","Cloud computing,
Computer security,
Data processing"
Volumetric Real-Time Tracking of Peripheral Human Vasculature With GPU-Accelerated Three-Dimensional Optoacoustic Tomography,"Optoacoustic tomography provides a unique possibility for ultra-high-speed 3-D imaging by acquiring complete volumetric datasets from interrogation of tissue by a single nanosecond-duration laser pulse. Yet, similarly to ultrasound, optoacoustics is a time-resolved imaging method, thus, fast 3-D imaging implies real-time acquisition and processing of high speed data from hundreds of detectors simultaneously, which presents significant technological challenges. Herein we present a highly efficient graphical processing unit (GPU) framework for real-time reconstruction and visualization of 3-D tomographic optoacoustic data. By utilizing a newly developed 3-D optoacoustic scanner, which simultaneously acquires signals with a handheld 256-element spherical ultrasonic array system, we further demonstrate tracking of deep tissue human vasculature rendered at a rate of 10 volumetric frames per second. The flexibility provided by the handheld hardware design, combined with the real-time operation, makes the developed platform highly usable for both clinical imaging practice and small animal research applications.","Image reconstruction,
Real-time systems,
Graphics processing units,
Tomography,
Arrays,
Acoustics"
Imaging Transverse Isotropic Properties of Muscle by Monitoring Acoustic Radiation Force Induced Shear Waves Using a 2-D Matrix Ultrasound Array,"A 2-D matrix ultrasound array is used to monitor acoustic radiation force impulse (ARFI) induced shear wave propagation in 3-D in excised canine muscle. From a single acquisition, both the shear wave phase and group velocity can be calculated to estimate the shear wave speed (SWS) along and across the fibers, as well as the fiber orientation in 3-D. The true fiber orientation found using the 3-D radon transform on B-mode volumes of the muscle was used to verify the fiber direction estimated from shear wave data. For the simplified imaging case when the ARFI push can be oriented perpendicular to the fibers, the error in estimating the fiber orientation using phase and group velocity measurements was 3.5±2.6° and 3.4±1.4° (mean ± standard deviation), respectively, over six acquisitions in different muscle samples. For the more general case when the push is oblique to the fibers, the angle between the push and the fibers is found using the dominant orientation of the shear wave displacement magnitude. In 30 acquisitions on six different muscle samples with oblique push angles up to 40°, the error in the estimated fiber orientation using phase and group velocity measurements was 5.4±2.9° and 5.3±3.2°, respectively, after estimating and accounting for the additional unknown push angle. Either the phase or group velocity measurements can be used to estimate fiber orientation and SWS along and across the fibers. Although it is possible to perform these measurements when the push is not perpendicular to the fibers, highly oblique push angles induce lower shear wave amplitudes which can cause inaccurate SWS measurements.",
Rank Preserving Sparse Learning for Kinect Based Scene Classification,"With the rapid development of the RGB-D sensors and the promptly growing population of the low-cost Microsoft Kinect sensor, scene classification, which is a hard, yet important, problem in computer vision, has gained a resurgence of interest recently. That is because the depth of information provided by the Kinect sensor opens an effective and innovative way for scene classification. In this paper, we propose a new scheme for scene classification, which applies locality-constrained linear coding (LLC) to local SIFT features for representing the RGB-D samples and classifies scenes through the cooperation between a new rank preserving sparse learning (RPSL) based dimension reduction and a simple classification method. RPSL considers four aspects: 1) it preserves the rank order information of the within-class samples in a local patch; 2) it maximizes the margin between the between-class samples on the local patch; 3) the L1-norm penalty is introduced to obtain the parsimony property; and 4) it models the classification error minimization by utilizing the least-squares error minimization. Experiments are conducted on the NYU Depth V1 dataset and demonstrate the robustness and effectiveness of RPSL for scene classification.","minimisation,
computer vision,
image classification,
learning (artificial intelligence),
least mean squares methods"
Spectrum Sensing in Opportunity-Heterogeneous Cognitive Sensor Networks: How to Cooperate?,"Cognitive sensor network (CSN) is a promising paradigm to address the spectrum scarcity problem in traditional wireless sensor networks. Reliable spectrum sensing is essential to enable the normal operation of a CSN. Existing researches showed that by exploiting spatial diversity, cooperative sensing can greatly improve the detection performance over non-cooperative sensing in opportunity-homogeneous environment. At a given time, cognitive sensors at different locations, however, may experience heterogeneous spectrum opportunities making the cooperation among cognitive sensors intractable. In this paper, we show the limitations and drawbacks of merely using temporal-domain detection performance metrics and introduce novel spatio-temporal detection performance metrics to guide the design of joint spatio-temporal spectrum sensing. An efficient one-bit hard decision based three-phase (i.e., a global cooperation phase, a local cooperation phase, and a joint decision phase) spatio-temporal sensing algorithm is proposed and numerical results demonstrates the effectiveness of the proposed algorithm.",
Higher Order Partial Least Squares (HOPLS): A Generalized Multilinear Regression Method,"A new generalized multilinear regression model, termed the higher order partial least squares (HOPLS), is introduced with the aim to predict a tensor (multiway array) Y from a tensor X through projecting the data onto the latent space and performing regression on the corresponding latent variables. HOPLS differs substantially from other regression models in that it explains the data by a sum of orthogonal Tucker tensors, while the number of orthogonal loadings serves as a parameter to control model complexity and prevent overfitting. The low-dimensional latent space is optimized sequentially via a deflation operation, yielding the best joint subspace approximation for both X and Y. Instead of decomposing X and Y individually, higher order singular value decomposition on a newly defined generalized cross-covariance tensor is employed to optimize the orthogonal loadings. A systematic comparison on both synthetic data and real-world decoding of 3D movement trajectories from electrocorticogram signals demonstrate the advantages of HOPLS over the existing methods in terms of better predictive ability, suitability to handle small sample sizes, and robustness to noise.",
Distributed Wireless Visual Communication With Power Distortion Optimization,"This paper proposes a novel framework called DCast for distributed video coding and transmission over wireless networks, which is different from existing distributed schemes in three aspects. First, coset quantized DCT coefficients and motion data are directly delivered to the channel coding layer without syndrome or entropy coding. Second, transmission power is directly allocated to coset data and motion data according to their distributions and magnitudes without forward error correction. Third, these data are transformed by Hadamard and then directly mapped using a dense constellation (64K-QAM) for transmission without Gray coding. One of the most important properties in this framework is that the coding and transmission rate is fixed and distortion is minimized by allocating the transmission power. Thus, we further propose a power distortion optimization algorithm to replace the traditional rate distortion optimization. This framework avoids the annoying cliff effect caused by the mismatch between transmission rate and channel condition. In multicast, each user can get approximately the best quality matching its channel condition. Our experiment results show that the proposed DCast outperforms the typical solution using H.264 over 802.11 up to 8 dB in video PSNR in video broadcast. Even in video unicast, the proposed DCast is still comparable to the typical solution.","Decoding,
Encoding,
Discrete cosine transforms,
Resource management,
Noise,
Vectors"
Automatic Detection and Reconstruction of Building Radar Footprints From Single VHR SAR Images,"The spaceborne synthetic aperture radar (SAR) systems Cosmo-SkyMed, TerraSAR-X, and TanDEM-X acquire imagery with very high spatial resolution (VHR), supporting various important application scenarios, such as damage assessment in urban areas after natural disasters. To ensure a reliable, consistent, and fast extraction of the information from the complex SAR scenes, automatic information extraction methods are essential. Focusing on the analysis of urban areas, which is of prime interest of VHR SAR, in this paper, we present a novel method for the automatic detection and 2-D reconstruction of building radar footprints from VHR SAR scenes. Unlike most of the literature methods, the proposed approach can be applied to single images. The method is based on the extraction of a set of low-level features from the images and on their composition to more structured primitives using a production system. Then, the concept of semantic meaning of the primitives is introduced and used for both the generation of building candidates and the radar footprint reconstruction. The semantic meaning represents the probability that a primitive belongs to a certain scattering class (e.g., double bounce, roof, facade) and has been defined in order to compensate for the lack of detectable features in single images. Indeed, it allows the selection of the most reliable primitives and footprint hypotheses on the basis of fuzzy membership grades. The efficiency of the proposed method is demonstrated by processing a 1-m resolution TerraSAR-X spotbeam scene containing flat- and gable-roof buildings at various settings. The results show that the method has a high overall detection rate and that radar footprints are well reconstructed, in particular for medium and large buildings.",
A High-Resolution Atlas and Statistical Model of the Human Heart From Multislice CT,"Atlases and statistical models play important roles in the personalization and simulation of cardiac physiology. For the study of the heart, however, the construction of comprehensive atlases and spatio-temporal models is faced with a number of challenges, in particular the need to handle large and highly variable image datasets, the multi-region nature of the heart, and the presence of complex as well as small cardiovascular structures. In this paper, we present a detailed atlas and spatio-temporal statistical model of the human heart based on a large population of 3D+time multi-slice computed tomography sequences, and the framework for its construction. It uses spatial normalization based on nonrigid image registration to synthesize a population mean image and establish the spatial relationships between the mean and the subjects in the population. Temporal image registration is then applied to resolve each subject-specific cardiac motion and the resulting transformations are used to warp a surface mesh representation of the atlas to fit the images of the remaining cardiac phases in each subject. Subsequently, we demonstrate the construction of a spatio-temporal statistical model of shape such that the inter-subject and dynamic sources of variation are suitably separated. The framework is applied to a 3D+time data set of 138 subjects. The data is drawn from a variety of pathologies, which benefits its generalization to new subjects and physiological studies. The obtained level of detail and the extendability of the atlas present an advantage over most cardiac models published previously.",
Effective Surface Impedance of a Printed-Circuit Tensor Impedance Surface (PCTIS),"The surface impedance and dispersion equation of a printed-circuit tensor impedance surface (PCTIS) are derived using a modified transverse resonance technique. A PCTIS consists of a subwavelength-patterned metallic cladding over a grounded dielectric substrate. The metallic cladding is analytically modeled as a tensor impedance sheet. An explicit expression is derived for the effective surface impedance of the PCTIS using a transmission-line approach. First, the surface-impedance expression is found for a printed-circuit scalar impedance surface using the transverse resonance technique. Next, a modified transverse resonance technique is applied to an idealized tensor impedance boundary condition (TIBC) to find its dispersion equation. Finally, the analysis of the printed-circuit scalar impedance is combined with that of the idealized TIBC to find the tensor surface impedance and dispersion equation of a PCTIS. A discussion of the principal axes and the propagation of TM and TE waves is provided. The special case of electrically thin PCTISs is also analyzed and discussed.","Surface impedance,
Impedance,
Tensile stress,
Surface waves,
Equations,
Dispersion,
Mathematical model"
Change Detection in VHR Images Based on Morphological Attribute Profiles,A new approach to change detection in very high resolution remote sensing images based on morphological attribute profiles (APs) is presented. A multiresolution contextual transformation performed by APs allows the extraction of geometrical features related to the structures within the scene at different scales. The temporal changes are detected by comparing the geometrical features extracted from the image of each date. The experiments performed on panchromatic QuickBird images related to an urban area show the effectiveness of the proposed technique in detecting changes on the basis of the spatial morphology by preserving geometrical detail.,"Remote sensing,
Reliability,
Feature extraction,
Spatial resolution,
Buildings,
Educational institutions"
Cosimulation Environment for Event-Driven Distributed Controls of Smart Grid,"This paper proposes a cosimulation environment for “hardware in the loop” or “software in the loop” validation of distributed controls in a Smart Grid. The controls are designed using model-driven engineering with the IEC 61499 Function Block architecture. These are connected with plant models, for example, in Matlab/Simulink, through communication channels such as UDP or TCP sockets. This solution enables multi-closed-loop plant-controller simulation. The communication between plant and controller is event-driven. In order to perform a realistic simulation, the proposed solution takes into account computation and communication delays on the controller side in Function Blocks and compensates model time on the plant side in Matlab model accordingly. Causality and accuracy of the method have been formally addressed. This approach has been tested and demonstrated with several Smart Grid-related examples.","Computational modeling,
Smart grids,
IEC standards,
Delays,
Data models,
Integrated circuit modeling"
BAHG: Back-Bone-Assisted Hop Greedy Routing for VANET's City Environments,"Using advanced wireless local area network technologies, vehicular ad hoc networks (VANETs) have become viable and valuable for their wide variety of novel applications, such as road safety, multimedia content sharing, commerce on wheels, etc. Multihop information dissemination in VANETs is constrained by the high mobility of vehicles and the frequent disconnections. Currently, geographic routing protocols are widely adopted for VANETs as they do not require route construction and route maintenance phases. Again, with connectivity awareness, they perform well in terms of reliable delivery. To obtain destination position, some protocols use flooding, which can be detrimental in city environments. Further, in the case of sparse and void regions, frequent use of the recovery strategy elevates hop count. Some geographic routing protocols adopt the minimum weighted algorithm based on distance or connectivity to select intermediate intersections. However, the shortest path or the path with higher connectivity may include numerous intermediate intersections. As a result, these protocols yield routing paths with higher hop count. In this paper, we propose a hop greedy routing scheme that yields a routing path with the minimum number of intermediate intersection nodes while taking connectivity into consideration. Moreover, we introduce back-bone nodes that play a key role in providing connectivity status around an intersection. Apart from this, by tracking the movement of source as well as destination, the back-bone nodes enable a packet to be forwarded in the changed direction. Simulation results signify the benefits of the proposed routing strategy in terms of high packet delivery ratio and shorter end-to-end delay.","Routing,
Roads,
Cities and towns,
Vehicles,
Routing protocols,
Bones"
Charge Quantity Influence on Resistance Switching Characteristic During Forming Process,"In this letter, we presented that the charge quantity is the critical factor for forming process. Forming is a pivotal process in resistance random access memory to activate the resistance switching behavior. However, overforming would lead to device damage. In general, the overshoot current has been considered as a degradation reason during the forming process. In this letter, the quantity of charge through the switching layer has been proven as the key element in the formation of the conduction path. Ultrafast pulse forming can form a discontinuous conduction path to reduce the operation power.","Switches,
Resistance,
Educational institutions,
Hafnium compounds,
Tin,
Electrodes,
Silicon"
Behavior-Rule Based Intrusion Detection Systems for Safety Critical Smart Grid Applications,"In this paper, a behavior-rule based intrusion detection system (BRIDS) is proposed for securing head-ends (HEs), distribution access points/data aggregation points (DAPs) and subscriber energy meters (SEMs) of a modern electrical grid in which continuity of operation is of the utmost importance. The impact of attacker behaviors on the effectiveness of a behavior-rule intrusion detection design is investigated. Using HEs, DAPs and SEMs as examples, it is demonstrated that a behavior-rule based intrusion detection technique can effectively trade false positives for a high detection probability to cope with sophisticated and hidden attackers to support ultra safe and secure applications. It is shown that BRIDS outperforms contemporary anomaly-based IDSs via comparative analysis.","Monitoring,
Intrusion detection,
Generators,
Sensors,
Density estimation robust algorithm,
Actuators,
Home appliances"
Steep switching tunnel FET: A promise to extend the energy efficient roadmap for post-CMOS digital and analog/RF applications,"Steep switching Tunnel FETs (TFET) can extend the supply voltage scaling with improved energy efficiency for both digital and analog/RF application. In this paper, recent approaches on III-V Tunnel FET device design, prototype device demonstration, modeling techniques and performance evaluations for digital and analog/RF application are discussed and compared to CMOS technology. The impact of steep switching, uni-directional conduction and negative differential resistance characteristics are explored from circuit design perspective. Circuit-level implementation such as III-V TFET based Adder and SRAM design shows significant improvement on energy efficiency and power reduction below 0.3V for digital application. The analog/RF metric evaluation is presented including gm/Ids metric, temperature sensitivity, parasitic impact and noise performance. TFETs exhibit promising performance for high frequency, high sensitivity and ultra-low power RF rectifier application.","Silicon,
FinFETs,
Radio frequency,
Logic gates,
CMOS integrated circuits,
Energy efficiency,
Random access memory"
Localization in Urban Environments Using a Panoramic Gist Descriptor,"Vision-based topological localization and mapping for autonomous robotic systems have received increased research interest in recent years. The need to map larger environments requires models at different levels of abstraction and additional abilities to deal with large amounts of data efficiently. Most successful approaches for appearance-based localization and mapping with large datasets typically represent locations using local image features. We study the feasibility of performing these tasks in urban environments using global descriptors instead and taking advantage of the increasingly common panoramic datasets. This paper describes how to represent a panorama using the global gist descriptor, while maintaining desirable invariance properties for location recognition and loop detection. We propose different gist similarity measures and algorithms for appearance-based localization and an online loop-closure detection method, where the probability of loop closure is determined in a Bayesian filtering framework using the proposed image representation. The extensive experimental validation in this paper shows that their performance in urban environments is comparable with local-feature-based approaches when using wide field-of-view images.","Image representation,
Vocabulary,
Urban areas,
Databases,
Robots,
Image recognition,
Cameras"
Exploring Malicious Meter Inspection in Neighborhood Area Smart Grids,"In smart grids, smart meters may potentially be attacked or compromised to cause certain security risks. It is challenging to identify malicious meters when there are a large number of users. In this paper, we explore the malicious meter inspection (MMI) problem in neighborhood area smart grids. We propose a suite of inspection algorithms in a progressive manner. First, we present a basic scanning method, which takes linear time to accomplish inspection. The scanning method is efficient when the malicious meter ratio is high. Then, we propose a binary-tree-based inspection algorithm, which performs better than scanning when the malicious meter ratio is low. Finally, we employ an adaptive-tree-based algorithm, which leverages advantages of both the scanning and binary-tree inspections. Our approaches are tailored to fit both static and dynamic situations. The theoretical and experimental results have shown the effectiveness of the adaptive tree approach.",
Five-Port Optical Router Based on Microring Switches for Photonic Networks-on-Chip,"We demonstrate a five-port optical router that is suitable for large-scale photonic networks-on-chip. The optical router is designed to passively route the optical signal travelling in one direction and actively route the optical signal making a turn. In the case that an XY dimension-order routing is used, the passive routing feature guarantees that the maximum power consumption to route the data through the network is a constant that is independent of the network size. The fabricated device has an efficient footprint of ~ 460 × 1000 μm2. The routing functionality of the device is verified by using a 12.5-Gbit/s optical signal. The capability of multiwavlength routing for the optical router is also explored and discussed.","Optical resonators,
Ports (Computers),
Optical switches,
Optical distortion,
Optical filters,
Optical device fabrication,
Optical interferometry"
Physics of Multiple-Node Charge Collection and Impacts on Single-Event Characterization and Soft Error Rate Prediction,"Physical mechanisms of single-event effects that result in multiple-node charge collection or charge sharing are reviewed and summarized. A historical overview of observed circuit responses is given that concentrates mainly on memory circuits. Memory devices with single-node upset mechanisms are shown to exhibit multiple cell upsets, and spatially redundant logic latches are shown to upset when charge is collected on multiple circuit nodes in the latch. Impacts on characterizing these effects in models and ground-based testing are presented. The impact of multiple-node charge collection on soft error rate prediction is also presented and shows that full circuit prediction is not yet well understood. Finally, gaps in research and potential future impacts are identified.","Transistors,
Junctions,
SRAM cells,
Silicon,
Integrated circuit modeling,
Photoconductivity"
Deaf Cooperation and Relay Selection Strategies for Secure Communication in Multiple Relay Networks,"In this paper, we investigate the roles of cooperative jamming (CJ) and noise forwarding (NF) in improving the achievable secrecy rates of a Gaussian wiretap channel (GWT). In particular, we study the role of a deaf helper in confusing the eavesdropper in a GWT channel by either transmitting white Gaussian noise (cooperative jamming) or by transmitting a dummy codeword of no context yet drawn from a codebook known to both the destination and the eavesdropper (noise forwarding). We first derive the conditions under which each mode of deaf cooperation improves over the secrecy capacity of the original wiretap channel and show that a helping node can be either a useful cooperative jammer or a useful noise forwarder but not both at the same time. Secondly, we derive the optimal power allocation for both the source and the helping node to be used in each of the two modes of deaf helping. Thirdly, we consider the deaf helper selection problem where there are N relays present in the system and it is required to select the best K deaf helpers, K ≥ 1, that yield the maximum possible achievable secrecy rate. For the case of K=1, we give the optimal selection strategy with optimal power allocation. The computational complexity of the optimal selection strategy when K > 1 is relatively large, especially for large values of K and N. Thus, we propose a suboptimal strategy for the selection problem when K > 1. We derive the complexity of the proposed selection strategies and show that, for K > 1, our suboptimal strategy, which works in a greedy fashion, enjoys a significantly less computational complexity than the optimal strategy. Nevertheless, as demonstrated by numerical examples, our suboptimal strategy gives rise to reasonable performance gains in terms of the achievable secrecy rate with respect to the case of K=1.","Relays,
Jamming,
Resource management,
Noise,
Noise measurement,
Complexity theory,
Receivers"
Estimation of NAND Flash Memory Threshold Voltage Distribution for Optimum Soft-Decision Error Correction,"As the feature size of NAND flash memory decreases, the threshold voltage signal becomes less reliable, and its distribution varies significantly with the number of program-erase (PE) cycles and the data retention time. We have developed parameter estimation algorithms to find the means and variances of the threshold voltage distribution that is modeled as a Gaussian mixture. The proposed methods find the best-fit parameters by minimizing the squared Euclidean distance between the measured threshold voltage values and those obtained from the Gaussian mixture model. For the parameter estimation, the gradient descent (GD) and the Levenberg-Marquardt (LM) based methods are employed. The developed algorithms are applied to both simulated and real NAND flash memory. It is also demonstrated that error correction with the estimated mean and variance values yields much better performance when compared to the method that only updates the mean.","Threshold voltage,
Flash memory,
Sensors,
Voltage measurement,
Signal to noise ratio,
Error correction,
Parameter estimation"
Toward Detection and Localization of Instruments in Minimally Invasive Surgery,"Methods for detecting and localizing surgical instruments in laparoscopic images are an important element of advanced robotic and computer-assisted interventions. Robotic joint encoders and sensors integrated or mounted on the instrument can provide information about the tool's position, but this often has inaccuracy when transferred to the surgeon's point of view. Vision sensors are currently a promising approach for determining the position of instruments in the coordinate frame of the surgical camera. In this study, we propose a vision algorithm for localizing the instrument's pose in 3-D leaving only rotation in the axis of the tool's shaft as an ambiguity. We propose a probabilistic supervised classification method to detect pixels in laparoscopic images that belong to surgical tools. We then use the classifier output to initialize an energy minimization algorithm for estimating the pose of a prior 3-D model of the instrument within a level set framework. We show that the proposed method is robust against noise using simulated data and we perform quantitative validation of the algorithm compared to ground truth obtained using an optical tracker. Finally, we demonstrate the practical application of the technique on in vivo data from minimally invasive surgery with traditional laparoscopic and robotic instruments.","Instruments,
Image color analysis,
Surgery,
Robots,
Vectors,
Noise,
Shape"
Optimal Multiple Surface Segmentation With Shape and Context Priors,"Segmentation of multiple surfaces in medical images is a challenging problem, further complicated by the frequent presence of weak boundary evidence, large object deformations, and mutual influence between adjacent objects. This paper reports a novel approach to multi-object segmentation that incorporates both shape and context prior knowledge in a 3-D graph-theoretic framework to help overcome the stated challenges. We employ an arc-based graph representation to incorporate a wide spectrum of prior information through pair-wise energy terms. In particular, a shape-prior term is used to penalize local shape changes and a context-prior term is used to penalize local surface-distance changes from a model of the expected shape and surface distances, respectively. The globally optimal solution for multiple surfaces is obtained by computing a maximum flow in a low-order polynomial time. The proposed method was validated on intraretinal layer segmentation of optical coherence tomography images and demonstrated statistically significant improvement of segmentation accuracy compared to our earlier graph-search method that was not utilizing shape and context priors. The mean unsigned surface positioning errors obtained by the conventional graph-search approach (6.30 ±1.58 μ m) was improved to 5.14±0.99 μ m when employing our new method with shape and context priors.","Shape,
Context,
Silicon,
Image segmentation,
Optimization,
USA Councils,
Cities and towns"
An Optimization Approach to Improved Petri Net Controller Design for Automated Manufacturing Systems,"Sensors and actuators are two indispensable parts in the paradigm of feedback control. Their implementation cost should be properly evaluated and constrained. In the previous work, a Petri net monitor with the least cost is synthesized through integer programming formulation. Despite its technical correctness, the existing method may lead to undesirable results when the net structure contains some shared or unshared resource places of a manufacturing-oriented net model. A necessary and sufficient condition is established to show that certain structures can lead to deadlock-prone supervisors. An efficient algorithm is developed to identify such structures. Furthermore, it is shown that if one can identify such structures at the initial stage, it is possible to achieve desirable controllers for the original systems. The theoretical correctness of the proposed algorithm is discussed. A manufacturing example is provided to illustrate the proposed approach.","Monitoring,
Petri nets,
IP networks,
Control systems,
Manufacturing systems,
Vectors,
Mathematical model"
Swarm Coordination Based on Smoothed Particle Hydrodynamics Technique,"The focus of this study is on the design of feedback control laws for swarms of robots that are based on models from fluid dynamics. We apply an incompressible fluid model to solve a pattern generation task. Possible applications of an efficient solution to this task are surveillance and the cordoning off of hazardous areas. More specifically, we use the smoothed-particle hydrodynamics (SPH) technique to devise decentralized controllers that force the robots to behave in a similar manner to fluid particles. Our approach deals with static and dynamic obstacles. Considerations such as finite size and nonholonomic constraints are also addressed. In the absence of obstacles, we prove the stability and convergence of controllers that are based on the SPH method. Computer simulations and actual robot experiments are shown to validate the proposed approach.","Robot kinematics,
Mathematical model,
Equations,
Kernel,
Harmonic analysis,
Hydrodynamics"
Magnetic Resonance Image Example-Based Contrast Synthesis,"The performance of image analysis algorithms applied to magnetic resonance images is strongly influenced by the pulse sequences used to acquire the images. Algorithms are typically optimized for a targeted tissue contrast obtained from a particular implementation of a pulse sequence on a specific scanner. There are many practical situations, including multi-institution trials, rapid emergency scans, and scientific use of historical data, where the images are not acquired according to an optimal protocol or the desired tissue contrast is entirely missing. This paper introduces an image restoration technique that recovers images with both the desired tissue contrast and a normalized intensity profile. This is done using patches in the acquired images and an atlas containing patches of the acquired and desired tissue contrasts. The method is an example-based approach relying on sparse reconstruction from image patches. Its performance in demonstrated using several examples, including image intensity normalization, missing tissue contrast recovery, automatic segmentation, and multimodal registration. These examples demonstrate potential practical uses and also illustrate limitations of our approach.","Image reconstruction,
Algorithm design and analysis,
Dictionaries,
Vectors,
Image segmentation,
Image analysis,
Histograms"
Empirical Study on the Effect of Achievement Badges in TRAKLA2 Online Learning Environment,"Achievement badges are a form of gamification that can be used to motivate users and to encourage desired actions. In this study, we describe and evaluate the use of achievement badges in the TRAKLA2 online learning environment where students complete interactive, automatically assessed exercises about data structures and algorithms. The students' activity in TRAKLA2 was logged in order to find out whether the achievement badges had an effect on their behavior. We used a between-subject experimental design where the students (N=281) were randomly divided into a treatment and a control group, with and without achievement badges. Students in the treatment group were awarded achievement badges, for example, for solving exercises with only one attempt, returning exercises early, or completing an exercise round with full points. Course grading was similar for both groups, i.e. collecting badges did not affect the final grade. Our results show that achievement badges can be used to affect the behavior of students even when the badges have no impact on the grading. Statistically significant differences in students' behavior were observed with some badge types, while some badges did not seem to have such an effect. We also found that students in the two studied courses responded differently to the badges. Based on our findings, achievement badges seem like a promising method to motivate students and to encourage desired study practices.","Games,
Data structures,
Computer science,
Educational institutions,
Algorithm design and analysis,
Calibration"
Distributed Angle Estimation for Localization in Wireless Sensor Networks,"In this paper, we design a new distributed angle estimation method for localization in wireless sensor networks (WSNs) under multipath propagation environment. We employ a two-antenna anchor that can emit two linear chirp waves simultaneously, and propose to estimate the angle of departure (AOD) of the emitted waves at each receiving node via frequency measurement of the local received signal strength indication (RSSI) signal. An improved estimation method is further proposed where multiple parallel arrays are adopted to provide the space diversity. The proposed methods rely only on radio transceivers and do not require frequency synchronization or precise time synchronization between the transceivers. More importantly, the angle is estimated at each sensor in a completely distributed manner. The performance analysis is derived and simulations are presented to corroborate the proposed studies.","Estimation,
Receivers,
Wireless sensor networks,
Antennas,
Interference,
Chirp,
Frequency estimation"
EEG-Based Classification of Fast and Slow Hand Movements Using Wavelet-CSP Algorithm,"A brain-computer interface (BCI) acquires brain signals, extracts informative features, and translates these features to commands to control an external device. This paper investigates the application of a noninvasive electroencephalography (EEG)based BCI to identify brain signal features in regard to actual hand movement speed. This provides a more refined control for a BCI system in terms of movement parameters. An experiment was performed to collect EEG data from subjects while they performed right-hand movement at two different speeds, namely fast and slow, in four different directions. The informative features from the data were obtained using the Wavelet-Common Spatial Pattern (W-CSP) algorithm that provided high-temporal-spatial-spectral resolution. The applicability of these features to classify the two speeds and to reconstruct the speed profile was studied. The results for classifying speed across seven subjects yielded a mean accuracy of 83.71% using a Fisher Linear Discriminant (FLD) classifier. The speed components were reconstructed using multiple linear regression and significant correlation of 0.52 (Pearson's linear correlation coefficient) was obtained between recorded and reconstructed velocities on an average. The spatial patterns of the W-CSP features obtained showed activations in parietal and motor areas of the brain. The results achieved promises to provide a more refined control in BCI by including control of movement speed.","Feature extraction,
Electroencephalography,
Filter banks,
Classification algorithms,
Algorithm design and analysis,
Filtering algorithms,
Discrete wavelet transforms"
Direct Causality Detection via the Transfer Entropy Approach,"The detection of direct causality, as opposed to indirect causality, is an important and challenging problem in root cause and hazard propagation analysis. Several methods provide effective solutions to this problem when linear relationships between variables are involved. For nonlinear relationships, currently only overall causality analysis can be conducted, but direct causality cannot be identified for such processes. In this paper, we describe a direct causality detection approach suitable for both linear and nonlinear connections. Based on an extension of the transfer entropy approach, a direct transfer entropy (DTE) concept is proposed to detect whether there is a direct information flow pathway from one variable to another. Especially, a differential direct transfer entropy concept is defined for continuous random variables, and a normalization method for the differential direct transfer entropy is presented to determine the connectivity strength of direct causality. The effectiveness of the proposed method is illustrated by several examples, including one experimental case study and one industrial case study.",
Long-Wavelength VCSEL Using High-Contrast Grating,"Recent advances in high-contrast grating (HCG) vertical-cavity surface-emitting lasers (VCSEL) emitting at 1550 nm is reported in this paper. The novel near-wavelength HCG has an ultrathin structure and broadband reflectivity. It enables a monolithic, simple fabrication process for realizing InP-based VCSELs emitting at ~1550 nm. We report 2.4-mW single-mode output under continuous-wave operation at 15°C. We show that, despite broadened by the Brownian motion, the HCG-VCSEL has a total linewidth of 60 MHz or a coherent length of 5 m in air, and an intrinsic linewidth <;20 MHz. Transmission of directly modulated 10 Gbps over 100-km dispersion-compensated single-mode fiber is demonstrated. Tunable HCG-VCSEL is demonstrated with the HCG integrated with a micro-electro-mechanical structure. Continuous wavelength tuning as wide as 26.3 nm is achieved. The tunable VCSEL was used as a source for external modulation for 40-Gbps differential-phase-shift-keyed signal and transmitted over 100-km dispersion-compensated link with negligible power penalty.","Vertical cavity surface emitting lasers,
Reflectivity,
Gratings,
Optical fiber communication,
Delay,
Micromechanical devices,
Fiber lasers"
Experimental study on conduction current of positive nanosecond-pulse diffuse discharge at atmospheric pressure,"Nanosecond pulsed discharges have various discharge modes, such as corona, diffuse discharge, spark or arc. A dense diffuse discharge is particularly desirable for various applications at atmospheric pressure. In this paper, a magnetic-compression pulse generator was used to produce repetitive positive nanosecond pulses for excitation of a diffuse discharge. The output pulse of the generator had a rise time of about 25 ns and a full width at half maximum of 40 ns. Electrical characteristics of the diffuse discharge were studied by measuring its voltage and current waveforms, as well as images of the discharge. The conduction current was calculated by the measured voltage and current, which was a true discharge current. The experimental results show that a stable diffuse discharge could be obtained at atmospheric pressure, and the conduction current was unipolar and had similar amplitude of several amperes under our experimental condition, which has the similar amplitude with the displacement current. Furthermore, the air gap spacing and pulse repetition frequency (PRF) affected the intensity and mode transition of the diffuse discharge. The conduction current increased with the PRF but decreased with the air gap spacing. Therefore, the diffuse discharge was likely available under some conditions of proper air gap, high PRF with positive pulse.",
Reliable Space-Mapping Optimization Integrated With EM-Based Adjoint Sensitivities,"We present a robust space mapping (SM) algorithm exploiting electromagnetic (EM)-based adjoint sensitivities for microwave design optimization. Our approach utilizes low-cost EM-based adjoint sensitivities and trust region methods to improve an SM algorithm at three levels, which are: 1) to build a better overall surrogate while ensuring convergence; 2) to speed up and safeguard the parameter extraction steps; and 3) to speed up and safeguard the surrogate optimization process. We describe the implementation at each level in detail. We review relevant adjoint sensitivity analysis methods. We also review prior SM methods that exploit both sensitivity and adjoint sensitivity. We summarize these methods in four categories. We compare our proposed approach with them. Efficiency, robustness, and versatility of our method are demonstrated by three design examples: an antenna, a planar filter, and a 3-D resonator filter. We compare the results with those obtained by SM without using adjoint sensitivity information and by direct optimization of the high-fidelity EM models.","Sensitivity,
Optimization,
Integrated circuit modeling,
Solid modeling,
Parameter extraction,
Computational modeling,
Convergence"
3-D Mesh-Based Optical Network-on-Chip for Multiprocessor System-on-Chip,"Optical networks-on-chip (ONoCs) are emerging communication architectures that can potentially offer ultrahigh communication bandwidth and low latency to multiprocessor systems-on-chip (MPSoCs). In addition to ONoC architectures, 3-D integrated technologies offer an opportunity to continue performance improvements with higher integration densities. In this paper, we present a 3-D mesh-based ONoC for MPSoCs, and new low-cost nonblocking 4 × 4, 5 × 5, 6 × 6, and 7 × 7 optical routers for dimension-order routing in the 3-D mesh-based ONoC. Besides, we propose an optimized floorplan for the 3-D mesh-based ONoC. The floorplan follows the regular 3-D mesh topology but implements all optical routers in a single optical layer. The floorplan is optimized to minimize the number of extra waveguide crossings caused when merging the 3-D ONoC to one optical layer. Based on a set of real applications and uniform traffic pattern, we develop a SystemC-based cycle-accurate NoC simulator and compare the 3-D mesh-based ONoC with the matched 2-D mesh-based ONoC and 2-D electronic NoC for performance and energy efficiency. Additionally, we quantitatively analyze thermal effects on the 3-D 8 × 8 × 2 mesh-based ONoC.","Optical waveguides,
Optical switches,
Optical network units,
Optical receivers,
Routing,
High-speed optical techniques"
A Comparative Study on Linear Regression-Based Noise Estimation for Hyperspectral Imagery,"In the traditional signal model, signal is assumed to be deterministic, and noise is assumed to be random, additive and uncorrelated to the signal component. A hyperspectral image has high spatial and spectral correlation, and a pixel can be well predicted using its spatial and/or spectral neighbors; any prediction error can be considered from noise. Using this concept, several algorithms have been developed for noise estimation for hyperspectral images. However, these algorithms have not been rigorously analyzed with a unified scheme. In this paper, we conduct a comparative study for such linear regression-based algorithms using simulated images with different signal-to-noise ratio (SNR) and real images with different land cover types. Based on experimental results, instructive guidance is concluded for their practical applications.","Estimation,
Standards,
Earth,
Hyperspectral imaging,
Signal to noise ratio"
Intercalibration of Microwave Radiometer Brightness Temperatures for the Global Precipitation Measurement Mission,"A technique for comparing spaceborne microwave radiometer brightness temperatures (Tb) is described in the context of the upcoming National Aeronautics and Space Administration Global Precipitation Measurement (GPM) mission. The GPM mission strategy is to measure precipitation globally with high temporal resolution by using a constellation of satellite radiometers logically united by the GPM core satellite, which will be in a non-sun-synchronous medium inclination orbit. The usefulness of the combined product depends on the consistency of precipitation retrievals from the various microwave radiometers. The Tb calibration requirement to achieve such consistency demands first that Tb's from the individual radiometers be free of instrument and measurement artifacts and, second, that these self-consistent Tb's will be translated to a common standard (GPM core) for the unification of the precipitation retrieval. The intersatellite radiometric calibration technique described herein serves both the purposes by comparing individual radiometer observations to radiative transfer model (RTM) simulations (for “self-consistency” check) and by using a double-difference technique (to establish a linear calibration transfer function from one radiometer to another). This double-difference technique subtracts the RTM-simulated difference from the observed difference between a pair of radiometer Tb's. To establish a linear inter-radiometer calibration transfer function, comparisons at both the cold (ocean) and the warm (land) end of the Tb's are necessary so that, using these two points, slope and offset coefficients are determined. To this end, a simplified calibration transfer technique at the warm end (over the Amazon and Congo rain forest) is introduced. Finally, an error model is described that provides an estimate of the uncertainty of the radiometric bias estimate between comparison radiometer channels.","Microwave radiometry,
Calibration,
Atmospheric modeling,
Ocean temperature,
Instruments,
Brightness temperature"
Crowdsourcing Multimedia QoE Evaluation: A Trusted Framework,"Crowdsourcing has emerged in recent years as a potential strategy to enlist the general public to solve a wide variety of tasks. With the advent of ubiquitous Internet access, it is now feasible to ask an Internet crowd to conduct QoE (Quality of Experience) experiments on their personal computers in their own residences rather than in a laboratory. The considerable size of the Internet crowd allows researchers to crowdsource their experiments to a more diverse set of participant pool at a relatively low economic cost. However, as participants carry out experiments without supervision, the uncertainty of the quality of their experiment results is a challenging problem. In this paper, we propose a crowdsourceable framework to quantify the QoE of multimedia content. To overcome the aforementioned quality problem, we employ a paired comparison method in our framework. The advantages of our framework are: 1) trustworthiness due to the support for cheat detection; 2) a simpler rating procedure than that of the commonly-used but more difficult mean opinion score (MOS), which places less burden on participants; 3) economic feasibility since reliable QoE measures can be acquired with less effort compared with MOS; and 4) generalizability across a variety of multimedia content. We demonstrate the effectiveness and efficiency of the proposed framework by a comparison with MOS. Moreover, the results of four case studies support our assertion that the framework can provide reliable QoE evaluation at a lower cost.","Multimedia communication,
Internet,
Reliability,
Laboratories,
Economics,
Atmospheric measurements,
Particle measurements"
Joint Power and Admission Control via Linear Programming Deflation,"We consider the joint power and admission control problem for a wireless network consisting of multiple interfering links. The goal is to support a maximum number of links at their specified signal to interference plus noise ratio (SINR) targets while using a minimum total transmission power. In this work, we first reformulate this NP-hard problem as a sparse l0-minimization problem and then relax it to a linear program. Furthermore, we derive two easy-to-check necessary conditions for all links in the network to be simultaneously supported at their target SINR levels, and use them to iteratively remove strong interfering links (deflation). An upper bound on the maximum number of supported links is also given. Numerical simulations show that the proposed approach compares favorably with the existing approaches in terms of the number of supported links, the total transmission power, and the execution time.","Interference,
Signal to noise ratio,
Admission control,
Joints,
Power control,
Vectors"
"Scalable, adaptive and survivable trust management for community of interest based Internet of Things systems","An Internet of Things (IoT) system connects a large amount of tags, sensors, and mobile devices to facilitate information sharing, enabling a variety of attractive applications. It challenges the design and evaluation of IoT systems to meet the scalability, compatibility, extendibility, dynamic adaptability and resiliency requirements. In this paper, we design and evaluate a scalable, adaptive and survivable trust management protocol in dynamic IoT environments. Recognizing that entities in an IoT system are connected through social networks of entity owners, we consider a community of interest (CoI) based social IoT where nodes form into communities of interest. Given inter-CoI vs. intra-CoI social connections among entity owners as input, we identify best trust protocol settings for achieving convergence, accuracy, dynamic adaptability and resiliency properties in the presence of dynamically changing conditions and malicious nodes performing trust-related attacks. For scalability, we consider a design by which a node only keeps trust information of a subset of nodes meeting its interest and performs minimum computation to update trust. We validate our design by extensive simulation considering both limited and ideal (unlimited) storage space. The results demonstrate that our trust management protocol using limited storage space achieves a similar performance level compared with the one under ideal storage space, and a newly joining node can quickly build up trust towards other nodes with desirable accuracy and convergence behavior.","Protocols,
Communities,
Scalability,
Storage management,
Convergence,
Internet of Things,
Accuracy"
On the steady-state of cache networks,"Over the past few years Content-Centric Networking, a networking model in which host-to-content communication protocols are introduced, has been gaining much attention. A central component of such an architecture is a large-scale interconnected caching system. To date, the way these Cache Networks operate and perform is still poorly understood. In this work, we demonstrate that certain cache networks are non-ergodic in that their steady-state characterization depends on the initial state of the system. We then establish several important properties of cache networks, in the form of three independently-sufficient conditions for a cache network to comprise a single ergodic component. Each property targets a different aspect of the system - topology, admission control and cache replacement policies. Perhaps most importantly we demonstrate that cache replacement can be grouped into equivalence classes, such that the ergodicity (or lack-thereof) of one policy implies the same property holds for all policies in the class.","Steady-state,
Markov processes,
Topology,
Network topology,
Routing,
Admission control,
Delays"
Underdetermined Sound Source Separation Using Power Spectrum Density Estimated by Combination of Directivity Gain,"A method for separating underdetermined sound sources based on a novel power spectral density (PSD) estimation is proposed. The method enables up to M(M-1)+1 sources to be separated when we use a microphone array of M sensors and a Wiener post-filter calculated by the estimated PSDs. The PSD of a beamformer's output is modelled by a mixture of source PSDs multiplied by the beamformer's directivity gain in the particular angle where each source is located. Based on this model, the PSD of each sound source is estimated from the PSD of multiple fixed beamformers' outputs using the difference in the combination of directivity gains. Simulation results proved that the proposed method effectively separated up to M(M-1)+1 sound sources if the fixed beamformers were appropriately selected. Experiments were also conducted in a reverberant chamber to ensure the proposed method was also effective in practical use.","Tin,
Microwave integrated circuits,
Arrays,
Estimation,
Array signal processing"
Adaptive Duty Cycle Control with Queue Management in Wireless Sensor Networks,"This paper proposes a control-based approach to the duty cycle adaptation for wireless sensor networks. The proposed method controls the duty cycle through the queue management to achieve high-performance under variable traffic rates. To have energy efficiency while minimizing the delay, we design a feedback controller, which adapts the sleep time to the traffic change dynamically by constraining the queue length at a predetermined value. In addition, we propose an efficient synchronization scheme using an active pattern, which represents the active time slot schedule for synchronization among sensor nodes, without affecting neighboring schedules. Based on the control theory, we analyze the adaptation behavior of the proposed controller and demonstrate system stability. The simulation results show that the proposed method outperforms existing schemes by achieving more power savings while minimizing the delay.",
Relay Selection and Resource Allocation for Two-Way DF-AF Cognitive Radio Networks,"In this letter, the problem of relay selection and optimal resource allocation for two-way relaying cognitive radio networks using half duplex amplify-and-forward and decode-and-forward protocols is investigated. The primary and secondary users are assumed to access the spectrum simultaneously, in a way that the interference introduced to the primary users should be below a certain tolerated limit. Dual decomposition and subgradient methods are used to find the optimal power allocation. A suboptimal approach based on a genetic algorithm is also presented. Simulation results show that the proposed suboptimal algorithm offers a performance close to the optimal performance with a considerable complexity saving.","resource allocation,
amplify and forward communication,
cognitive radio,
decode and forward communication,
genetic algorithms,
protocols,
relay networks (telecommunication)"
Pattern-Reconfigurable Planar Circular Ultra-Wideband Monopole Antenna,"A novel pattern-reconfigurable compact planar ultra-wideband monopole antenna is presented. By the incorporation of four p-i-n diode switches and two parasitic elements, the antenna's radiation patterns can be shaped to concentrate energy in specific directions while minimising the gain in other unwanted directions without significantly affecting the impedance bandwidth of the antenna. A fully functional prototype has been developed and tested. The measured results of the return loss, radiation patterns, and realised gain verify the effectiveness of the proposed antenna configuration. The antenna switches its radiation patterns between an omni-directional mode and two directional modes with opposite directions in the operating range from 3 to 6 GHz. The proposed antenna could be a suitable candidate for advanced and smart radio applications such as cognitive radio (CR) as it can enhance the radio front-end flexibility and performance by adding the benefits of pattern diversity, specifically in multipath environments.","Antenna radiation patterns,
Ultra wideband antennas,
P-i-n diodes,
Antenna measurements,
Bandwidth,
Directive antennas"
A Novel Method for Calculating Service Reputation,"Owing to their rapid development, services are increasing rapidly in quantity. The consequence is that there are so many services that share the same or similar functions. Therefore, it is important to select a credible and optimal service. Reputation as one of the important parameters of services plays a significant role in the decision support for service selection. This paper proposes a novel two-phase method to calculate service reputation. The first phase uses a dynamic weight formula to calculate reputation such that it can reflect the latest tendency of a service. The second one uses an olfactory response formula to mitigate the negative effect of unfair ratings. Some experiments are conducted and the results validate the effectiveness of the proposed method.","Olfactory,
Fatigue,
Web services,
Quality of service,
Fading,
Hidden Markov models,
Bayesian methods"
A Lightweight Multicast Authentication Mechanism for Small Scale IoT Applications,"Security is very important for Internet of Things (IoTs). As a main communication mode, the security mechanism for multicast is not only the measure to ensure secured communications, but also the precondition for other security services. With the analysis of Nyberg's fast one-way accumulator and its security, we discover that it has the property of absorbency in addition to the one-way and quasi-communicative property that makes it very suitable for applications in which accumulated items are dynamic. In this paper, we revise the original Nyberg's fast one-way accumulator and construct a lightweight multicast authentication mechanism for small scale IoT applications. We analyze the security of the mechanism in detail. In addition, we evaluate seven performance aspects of the mechanism.","telecommunication security,
Internet of Things"
Mining Semantic Context Information for Intelligent Video Surveillance of Traffic Scenes,"Automated visual surveillance systems are attracting extensive interest due to public security. In this paper, we attempt to mine semantic context information including object-specific context information and scene-specific context information (learned from object-specific context information) to build an intelligent system with robust object detection, tracking, and classification and abnormal event detection. By means of object-specific context information, a cotrained classifier, which takes advantage of the multiview information of objects and reduces the number of labeling training samples, is learned to classify objects into pedestrians or vehicles with high object classification performance. For each kind of object, we learn its corresponding semantic scene-specific context information: motion pattern, width distribution, paths, and entry/exist points. Based on this information, it is efficient to improve object detection and tracking and abnormal event detection. Experimental results demonstrate the effectiveness of our semantic context features for multiple real-world traffic scenes.","Context,
Trajectory,
Semantics,
Vehicles,
Object detection,
Training,
Tracking"
Spectrum and Energy Efficient Relay Station Placement in Cognitive Radio Networks,"Cognitive radio technology enables secondary users (SUs) to opportunistically use the vacant licensed spectrum and significantly improves the utilization of spectrum resource. Traditional architectures for cognitive radio networks (CRNs), such as cognitive cellular networks and cognitive ad hoc networks, impose energy-consuming cognitive radios to SUs' devices for communication and cannot efficiently utilize the spectrum harvested from the primary users (PUs). To enhance the spectrum and energy efficiencies of CRNs, we have designed a new architecture, which is called the Cognitive Capacity Harvesting network (CCH). In CCH, a collection of relay stations (RSs) with cognitive capability are deployed to facilitate the accessing of SUs. In this way, the architecture not only removes the requirement of cognitive radios from SUs and reduces their energy consumption, but also increases frequency reuse and enhances spectrum efficiency. In view of the importance of the RSs on the improvement of spectrum and energy efficiencies, in this paper, we study the RS placement strategy in CCH. A cost minimization problem is mathematically formulated under the spectrum and energy efficiency constraints. Considering the NP-hardness of the problem, we design a framework of heuristic algorithms to compute the near-optimal solutions. Extensive simulations show that the proposed algorithms outperform the random placement strategy and the number of required RSs obtained by our algorithms is always within 2 times of that in the optimal solution.","relay networks (telecommunication),
cognitive radio,
communication complexity,
cost reduction,
frequency allocation"
Using robotic exploratory procedures to learn the meaning of haptic adjectives,"Delivering on the promise of real-world robotics will require robots that can communicate with humans through natural language by learning new words and concepts through their daily experiences. Our research strives to create a robot that can learn the meaning of haptic adjectives by directly touching objects. By equipping the PR2 humanoid robot with state-of-the-art biomimetic tactile sensors that measure temperature, pressure, and fingertip deformations, we created a platform uniquely capable of feeling the physical properties of everyday objects. The robot used five exploratory procedures to touch 51 objects that were annotated by human participants with 34 binary adjective labels. We present both static and dynamic learning methods to discover the meaning of these adjectives from the labeled objects, achieving average F1 scores of 0.57 and 0.79 on a set of eight previously unfelt items.","Robot sensing systems,
Haptic interfaces,
Grippers,
Metals,
Biosensors"
Projection Reconstruction Magnetic Particle Imaging,"We acquire the first experimental 3-D tomographic images with magnetic particle imaging (MPI) using projection reconstruction methodology, which is similar to algorithms employed in X-ray computed tomography. The primary advantage of projection reconstruction methods is an order of magnitude increase in signal-to-noise ratio (SNR) due to averaging. We first derive the point spread function, resolution, number of projections required, and the SNR gain in projection reconstruction MPI. We then design and construct the first scanner capable of gathering the necessary data for nonaliased projection reconstruction and experimentally verify our mathematical predictions. We demonstrate that filtered backprojection in MPI is experimentally feasible and illustrate the SNR and resolution improvements with projection reconstruction. Finally, we show that MPI is capable of producing three dimensional imaging volumes in both phantoms and postmortem mice.","Image reconstruction,
Signal to noise ratio,
Magnetic resonance imaging,
Mathematical model,
Equations,
Coils"
Technological roadmap to boost the introduction of AGVs in industrial applications,"This paper describes systems of multiple Automated Guided Vehicles (AGVs) used in factory logistics for the transportation of goods. We describe currently applied solutions, highlighting the main issues that, so far, have prevented a pervasive diffusion of these systems. A roadmap of technological solutions is then drafted, to improve the performance of AGV systems and boost their wide application in factory logistics.","Sensors,
Logistics,
Safety,
Production facilities,
Transportation,
Layout,
Lasers"
Toward a Statistical Framework for Source Anonymity in Sensor Networks,"In certain applications, the locations of events reported by a sensor network need to remain anonymous. That is, unauthorized observers must be unable to detect the origin of such events by analyzing the network traffic. Known as the source anonymity problem, this problem has emerged as an important topic in the security of wireless sensor networks, with variety of techniques based on different adversarial assumptions being proposed. In this work, we present a new framework for modeling, analyzing, and evaluating anonymity in sensor networks. The novelty of the proposed framework is twofold: first, it introduces the notion of ""interval indistinguishability” and provides a quantitative measure to model anonymity in wireless sensor networks; second, it maps source anonymity to the statistical problem of binary hypothesis testing with nuisance parameters. We then analyze existing solutions for designing anonymous sensor networks using the proposed model. We show how mapping source anonymity to binary hypothesis testing with nuisance parameters leads to converting the problem of exposing private source information into searching for an appropriate data transformation that removes or minimize the effect of the nuisance information. By doing so, we transform the problem from analyzing real-valued sample points to binary codes, which opens the door for coding theory to be incorporated into the study of anonymous sensor networks. Finally, we discuss how existing solutions can be modified to improve their anonymity.","Games,
Random variables,
Wireless sensor networks,
Monitoring,
Testing,
Delay,
Cryptography"
Bridging the gap between the total and additional test-case prioritization strategies,"In recent years, researchers have intensively investigated various topics in test-case prioritization, which aims to re-order test cases to increase the rate of fault detection during regression testing. The total and additional prioritization strategies, which prioritize based on total numbers of elements covered per test, and numbers of additional (not-yet-covered) elements covered per test, are two widely-adopted generic strategies used for such prioritization. This paper proposes a basic model and an extended model that unify the total strategy and the additional strategy. Our models yield a spectrum of generic strategies ranging between the total and additional strategies, depending on a parameter referred to as the p value. We also propose four heuristics to obtain differentiated p values for different methods under test. We performed an empirical study on 19 versions of four Java programs to explore our results. Our results demonstrate that wide ranges of strategies in our basic and extended models with uniform p values can significantly outperform both the total and additional strategies. In addition, our results also demonstrate that using differentiated p values for both the basic and extended models with method coverage can even outperform the additional strategy using statement coverage.","Fault detection,
Measurement,
Java,
Testing,
Arrays,
Software,
Educational institutions"
Query-Adaptive Image Search With Hash Codes,"Scalable image search based on visual similarity has been an active topic of research in recent years. State-of-the-art solutions often use hashing methods to embed high-dimensional image features into Hamming space, where search can be performed in real-time based on Hamming distance of compact hash codes. Unlike traditional metrics (e.g., Euclidean) that offer continuous distances, the Hamming distances are discrete integer values. As a consequence, there are often a large number of images sharing equal Hamming distances to a query, which largely hurts search results where fine-grained ranking is very important. This paper introduces an approach that enables query-adaptive ranking of the returned images with equal Hamming distances to the queries. This is achieved by firstly offline learning bitwise weights of the hash codes for a diverse set of predefined semantic concept classes. We formulate the weight learning process as a quadratic programming problem that minimizes intra-class distance while preserving inter-class relationship captured by original raw image features. Query-adaptive weights are then computed online by evaluating the proximity between a query and the semantic concept classes. With the query-adaptive bitwise weights, returned images can be easily ordered by weighted Hamming distance at a finer-grained hash code level rather than the original Hamming distance level. Experiments on a Flickr image dataset show clear improvements from our proposed approach.","Hamming distance,
Visualization,
Semantics,
Indexing,
Real-time systems,
Educational institutions,
Electronic mail"
Distributed Power Allocation for Coordinated Multipoint Transmissions in Distributed Antenna Systems,"This paper investigates the distributed power allocation problem for coordinated multipoint (CoMP) transmissions in distributed antenna systems (DAS). Traditional duality-based optimization techniques cannot be directly applied to this problem, because the non-strict concavity of the CoMP transmission's achievable rate with respect to the transmission power induces that the local power allocation subproblems have non-unique optimum solutions. We propose a distributed power allocation algorithm to resolve this non-strict concavity difficulty. This algorithm only requires local information exchange among neighboring base stations serving the same user, and is thus flexible with respect to network size and topology. The step-size parameters of this algorithm are determined by only local user access relationship (i.e., the number of users served by each antenna), but do not rely on channel coefficients. Therefore, the convergence speed of this algorithm is quite robust to channel fading. We rigorously prove that this algorithm converges to an optimum solution of the power allocation problem. Simulation results are presented to demonstrate the effectiveness of the proposed power allocation algorithm.",
Joint Social and Content Recommendation for User-Generated Videos in Online Social Network,"Online social network is emerging as a promising alternative for users to directly access video contents. By allowing users to import videos and re-share them through the social connections, a large number of videos are available to users in the online social network. The rapid growth of the user-generated videos provides enormous potential for users to find the ones that interest them; while the convergence of online social network service and online video sharing service makes it possible to perform recommendation using social factors and content factors jointly. In this paper, we design a joint social-content recommendation framework to suggest users which videos to import or re-share in the online social network. In this framework, we first propose a user-content matrix update approach which updates and fills in cold user-video entries to provide the foundations for the recommendation. Then, based on the updated user-content matrix, we construct a joint social-content space to measure the relevance between users and videos, which can provide a high accuracy for video importing and re-sharing recommendation. We conduct experiments using real traces from Tencent Weibo and Youku to verify our algorithm and evaluate its performance. The results demonstrate the effectiveness of our approach and show that our approach can substantially improve the recommendation accuracy.","Videos,
Joints,
Twitter,
Collaboration,
Laboratories,
Internet"
Joint scheduling and resource allocation for device-to-device underlay communication,"Device-to-device (D2D) communication as an underlay to cellular networks can bring significant benefits to users' throughput. However, as D2D user equipments (TIEs) can cause interference to cellular TIEs, the scheduling and allocation of channel resources and power to D2D communication need elaborate coordination. In this paper, we propose a joint scheduling and resource allocation scheme to improve the performance of D2D communication. We take network throughput and TIEs' fairness into account by performing interference management. Specifically, we develop a Stackelberg game framework in which we group a cellular TIE and a D2D TIE to form a leader-follower pair. The cellular user is the leader, and the D2D TIE is the follower who buys channel resources from the leader. We analyze the equilibrium of the game, and propose an algorithm for joint scheduling and resource allocation. Finally, we perform computer simulations to study the performance of the proposed algorithm.",
A dense pressure sensitive bedsheet design for unobtrusive sleep posture monitoring,"Sleep plays a pivotal role in the quality of life, and sleep posture is related to many medical conditions such as sleep apnea. In this paper, we design a dense pressure-sensitive bedsheet for sleep posture monitoring. In contrast to existing techniques, our bedsheet system offers a completely unobtrusive method using comfortable textile sensors. Based on high-resolution pressure distributions from the bedsheet, we develop a novel framework for pressure image analysis to monitor sleep postures, including a set of geometrical features for sleep posture characterization and three sparse classifiers for posture recognition. We run a pilot study and evaluate the performance of our methods with 14 subjects to analyze 6 common postures. The experimental results show that our proposed method enables reliable sleep posture recognition and offers better overall performance than state-of-the-art methods, achieving up to 83.0% precision and 83.2% recall on average.","Sleep apnea,
Sensors,
Hip,
Feature extraction,
Shoulder,
Monitoring,
Training"
A Novel Mat-Based System for Position-Varying Wireless Power Transfer to Biomedical Implants,"Wireless power transfer via magnetically resonant coupling is a new technology to deliver power over a relatively long distance. Here, we present a mat-based design to wirelessly power moving targets based on this technology. Our design is specifically applied to transcutaneously power medical implants within free-moving laboratory animals. Our system comprises a driver coil array, a hexagonally packed transmitter mat, a receiver coil, and a load coil, and generates a nearly flat magnetic distribution over a defined area to produce an approximately constant power output independent of the location of the receiver coil. This paper also describes a novel power receiver coil design of the same shape as the exterior of the implant, allowing for maximum magnetic coupling, eliminating the space restrictions due to the coil within the implant, and matching the resonant frequencies of the implant and the transmitter coil. Our new transmitter and receiver designs significantly reduce the size of a biomedical implant and may provide a lifetime power supply to implanted circuits without the need for an internal battery. Our designs are also useful in various other applications involving moving targets, such as part of a robot or a vehicle.","Coils,
Implants,
Animals,
Resonant frequency,
Receivers,
Arrays,
Wireless communication"
Statistical Reconstruction of Material Decomposed Data in Spectral CT,"Photon-counting detector technology has enabled the first experimental investigations of energy-resolved computed tomography (CT) imaging and the potential use for K-edge imaging. However, limitations in regards to detecter technology have been imposing a limit to effective count rates. As a consequence, this has resulted in high noise levels in the obtained images given scan time limitations in CT imaging applications. It has been well recognized in the area of low-dose imaging with conventional CT that iterative image reconstruction provides a superior signal to noise ratio compared to traditional filtered backprojection techniques. Furthermore, iterative reconstruction methods also allow for incorporation of a roughness penalty function in order to make a trade-off between noise and spatial resolution in the reconstructed images. In this work, we investigate statistically-principled iterative image reconstruction from material-decomposed sinograms in spectral CT. The proposed reconstruction algorithm seeks to minimize a penalized likelihood-based cost functional, where the parameters of the likelihood function are estimated by computing the Fisher information matrix associated with the material decomposition step. The performance of the proposed reconstruction method is quantitatively investigated by use of computer-simulated and experimental phantom data. The potential for improved K-edge imaging is also demonstrated in an animal experiment.","Image reconstruction,
Computed tomography,
Materials,
Detectors,
Photonics,
Noise"
Interference-aware graph based resource sharing for device-to-device communications underlaying cellular networks,"Device-to-device (D2D) communications underlaying cellular networks have recently been considered as a promising means to improve the resource utilization of the cellular network and the user throughput between devices in proximity to each other. In this paper, we investigate the resource sharing problem to optimize the system performance in such a scenario. Specifically, we formulate the interference relationships among different D2D communication links and cellular communication links as a novel interference-aware graph, and propose an interference-aware graph based resource sharing algorithm that can effectively obtain the near optimal resource assignment solutions at the base station (BS) but with low computational complexity. Simulation results confirm that, with markedly reduced complexity, our proposed scheme achieves a network sum rate that approaches the one corresponding to the optimal resource sharing scheme obtained via exhaustive search.","Resource management,
Interference,
Complexity theory,
Data communication,
Clustering algorithms,
Indexes,
Optimization"
DIRECTFN: Fully Numerical Algorithms for High Precision Computation of Singular Integrals in Galerkin SIE Methods,"Fully numerical schemes are presented for high precision computations of the four-dimensional integrals arising in Galerkin surface integral equation formulations. More specifically, the focal point of this paper is the singular integrals for coincident, edge adjacent and vertex adjacent planar and curvilinear triangular elements. The proposed method, dubbed as DIRECTFN, utilizes a series of variable transformations, able to cancel both weak (1/R) and strong (1/R2) singularities. In addition, appropriate interchanges in the order of the associated one-dimensional integrations result in further regularization of the overall integrals. The final integrands are analytic functions with respect to all variables involved and, hence, the integrals can be efficiently evaluated by means of simple Gaussian integration. The accuracy and convergence properties of the new schemes are demonstrated by evaluating representative weakly singular and strongly singular integrals over planar and quadratic curvilinear elements.","Moment methods,
Integral equations,
Electric potential,
Frequency modulation,
Testing,
Kernel,
Jacobian matrices"
KINECT applications for the physical rehabilitation,"This report presents the results of KINECT applications used in physical rehabilitation tests. Aoyama Gakuin and Kitasato universities collaborated on this project, which is supported by SCOPE. The applications, following standard tests, are for the timed “Up & Go Test”, the timed “10-Meter Walk Test” and for a Joint “Range of Motion” Measurement”; test results are given. The implementation, evaluation and advantages of a proposed “Real-time ROM Measurement” are also given. The proposed KINECT application will be useful for enhancement of KINECT technical capabilities and for further advancements in medical care.","Joints,
Read only memory,
Educational institutions,
Tracking,
Manuals,
Software,
Cameras"
How shadowing hurts vehicular communications and how dynamic beaconing can help,"We study the effect of radio signal shadowing dynamics, caused by vehicles and by buildings, on the performance of beaconing protocols in Inter-Vehicular Communication (IVC). Recent research indicates that beaconing, i.e., one hop message broadcast, shows excellent characteristics and can outperform other communication approaches for both safety and efficiency applications, which require low latency and wide area information dissemination, respectively. We show how shadowing dynamics of moving obstacles hurt IVC, reducing the performance of beaconing protocols. At the same time, shadowing also limits the risk of overloading the wireless channel. To the best of our knowledge, this is the first study identifying the problems and resulting possibilities of such dynamic radio shadowing. We demonstrate how these challenges and opportunities can be taken into account and outline a novel approach to dynamic beaconing. It provides low-latency communication (i.e., very short beaconing intervals), while ensuring not to overload the wireless channel. The presented simulation results substantiate our theoretical considerations.",
On the performance of hybrid RF and RF/FSO fixed gain dual-hop transmission systems,"In this work, we present the performance analysis of a dual-branch transmission system composed of a direct radio frequency (RF) link and a dual-hop relay composed of asymmetric RF and free-space optical (FSO) links and compare it without having a direct RF path to see the effects of diversity on our system. The FSO link accounts for pointing errors and both types of detection techniques (i.e. indirect modulation/direct detection (IM/DD) as well as heterodyne detection). The performance is evaluated under the assumption of selection combining diversity scheme. RF links are modeled by Rayleigh fading distribution whereas the FSO link is modeled by a unified Gamma-Gamma fading distribution. Specifically, we derive new exact closed-form expressions for the cumulative distribution function, probability density function, moment generating function, and moments of the end-to-end signal-to-noise ratio of these systems in terms of the Meijer's G function. We then capitalize on these results to offer new exact closed-form expressions for the outage probability, higher-order amount of fading, average error rate for binary and M-ary modulation schemes, and ergodic capacity, all in terms of Meijer's G functions. All our new analytical results are also verified via computer-based Monte-Carlo simulations.",
"Large-Area 2-D Electronics: Materials, Technology, and Devices","Recent experiments since the discovery of monolayer graphite or graphene have led to an exciting revival in the interest in the electronic applications for graphene, as well as other 2-D materials such as hexagonal boron nitride (hBN) and molybdenum disulfide (MoS2). These layered materials serve as an exciting new platform for flexible and transparent electronics where surfaces can be enriched with new functionality. This paper aims to provide an overview behind these new class of materials ranging upon important issues for electronic integration including synthesis all the way to current state-of-the-art circuits and devices made from these materials.","Graphene,
Boron alloys,
Substrates,
Silicon carbide,
Transistors"
Performance of Random Number Generators Using Noise-Based Superluminescent Diode and Chaos-Based Semiconductor Lasers,"We investigate two optical sources used for random number generation: superluminescent diode (SLD) and semiconductor lasers. Amplified spontaneous emission noise is generated in the SLD and chaotic intensity fluctuation is generated in a semiconductor laser. We investigate the performance of random number generation for both optical sources. For single-bit generation of random numbers, the maximum generation rate is 8.33 Gb/s for both the SLD and the laser with a similar bandwidth of ~15 GHz. For multibit generation schemes, we obtain the generation rate up to 400 Gb/s for both the SLD and the laser. The overall characteristics are similar between the SLD and the laser, since similar bandwidths of the RF spectra are used. The probability density function of the SLD is more symmetric than that of the chaotic laser. This fact results in slightly good performance of random number generation using the SLD for multibit generation.","Semiconductor lasers,
Superluminescent diodes,
Bandwidth,
Optical fibers,
Optical amplifiers,
Fiber lasers,
NIST"
Efficient Byzantine Fault-Tolerance,"We present two asynchronous Byzantine fault-tolerant state machine replication (BFT) algorithms, which improve previous algorithms in terms of several metrics. First, they require only 2f+1 replicas, instead of the usual 3f+1. Second, the trusted service in which this reduction of replicas is based is quite simple, making a verified implementation straightforward (and even feasible using commercial trusted hardware). Third, in nice executions the two algorithms run in the minimum number of communication steps for nonspeculative and speculative algorithms, respectively, four and three steps. Besides the obvious benefits in terms of cost, resilience and management complexity-fewer replicas to tolerate a certain number of faults-our algorithms are simpler than previous ones, being closer to crash fault-tolerant replication algorithms. The performance evaluation shows that, even with the trusted component access overhead, they can have better throughput than Castro and Liskov's PBFT, and better latency in networks with nonnegligible communication delays.","Servers,
Radiation detectors,
Fault tolerance,
Fault tolerant systems,
Delay,
Hardware"
b-SPECS+: Batch Verification for Secure Pseudonymous Authentication in VANET,"The security and privacy preservation issues are prerequisites for vehicular ad hoc networks. Recently, secure and privacy enhancing communication schemes (SPECS) was proposed and focused on intervehicle communications. SPECS provided a software-based solution to satisfy the privacy requirement and gave lower message overhead and higher successful rate than previous solutions in the message verification phase. SPECS also presented the first group communication protocol to allow vehicles to authenticate and securely communicate with others in a group of known vehicles. Unfortunately, we find out that SPECS is vulnerable to impersonation attack. SPECS has a flow such that a malicious vehicle can force arbitrary vehicles to broadcast fake messages to other vehicles or even a malicious vehicle in the group can counterfeit another group member to send fake messages securely among themselves. In this paper, we provide a secure scheme that can achieve the security and privacy requirements, and overcome the weaknesses of SPECS. Moreover, we show the efficiency merits of our scheme through performance evaluations in terms of verification delay and transmission overhead.",
QoS Guarantees and Service Differentiation for Dynamic Cloud Applications,"Cloud elasticity allows dynamic resource provisioning in concert with actual application demands. Feedback control approaches have been applied with success to resource allocation in physical servers. However, cloud dynamics make the design of an accurate and stable resource controller challenging, especially when application-level performance is considered as the measured output. Application-level performance is highly dependent on the characteristics of workload and sensitive to cloud dynamics. To address these challenges, we extend a self-tuning fuzzy control (STFC) approach, originally developed for response time assurance in web servers to resource allocation in virtualized environments. We introduce mechanisms for adaptive output amplification and flexible rule selection in the STFC approach for better adaptability and stability. Based on the STFC, we further design a two-layer QoS provisioning framework, DynaQoS, that supports adaptive multi-objective resource allocation and service differentiation. We implement a prototype of DynaQoS on a Xen-based cloud testbed. Experimental results on representative server workloads show that STFC outperforms popular controllers such as Kalman filter, ARMA and, Adaptive PI in the control of CPU, memory, and disk bandwidth resources under both static and dynamic workloads. Further results with multiple control objectives and service classes demonstrate the effectiveness of DynaQoS in performance-power control and service differentiation.",
Comparison of feedforward and recurrent neural network language models,"Research on language modeling for speech recognition has increasingly focused on the application of neural networks. Two competing concepts have been developed: On the one hand, feedforward neural networks representing an n-gram approach, on the other hand recurrent neural networks that may learn context dependencies spanning more than a fixed number of predecessor words. To the best of our knowledge, no comparison has been carried out between feedforward and state-of-the-art recurrent networks when applied to speech recognition. This paper analyzes this aspect in detail on a well-tuned French speech recognition task. In addition, we propose a simple and efficient method to normalize language model probabilities across different vocabularies, and we show how to speed up training of recurrent neural networks by parallelization.","Artificial neural networks,
Feedforward neural networks,
Speech recognition,
Computational modeling,
Vocabulary,
Training"
RTSP: An Accurate and Energy-Efficient Protocol for Clock Synchronization in WSNs,"Wireless sensor networks need accurate time synchronization for data consistency and coordination. Although the existing algorithms for time synchronization offer very good accuracy, their energy consumption is high, and distant nodes are poorly synchronized. We propose a Recursive Time Synchronization Protocol (RTSP) which accurately synchronizes all the nodes in a network to a global clock using multi-hop architecture in an energy-efficient way. It achieves better performance due to the MAC-layer time-stamping based on Start of Frame Delimiter byte, infrequent broadcasts by a dynamically elected reference node, compensation of the propagation delay and adjustment of the timestamps at each hop, estimation of the relative skew and offset using least square linear regression on two data points (2LR), adaptive re-synchronization interval, aggregation of the synchronization requests, and energy awareness. A detailed analysis of the sources of errors is also provided. Simulation results show that the RTSP can achieve an average accuracy of 0.3 microseconds in a large multi-hop flat network while using five-times lesser energy than that of FTSP in the long run and performs even better in a clustered network where it can achieve an average accuracy of 0.23 microseconds while using seven-times lesser energy.","Synchronization,
Accuracy,
Clustering algorithms,
Protocols,
Wireless sensor networks,
Clocks,
Spread spectrum communication"
Competing Memes Propagation on Networks: A Network Science Perspective,"In this paper, we study the intertwined propagation of two competing ""memes"" (or data, rumors, etc.) in a composite network. Within the constraints of this scenario, we ask two key questions: (a) which meme will prevail? and (b) can one influence the outcome of the propagations? Our model is underpinned by two key concepts, a structural graph model (composite network) and a viral propagation model (SI1I2S). Using this framework, we formulate a non-linear dynamic system and perform an eigenvalue analysis to identify the tipping point of the epidemic behavior. Based on insights gained from this analysis, we demonstrate an effective and accurate prediction method to determine viral dominance, which we call the EigenPredictor. Next, using a combination of synthetic and real composite networks, we evaluate the effectiveness of various viral suppression techniques by either a) concurrently suppressing both memes or b) unilaterally suppressing a single meme while leaving the other relatively unaffected.","Eigenvalues and eigenfunctions,
Jacobian matrices,
Computational modeling,
Predictive models,
Data models,
Topology,
Vectors"
Harvesting-Aware Energy Management for Time-Critical Wireless Sensor Networks With Joint Voltage and Modulation Scaling,"As Cyber-Physical-Systems (CPSs) evolve they will be increasingly relied on to support time-critical and performance-intensive monitoring and control activities. Further, many CPSs that utilize Wireless Sensor Networking (WSN) technologies will require the use of energy harvesting methods to extend their lifetimes. For this application class, there are currently few algorithmic techniques that combine performance sensitive processing and communication with efficient management techniques for energy harvesting. Our paper addresses this problem. We first propose a general purpose, multihop WSN architecture capable of supporting time-critical CPS systems using energy harvesting. We then present a set of Harvesting Aware Speed Selection (HASS) algorithms. Our technique maximizes the minimum energy reserve for all the nodes in the network, thus ensuring highly resilient performance under emergency or fault-driven situations. We present an optimal centralized solution, along with an efficient, distributed solution. We propose a CPS-specific experimental methodology, enabling us to evaluate our approach. Our experiments show that our algorithms yield significantly higher energy reserves than baseline methods.","Wireless sensor networks,
Energy states,
Energy harvesting,
Time factors,
Energy consumption,
Real time systems,
Voltage control"
IkeaBot: An autonomous multi-robot coordinated furniture assembly system,"We present an automated assembly system that directs the actions of a team of heterogeneous robots in the completion of an assembly task. From an initial user-supplied geometric specification, the system applies reasoning about the geometry of individual parts in order to deduce how they fit together. The task is then automatically transformed to a symbolic description of the assembly-a sort of blueprint. A symbolic planner generates an assembly sequence that can be executed by a team of collaborating robots. Each robot fulfills one of two roles: parts delivery or parts assembly. The latter are equipped with specialized tools to aid in the assembly process. Additionally, the robots engage in coordinated co-manipulation of large, heavy assemblies. We provide details of an example furniture kit assembled by the system.","Assembly,
Robot kinematics,
Planning,
Legged locomotion,
Transforms,
Assembly systems"
On Acoustic Emotion Recognition: Compensating for Covariate Shift,"Pattern recognition tasks often face the situation that training data are not fully representative of test data. This problem is well-recognized in speech recognition, where methods like cepstral mean normalization (CMN), vocal tract length normalization (VTLN) and maximum likelihood linear regression (MLLR) are used to compensate for channel and speaker differences. Speech emotion recognition (SER) is an important emerging field in human-computer interaction and faces the same data shift problems, a fact which has been generally overlooked in this domain. In this paper, we show that compensating for channel and speaker differences can give significant improvements in SER by modelling these differences as a covariate shift. We employ three algorithms from the domain of transfer learning that apply importance weights (IWs) within a support vector machine classifier to reduce the effects of covariate shift. We test these methods on the FAU Aibo Emotion Corpus, which was used in the Interspeech 2009 Emotion Challenge. It consists of two separate parts recorded independently at different schools; hence the two parts exhibit covariate shift. Results show that the IW methods outperform combined CMN and VTLN and significantly improve on the baseline performance of the Challenge. The best of the three methods also improves significantly on the winning contribution to the Challenge.",
Redundancy Management of Multipath Routing for Intrusion Tolerance in Heterogeneous Wireless Sensor Networks,"In this paper we propose redundancy management of heterogeneous wireless sensor networks (HWSNs), utilizing multipath routing to answer user queries in the presence of unreliable and malicious nodes. The key concept of our redundancy management is to exploit the tradeoff between energy consumption vs. the gain in reliability, timeliness, and security to maximize the system useful lifetime. We formulate the tradeoff as an optimization problem for dynamically determining the best redundancy level to apply to multipath routing for intrusion tolerance so that the query response success probability is maximized while prolonging the useful lifetime. Furthermore, we consider this optimization problem for the case in which a voting-based distributed intrusion detection algorithm is applied to detect and evict malicious nodes in a HWSN. We develop a novel probability model to analyze the best redundancy level in terms of path redundancy and source redundancy, as well as the best intrusion detection settings in terms of the number of voters and the intrusion invocation interval under which the lifetime of a HWSN is maximized. We then apply the analysis results obtained to the design of a dynamic redundancy management algorithm to identify and apply the best design parameter settings at runtime in response to environment changes, to maximize the HWSN lifetime.","Wireless sensor management,
Routing protocls,
Intrusion detection,
Telecommunication traffic,
Network sensors,
Energy conservation,
Multipath channels"
Sentiment analysis of movie reviews: A new feature-based heuristic for aspect-level sentiment classification,"This paper presents our experimental work on a new kind of domain specific feature-based heuristic for aspect-level sentiment analysis of movie reviews. We have devised an aspect oriented scheme that analyses the textual reviews of a movie and assign it a sentiment label on each aspect. The scores on each aspect from multiple reviews are then aggregated and a net sentiment profile of the movie is generated on all parameters. We have used a SentiWordNet based scheme with two different linguistic feature selections comprising of adjectives, adverbs and verbs and n-gram feature extraction. We have also used our SentiWordNet scheme to compute the document-level sentiment for each movie reviewed and compared the results with results obtained using Alchemy API. The sentiment profile of a movie is also compared with the document-level sentiment result. The results obtained show that our scheme produces a more accurate and focused sentiment profile than the simple document-level sentiment analysis.","Motion pictures,
Sentiment analysis,
Accuracy,
Feature extraction,
Classification algorithms,
Pragmatics,
Entropy"
Comb-Push Ultrasound Shear Elastography (CUSE) With Various Ultrasound Push Beams,"Comb-push ultrasound shear elastography (CUSE) has recently been shown to be a fast and accurate 2-D elasticity imaging technique that can provide a full field-of-view (FOV) shear wave speed map with only one rapid data acquisition. The initial version of CUSE was termed U-CUSE because unfocused ultrasound push beams were used. In this paper, we present two new versions of CUSE-focused CUSE (F-CUSE) and marching CUSE (M-CUSE), which use focused ultrasound push beams to improve acoustic radiation force penetration and produce stronger shear waves in deep tissues (e.g., kidney and liver). F-CUSE divides transducer elements into several subgroups which transmit multiple focused ultrasound beams simultaneously. M-CUSE uses more elements for each focused push beam and laterally marches the push beams. Both F-CUSE and M-CUSE can generate comb-shaped shear wave fields that have shear wave motion at each imaging pixel location so that a full FOV 2-D shear wave speed map can be reconstructed with only one data acquisition. Homogeneous phantom experiments showed that U-CUSE, F-CUSE, and M-CUSE can all produce smooth shear wave speed maps with accurate shear wave speed estimates. An inclusion phantom experiment showed that all CUSE methods could provide good contrast between the inclusion and background with sharp boundaries while F-CUSE and M-CUSE require shorter push durations to achieve shear wave speed maps with comparable SNR to U-CUSE. A more challenging inclusion phantom experiment with a very stiff and deep inclusion shows that better shear wave penetration could be gained by using F-CUSE and M-CUSE. Finally, a shallow inclusion experiment showed that good preservations of inclusion shapes could be achieved by both U-CUSE and F-CUSE in the near field. Safety measurements showed that all safety parameters are below FDA regulatory limits for all CUSE methods. These promising results suggest that, using various push beams, CUSE is capable of reconstructing a 2-D full FOV shear elasticity map using only one push-detection data acquisition in a wide range of depths for soft tissue elasticity imaging.",
Flexible Complementary Logic Gates Using Inkjet-Printed Polymer Field-Effect Transistors,"High-performance inkjet-printed top-gate/bottom-contact organic field-effect transistors (OFETs) and complementary electronic circuitry are reported. Blends of poly(vinylidenefluoride-trifluoroethylene) (P(VDF-TrFE)) and poly(methyl methacrylate) (PMMA) dielectrics effectively reduce the operation voltage. At the optimized blend ratio of 7 : 3 wt.% for P(VDF-TrFE) and PMMA, both p- and n-type printed OFETs show well-balanced high field-effect mobility values (~ 0.5 cm2/V·s) and low threshold voltages ( ±5 V). The high-performance inverters and various digital logic gates such as nand, nor, or, and xor are demonstrated on flexible plastic substrates. The inverter shows a high gain (>; 25), an ideal inverting voltage near half of the supplied bias (1/2VDD), and a high noise immunity (up to 79 % of 1/2VDD).","Logic gates,
Polymers,
OFETs,
Dielectrics,
Inverters,
Noise"
Towards omnidirectional passive human detection,"Passive human detection and localization serve as key enablers for various pervasive applications such as smart space, human-computer interaction and asset security. The primary concern in devising scenario-tailored detecting systems is the coverage of their monitoring units. In conventional radio-based schemes, the basic unit tends to demonstrate a directional coverage, even if the underlying devices are all equipped with omnidirectional antennas. Such an inconsistency stems from the link-centric architecture, creating an anisotropic wireless propagating environment. To achieve an omnidirectional coverage while retaining the link-centric architecture, we propose the concept of Omnidirectional Passive Human Detection, and investigate to harness the PHY layer features to virtually tune the shape of the unit coverage by fingerprinting approaches, which is previously prohibited with mere MAC layer RSSI. We design the scheme with ubiquitously deployed WiFi infrastructure and evaluate it in typical multipath-rich indoor scenarios. Experimental results show that our scheme achieves an average false positive of 8% and an average false negative of 7% in detecting human presence in 4 directions.",
Gaussian Processes for Personalized e-Health Monitoring With Wearable Sensors,"Advances in wearable sensing and communications infrastructure have allowed the widespread development of prototype medical devices for patient monitoring. However, such devices have not penetrated into clinical practice, primarily due to a lack of research into “intelligent” analysis methods that are sufficiently robust to support large-scale deployment. Existing systems are typically plagued by large false-alarm rates, and an inability to cope with sensor artifact in a principled manner. This paper has two aims: 1) proposal of a novel, patient-personalized system for analysis and inference in the presence of data uncertainty, typically caused by sensor artifact and data incompleteness; 2) demonstration of the method using a large-scale clinical study in which 200 patients have been monitored using the proposed system. This latter provides much-needed evidence that personalized e-health monitoring is feasible within an actual clinical environment, at scale, and that the method is capable of improving patient outcomes via personalized healthcare.","Biomedical monitoring,
Monitoring,
Hospitals,
Gaussian processes,
Wearable sensors,
Robustness,
Manuals"
General Constructions for Threshold Multiple-Secret Visual Cryptographic Schemes,"A conventional threshold (k out of n) visual secret sharing scheme encodes one secret image P into n transparencies (called shares) such that any group of k transparencies reveals P when they are superimposed, while that of less than k ones cannot. We define and develop general constructions for threshold multiple-secret visual cryptographic schemes (MVCSs) that are capable of encoding s secret images P1,P2,...,Ps into n shares such that any group of less than k shares obtains none of the secrets, while 1) each group of k, k+1,..., n shares reveals P1, P2, ..., Ps, respectively, when superimposed, referred to as (k, n, s)-MVCS where s=n-k+1; or 2) each group of u shares reveals P(ru) where ru ∈ {0,1,2,...,s} (ru=0 indicates no secret can be seen), k ≤ u ≤ n and 2 ≤ s ≤ n-k+1, referred to as (k, n, s, R)-MVCS in which R=(rk, rk+1, ..., rn) is called the revealing list. We adopt the skills of linear programming to model (k, n, s) - and (k, n, s, R) -MVCSs as integer linear programs which minimize the pixel expansions under all necessary constraints. The pixel expansions of different problem scales are explored, which have never been reported in the literature. Our constructions are novel and flexible. They can be easily customized to cope with various kinds of MVCSs.","Visualization,
Cryptography,
Hamming weight,
Image color analysis,
Linear programming,
Decoding"
Dynamic Extreme Learning Machine and Its Approximation Capability,"Extreme learning machines (ELMs) have been proposed for generalized single-hidden-layer feedforward networks which need not be neuron alike and perform well in both regression and classification applications. The problem of determining the suitable network architectures is recognized to be crucial in the successful application of ELMs. This paper first proposes a dynamic ELM (D-ELM) where the hidden nodes can be recruited or deleted dynamically according to their significance to network performance, so that not only the parameters can be adjusted but also the architecture can be self-adapted simultaneously. Then, this paper proves in theory that such D-ELM using Lebesgue p-integrable hidden activation functions can approximate any Lebesgue p-integrable function on a compact input set. Simulation results obtained over various test problems demonstrate and verify that the proposed D-ELM does a good job reducing the network size while preserving good generalization performance.",
Back-Pressure-Based Packet-by-Packet Adaptive Routing in Communication Networks,"Back-pressure-based adaptive routing algorithms where each packet is routed along a possibly different path have been extensively studied in the literature. However, such algorithms typically result in poor delay performance and involve high implementation complexity. In this paper, we develop a new adaptive routing algorithm built upon the widely studied back-pressure algorithm. We decouple the routing and scheduling components of the algorithm by designing a probabilistic routing table that is used to route packets to per-destination queues. The scheduling decisions in the case of wireless networks are made using counters called shadow queues. The results are also extended to the case of networks that employ simple forms of network coding. In that case, our algorithm provides a low-complexity solution to optimally exploit the routing-coding tradeoff.","Routing,
Algorithm design and analysis,
Delay,
Scheduling,
Adaptive systems,
Schedules,
Network coding"
Discrimination Between Control and Idle States in Asynchronous SSVEP-Based Brain Switches: A Pseudo-Key-Based Approach,"A steady-state visual evoked potential (SSVEP)-based brain-computer interface (BCI) can operate as an asynchronous brain switch. When SSVEP is detected with the “on/off” button flickering at a fixed frequency, the subject is identified as in the control state. Otherwise, he is in the idle state. Generally, the detection of the idle/control state is based on a predefined threshold, which is related to power. However, due to the variability of the electroencephalogram (EEG) signal, it is difficult to find an optimal threshold to achieve a high true-positive rate (TPR) in the control state while maintaining a low false-positive rate (FPR) in the idle state. In this paper, a novel pseudo-key-based approach is presented for better discriminating the control and idle states. A dedicated “on/off” button (target key) and several additional buttons (pseudo-keys) are displayed on the graphical user interface (GUI), and all of these buttons flash at different frequencies. The control state is identified from the EEG signal under two conditions. The first is a common thresholding condition, where the power ratio of the target key frequency component to a certain neighboring frequency band is above a predefined threshold. The second is a comparison condition, where the power of the target key frequency component is higher than any of the pseudo-keys. The effectiveness of the proposed approach is validated by several experiments. Further analysis shows that introducing the pseudo-keys can significantly reduce the probability that the SSVEP will be detected in response to the flickering target key in the idle state without substantially affecting the detection in the control state, providing strong evidence in support of our approach.","visual evoked potentials,
brain-computer interfaces,
electroencephalography,
graphical user interfaces,
medical signal processing"
Sampling Piecewise Convex Unmixing and Endmember Extraction,"A Metropolis-within-Gibbs sampler for piecewise convex hyperspectral unmixing and endmember extraction is presented. The standard linear mixing model used for hyperspectral unmixing assumes that hyperspectral data reside in a single convex region. However, hyperspectral data are often nonconvex. Furthermore, in standard endmember extraction and unmixing methods, endmembers are generally represented as a single point in the high-dimensional space. However, the spectral signature for a material varies as a function of the inherent variability of the material and environmental conditions. Therefore, it is more appropriate to represent each endmember as a full distribution and use this information during spectral unmixing. The proposed method searches for several sets of endmember distributions. By using several sets of endmember distributions, a piecewise convex mixing model is applied, and given this model, the proposed method performs spectral unmixing and endmember estimation given this nonlinear representation of the data. Each set represents a random simplex. The vertices of the random simplex are modeled by the endmember distributions. The hyperspectral data are partitioned into sets associated with each of the extracted sets of endmember distributions using a Dirichlet process prior. The Dirichlet process prior also estimates the number of sets. Thus, the Metropolis-within-Gibbs sampler partitions the data into convex regions, estimates the required number of convex regions, and estimates endmember distributions and abundance values for all convex regions. Results are presented on real hyperspectral and simulated data that indicate the ability of the method to effectively estimate endmember distributions and the number of sets of endmember distributions.",
A cooperative game based allocation for sharing data center networks,"In current IaaS datacenters, tenants are suffering unfairness since the network bandwidth is shared in a besteffort manner. To achieve predictable network performance for rented virtual machines (VMs), cloud providers should guarantee minimum bandwidth for VMs or allocate the network bandwidth in a fairness fashion at VM-level. At the same time, the network should be efficiently utilized in order to maximize cloud providers' revenue. In this paper, we model the bandwidth sharing problem as a Nash bargaining game, and propose the allocation principles by defining a tunable base bandwidth for each VM. Specifically, we guarantee bandwidth for those VMs with lower network rates than their base bandwidth, while maintaining fairness among other VMs with higher network rates than their base bandwidth. Based on rigorous cooperative game-theoretic approaches, we design a distributed algorithm to achieve efficient and fair bandwidth allocation corresponding to the Nash bargaining solution (NBS). With simulations under typical scenarios, we show that our strategy can meet the two desirable requirements towards predictable performance for tenants as well as high utilization for providers. And by tuning the base bandwidth, our solution can enable cloud providers to flexibly balance the tradeoff between minimum guarantees and fair sharing of datacenter networks.","Bandwidth,
Servers,
Channel allocation,
Resource management,
Games,
Bismuth,
NIST"
A Self-Adapting Flexible (SELFLEX) Antenna Array for Changing Conformal Surface Applications,"A phased-array test platform for studying the self-adapting capabilities of conformal antennas is developed and presented. Specifically, a four-port 2.45-GHz receiver with voltage controlled phase shifters and attenuators is designed along with four individual printed microstrip patch antennas attached to a conformal surface. Each antenna is connected to the corresponding receiver port with a flexible SMA cable. It is shown that with appropriate phase compensation, the distorted radiation pattern of the array can be recovered as the surface of the conformal array changes shape. This pattern recovery information is then used to develop a new self-adapting flexible 1 &times; 4 microstrip antenna array with an embedded flexible sensor system. In particular, a flexible resistive sensor is used to measure the deformation of the substrate of a conformal antenna array, while a sensor circuit is used to measure the changing resistance. The circuit then uses this information to control the individual voltage of the phase shifters of each radiating element in the array. It is shown that with appropriate phase compensation, the radiation properties of the array can be autonomously recovered as the surface of the flexible array changes shape during normal operation. Throughout this work, measurements are shown to agree with analytical solutions and simulations.",
Regional Spatially Adaptive Total Variation Super-Resolution With Spatial Information Filtering and Clustering,"Total variation is used as a popular and effective image prior model in the regularization-based image processing fields. However, as the total variation model favors a piecewise constant solution, the processing result under high noise intensity in the flat regions of the image is often poor, and some pseudoedges are produced. In this paper, we develop a regional spatially adaptive total variation model. Initially, the spatial information is extracted based on each pixel, and then two filtering processes are added to suppress the effect of pseudoedges. In addition, the spatial information weight is constructed and classified with k-means clustering, and the regularization strength in each region is controlled by the clustering center value. The experimental results, on both simulated and real datasets, show that the proposed approach can effectively reduce the pseudoedges of the total variation regularization in the flat regions, and maintain the partial smoothness of the high-resolution image. More importantly, compared with the traditional pixel-based spatial information adaptive approach, the proposed region-based spatial information adaptive total variation model can better avoid the effect of noise on the spatial information extraction, and maintains robustness with changes in the noise intensity in the super-resolution process.","Information filters,
Adaptation models,
Noise,
TV,
Image edge detection,
Image resolution"
Highly Undersampled Magnetic Resonance Image Reconstruction Using Two-Level Bregman Method With Dictionary Updating,"In recent years Bregman iterative method (or related augmented Lagrangian method) has shown to be an efficient optimization technique for various inverse problems. In this paper, we propose a two-level Bregman Method with dictionary updating for highly undersampled magnetic resonance (MR) image reconstruction. The outer-level Bregman iterative procedure enforces the sampled k-space data constraints, while the inner-level Bregman method devotes to updating dictionary and sparse representation of small overlapping image patches, emphasizing local structure adaptively. Modified sparse coding stage and simple dictionary updating stage applied in the inner minimization make the whole algorithm converge in a relatively small number of iterations, and enable accurate MR image reconstruction from highly undersampled k-space data. Experimental results on both simulated MR images and real MR data consistently demonstrate that the proposed algorithm can efficiently reconstruct MR images and present advantages over the current state-of-the-art reconstruction approach.","Dictionaries,
Image reconstruction,
Iterative methods,
Transforms,
Magnetic resonance imaging,
Minimization,
TV"
Joint Histogram-Based Cost Aggregation for Stereo Matching,"This paper presents a novel method for performing efficient cost aggregation in stereo matching. The cost aggregation problem is reformulated from the perspective of a histogram, giving us the potential to reduce the complexity of the cost aggregation in stereo matching significantly. Differently from previous methods which have tried to reduce the complexity in terms of the size of an image and a matching window, our approach focuses on reducing the computational redundancy that exists among the search range, caused by a repeated filtering for all the hypotheses. Moreover, we also reduce the complexity of the window-based filtering through an efficient sampling scheme inside the matching window. The tradeoff between accuracy and complexity is extensively investigated by varying the parameters used in the proposed method. Experimental results show that the proposed method provides high-quality disparity maps with low complexity and outperforms existing local methods. This paper also provides new insights into complexity-constrained stereo-matching algorithm design.","Complexity theory,
Joints,
Accuracy,
Image color analysis,
Histograms,
Redundancy"
Performance of Synchrophasor Estimators in Transient Conditions: A Comparative Analysis,"Transient amplitude or phase changes in current or voltage waveforms may seriously affect synchrophasor estimator's accuracy and responsiveness. The IEEE Standard C37.118.1-2011 specifies test conditions as well as accuracy and response delay limits for different types of disturbances. In this paper, the performances of three state-of-the-art techniques based on phasor Taylor's series expansion specifically conceived to track phasors in dynamic conditions are analyzed and compared with the one-cycle discrete Fourier transform estimator under the effect of amplitude step changes, phase step changes, and linear frequency variations. Several simulation results show that the total vector error (TVE) tends to increase linearly with the step size. However, the peak TVE increments for a given step size are quite similar for all the considered techniques and are dominated by amplitude or phase errors, depending on whether the step affects the waveform amplitude or its phase, respectively. In this paper, the response times of the considered estimators for two different TVE thresholds are also analyzed and compared as a function of the step size, to assess their compliance to the requirements of the standard. Further simulation results show that in the case of linear frequency variations, responsiveness is not an issue and the TVE values of all estimators lie within the same worst case boundaries as those related to the case of static off-nominal frequency offsets.","Discrete Fourier transforms,
Accuracy,
Phasor measurement units,
Transient analysis,
Simulation,
Time factors,
Frequency estimation"
Joint Scalable Coding and Routing for 60 GHz Real-Time Live HD Video Streaming Applications,"Transmission of high-definition (HD) video is a promising application for 60 GHz wireless links, since very high transmission rates (up to several Gbit/s) are possible. In particular we consider a sports stadium broadcasting system where signals from multiple cameras are transmitted to a central location. Due to the high pathloss of 60 GHz radiation over the large distances encountered in this scenario, the use of relays might be required. The current paper analyzes the joint selection of the routes (relays) and the compression rates from the various sources for maximization of the overall video quality. We consider three different scenarios: (i) each source transmits only to one relay and the relay can receive only one data stream, and (ii) each source can transmit only to a single relay, but relays can aggregate streams from different sources and forward to the destination, and (iii) the source can split its data stream into parallel streams, which can be transmitted via different relays to the destination. For each scenario, we derive the mathematical formulations of the optimization problem and re-formulate them as convex mixed-integer programming, which can guarantee optimal solutions. Extensive simulations demonstrate that high-quality transmission is possible for at least ten cameras over distances of 300 m. Furthermore, optimization of the video quality gives results that can significantly outperform algorithms that maximize data rates.","Relays,
High definition video,
Streaming media,
Wireless communication,
Antennas,
Broadcasting"
Retina Verification System Based on Biometric Graph Matching,"This paper presents an automatic retina verification framework based on the biometric graph matching (BGM) algorithm. The retinal vasculature is extracted using a family of matched filters in the frequency domain and morphological operators. Then, retinal templates are defined as formal spatial graphs derived from the retinal vasculature. The BGM algorithm, a noisy graph matching algorithm, robust to translation, non-linear distortion, and small rotations, is used to compare retinal templates. The BGM algorithm uses graph topology to define three distance measures between a pair of graphs, two of which are new. A support vector machine (SVM) classifier is used to distinguish between genuine and imposter comparisons. Using single as well as multiple graph measures, the classifier achieves complete separation on a training set of images from the VARIA database (60% of the data), equaling the state-of-the-art for retina verification. Because the available data set is small, kernel density estimation (KDE) of the genuine and imposter score distributions of the training set are used to measure performance of the BGM algorithm. In the one dimensional case, the KDE model is validated with the testing set. A 0 EER on testing shows that the KDE model is a good fit for the empirical distribution. For the multiple graph measures, a novel combination of the SVM boundary and the KDE model is used to obtain a fair comparison with the KDE model for the single measure. A clear benefit in using multiple graph measures over a single measure to distinguish genuine and imposter comparisons is demonstrated by a drop in theoretical error of between 60% and more than two orders of magnitude.","support vector machines,
biometrics (access control),
graph theory,
image classification,
image matching,
matched filters,
mathematical morphology,
retinal recognition"
Saddle Point in the Minimax Converse for Channel Coding,"A minimax metaconverse has recently been proposed as a simultaneous generalization of a number of classical results and a tool for the nonasymptotic analysis. In this paper, it is shown that the order of optimizing the input and output distributions can be interchanged without affecting the bound. In the course of the proof, a number of auxiliary results of separate interest are obtained. In particular, it is shown that the optimization problem is convex and can be solved in many cases by the symmetry considerations. As a consequence, it is demonstrated that in the latter cases, the (multiletter) input distribution in information-spectrum (Verdú-Han) converse bound can be taken to be a (memoryless) product of single-letter ones. A tight converse for the binary erasure channel is rederived by computing the optimal (nonproduct) output distribution. For discrete memoryless channels, a conjecture of Poor and Verdú regarding the tightness of the information spectrum bound on the error exponents is resolved in the negative. Concept of the channel symmetry group is established and relations with the definitions of symmetry by Gallager and Dobrushin are investigated.","Testing,
Optimization,
Memoryless systems,
Channel coding,
Standards,
Extraterrestrial measurements,
Decoding"
Robust MIMO Cognitive Radio Systems Under Interference Temperature Constraints,"Cognitive Radio (CR) systems are built on the coexistence of primary users (PUs) and secondary users (SUs), the latter being allowed to share spectral resources with the PUs but under strict interference limitations. However, such limitations may easily be violated by SUs if perfect SU-to-PU channel state information (CSI) is not available at the secondary transmitters, which always happens in practice. In this paper, we propose a distributed design of MIMO CR networks under global interference temperature constraints that is robust (in the worst-case sense) against SU-to-PU channel uncertainties. More specifically, we consider two alternative formulations that are complementary to each other in terms of signaling and system performance, namely: a game-theoretical design and a social-oriented optimization. To study and solve the proposed formulations we hinge on the new theory of finite-dimensional variational inequalities (VI) in the complex domain and a novel parallel decomposition technique for nonconvex sum-utility problems with coupling constraints, respectively. A major contribution of this paper is to devise a new class of distributed best-response algorithms with provable convergence. The algorithms differ in computational complexity, convergence speed, communication overhead, and achievable performance; they are thus applicable to a variety of CR scenarios, either cooperative or non-cooperative, which allow the SUs to explore the trade-off between signaling and performance.","Robustness,
Interference constraints,
Games,
Convergence,
Optimization,
MIMO"
Accurate Estimation of Human Body Orientation From RGB-D Sensors,"Accurate estimation of human body orientation can significantly enhance the analysis of human behavior, which is a fundamental task in the field of computer vision. However, existing orientation estimation methods cannot handle the various body poses and appearances. In this paper, we propose an innovative RGB-D-based orientation estimation method to address these challenges. By utilizing the RGB-D information, which can be real time acquired by RGB-D sensors, our method is robust to cluttered environment, illumination change and partial occlusions. Specifically, efficient static and motion cue extraction methods are proposed based on the RGB-D superpixels to reduce the noise of depth data. Since it is hard to discriminate all the 360 ° orientation using static cues or motion cues independently, we propose to utilize a dynamic Bayesian network system (DBNS) to effectively employ the complementary nature of both static and motion cues. In order to verify our proposed method, we build a RGB-D-based human body orientation dataset that covers a wide diversity of poses and appearances. Our intensive experimental evaluations on this dataset demonstrate the effectiveness and efficiency of the proposed method.","Estimation,
Feature extraction,
Sensors,
Histograms,
Data mining,
Geometry,
Noise measurement"
Applications of Collective Circular Motion Control to Multirobot Systems,"Collective circular motion is common in both natural systems and engineering applications. Recent theoretical research has intensively studied the fundamental control mechanism. This brief aims to pave the way from theoretical design to practical implementation by addressing a set of issues encountered in real applications. As a result, a practically effective control algorithm is successfully implemented and examined for a multirobot system to achieve a desired circular formation.","Robot sensing systems,
Mobile robots,
Multirobot systems,
Collision avoidance,
Sonar"
Exploration and Optimization of 3-D Integrated DRAM Subsystems,"Energy efficiency is the major optimization criterion for systems-on-chip (SoCs) for mobile devices (smartphones and tablets). Through silicon via (TSV) technology enables 3-D integration of dies and the heterogeneous stacking of multiple memory or logic layers, allowing increased bandwidth and lower energy consumption of the memory interface compared to traditional approaches. In this paper, we explore the 3-D-DRAM architecture design space. The result is an optimized 2 Gb 3-D-DRAM, which shows a 83% lower energy/bit than a 2 Gb device. Furthermore, we propose a highly energy-efficient DRAM subsystem for next-generation 3-D-integrated SoCs, consisting of a SDR/DDR 3-D-DRAM controller and an attached 3-D-DRAM cube with fine-grained access and a flexible (WIDE-IO) interface. We assess the energy efficiency using a synthesizable model of the SDR/DDR 3-D-DRAM channel controller (CC) as well as functional models of the 3-D-stacked DRAM, including an accurate power estimation engine. We also investigate different DRAM families (WIDE IO SDR/DDR, LPDDR, and LPDDR2) and densities from 256 Mb to 4 Gb per channel. The implementation results of the proposed 3-D-DRAM subsystem show that energy optimized accesses to the 3-D-DRAM enable up to 50% energy savings compared to standard accesses. To the best of our knowledge this is the first design space exploration for 3-D-stacked DRAM considering different technologies based on real-world physical data and the first design of a 3-D-DRAM CC and 3-D-DRAM model featuring co-optimization of memory and controller architecture.","Random access memory,
Computer architecture,
Integrated circuit modeling,
Through-silicon vias,
Bandwidth,
Organizations"
Multivariate Prediction of Subcutaneous Glucose Concentration in Type 1 Diabetes Patients Based on Support Vector Regression,"Data-driven techniques have recently drawn significant interest in the predictive modeling of subcutaneous (s.c.) glucose concentration in type 1 diabetes. In this study, the s.c. glucose prediction is treated as a multivariate regression problem, which is addressed using support vector regression (SVR). The proposed method is based on variables concerning: 1) the s.c. glucose profile; 2) the plasma insulin concentration; 3) the appearance of meal-derived glucose in the systemic circulation; and 4) the energy expenditure during physical activities. Six cases corresponding to different combinations of the aforementioned variables are used to investigate the influence of the input on the daily glucose prediction. The proposed method is evaluated using a dataset of 27 patients in free-living conditions. Tenfold cross validation is applied to each dataset individually to both optimize and test the SVR model. In the case, where all the input variables are considered, the average prediction errors are 5.21, 6.03, 7.14, and 7.62 mg/dl for 15-, 30-, 60-, and 120-min prediction horizons, respectively. The results clearly indicate that the availability of multivariable data and their effective combination can significantly increase the accuracy of both short-term and long-term predictions.",
Comprehensive Analysis of Short-Channel Effects in Ultrathin SOI MOSFETs,"This paper analyzes the 2-D short-channel effect in ultrathin SOI MOSFETs. An empirical, channel length-dependent scale length is extracted from the lateral field slope of a series of numerically simulated devices. We show how this scale length is related to the short-channel threshold voltage roll-off and minimum channel length with and without a substrate bias. The benefit of a reverse substrate bias is investigated and understood in terms of the field and distribution of inversion charge in the silicon film. In particular, how a bulk-like short-channel effect is achieved when an accumulation layer is formed at the back surface. Furthermore, the effect of a high-κ gate insulator is studied and scaling implications discussed.",
Thematic Patterns in Georeferenced Tweets through Space-Time Visual Analytics,An exploratory study of the potential of georeferenced Twitter data (using tweets from Seattle-area residents over a two-month period) extracts knowledge about people's everyday life.,
Control design along trajectories with sums of squares programming,"Motivated by the need for formal guarantees on the stability and safety of controllers for challenging robot control tasks, we present a control design procedure that explicitly seeks to maximize the size of an invariant “funnel” that leads to a predefined goal set. Our certificates of invariance are given in terms of sums of squares proofs of a set of appropriately defined Lyapunov inequalities. These certificates, together with our proposed polynomial controllers, can be efficiently obtained via semidefinite optimization. Our approach can handle time-varying dynamics resulting from tracking a given trajectory, input saturations (e.g. torque limits), and can be extended to deal with uncertainty in the dynamics and state. The resulting controllers can be used by space-filling feedback motion planning algorithms to fill up the space with significantly fewer trajectories. We demonstrate our approach on a severely torque limited underactuated double pendulum (Acrobot) and provide extensive simulation and hardware validation.","Trajectory,
Polynomials,
Lyapunov methods,
Optimization,
Programming,
Torque,
Nonlinear dynamical systems"
Design QoS-Aware Multi-Path Provisioning Strategies for Efficient Cloud-Assisted SVC Video Streaming to Heterogeneous Clients,"We layout a network infrastructure that leverages the storage and computing power of a cloud residing in the core for collecting network status and computing multi-path scalable video coding (SVC) streaming provisioning strategies. Therefore, in addition to its conventional tasks in the application layer, the cloud also gets involved in the network layer for the optimization of routing and forwarding. We call this scheme as cloud-assisted SVC streaming, and use it to further improve the performance of SVC streaming by using close cooperation between cloud and network. Compared to source-routing based provisioning, the cloud-assisted scheme can provide more cost-effective provisioning strategies by utilizing better knowledge of network environment together with more powerful computation power. We then propose several multi-path provisioning algorithms for cloud-assisted SVC streaming in heterogeneous networks. To the best of our knowledge, these are the first proposals to work on the problem of adaptive multi-path SVC streaming under the bandwidth, delay and differential delay constraints. Our design of the provisioning algorithms starts from an approach that is based on Max Flow and an Auxiliary Graph. Several extensions are then made based on this approach to address the situations such as provisioning from multiple sources and provisioning in dynamic network environments with rapid background traffic fluctuations. Simulations in both static and dynamic network environments show that the proposed algorithms can achieve effective performance improvements in terms of request blocking probability, bandwidth utilization, packet delay, packet loss rate, and video playback quality.","Static VAr compensators,
Streaming media,
Routing,
Delay,
Bandwidth,
Quality of service,
Heuristic algorithms"
CORDIC Designs for Fixed Angle of Rotation,"Rotation of vectors through fixed and known angles has wide applications in robotics, digital signal processing, graphics, games, and animation. But, we do not find any optimized coordinate rotation digital computer (CORDIC) design for vector-rotation through specific angles. Therefore, in this paper, we present optimization schemes and CORDIC circuits for fixed and known rotations with different levels of accuracy. For reducing the area- and time-complexities, we have proposed a hardwired pre-shifting scheme in barrel-shifters of the proposed circuits. Two dedicated CORDIC cells are proposed for the fixed-angle rotations. In one of those cells, micro-rotations and scaling are interleaved, and in the other they are implemented in two separate stages. Pipelined schemes are suggested further for cascading dedicated single-rotation units and bi-rotation CORDIC units for high-throughput and reduced latency implementations. We have obtained the optimized set of micro-rotations for fixed and known angles. The optimized scale-factors are also derived and dedicated shift-add circuits are designed to implement the scaling. The fixed-point mean-squared-error of the proposed CORDIC circuit is analyzed statistically, and strategies for reducing the error are given. We have synthesized the proposed CORDIC cells by Synopsys Design Compiler using TSMC 90-nm library, and shown that the proposed designs offer higher throughput, less latency and less area-delay product than the reference CORDIC design for fixed and known angles of rotation. We find similar results of synthesis for different Xilinx field-programmable gate-array platforms.","Adders,
Accuracy,
Optimization,
Vectors,
Registers,
Complexity theory,
Digital signal processing"
Modeling options for demand side participation of thermostatically controlled loads,"Residential thermostatically controlled loads (TCLs) have potential for participation in electricity markets. This is because we can control a large group of these loads to achieve aggregate system behavior such as providing frequency reserves while ensuring the control actions are non-disruptive to the end users. A main challenge in controlling aggregations of TCLs is developing dynamical system models that are simple enough for optimization and control, but rich enough to capture the behavior of the loads. In this work, we propose three classes of models that approximate aggregate TCL dynamics. We analyze these models in terms of their accuracy and computational tractability. The models demonstrate a progression from models that help us analyze and predict TCL population behavior to those that help us develop large-scale automatic control strategies. Specifically, we demonstrate how formal methods from computer science and optimal control can be used to derive bounds on model error, guarantees for trajectory tracking, and algorithms for price arbitrage. We find that the accuracy of the analytic results decreases as TCL parameter heterogeneity is introduced. Thus, we motivate further development of analytical tools and modeling approaches to investigate realistic TCL behavior in power systems.","Sociology,
Statistics,
Markov processes,
Analytical models,
Computational modeling,
Mathematical model,
Load modeling"
Multi-Field-of-View Framework for Distinguishing Tumor Grade in ER+ Breast Cancer From Entire Histopathology Slides,"Modified Bloom-Richardson (mBR) grading is known to have prognostic value in breast cancer (BCa), yet its use in clinical practice has been limited by intra- and interobserver variability. The development of a computerized system to distinguish mBR grade from entire estrogen receptor-positive (ER+) BCa histopathology slides will help clinicians identify grading discrepancies and improve overall confidence in the diagnostic result. In this paper, we isolate salient image features characterizing tumor morphology and texture to differentiate entire hematoxylin and eosin (H and E) stained histopathology slides based on mBR grade. The features are used in conjunction with a novel multifield-of-view (multi-FOV) classifier-a whole-slide classifier that extracts features from a multitude of FOVs of varying sizes-to identify important image features at different FOV sizes. Image features utilized include those related to the spatial arrangement of cancer nuclei (i.e., nuclear architecture) and the textural patterns within nuclei (i.e., nuclear texture). Using slides from 126 ER+ patients (46 low, 60 intermediate, and 20 high mBR grade), our grading system was able to distinguish low versus high, low versus intermediate, and intermediate versus high grade patients with area under curve values of 0.93, 0.72, and 0.74, respectively. Our results suggest that the multi-FOV classifier is able to 1) successfully discriminate low, medium, and high mBR grade and 2) identify specific image features at different FOV sizes that are important for distinguishing mBR grade in Hand E stained ER+ BCa histology slides.","Feature extraction,
Image color analysis,
Cancer,
Tumors,
Erbium,
Educational institutions,
Image edge detection"
Scalable Face Image Retrieval Using Attribute-Enhanced Sparse Codewords,"Photos with people (e.g., family, friends, celebrities, etc.) are the major interest of users. Thus, with the exponentially growing photos, large-scale content-based face image retrieval is an enabling technology for many emerging applications. In this work, we aim to utilize automatically detected human attributes that contain semantic cues of the face photos to improve content-based face retrieval by constructing semantic codewords for efficient large-scale face retrieval. By leveraging human attributes in a scalable and systematic framework, we propose two orthogonal methods named attribute-enhanced sparse coding and attribute-embedded inverted indexing to improve the face retrieval in the offline and online stages. We investigate the effectiveness of different attributes and vital factors essential for face retrieval. Experimenting on two public datasets, the results show that the proposed methods can achieve up to 43.5% relative improvement in MAP compared to the existing methods.",
Harmonic Analysis in Frequency and Time Domain,"This paper presents a review with a concise description and analysis of the fundamentals, characteristics, analytical details, merits, and drawbacks associated with existing methods in frequency and time domain for harmonic analysis in practical power networks. The description and analysis are centered on methods developed in the harmonic domain, hybrid frequency-time domain, and time domain, respectively. Validation of the reviewed methods for harmonic analysis, against one of the widely accepted digital simulators, such as EMTP, EMTDC, or MATLAB/SIMULINK, is reported in the cited individual contributions.","power system harmonics,
harmonic analysis"
"State Estimation for Genetic Regulatory Networks With Mode-Dependent Leakage Delays, Time-Varying Delays, and Markovian Jumping Parameters","This paper considers the state estimation problem for Markovian jumping genetic regulatory networks (GRNs) with mode-dependent leakage and time-varying delays. In order to approximate the true concentrations of the mRNA and protein, the state estimator is designed using available measurement outputs. The GRNs are composed of N modes. The system switches from one mode to another according to a Markovian chain with known transition probabilities. Based on the Lyapunov functionals, including triple integral terms, some inequalities, and a time-varying delay partitioning approach, delay-dependent criteria which employ all upper bounds of time delays of each mode are obtained in terms of linear matrix inequalities (LMIs). This guarantees that the estimation error dynamics can be globally asymptotically stable from solutions of LMIs. Finally, a numerical example is presented to demonstrate the efficiency of the proposed estimation scheme.","State estimation,
Lyapunov methods,
Linear matrix inequalities,
Numerical analysis"
A location-aided routing protocol for cognitive radio networks,"Multi-hop cognitive radio networks (CRNs) are gaining interest recently in many practical applications. With location information becoming more available, designing location-aware routing protocols that fit the nature of CRNs becomes a necessity. We present LAUNCH as a location-aided routing protocol for CRNs that has a set of desirable properties: efficient use of the common control channel, has a minimal route setup delay, prefers stable routes, handles primary users heterogeneity, and handles secondary users mobility. LAUNCH is based on four main concepts: (1) a novel location-aware CRN routing metric that takes into account the PUs activity; (2) distributed calculations at the neighbors; (3) a channel locking mechanism to achieve the route stability and minimize channel switching time; (4) an efficient route maintenance strategy. Evaluation of LAUNCH on the NS2 simulator shows that its performance significantly outperforms the current state-of-the-art CRNs routing protocols in terms of end-to-end delay and packet loss rate. In addition, LAUNCH incurs a low control overhead with a fast route establishment delay.","Routing protocols,
Routing,
Delays,
Switches,
Cognitive radio"
Towards Cross-Domain Learning for Social Video Popularity Prediction,"Previous research on online media popularity prediction concluded that the rise in popularity of online videos maintains a conventional logarithmic distribution. However, recent studies have shown that a significant portion of online videos exhibit bursty/sudden rise in popularity, which cannot be accounted for by video domain features alone. In this paper, we propose a novel transfer learning framework that utilizes knowledge from social streams (e.g., Twitter) to grasp sudden popularity bursts in online content. We develop a transfer learning algorithm that can learn topics from social streams allowing us to model the social prominence of video content and improve popularity predictions in the video domain. Our transfer learning framework has the ability to scale with incoming stream of tweets, harnessing physical world event information in real-time. Using data comprising of 10.2 million tweets and 3.5 million YouTube videos, we show that social prominence of the video topic (context) is responsible for the sudden rise in its popularity where social trends have a ripple effect as they spread from the Twitter domain to the video domain. We envision that our cross-domain popularity prediction model will be substantially useful for various media applications that could not be previously solved by traditional multimedia techniques alone.","video retrieval,
computer aided instruction,
content management,
multimedia computing,
prediction theory,
social networking (online)"
Fairness-Aware and Privacy-Preserving Friend Matching Protocol in Mobile Social Networks,"Mobile social networks represent a promising cyber-physical system, which connects mobile nodes within a local physical proximity using mobile smart phones as well as wireless communication. In mobile social networks, the mobile users may, however, face the risk of leaking their personal information and location privacy. In this paper, we first model the secure friend discovery process as a generalized privacy-preserving interest and profile matching problem. We identify a new security threat arising from existing secure friend discovery protocols, coined as runaway attack, which can introduce a serious unfairness issue. To thwart this new threat, we introduce a novel blind vector transformation technique, which could hide the correlation between the original vector and transformed results. Based on this, we propose our privacy-preserving and fairness-aware interest and profile matching protocol, which allows one party to match its interest with the profile of another, without revealing its real interest and profile and vice versa. The detailed security analysis as well as real-world implementations demonstrate the effectiveness and efficiency of the proposed protocol.",
A performance study of cooperative awareness in ETSI ITS G5 and IEEE WAVE,"The idea of wirelessly connected vehicles has long ceased to be a vision as researchers from both academic and industrial institutions and field operational tests all over the world are contributing to bringing this technology to life. Both ETSI and IEEE have been working on respective standards (ETSI ITS G5 in Europe, IEEE WAVE in North America) to enable this new application of wireless communication. In this paper we compare medium access in these systems by means of an extensive simulation study while focusing on the transmission of periodic safety messages on the control channel. We observe that for different reasons high node density scenarios appear to be critical for the overall performance of both systems. This includes end-to-end delay, packet error rates and a non-optimal channel utilization that leaves room for improvement. We find that the approach proposed by ETSI ITS G5 with Decentralized Congestion Control (DCC) may access the channel rather conservatively but still outperforms IEEE WAVE in most of the scenarios.","Vehicles,
Telecommunication standards,
Safety,
Wireless communication,
Delays,
Cams"
Stochastic Analysis of a Standby System With Waiting Repair Strategy,"This paper investigates the reliability of a standby system incorporating waiting time to repair. The considered system consists of two units, namely, the main unit and the standby unit. Whenever the main unit fails, the whole load is transferred to the standby unit instantaneously by a switching-over device. As regards to the repairing of the main unit, it has to wait for repair whenever it fails due to unavailability of repair facility. When both the main and standby units fail, then the system goes to the complete failure mode. The system may also fail due to incorrect start of the system, which can occur due to an untrained and inexperience operator. The repair of the main and standby units follows general distribution, whereas repair due to human error is obtained with the help of Gumbel-Hougaard family copula. The system is analyzed by supplementary variable technique and Laplace transformation. Various reliability measures like availability, mean time to failure, and profit function have been evaluated for the considered system. A numerical example with a way to illustrate the utility of the model has also been presented.",
Modeling and Reduction of Conducted EMI of Inverters With SiC JFETs on Insulated Metal Substrate,"This paper presents the suppression of conducted common-mode (CM) electromagnetic interference (EMI) in an inverter for motor drive with discrete silicon carbide (SiC) JFETs attached on top of the insulated metal substrate (IMS). The EMC performance of the IMS inverter is compared with that of a heat sink inverter in a similar circuit layout. Both are under the same influence of parasitic capacitive couplings between the SiC JFET drains and the substrate base plate. It is found that although the application of conventional CM filters effectively suppresses the emitted noise in the low-frequency (LF) range, the influence of this capacitive coupling results in slight or no improvement in the middle-frequency (MF) and high-frequency (HF) ranges. To deal with this problem, a system CM equivalent circuit model with extracted parasitic parameters is proposed. The model is able to evaluate the filter insertion losses over a broad conducted EMI frequency band, which is essential to achieve an optimized filter design balanced between performance and cost. The presented experimental and calculated results form the step-by-step guideline that effectively suppresses the generated EMI to comply with the standard prescribed by IEC61800-3 C2: Qp.",
Rate-Dependent Analysis of the Asymptotic Behavior of Channel Polarization,"We consider the asymptotic behavior of the polarization process in the large block-length regime when transmission takes place over a binary-input memoryless symmetric channel W. In particular, we study the asymptotics of the cumulative distribution P(Zn ≤ z), where {Zn} is the Bhattacharyya process associated with W, and its dependence on the rate of transmission. On the basis of this result, we characterize the asymptotic behavior, as well as its dependence on the rate, of the block error probability of polar codes using the successive cancellation decoder. This refines the original asymptotic bounds by Arıkan and Telatar. Our results apply to general polar codes based on l×l kernel matrices. We also provide asymptotic lower bounds on the block error probability of polar codes using the maximum a posteriori (MAP) decoder. The MAP lower bound and the successive cancellation upper bound coincide when l = 2, but there is a gap for l > 2.","Decoding,
Error probability,
Kernel,
Zinc,
Vectors,
Random variables,
Transforms"
Accelerated Edge-Preserving Image Restoration Without Boundary Artifacts,"To reduce blur in noisy images, regularized image restoration methods have been proposed that use nonquadratic regularizers (like l1 regularization or total-variation) that suppress noise while preserving edges in the image. Most of these methods assume a circulant blur (periodic convolution with a blurring kernel) that can lead to wraparound artifacts along the boundaries of the image due to the implied periodicity of the circulant model. Using a noncirculant model could prevent these artifacts at the cost of increased computational complexity. In this paper, we propose to use a circulant blur model combined with a masking operator that prevents wraparound artifacts. The resulting model is noncirculant, so we propose an efficient algorithm using variable splitting and augmented Lagrangian (AL) strategies. Our variable splitting scheme, when combined with the AL framework and alternating minimization, leads to simple linear systems that can be solved noniteratively using fast Fourier transforms (FFTs), eliminating the need for more expensive conjugate gradient-type solvers. The proposed method can also efficiently tackle a variety of convex regularizers, including edge-preserving (e.g., total-variation) and sparsity promoting (e.g., l1-norm) regularizers. Simulation results show fast convergence of the proposed method, along with improved image quality at the boundaries where the circulant model is inaccurate.","Image restoration,
Minimization,
Computational modeling,
Image edge detection,
Convergence,
Image reconstruction,
Cost function"
"RASS: A Real-Time, Accurate, and Scalable System for Tracking Transceiver-Free Objects","Transceiver-free object tracking is to trace a moving object that does not carry any communication device in an environment with some monitoring nodes predeployed. Among all the tracking technologies, RF-based technology is an emerging research field facing many challenges. Although we proposed the original idea, until now there is no method achieving scalability without sacrificing latency and accuracy. In this paper, we put forward a real-time tracking system RASS, which can achieve this goal and is promising in the applications like the safeguard system. Our basic idea is to divide the tracking field into different areas, with adjacent areas using different communication channels. So, the interference among different areas can be prevented. For each area, three communicating nodes are deployed on the ceiling as a regular triangle to monitor this area. In each triangle area, we use a Support Vector Regression (SVR) model to locate the object. This model simulates the relationship between the signal dynamics caused by the object and the object position. It not only considers the ideal case of signal dynamics caused by the object, but also utilizes their irregular information. As a result, it can reach the tracking accuracy to around 1 m by just using three nodes in a triangle area with 4 m in each side. The experiments show that the tracking latency of the proposed RASS system is bounded by only about 0.26 m. Our system scales well to a large deployment field without sacrificing the latency and accuracy.","Accuracy,
Interference,
Monitoring,
Educational institutions,
Wireless communication,
Electronic mail,
Real time systems"
Congestion-Controlled-Coordinator-Based MAC for Safety-Critical Message Transmission in VANETs,"Vehicular ad hoc networks (VANETs) provide the communication framework for the dissemination of safety-critical messages such as beacons and emergency messages. The communication channel witnesses significant network load generated by frequently exchanged beacons. Under high-density situations, it leads to a serious scalability problem in VANETs. Moreover, contention-based medium access control (MAC) protocols suffer from a great number of packet collisions, and as a result, the reliability and latency of safety messages are severely affected. Because of the periodic nature of beacons, time-division multiple access (TDMA) can be a good choice over contention-based MAC. In this paper, we propose congestion-controlled-coordinator-based MAC (CCC-MAC), which is a time-slot-based medium access protocol that addresses beacons and emergency messages. Basically, the network is virtually partitioned into a number of segments. Within a segment, medium access is accomplished by using a time-slot-scheduling mechanism supervised by a local coordinator vehicle. A significant number of vehicles can be supported under the proposed configuration. In fact, the proposed scheduling mitigates channel congestion by reducing the transmission time of beacons through the use of multiple data rates. Bandwidth utilization is also improved by reusing the unoccupied time slots. Finally, CCC-MAC ensures fast and reliable propagation of emergency messages by employing a pulse-based reservation mechanism. In the simulations, we demonstrate the ability of CCC-MAC to scale well in different vehicular density scenarios. Moreover, it outperforms existing MAC-layer protocols with respect to packet reception probability and latency of safety messages.","vehicular ad hoc networks,
probability,
scheduling,
telecommunication network reliability,
time division multiple access"
Decentralized Hypothesis Testing in Wireless Sensor Networks in the Presence of Misbehaving Nodes,"Wireless sensor networks are prone to node misbehavior arising from tampering by an adversary (Byzantine attack), or due to other factors such as node failure resulting from hardware or software degradation. In this paper, we consider the problem of decentralized detection in wireless sensor networks in the presence of one or more classes of misbehaving nodes. Binary hypothesis testing is considered where the honest nodes transmit their binary decisions to the fusion center (FC), while the misbehaving nodes transmit fictitious messages. The goal of the FC is to identify the misbehaving nodes and to detect the state of nature. We identify each class of nodes with an operating point (false alarm and detection probabilities) on the receiver operating characteristic (ROC) curve. Maximum likelihood estimation of the nodes' operating points is then formulated and solved using the expectation maximization (EM) algorithm with the nodes' identities as latent variables. The solution from the EM algorithm is then used to classify the nodes and to solve the decentralized hypothesis testing problem. Numerical results compared with those from the reputation-based schemes show a significant improvement in both classification of the nodes and hypothesis testing results. We also discuss an inherent ambiguity in the node classification problem which can be resolved if the honest nodes are in majority.","Vectors,
Testing,
Wireless sensor networks,
Sensors,
Collaboration,
Estimation,
Maximum likelihood detection"
Image-Guidance Enables New Methods for Customizing Cochlear Implant Stimulation Strategies,"Over the last 20 years, cochlear implants (CIs) have become what is arguably the most successful neural prosthesis to date. Despite this success, a significant number of CI recipients experience marginal hearing restoration, and, even among the best performers, restoration to normal fidelity is rare. In this paper, we present image processing techniques that can be used to detect, for the first time, the positions of implanted CI electrodes and the nerves they stimulate for individual CI users. These techniques permit development of new, customized CI stimulation strategies. We present one such strategy and show that it leads to significant hearing improvement in an experiment conducted with 11 CI recipients. These results indicate that image-guidance can be used to improve hearing outcomes for many existing CI recipients without requiring additional surgical procedures.","Electrodes,
Computed tomography,
Shape,
Image segmentation,
Auditory system,
Computational modeling,
Arrays"
Generic factor-based node marginalization and edge sparsification for pose-graph SLAM,"This paper reports on a factor-based method for node marginalization in simultaneous localization and mapping (SLAM) pose-graphs. Node marginalization in a pose-graph induces fill-in and leads to computational challenges in performing inference. The proposed method is able to produce a new set of constraints over the elimination clique that can represent either the true marginalization, or a sparse approximation of the true marginalization using a Chow-Liu tree. The proposed algorithm improves upon existing methods in two key ways: First, it is not limited to strictly full-state relative-pose constraints and works equally well with other low-rank constraints such as those produced by monocular vision. Second, the new factors are produced in a way that accounts for measurement correlation, a problem ignored in other methods that rely upon measurement composition. We evaluate the proposed method over several real-world SLAM graphs and show that it outperforms other state-of-the-art methods in terms of Kullback-Leibler divergence.","Approximation methods,
Simultaneous localization and mapping,
Mutual information,
Symmetric matrices,
Correlation,
Joints,
Jacobian matrices"
Output Feedback Sliding Mode Control for a Stewart Platform With a Nonlinear Observer-Based Forward Kinematics Solution,"In this paper, an observer-based forward kinematics solution of a 6-6 Stewart platform is proposed and this algorithm is applied to implement an output feedback sliding mode control. The conventional forward kinematics solutions take too much computational load or are too complex to be carried out in the online control scheme. The proposed nonlinear observer-based algorithm provides a simple method to obtain a real-time forward kinematics solution. With this solution, 6-degrees-of-freedom posture control of the moving platform can be achieved without installation of any external sensor after applying an output feedback control. In contrast with the conventional control scheme which aims to control individual leg length in actuator domain, the output feedback controller is proposed here to control the posture in Cartesian domain directly. The stability of the whole system is thoroughly proved to ensure convergence of the control errors. Simulations and experimental results are presented to validate the feasibility of the hereby proposed results.","Observers,
Kinematics,
Vectors,
Jacobian matrices,
Output feedback,
Observability,
Nonlinear systems"
Design of an Inertially Counterbalanced Z -Nanopositioner for High-Speed Atomic Force Microscopy,"In many conventional atomic force microscopes (AFMs), one of the key hurdles to high-speed scanning in constant-force contact mode is the low-feedback control bandwidth of the -axis loop. This paper presents the design of a fast -nanoposi-tioner to overcome this limitation. The -nanopositioner has its first resonant mode at 60 kHz and a travel range of 5 m. It consists of a piezoelectric stack actuator and a diaphragm flexure. The flexure serves as a linear spring to preload the actuator and to prevent it from getting damaged during high-speed operations. The -nanopositioner is mounted to an XY-nanopositioner. To avoid exciting the resonance of the XY -nanopositioner, an inertial counterbalance configuration was incorporated in the design of the -nanopositioner. With this configuration, the resonances of the XY-nanopositioner were not triggered. A closed-loop vertical control bandwidth of 6.5 kHz is achieved. High-speed constant-force contact-mode images were recorded at a resolution of 200 200 pixels at 10, 100, and 200 Hz line rates without noticeable image artifacts due to insufficient control bandwidth and vibrations. Images were also recorded at 312- and 400-Hz line rates. These images do not show significant artifacts. These line rates are much higher than the closed-loop bandwidth of a conventional AFM in which this nanopositioner was tested.",
A Data Fusion Technique for Wireless Ranging Performance Improvement,"The increasing diffusion of mobile and portable devices provided with wireless connectivity makes the problem of distance measurement based on radio-frequency technologies increasingly important for the development of next-generation nomadic applications. In this paper, the performance limitations of two classic wireless ranging techniques based on received signal strength (RSS) and two-way time-of-flight (ToF) measurements, respectively, are analyzed and compared in detail. On the basis of this study, a data fusion algorithm is proposed to combine both techniques in order to improve ranging accuracy. The algorithm has been implemented and tested on the field using a dedicated embedded prototype made with commercial off-the-shelf components. Several experimental results prove that the combination of both techniques can significantly reduce measurement uncertainty. The results obtained with the developed prototype are not accurate enough for fine-grained position tracking in Ambient Assisted Living applications. However, the platform can be successfully used for reliable indoor zoning, e.g., for omnidirectional and adjustable hazard proximity detection. Most importantly, the proposed solution is absolutely general, and it is quite simple and light from the computational point of view. Accuracy could be further improved by using a more isotropic antenna and by integrating the ToF measurement technique at the lowest possible level on the same radio chip used for communication. Usually, this feature is not available in typical low-cost short-range wireless modules, e.g., for wireless sensor networks. Thus, the results of this research suggest that combining RSS with ToF measurements could be a viable solution for chip manufacturers interested in adding ranging capabilities to their radio modules.",
A Junctionless Gate-All-Around Silicon Nanowire FET of High Linearity and Its Potential Applications,"The linearity of a gate-all-around junctionless silicon nanowire (SiNW) FET has been analyzed. The SiNW FET shows a perfectly linear ID-VG relation and a nearly zero output conductance. The mechanism of its linear behaviors due to degenerate doping level has been also demonstrated. For RF applications, the proposed SiNW FET exhibits a much lower distortion for a whole range of load resistance, making it superior to modern short-channel MOSFET.","Linearity,
MOSFET,
Logic gates,
Radio frequency,
Doping,
Resistance"
Energy-Efficient Intrusion Detection with a Barrier of Probabilistic Sensors: Global and Local,"Intrusion detection is a significant application in wireless sensor networks (WSNs). S. Kumar et al have introduced the concept of barrier coverage, which deploys sensors in a narrow belt region to guarantee that any intrusion across the region is to be detected. However, the practical issues have not been investigated such as scheduling sensors energy-efficiently while guaranteeing the detection probability of any intrusion across the region based on probabilistic sensing model. Besides, the intruders may be humans, animals, fighter planes or other things, which obviously have diverse moving speeds. In this paper, we analyze the detection probability of arbitrary path across the barrier of sensors theoretically and take the maximum speed of possible intruders into consideration since the sensor networks are designed for different intruders in different scenarios. Based on the theoretical analysis of detection probability, we formulate Minimum Weight ε-Barrier Problem about how to schedule sensors energy-efficiently and prove it is NP-hard. We propose both global and local solutions to the problem. The global solution called Minimum Weight Barrier Algorithm is a bounded approximation algorithm, based on which a localized protocol for energy-efficient scheduling is designed. To evaluate our design, we analyze the performance of our approaches theoretically and also perform extensive simulations to demonstrate the effectiveness of our proposed algorithm.","Sensors,
Wireless sensor networks,
Probabilistic logic,
Belts,
Algorithm design and analysis,
Approximation methods,
Approximation algorithms"
State-Plane Analysis of Regenerative Snubber for Flyback Converters,"The flyback converter is a popular topology for implementing low power and multiple output power supplies. However, the high leakage inductance of the flyback transformer causes high voltage spikes that can damage the main transistor when the switch is turned OFF. Therefore, a turn-off snubber is needed to limit the peak voltage stress. This paper presents the analysis of an energy regenerative snubber using the graphical state-plane technique. The undertaken approach yields a clear-cut design procedure for minimum switch voltage stress. Experimental evaluation of the energy regenerative snubber in comparison with other common snubbers shows that under the same voltage stress the efficiency of energy regenerative snubber has 8% improvement on average over an RCD snubber and 2% improvement over the nondissipative LC snubber.",
Surface Laplacian of Central Scalp Electrical Signals is Insensitive to Muscle Contamination,"The objective of this paper was to investigate the effects of surface Laplacian processing on gross and persistent electromyographic (EMG) contamination of electroencephalographic (EEG) signals in electrical scalp recordings. We made scalp recordings during passive and active tasks, on awake subjects in the absence and in the presence of complete neuromuscular blockade. Three scalp surface Laplacian estimators were compared to left ear and common average reference (CAR). Contamination was quantified by comparing power after paralysis (brain signal, B) with power before paralysis (brain plus muscle signal, B+M). Brain:Muscle (B:M) ratios for the methods were calculated using B and differences in power after paralysis to represent muscle (M). There were very small power differences after paralysis up to 600 Hz using surface Laplacian transforms (B:M >; 6 above 30 Hz in central scalp leads). Scalp surface Laplacian transforms reduce muscle power in central and pericentral leads to less than one sixth of the brain signal, two to three times better signal detection than CAR. Scalp surface Laplacian transformations provide robust estimates for detecting high-frequency (gamma) activity, for assessing electrophysiological correlates of disease, and also for providing a measure of brain electrical activity for use as a standard in the development of brain/muscle signal separation methods.","Laplace equations,
Scalp,
Muscles,
Spline,
Surface contamination,
Transforms,
Electromyography"
User Selection for Multiuser MIMO Downlink With Zero-Forcing Beamforming,"In this paper, we propose a greedy user selection with swap (GUSS) algorithm based on zero-forcing beamforming for multiuser multiple-input-multiple-output (MIMO) downlink channels. Existing user selection algorithms such as zero forcing with selection (ZFS) have the flaws of “redundant users” and “local optimum,” which compromise the achieved sum rate. GUSS improves the performance by adding the “delete” and “swap” operations to the user selection procedure of ZFS to eliminate “redundant users” and escape from “local optimum,” respectively. In addition, an effective-channel-vector-based effective-channel-gain-updating scheme is proposed to reduce the complexity of GUSS. With the help of this updating scheme, GUSS has the same order of complexity as ZFS with only a linear increment. Simulation results indicate that over the range of transmit signal-to-noise ratios (SNRs) considered, on average, the sum rate of GUSS reaches 99.3% of the upper bound that is achieved by exhaustive search, with only 1.51 to 2.29 times the complexity of ZFS.",
A Dual Decomposition Approach to Feature Correspondence,"In this paper, we present a new approach for establishing correspondences between sparse image features related by an unknown nonrigid mapping and corrupted by clutter and occlusion, such as points extracted from images of different instances of the same object category. We formulate this matching task as an energy minimization problem by defining an elaborate objective function of the appearance and the spatial arrangement of the features. Optimization of this energy is an instance of graph matching, which is in general an NP-hard problem. We describe a novel graph matching optimization technique, which we refer to as dual decomposition (DD), and demonstrate on a variety of examples that this method outperforms existing graph matching algorithms. In the majority of our examples, DD is able to find the global minimum within a minute. The ability to globally optimize the objective allows us to accurately learn the parameters of our matching model from training examples. We show on several matching tasks that our learned model yields results superior to those of state-of-the-art methods.","Vectors,
Optimization,
Labeling,
Computational modeling,
Indexes,
Feature extraction,
Minimization"
Software enabled wear-leveling for hybrid PCM main memory on embedded systems,"Phase Change Memory (PCM) is a promising DRAM replacement in embedded systems due to its attractive characteristics. However, relatively low endurance has limited its practical applications. In this paper, in additional to existing hardware level optimizations, we propose software enabled wear-leveling techniques to further extend PCM's lifetime when it is adopted in embedded systems. A polynomial-time algorithm, the Software Wear-Leveling (SWL) algorithm, is proposed in this paper to achieve wear-leveling without hardware overhead. According to the experimental results, the proposed technique can reduce the number of writes on the most-written bits by more than 80% when compared with a greedy algorithm, and by around 60% when compared with the existing Optimal Data Allocation (ODA) algorithm with under 6% memory access overhead.","Phase change materials,
Software,
Software algorithms,
Random access memory,
Hardware,
Resource management,
Nonvolatile memory"
Exponential Local Discriminant Embedding and Its Application to Face Recognition,"Local discriminant embedding (LDE) has been recently proposed to overcome some limitations of the global linear discriminant analysis method. In the case of a small training data set, however, LDE cannot directly be applied to high-dimensional data. This case is the so-called small-sample-size (SSS) problem. The classical solution to this problem was applying dimensionality reduction on the raw data (e.g., using principal component analysis). In this paper, we introduce a novel discriminant technique called “exponential LDE” (ELDE). The proposed ELDE can be seen as an extension of LDE framework in two directions. First, the proposed framework overcomes the SSS problem without discarding the discriminant information that was contained in the null space of the locality preserving scatter matrices associated with LDE. Second, the proposed ELDE is equivalent to transforming original data into a new space by distance diffusion mapping (similar to kernel-based nonlinear mapping), and then, LDE is applied in such a new space. As a result of diffusion mapping, the margin between samples belonging to different classes is enlarged, which is helpful in improving classification accuracy. The experiments are conducted on five public face databases: Yale, Extended Yale, PF01, Pose, Illumination, and Expression (PIE), and Facial Recognition Technology (FERET). The results show that the performances of the proposed ELDE are better than those of LDE and many state-of-the-art discriminant analysis techniques.","Principal component analysis,
Kernel,
Symmetric matrices,
Eigenvalues and eigenfunctions,
Matrices,
Face recognition,
Feature extraction"
Efficient Computer Network Anomaly Detection by Changepoint Detection Methods,"We consider the problem of efficient on-line anomaly detection in computer network traffic. The problem is approached statistically, as that of sequential (quickest) changepoint detection. A multi-cyclic setting of quickest change detection is a natural fit for this problem. We propose a novel score-based multi-cyclic detection algorithm. The algorithm is based on the so-called Shiryaev-Roberts procedure. This procedure is as easy to employ in practice and as computationally inexpensive as the popular Cumulative Sum chart and the Exponentially Weighted Moving Average scheme. The likelihood ratio based Shiryaev-Roberts procedure has appealing optimality properties, particularly it is exactly optimal in a multi-cyclic setting geared to detect a change occurring at a far time horizon. It is therefore expected that an intrusion detection algorithm based on the Shiryaev-Roberts procedure will perform better than other detection schemes. This is confirmed experimentally for real traces. We also discuss the possibility of complementing our anomaly detection algorithm with a spectral-signature intrusion detection system with false alarm filtering and true attack confirmation capability, so as to obtain a synergistic system.","Computer networks,
Delay,
Computer security,
Detection algorithms,
Tin,
Educational institutions,
Intrusion detection"
Novel Fault Ride-Through Configuration and Transient Management Scheme for Doubly Fed Induction Generator,"This paper proposed a novel fault ride-through (FRT) configuration and transient management scheme to enhance the FRT capability of doubly fed induction generator-based wind turbines. The new configuration of the grid-side converter introduces shunt and series compensation for normal operation and voltage dips, respectively. A braking resistor is added to smooth switching transients from shunt to series interfaces and dissipate excessive power from the grid-side converter. To attain a flexible control solution for balanced and unbalanced fault conditions, the proposed transient management scheme employs positive and negative sequence controllers. A small-signal linear model is developed and examined to analyze the system dynamics for the series compensation topology. Based on the mathematical model, the controller is tuned to balance both voltage regulation performance and transient stability margins with consideration of various operating conditions. The combination of shunt and series interfaces demonstrates a low component count, simple protection structure, and improved performance of FRT with effective compensation to the electric grid. A comprehensive simulation verified the capability of the new configuration and transient management scheme.","Rotors,
Resistors,
Transient analysis,
Stator windings,
Voltage fluctuations,
Voltage control"
The 2nd competition on counter measures to 2D face spoofing attacks,"As a crucial security problem, anti-spoofing in biometrics, and particularly for the face modality, has achieved great progress in the recent years. Still, new threats arrive inform of better, more realistic and more sophisticated spoofing attacks. The objective of the 2nd Competition on Counter Measures to 2D Face Spoofing Attacks is to challenge researchers to create counter measures effectively detecting a variety of attacks. The submitted propositions are evaluated on the Replay-Attack database and the achieved results are presented in this paper.",
Linearity and Shift Invariance for Quantitative Magnetic Particle Imaging,"Magnetic Particle Imaging (MPI) is a promising tracer imaging modality that employs a kidney-safe contrast agent and does not use ionizing radiation. MPI already shows high contrast and sensitivity in small animal imaging, with great potential for many clinical applications, including angiography, cancer detection, inflammation imaging, and treatment monitoring. Currently, almost all clinically relevant imaging techniques can be modeled as systems with linearity and shift invariance (LSI), characteristics crucial for quantification and diagnostic utility. In theory, MPI has been proven to be LSI. However, in practice, high-pass filters designed to remove unavoidable direct feedthrough interference also remove information crucial to ensuring LSI in MPI scans. In this work, we present a complete theoretical and experimental description of the image artifacts from filtering. We then propose and validate a robust algorithm to completely restore the lost information for the x-space MPI method. We provide the theoretical, simulated, and experimental proof that our algorithm indeed restores the LSI properties of MPI.",
Sensorless Control of CSC-Fed IPM Machine for Zero- and Low-Speed Operations Using Pulsating HFI Method,"In this paper, a sensorless method for low- and zero-speed operations is proposed for a high-power medium-voltage pulsewidth-modulated current-source-converter-fed interior-permanent-magnet motor drive system. The proposed method is based on the injection of a high frequency (HF) pulsating sinusoidal signal in the estimated synchronous reference frame of the drive's field-oriented control (FOC) scheme. The conventional FOC control scheme, low switching frequency, dc-link inductor, and the inverter output three-phase filter capacitor of the medium-voltage high-power current-source drive present some challenges in the generation and design of the HF-injection signal. To overcome these challenges, the FOC scheme is modified by introducing a modulation index control with suitable dc-link current compensation to enhance the dynamic response of the injected signal and prevent any clamp in the injected signal. In addition, a multisampling-space-vector-modulation method is proposed to prevent the distortion in the HF signal due to a low switching frequency to injected signal ratio. A detailed study and analysis regarding the influence of low switching frequency, output filter capacitor, and magnetic saturation in the injection method is carried out to determine the visible HF range of the injected signal. It is found that, by using the proposed FOC scheme and multisampling modulation scheme and by the proper design of the HF signal, an accurate rotor flux angle can be estimated for sensorless zero-/low-speed operations. Experimental results are provided to verify the proposed control method.","Hafnium,
Rotors,
Inverters,
Modulation,
Capacitors,
Rectifiers,
Stators"
Novel Anonymous Authentication Scheme Using Smart Cards,"Smart card based authentication scheme has been widely utilized for various transaction-oriented services such as electronic currency exchange, social insurance payment and e-commerce payment charge in modern society. How to develop a smart card based authentication scheme to support initiator untraceability and defend against major security threats for a transaction service user has become a crucial topic for researchers. Recent efforts for developing anonymous authentication scheme with smart card have failed to provide initiator untraceability for user or been vulnerable to some security attacks. This paper first presents a security model for anonymous authentication and then proposes a new anonymous authentication scheme using smart card. Security robustness of the proposed scheme is constructed by one-way hash function and elliptic curve cryptosystem. Our security analysis shows that the proposed scheme achieves general security requirement and offers initiator untraceability for user without requiring database support. Performance analysis on communication overhead and computation cost shows that the proposed scheme has better or similar efficiency in comparison with other existing smart card based authentication schemes.","Smart cards,
Security,
Authentication,
Robustness,
Elliptic curve cryptography"
Local Edge-Preserving Multiscale Decomposition for High Dynamic Range Image Tone Mapping,"A novel filter is proposed for edge-preserving decomposition of an image. It is different from previous filters in its locally adaptive property. The filtered image contains local means everywhere and preserves local salient edges. Comparisons are made between our filtered result and the results of three other methods. A detailed analysis is also made on the behavior of the filter. A multiscale decomposition with this filter is proposed for manipulating a high dynamic range image, which has three detail layers and one base layer. The multiscale decomposition with the filter addresses three assumptions: 1) the base layer preserves local means everywhere; 2) every scale's salient edges are relatively large gradients in a local window; and 3) all of the nonzero gradient information belongs to the detail layer. An effective function is also proposed for compressing the detail layers. The reproduced image gives a good visualization. Experimental results on real images demonstrate that our algorithm is especially effective at preserving or enhancing local details.","Image edge detection,
Dynamic range,
Image coding,
Lighting,
Oscillators"
Automatic Dynamic Texture Segmentation Using Local Descriptors and Optical Flow,"A dynamic texture (DT) is an extension of the texture to the temporal domain. How to segment a DT is a challenging problem. In this paper, we address the problem of segmenting a DT into disjoint regions. A DT might be different from its spatial mode (i.e., appearance) and/or temporal mode (i.e., motion field). To this end, we develop a framework based on the appearance and motion modes. For the appearance mode, we use a new local spatial texture descriptor to describe the spatial mode of the DT; for the motion mode, we use the optical flow and the local temporal texture descriptor to represent the temporal variations of the DT. In addition, for the optical flow, we use the histogram of oriented optical flow (HOOF) to organize them. To compute the distance between two HOOFs, we develop a simple effective and efficient distance measure based on Weber's law. Furthermore, we also address the problem of threshold selection by proposing a method for determining thresholds for the segmentation method by an offline supervised statistical learning. The experimental results show that our method provides very good segmentation results compared to the state-of-the-art methods in segmenting regions that differ in their dynamics.",
Kernelization of Tensor-Based Models for Multiway Data Analysis: Processing of Multidimensional Structured Data,"Tensors (also called multiway arrays) are a generalization of vectors and matrices to higher dimensions based on multilinear algebra. The development of theory and algorithms for tensor decompositions (factorizations) has been an active area of study within the past decade, e.g., [1] and [2]. These methods have been successfully applied to many problems in unsupervised learning and exploratory data analysis. Multiway analysis enables one to effectively capture the multilinear structure of the data, which is usually available as a priori information about the data. Hence, it might provide advantages over matrix factorizations by enabling one to more effectively use the underlying structure of the data. Besides unsupervised tensor decompositions, supervised tensor subspace regression and classification formulations have been also successfully applied to a variety of fields including chemometrics, signal processing, computer vision, and neuroscience.",
Experiencing BCI Control in a Popular Computer Game,"Brain-computer interfaces (BCIs) are not only being developed to aid disabled individuals with motor substitution, motor recovery, and novel communication possibilities, but also as a modality for healthy users in entertainment and gaming. This study investigates whether the incorporation of a BCI in the popular game World of Warcraft (WoW) has effects on the user experience. A BCI control channel based on parietal alpha band power is used to control the shape and function of the avatar in the game. In the experiment, participants (n=42) , a mix of experienced and inexperienced WoW players, played with and without the use of BCI in a within-subjects design. Participants themselves could indicate when they wanted to stop playing. Actual and estimated duration was recorded and questionnaires on presence and control were administered. Afterwards, oral interviews were taken. No difference in actual duration was found between conditions. Results indicate that the difference between estimated and actual duration was not related to user experience but was person specific. When using a BCI, control and involvement were rated lower. But BCI control did not significantly decrease fun. During interviews, experienced players stated that they saw potential in the application of BCIs in games with complex interfaces such as WoW. This study suggests that BCI as an additional control can be as much fun and natural to use as keyboard/mouse control, even if the amount of control is limited.","Games,
Shape,
Electroencephalography,
Headphones,
Interviews,
Keyboards,
Mice"
Max-Min Fairness Linear Transceiver Design for a Multi-User MIMO Interference Channel,"Consider the max-min fairness linear transceiver design problem for a multi-user multi-input multi-output (MIMO) interference channel. When the channel knowledge is perfectly known, this problem can be formulated as the maximization of the minimum signal-to-interference-plus-noise ratio (SINR) utility, subject to individual power constraints at each transmitter. We prove in this paper that, if the number of antennas is at least two at each transmitter (receiver) and is at least three at each receiver (transmitter), the max-min fairness linear transceiver design problem is computationally intractable as the number of users becomes large. In fact, even the problem of checking the feasibility of a given set of target SINR levels is strongly NP-hard. We then propose two iterative algorithms to solve the max-min fairness linear transceiver design problem. The transceivers generated by these algorithms monotonically improve the min-rate utility and are guaranteed to converge to a stationary solution. The efficiency and performance of the proposed algorithms compare favorably with solutions obtained from the channel matched beamforming or the leakage interference minimization.","Interference,
Signal to noise ratio,
Transceivers,
Receivers,
Polynomials,
Transmitters,
Algorithm design and analysis"
Compressive Blind Image Deconvolution,"We propose a novel blind image deconvolution (BID) regularization framework for compressive sensing (CS) based imaging systems capturing blurred images. The proposed framework relies on a constrained optimization technique, which is solved by a sequence of unconstrained sub-problems, and allows the incorporation of existing CS reconstruction algorithms in compressive BID problems. As an example, a non-convex lp quasi-norm with 0 <; p <; 1 is employed as a regularization term for the image, while a simultaneous auto-regressive regularization term is selected for the blur. Nevertheless, the proposed approach is very general and it can be easily adapted to other state-of-the-art BID schemes that utilize different, application specific, image/blur regularization terms. Experimental results, obtained with simulations using blurred synthetic images and real passive millimeter-wave images, show the feasibility of the proposed method and its advantages over existing approaches.",
From Complex {\rm B}_{1} Mapping to Local SAR Estimation for Human Brain MR Imaging Using Multi-Channel Transceiver Coil at 7T,"Elevated specific absorption rate (SAR) associated with increased main magnetic field strength remains a major safety concern in ultra-high-field (UHF) magnetic resonance imaging (MRI) applications. The calculation of local SAR requires the knowledge of the electric field induced by radio-frequency (RF) excitation, and the local electrical properties of tissues. Since electric field distribution cannot be directly mapped in conventional MR measurements, SAR estimation is usually performed using numerical model-based electromagnetic simulations which, however, are highly time consuming and cannot account for the specific anatomy and tissue properties of the subject undergoing a scan. In the present study, starting from the measurable RF magnetic fields (B1) in MRI, we conducted a series of mathematical deduction to estimate the local, voxel-wise and subject-specific SAR for each single coil element using a multi-channel transceiver array coil. We first evaluated the feasibility of this approach in numerical simulations including two different human head models. We further conducted experimental study in a physical phantom and in two human subjects at 7T using a multi-channel transceiver head coil. Accuracy of the results is discussed in the context of predicting local SAR in the human brain at UHF MRI using multi-channel RF transmission.",
Grand Challenges in Interfacing Engineering With Life Sciences and Medicine,"This paper summarizes the discussions held during the First IEEE Life Sciences Grand Challenges Conference, held on October 4-5, 2012, at the National Academy of Sciences, Washington, DC, and the grand challenges identified by the conference participants. Despite tremendous efforts to develop the knowledge and ability that are essential in addressing biomedical and health problems using engineering methodologies, the optimization of this approach toward engineering the life sciences and healthcare remains a grand challenge. The conference was aimed at high-level discussions by participants representing various sectors, including academia, government, and industry. Grand challenges were identified by the conference participants in five areas including engineering the brain and nervous system; engineering the cardiovascular system; engineering of cancer diagnostics, therapeutics, and prevention; translation of discoveries to clinical applications; and education and training. A number of these challenges are identified and summarized in this paper.",
Trusted Collaborative Spectrum Sensing for Mobile Cognitive Radio Networks,"Collaborative spectrum sensing is a key technology in cognitive radio networks (CRNs). Although mobility is an inherent property of wireless networks, there has been no prior work studying the performance of collaborative spectrum sensing under attacks in mobile CRNs. Existing solutions based on user trust for secure collaborative spectrum sensing cannot be applied to mobile scenarios, since they do not consider the location diversity of the network, thus over penalize honest users who are at bad locations with severe path-loss. In this paper, we propose to use two trust parameters, location reliability and malicious intention (LRMI), to improve both malicious user detection and primary user detection in mobile CRNs under attack. Location reliability reflects path-loss characteristics of the wireless channel and malicious intention captures the true intention of secondary users, respectively. We propose a primary user detection method based on location reliability (LR) and a malicious user detection method based on LR and Dempster-Shafer (D-S) theory. Simulations show that mobility helps train location reliability and detect malicious users based on our methods. Our proposed detection mechanisms based on LRMI significantly outperforms existing solutions. In comparison to the existing solutions, we show an improvement of malicious user detection rate by 3 times and primary user detection rate by 20% at false alarm rate of 5%, respectively.","Sensors,
Mobile communication,
Collaboration,
Reliability theory,
Shadow mapping,
Fading"
Real-Time Multiple Human Perception With Color-Depth Cameras on a Mobile Robot,"The ability to perceive humans is an essential requirement for safe and efficient human-robot interaction. In real-world applications, the need for a robot to interact in real time with multiple humans in a dynamic, 3-D environment presents a significant challenge. The recent availability of commercial color-depth cameras allow for the creation of a system that makes use of the depth dimension, thus enabling a robot to observe its environment and perceive in the 3-D space. Here we present a system for 3-D multiple human perception in real time from a moving robot equipped with a color-depth camera and a consumer-grade computer. Our approach reduces computation time to achieve real-time performance through a unique combination of new ideas and established techniques. We remove the ground and ceiling planes from the 3-D point cloud input to separate candidate point clusters. We introduce the novel information concept, depth of interest, which we use to identify candidates for detection, and that avoids the computationally expensive scanning-window methods of other approaches. We utilize a cascade of detectors to distinguish humans from objects, in which we make intelligent reuse of intermediary features in successive detectors to improve computation. Because of the high computational cost of some methods, we represent our candidate tracking algorithm with a decision directed acyclic graph, which allows us to use the most computationally intense techniques only where necessary. We detail the successful implementation of our novel approach on a mobile robot and examine its performance in scenarios with real-world challenges, including occlusion, robot motion, nonupright humans, humans leaving and reentering the field of view (i.e., the reidentification challenge), human-object and human-human interaction. We conclude with the observation that the incorporation of the depth information, together with the use of modern techniques in new ways, we are able to create an accurate system for real-time 3-D perception of humans by a mobile robot.","Cameras,
Robot vision systems,
Real-time systems,
Detectors,
Image color analysis,
Target tracking"
Automatic Fall Detection and Activity Classification by a Wearable Embedded Smart Camera,"Robust detection of events and activities, such as falling, sitting, and lying down, is a key to a reliable elderly activity monitoring system. While fast and precise detection of falls is critical in providing immediate medical attention, other activities like sitting and lying down can provide valuable information for early diagnosis of potential health problems. In this paper, we present a fall detection and activity classification system using wearable cameras. Since the camera is worn by the subject, monitoring is not limited to confined areas, and extends to wherever the subject may go including indoors and outdoors. Furthermore, since the captured images are not of the subject, privacy concerns are alleviated. We present a fall detection algorithm employing histograms of edge orientations and strengths, and propose an optical flow-based method for activity classification. The first set of experiments has been performed with prerecorded video sequences from eight different subjects wearing a camera on their waist. Each subject performed around 40 trials, which included falling, sitting, and lying down. Moreover, an embedded smart camera implementation of the algorithm was also tested on a CITRIC platform with subjects wearing the CITRIC camera, and each performing 50 falls and 30 non-fall activities. Experimental results show the success of the proposed method.","video signal processing,
assisted living,
data privacy,
edge detection,
geriatrics,
image classification,
image sequences,
object detection,
patient diagnosis,
patient monitoring,
video cameras"
VeriTrust: Verification for hardware trust,"Hardware Trojans (HTs) implemented by adversaries serve as backdoors to subvert or augment the normal operation of infected devices, which may lead to functionality changes, sensitive information leakages, or Denial of Service attacks. To tackle such threats, this paper proposes a novel verification technique for hardware trust, namely VeriTrust, which facilitates to detect HTs inserted at design stage. Based on the observation that HTs are usually activated by dedicated trigger inputs that are not sensitized with verification test cases, VeriTrust automatically identifies such potential HT trigger inputs by examining verification corners. The key difference between VeriTrust and existing HT detection techniques is that VeriTrust is insensitive to the implementation style of HTs. Experimental results show that VeriTrust is able to detect all HTs evaluated in this paper (constructed based on various HT design methodologies shown in the literature) at the cost of moderate extra verification time, which is not possible with existing solutions.","Hardware,
Measurement,
Detection algorithms,
Integrated circuit modeling,
Payloads,
Runtime"
Stopped Object Detection by Learning Foreground Model in Videos,"The automatic detection of objects that are abandoned or removed in a video scene is an interesting area of computer vision, with key applications in video surveillance. Forgotten or stolen luggage in train and airport stations and irregularly parked vehicles are examples that concern significant issues, such as the fight against terrorism and crime, and public safety. Both issues involve the basic task of detecting static regions in the scene. We address this problem by introducing a model-based framework to segment static foreground objects against moving foreground objects in single view sequences taken from stationary cameras. An image sequence model, obtained by learning in a self-organizing neural network image sequence variations, seen as trajectories of pixels in time, is adopted within the model-based framework. Experimental results on real video sequences and comparisons with existing approaches show the accuracy of the proposed stopped object detection approach.",
"Quantum Search Algorithms, Quantum Wireless, and a Low-Complexity Maximum Likelihood Iterative Quantum Multi-User Detector Design","The high complexity of numerous optimal classic communication schemes, such as the maximum likelihood (ML) multiuser detector (MUD), often prevents their practical implementation. In this paper, we present an extensive review and tutorial on quantum search algorithms (QSA) and their potential applications, and we employ a QSA that finds the minimum of a function in order to perform optimal hard MUD with a quadratic reduction in the computational complexity when compared to that of the ML MUD. Furthermore, we follow a quantum approach to achieve the same performance as the optimal soft-input soft-output classic detectors by replacing them with a quantum algorithm, which estimates the weighted sum of a function's evaluations. We propose a soft-input soft-output quantum-assisted MUD (QMUD) scheme, which is the quantum-domain equivalent of the ML MUD. We then demonstrate its application using the design example of a direct-sequence code division multiple access system employing bit-interleaved coded modulation relying on iterative decoding, and compare it with the optimal ML MUD in terms of its performance and complexity. Both our extrinsic information transfer charts and bit error ratio curves show that the performance of the proposed QMUD and that of the optimal classic MUD are equivalent, but the QMUD's computational complexity is significantly lower.","Parallel processing,
Quantum computing,
Interleaved codes,
Amplitude modulation,
Search methods,
Computational complexity,
Algorithm design and analysis,
Modulation,
Maximum likelihood decoding"
MPEG-2 to HEVC Video Transcoding With Content-Based Modeling,"This paper proposes an efficient MPEG-2 to High Efficiency Video Coding (HEVC) video transcoder. The objective of the transcoder is to migrate the abundant MPEG-2 video content to the emerging HEVC video coding standard. The transcoder introduces a content-based machine learning solution to predict the depth of the HEVC coding units. The proposed transcoder utilizes full re-encoding to find a mapping between the incoming MPEG-2 coding information and the outgoing HEVC depths of the coding units. Once the model is built, a switch to transcoding mode occurs. Hence, the model is content based and varies from one video sequence to another. The transcoder is compared against full re-encoding using the default HEVC fast motion estimation. Using HEVC test sequences, it is shown that a speedup factor of up to 3 is achieved, while reducing the bitrate of the incoming video by around 50%. In comparison to full re-encoding, an average of 3.9% excessive bitrate is encountered with an average PSNR drop of 0.1 dB. Since this is the first work to report on MPEG-2 to HEVC video transcoding, the reported results can be used as a benchmark for future transcoding research.","Transform coding,
Transcoding,
Bit rate,
Vectors,
Video coding,
PSNR"
A load balancing model based on cloud partitioning for the public cloud,Load balancing in the cloud computing environment has an important impact on the performance. Good load balancing makes cloud computing more efficient and improves user satisfaction. This article introduces a better load balance model for the public cloud based on the cloud partitioning concept with a switch mechanism to choose different strategies for different situations. The algorithm applies the game theory to the load balancing strategy to improve the efficiency in the public cloud environment.,"Cloud computing,
Load management,
Round robin,
Load modeling,
Computational modeling,
Heuristic algorithms,
Game theory"
Energy-Efficient Transmissions of Bursty Data Packets with Strict Deadlines over Time-Varying Wireless Channels,"We develop a novel approach to energy-efficient transmissions with arbitrary packet arrival process and strict delay constraints over time-varying wireless channels. When the arrivals, deadlines, and channel realizations are known a priori, we formulate the problem as a convex program. Relying on the specific structure of the optimality conditions, we put forth an efficient algorithm with a linear computational complexity in the order of constraint number to find the (offline) optimal rate control strategy. It is revealed that the power usage under the optimal policy admits a multi-level water-filling form, where the determination of the multiple water-levels can be visualized by the trajectory of letting a string tie its two ends and then taut between what we call the ""water"" arrival and departure curves. Guided by the optimal strategy, development of energy-efficient online schedules in practical systems is discussed. Numerical results are provided to demonstrate the merits of the proposed novel scheme.","Wireless communication,
Delays,
Wireless sensor networks,
Ad hoc networks,
Convex functions,
Scheduling,
Vectors"
Detection of Concealed Individuals Based on Their Vital Signs by Using a See-Through-Wall Imaging System With a Self-Injection-Locked Radar,"This paper presents a self-injection-locked (SIL) radar with ranging and tracking capabilities to see through walls for discovering hidden people. Characterized by low complexity and high sensitivity, the proposed SIL radar merges the frequency-modulated continuous-wave and sum-difference pattern detection approaches to determine the distance and azimuth from the radar to each individual in a scene behind a wooden partition wall. An individual can be distinguished from a stationary object by using dynamic spectral subtraction to extract human motions or vital signs. Additionally, two or more individuals can be distinguished from each other by decomposing the Doppler signal into contributions of individuals in a polar domain. Consequently, a see-through-wall imaging system is constructed with the proposed SIL radar to position different individuals concealed behind a wall.","Voltage-controlled oscillators,
Radar antennas,
Radar imaging,
Radar detection,
Doppler radar,
Radar tracking"
A Finite-State Machine for Accommodating Unexpected Large Ground-Height Variations in Bipedal Robot Walking,"This paper presents a feedback controller that allows MABEL, which is a kneed planar bipedal robot with 1-m-long legs, to accommodate terrain that presents large unexpected increases and decreases in height. The robot is provided no information regarding where the change in terrain height occurs and by how much. A finite-state machine is designed that manages transitions among controllers for flat-ground walking, stepping-up and -down, and a trip reflex. If the robot completes a step, the depth of a step-down or the height of a step-up can be immediately estimated at impact from the lengths of the legs and the angles of the robot’s joints. The change in height can be used to invoke a proper control response. On the other hand, if the swing leg impacts an obstacle during a step, or has a premature impact with the ground, a trip reflex is triggered on the basis of specially designed contact switches on the robot’s shins, contact switches at the end of each leg, and the current configuration of the robot. The design of each control mode and the transition conditions among them are presented. This paper concludes with experimental results of MABEL (blindly) accommodating various types of platforms, including ascent of a 12.5-cm-high platform, stepping-off an 18.5-cm-high platform, and walking over a platform with multiple ascending and descending steps.",
Almost optimal virtual machine placement for traffic intense data centers,"The recent growing popularity of cloud-based solutions and the variety of new applications present new challenges for cloud management and resource utilization. In this paper we concentrate on the networking aspect and consider the placement problem of virtual machines (VMs) of applications with intense bandwidth requirements. Optimizing the available network bandwidth is far more complex than optimizing resources like memory or CPU, since every network link may be used by many physical hosts and thus by the VMs residing in these hosts. We focus on maximizing the benefit from the overall communication sent by the VMs to a single designated point in the data center (called the root). This is the typical case when considering a storage area network of applications with intense storage requirements. We formulate a bandwidth-constrained VM placement optimization problem that models this setting. This problem is NP hard, and we present a polynomial-time constant approximation algorithm for its most general version, in which hosts are connected to the root by a general network graph. For more practical cases, in which the network topology is a tree and the revenue is a simple function of the allocated bandwidth, we present improved approximation algorithms that are more efficient in terms of running time. We evaluate the expected performance of our proposed algorithms through a simulation study over traces from a real production data center, providing strong indications to the superiority of our proposed solutions.",
Context-Aware and Energy-Driven Route Optimization for Fully Electric Vehicles via Crowdsourcing,"Route planning for fully electric vehicles (FEVs) must take energy efficiency into account due to limited battery capacity and time-consuming recharging. In addition, the planning algorithm should allow for negative energy costs in the road network due to regenerative braking, which is a unique feature of FEVs. In this paper, we propose a framework for energy-driven and context-aware route planning for FEVs. It has two novel aspects: 1) It is context aware, i.e., the framework has access to real-time traffic data for routing cost estimation; and it is energy driven, i.e., both time and energy efficiency are accounted for; which implies a biobjective nature of the optimization. In addition, in the case of insufficient energy on board, an optimal detour via recharge points is computed. Our main contributions to address these issues can be highlighted as follows: A vehicle-to-vehicle (V2V) communication protocol is proposed to realize the context awareness, and we replace the original biobjective form of optimality with two single-objective forms and propose a constrained A* ( CA*) algorithm to find the solutions. The algorithm maintains a Pareto front while it confines its search by energy constraints. The best recharging detour can be also found using the algorithm. We first compared the performance of the CA* algorithm with other algorithms. We then evaluate the impact of the context awareness on road traffic by simulations using a realistic road network regarding different forms of optimality. Finally, we show that the CA* algorithm can effectively produce optimal recharging detours.","vehicular ad hoc networks,
battery powered vehicles,
constraint handling,
costing,
energy conservation,
Pareto optimisation,
protocols,
regenerative braking,
road traffic,
traffic engineering computing,
ubiquitous computing,
vehicle routing"
Robust Hybrid Beamforming with Phased Antenna Arrays for Downlink SDMA in Indoor 60 GHz Channels,"A hybrid architecture is presented for downlink beamforming (BF) with phased antenna arrays (PAA) in indoor 60 GHz spatial division multiple access (SDMA) channels. To manage the multiple access and inter-symbol interferences (MAI/ISI) encountered in SDMA with limited feedbacks, a cost-effective time-domain hybrid BF (HBF) method is presented to exploit the directivity provided by PAA in radio frequency (RF) beam patterns and the spatial diversity offered by multiple baseband processing modules. To maintain signal qualities under unpredictable MAI/ISI in wireless multimedia streaming to which indoor 60 GHz radio mainly applies, robust beamformers are designed to maintain the signal to interference-plus-noise ratio (SINR) for each user with minimum total transmit power. The percentages in which the target SINRs can be satisfied with the proposed HBF schemes are found sensitive to uncertainties in the phase shifters of PAA. Two kinds of robust formulations are thus proposed to jointly combat the MAI, ISI and phase uncertainties. Robust beamformers with semi closed-form expressions can be obtained with a nonlinear kind of them, whose SINR satisfaction ratio can attain 80% or more by extensive simulations in an indoor two-user 60 GHz environment if RF beam patterns of the users do not highly overlap in space.","Multiaccess communication,
Robustness,
Phased arrays,
Interference,
Phase shifters,
Array signal processing"
Automatic detection of performance deviations in the load testing of Large Scale Systems,"Load testing is one of the means for evaluating the performance of Large Scale Systems (LSS). At the end of a load test, performance analysts must analyze thousands of performance counters from hundreds of machines under test. These performance counters are measures of run-time system properties such as CPU utilization, Disk I/O, memory consumption, and network traffic. Analysts observe counters to find out if the system is meeting its Service Level Agreements (SLAs). In this paper, we present and evaluate one supervised and three unsupervised approaches to help performance analysts to 1) more effectively compare load tests in order to detect performance deviations which may lead to SLA violations, and 2) to provide them with a smaller and manageable set of important performance counters to assist in root-cause analysis of the detected deviations. Our case study is based on load test data obtained from both a large scale industrial system and an open source benchmark application. The case study shows, that our wrapper-based supervised approach, which uses a search-based technique to find the best subset of performance counters and a logistic regression model for deviation prediction, can provide up to 89% reduction in the set of performance counters while detecting performance deviations with few false positives (i.e., 95% average precision). The study also shows that the supervised approach is more stable and effective than the unsupervised approaches but it has more overhead due to its semi-automated training phase.",
Space Transformation for Understanding Group Movement,"We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract 'group space'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group's movement. Based on the individuals' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.","Trajectory,
Visual analytics,
Market research,
Behavioral science,
Data models"
A Printed Single-Layer UWB Monopole Antenna With Extended Ground Plane Stubs,"In this letter, a compact coplanar-waveguide-fed single-layer printed antenna with an ultrawideband (UWB) rectangular monopole radiator etched with a half-elliptical slot is presented. Collaborating with the UWB radiator, two symmetrical open-circuit stubs are extended from the ground plane to jointly achieve an ultrawideband impedance match with a compact size. The proposed antenna is fabricated and tested in an anechoic chamber, showing an ultrawide operating frequency range from 3.7 to 10.1 GHz with a quasi-omnidirectional gain from 2.0 to 7.3 dBi. With the advantages of a reduced size, an improved voltage standing wave ratio (VSWR), and a monolayer configuration without any back ground plane, the proposed antenna can be used in a wide range of UWB applications.",
Adaptive Spectrum Sensing Algorithm Under Different Primary User Utilizations,"Spectrum sensing is one of the key technologies to realize dynamic spectrum access in cognitive radio (CR) systems. In this letter, a novel adaptive threshold spectrum sensing algorithm is proposed to achieve an efficient trade-off between the detection and false alarm probability. The proposed adaptive threshold algorithm demonstrates a better spectrum efficiency for both primary users (PUs) and secondary users (SUs) in comparison with the conventional fixed one. A closed-from expression between PUs' spectrum utilization ratio and the proposed adaptive threshold is derived and simplified.","Signal to noise ratio,
Sensors,
Cognitive radio,
Algorithm design and analysis,
Adaptation models,
Heuristic algorithms"
New Insights in the Nanostructure and Defect States of Hydrogenated Amorphous Silicon Obtained by Annealing,"Temperature annealing is used as a tool to study the validity of network models for the nanostructure of hydrogenated amorphous silicon (a-Si:H) and its relation to defect states. The changes in the size of the dominant open volume deficiencies have been studied using Doppler broadening positron annihilation spectroscopy and Fourier transform infrared spectroscopy. It is shown that the dominant open volume deficiencies for as-deposited films are divacancies, which appear to agglomerate into larger open volume deficiencies up to 400 °C. Above this temperature, the largest open volume deficiencies are suggested to be released at the surface of the sample. Fourier transform photocurrent spectroscopy results indicate a dramatic increase in the density of various subgap defect state distributions during temperature annealing. In addition, at least four defect states have been identified. These findings cannot be directly explained by assuming solely dangling bonds as the dominant defects in a-Si:H. We discuss that a model based on an anisotropic disordered network with volume deficiencies does explain our findings better than the classical model based on a continuous random network with solely an isotropic distribution of coordination defects. The claim is made that next to dangling bonds not fully hydrogen-passivated vacancies are significantly contributing to the dominant defect states in a-Si:H.",
Prostate Histopathology: Learning Tissue Component Histograms for Cancer Detection and Classification,"Radical prostatectomy is performed on approximately 40% of men with organ-confined prostate cancer. Pathologic information obtained from the prostatectomy specimen provides important prognostic information and guides recommendations for adjuvant treatment. The current pathology protocol in most centers involves primarily qualitative assessment. In this paper, we describe and evaluate our system for automatic prostate cancer detection and grading on hematoxylin & eosin-stained tissue images. Our approach is intended to address the dual challenges of large data size and the need for high-level tissue information about the locations and grades of tumors. Our system uses two stages of AdaBoost-based classification. The first provides high-level tissue component labeling of a superpixel image partitioning. The second uses the tissue component labeling to provide a classification of cancer versus noncancer, and low-grade versus high-grade cancer. We evaluated our system using 991 sub-images extracted from digital pathology images of 50 whole-mount tissue sections from 15 prostatectomy patients. We measured accuracies of 90% and 85% for the cancer versus noncancer and high-grade versus low-grade classification tasks, respectively. This system represents a first step toward automated cancer quantification on prostate digital histopathology imaging, which could pave the way for more accurately informed postprostatectomy patient care.","Accuracy,
Histograms,
Prostate cancer,
Glands,
Pathology,
Labeling"
RWCap: A Floating Random Walk Solver for 3-D Capacitance Extraction of Very-Large-Scale Integration Interconnects,"A floating random walk (FRW) solver, called RWCap, is presented for the capacitance extraction of very-large-scale integration (VLSI) interconnects. An approach, including the numerical characterization of the cross-interface transition probability and weight value, is proposed to accelerate the extraction of structures with multiple dielectric layers. A comprehensive variance reduction scheme based on the importance sampling and stratified sampling is proposed to improve the convergence rate of the FRW algorithm. Finally, the space management technique using an octree data structure and the parallel computing technique are presented to further improve the efficiency. Numerical experiments are carried out with the test cases generated under the 180 and 45-nm process technologies. They demonstrate that the proposed multidielectric FRW algorithm achieves up to 160× speedup over the FRW algorithm using spherical transition domains to cross dielectric interface, with very small memory overhead. The variance reduction techniques further bring 3× or more speedup without memory overhead and the loss of accuracy. The RWCap also outperforms other existing FRW algorithm and fast boundary element method solvers in terms of computational time or scalability. The experiments on an 8-core CPU machine show that the parallel RWCap is over 6× faster than its serial-computing version.","Dielectrics,
Capacitance,
Green's function methods,
Conductors,
Frequency division multiplexing,
Very large scale integration,
Algorithm design and analysis"
Blind Color Decomposition of Histological Images,"Cancer diagnosis is based on visual examination under a microscope of tissue sections from biopsies. But whereas pathologists rely on tissue stains to identify morphological features, automated tissue recognition using color is fraught with problems that stem from image intensity variations due to variations in tissue preparation, variations in spectral signatures of the stained tissue, spectral overlap and spatial aliasing in acquisition, and noise at image acquisition. We present a blind method for color decomposition of histological images. The method decouples intensity from color information and bases the decomposition only on the tissue absorption characteristics of each stain. By modeling the charge-coupled device sensor noise, we improve the method accuracy. We extend current linear decomposition methods to include stained tissues where one spectral signature cannot be separated from all combinations of the other tissues' spectral signatures. We demonstrate both qualitatively and quantitatively that our method results in more accurate decompositions than methods based on non-negative matrix factorization and independent component analysis. The result is one density map for each stained tissue type that classifies portions of pixels into the correct stained tissue allowing accurate identification of morphological features that may be linked to cancer.","Image color analysis,
Colored noise,
Microscopy,
Absorption,
Vectors,
Educational institutions"
Rapid Feedforward Computation by Temporal Encoding and Learning With Spiking Neurons,"Primates perform remarkably well in cognitive tasks such as pattern recognition. Motivated by recent findings in biological systems, a unified and consistent feedforward system network with a proper encoding scheme and supervised temporal rules is built for solving the pattern recognition task. The temporal rules used for processing precise spiking patterns have recently emerged as ways of emulating the brain's computation from its anatomy and physiology. Most of these rules could be used for recognizing different spatiotemporal patterns. However, there arises the question of whether these temporal rules could be used to recognize real-world stimuli such as images. Furthermore, how the information is represented in the brain still remains unclear. To tackle these problems, a proper encoding method and a unified computational model with consistent and efficient learning rule are proposed. Through encoding, external stimuli are converted into sparse representations, which also have properties of invariance. These temporal patterns are then learned through biologically derived algorithms in the learning layer, followed by the final decision presented through the readout layer. The performance of the model with images of digits from the MNIST database is presented. The results show that the proposed model is capable of recognizing images correctly with a performance comparable to that of current benchmark algorithms. The results also suggest a plausibility proof for a class of feedforward models of rapid and robust recognition in the brain.",
Efficient Method for Content Reconstruction With Self-Embedding,"This paper presents a new model of the content reconstruction problem in self-embedding systems, based on an erasure communication channel. We explain why such a model is a good fit for this problem, and how it can be practically implemented with the use of digital fountain codes. The proposed method is based on an alternative approach to spreading the reference information over the whole image, which has recently been shown to be of critical importance in the application at hand. Our paper presents a theoretical analysis of the inherent restoration trade-offs. We analytically derive formulas for the reconstruction success bounds, and validate them experimentally with Monte Carlo simulations and a reference image authentication system. We perform an exhaustive reconstruction quality assessment, where the presented reference scheme is compared to five state-of-the-art alternatives in a common evaluation scenario. Our paper leads to important insights on how self-embedding schemes should be constructed to achieve optimal performance. The reference authentication system designed according to the presented principles allows for high-quality reconstruction, regardless of the amount of the tampered content. The average reconstruction quality, measured on 10000 natural images is 37 dB, and is achievable even when 50% of the image area becomes tampered.",
On the Method of Logarithmic Cumulants for Parametric Probability Density Function Estimation,"Parameter estimation of probability density functions is one of the major steps in the area of statistical image and signal processing. In this paper we explore several properties and limitations of the recently proposed method of logarithmic cumulants (MoLC) parameter estimation approach which is an alternative to the classical maximum likelihood (ML) and method of moments (MoM) approaches. We derive the general sufficient condition for a strong consistency of the MoLC estimates which represents an important asymptotic property of any statistical estimator. This result enables the demonstration of the strong consistency of MoLC estimates for a selection of widely used distribution families originating from (but not restricted to) synthetic aperture radar image processing. We then derive the analytical conditions of applicability of MoLC to samples for the distribution families in our selection. Finally, we conduct various synthetic and real data experiments to assess the comparative properties, applicability and small sample performance of MoLC notably for the generalized gamma and K families of distributions. Supervised image classification experiments are considered for medical ultrasound and remote-sensing SAR imagery. The obtained results suggest that MoLC is a feasible and computationally fast yet not universally applicable alternative to MoM. MoLC becomes especially useful when the direct ML approach turns out to be unfeasible.","method of moments,
gamma distribution,
image classification,
image processing,
maximum likelihood estimation"
Knowledge-Leverage-Based Fuzzy System and Its Modeling,"The classical fuzzy system modeling methods only consider the current scene where the training data are assumed fully collectable. However, if the available data from that scene are insufficient, the fuzzy systems trained will suffer from weak generalization for the modeling task in this scene. In order to overcome this problem, a fuzzy system with knowledge-leverage capability, which is known as a knowledge-leverage-based fuzzy system (KL-FS), is proposed in this paper. The KL-FS not only makes full use of the data from the current scene in the learning procedure but can effectively make leverage on the existing knowledge from the reference scene, e.g., the parameters of a fuzzy system obtained from a reference scene, as well. Specifically, a knowledge-leverage-based Mamdani-Larsen-type fuzzy system (KL-ML-FS) is proposed by using the reduced set density estimation technique integrating with the corresponding knowledge-leverage mechanism. The new fuzzy system modeling technique has been verified by experiments on synthetic and real-world datasets, where KL-ML-FS has better performance and adaptability than the traditional fuzzy modeling methods in scenarios with insufficient data.",
Image Feature Representation of the Subband Power Distribution for Robust Sound Event Classification,"The ability to automatically recognize a wide range of sound events in real-world conditions is an important part of applications such as acoustic surveillance and machine hearing. Our approach takes inspiration from both audio and image processing fields, and is based on transforming the sound into a two-dimensional representation, then extracting an image feature for classification. This provided the motivation for our previous work on the spectrogram image feature (SIF). In this paper, we propose a novel method to improve the sound event classification performance in severe mismatched noise conditions. This is based on the subband power distribution (SPD) image - a novel two-dimensional representation that characterizes the spectral power distribution over time in each frequency subband. Here, the high-powered reliable elements of the spectrogram are transformed to a localized region of the SPD, hence can be easily separated from the noise. We then extract an image feature from the SPD, using the same approach as for the SIF, and develop a novel missing feature classification approach based on a nearest neighbor classifier (kNN). We carry out comprehensive experiments on a database of 50 environmental sound classes over a range of challenging noise conditions. The results demonstrate that the SPD-IF is both discriminative over the broad range of sound classes, and robust in severe non-stationary noise.","Feature extraction,
Noise,
Spectrogram,
Time frequency analysis,
Speech,
Robustness"
A Linear Support Higher-Order Tensor Machine for Classification,"There has been growing interest in developing more effective learning machines for tensor classification. At present, most of the existing learning machines, such as support tensor machine (STM), involve nonconvex optimization problems and need to resort to iterative techniques. Obviously, it is very time-consuming and may suffer from local minima. In order to overcome these two shortcomings, in this paper, we present a novel linear support higher-order tensor machine (SHTM) which integrates the merits of linear C-support vector machine (C-SVM) and tensor rank-one decomposition. Theoretically, SHTM is an extension of the linear C-SVM to tensor patterns. When the input patterns are vectors, SHTM degenerates into the standard C-SVM. A set of experiments is conducted on nine second-order face recognition datasets and three third-order gait recognition datasets to illustrate the performance of the proposed SHTM. The statistic test shows that compared with STM and C-SVM with the RBF kernel, SHTM provides significant performance gain in terms of test accuracy and training speed, especially in the case of higher-order tensors.",
Understanding How Adolescents with Autism Respond to Facial Expressions in Virtual Reality Environments,"Autism Spectrum Disorders (ASD) are characterized by atypical patterns of behaviors and impairments in social communication. Among the fundamental social impairments in the ASD population are challenges in appropriately recognizing and responding to facial expressions. Traditional intervention approaches often require intensive support and well-trained therapists to address core deficits, with many with ASD having tremendous difficulty accessing such care due to lack of available trained therapists as well as intervention costs. As a result, emerging technology such as virtual reality (VR) has the potential to offer useful technology-enabled intervention systems. In this paper, an innovative VR-based facial emotional expression presentation system was developed that allows monitoring of eye gaze and physiological signals related to emotion identification to explore new efficient therapeutic paradigms. A usability study of this new system involving ten adolescents with ASD and ten typically developing adolescents as a control group was performed. The eye tracking and physiological data were analyzed to determine intragroup and intergroup variations of gaze and physiological patterns. Performance data, eye tracking indices and physiological features indicated that there were differences in the way adolescents with ASD process and recognize emotional faces compared to their typically developing peers. These results will be used in the future for an online adaptive VR-based multimodal social interaction system to improve emotion recognition abilities of individuals with ASD.",
CSI Feedback Reduction for MIMO Interference Alignment,"Interference alignment (IA) is a linear precoding strategy that can achieve optimal capacity scaling at high SNR in interference networks. Most of the existing IA designs require full channel state information (CSI) at the transmitters, which induces a huge CSI signaling cost. Hence it is desirable to improve the feedback efficiency for IA and in this paper, we propose a novel IA scheme with a significantly reduced CSI feedback. To quantify the CSI feedback cost, we introduce a novel metric, namely the feedback dimension. This metric serves as a first-order measurement of CSI feedback overhead. Due to the partial CSI feedback constraint, conventional IA schemes can not be applied and hence, we develop a novel IA precoder/decorrelator design and establish new IA feasibility conditions. Via dynamic feedback profile design, the proposed IA scheme can also achieve a flexible tradeoff between the degree of freedom (DoF) requirements for data streams, the antenna resources and the CSI feedback cost. We show by analysis and simulations that the proposed scheme achieves substantial reductions of CSI feedback overhead under the same DoF requirement in MIMO interference networks.","wireless channels,
MIMO communication,
radiofrequency interference"
Tracking deformable objects with point clouds,"We introduce an algorithm for tracking deformable objects from a sequence of point clouds. The proposed tracking algorithm is based on a probabilistic generative model that incorporates observations of the point cloud and the physical properties of the tracked object and its environment. We propose a modified expectation maximization algorithm to perform maximum a posteriori estimation to update the state estimate at each time step. Our modification makes it practical to perform the inference through calls to a physics simulation engine. This is significant because (i) it allows for the use of highly optimized physics simulation engines for the core computations of our tracking algorithm, and (ii) it makes it possible to naturally, and efficiently, account for physical constraints imposed by collisions, grasping actions, and material properties in the observation updates. Even in the presence of the relatively large occlusions that occur during manipulation tasks, our algorithm is able to robustly track a variety of types of deformable objects, including ones that are one-dimensional, such as ropes; two-dimensional, such as cloth; and three-dimensional, such as sponges. Our implementation can track these objects in real time.","Computational modeling,
Noise,
Probabilistic logic,
Inference algorithms,
Physics,
Solid modeling,
Mathematical model"
Weight Distribution of a Class of Cyclic Codes With Arbitrary Number of Zeros,"Cyclic codes have been widely used in digital communication systems and consumer electronics as they have efficient encoding and decoding algorithms. The weight distribution of cyclic codes has been an important topic of study for many years. It is in general hard to determine the weight distribution of linear codes. In this paper, a class of cyclic codes with any number of zeros is described and their weight distributions are determined.","Additives,
Linear codes,
Educational institutions,
Polynomials,
Indexes,
Generators,
Laboratories"
Silicon-Embedded Receiving Coil for High-Efficiency Wireless Power Transfer to Implantable Biomedical ICs,"In this letter, a silicon-embedded receiving coil is designed and fabricated for high-efficiency wireless power transfer to implantable biomedical ICs. The 4.5 mm × 4.5 mm embedded receiving coil achieved a large inductance of 4 μH and a high peak quality factor of 20 at 2.8 MHz. Measurement results of an inductive power link using the embedded receiving coil and a conventional printed-circuit-board transmitting coil (2 cm × 2 cm) demonstrated peak voltage gains of 0.84 and 0.24 and peak efficiency values of 30% and 4.3% for separation distances of 5 and 12 mm, respectively. This is the best reported wireless power transmission efficiency for separation distance similar to the implant chip size.","Coils,
Wireless communication,
Implants,
Silicon compounds,
Educational institutions,
Prototypes,
Inductors"
Matching-Area-Based Seam Carving for Video Retargeting,"This paper presents a video retargeting method considering both spatial and temporal coherence for resizing videos. Our algorithm is based on a novel matching-area-based temporal energy adjustment that allows per-frame seam carving to remove the optimal pixels to achieve spatially and temporally continuous resized videos. The temporal energy adjustment allows the seam to track the object it previously carved, and avoid carving the seam on different objects in two consecutive frames to achieve both spatial and temporal coherence. Our method outperforms other state-of-the-art retargeting systems, as demonstrated in the results and widely supported by the conducted user study.","Coherence,
Video sequences,
Cameras,
Optimization,
Indexes,
Dynamic programming,
Spatial coherence"
Evaluating the effectiveness of flipped classrooms for teaching CS1,"An alternative to the traditional classroom structure that has seen increased use in higher education is the flipped classroom. Flipping the classroom switches when assignments (e.g. homework) and knowledge transfer (e.g. lecture) occur. Flipped classrooms are getting popular in secondary and post-secondary teaching institutions as evidenced by the marked increase in the study, use, and application of the flipped pedagogy as it applies to learning and retention. The majority of the courses that have undergone this change use applied learning strategies and include a significant “learning-by-doing” component. The research in this area is skewed towards such courses and in general there are many considerations that educators ought to account for if they were to move to this form of teaching. Introductory courses in computer programming can appear to have all the elements needed to move to a flipped environment; however, initial observations from our research identify possible pitfalls with the assumption. In this work in progress the authors discuss early results and observations of implementing a flipped classroom to teach an introductory programming course (CS1) to engineering, engineering technology, and software engineering undergraduates.","Computational modeling,
Programming profession,
Computers,
Educational institutions,
Software engineering"
Analytical Approach to Wave Field Reconstruction Filtering in Spatio-Temporal Frequency Domain,"For transmission of a physical sound field in a large area, it is necessary to transform received signals of a microphone array into driving signals of a loudspeaker array to reproduce the sound field. We propose a method for transforming these signals by using planar or linear arrays of microphones and loudspeakers. A continuous transform equation is analytically derived based on the physical equation of wave propagation in the spatio-temporal frequency domain. By introducing spatial sampling, the uniquely determined transform filter, called a wave field reconstruction filter (WFR filter), is derived. Numerical simulations show that the WFR filter can achieve the same performance as that obtained using the conventional least squares (LS) method. However, since the proposed WFR filter is represented as a spatial convolution, it has many advantages in filter design, filter size, computational cost, and filter stability over the transform filter designed by the LS method.","Loudspeakers,
Microphones,
Arrays,
Equations,
Mathematical model,
Transforms,
Frequency domain analysis"
Privacy-Assured Outsourcing of Image Reconstruction Service in Cloud,"Large-scale image data sets are being exponentially generated today. Along with such data explosion is the fast-growing trend to outsource the image management systems to the cloud for its abundant computing resources and benefits. How to protect the sensitive data while enabling outsourced image services, however, becomes a major concern. To address these challenges, we propose outsourced image recovery service (OIRS), a novel outsourced image recovery service architecture, which exploits different domain technologies and takes security, efficiency, and design complexity into consideration from the very beginning of the service flow. Specifically, we choose to design OIRS under the compressed sensing framework, which is known for its simplicity of unifying the traditional sampling and compression for image acquisition. Data owners only need to outsource compressed image samples to cloud for reduced storage overhead. In addition, in OIRS, data users can harness the cloud to securely reconstruct images without revealing information from either the compressed image samples or the underlying image content. We start with the OIRS design for sparse data, which is the typical application scenario for compressed sensing, and then show its natural extension to the general data for meaningful tradeoffs between efficiency and accuracy. We thoroughly analyze the privacy-protection of OIRS and conduct extensive experiments to demonstrate the system effectiveness and efficiency. For completeness, we also discuss the expected performance speedup of OIRS through hardware built-in system design.",
Multimedia Event Detection Using A Classifier-Specific Intermediate Representation,"Multimedia event detection (MED) plays an important role in many applications such as video indexing and retrieval. Current event detection works mainly focus on sports and news event detection or abnormality detection in surveillance videos. Differently, our research aims to detect more complicated and generic events within a longer video sequence. In the past, researchers have proposed using intermediate concept classifiers with concept lexica to help understand the videos. Yet it is difficult to judge how many and what concepts would be sufficient for the particular video analysis task. Additionally, obtaining robust semantic concept classifiers requires a large number of positive training examples, which in turn has high human annotation cost. In this paper, we propose an approach that exploits the external concepts-based videos and event-based videos simultaneously to learn an intermediate representation from video features. Our algorithm integrates the classifier inference and latent intermediate representation into a joint framework. The joint optimization of the intermediate representation and the classifier makes them mutually beneficial and reciprocal. Effectively, the intermediate representation and the classifier are tightly correlated. The classifier dependent intermediate representation not only accurately reflects the task semantics but is also more suitable for the specific classifier. Thus we have created a discriminative semantic analysis framework based on a tightly coupled intermediate representation. Extensive experiments on multimedia event detection using real-world videos demonstrate the effectiveness of the proposed approach.",
Missing-Area Reconstruction in Multispectral Images Under a Compressive Sensing Perspective,"The intent of this paper is to propose new methods for the reconstruction of areas obscured by clouds. They are based on compressive sensing (CS) theory, which allows finding sparse signal representations in underdetermined linear equation systems. In particular, two common CS solutions are adopted for our reconstruction problem: the basis pursuit and the orthogonal matching pursuit methods. A novel alternative CS solution is also proposed through a formulation within a multiobjective genetic optimization scheme. To illustrate the performances of the proposed methods, a thorough experimental analysis on FORMOsa SATellite-2 and Satellite Pour l'Observation de la Terre-5 multispectral images is reported and discussed. It includes a detailed simulation study that aims at assessing the accuracy of the methods in different qualitative and quantitative cloud-contamination conditions. Compared with state-of-the-art techniques for cloud removal, the proposed methods show a clear superiority, which makes them a promising tool in cleaning images in the presence of clouds.","Image reconstruction,
Clouds,
Dictionaries,
Biological cells,
Sociology,
Statistics,
Genetic algorithms"
Personalization and Evaluation of a Real-Time Depth-Based Full Body Tracker,"Reconstructing a three-dimensional representation of human motion in real-time constitutes an important research topic with applications in sports sciences, human-computer-interaction, and the movie industry. In this paper, we contribute with a robust algorithm for estimating a personalized human body model from just two sequentially captured depth images that is more accurate and runs an order of magnitude faster than the current state-of-the-art procedure. Then, we employ the estimated body model to track the pose in real-time from a stream of depth images using a tracking algorithm that combines local pose optimization and a stabilizing dataBase look-up. Together, this enables accurate pose tracking that is more accurate than previous approaches. As a further contribution, we evaluate and compare our algorithm to previous work on a comprehensive benchmark dataset containing more than 15 minutes of challenging motions. This dataset comprises calibrated marker-Based motion capture data, depth data, as well as ground truth tracking results and is publicly available for research purposes.","Shape,
Vectors,
Estimation,
Three-dimensional displays,
Tracking,
Optimization,
Computational modeling"
An Efficient Data-Driven Particle PHD Filter for Multitarget Tracking,"In this paper, we propose an efficient data-driven particle probability hypothesis density (PHD) filter for real-time multitarget tracking of nonlinear/non-Gaussian system in dense clutter environment. In specific, the input measurements are first classified into two sets, namely survival measurements and spontaneous birth measurements, after eliminating clutters by using existing historic state data of targets. Since most clutters do not participate in the complex weight computation of particle PHD filter, better real-time performance can be achieved. The tracking performance is also improved because the survival measurements are used for survival targets and the spontaneous birth measurements are used for spontaneous birth targets, resulting in less interference from each other and from clutters. Extensive simulations validate the improvement of both the real-time performance and tracking performance of the proposed data-driven particle PHD filter in comparison with the traditional particle PHD filter.",
The Impact of Rank Attack on Network Topology of Routing Protocol for Low-Power and Lossy Networks,"Routing protocol for low power and lossy networks (RPL) is the underlying routing protocol of 6LoWPAN, a core communication standard for the Internet of Things. RPL outperforms other wireless sensor and ad hoc routing protocols in quality of service (QoS), device management, and energy saving performance. The Rank concept in RPL serves multiple purposes, including route optimization, prevention of loops, and managing control overhead. In this paper, we analyze several different types of internal threats that are aimed at the Rank property and study their impact on the performance of the wireless sensor network. Our analysis raises the question of an RPL weakness, which is the lack of a monitoring parent in every node. In RPL, the child node only receives the parent information through control messages, but it cannot check the services that its parent provide hence it will follow a bad quality route if it has a malicious parent. Our results show that different types of the Rank attacks can be used to intentionally downgrade specific QoS parameters. This paper also reveals that attack in a high forwarding load area will have more impact on network performance than attack in other areas. The defenders can use the knowledge of such correlation between attack location and its impact to set higher security levels at particular positions by monitoring sensitive network parameters and detecting the anomalies.","wireless sensor networks,
computer network security,
Internet of Things,
quality of service,
routing protocols,
telecommunication network topology,
wireless LAN"
A high-performance Cantonese keyword search system,"We present a system for keyword search on Cantonese conversational telephony audio, collected for the IARPA Babel program, that achieves good performance by combining postings lists produced by diverse speech recognition systems from three different research groups. We describe the keyword search task, the data on which the work was done, four different speech recognition systems, and our approach to system combination for keyword search. We show that the combination of four systems outperforms the best single system by 7%, achieving an actual term-weighted value of 0.517.","Keyword search,
Speech recognition,
Training,
Acoustics,
Indexes,
Speech,
Decoding"
Representing and Retrieving Video Shots in Human-Centric Brain Imaging Space,"Meaningful representation and effective retrieval of video shots in a large-scale database has been a profound challenge for the image/video processing and computer vision communities. A great deal of effort has been devoted to the extraction of low-level visual features, such as color, shape, texture, and motion for characterizing and retrieving video shots. However, the accuracy of these feature descriptors is still far from satisfaction due to the well-known semantic gap. In order to alleviate the problem, this paper investigates a novel methodology of representing and retrieving video shots using human-centric high-level features derived in brain imaging space (BIS) where brain responses to natural stimulus of video watching can be explored and interpreted. At first, our recently developed dense individualized and common connectivity-based cortical landmarks (DICCCOL) system is employed to locate large-scale functional brain networks and their regions of interests (ROIs) that are involved in the comprehension of video stimulus. Then, functional connectivities between various functional ROI pairs are utilized as BIS features to characterize the brain's comprehension of video semantics. Then an effective feature selection procedure is applied to learn the most relevant features while removing redundancy, which results in the formation of the final BIS features. Afterwards, a mapping from low-level visual features to high-level semantic features in the BIS is built via the Gaussian process regression (GPR) algorithm, and a manifold structure is then inferred, in which video key frames are represented by the mapped feature vectors in the BIS. Finally, the manifold-ranking algorithm concerning the relationship among all data is applied to measure the similarity between key frames of video shots. Experimental results on the TRECVID 2005 dataset demonstrate the superiority of the proposed work in comparison with traditional methods.","video retrieval,
biomedical MRI,
brain,
cognition,
neurophysiology"
Accurate Ego-Vehicle Global Localization at Intersections Through Alignment of Visual Data With Digital Map,"This paper proposes a method for achieving improved ego-vehicle global localization with respect to an approaching intersection, which is based on the alignment of visual landmarks perceived by the on-board visual system, with the information from a proposed extended digital map (EDM). The visual system relies on a stereovision system that provides a detailed 3-D description of the environment, including road landmark information (lateral lane delimiters, painted traffic signs, curbs, and stop lines) and dynamic environment information (other vehicles). An EDM is proposed, which enriches the standard map information with a detailed description of the intersection required for current lane identification, landmark alignment, and ego-vehicle accurate global localization. A novel approach for lane-delimiter classification, which is necessary for the lane identification, is also presented. An original solution for identifying the current lane, combining visual and map information with the help of a Bayesian network (BN), is proposed. Extensive experiments have been performed, and the results are evaluated with a Global Navigation Satellite System of high accuracy (2 cm). The achieved global localization accuracy is of submeter level, depending on the performance of the stereovision system.","Vehicles,
Visualization,
Roads,
Global Positioning System,
Asphalt,
Gray-scale,
Global Navigation Satellite Systems"
Mixture contrast limited adaptive histogram equalization for underwater image enhancement,"Within the last decades, improving the quality of an underwater image has received considerable attention due to poor visibility of the image which is caused by physical properties of the water medium. This paper presents a new method called mixture Contrast Limited Adaptive Histogram Equalization (CLAHE) color models that specifically developed for underwater image enhancement. The method operates CLAHE on RGB and HSV color models and both results are combined together using Euclidean norm. The underwater images used in this study were taken from Redang Island and Bidong Island in Terengganu, Malaysia. Experimental results show that the proposed approach significantly improves the visual quality of underwater images by enhancing contrast, as well as reducing noise and artifacts.","Image color analysis,
Histograms,
PSNR,
Adaptive equalizers,
Colored noise,
Color"
Reduced and Fixed-Complexity Variants of the LLL Algorithm for Communications,"The Lenstra-Lenstra-Lovász (LLL) algorithm is a popular lattice reduction algorithm in communications. In this paper, variants of the LLL algorithm with either reduced or fixed complexity are proposed and analyzed. Specifically, the use of effective LLL reduction for lattice decoding is presented, where size reduction is only performed for pairs of consecutive basis vectors. Its average complexity (measured by the number of floating-point operations and averaged over i.i.d. standard normal lattice bases) is shown to be O(n^3 log n), where n is the lattice dimension. This average complexity is an order lower than previously thought. To address the issue of variable complexity of the LLL algorithm, two fixed-complexity approximations are proposed. One is fixed-complexity effective LLL, for which the first vector of the basis is proven to be bounded in length; the other is fixed-complexity LLL with deep insertion, which is shown to be closely related to the well known V-BLAST algorithm. Such fixed-complexity structures are much desirable in hardware implementation since they allow straightforward constant-throughput implementation.",
A Wireless Robot for Networked Laparoscopy,"State-of-the-art laparoscopes for minimally invasive abdominal surgery are encumbered by cabling for power, video, and light sources. Although these laparoscopes provide good image quality, they interfere with surgical instruments, occupy a trocar port, require an assistant in the operating room to control the scope, have a very limited field of view, and are expensive. MARVEL is a wireless Miniature Anchored Robotic Videoscope for Expedited Laparoscopy that addresses these limitations by providing an inexpensive in vivo wireless camera module (CM) that eliminates the surgical-tool bottleneck experienced by surgeons in current laparoscopic endoscopic single-site (LESS) procedures. The MARVEL system includes1) multiple CMs that feature awirelessly controlled pan/tilt camera platform, which enable a full hemisphere field of view inside the abdominal cavity, wirelessly adjustable focus, and a multiwavelength illumination control system; 2) a master control module that provides a near-zero latency video wireless communications link, independent wireless control for multiple MARVEL CMs, digital zoom; and 3) a wireless human-machine interface that gives the surgeon full control over CM functionality. The research reported in this paper is the first step in developing a suite of semiautonomous wirelessly controlled and networked robotic cyberphysical devices to enable a paradigm shift in minimally invasive surgery and other domains such as wireless body area networks.","Wireless communication,
Solid modeling,
Light emitting diodes,
Lenses,
In vivo,
Cameras,
Wireless sensor networks"
Arithmetic Circuits: A Chasm at Depth Three,"We show that, over Q, if an n-variate polynomial of degree d = nO(1) is computable by an arithmetic circuit of size s (respectively by an arithmetic branching program of size s) then it can also be computed by a depth three circuit (i.e. a ΣΠΣ-circuit) of size exp(O(√(d log n log d log s))) (respectively of size exp(O(√(d log n log s))). In particular this yields a ΣΠΣ circuit of size exp(O(√(d log d))) computing the d × d determinant Detd. It also means that if we can prove a lower bound of exp(omega(√(d log d))) on the size of any ΣΠΣ-circuit computing the d × d permanent Permd then we get super polynomial lower bounds for the size of any arithmetic branching program computing Permd. We then give some further results pertaining to derandomizing polynomial identity testing and circuit lower bounds. The ΣΠΣ circuits that we construct have the property that (some of) the intermediate polynomials have degree much higher than d. Indeed such a counterintuitive construction is unavoidable - it is known that in any ΣΠΣ circuit C computing either Detd or Perm_d, if every multiplication gate has fanin at most d (or any constant multiple thereof) then C must have size at least exp(Ω(d)).",
Robust Texture Analysis Using Multi-Resolution Gray-Scale Invariant Features for Breast Sonographic Tumor Diagnosis,"Computer-aided diagnosis (CAD) systems in gray-scale breast ultrasound images have the potential to reduce unnecessary biopsy of breast masses. The purpose of our study is to develop a robust CAD system based on the texture analysis. First, gray-scale invariant features are extracted from ultrasound images via multi-resolution ranklet transform. Thus, one can apply linear support vector machines (SVMs) on the resulting gray-level co-occurrence matrix (GLCM)-based texture features for discriminating the benign and malignant masses. To verify the effectiveness and robustness of the proposed texture analysis, breast ultrasound images obtained from three different platforms are evaluated based on cross-platform training/testing and leave-one-out cross-validation (LOO-CV) schemes. We compare our proposed features with those extracted by wavelet transform in terms of receiver operating characteristic (ROC) analysis. The AUC values derived from the area under the curve for the three databases via ranklet transform are 0.918 (95% confidence interval [CI], 0.848 to 0.961), 0.943 (95% CI, 0.906 to 0.968), and 0.934 (95% CI, 0.883 to 0.961), respectively, while those via wavelet transform are 0.847 (95% CI, 0.762 to 0.910), 0.922 (95% CI, 0.878 to 0.958), and 0.867 (95% CI, 0.798 to 0.914), respectively. Experiments with cross-platform training/testing scheme between each database reveal that the diagnostic performance of our texture analysis using ranklet transform is less sensitive to the sonographic ultrasound platforms. Also, we adopt several co-occurrence statistics in terms of quantization levels and orientations (i.e., descriptor settings) for computing the co-occurrence matrices with 0.632+ bootstrap estimators to verify the use of the proposed texture analysis. These experiments suggest that the texture analysis using multi-resolution gray-scale invariant features via ranklet transform is useful for designing a robust CAD system.","Feature extraction,
Transforms,
Tumors,
Support vector machines,
Databases,
Gray-scale,
Training"
Robust mask-constrained linear array synthesis through aninterval-based particle SWARM optimisation,"An innovative strategy for the robust design of linear antenna arrays is presented. Being the array elements characterised by tolerance errors, the synthesis is aimed at determining the intervals of values fitting the user-defined mask constraints on the radiated power pattern. With reference to the upper and lower bounds of the power pattern analytically determined for given tolerances through interval analysis, the nominal excitations of the array elements are then optimised by means of a global stochastic optimiser suitably customised to deal with interval numbers. A set of numerical examples is reported to show the behaviour of the proposed method as well as to assess its potentials in dealing with the robust synthesis of pencil and shaped beams.","stochastic processes,
antenna radiation patterns,
linear antenna arrays,
particle swarm optimisation"
Compressive sensing based monitoring with vehicular networks,"Vehicles are becoming powerful mobile sensors, and vehicular networks provide a promising platform to support a wide range of existing large-scale monitoring applications such as road surface monitoring, and etc. In vehicular networks, inter-vehicle contacts are scarce resources for data delivery. This presents a major challenge for monitoring applications with vehicular networks. By analyzing a large dataset of taxi traces collected from around 2,600 taxis in Shanghai, China, we reveal that there is strong correlation with data readings on vehicles. Motivated by this important observation, we propose a compressive sensing based approach called CSM to monitor with vehicular networks. Two key issues must be addressed. First, there is an intrinsic tradeoff between communication cost and estimation accuracy. Second, guaranteed estimation accuracy should be provided over the highly dynamic network. To address the above issues, we first characterize the relationship between estimation error (12 error) and sparsity property of a dataset. Then, we determine two critical parameters: the minimum number of seeds and the minimum transmission hop length for compressive measurements in the network. The selection of the two parameters can reduce the communication cost while guaranteeing the required estimation accuracy. Extensive simulations based on real vehicular GPS traces collected in Shanghai, China have been performed and results demonstrate that CSM achieves much higher estimation accuracy at the same communication cost compared with other alternative schemes.","Vehicles,
Monitoring,
Compressed sensing,
Entropy,
Accuracy,
Estimation error"
NameFilter: Achieving fast name lookup with low memory cost via applying two-stage Bloom filters,"In this paper we design, implement and evaluate NameFilter, a two-stage Bloom filter-based scheme for Named Data Networking name lookup, in which the first stage determines the length of a name prefix, and the second stage looks up the prefix in a narrowed group of Bloom filters based on the results from the first stage. Moreover, we optimize the hash value calculation of name strings, as well as the data structure to store multiple Bloom filters, which significantly reduces the memory access times compared with that of non-optimized Bloom filters. We conduct extensive experiments on a commodity server to test NameFilter's throughput, memory occupation, name update as well as scalability. Evaluation results on a name prefix table with 10M entries show that our proposed scheme achieves lookup throughput of 37 million searches per second at low memory cost of only 234.27 MB, which means 12 times speedup and 77% memory savings compared to the traditional character trie structure. The results also demonstrate that NameFilter can achieve 3M per second incremental updates and exhibit good scalability to large-scale prefix tables.","IP networks,
Memory management,
Ports (Computers),
Throughput,
Instruction sets,
Scalability,
Internet"
A Cross-Layer Approach to Privacy-Preserving Authentication in WAVE-Enabled VANETs,"We present an anonymous authentication and verification scheme for the IEEE Wireless Access in Vehicular Communications (WAVE)-based vehicular ad hoc networks (VANETs). Our contribution includes vehicular message authentication and an efficient prioritized verification strategy for periodic road safety messages. A variation of elliptic curve digital signature algorithm (ECDSA) is used in combination with the identity-based (ID-based) signature, where current position information on a vehicle is utilized as the ID of the corresponding vehicle. This waives the need for a third-party public key certificate for message authentication in VANETs. A high-density road traffic condition poses a challenge for authentication of vehicular messages since the required verification time is often much longer than the average interarrival time. To mitigate the issue, messages of each traffic class are verified following the VANET's medium access control (MAC) layer priorities and the application relevance of individual safety messages. Performance analysis and simulation results have shown that our approach is secure, privacy preserving, scalable, and resource efficient.",
Approximate Constraint Satisfaction Requires Large LP Relaxations,"We prove super-polynomial lower bounds on the size of linear programming relaxations for approximation versions of constraint satisfaction problems. We show that for these problems, polynomial-sized linear programs are exactly as powerful as programs arising from a constant number of rounds of the Sherali-Adams hierarchy. In particular, any polynomial-sized linear program for MAX CUT has an integrality gap of 1/2 and any such linear program for MAX 3-SAT has an integrality gap of 7/8.",
Initial Friction Compensation Using Rheology-Based Rolling Friction Model in Fast and Precise Positioning,"This paper presents an initial friction compensation by a disturbance observer which is designed on the basis of a rolling friction model (RFM) for the fast and precise positioning of ball-screw-driven table systems. Rolling friction in the table drive mechanism behaves as a nonlinear elastic component in the microdisplacement region, deteriorating the fine settling performance. The effects of the rolling friction on the positioning, therefore, should be compensated to provide the desired control performance. In the compensator design, a feedback control with a disturbance observer allows the plant system to behave as a nominal one with a robust stability and compensates for the effects of nonlinear friction on the positioning performance. The disturbance observer, however, inherently includes an estimation delay at the starting motion due to low-pass filters and delay components. In this paper, therefore, an RFM is adopted as an initial value compensation of the disturbance observer to compensate for the initial friction behavior, providing the delay-free estimation. The proposed compensation method has been verified by numerical simulations and experiments using a prototype for industrial positioning devices.","Friction,
Observers,
Force,
Load modeling,
Vibrations,
Servomotors,
Mathematical model"
Determining the Intrinsic Dimension of a Hyperspectral Image Using Random Matrix Theory,"Determining the intrinsic dimension of a hyperspectral image is an important step in the spectral unmixing process and under- or overestimation of this number may lead to incorrect unmixing in unsupervised methods. In this paper, we discuss a new method for determining the intrinsic dimension using recent advances in random matrix theory. This method is entirely unsupervised, free from any user-determined parameters and allows spectrally correlated noise in the data. Robustness tests are run on synthetic data, to determine how the results were affected by noise levels, noise variability, noise approximation, and spectral characteristics of the end-members. Success rates are determined for many different synthetic images, and the method is tested on two pairs of real images, namely a Cuprite scene taken from Airborne Visible InfraRed Imaging Spectrometer (AVIRIS) and SpecTIR sensors, and a Lunar Lakes scene taken from AVIRIS and Hyperion, with good results.","Noise,
Eigenvalues and eigenfunctions,
Hyperspectral imaging,
Covariance matrix,
Vectors,
Approximation algorithms"
A Direct Masking Approach to Robust ASR,"Recently, much work has been devoted to the computation of binary masks for speech segregation. Conventional wisdom in the field of ASR holds that these binary masks cannot be used directly; the missing energy significantly affects the calculation of the cepstral features commonly used in ASR. We show that this commonly held belief may be a misconception; we demonstrate the effectiveness of directly using the masked data on both a small and large vocabulary dataset. In fact, this approach, which we term the direct masking approach, performs comparably to two previously proposed missing feature techniques. We also investigate the reasons why other researchers may have not come to this conclusion; variance normalization of the features is a significant factor in performance. This work suggests a much better baseline than unenhanced speech for future work in missing feature ASR.","Speech,
Cepstral analysis,
Speech recognition,
Hidden Markov models,
Reliability,
Vocabulary,
Vectors"
Competitive ratio analysis of online algorithms to minimize packet transmission time in energy harvesting communication system,"The design of online algorithms for minimizing packet transmission time is considered for single-user Gaussian channel and two-user Gaussian multiple access channel (GMAC) powered by natural renewable sources. The most general case of arbitrary energy arrivals is considered where neither the future energy arrival instants or amount, nor their distribution is known. The online algorithm adaptively changes the transmission rate according to the causal energy arrival information, so as to minimize the packet transmission time. For a minimization problem, the utility of an online algorithm is tested by finding its competitive ratio or competitiveness that is the maximum of the ratio of the gain of the online algorithm and the optimal offline algorithm over all input sequences. We derive a lower bound that shows that competitive ratio of any online algorithm is at least 1.38 for single-user Gaussian channel and 1.356 for GMAC. A `lazy' transmission policy that chooses its transmission power to minimize the transmission time assuming that no further energy arrivals are going to occur in future is shown to be strictly two-competitive for both the single-user Gaussian channel and the GMAC.","Algorithm design and analysis,
Energy harvesting,
Optimization,
Upper bound,
Channel models,
Indexes,
Communication systems"
Experimental study of Q-V Lissajous figures in nanosecond-pulse surface discharges,"A charge-voltage Lissajous figure is a standard method for the electrical diagnostics of DBD discharges. Based on a repetitive nanosecond-pulse generator, some experiments on surface discharges are carried out in open air. The effects of applied voltage amplitude, pulse repetition frequency, electrode gap spacing, and electrode width on the characteristics of the Lissajous figures are presented in this paper. Results show that two different kinds of typical discharge characteristics are observed, and the discharge characteristics vary between these two kinds of discharges when the discharge parameters change. The applied voltage has little effect on the shape of the Lissajous figure, and the total and barrier capacitances of actuator. Both transported charge and energy per pulse are proportional to the applied voltage amplitude. The applied voltage plays an important role in the discharge uniformity, intensity and length of surface plasmas. The pulse repetition frequency plays an important role in the energy and discharge intensity accumulation and has no effect the electrical parameters of surface discharges. The shape of the Lissajous figure gradually changes with the electrode gap and the transported charges proportionally decrease as the electrode gap increases. There is a transition gap spacing to obtain the maximum plasma energy and to achieve a relatively uniform plasma. The capacitances of the actuator, the transported charges and energy per pulse increase with the electrode width. The intensity of surface discharges is little affected by the electrode width, but the plasma uniformity tends to worsen with the increasing width. There is a corresponding relationship between the shape of the Lissajous figures and the uniformity of plasma distribution. The almond-like Lissajous figure is attained with a compromise between the electrode gap and width.","Discharges (electric),
Surface discharges,
Electrodes,
Plasmas,
Fault location,
Voltage measurement"
Activation Energies (E_{a}) of Failure Mechanisms in Advanced NAND Flash Cells for Different Generations and Cycling,"The conventional temperature-accelerated lifetime test method of NAND Flash memory does not follow the Arrhenius model, as various failure mechanisms occur concurrently. We completely separated three main failure mechanisms and extracted each activation energy (Ea) value in three generations (A, B, C) of advanced NAND Flash memory. We compared and analyzed each value of Ea of the three main mechanisms with different device generations and cycling times. The results confirmed that each failure mechanism follows the Arrhenius law. The extracted Ea values of the detrapping mechanism were almost the same (Ea ~ 1.0 eV) regardless of the generation or the cycling times because they are determined by the rate of change of the detrapping probability of each trapped electron according to the baking temperature, not the surface area or trap density. However, the Ea value of the trap-assisted tunneling (TAT) mechanism is dependent on the generation and cycling times. Both the dominant trap energy levels and the average distance between the traps in the oxide layer have a strong impact on the Eavalue of the TAT mechanism. The interface trap recovery mechanism has very small time-constant (τ), and its activation energy is very small (Ea ~ 0.2 eV).","Flash memory,
Electron traps,
Failure analysis,
Temperature measurement,
Lifetime estimation,
Energy states,
Temperature distribution"
OFDM Radar Space-Time Adaptive Processing by Exploiting Spatio-Temporal Sparsity,"We propose a sparsity-based space-time adaptive processing (STAP) algorithm to detect a slowly-moving target using an orthogonal frequency division multiplexing (OFDM) radar. We observe that the target and interference spectra are inherently sparse in the spatio-temporal domain. Hence, we exploit that sparsity to develop an efficient STAP technique that utilizes considerably lesser number of secondary data and produces an equivalent performance as the other existing STAP techniques. In addition, the use of an OFDM signal increases the frequency diversity of our system, as different scattering centers of a target resonate at different frequencies, and thus improves the target detectability. First, we formulate a realistic sparse-measurement model for an OFDM radar considering both the clutter and jammer as the interfering sources. Then, we apply a residual sparse-recovery technique based on the LASSO estimator to estimate the target and interference covariance matrices, and subsequently compute the optimal STAP-filter weights. Our numerical results demonstrate a comparative performance analysis of the proposed sparse-STAP algorithm with four other existing STAP methods. Furthermore, we discover that the OFDM-STAP filter-weights are adaptable to the frequency-variabilities of the target and interference responses, in addition to the spatio-temporal variabilities. Hence, by better utilizing the frequency variabilities, we propose an adaptive OFDM-waveform design technique, and consequently gain a significant amount of STAP-performance improvement.","OFDM,
Clutter,
Radar,
Jamming,
Vectors,
Covariance matrix"
Coordination of Multiagents Interacting Under Independent Position and Velocity Topologies,"We consider the coordination control for multiagent systems in a very general framework where the position and velocity interactions among agents are modeled by independent graphs. Different algorithms are proposed and analyzed for different settings, including the case without leaders and the case with a virtual leader under fixed position and velocity interaction topologies, as well as the case with a group velocity reference signal under switching velocity interaction. It is finally shown that the proposed algorithms are feasible in achieving the desired coordination behavior provided the interaction topologies satisfy the weakest possible connectivity conditions. Such conditions relate only to the structure of the interactions among agents while irrelevant to their magnitudes and thus are easy to verify. Rigorous convergence analysis is preformed based on a combined use of tools from algebraic graph theory, matrix analysis as well as the Lyapunov stability theory.","stability,
cooperative systems,
graph theory,
Lyapunov methods,
matrix algebra,
mobile robots,
multi-robot systems"
System combination and score normalization for spoken term detection,"Spoken content in languages of emerging importance needs to be searchable to provide access to the underlying information. In this paper, we investigate the problem of extending data fusion methodologies from Information Retrieval for Spoken Term Detection on low-resource languages in the framework of the IARPA Babel program. We describe a number of alternative methods improving keyword search performance. We apply these methods to Cantonese, a language that presents some new issues in terms of reduced resources and shorter query lengths. First, we show score normalization methodology that improves in average by 20% keyword search performance. Second, we show that properly combining the outputs of diverse ASR systems performs 14% better than the best normalized ASR system.","Hidden Markov models,
Data integration,
Speech,
Lattices,
Tuning,
Training,
Indexes"
Microfluidically Switched Frequency-Reconfigurable Slot Antennas,"This letter proposes a concept for frequency-reconfigurable slot antennas enabled by pressure-driven capacitive microfluidic switches. The switches are operated by pneumatically displacing a plug of eutectic gallium indium alloy (EGaIn) within an air-filled microchannel that traverses the slot orthogonally. Frequency reconfigurability is achieved by altering the displacement of conductive fluid within the channel, which reactively loads the slot. A transmission-line model is developed to capture the physical behavior of the fluid channel, and measurements are provided that show good agreement with the behavior of the model.","slot antenna,
Frequency-reconfigurable,
microfluidic switch"
Distributed data provenance for large-scale data-intensive computing,"It has become increasingly important to capture and understand the origins and derivation of data (its provenance). A key issue in evaluating the feasibility of data provenance is its performance, overheads, and scalability. In this paper, we explore the feasibility of a general metadata storage and management layer for parallel file systems, in which metadata includes both file operations and provenance metadata. We experimentally investigate the design optimality-whether provenance metadata should be loosely-coupled or tightly integrated with a file metadata storage systems. We consider two systems that have applied similar distributed concepts to metadata management, but focusing singularly on kind of metadata: (i) FusionFS, which implements a distributed file metadata management based on distributed hash tables, and (ii) SPADE, which uses a graph database to store audited provenance data and provides distributed module for querying provenance. Our results on a 32-node cluster show that FusionFS+SPADE is a promising prototype with negligible provenance overhead and has promise to scale to petascale and beyond. Furthermore, FusionFS with its own storage layer for provenance capture is able to scale up to 1 K nodes on BlueGene/P supercomputer.","Kernel,
Scalability,
Java,
Throughput"
Edge-SIFT: Discriminative Binary Descriptor for Scalable Partial-Duplicate Mobile Search,"As the basis of large-scale partial duplicate visual search on mobile devices, image local descriptor is expected to be discriminative, efficient, and compact. Our study shows that the popularly used histogram-based descriptors, such as scale invariant feature transform (SIFT) are not optimal for this task. This is mainly because histogram representation is relatively expensive to compute on mobile platforms and loses significant spatial clues, which are important for improving discriminative power and matching near-duplicate image patches. To address these issues, we propose to extract a novel binary local descriptor named Edge-SIFT from the binary edge maps of scale- and orientation-normalized image patches. By preserving both locations and orientations of edges and compressing the sparse binary edge maps with a boosting strategy, the final Edge-SIFT shows strong discriminative power with compact representation. Furthermore, we propose a fast similarity measurement and an indexing framework with flexible online verification. Hence, the Edge-SIFT allows an accurate and efficient image search and is ideal for computation sensitive scenarios such as a mobile image search. Experiments on a large-scale dataset manifest that the Edge-SIFT shows superior retrieval accuracy to Oriented BRIEF (ORB) and is superior to SIFT in the aspects of retrieval precision, efficiency, compactness, and transmission cost.",
Design and Implementation of a Web-Service-Based Public-Oriented Personalized Health Care Platform,"The use of information technology and management systems for the betterment of health care is more and more important and popular. However, existing efforts mainly focus on informatization of hospitals or medical institutions within the organizations, and few are directly oriented to the patients, their families, and other ordinary people. The strong demand for various medical and public health care services from customers calls for the creation of powerful individual-oriented personalized health care service systems. Service computing and related technologies can greatly help one in fulfilling this task. In this paper, we present PHISP: a Public-oriented Health care Information Service Platform, which is based on such technologies. It can support numerous health care tasks, provide individuals with many intelligent and personalized services, and support basic remote health care and guardianship. In order to realize the personalized customization and active recommendation of intelligent services for individuals, several key techniques for service composition are integrated, which can support branch and parallel control structures in the process models of composite services and are highlighted in this paper.",
Fourier Lucas-Kanade Algorithm,"In this paper, we propose a framework for both gradient descent image and object alignment in the Fourier domain. Our method centers upon the classical Lucas &#x0026; Kanade (LK) algorithm where we represent the source and template/model in the complex 2D Fourier domain rather than in the spatial 2D domain. We refer to our approach as the Fourier LK (FLK) algorithm. The FLK formulation is advantageous when one preprocesses the source image and template/model with a bank of filters (e.g., oriented edges, Gabor, etc.) as 1) it can handle substantial illumination variations, 2) the inefficient preprocessing filter bank step can be subsumed within the FLK algorithm as a sparse diagonal weighting matrix, 3) unlike traditional LK, the computational cost is invariant to the number of filters and as a result is far more efficient, and 4) this approach can be extended to the Inverse Compositional (IC) form of the LK algorithm where nearly all steps (including Fourier transform and filter bank preprocessing) can be precomputed, leading to an extremely efficient and robust approach to gradient descent image matching. Further, these computational savings translate to nonrigid object alignment tasks that are considered extensions of the LK algorithm, such as those found in Active Appearance Models (AAMs).","Active appearance model,
Jacobian matrices,
Integrated circuits,
Vectors,
Robustness,
Linear programming,
Lighting"
Kernelized Supervised Dictionary Learning,"In this paper, we propose supervised dictionary learning (SDL) by incorporating information on class labels into the learning of the dictionary. To this end, we propose to learn the dictionary in a space where the dependency between the signals and their corresponding labels is maximized. To maximize this dependency, the recently introduced Hilbert Schmidt independence criterion (HSIC) is used. One of the main advantages of this novel approach for SDL is that it can be easily kernelized by incorporating a kernel, particularly a data-dependent kernel such as normalized compression distance, into the formulation. The learned dictionary is compact and the proposed approach is fast. We show that it outperforms other unsupervised and supervised dictionary learning approaches in the literature, using real-world data.","Dictionaries,
Training,
Kernel,
Educational institutions,
Matching pursuit algorithms,
Image reconstruction,
Electronic mail"
iBOAT: Isolation-Based Online Anomalous Trajectory Detection,"Trajectories obtained from Global Position System (GPS)-enabled taxis grant us an opportunity not only to extract meaningful statistics, dynamics, and behaviors about certain urban road users but also to monitor adverse and/or malicious events. In this paper, we focus on the problem of detecting anomalous routes by comparing the latter against time-dependent historically “normal” routes. We propose an online method that is able to detect anomalous trajectories “on-the-fly” and to identify which parts of the trajectory are responsible for its anomalousness. Furthermore, we perform an in-depth analysis on around 43 800 anomalous trajectories that are detected out from the trajectories of 7600 taxis for a month, revealing that most of the anomalous trips are the result of conscious decisions of greedy taxi drivers to commit fraud. We evaluate our proposed isolation-based online anomalous trajectory (iBOAT) through extensive experiments on large-scale taxi data, and it shows that iBOAT achieves state-of-the-art performance, with a remarkable performance of the area under a curve (AUC) ≥ 0.99.","Trajectory,
Global Positioning System,
Cities and towns,
Indexes,
Vehicles,
Roads,
Accuracy"
Real-time Estimate of Body Kinematics During a Planar Squat Task Using a Single Inertial Measurement Unit,"This study aimed at the real-time estimation of the lower-limb joint and torso kinematics during a squat exercise, performed in the sagittal plane, using a single inertial measurement unit placed on the lower back. The human body was modeled with a 3-DOF planar chain. The planar IMU orientation and vertical displacement were estimated using one angular velocity and two acceleration components and a weighted Fourier linear combiner. The ankle, knee, and hip joint angles were thereafter obtained through a novel inverse kinematic module based on the use of a Jacobian pseudoinverse matrix and null-space decoupling. The aforementioned algorithms were validated on a humanoid robot for which the mechanical model used and the measured joint angles virtually exhibited no inaccuracies. Joint angles were estimated with a maximal error of 1.5°. The performance of the proposed analytical and experimental methodology was also assessed by conducting an experiment on human volunteers and by comparing the relevant results with those obtained through the more conventional photogrammetric approach. The joint angles provided by the two methods displayed differences equal to 3 ± 1°. These results, associated with the real-time capability of the method, open the door to future field applications in both rehabilitation and sport.","Joints,
Kinematics,
Biological system modeling,
Humans,
Sensors,
Robots,
Biomechanics"
A Weighted Dictionary Learning Model for Denoising Images Corrupted by Mixed Noise,"This paper proposes a general weighted l2-l0 norms energy minimization model to remove mixed noise such as Gaussian-Gaussian mixture, impulse noise, and Gaussian-impulse noise from the images. The approach is built upon maximum likelihood estimation framework and sparse representations over a trained dictionary. Rather than optimizing the likelihood functional derived from a mixture distribution, we present a new weighting data fidelity function, which has the same minimizer as the original likelihood functional but is much easier to optimize. The weighting function in the model can be determined by the algorithm itself, and it plays a role of noise detection in terms of the different estimated noise parameters. By incorporating the sparse regularization of small image patches, the proposed method can efficiently remove a variety of mixed or single noise while preserving the image textures well. In addition, a modified K-SVD algorithm is designed to address the weighted rank-one approximation. The experimental results demonstrate its better performance compared with some existing methods.","Dictionaries,
Noise reduction,
Gaussian noise,
Approximation algorithms,
Approximation methods,
Minimization"
A new analytical technique for designing provably efficient MapReduce schedulers,"With the rapid increase in size and number of jobs that are being processed in the MapReduce framework, efficiently scheduling jobs under this framework is becoming increasingly important. We consider the problem of minimizing the total flowtime of a sequence of jobs in the MapReduce framework, where the jobs arrive over time and need to be processed through both Map and Reduce procedures before leaving the system. We show that for this problem for non-preemptive tasks, no on-line algorithm can achieve a constant competitive ratio (defined as the ratio between the completion time of the online algorithm to the completion time of the optimal non-causal off-line algorithm). We then construct a slightly weaker metric of performance called the efficiency ratio. An online algorithm is said to achieve an efficiency ratio of γ when the flow-time incurred by that scheduler divided by the minimum flow-time achieved over all possible schedulers is almost surely less than or equal to γ. Under some weak assumptions, we then show a surprising property that, for the flow-time problem, any work-conserving scheduler has a constant efficiency ratio in both preemptive and nonpreemptive scenarios. More importantly, we are able to develop an online scheduler with a very small efficiency ratio (2), and through simulations we show that it outperforms the state-of-the-art schedulers.",
Development of an Approach Toward Comprehensive Identification of Hysteretic Dynamics in Piezoelectric Actuators,"This paper presents a comprehensive approach for the identification of the hysteresis and coupled nonhysteretic dynamics of piezoelectric actuators over a broad range of frequencies. The approach leverages on the special characteristics and distinctions of the hysteretic and nonhysteretic components to identify them in sequence, efficiently. The nonhysteretic dynamics is identified using square wave input signals. The creep dynamics is identified using an input signal with a long period. Conversely, electric and vibration dynamics are identified using an input signal with a small period. Moreover, the drift due to the creep is eliminated by employing its model inversion. The Preisach hysteresis is identified with specially designed harmonic input signals and sampling rules, which overcome the persistent excitation problem of hysteresis identification and improve the computational efficiency. Simulation and experiments are conducted to validate the effectiveness of the identification approach.","Hysteresis,
Creep,
Vibrations,
Harmonic analysis,
Broadband communication,
Density functional theory,
Couplings"
Human posture recognition using human skeleton provided by Kinect,"Human posture recognition is an attractive and challenging topic in computer vision because of its wide range of application. The coming of low cost device Kinect with its SDK gives us a possibility to resolve with ease some difficult problems encountered when working with conventional cameras. In this paper, we explore the capacity of using skeleton information provided by Kinect for human posture recognition in a context of a health monitoring framework. We conduct 7 different experiments with 4 types of features extracted from human skeleton. The obtained results show that this device can detect with high accuracy four interested postures (lying, sitting, standing, bending).","Joints,
Support vector machines,
Accuracy,
Feature extraction,
Cameras,
Databases"
Your Heart on Your Sleeve: Advances in Textile-Based Electronics Are Weaving Computers Right into the Clothes We Wear,"In this article, we give an overview of these items and discuss the associated technological trends. In the first section, the history of wearable electronics is summarized, with special emphasis on I/O systems and substrate and packaging issues. Interconnections for wearable devices are introduced in the second section; they can be split into wireline and wireless approaches, as well as permanent versus detachable connections. In the third section, wearable health care systems on a chip (SoCs) and systems on textiles (SoTs) are explained in connection with their appropriate applications. Since wearable health care applications are a good match with wearable technologies, most of the dedicated chips have been developed for health care monitoring, diagnosis, and treatment. A final section presents anumber of conclusions regarding wearable electronics.","Tutorials,
Wearable computers,
Medical services,
Biomedical equipment,
Human computer interfaces,
Mobile computing,
Graphical user interfaces,
Textiles"
Extended Master Equation Models for Molecular Communication Networks,"We consider molecular communication networks consisting of transmitters and receivers distributed in a fluidic medium. In such networks, a transmitter sends one or more signaling molecules, which are diffused over the medium, to the receiver to realize the communication. In order to be able to engineer synthetic molecular communication networks, mathematical models for these networks are required. This paper proposes a new stochastic model for molecular communication networks called reaction-diffusion master equation with exogenous input (RDMEX). The key idea behind RDMEX is to model the transmitters as time series of signaling molecule counts, while diffusion in the medium and chemical reactions at the receivers are modeled as Markov processes using master equation. An advantage of RDMEX is that it can readily be used to model molecular communication networks with multiple transmitters and receivers. For the case where the reaction kinetics at the receivers is linear, we show how RDMEX can be used to determine the mean and covariance of the receiver output signals, and derive closed-form expressions for the mean receiver output signal of the RDMEX model. These closed-form expressions reveal that the output signal of a receiver can be affected by the presence of other receivers. Numerical examples are provided to demonstrate the properties of the model.",
Cloud Paradigms and Practices for Computational and Data-Enabled Science and Engineering,"Clouds are rapidly joining high-performance computing (HPC) systems, clusters, and grids as viable platforms for scientific exploration and discovery. As a result, understanding application formulations and usage modes that are meaningful in such a hybrid infrastructure, and how application workflows can effectively utilize it, is critical. Here, three hybrid HPC/grid and cloud cyber infrastructure usage modes are explored: HPC in the Cloud, HPC plus Cloud, and HPC as a Service, presenting illustrative scenarios in each case and outlining benefits, limitations, and research challenges.",
"Active Contour-Based Visual Tracking by Integrating Colors, Shapes, and Motions","In this paper, we present a framework for active contour-based visual tracking using level sets. The main components of our framework include contour-based tracking initialization, color-based contour evolution, adaptive shape-based contour evolution for non-periodic motions, dynamic shape-based contour evolution for periodic motions, and the handling of abrupt motions. For the initialization of contour-based tracking, we develop an optical flow-based algorithm for automatically initializing contours at the first frame. For the color-based contour evolution, Markov random field theory is used to measure correlations between values of neighboring pixels for posterior probability estimation. For adaptive shape-based contour evolution, the global shape information and the local color information are combined to hierarchically evolve the contour, and a flexible shape updating model is constructed. For the dynamic shape-based contour evolution, a shape mode transition matrix is learnt to characterize the temporal correlations of object shapes. For the handling of abrupt motions, particle swarm optimization is adopted to capture the global motion which is applied to the contour in the current frame to produce an initial contour in the next frame.","Shape,
Tracking,
Level set,
Computer vision,
Image color analysis,
Image motion analysis,
Optical imaging"
Computational Study of Spin-Torque Oscillator Interactions for Non-Boolean Computing Applications,"We present a bottom-up approach for building non-Boolean signal processing devices from coupled spin-torque oscillators (STOs). We use micromagnetic simulations to study frequency-locking properties of electrically connected out-of plane magnetized STOs. After developing and verifying compact models for interacting STOs, we show that the frequency locking of STOs exhibits associative properties. Coupled STO networks therefore may be used as building blocks of non-Boolean pattern matching circuitry.",
A Framework for Uplink Intercell Interference Modeling with Channel-Based Scheduling,"This paper presents a novel framework for modeling the uplink intercell interference (ICI) in a multiuser cellular network. The proposed framework assists in quantifying the impact of various fading channel models and state-of-the-art scheduling schemes on the uplink ICI. Firstly, we derive a semi-analytical expression for the distribution of the location of the scheduled user in a given cell considering a wide range of scheduling schemes. Based on this, we derive the distribution and moment generating function (MGF) of the uplink ICI considering a single interfering cell. Consequently, we determine the MGF of the cumulative ICI observed from all interfering cells and derive explicit MGF expressions for three typical fading models. Finally, we utilize the obtained expressions to evaluate important network performance metrics such as the outage probability, ergodic capacity, and average fairness numerically. Monte-Carlo simulation results are provided to demonstrate the efficacy of the derived analytical expressions.",
Degrees of Freedom Region of the MIMO Interference Channel With Output Feedback and Delayed CSIT,"The two-user multiple-input multiple-output (MIMO) interference channel (IC) with arbitrary numbers of antennas at each terminal is considered and the degrees of freedom (DoF) region is characterized in the presence of noiseless channel output feedback from each receiver to its respective transmitter and availability of delayed channel state information at the transmitters (CSIT). It is shown that having output feedback and delayed CSIT can strictly enlarge the DoF region of the MIMO IC when compared to the case in which only delayed CSIT is present. The proposed coding schemes that achieve the corresponding DoF region with feedback and delayed CSIT utilize both resources, i.e., feedback and delayed CSIT in a nontrivial manner. It is also shown that the DoF region with local feedback and delayed CSIT is equal to the DoF region with global feedback and delayed CSIT, i.e., local feedback and delayed CSIT is equivalent to global feedback and delayed CSIT from the perspective of the DoF region. The converse is proved for a stronger setting in which the channels to the two receivers need not be statistically equivalent.","Receivers,
Output feedback,
Transmitters,
MIMO,
Encoding,
Interference,
Integrated circuits"
A 3-D Split Manufacturing Approach to Trustworthy System Development,"Securing the supply chain of integrated circuits is of utmost importance to computer security. In addition to counterfeit microelectronics, the theft or malicious modification of designs in the foundry can result in catastrophic damage to critical systems and large projects. In this letter, we describe a 3-D architecture that splits a design into two separate tiers: one tier that contains critical security functions is manufactured in a trusted foundry; another tier is manufactured in an unsecured foundry. We argue that a split manufacturing approach to hardware trust based on 3-D integration is viable and provides several advantages over other approaches.","Foundries,
Through-silicon vias,
Monitoring,
Cryptography,
Hardware,
Manufacturing"
A Systematic Approach for Ranking Distribution Systems Fault Location Algorithms and Eliminating False Estimates,"The need for distribution reliability enhancement in the age of smart grids requires reliable methods for locating faults on distribution systems leading to a faster service restoration and maintenance cost optimization. Given the numerous fault location methods, one faces the challenge of objectively evaluating and selecting the most proper method. In this paper, a two-step approach is proposed and discussed for ranking available fault location methods that takes into account application requirements and modeling limitations and uncertainties. The ranking method formulated as uncertainty analysis utilizes 2 n + 1 point estimation to calculate the statistical moments of the fault location estimation error. These moments plugged into the Chebyshev's inequality provide a basis for ranking the fault location method. The selected method may still suffer from multiple fault location estimations. To address this caveat, voltage sag characteristics reported by few intelligent electronic devices (IEDs) along the feeder are utilized. The number and location of these IEDs are determined through an optimal approach specifically formulated for this problem. The proposed two-step ranking methodology and the IED placement optimization approach were implemented on a simulated distribution system and their effectiveness was demonstrated through a few select scenarios and case studies.","Fault location,
Uncertainty,
Voltage fluctuations,
Circuit faults,
Estimation,
Substations,
Standards"
Action Recognition Using Multilevel Features and Latent Structural SVM,"We first propose a new low-level visual feature, called spatio-temporal context distribution feature of interest points, to describe human actions. Each action video is expressed as a set of relative XYT coordinates between pairwise interest points in a local region. We learn a global Gaussian mixture model (GMM) (referred to as a universal background model) using the relative coordinate features from all the training videos, and then we represent each video as the normalized parameters of a video-specific GMM adapted from the global GMM. In order to capture the spatio-temporal relationships at different levels, multiple GMMs are utilized to describe the context distributions of interest points over multiscale local regions. Motivated by the observation that some actions share similar motion patterns, we additionally propose a novel mid-level class correlation feature to capture the semantic correlations between different action classes. Each input action video is represented by a set of decision values obtained from the pre-learned classifiers of all the action classes, with each decision value measuring the likelihood that the input video belongs to the corresponding action class. Moreover, human actions are often associated with some specific natural environments and also exhibit high correlation with particular scene classes. It is therefore beneficial to utilize the contextual scene information for action recognition. In this paper, we build the high-level co-occurrence relationship between action classes and scene classes to discover the mutual contextual constraints between action and scene. By treating the scene class label as a latent variable, we propose to use the latent structural SVM (LSSVM) model to jointly capture the compatibility between multilevel action features (e.g., low-level visual context distribution feature and the corresponding mid-level class correlation feature) and action classes, the compatibility between multilevel scene features (i.e., SIFT feature and the corresponding class correlation feature) and scene classes, and the contextual relationship between action classes and scene classes. Extensive experiments on UCF Sports, YouTube and UCF50 datasets demonstrate the effectiveness of the proposed multilevel features and action-scene interaction based LSSVM model for human action recognition. Moreover, our method generally achieves higher recognition accuracy than other state-of-the-art methods on these datasets.","Context,
Visualization,
Feature extraction,
Correlation,
Vectors,
Humans,
Context modeling"
Remote Control Laboratory Using EJS Applets and TwinCAT Programmable Logic Controllers,"This paper presents a new methodology to develop remote laboratories for systems engineering and automation control courses, based on the combined use of TwinCAT, a laboratory Java server application, and Easy Java Simulations (EJS). The TwinCAT system is used to close the control loop for the selected plants by means of programmable logic controllers (PLCs) deployed in PCs with the TwinCAT run-time tool. EJS is used to develop the laboratory front-end applets that let teachers and students parametrize and observe the behavior of the PLCs from any computer. The laboratory Java server application establishes the connection between the EJS applets and the PLCs, fulfilling the TwinCAT connection requirements while ensuring an individualized access to each PLC. This paper also shows how the practical work in some undergraduate control courses at the Complutense University of Madrid, Spain, already uses the TwinCAT PLC + Java server + EJS applet strategy to provide real-time support to the controllers, remote individualized access to the experiments, and a user-friendly graphic controller interface for the students.","Libraries,
Servers,
Java,
Real time systems,
Remote laboratories,
Graphical user interfaces"
A Simple Carrier-Based Modulation for the SVM of the Matrix Converter,"Today, industry has not fully embraced the matrix converter solution. One important reason is its high control complexity. It is therefore relevant to propose a simpler but efficient modulation scheme, similar as three phase voltage source inverter modulators with the well-known symmetrical carrier-based ones. The modulation presented in this paper is equivalent to a particular space vector modulation (SVM) and takes into account harmonics and unbalanced input voltages, with the same maximum voltage transfer ratio (86%). The aim of this work is to propose a simple and general pulse-width-modulation method using carrier-based modulator for an easier matrix converter control. Furthermore, a simple duty cycle calculation method is used, based on a virtual matrix converter. Finally, simulations and experimentations are presented to validate this simple, original and efficient modulation concept equivalent to matrix converter SVM.","Matrix converters,
Support vector machines,
Vectors,
Electric potential,
Pulse width modulation,
Switches"
Resolve the virtual network embedding problem: A column generation approach,"In this paper, we study the virtual network embedding (VNE) problem in the network virtualization context, which aims at mapping the virtual network requests of the service providers (SPs) to the substrate networks managed by the infrastructure providers (InPs). Given the NP-Completeness of the VNE problem, prior approaches primarily rely on solving/relaxing the link-based Integer Linear Programming (ILP) formulations, which lead to either extensive computational time, or non-optimal solutions. In this paper, for the first time, we present a path-based model for the VNE problem, namely P-VNE. By analyzing the dual formulation of the P-VNE model, we propose a column generation process, with which an optimal solution to the VNE problem can be found efficiently (when embedded into a branch-and-bound framework).","Substrates,
Computational modeling,
Bandwidth,
Virtualization,
Internet,
Polynomials,
Indium phosphide"
Design of a Parallel Robot for Needle-Based Interventions on Small Animals,"In this paper, a novel 5-degrees-of-freedom robot for performing needle-based interventions on small animal subjects is presented. The robot can realize dexterous alignment of the needle using two parallel mechanisms, and has a syringe mechanism to insert needles to subjects. Operations on small animals require high accuracy positioning during needle insertion. The kinematic calibration procedure of the robot using an optical tracker as an external sensor is presented to enhance accuracy of the system. After the kinematic calibration, the positioning accuracy of the needle tip is measured as 0.4 mm RMS. The robot design is light weight, and has a motion bandwidth of 4 Hz. The robot can track reference trajectories with a closed-loop controller.",
Performance of Motor Imagery Brain-Computer Interface Based on Anodal Transcranial Direct Current Stimulation Modulation,"Voluntarily modulating neural activity plays a key role in brain-computer interface (BCI). In general, the self-regulated neural activation patterns are used in the current BCI systems involving the repetitive trainings with feedback for an attempt to achieve a high-quality control performance. With the limitation posed by the training procedure in most BCI studies, the present work aims to investigate whether directly modulating the neural activity by using an external method could facilitate the BCI control. We designed an experimental paradigm that combines anodal transcranial direct current stimulation (tDCS) with a motor imagery (MI)-based feedback EEG BCI system. Thirty-two young and healthy human subjects were randomly assigned to the real and sham stimulation groups to evaluate the effect of tDCS-induced EEG pattern changes on BCI classification accuracy. Results showed that the anodal tDCS obviously induces sensorimotor rhythm (SMR)-related event-related desynchronization (ERD) pattern changes in the upper-mu (10-14 Hz) and beta (14-26 Hz) rhythm components. Both the online and offline BCI classification results demonstrate that the enhancing ERD patterns could conditionally improve BCI performance. This pilot study suggests that the tDCS is a promising method to help the users to develop reliable BCI control strategy in a relatively short time.","Electrodes,
Electroencephalography,
DC motors,
Rhythm,
Band pass filters,
Training,
Classification algorithms"
Resource Allocation in Relay-Aided OFDM Cognitive Radio Networks,"In this paper, we investigate the resource allocation problem in a single-user relay-aided cognitive radio (CR) underlay network. Both the CR network and the primary network operate under the orthogonal frequency-division multiplexing (OFDM) scheme. Different from the conventional resource allocation problem, the relay node here is capable of performing subcarrier permutation over two hops such that the signal received over a particular subcarrier is forwarded via a different subcarrier. The objective is to maximize the throughput of the CR network subject to a limited power budget at the secondary source and the relay node and to interference constraints at the primary receiver. Optimization is performed under a unified framework where power allocation at the source node, power allocation at the relay node, and subcarrier pairing at the two hops are jointly optimized. The joint resource-allocation scheme yields an asymptotically optimal solution. We further design a suboptimal algorithm that sacrifices little on performance but could significantly reduce computational complexity. Finally, numerical examples are provided to corroborate the proposed studies.",
Characterization and Modeling of the Peripheral Cardiac Conduction System,"The development of biophysical models of the heart has the potential to get insights in the patho-physiology of the heart, which requires to accurately modeling anatomy and function. The electrical activation sequence of the ventricles depends strongly on the cardiac conduction system (CCS). Its morphology and function cannot be observed in vivo, and therefore data available come from histological studies. We present a review on data available of the peripheral CCS including new experiments. In order to build a realistic model of the CCS we designed a procedure to extract morphological characteristics of the CCS from stained calf tissue samples. A CCS model personalized with our measurements has been built using L-systems. The effect of key unknown parameters of the model in the electrical activation of the left ventricle has been analyzed. The CCS models generated share the main characteristics of observed stained Purkinje networks. The timing of the simulated electrical activation sequences were in the physiological range for CCS models that included enough density of PMJs. These results show that this approach is a potential methodology for collecting knowledge-domain data and build improved CCS models of the heart automatically.",
A Byzantine Attack Defender in Cognitive Radio Networks: The Conditional Frequency Check,"Security concerns are raised for collaborative spectrum sensing due to its vulnerabilities to the potential attacks from malicious secondary users. Most existing malicious user detection methods are reputation-based, which become incapable when the malicious users dominate the network. On the other hand, although Markovian models characterize the spectrum state behavior more precisely, there is a scarcity of malicious user detection methods which fully explore this feature. In this paper, a new malicious user detection method using two proposed conditional frequency check (CFC) statistics is developed under the Markovian model for the spectrum state. With the assistance of one trusted user, the proposed method can achieve high malicious user detection accuracy (≥ 95%) for arbitrary percentage of malicious users that may even be equipped with more advanced sensing devices, and can thus improve the collaborative spectrum sensing performance significantly. Simulation results are provided to verify the theoretical analysis and effectiveness of the proposed method.","Sensor fusion,
Approximation methods,
Markov processes,
Collaboration,
Computational modeling,
Hamming distance"
Gap Sense: Lightweight coordination of heterogeneous wireless devices,"Coordination of co-located wireless devices is a fundamental function/requirement for reducing interference. However, different devices cannot directly coordinate with one another as they often use incompatible modulation schemes. Even for the same type (e.g., WiFi) of devices, their coordination is infeasible when neighboring transmitters adopt different spectrum widths. Such an incompatibility between heterogeneous devices may severely degrade the network performance. In this paper, we introduce Gap Sense (GSense), a novel mechanism that can coordinate heterogeneous devices without modifying their PHYlayer modulation schemes or spectrum widths. GSense prepends legacy packets with a customized preamble, which piggy-backs information to enhance inter-device coordination. The preamble leverages the quiet period between signal pulses to convey such information, and can be detected by neighboring nodes even when they have incompatible PHY layers. We have implemented and evaluated GSense on a software radio platform, demonstrating its significance and utility in three popular protocols. GSense is shown to deliver coordination information with close to 100% accuracy within practical SNR regions. It can also reduce the energy consumption by around 44%, and the collision rate by more than 88% in networks of heterogeneous transmitters and receivers.","Receivers,
Signal to noise ratio,
IEEE 802.11 Standards,
Zigbee,
Radio transmitters,
Protocols,
Clocks"
Cost-Aware Cooperative Resource Provisioning for Heterogeneous Workloads in Data Centers,"Recent cost analysis shows that the server cost still dominates the total cost of high-scale data centers or cloud systems. In this paper, we argue for a new twist on the classical resource provisioning problem: heterogeneous workloads are a fact of life in large-scale data centers, and current resource provisioning solutions do not act upon this heterogeneity. Our contributions are threefold: first, we propose a cooperative resource provisioning solution, and take advantage of differences of heterogeneous workloads so as to decrease their peak resources consumption under competitive conditions; second, for four typical heterogeneous workloads: parallel batch jobs, web servers, search engines, and MapReduce jobs, we build an agile system PhoenixCloud that enables cooperative resource provisioning; and third, we perform a comprehensive evaluation for both real and synthetic workload traces. Our experiments show that our solution could save the server cost aggressively with respect to the noncooperative solutions that are widely used in state-of-the-practice hosting data centers or cloud systems: for example, EC2, which leverages the statistical multiplexing technique, or RightScale, which roughly implements the elastic resource provisioning technique proposed in related state-of-the-art work.",
Continuous Time Level Crossing Sampling ADC for Bio-Potential Recording Systems,"In this paper we present a fixed window level crossing sampling analog to digital convertor for bio-potential recording sensors. This is the first proposed and fully implemented fixed window level crossing ADC without local DACs and clocks. The circuit is designed to reduce data size, power, and silicon area in future wireless neurophysiological sensor systems. We built a testing system to measure bio-potential signals and used it to evaluate the performance of the circuit. The bio-potential amplifier offers a gain of 53 dB within a bandwidth of 200 Hz-20 kHz. The input-referred rms noise is 2.8 μV. In the asynchronous level crossing ADC, the minimum delta resolution is 4 mV. The input signal frequency of the ADC is up to 5 kHz. The system was fabricated using the AMI 0.5 μm CMOS process. The chip size is 1.5 mm by 1.5 mm. The power consumption of the 4-channel system from a 3.3 V supply is 118.8 μW in the static state and 501.6 μW with a 240 kS/s sampling rate. The conversion efficiency is 1.6 nJ/conversion.","Sensor arrays,
Clocks,
Noise,
Computational efficiency,
Signal resolution"
Part-of-speech tagging of program identifiers for improved text-based software engineering tools,"To aid program comprehension, programmers choose identifiers for methods, classes, fields and other program elements primarily by following naming conventions in software. These software “naming conventions” follow systematic patterns which can convey deep natural language clues that can be leveraged by software engineering tools. For example, they can be used to increase the accuracy of software search tools, improve the ability of program navigation tools to recommend related methods, and raise the accuracy of other program analyses. After splitting multi-word names into their component words, the next step to extracting accurate natural language information is tagging each word with its part of speech (POS) and then chunking the name into natural language phrases. State-of-theart approaches, most of which rely on “traditional POS taggers” trained on natural language documents, do not capture the syntactic structure of program elements. In this paper, we present a POS tagger and syntactic chunker for source code names that takes into account programmers' naming conventions to understand the regular, systematic ways a program element is named. We studied the naming conventions used in Object Oriented Programming and identified different grammatical constructions that characterize a large number of program identifiers. This study then informed the design of our POS tagger and chunker. Our evaluation results show a significant improvement in accuracy(11%-20%) of POS tagging of identifiers, over the current approaches. With this improved accuracy, both automated software engineering tools and developers will be able to better capture and understand the information available in code.",
Complexity Analysis and Algorithm Design for Advance Bandwidth Scheduling in Dedicated Networks,"An increasing number of high-performance networks provision dedicated channels through circuit switching or MPLS/GMPLS techniques to support large data transfer. The link bandwidths in such networks are typically shared by multiple users through advance reservation, resulting in varying bandwidth availability in future time. Developing efficient scheduling algorithms for advance bandwidth reservation has become a critical task to improve the utilization of network resources and meet the transport requirements of application users. We consider an exhaustive combination of different path and bandwidth constraints and formulate four types of advance bandwidth scheduling problems, with the same objective to minimize the data transfer end time for a given transfer request with a prespecified data size: fixed path with fixed bandwidth (FPFB); fixed path with variable bandwidth (FPVB); variable path with fixed bandwidth (VPFB); and variable path with variable bandwidth (VPVB). For VPFB and VPVB, we further consider two subcases where the path switching delay is negligible or nonnegligible. We propose an optimal algorithm for each of these scheduling problems except for FPVB and VPVB with nonnegligible path switching delay, which are proven to be NP-complete and nonapproximable, and then tackled by heuristics. The performance superiority of these heuristics is verified by extensive experimental results in a large set of simulated networks in comparison to optimal and greedy strategies.","Bandwidth,
Switches,
Optimal scheduling,
Complexity theory,
Scheduling,
Algorithm design and analysis,
Delay"
Compact Microstrip 3-dB Coupled-Line Ring and Branch-Line Hybrids With New Symmetric Equivalent Circuits,"New symmetric equivalent circuits are suggested for 90° and 270° transmission-line sections, with which compact coupled-line ring and branch-line hybrids can be designed and fabricated. For this purpose, firstly stepped-impedance transmission-line (SITL) sections, being equivalent to a uniform transmission-line section with arbitrary electrical lengths, are synthesized, and design formulas for the SITL sections are derived. Secondly, three types of equivalent circuits are introduced by combining the SITL sections with coupled-line Π-, modified Π-, or T-type, and are called stepped-impedance coupled-line Π-type (SCΠ ), stepped-impedance modified T-type (SMT), and stepped-impedance modified Π-type (SMΠ). The SCΠs are for 270° transmission-line sections, while both SMTs and SMΠs are for 90° transmission-line sections. Based on the suggested equivalent circuits, compact coupled-line ring and branch-line hybrids designed at 1 GHz are fabricated, and the measured bandwidth of the ring hybrid is 50% with 15-dB return loss. The measured results may be considered as excellent, reflecting their total transmission-line lengths of 183° and 111° for the ring and branch-line hybrids, respectively.","Equivalent circuits,
Impedance,
Structural rings,
Microstrip,
Bandwidth,
Integrated circuit modeling"
Resource pricing game in geo-distributed clouds,"Cloud computing enables larger classes of application service providers to distribute their services to world-wide users in multiple regions without their own private data centers. Heterogeneity and resource limitation of geo-graphically distributed cloud data centers impose application service providers to have incentives to optimize their computing resource usage while guaranteeing some level of quality of service. Recent studies proposed various techniques for optimization of computing resource usage from cloud users (or application service providers) perspective with little consideration of competition. In addition, optimization efforts of application service providers motivate cloud service providers owning multiple geo-distributed clouds to decide their computing resource prices considering their efforts. In this context, we formulate this problem for cloud service providers as a game of resource pricing in geo-distributed clouds. One of the main challenges in this problem is how to model the best responses of application service providers, given resource price information of clouds in non-overlapped regions. We propose a novel concave game to describe the quantity competition among application service providers reducing payment while guaranteeing fair service delay to end users. Furthermore, we optimize the prices of computing resources to converge to the equilibrium. In addition, we show several characteristics of the equilibrium point and discuss their implications to design computing resource markets for geo-distributed clouds.","Games,
Pricing,
Cloud computing,
Distributed databases,
Time factors,
Optimization,
Quality of service"
Flocking Multiple Microparticles With Automatically Controlled Optical Tweezers: Solutions and Experiments,"This paper presents an efficient approach to achieve microparticles flocking with robotics and optical tweezers technologies. All particles trapped by optical tweezers can be automatically moved toward a predefined region without collision. The main contribution of this paper lies in the proposal of several solutions to the flocking manipulation of microparticles in microenvironments. First, a simple flocking controller is proposed to generate the desired positions and velocities for particles' movement. Second, a velocity saturation method is implemented to prevent the desired velocities from exceeding a safe limit. Third, a two-layer control architecture is proposed for the motion control of optical tweezers. This architecture can help make many robotic manipulations achievable under microenvironments. The proposed approach with these solutions can be applied to many bioapplications especially in cell engineering and biomedicine. Experiments on yeast cells with a robot-tweezers system are finally performed to verify the effectiveness of the proposed approach.",
A Kernel-Based Target-Constrained Interference-Minimized Filter for Hyperspectral Sub-Pixel Target Detection,"The target-constrained interference-minimized filter (TCIMF) method has been successfully applied to various hyperspectral target detection applications. This paper presents a nonlinear version of TCIMF, called kernel-based TCIMF (KTCIMF), employing the kernel method to resolve the issue of nonlinear endmember mixing in hyperspectral images (HSI). Input data are implicitly mapped into a high-dimensional feature space, where it is assumed that target signals are more separable from background signals. Conventional TCIMF performs well in suppressing undesired signatures whose spectra are similar to that of the targets, thereby enhancing performance, and with less false alarms. KTCIMF not only takes into consideration the nonlinear endmember mixture but also fully exploits the other spectrally similar interference signatures. In this way, it is effective in suppressing both the background and those undesired signatures that may cause false alarms in traditional methods. Experimental results with both simulated and real hyperspectral image data confirm KTCIMF's performance with intimately mixed data. Compared with conventional kernel detectors, KTCIMF shows improved ROC curves and better separability between targets and backgrounds.","Kernel,
Detectors,
Object detection,
Hyperspectral imaging,
Vectors,
Eigenvalues and eigenfunctions"
Wireless Video Surveillance: A Survey,"A wireless video surveillance system consists of three major components: 1) the video capture and preprocessing; 2) the video compression and transmission in wireless sensor networks; and 3) the video analysis at the receiving end. A myriad of research works have been dedicated to this field due to its increasing popularity in surveillance applications. This survey provides a comprehensive overview of existing state-of-the-art technologies developed for wireless video surveillance, based on the in-depth analysis of the requirements and challenges in current systems. Specifically, the physical network infrastructure for video transmission over wireless channel is analyzed. The representative technologies for video capture and preliminary vision tasks are summarized. For video compression and transmission over the wireless networks, the ultimate goal is to maximize the received video quality under the resource limitation. This is also the main focus of this survey. We classify different schemes into categories including unequal error protection, error resilience, scalable video coding, distributed video coding, and cross-layer control. Cross-layer control proves to be a desirable measure for system-level optimal resource allocation. At the receiver's end, the received video is further processed for higher-level vision tasks, and the security and privacy issues in surveillance applications are also discussed.","Cameras,
Wireless sensor networks,
Wireless communication,
Communication system security,
Video surveillance,
Video compression"
"Automatically mining software-based, semantically-similar words from comment-code mappings","Many software development and maintenance tools involve matching between natural language words in different software artifacts (e.g., traceability) or between queries submitted by a user and software artifacts (e.g., code search). Because different people likely created the queries and various artifacts, the effectiveness of these tools is often improved by expanding queries and adding related words to textual artifact representations. Synonyms are particularly useful to overcome the mismatch in vocabularies, as well as other word relations that indicate semantic similarity. However, experience shows that many words are semantically similar in computer science situations, but not in typical natural language documents. In this paper, we present an automatic technique to mine semantically similar words, particularly in the software context. We leverage the role of leading comments for methods and programmer conventions in writing them. Our evaluation of our mined related comment-code word mappings that do not already occur in WordNet are indeed viewed as computer science, semantically-similar word pairs in high proportions.","Software,
Context,
Semantics,
Computer science,
Data mining,
Tagging,
Maintenance engineering"
Quantifying the Objective Cost of Uncertainty in Complex Dynamical Systems,"Real-world problems often involve complex systems that cannot be perfectly modeled or identified, and many engineering applications aim to design operators that can perform reliably in the presence of such uncertainty. In this paper, we propose a novel Bayesian framework for objective-based uncertainty quantification (UQ), which quantifies the uncertainty in a given system based on the expected increase of the operational cost that it induces. This measure of uncertainty, called MOCU (mean objective cost of uncertainty), provides a practical way of quantifying the effect of various types of system uncertainties on the operation of interest. Furthermore, the proposed UQ framework provides a general mathematical basis for designing robust operators, and it can be applied to diverse applications, including robust filtering, classification, and control. We demonstrate the utility and effectiveness of the proposed framework by applying it to the problem of robust structural intervention of gene regulatory networks, an important application in translational genomics.","Uncertainty,
Hidden Markov models,
Robustness,
Mathematical model,
Entropy,
Bayes methods,
Data models"
Stress detection from speech and Galvanic Skin Response signals,The problem of stress-management has been receiving an increasing attention in related research communities due to a wider recognition of potential problems caused by chronic stress and due to the recent developments of technologies providing non-intrusive ways of collecting continuously objective measurements to monitor person's stress level. Experimental studies have shown already that stress level can be judged based on the analysis of Galvanic Skin Response (GSR) and speech signals. In this paper we investigate how classification techniques can be used to automatically determine periods of acute stress relying on information contained in GSR and/or speech of a person.,
A Class of Uncontrollable Diffusively Coupled Multiagent Systems with Multichain Topologies,"We construct systematically a class of uncontrollable diffusively coupled multiagent systems with a single leader and multichain topologies. For studying the controllability of diffusively coupled multiagent systems, such identified uncontrollable systems serve as counterexamples that prove the need to modify the existing sufficient condition using graph partitioning characterization. The uncontrollability of the constructed multichain structures can be preserved when the structures are further augmented to get better connected. The paper also provides an algorithm to obtain the minimal leader-invariant relaxed equitable partition for the graph associated with any diffusively coupled multiagent system guided by a single leader.","Partitioning algorithms,
Multiagent systems,
Eigenvalues and eigenfunctions,
Controllability,
Topology,
Vectors"
Asymptotically Near-Optimal Planning With Probabilistic Roadmap Spanners,"Asymptotically optimal motion planners guarantee that solutions approach optimal as more iterations are performed. A recently proposed roadmap-based method, i.e., the \hbox{\tt PRM}^{*}
approach, provides this desirable property and minimizes the computational cost of generating the roadmap. Even for this method, however, the roadmap can be slow to construct and quickly grows too large for storage or fast online query resolution, especially for relatively high-dimensional instances. In graph theory, there are algorithms that produce sparse subgraphs, which are known as graph spanners, that guarantee near-optimal paths. This paper proposes different alternatives for interleaving graph spanners with the asymptotically optimal \hbox{\tt PRM}^{*}
algorithm. The first alternative follows a sequential approach, where a graph spanner algorithm is applied to the output roadmap of \hbox{\tt PRM}^{*}
. The second one is an incremental method, where certain edges are not considered during the construction of the roadmap as they are not necessary for a roadmap spanner. The result in both cases is an asymptotically near-optimal motion planning solution. Theoretical analysis and experiments performed on typical, geometric motion planning instances show that large reductions in construction time, roadmap density, and online query resolution time can be achieved with a small sacrifice of path quality through roadmap spanners.",
A Hierarchical Approach to Change Detection in Very High Resolution SAR Images for Surveillance Applications,"The availability of very high resolution (VHR) synthetic aperture radar (SAR) images, which can be acquired by satellites over the same geographical area with short repetition interval, makes the development of effective unsupervised change detection (CD) techniques very important. This paper proposes a hierarchical approach to CD in VHR SAR images for addressing surveillance applications, where VHR data are acquired with high temporal resolution (e.g., one image every few days). The proposed approach is based on two concepts: exploitation of a multiscale technique for a preliminary detection of areas containing changes in backscattering at different scales (hot spots) and explicit modeling of the semantic meaning of changes by using both the intrinsic SAR image properties (e.g., acquisition geometry and scattering mechanisms) and the available prior information. In order to illustrate the effectiveness of the proposed approach, a problem of freight traffic surveillance is addressed considering two data sets. Each of them is made up of a pair of multitemporal VHR SAR images acquired by the COSMO-SkyMed (COnstellation of small Satellites for the Mediterranean basin Observation) constellation in spotlight mode. Each data set defines a complex CD problem due to both the presence of a variety of changes on the ground and the complexity of object backscattering. Experimental results point out the effectiveness of the proposed approach.","Synthetic aperture radar,
Backscatter,
Surveillance,
Semantics,
Spatial resolution,
Buildings"
LabelRank: A stabilized label propagation algorithm for community detection in networks,"An important challenge in big data analysis nowadays is detection of cohesive groups in large-scale networks, including social networks, genetic networks, communication networks and so. In this paper, we propose LabelRank, an efficient algorithm detecting communities through label propagation. A set of operators is introduced to control and stabilize the propagation dynamics. These operations resolve the randomness issue in traditional label propagation algorithms (LPA), stabilizing the discovered communities in all runs of the same network. Tests on real-world networks demonstrate that LabelRank significantly improves the quality of detected communities compared to LPA, as well as other popular algorithms.","Communities,
Social network services,
Electronic mail,
Clustering algorithms,
Algorithm design and analysis,
Heuristic algorithms,
Sociology"
Two Tales of Privacy in Online Social Networks,"Privacy is one of the friction points that emerge when communications are mediated in online social networks (OSNs). Different communities of computer science researchers have framed the OSN privacy problem as one of surveillance, institutional privacy, or social privacy. In tackling these problems, researchers have also treated them as if they were independent. In this article, the authors argue that the different privacy problems are entangled and that OSN privacy research would benefit from a more holistic approach.","human-computer interaction,
online social networks,
surveillance,
social privacy,
privacy-enhancing technologies"
Regularized Feature Reconstruction for Spatio-Temporal Saliency Detection,"Multimedia applications such as image or video retrieval, copy detection, and so forth can benefit from saliency detection, which is essentially a method to identify areas in images and videos that capture the attention of the human visual system. In this paper, we propose a new spatio-temporal saliency detection framework on the basis of regularized feature reconstruction. Specifically, for video saliency detection, both the temporal and spatial saliency detection are considered. For temporal saliency, we model the movement of the target patch as a reconstruction process using the patches in neighboring frames. A Laplacian smoothing term is introduced to model the coherent motion trajectories. With psychological findings that abrupt stimulus could cause a rapid and involuntary deployment of attention, our temporal model combines the reconstruction error, regularizer, and local trajectory contrast to measure the temporal saliency. For spatial saliency, a similar sparse reconstruction process is adopted to capture the regions with high center-surround contrast. Finally, the temporal saliency and spatial saliency are combined together to favor salient regions with high confidence for video saliency detection. We also apply the spatial saliency part of the spatio-temporal model to image saliency detection. Experimental results on a human fixation video dataset and an image saliency detection dataset show that our method achieves the best performance over several state-of-the-art approaches.",
Measurement and Modeling of Video Watching Time in a Large-Scale Internet Video-on-Demand System,"Video watching time is a crucial measure for studying user watching behavior in online Internet video-on-demand (VoD) systems. It is important for system planning, user engagement understanding, and system quality evaluation. However, due to the limited access of user data in large-scale streaming systems, a systematic measurement, analysis, and modeling of video watching time is still missing. In this paper, we measure PPLive, one of the most popular commercial Internet VoD systems in China, over a three week period. We collect accurate user watching data of more than 100 million streaming sessions of more than 100 thousand distinct videos. Based on the measurement data, we characterize the distribution of watching time of different types of videos and reveal a number of interesting characteristics regarding the relation between video watching time and various video-related features (including video type, duration, and popularity). We further build a suite of mathematical models for characterizing these relationships. Extensive performance evaluation shows the high accuracy of these models as compared with commonly used data-mining based models. Our measurement and modeling results bring forth important insights for simulation, design, deployment, and evaluation of Internet VoD systems.","Streaming media,
Internet,
Mathematical model,
Watches,
IPTV"
High-Resolution Cardiovascular MRI by Integrating Parallel Imaging With Low-Rank and Sparse Modeling,"Magnetic resonance imaging (MRI) has long been recognized as a powerful tool for cardiovascular imaging because of its unique potential to measure blood flow, cardiac wall motion, and tissue properties jointly. However, many clinical applications of cardiac MRI have been limited by low imaging speed. In this paper, we present a novel method to accelerate cardiovascular MRI through the integration of parallel imaging, low-rank modeling, and sparse modeling. This method consists of a novel image model and specialized data acquisition. Of particular novelty is the proposed low-rank model component, which is specially adapted to the particular low-rank structure of cardiovascular signals. Simulations and in vivo experiments were performed to evaluate the method, as well as an analysis of the low-rank structure of a numerical cardiovascular phantom. Cardiac imaging experiments were carried out on both human and rat subjects without the use of ECG or respiratory gating and without breath holds. The proposed method reconstructed 2-D human cardiac images up to 22 fps and 1.0 mm × 1.0 mm spatial resolution and 3-D rat cardiac images at 67 fps and 0.65 mm × 0.65 mm × 0.31 mm spatial resolution. These capabilities will enhance the practical utility of cardiovascular MRI.","Magnetic resonance imaging,
Image reconstruction,
Cardiovascular system,
Data acquisition,
Data models,
Inverse problems"
PV Module Parameter Characterization From the Transient Charge of an External Capacitor,"In the classical model of the photovoltaic (PV) cell/module, based on the single-exponential or double-exponential representation of PV cell/module behavior, parasitic parameters are ignored. Their presence, however, has multiple effects, such as the maximum power point tracking on the current-voltage curve, the switching ON/OFF of the inverters for grid connection, and the electrical safety of persons against indirect contact due to ground leakage currents and lightning phenomena. The effects of parasitic parameters can be visualized in the experimental results gathered through the transient charge of an external capacitor connected to the PV generator terminals. The impact of the parasitic components is different when considering a single PV module or a PV array composed of several PV modules. At the module scale, an oscillation occurs in the initial part of the current waveform, which indicates the presence of some inductive components. At the array scale, the inductive phenomena are overdamped, and parasitic capacitive effects become predominant. This paper shows how to determine the parameters of an extended model of PV modules embedding the parasitic parameter effects. It starts from the experimental results obtained from the fast-sampled voltage and current waveforms during the transient charge of an external capacitor. Numerical examples taken from real cases with different PV technologies are provided.","Capacitors,
Capacitance,
Photovoltaic cells,
Current measurement,
Transient analysis,
Integrated circuit modeling"
Attributed Relational Graphs for Cell Nucleus Segmentation in Fluorescence Microscopy Images,"More rapid and accurate high-throughput screening in molecular cellular biology research has become possible with the development of automated microscopy imaging, for which cell nucleus segmentation commonly constitutes the core step. Although several promising methods exist for segmenting the nuclei of monolayer isolated and less-confluent cells, it still remains an open problem to segment the nuclei of more-confluent cells, which tend to grow in overlayers. To address this problem, we propose a new model-based nucleus segmentation algorithm. This algorithm models how a human locates a nucleus by identifying the nucleus boundaries and piecing them together. In this algorithm, we define four types of primitives to represent nucleus boundaries at different orientations and construct an attributed relational graph on the primitives to represent their spatial relations. Then, we reduce the nucleus identification problem to finding predefined structural patterns in the constructed graph and also use the primitives in region growing to delineate the nucleus borders. Working with fluorescence microscopy images, our experiments demonstrate that the proposed algorithm identifies nuclei better than previous nucleus segmentation algorithms.","Image segmentation,
Shape,
Microscopy,
Clustering algorithms,
Standards,
Noise,
Feature extraction"
Stationary Detection of the Pedestrian?s Intention at Intersections,"This paper focuses on stat ionary detect ion of the pedestrian's intention to enter the traffic lane at intersections. We use an Interacting Multiple Model Extended Kalman Filter (IMM-EKF) based tracking approach as basic method to recognize this. In addition, we propose a novel Motion Contour image based HOG-like descriptor (MCHOG) in combination with Support Vector Machine (SVM) classification that reaches the decision at an accuracy of 99 % within the initial step at the curb of smart infrastructure. MCHOG implicitly comprises the body language of gait initiation, especially the body bending and the spread of legs. As a result of a case study at laboratory conditions we present Receiver Operating Characteristic (ROC) performance data and an evaluation of the span of time necessary for recognition. While MCHOG in special cases indicates detection of the intention before the whole body moves, on average it allows for detection of gait initiation within 6 frames at a frame rate of 50 Hz and an accuracy of 80%. In addition to a comprehensive evaluation under laboratory conditions we demonstrate feasibility of the methods in a real world intersection scenario and we show the gain which we achieve with MCHOG compared to the IMM-EKF approach.",
Vibrotactile Sensory Substitution for Electromyographic Control of Object Manipulation,"It has been shown that incorporating augmentative vibrotactile feedback can improve performance of a virtual object manipulation task using finger movement. Vibrotactile sensory substitution for prosthetic applications, however, will necessarily not involve actual finger movement for control. Here we study the utility of such feedback when using myoelectric (EMG) signals for control, and demonstrate task improvement and learning for a force-motion task in a virtual environment. Using vibrotactile feedback, a group of unimpaired participants (N = 10) were able to increase performance in a single session. We go on to study the feasibility of this method for two prosthetic hand users, one of whom had targeted muscle reinnervation allowing the augmentative feedback to be perceived as if it were on the absent hand.","Electromyography,
Virtual environments,
Thumb,
Prosthetics,
Force,
Muscles"
The travelling thief problem: The first step in the transition from theoretical problems to realistic problems,"There are some questions concerning the applicability of meta-heuristic methods for real-world problems; further, some researchers claim there is a growing gap between research and practice in this area. The reason is that the complexity of real-world problems is growing very fast (e.g. due to globalisation), while researchers experiment with benchmark problems that are fundamentally the same as those of 50 years ago. Thus there is a need for a new class of benchmark problems that reflect the characteristics of real-world problems. In this paper, two main characteristics of real-world problems are introduced: combination and interdependence. We argue that real-world problems usually consist of two or more sub-problems that are interdependent (to each other). This interdependence is responsible for the complexity of the real-world problems, while the type of complexity in current benchmark problems is missing. A new problem, called the travelling thief problem, is introduced; it is a combination of two well-known problems, the knapsack problem and the travelling salesman problem. Some parameters which are responsible for the interdependence of these two sub-problems are defined. Two sets of parameters are introduced that result in generating two instances of the travelling thief problem. The complexities that are raised by interdependences for these two instances are discussed in detail. Finally, a procedure for generating these two instances is given.",
Reconstructing and tracking network state from a limited number of synchrophasor measurements,"A method is proposed to reconstruct and track network state from a limited number of phasor measurement unit (PMU) data. To deal with the resulting unobservability, the state with bus powers and generator voltages closest to previously estimated values is computed. Those values, treated as pseudo-measurements, are obtained from the last reconstructed state, in a recursive manner. The method involves solving an optimization problem with linear constraints. It is scalable insofar as it accommodates from a few PMUs up to configurations ensuring full network observability. Reconstruction of only a region is possible. These and other features are demonstrated on the Nordic32 test system, with synchronized phasors obtained from detailed time simulation of a situation evolving towards instability. Suitable choices of PMU location and pseudo-measurements are also discussed.",
Efficient Resource Provisioning and Rate Selection for Stream Mining in a Community Cloud,"Real-time stream mining such as surveillance and personal health monitoring, which involves sophisticated mathematical operations, is computation-intensive and prohibitive for mobile devices due to the hardware/computation constraints. To satisfy the growing demand for stream mining in mobile networks, we propose to employ a cloud-based stream mining system in which the mobile devices send via wireless links unclassified media streams to the cloud for classification. We aim at minimizing the classification-energy cost, defined as an affine combination of classification cost and energy consumption at the cloud, subject to an average stream mining delay constraint (which is important in real-time applications). To address the challenge of time-varying wireless channel conditions without a priori information about the channel statistics, we develop an online algorithm in which the cloud operator can dynamically adjust its resource provisioning on the fly and the mobile devices can adapt their transmission rates to the instantaneous channel conditions. It is proved that, at the expense of increasing the average stream mining delay, the online algorithm achieves a classification-energy cost that can be pushed arbitrarily close to the minimum cost achieved by the optimal offline algorithm. Extensive simulations are conducted to validate the analysis.",
Modeling Temporal Interactions with Interval Temporal Bayesian Networks for Complex Activity Recognition,"Complex activities typically consist of multiple primitive events happening in parallel or sequentially over a period of time. Understanding such activities requires recognizing not only each individual event but, more importantly, capturing their spatiotemporal dependencies over different time intervals. Most of the current graphical model-based approaches have several limitations. First, time--sliced graphical models such as hidden Markov models (HMMs) and dynamic Bayesian networks are typically based on points of time and they hence can only capture three temporal relations: precedes, follows, and equals. Second, HMMs are probabilistic finite-state machines that grow exponentially as the number of parallel events increases. Third, other approaches such as syntactic and description-based methods, while rich in modeling temporal relationships, do not have the expressive power to capture uncertainties. To address these issues, we introduce the interval temporal Bayesian network (ITBN), a novel graphical model that combines the Bayesian Network with the interval algebra to explicitly model the temporal dependencies over time intervals. Advanced machine learning methods are introduced to learn the ITBN model structure and parameters. Experimental results show that by reasoning with spatiotemporal dependencies, the proposed model leads to a significantly improved performance when modeling and recognizing complex activities involving both parallel and sequential events.","Hidden Markov models,
Bayesian methods,
Computational modeling,
Probabilistic logic,
Uncertainty,
Graphical models"
On Diversity Order and Coding Gain of Multisource Multirelay Cooperative Wireless Networks With Binary Network Coding,"In this paper, a multisource multirelay cooperative wireless network with binary modulation and binary network coding is studied. The system model encompasses 1) a Demodulate-and-Forward (DemF) protocol at the relays, where the received packets are forwarded, regardless of their reliability, and 2) a maximum-likelihood optimum demodulator at the destination, which accounts for possible demodulation errors at the relays. An asymptotically tight and closed-form expression of the end-to-end error probability is derived, which showcases the diversity order and coding gain of each source. Unlike other papers available in the literature, the proposed framework has three main distinguishable features: 1) It is useful for general network topologies and arbitrary binary encoding vectors; 2) it shows how network code and two-hop forwarding protocol affect diversity order and coding gain; and 3) it accounts for realistic fading channels and demodulation errors at the relays. The framework provides four main conclusions: 1) Each source achieves a diversity order equal to the separation vector of the network code; 2) the design of diversity-achieving network codes is equivalent to the design of systematic block codes over fully interleaved point-to-point links; 3) the coding gain of each source decreases with the number of mixed packets at the relays; and 4) if the destination cannot take into account demodulation errors at the relays, it loses approximately half of the diversity order. Our theoretical findings are validated through extensive Monte Carlo simulations.","Relays,
Encoding,
Wireless networks,
Demodulation,
Protocols,
Vectors,
Diversity reception"
Real-Time Implementation of a Dual-Mode Ultrasound Array System: In Vivo Results,"A real-time dual-mode ultrasound array (DMUA) system for imaging and therapy is described. The system utilizes a concave (40-mm radius of curvature) 3.5 MHz, 32 element array, and modular multichannel transmitter/receiver. The system is capable of operating in a variety of imaging and therapy modes (on transmit) and continuous receive on all array elements even during high-power operation. A signal chain consisting of field-programmable gate arrays and graphical processing units is used to enable real time, software-defined beamforming and image formation. Imaging data, from quality assurance phantoms as well as in vivo small- and large-animal models, are presented and discussed. Corresponding images obtained using a temporally-synchronized and spatially-aligned diagnostic probe confirm the DMUA's ability to form anatomically-correct images with sufficient contrast in an extended field of view around its geometric center. In addition, high-frame rate DMUA data also demonstrate the feasibility of detection and localization of echo changes indicative of cavitation and/or tissue boiling during high-intensity focused ultrasound exposures with 45-50 dB dynamic range. The results also show that the axial and lateral resolution of the DMUA are consistent with its fnumber and bandwidth with well-behaved speckle cell characteristics. These results point the way to a theranostic DMUA system capable of quantitative imaging of tissue property changes with high specificity to lesion formation using focused ultrasound.","Imaging,
Arrays,
Probes,
Ultrasonic imaging,
Lesions,
Speckle,
Transducers"
Aspect-Oriented Model-Driven Engineering for Embedded Systems Applied to Automation Systems,"Automation and control systems include many “intelligent” automation devices, which are usually implemented as complex embedded systems. New methods and tools are demanded to cope with the increasing design complexity, while keeping the project on schedule. Proper handling of nonfunctional system requirements is a key factor during the design of industrial automation systems, since in some application domains they are as important as (sometimes, more important than) functional requirements. This paper presents a model-driven engineering approach, which combines Unified Modeling Language (UML) and aspect-oriented software development (AOSD) to design real-time and embedded automation systems. The proposed approach allows a smooth transition from the initial phases to implementation by using software tools, comprising the system specification and the automatic generation of source code. By combining UML with model-level aspects and a script-base code generation tool, it enables the use of AOSD during system design and implementation, even though the target platform does not natively support such concepts. Experimental results on using this approach to design real-world examples of automation systems are presented. The results indicate a positive impact on the design of automation systems. The encapsulation of nonfunctional requirements was improved, increasing the reuse of developed artifacts. Generated source code statistics indicate that the proposed approach can generated a fair amount of code per model element.","Unified modeling language,
Automation,
Real-time systems,
Embedded systems,
Software engineering"
Cross-Layer Metrics for Reliable Routing in Wireless Mesh Networks,"Wireless mesh networks (WMNs) have emerged as a flexible and low-cost network infrastructure, where heterogeneous mesh routers managed by different users collaborate to extend network coverage. This paper proposes a novel routing metric, Expected Forwarded Counter (EFW), and two further variants, to cope with the problem of selfish behavior (i.e., packet dropping) of mesh routers in a WMN. EFW combines, in a cross-layer fashion, routing-layer observations of forwarding behavior with MAC-layer measurements of wireless link quality to select the most reliable and high-performance path. We evaluate the proposed metrics both through simulations and real-life deployments on two different wireless testbeds, performing a comparative analysis with On-Demand Secure Byzantine Resilient Routing (ODSBR) Protocol and Expected Transmission Counter (ETX). The results show that our cross-layer metrics accurately capture the path reliability and considerably increase the WMN performance, even when a high percentage of network nodes misbehave.",
Protecting Sensitive Labels in Social Network Data Anonymization,"Privacy is one of the major concerns when publishing or sharing social network data for social science research and business analysis. Recently, researchers have developed privacy models similar to k-anonymity to prevent node reidentification through structure information. However, even when these privacy models are enforced, an attacker may still be able to infer one's private information if a group of nodes largely share the same sensitive labels (i.e., attributes). In other words, the label-node relationship is not well protected by pure structure anonymization methods. Furthermore, existing approaches, which rely on edge editing or node clustering, may significantly alter key graph properties. In this paper, we define a k-degree-l-diversity anonymity model that considers the protection of structural information as well as sensitive labels of individuals. We further propose a novel anonymization methodology based on adding noise nodes. We develop a new algorithm by adding noise nodes into the original graph with the consideration of introducing the least distortion to graph properties. Most importantly, we provide a rigorous analysis of the theoretical bounds on the number of noise nodes added and their impacts on an important graph property. We conduct extensive experiments to evaluate the effectiveness of the proposed technique.",
Trapping Mobile Targets in Wireless Sensor Networks: An Energy-Efficient Perspective,"Mobile target detection is a significant application in wireless sensor networks (WSNs). In fact, it is rather expensive to require every part of the region of interest (RoI) to be covered in a large-scale WSN for target detection. Trap coverage has been proposed to trade off between sensing performance and the cost of sensor deployments. It restricts the farthest distance that a target can move without being detected rather than providing full coverage to the region. However, the results cannot be directly applied in a real WSN since the detection pattern of a sensor in practical scenarios follows a probabilistic sensing model. Moreover, the trap coverage model does not consider the various moving speeds of targets, which is important for trapping targets. To extend the concept of mobile target trapping into a real large-scale WSN, we analyze the detection probability of a mobile target in the sensor network theoretically and define probabilistic trap coverage in this paper, which restricts the farthest displacement of a mobile target with a detection probability less than the threshold. We develop the theory of circle graph, which can be generally applied in the area of intrusion detection such as trap coverage and barrier coverage. We further study the practical issue of how to schedule sensors to maximize the lifetime of a network while guaranteeing probabilistic trap coverage. A localized protocol is proposed to solve the problem, and the performance of the protocol is theoretically analyzed. The lower bound of lifetime acquired by the protocol is nearly half the optimum lifetime. To evaluate our design, we perform extensive simulations to compare our algorithm with the state-of-the-art solution and demonstrate the superiority of our algorithm.","Probabilistic logic,
Sensors,
Mobile communication,
Wireless sensor networks,
Charge carrier processes,
Protocols,
Mobile computing"
Computing a k-sparse n-length Discrete Fourier Transform using at most 4k samples and O(k log k) complexity,"Given an n-length input signal x, it is well known that its Discrete Fourier Transform (DFT), X, can be computed in O(nlogn) complexity using a Fast Fourier Transform. If the spectrum X is exactly k-sparse (where k <;<; n), can we do better? We show that asymptotically in k and n, when k is sub-linear in n (i.e., k ∝ nδ where 0 <; δ <; 1), and the support of the non-zero DFT coefficients is uniformly random, we can exploit this sparsity in two fundamental ways (i) sample complexity: we need only M = rk deterministically chosen samples of the input signal x (where r <; 4 when 0 <; δ <; 0.99); and (ii) computational complexity: we can reliably compute the DFT X using O(k log k) operations, where the constants in the big Oh are small. Our algorithm succeeds with high probability, with the probability of failure vanishing to zero asymptotically in the number of samples acquired, M. Our approach is based on filterless subsampling of the input signal x using a small set of carefully chosen uniform subsampling patterns guided by the Chinese Remainder Theorem (CRT). Specifically, our subsampling operation on x is designed to create aliasing patterns on the spectrum X that ""look like"" parity-check constraints of good erasure-correcting sparse-graph codes. We show how computing the sparse DFT X is equivalent to decoding of these sparse-graph codes and is low in both sample complexity and decoding complexity. We accordingly dub our algorithm the FFAST (Fast Fourier Aliasing-based Sparse Transform) algorithm. In our analysis, we rigorously connect our CRT based graph constructions to random sparse-graph codes based on a balls-and-bins model and analyze the convergence behavior of the latter using well-studied density evolution techniques from coding theory. We provide simulation results in Section IV that corroborate our theoretical findings, and validate the empirical performance of the FFAST algorithm.",
Cloud task scheduling based on ant colony optimization,"Cloud computing is the development of distributed computing, parallel computing and grid computing, or defined as the commercial implementation of these computer science concepts. One of the fundamental issues in this environment is related to task scheduling. Cloud task scheduling is an NP-hard optimization problem, and many meta-heuristic algorithms have been proposed to solve it. A good task scheduler should adapt its scheduling strategy to the changing environment and the types of tasks. In this paper a cloud task scheduling policy based on ant colony optimization algorithm compared with different scheduling algorithms FCFS and round-robin, has been presented. The main goal of these algorithms is minimizing the makespan of a given tasks set. Ant colony optimization is random optimization search approach that will be used for allocating the incoming jobs to the virtual machines. Algorithms have been simulated using Cloudsim toolkit package. Experimental results showed that the ant colony optimization outperformed FCFS and round-robin algorithms.","Processor scheduling,
Cloud computing,
Scheduling,
Heuristic algorithms,
Resource management,
Computational modeling,
Optimization"
AMVS-NDN: Adaptive mobile video streaming and sharing in wireless named data networking,"Recently, mobile traffic (especially video traffic) explosion becomes a serious concern for mobile network operators. While video streaming services become crucial for mobile users, their traffic may often exceed the bandwidth capacity of cellular networks. To address the video traffic problem, we consider a future Internet architecture: Named Data Networking (NDN). In this paper, we design and implement a framework of adaptive mobile video streaming and sharing in the NDN architecture (AMVS-NDN) considering that most of mobile stations have multiple wireless interfaces (e.g., 3G and WiFi). To demonstrate the benefit of NDN, AMVS-NDN has two key functionalities: (1) a mobile station (MS) seeks to use either 3G/4G or WiFi links opportunistically, and (2) MSs can share content directly by exploiting local WiFi connectivities. We implement AMVS-NDN over CCNx, and perform tests in a real testbed consisting of a WiMAX base station and Android phones. Testing with time-varying link conditions in mobile environments reveals that AMVS-NDN achieves the higher video quality and less cellular traffic than other solutions.",
Precise dynamic turning of a 10 cm legged robot on a low friction surface using a tail,"For maximum maneuverability, terrestrial robots need to be able to turn precisely, quickly, and with a small radius. Previous efforts at turning in legged robots primarily have used leg force or velocity modulation. We developed a palm-sized legged robot, called TAYLRoACH. The tailed robot was able to make rapid, precise turns using only the actuation of a tail appendage. By rapidly rotating the tail as the robot runs forward, the robot was able to make sudden 90° turns at 360 °s-1. Unlike other robots, this is done with almost no change in its running speed. We have also modeled the dynamics of this maneuver, to examine how features, such as tail length and mass, affect the robot's turning ability. This approach has produced turns with a radius of 0.4 body lengths at 3.2 body lengths per second running speed. Using gyro feedback and bang-bang control, we achieve an accuracy of ± 5° for a 60° turn.","Robot kinematics,
Robot sensing systems,
IEEE 802.15 Standards"
Common-Centroid Capacitor Layout Generation Considering Device Matching and Parasitic Minimization,"In analog layout design, the accuracy of capacitance ratios correlates closely with both the matching properties among the ratioed capacitors and the induced parasitics due to interconnecting wires. However, most of the previous works only emphasized the matching properties of a common-centroid placement, but ignored the induced parasitics after it is routed. This paper addresses the parasitic issue in addition to device matching during common-centroid capacitor layout generation. To effectively minimize the routing-induced parasitics, a novel common-centroid placement style, distributed connected unit capacitors, is presented. Based on the placement style, the ratioed capacitor layout generation flow and algorithms are proposed to simultaneously optimize the matching properties of a common-centroid placement and minimize the induced parasitics. Experimental results show that the proposed approach can greatly reduce area, wirelength, and routing-induced parasitics, and guarantee the best matching quality after routing.","Capacitors,
Routing,
Arrays,
Layout,
Wires,
Systematics,
Minimization"
Decentralized Edge Clouds,"Cloud computing services are traditionally deployed on centralized computing infrastructures confined to a few data centers, while cloud applications run in a single data center. However, the cloud's centralized nature can be limiting in terms of performance and cost for applications where users, data, and computation are distributed. The authors present an overview of distributed clouds that might be better suited for such applications. They briefly describe the distributed cloud landscape and introduce Nebula, a highly decentralized cloud that uses volunteer edge resources. The authors provide insights into some of its key properties and design issues, and describe a distributed MapReduce application scenario to illustrate the benefits and trade-offs of using distributed and decentralized clouds for distributed data-intensive computing applications.","Distributed databases,
Computational modeling,
Cloud computing,
Computer science,
Monitoring,
Data models"
Charge Allocation in Hybrid Electrical Energy Storage Systems,"A hybrid electrical energy storage (HEES) system consists of multiple banks of heterogeneous electrical energy storage (EES) elements placed between a power source and some load devices and providing charge storage and retrieval functions. For an HEES system to perform its desired functions of 1) reducing electricity costs by storing electricity obtained from the power grid at off-peak times when its price is lower, for use at peak times instead of electricity that must be bought then at higher prices, and 2) alleviating problems, such as excessive power fluctuation and undependable power supply, which are associated with the use of large amounts of renewable energy on the grid, appropriate charge management policies must be developed in order to efficiently store and retrieve electrical energy while attaining performance metrics that are close to the respective best values across the constituent EES banks in the HEES system. This paper is the first to formally describe the global charge allocation problem in HEES systems, namely, distributing a specified level of incoming power to a subset of destination EES banks so that maximum charge allocation efficiency is achieved. The problem is formulated as a mixed integer nonlinear program with the objective function set to the global charge allocation efficiency and the constraints capturing key requirements and features of the system such as the energy conservation law, power conversion losses in the chargers, the rate capacity, and self-discharge effects in the EES elements. A rigorous algorithm is provided to obtain near-optimal charge allocation efficiency under a daily charge allocation schedule. A photovoltaic array is used as an example of the power source for the charge allocation process and a heuristic is provided to predict the solar radiation level with a high accuracy. Simulation results using this photovoltaic cell array and a representative HEES system demonstrate up to 25% gain in the charge allocation efficiency by employing the proposed algorithm.","Batteries,
Resource management,
Supercapacitors,
Arrays,
Voltage control,
Integrated circuit modeling"
Throughput-Delay Analysis of Random Linear Network Coding for Wireless Broadcasting,"In an unreliable single-hop broadcast network setting, we investigate the throughput and decoding-delay performance of random linear network coding as a function of the coding window size and the network size. Our model consists of a source transmitting packets of a single flow to a set of n users over independent time-correlated erasure channels. The source performs random linear network coding (RLNC) over k (coding window size) packets and broadcasts them to the users. We note that the broadcast throughput of RLNC must vanish with increasing n, for any fixed k. Hence, in contrast to other works in the literature, we investigate how the coding window size k must scale for increasing n. Our analysis reveals that the coding window size of Θ(ln(n)) represents a phase transition rate, below which the throughput converges to zero, and above which, it converges to the broadcast capacity. Further, we characterize the asymptotic distribution of decoding delay and provide approximate expressions for the mean and variance of decoding delay for the scaling regime of k=ω(ln(n)). These asymptotic expressions reveal the impact of channel correlations on the throughput and delay performance of RLNC. We also show that how our analysis can be extended to other rateless block coding schemes such as the LT codes. Finally, we comment on the extension of our results to the cases of dependent channels across users and asymmetric channel model.","Delays,
Throughput,
Encoding,
Decoding,
Channel models,
Random variables,
Network coding"
An interdisciplinary SysML based modeling approach for analyzing change influences in production plants to support the engineering,"Modern mechatronic production plants contain a multitude of mechanical, electrical/electronic and software components. During its lifecycle such a system evolves through changes of different system components. In order to take the influences of these changes, discipline specific as well as interdisciplinary, into account during the development an adequate modeling approach and notation is required. In this paper an approach (called SysML4Mechatronics) utilizing the port-concept of the current version 1.3 of the Systems Modeling Language, to depict and analyze change influences in mechatronic production plants is presented.","Unified modeling language,
Ports (Computers),
Software,
Solid modeling,
Production,
Mechatronics,
Optical sensors"
Security Analysis and Improvement of a Secure and Distributed Reprogramming Protocol for Wireless Sensor Networks,"Wireless reprogramming in a wireless sensor network (WSN) is the process of propagating a new code image or relevant commands to sensor nodes. As a WSN is usually deployed in hostile environments, secure reprogramming is and will continue to be a major concern. While all existing insecure/secure reprogramming protocols are based on the centralized approach, it is important to support distributed reprogramming in which multiple authorized network users can simultaneously and directly reprogram sensor nodes without involving the base station. Very recently, a novel secure and distributed reprogramming protocol named SDRP has been proposed, which is the first work of its kind. However, in this paper, we identify an inherent design weakness in the user preprocessing phase of SDRP and demonstrate that it is vulnerable to an impersonation attack by which an adversary can easily impersonate any authorized user to carry out reprogramming. Subsequently, we propose a simple modification to fix the identified security problem without losing any features of SDRP. Our experimental results demonstrate that it is possible to eliminate the design weakness by adding 1-B redundant data and that the execution time of the suggested solution in a 1.6-GHz laptop PC is no more than 1 ms. Therefore, our solution is feasible and secure for real-world applications. Moreover, we show that, in order to further improve the security and efficiency of SDRP, any better established identity-based signature algorithm can be directly employed in SDRP. Based on implementation results, we demonstrate efficiency improvement over the original SDRP.",
On the Discovery of Critical Links and Nodes for Assessing Network Vulnerability,"The assessment of network vulnerability is of great importance in the presence of unexpected disruptive events or adversarial attacks targeting on critical network links and nodes. In this paper, we study Critical Link Disruptor (CLD) and Critical Node Disruptor (CND) optimization problems to identify critical links and nodes in a network whose removals maximally destroy the network's functions. We provide a comprehensive complexity analysis of CLD and CND on general graphs and show that they still remain NP-complete even on unit disk graphs and power-law graphs. Furthermore, the CND problem is shown NP-hard to be approximated within Ω([(n-k)/(nε)] ) on general graphs with n vertices and k critical nodes. Despite the intractability of these problems, we propose HILPR, a novel LP-based rounding algorithm, for efficiently solving CLD and CND problems in a timely manner. The effectiveness of our solutions is validated on various synthetic and real-world networks.","Measurement,
Polynomials,
IEEE transactions,
Optimization,
Internet,
Materials,
Network topology"
RIFFA 2.0: A reusable integration framework for FPGA accelerators,"We present RIFFA 2.0, a reusable integration framework for FPGA accelerators. RIFFA 2.0 provides communication and synchronization for FPGA accelerated applications using simple interfaces for hardware and software. Our goal is to expand the use of FPGAs as an acceleration platform by releasing, as open source, a framework that easily integrates software running on commodity CPUs with FPGA cores. RIFFA 2.0 uses PCIe to connect FPGAs to a CPU's system bus. RIFFA 2.0 extends the original RIFFA project by supporting more classes of Xilinx FPGAs, multiple FPGAs in a system, more PCIe link configurations, higher bandwidth, and Linux and Windows operating systems. This release also supports C/C++, Java, and Python bindings. Tests show that data transfers between hardware and software can saturate the PCIe link to achieve the highest bandwidth possible.",
Experiences in Developing an Experimental Robotics Course Program for Undergraduate Education,"An interdisciplinary undergraduate-level robotics course offers students the chance to integrate their engineering knowledge learned throughout their college years by building a robotic system. Robotics is thus a core course in system and control-related engineering education. This paper summarizes the experience of developing robotics courses presented in the literature and shares the author's experiences through many years of teaching and developing robotics courses with other educators in the Department of Mechatronics, Chungnam National University (CNU), Daejeon, Korea. First, the CNU robotics course described here has classroom and laboratory sections. In class, students learn the theories behind robotics and practice them by performing simulation studies. In parallel, students perform robotics exercises in the laboratory. Second, the lab exercises are focused on hands-on experiments on robot systems; these include an experimental kit, LEGO robots, humanoid robots, industrial robots, and home service robots. Third, competition-based learning is explored by assigning a class project to develop a boxing robot, which covers both manipulation and mobility. Finally, the course introduces robotics-associated outreach activities. The analysis of several years of student evaluation is presented.",
A Novel Query Tree Protocol with Bit Tracking in RFID Tag Identification,"Tag anticollision has long been an important issue in RFID systems. To accelerate tag identification, some researchers have recently adopted bit tracking technology that allows the reader to detect the locations of collided bits in a collision slot. However, these methods still encounter the problem of too many collisions occurring at the beginning of identification. This paper proposes an optimal query tracking tree protocol (OQTT) that tries to separate all of the tags into smaller sets to reduce collisions at the beginning of identification. Using bit tracking technology, OQTT mainly adopts three proposed approaches, bit estimation, optimal partition, and query tracking tree. Bit estimation first estimates the number of tags based on the locations of collided bits. Optimal partition then determines the optimal number of the initial sets based on this estimation. Query tracking tree splits a set of collided tags into two subsets using the first collided bit in the tag IDs. This paper analyzes the efficiency of OQTT, which represents how many tags can be identified in a slot. Results show that its efficiency is close to 0.614, the highest efficiency published to date. The simulation results further show that OQTT outperforms other existing algorithms.","Estimation,
Algorithm design and analysis,
Protocols,
Mobile computing,
Radiofrequency identification,
Delay,
Wireless communication"
"RNS Reverse Converters for Moduli Sets With Dynamic Ranges up to (8n+1)
-bit","In the last years, investigation on residue number systems (RNS) has targeted parallelism and larger dynamic ranges. In this paper, we start from the moduli set {2n,2n-1,2n+1,2n-2(n+1)/2+1,2n+2(n+1)/2+1} , with an equivalent 5n -bit dynamic range, and propose horizontal and vertical extensions in order to improve the parallelism and increase the dynamic range. The vertical extensions increase the value of the power-of-2 modulus in the five-moduli set. With the horizontal extensions, new six channel sets are allowed by introducing the 2n+1+1 or 2n-1+1 moduli. This paper proposes methods to design memoryless reverse converters for the proposed moduli sets with large dynamic ranges, up to (8n+1)-bit. Due to the complexity of the reverse conversion, both the Chinese Remainder Theorem and the Mixed Radix Conversion are applied in the proposed methods to derive efficient reverse converters. Experimental results suggest that the proposed vertical extensions allow to reduce the area-delay-product up to 1.34 times in comparison with the related state-of-the-art. The horizontal extensions allow larger and more balanced moduli sets, resulting in an improvement of the RNS arithmetic computation, at the cost of lower reverse conversion performance.","Dynamic range,
Arrays,
Parallel processing,
Design methodology,
Complexity theory,
Digital signal processing,
Cryptography"
Understanding and Enhancement of Internal Clustering Validation Measures,"Clustering validation has long been recognized as one of the vital issues essential to the success of clustering applications. In general, clustering validation can be categorized into two classes, external clustering validation and internal clustering validation. In this paper, we focus on internal clustering validation and present a study of 11 widely used internal clustering validation measures for crisp clustering. The results of this study indicate that these existing measures have certain limitations in different application scenarios. As an alternative choice, we propose a new internal clustering validation measure, named clustering validation index based on nearest neighbors (CVNN), which is based on the notion of nearest neighbors. This measure can dynamically select multiple objects as representatives for different clusters in different situations. Experimental results show that CVNN outperforms the existing measures on both synthetic data and real-world data in different application scenarios.","Indexes,
Noise,
Clustering algorithms,
Educational institutions,
Current measurement,
Shape,
Atmospheric measurements"
A Current Controller Design for Current Source Inverter-Fed AC Machine Drive System,"A current source inverter (CSI) requires a capacitor filter for the commutation of switching device as well as for attenuating switching harmonics. Hence, the CSI-fed ac machine has a second-order system in the continuous time domain. This paper presents a design methodology for the closed-loop current controller of the CSI-fed ac machine drive system. A multiloop current controller design using a pole/zero cancellation method is employed with a transfer function matrix. To decouple the cross-coupling terms which cause mutual interferences between the d- and q-axes in the synchronous reference frame, two types of controller are proposed and implemented using different decoupling method. Additionally, active damping methods are incorporated to enhance the stability of the system. A stability analysis in discrete-time domain is investigated to verify the feasibility of the proposed closed-loop current controller. To evaluate the effectiveness of the proposed current controller, computer simulations and experimental tests were performed and the results are discussed.",
DrivingStyles: A smartphone application to assess driver behavior,"The DrivingStyles architecture integrates both data mining techniques and neural networks to generate a classification of driving styles by analyzing the driver behavior along each route. In particular, based on parameters such as speed, acceleration, and revolutions per minute of the engine (rpm), we have implemented a neural network based algorithm that is able to characterize the type of road on which the vehicle is moving, as well as the degree of aggressiveness of each driver. The final goal is to assist drivers at correcting the bad habits in their driving behavior, while offering helpful tips to improve fuel economy. In this work we take advantage of two key-points: the evolution of mobile terminals and the availability of a standard interface to access car data. Our DrivingStyles platform to achieve a symbiosis between smartphones and vehicles able to make the former operate as an onboard unit. Results show that neural networks were able to achieve a high degree of exactitude at classifying both road and driver types based on user traces. DrivingStyles is currently available on the Google Play Store platform for free download, and has achieved more than 1550 downloads from different countries in just a few months.","Vehicles,
Artificial neural networks,
Fuels,
Acceleration,
Roads,
Safety,
Google"
Relational Multimanifold Coclustering,"Coclustering targets on grouping the samples (e.g., documents and users) and the features (e.g., words and ratings) simultaneously. It employs the dual relation and the bilateral information between the samples and features. In many real-world applications, data usually reside on a submanifold of the ambient Euclidean space, but it is nontrivial to estimate the intrinsic manifold of the data space in a principled way. In this paper, we focus on improving the coclustering performance via manifold ensemble learning, which is able to maximally approximate the intrinsic manifolds of both the sample and feature spaces. To achieve this, we develop a novel coclustering algorithm called relational multimanifold coclustering based on symmetric nonnegative matrix trifactorization, which decomposes the relational data matrix into three submatrices. This method considers the intertype relationship revealed by the relational data matrix and also the intratype information reflected by the affinity matrices encoded on the sample and feature data distributions. Specifically, we assume that the intrinsic manifold of the sample or feature space lies in a convex hull of some predefined candidate manifolds. We want to learn a convex combination of them to maximally approach the desired intrinsic manifold. To optimize the objective function, the multiplicative rules are utilized to update the submatrices alternatively. In addition, both the entropic mirror descent algorithm and the coordinate descent algorithm are exploited to learn the manifold coefficient vector. Extensive experiments on documents, images, and gene expression data sets have demonstrated the superiority of the proposed algorithm compared with other well-established methods.","Manifolds,
Matrix decomposition,
Symmetric matrices,
Vectors,
Partitioning algorithms,
Linear programming,
Laplace equations"
Cooperative robot localization and target tracking based on least squares minimization,"In this paper we address the problem of cooperative localization and target tracking with a team of moving robots. We model the problem as a least squares minimization problem and show that this problem can be efficiently solved using sparse optimization methods. To achieve this, we represent the problem as a graph, where the nodes are robot and target poses at individual time-steps and the edges are their relative measurements. Static landmarks at known position are used to define a common reference frame for the robots and the targets. In this way, we mitigate the risk of using measurements and state estimates more than once, since all the relative measurements are i.i.d. and no marginalization is performed. Experiments performed using a set of real robots show higher accuracy compared to a Kalman filter.","Robots,
Size measurement,
Optimization"
Active current balancing for parallel-connected silicon carbide MOSFETs,"In high power applications of silicon carbide (SiC) MOSFETs where parallelism is employed, current unbalance can occur and affect the performance and reliability of the power devices. In this paper, factors which cause current unbalance in these devices are analyzed. Among them, the threshold voltage mismatch is identified as a major factor for dynamic current unbalance. The threshold distribution of SiC MOSFETs is investigated, and its effect on current balance is studied in experiments. Based on these analyses, an active current balancing scheme is proposed. It is able to sense the unbalanced current and eliminate it by actively controlling the gate drive signal to each device. The features of fine time resolution and low complexity make this scheme attractive to a wide variety of wide-band-gap device applications. Experimental and simulation results verify the feasibility and effectiveness of the proposed scheme.",
A Hybrid Scalable Peer-to-Peer IP-Based Multimedia Services Architecture in Ethernet Passive Optical Networks,"Peer-to-peer (P2P) applications such as P2P video streaming and internet video calling have gained tremendous popularity and are expected to be vastly increasing in the next few years. However, low-cost large-scale video services have remained an intangible goal. The ethernet passive optical network (EPON) is being regarded as one of the promising for next-generation optical access solutions in the access networks attempt to tackle this problem but facing a major challenge to offer scalable large-scale video services. Therefore, in this paper, we propose an architecture which combines the advantages of EPON and P2P architecture to provide scalable Internet Protocol delivery multimedia services and improve quality-of-services. In the proposed architecture, we design new optical network unit (ONU) mechanisms, which support traffic redirection communication among ONUs in combination with caching. Thus, it can reduce the resource consumption and add extra downstream bandwidth at the optical line terminal since the intra-PON traffic is not necessary to be buffered and scheduled in the downstream direction. Finally, we propose a “Redirect” dynamic bandwidth allocation scheme, which can support intra-PON traffic redirection and intertraffic bandwidth allocation. Simulation results have shown that our proposed architecture can improve the overall QoS in terms of end-to-end delay, jitter, system throughput, fairness, and packet dropping rate.","Optical network units,
Streaming media,
Bandwidth,
EPON,
IEEE 802.3 Standards,
Peer to peer computing,
Computer architecture"
"Fragmentation-aware routing, modulation and spectrum assignment algorithms in elastic optical networks","We investigate the principle of how dynamic service provisioning fragments the spectral resources on links along a path, and propose corresponding RMSA algorithms to alleviate spectrum fragmentation in dynamic network environments.",
Fairness Resource Allocation in Blind Wireless Multimedia Communications,"Traditional α -fairness resource allocation in wireless multimedia communications assumes that the quality of experience (QoE) model (or utility function) of each user is available to the base station (BS), which may not be valid in many practical cases. In this paper, we consider a blind scenario where the BS has no knowledge of the underlying QoE model. Generally, this consideration raises two fundamental questions. Is it possible to set the fairness parameter α in a precisely mathematical specific α -fairness resource allocation schememanner? If so, is it possible to implement a specific α -fairness resource allocation scheme online? In this work, we will give positive answers to both questions. First, we characterize the tradeoff between the performance and fairness by providing an upper bound of the performance loss resulting from employing α -fairness scheme. Then, we decompose the α-fairness problem into two subproblems that describe the behaviors of the users and BS and design a bidding game for the reconciliation between the two subproblems. We demonstrate that, although all users behave selfishly, the equilibrium point of the game can realize the α-fairness efficiently, and the convergence time is reasonably short. Furthermore, we present numerical simulation results that confirm the validity of the analytical results.","Resource management,
Multimedia communication,
Games,
Upper bound,
Educational institutions,
System performance,
Wireless communication"
Vision-Based Control of a Handheld Surgical Micromanipulator With Virtual Fixtures,"Performing micromanipulation and delicate operations in submillimeter workspaces is difficult because of destabilizing tremor and imprecise targeting. Accurate micromanipulation is especially important for microsurgical procedures, such as vitreoretinal surgery, to maximize successful outcomes and minimize collateral damage. Robotic aid combined with filtering techniques that suppress tremor frequency bands increases performance; however, if knowledge of the operator's goals is available, virtual fixtures have been shown to further improve performance. In this paper, we derive a virtual fixture framework for active handheld micromanipulators that is based on high-bandwidth position measurements rather than forces applied to a robot handle. For applicability in surgical environments, the fixtures are generated in real time from microscope video during the procedure. Additionally, we develop motion scaling behavior around virtual fixtures as a simple and direct extension to the proposed framework. We demonstrate that virtual fixtures significantly outperform tremor cancellation algorithms on a set of synthetic tracing tasks (p <; 0.05). In more medically relevant experiments of vein tracing and membrane peeling in eye phantoms, virtual fixtures can significantly reduce both positioning error and forces applied to tissue (p <; 0.05).","Surgery,
Micromanipulators,
Retina,
Instruments,
Fixtures,
Splines (mathematics)"
An Efficient Denoising Architecture for Removal of Impulse Noise in Images,"Images are often corrupted by impulse noise in the procedures of image acquisition and transmission. In this paper, we propose an efficient denoising scheme and its VLSI architecture for the removal of random-valued impulse noise. To achieve the goal of low cost, a low-complexity VLSI architecture is proposed. We employ a decision-tree-based impulse noise detector to detect the noisy pixels, and an edge-preserving filter to reconstruct the intensity values of noisy pixels. Furthermore, an adaptive technology is used to enhance the effects of removal of impulse noise. Our extensive experimental results demonstrate that the proposed technique can obtain better performances in terms of both quantitative evaluation and visual quality than the previous lower complexity methods. Moreover, the performance can be comparable to the higher,- complexity methods. The VLSI architecture of our design yields a processing rate of about 200 MHz by using TSMC 0.18 μm technology. Compared with the state-of-the-art techniques, this work can reduce memory storage by more than 99 percent. The design requires only low computational complexity and two line memory buffers. Its hardware cost is low and suitable to be applied to many real-time applications.","Noise,
Noise measurement,
Image edge detection,
Very large scale integration,
Computer architecture,
Noise reduction,
Detectors"
On Multiple Users Scheduling Using Superposition Coding over Rayleigh Fading Channels,"In this letter, numerical results are provided to analyze the gains of multiple users scheduling via superposition coding with successive interference cancellation in comparison with the conventional single user scheduling in Rayleigh block-fading broadcast channels. The information-theoretic optimal power, rate and decoding order allocation for the superposition coding scheme are considered and the corresponding histogram for the optimal number of scheduled users is evaluated. Results show that at optimality there is a high probability that only two or three users are scheduled per channel transmission block. Numerical results for the gains of multiple users scheduling in terms of the long term throughput under hard and proportional fairness as well as for fixed merit weights for the users are also provided. These results show that the performance gain of multiple users scheduling over single user scheduling increases when the total number of users in the network increases, and it can exceed 10% for high number of users.","Throughput,
Signal to noise ratio,
Fading,
Encoding,
Resource management,
Gain,
Optimization"
Relocating Underwater Features Autonomously Using Sonar-Based SLAM,"This paper describes a system for reacquiring features of interest in a shallow-water ocean environment, using autonomous underwater vehicles (AUVs) equipped with low-cost sonar and navigation sensors. In performing mine countermeasures, it is critical to enable AUVs to navigate accurately to previously mapped objects of interest in the water column or on the seabed, for further assessment or remediation. An important aspect of the overall system design is to keep the size and cost of the reacquisition vehicle as low as possible, as it may potentially be destroyed in the reacquisition mission. This low-cost requirement prevents the use of sophisticated AUV navigation sensors, such as a Doppler velocity log (DVL) or an inertial navigation system (INS). Our system instead uses the Proviewer 900-kHz imaging sonar from Blueview Technologies, which produces forward-looking sonar (FLS) images at ranges up to 40 mat approximately 4 Hz. In large volumes, it is hoped that this sensor can be manufactured at low cost. Our approach uses a novel simultaneous localization and mapping (SLAM) algorithm that detects and tracks features in the FLS images to renavigate to a previously mapped target. This feature-based navigation (FBN) system incorporates a number of recent advances in pose graph optimization algorithms for SLAM. The system has undergone extensive field testing over a period of more than four years, demonstrating the potential for the use of this new approach for feature reacquisition. In this report, we review the methodologies and components of the FBN system, describe the system's technological features, review the performance of the system in a series of extensive in-water field tests, and highlight issues for future research.","Vehicles,
Sonar,
Feature extraction,
Simultaneous localization and mapping,
Sonar navigation,
Oceans"
Learning Doubly Sparse Transforms for Images,"The sparsity of images in a transform domain or dictionary has been exploited in many applications in image processing. For example, analytical sparsifying transforms, such as wavelets and discrete cosine transform (DCT), have been extensively used in compression standards. Recently, synthesis sparsifying dictionaries that are directly adapted to the data have become popular especially in applications such as image denoising. Following up on our recent research, where we introduced the idea of learning square sparsifying transforms, we propose here novel problem formulations for learning doubly sparse transforms for signals or image patches. These transforms are a product of a fixed, fast analytic transform such as the DCT, and an adaptive matrix constrained to be sparse. Such transforms can be learnt, stored, and implemented efficiently. We show the superior promise of our learnt transforms as compared with analytical sparsifying transforms such as the DCT for image representation. We also show promising performance in image denoising that compares favorably with approaches involving learnt synthesis dictionaries such as the K-SVD algorithm. The proposed approach is also much faster than K-SVD denoising.","Dictionaries,
Analytical models,
Sparse matrices,
Algorithm design and analysis,
Convergence,
Discrete cosine transforms"
Duty-Cycle-Aware Minimum-Energy Multicasting in Wireless Sensor Networks,"In duty-cycled wireless sensor networks, the nodes switch between active and dormant states, and each node may determine its active/dormant schedule independently. This complicates the Minimum-Energy Multicasting (MEM) problem, which was primarily studied in always-active wireless ad hoc networks. In this paper, we study the duty-cycle-aware MEM problem in wireless sensor networks both for one-to-many multicasting and for all-to-all multicasting. In the case of one-to-many multicasting, we present a formalization of the Minimum-Energy Multicast Tree Construction and Scheduling (MEMTCS) problem. We prove that the MEMTCS problem is NP-hard, and it is unlikely to have an approximation algorithm with a performance ratio of (1 - 0(1)) ln Δ, where Δ is the maximum node degree in a network. We propose a polynomial-time approximation algorithm for the MEMTCS problem with a performance ratio of O (H(Δ + 1)), where H(·) is the harmonic number. In the case of all-to-all multicasting, we prove that the Minimum-Energy Multicast Backbone Construction and Scheduling (MEMBCS) problem is also NP-hard and present an approximation algorithm for it, which has the same approximation ratio as that of the proposed algorithm for the MEMTCS problem. We also provide a distributed implementation of our algorithms, as well as a simple but efficient collision-free scheduling scheme to avoid packet loss. Finally, we perform extensive simulations, and the results demonstrate that our algorithms significantly outperform other known algorithms in terms of the total transmission energy cost, without sacrificing much of the delay performance.",
Noninvasive vascular elastography using plane-wave and sparse-array imaging,"Stroke may occur when an atherosclerotic plaque ruptures in the carotid artery. Noninvasive vascular elastography (NIVE) visualizes the strain distribution within the carotid artery, which is related to its mechanical properties that govern plaque rupture. Strain elastograms obtained from the transverse plane of the carotid artery are difficult to interpret, because strain is estimated in Cartesian coordinates. Sparsearray (SA) elastography overcomes this problem by transforming shear and normal strain to polar coordinates. However, the SA's transmit power may be too weak to produce useful elastograms in the clinical setting. Consequently, we are exploring other imaging methods to solve this potential problem. This study evaluated the quality of elastograms produced with SA imaging, plane-wave (PW) imaging, and compounded-plane-wave (CPW) imaging. We performed studies on simulated and physical vessel phantoms, and the carotid artery of a healthy volunteer. All echo imaging was performed with a linear transducer array that contained 128 elements, operating at 5 MHz. In SA imaging, 7 elements were fired during transmission, but all 128 elements were active during reception. In PW imaging, all 128 elements were active during both transmission and reception. We created CPW images by steering the acoustic beam within the range of -15° to 15° in increments of 5°. SA radial and circumferential strain elastograms were comparable to those produced using PW and CPW imaging. Additionally, side-lobe levels incurred during SA imaging were 20 dB lower than those produced during PW imaging, and 10 dB lower than those computed using CPW imaging. Overall, SA imaging performs well in vivo; therefore, we plan to improve the technique and perform preclinical studies.",
Low-Common Mode Voltage H-Bridge Converter with Additional Switch Legs,"H-bridge converter with additional switch legs (HA converter) and its offspring circuit are proposed in this paper with the intent to reduce the common mode noise. The proposed topology connects grounds of the input and output terminals, which gives zero common mode current in the ideal case. The operation of the proposed circuit is flexible and allows for the circuit to be capable of both ac–dc and dc–ac conversions. The proposed topology is especially advantageous when it is applied to the photovoltaic power conditioning system in dc distribution system or stand-alone power system because they include large stray capacitances and are prone to common mode EMI. In this paper, a 4-switch HA (HA4S) converter for both ac–dc rectification and dc–ac inversion is derived from the proposed HA converter as the implementation example. The experimental results based on the proposed and the conventional prototype circuits prove that the HA4S converter outperforms the conventional counterparts.",
Chance-Constrained Optimization of Demand Response to Price Signals,"Household-based demand response is expected to play an increasing role in supporting the large scale integration of renewable energy generation in existing power systems and electricity markets. While the direct control of the consumption level of households is envisaged as a possibility, a credible alternative is that of indirect control based on price signals to be sent to these end-consumers. A methodology is described here allowing to estimate in advance the potential response of flexible end-consumers to price variations, subsequently embedded in an optimal price-signal generator. In contrast to some real-time pricing proposals in the literature, here prices are estimated and broadcast once a day for the following one, for households to optimally schedule their consumption. The price-response is modeled using stochastic finite impulse response (FIR) models. Parameters are estimated within a recursive least squares (RLS) framework using data measurable at the grid level, in an adaptive fashion. Optimal price signals are generated by embedding the FIR models within a chance-constrained optimization framework. The objective is to keep the price signal as unchanged as possible from the reference market price, whilst keeping consumption below a pre-defined acceptable level.",
User-Adaptive Sketch-Based 3-D CAD Model Retrieval,"3-D CAD models are an important digital resource in the manufacturing industry. 3-D CAD model retrieval has become a key technology in product lifecycle management enabling the reuse of existing design data. In this paper, we propose a new method to retrieve 3-D CAD models based on 2-D pen-based sketch inputs. Sketching is a common and convenient method for communicating design intent during early stages of product design, e.g., conceptual design. However, converting sketched information into precise 3-D engineering models is cumbersome, and much of this effort can be avoided by reuse of existing data. To achieve this purpose, we present a user-adaptive sketch-based retrieval method in this paper. The contributions of this work are twofold. First, we propose a statistical measure for CAD model retrieval: the measure is based on sketch similarity and accounts for users' drawing habits. Second, for 3-D CAD models in the database, we propose a sketch generation pipeline that represents each 3-D CAD model by a small yet sufficient set of sketches that are perceptually similar to human drawings. User studies and experiments that demonstrate the effectiveness of the proposed method in the design process are presented.",
Linear Precoder Design for MIMO Interference Channels with Finite-Alphabet Signaling,"This paper investigates the linear precoder design for K-user interference channels of multiple-input multiple-output (MIMO) transceivers under finite alphabet inputs. We first obtain general explicit expressions of the achievable rate for users in the MIMO interference channel systems. We study optimal transmission strategies in both low and high signal-to-noise ratio (SNR) regions. Given finite alphabet inputs, we show that a simple power allocation design achieves optimal performance at high SNR whereas the well-known interference alignment technique for Gaussian inputs only utilizes a partial interference-free signal space for transmission and leads to a constant rate loss when applied naively to finite-alphabet inputs. Moreover, we establish necessary conditions for the linear precoder design to achieve weighted sum-rate maximization. We also present an efficient iterative algorithm for determining precoding matrices of all the users. Our numerical results demonstrate that the proposed iterative algorithm achieves considerably higher sum-rate under practical QAM inputs than other known methods.",
Fourth-Order Statistics for Blind Classification of Spatial Multiplexing and Alamouti Space-Time Block Code Signals,"Blind signal classification, a major task of intelligent receivers, has important civilian and military applications. This problem becomes more challenging in multi-antenna scenarios due to the diverse transmission schemes that can be employed, e.g., spatial multiplexing (SM) and space-time block codes (STBCs). This paper presents a class of novel algorithms for blind classification of SM and Alamouti STBC (AL-STBC) transmissions. Unlike the prior art, we show that signal classification can be performed using a single receive antenna by taking advantage of the space-time redundancy. The first proposed algorithm relies on the fourth-order moment as a discriminating feature and employs the likelihood ratio test for achieving maximum average probability of correct classification. This requires knowledge of the channel coefficients, modulation type, and noise power. To avoid this drawback, three algorithms have been further developed. Their common idea is that the discrete Fourier transform of the fourth-order lag product exhibits peaks at certain frequencies for the AL-STBC signals, but not for the SM signals, and thus, provides the basis of a useful discriminating feature for signal classification. The effectiveness of these algorithms has been demonstrated in extensive simulation experiments, where a Nakagami-m fading channel and the presence of timing and frequency offsets are assumed.",
Intelligence-Based Supervisory Control for Optimal Operation of a DCS-Controlled Grinding System,"Optimizing the final grinding production indices (GPIs), which include the product particle size and the grinding production rate, to meet the overall manufacturing performance requirements is the main function of automatic control of a grinding circuit (GC). However, the complex and time-varying nature of the GC process dictates that these GPIs cannot be optimized solely by the lower-level distributed control systems (DCS), therefore an operator is often incorporated to manually determine the set-points for the DCS using his/her operational experience. With a human being involved, the performance and even the safety and stability of the GC operation is subject to human errors. Focusing on this practical challenge, this paper proposes an intelligence-based supervisory control strategy that consists of a control loop set-point optimization module, an artificial neural network-based soft-sensor module, a fuzzy logic-based dynamic adjustor, and an expert-based overload diagnosis and adjustment module to perform the control tasks for the GC system. This hybrid system can automatically adjust the set-points for the DCS-controlled grinding system in response to the changes in boundary conditions or the imminent overload conditions, thereby eliminating the need for an operator. Practical applications have shown the validity and effectiveness of the proposed approach.",
Optimal sampling-based planning for linear-quadratic kinodynamic systems,"We propose a new method for applying RRT* to kinodynamic motion planning problems by using finite-horizon linear quadratic regulation (LQR) to measure cost and to extend the tree. First, we introduce the method in the context of arbitrary affine dynamical systems with quadratic costs. For these systems, the algorithm is shown to converge to optimal solutions almost surely. Second, we extend the algorithm to non-linear systems with non-quadratic costs, and demonstrate its performance experimentally.","Trajectory,
Heuristic algorithms,
Planning,
Equations,
Cost function,
Aerospace electronics,
Dynamics"
A Decentralized Service Discovery Approach on Peer-to-Peer Networks,"Service-Oriented Computing (SOC) is emerging as a paradigm for developing distributed applications. A critical issue of utilizing SOC is to have a scalable, reliable, and robust service discovery mechanism. However, traditional service discovery methods using centralized registries can easily suffer from problems such as performance bottleneck and vulnerability to failures in large scalable service networks, thus functioning abnormally. To address these problems, this paper proposes a peer-to-peer-based decentralized service discovery approach named Chord4S. Chord4S utilizes the data distribution and lookup capabilities of the popular Chord to distribute and discover services in a decentralized manner. Data availability is further improved by distributing published descriptions of functionally equivalent services to different successor nodes that are organized into virtual segments in the Chord4S circle. Based on the service publication approach, Chord4S supports QoS-aware service discovery. Chord4S also supports service discovery with wildcard(s). In addition, the Chord routing protocol is extended to support efficient discovery of multiple services with a single query. This enables late negotiation of Service Level Agreements (SLAs) between service consumers and multiple candidate service providers. The experimental evaluation shows that Chord4S achieves higher data availability and provides efficient query with reasonable overhead.","Quality of service,
Peer to peer computing,
Web services,
System-on-a-chip,
Availability,
Postal services,
Servers"
Hardware Trojan Insertion by Direct Modification of FPGA Configuration Bitstream,"In this work, we have demonstrated the feasibility of hardware Trojan insertion in circuits mapped on FPGAs by direct modification of the FPGA configuration bitstream. The main challenge of this attack proved to be the lack of sufficient information in the public domain about the bitstream format and the internal architecture and configurability of the FPGA. Nevertheless, we were able to show that under certain constraints on the functionality, size and placement of the Trojan on the FPGA, it is possible to modify the configuration bitstream by a software program to insert a hardware Trojan in the design. The main strength of the attack lies in the fact that since the modification is at the configuration bitstream level, it bypasses all predeployment design validation mechanisms. We also propose some techniques to prevent the demonstrated attack. We hope that this work will raise awareness among FPGA users about the potency of the threat posed by this relatively simple attack and its improved variants. .",
Differentially private grids for geospatial data,"In this paper, we tackle the problem of constructing a differentially private synopsis for two-dimensional datasets such as geospatial datasets. The current state-of-the-art methods work by performing recursive binary partitioning of the data domains, and constructing a hierarchy of partitions. We show that the key challenge in partition-based synopsis methods lies in choosing the right partition granularity to balance the noise error and the non-uniformity error. We study the uniform-grid approach, which applies an equi-width grid of a certain size over the data domain and then issues independent count queries on the grid cells. This method has received no attention in the literature, probably due to the fact that no good method for choosing a grid size was known. Based on an analysis of the two kinds of errors, we propose a method for choosing the grid size. Experimental results validate our method, and show that this approach performs as well as, and often times better than, the state-of-the-art methods. We further introduce a novel adaptive-grid method. The adaptive grid method lays a coarse-grained grid over the dataset, and then further partitions each cell according to its noisy count. Both levels of partitions are then used in answering queries over the dataset. This method exploits the need to have finer granularity partitioning over dense regions and, at the same time, coarse partitioning over sparse regions. Through extensive experiments on real-world datasets, we show that this approach consistently and significantly outperforms the uniform-grid method and other state-of-the-art methods.",
Mitigate DDoS attacks in NDN by interest traceback,"Current Internet is reaching the limits of its capabilities due to its function transition from host-to-host communication to content dissemination. Named Data Networking (NDN) - an instantiation of Content-Centric Networking approach, embraces this shift by stressing the content itself, rather than where it locates. NDN tries to provide better security and privacy than current Internet does, and resilience to Distributed Denial of Service (DDoS) is a significant issue. In this paper, we present a specific and concrete scenario of DDoS attack in NDN, where perpetrators make use of NDN's packet forwarding rules to send out Interest packets with spoofed names as attacking packets. Afterwards, we identify the victims of NDN DDoS attacks include both the hosts and routers. But the largest victim is not the hosts, but the routers, more specifically, the Pending Interest Table (PIT) within the router. PIT brings NDN many elegant features, but it suffers from vulnerability. We propose Interest traceback as a counter measure against the studied NDN DDoS attacks, which traces back to the originator of the attacking Interest packets. At last, we assess the harmful consequences brought by these NDN DDoS attacks and evaluate the Interest traceback counter measure. Evaluation results reveal that the Interest traceback method effectively mitigates the NDN DDoS attacks studied in this paper.","Computer crime,
IP networks,
Radiation detectors,
Memory management,
Routing,
Internet,
Servers"
An Energy Efficient Key Management Scheme for Body Sensor Networks,"Body sensor networks (BSNs) are distributed systems where biosensor nodes are distributed in different positions to collect health data from the human body and deliver the information to a remote medical center. Due to medical data regulations, security of BSNs is very important. However, the operational resources of biosensor nodes in BSNs are very restricted, and traditional security technologies are not directly applicable to BSNs. Due to characteristics of biosensors, time synchronization and low-energy communication are two challenging problems for BSNs. In this paper, a fuzzy commitment technology with weak time synchronization mechanism for keys negotiation is developed, with a multihop route key management scheme proposed for efficient energy consumption management, including an energy-based multihop-route-choice method. Security analyses and performance evaluation have been provided to validate the proposed scheme.","Biosensors,
Synchronization,
Personal digital assistants,
Security,
Biometrics (access control),
Energy consumption,
Peer to peer computing"
Information Processing Using Transient Dynamics of Semiconductor Lasers Subject to Delayed Feedback,"The increasing amount of data being generated in different areas of science and technology require novel and efficient techniques of processing, going beyond traditional concepts. In this paper, we numerically study the information processing capabilities of semiconductor lasers subject to delayed optical feedback. Based on the recent concept of reservoir computing, we show that certain tasks, which are inherently hard for traditional computers, can be efficiently tackled by such systems. Major advantages of this approach comprise the possibility of simple and low-cost hardware implementation of the reservoir and ultrafast processing speed. Experimental results corroborate the numerical predictions.","Laser feedback,
Semiconductor lasers,
Optical feedback,
Reservoirs,
Optical polarization,
Adaptive optics,
Laser modes"
A self-adaptive heterogeneous pso for real-parameter optimization,"Heterogeneous particle swarm optimizers (HPSO) allow particles to use different update equations, referred to as behaviors, within the swarm. Dynamic HPSOs allow the particles to change their behaviors during the search. These HPSOs alter the exploration/exploitation balance during the search which alters the search behavior of the swarm. This paper introduces a new self-adaptive HPSO and compares it with other HPSO algorithms on the CEC 2013 real-parameter optimization benchmark functions. The proposed algorithm keeps track of how successful each behavior has been over a number of iterations and uses that information to select the next behavior of a particle. The results show that the proposed algorithm outperforms existing HPSO algorithms on the benchmark functions.","Benchmark testing,
Mathematical model,
Acceleration,
Tuning,
Equations,
Algorithm design and analysis,
Optimization"
Ultralow Leakage Current AlGaN/GaN Schottky Diodes With 3-D Anode Structure,"We demonstrate ultralow leakage current AlGaN/GaN Schottky-barrier diodes (SBDs) based on a 3-D anode contact. In contrast to conventional AlGaN/GaN SBDs, this new device forms a Schottky contact directly to the 2-D electron gas (2-DEG) at the sidewalls of the 3-D anode structure to improve its turn-on characteristics. In addition, this device integrates an insulated trigate MOS structure to reduce its reverse-bias leakage current. By optimizing this new technology, we demonstrate SBDs with 3-D anode structures with turn-on voltage of 0.85 V, ON-resistance of 5.96 Ωmm and ideality factor of 1.27. The reverse-bias leakage current was significantly reduced by nearly four orders of magnitude, down to 260 pA/mm, with a breakdown voltage of up to 127 V for a distance of 1.5 μm between the cathode and anode electrodes. To the best of our knowledge, this is among the lowest leakage currents reported in lateral AlGaN/GaN SBDs fabricated on silicon substrate.","Anodes,
Leakage currents,
Aluminum gallium nitride,
Schottky diodes,
Gallium nitride,
MOSFET,
Junctions"
Cooperative caching through routing control in information-centric networks,"Information-centric network (ICN), which is one of the prominent Internet re-design architectures, relies on in-network caching for its fundamental operation. However, previous works argue that the performance of in-network caching is highly degraded with the current cache-along-default-path design, which makes popular objects to be cached redundantly in many places. Thus, it would be beneficial to have a distributed and uncoordinated design. Although cooperative caches could be an answer to this, previous research showed that they are generally unfeasible due to excessive signaling burden, protocol complexity, and a need for fault tolerance. In this work we illustrate the ICN caching problem, and propose a novel architecture to overcome the problem of uncooperative caches. Our design possesses the cooperation property intrinsically. We utilize controlled off-path caching to achieve almost 9-fold increase in cache efficiency, and around 20% increase in server load reduction when compared to the classic on-path caching used in ICN proposals.","Servers,
Routing,
Indexes,
Internet,
Sociology,
Statistics,
Network topology"
Main-memory hash joins on multi-core CPUs: Tuning to the underlying hardware,"The architectural changes introduced with multi-core CPUs have triggered a redesign of main-memory join algorithms. In the last few years, two diverging views have appeared. One approach advocates careful tailoring of the algorithm to the architectural parameters (cache sizes, TLB, and memory bandwidth). The other approach argues that modern hardware is good enough at hiding cache and TLB miss latencies and, consequently, the careful tailoring can be omitted without sacrificing performance. In this paper we demonstrate through experimental analysis of different algorithms and architectures that hardware still matters. Join algorithms that are hardware conscious perform better than hardware-oblivious approaches. The analysis and comparisons in the paper show that many of the claims regarding the behavior of join algorithms that have appeared in literature are due to selection effects (relative table sizes, tuple sizes, the underlying architecture, using sorted data, etc.) and are not supported by experiments run under different parameters settings. Through the analysis, we shed light on how modern hardware affects the implementation of data operators and provide the fastest implementation of radix join to date, reaching close to 200 million tuples per second.","Hardware,
Probes,
Latches,
Partitioning algorithms,
Tuning,
Instruction sets,
Algorithm design and analysis"
Statistic and Parallel Testing Procedure for Evaluating Maximum Power Point Tracking Algorithms of Photovoltaic Power Systems,"Maximum power point tracking (MPPT) methods are essential for photovoltaic (PV) systems to take full advantage of the available solar energy. Over the past few years, an increasing number of new MPPT methods have been proposed in the literature, and they show better capability of capturing the maximum power point. The testing and evaluation procedure of any new MPPT method is a crucial step for assessing its robustness and performance. PV panel manufacturers always specify power output tolerances, ranging from ±2% to ±5%. Thus, nonideal factors might dominate the subsystem output and defeat any performance comparison attempt and might lead to inaccurate results. This paper highlights the main shortcomings of previous MPPT testing procedures and proposes a comprehensive testing approach using paired difference tests to evaluate the performance of MPPT. The dual channel bench system demonstrates a systematic framework to deal with the nonideal factors associated with PV manufacturing, quantify experimental data, and correctly illustrate the performance improvement of MPPT. The case study shows that the 1% improvement of MPPT could be easily overshadowed by the nonideal factors shown previously. The proposed test setup and analysis method provide the effective solution for evaluating the MPPT performance.","statistical testing,
maximum power point trackers,
photovoltaic power systems,
solar power stations"
AMUSE: Empowering users for cost-aware offloading with throughput-delay tradeoffs,"Mobile users face a tradeoff between cost, throughput, and delay in making their offloading decisions. To navigate this tradeoff, we propose AMUSE (Adaptive bandwidth Management through USer-Empowerment), a practical, costaware WiFi offloading system that takes into account a user's throughput-delay tradeoffs and cellular budget constraint. Based on predicted future usage and WiFi availability, AMUSE decides which applications to offload to what times of the day. To practically enforce the assigned rate of each TCP application, we introduce a receiver-side TCP bandwidth control algorithm that adjusts the rate by controlling the TCP advertisement window from the user side. We implement AMUSE on Windows 7 tablets and evaluate its effectiveness with 3G and WiFi usage data obtained from a trial with 25 mobile users. Our results show that AMUSE improves user utility.","IEEE 802.11 Standards,
Bandwidth,
Prediction algorithms,
Delays,
Throughput,
Mobile communication,
Educational institutions"
A contextual approach towards more accurate duplicate bug report detection,"Bug-tracking and issue-tracking systems tend to be populated with bugs, issues, or tickets written by a wide variety of bug reporters, with different levels of training and knowledge about the system being discussed. Many bug reporters lack the skills, vocabulary, knowledge, or time to efficiently search the issue tracker for similar issues. As a result, issue trackers are often full of duplicate issues and bugs, and bug triaging is time consuming and error prone. Many researchers have approached the bug-deduplication problem using off-the-shelf information-retrieval tools, such as BM25F used by Sun et al. In our work, we extend the state of the art by investigating how contextual information, relying on our prior knowledge of software quality, software architecture, and system-development (LDA) topics, can be exploited to improve bug-deduplication. We demonstrate the effectiveness of our contextual bug-deduplication method on the bug repository of the Android ecosystem. Based on this experience, we conclude that researchers should not ignore the context of software engineering when using IR tools for deduplication.","Androids,
Humanoid robots,
Computer bugs,
Software,
Context,
Sun,
Accuracy"
Nonuniform Compressive Sensing for Heterogeneous Wireless Sensor Networks,"In this paper, we consider the problem of using wireless sensor networks (WSNs) to measure the temporal-spatial profile of some physical phenomena. We base our work on two observations. First, most physical phenomena are compressible in some transform domain basis. Second, most WSNs have some form of heterogeneity. Given these two observations, we propose a nonuniform compressive sensing method to improve the performance of WSNs by exploiting both compressibility and heterogeneity. We apply our proposed method to real WSN data sets. We find that our method can provide a more accurate temporal-spatial profile for a given energy budget compared with other sampling methods.","Wireless sensor networks,
Sensors,
Vectors,
Compressed sensing,
Wind speed,
Transforms,
Energy consumption"
A Novel Approach for Lung Nodules Segmentation in Chest CT Using Level Sets,"A new variational level set approach is proposed for lung nodule segmentation in lung CT scans. A general lung nodule shape model is proposed using implicit spaces as a signed distance function. The shape model is fused with the image intensity statistical information in a variational segmentation framework. The nodule shape model is mapped to the image domain by a global transformation that includes inhomogeneous scales, rotation, and translation parameters. A matching criteria between the shape model and the image implicit representations is employed to handle the alignment process. Transformation parameters evolve through gradient descent optimization to handle the shape alignment process and hence mark the boundaries of the nodule “head.” The embedding process takes into consideration the image intensity as well as prior shape information. A nonparametric density estimation approach is employed to handle the statistical intensity representation of the nodule and background regions. The proposed technique does not depend on nodule type or location. Exhaustive experimental and validation results are demonstrated on 742 nodules obtained from four different CT lung databases, illustrating the robustness of the approach.","Lungs,
Shape,
Image segmentation,
Level set,
Computed tomography,
Solid modeling,
Head"
THEMIS: A Mutually Verifiable Billing System for the Cloud Computing Environment,"With the widespread adoption of cloud computing, the ability to record and account for the usage of cloud resources in a credible and verifiable way has become critical for cloud service providers and users alike. The success of such a billing system depends on several factors: The billing transactions must have integrity and nonrepudiation capabilities; the billing transactions must be nonobstructive and have a minimal computation cost; and the service level agreement (SLA) monitoring should be provided in a trusted manner. Existing billing systems are limited in terms of security capabilities or computational overhead. In this paper, we propose a secure and nonobstructive billing system called THEMIS as a remedy for these limitations. The system uses a novel concept of a cloud notary authority for the supervision of billing. The cloud notary authority generates mutually verifiable binding information that can be used to resolve future disputes between a user and a cloud service provider in a computationally efficient way. Furthermore, to provide a forgery-resistive SLA monitoring mechanism, we devised a SLA monitoring module enhanced with a trusted platform module (TPM), called S-Mon. The performance evaluation confirms that the overall latency of THEMIS billing transactions (avg. 4.89 ms) is much shorter than the latency of public key infrastructure (PKI)-based billing transactions (avg. 82.51 ms), though THEMIS guarantees identical security features as a PKI. This work has been undertaken on a real cloud computing service called iCubeCloud.","Monitoring,
Cloud computing,
Protocols,
Digital signatures,
Computer architecture,
Grid computing"
Quantitative Study of Music Listening Behavior in a Social and Affective Context,"A scientific understanding of emotion experience requires information on the contexts in which the emotion is induced. Moreover, as one of the primary functions of music is to regulate the listener's mood, the individual's short-term music preference may reveal the emotional state of the individual. In light of these observations, this paper presents the first scientific study that exploits the online repository of social data to investigate the connections between a blogger's emotional state, user context manifested in the blog articles, and the content of the music titles the blogger attached to the post. A number of computational models are developed to evaluate the accuracy of different content or context cues in predicting emotional state, using 40,000 pieces of music listening records collected from the social blogging website LiveJournal. Our study shows that it is feasible to computationally model the latent structure underlying music listening and mood regulation. The average area under the receiver operating characteristic curve (AUC) for the content-based and context-based models attains 0.5462 and 0.6851, respectively. The association among user mood, music emotion, and individual's personality is also identified.","Web sites,
behavioural sciences computing,
music"
"Wireless Network-Coded Bidirectional Relaying Using Latin Squares for
M
-PSK Modulation","The design of modulation schemes for the physical layer network-coded two-way relaying scenario is considered with a protocol which employs two phases: multiple access (MA) phase and broadcast (BC) phase. It was observed by Koike-Akino et al. that adaptively changing the network coding map used at the relay according to the channel conditions greatly reduces the impact of MA interference which occurs at the relay during the MA phase and all these network coding maps should satisfy a requirement called the exclusive law. We show that every network coding map that satisfies the exclusive law is representable by a Latin Square and conversely, that this relationship can be used to get the network coding maps satisfying the exclusive law. The channel fade states for which the minimum distance of the effective constellation at the relay become zero are referred to as the singular fade states. For M- PSK modulation ( M any power of 2), it is shown that there are (M2/4- M/2+1 )M singular fade states. Also, it is shown that the constraints which the network coding maps should satisfy so that the harmful effects of the singular fade states are removed, can be viewed equivalently as partially filled Latin Squares (PFLS). The problem of finding all the required maps is reduced to finding a small set of maps for M- PSK constellations ( M any power of 2), obtained by the completion of PFLS. Even though the completability of M ×M PFLS using M symbols is an open problem, specific cases where such a completion is always possible are identified and explicit construction procedures are provided. Having obtained the network coding maps, the set of all possible channel realizations (the complex plane) is quantized into a finite number of regions, with a specific network coding map chosen in a particular region. It is shown that the complex plane can be partitioned into two regions: a region in which any network coding map which satisfies the exclusive law gives the same best performance and a region in which the choice of the network coding map affects the performance. The quantization thus obtained analytically, leads to the same as the one obtained using computer search for 4-PSK signal set by Koike-Akino et al. when specialized for Simulation results show that the proposed scheme performs better than the conventional exclusive-OR (XOR) network coding and in some cases outperforms the scheme proposed by Koike-Akino et al.","Network coding,
Relays,
Clustering algorithms,
Quantization (signal),
Computer numerical control,
Encoding,
Wireless communication"
Switch and Tap-Changer Reconfiguration of Distribution Networks Using Evolutionary Algorithms,"The reconfiguration of distribution networks is an important combinatorial problem. This work addresses the particular case of reconfiguration after an outage caused by the loss of a single branch of the network. The reconfiguration is carried out over two domains simultaneously: re-switching strategies and transformer tap-changer adjustments. The approach was tested using a real large-scale network within the concession area of Energy Australia. The model considers four operational elements: an AC power flow model, the network's radial topology when operating, voltage limits and load limits. Two evolutionary algorithms were implemented and tested. The first was a genetic algorithm, applied over the space of possible re-switching strategies, and for both re-switching and tap-changer adjustments, simultaneously. The second was a memetic algorithm, applied over the same two variations of the reconfiguration problem. Computational tests consider the evaluation of the loss of every branch, reporting the number of buses affected, and the number of overloaded branches after the reconfiguration.","Switches,
Memetics,
Australia,
Genetics,
Genetic algorithms,
Search problems,
Network topology"
Covariance Estimation in High Dimensions Via Kronecker Product Expansions,"This paper presents a new method for estimating high dimensional covariance matrices. The method, permuted rank-penalized least-squares (PRLS), is based on a Kronecker product series expansion of the true covariance matrix. Assuming an i.i.d. Gaussian random sample, we establish high dimensional rates of convergence to the true covariance as both the number of samples and the number of variables go to infinity. For covariance matrices of low separation rank, our results establish that PRLS has significantly faster convergence than the standard sample covariance matrix (SCM) estimator. The convergence rate captures a fundamental tradeoff between estimation error and approximation error, thus providing a scalable covariance estimation framework in terms of separation rank, similar to low rank approximation of covariance matrices . The MSE convergence rates generalize the high dimensional rates recently obtained for the ML Flip-flop algorithm , for Kronecker product covariance estimation. We show that a class of block Toeplitz covariance matrices is approximatable by low separation rank and give bounds on the minimal separation rank r that ensures a given level of bias. Simulations are presented to validate the theoretical bounds. As a real world application, we illustrate the utility of the proposed Kronecker covariance estimator for spatio-temporal linear least squares prediction of multivariate wind speed measurements.","Covariance matrices,
Convergence,
Symmetric matrices,
Estimation,
Least squares approximations,
Brain modeling,
Standards"
Gaussian Process Regression for Sensor Networks Under Localization Uncertainty,"In this paper, we formulate Gaussian process regression with observations under the localization uncertainty due to the resource-constrained sensor networks. In our formulation, effects of observations, measurement noise, localization uncertainty, and prior distributions are all correctly incorporated in the posterior predictive statistics. The analytically intractable posterior predictive statistics are proposed to be approximated by two techniques, viz., Monte Carlo sampling and Laplace's method. Such approximation techniques have been carefully tailored to our problems and their approximation error and complexity are analyzed. Simulation study demonstrates that the proposed approaches perform much better than approaches without considering the localization uncertainty properly. Finally, we have applied the proposed approaches on the experimentally collected real data from a dye concentration field over a section of a river and a temperature field of an outdoor swimming pool to provide proof of concept tests and evaluate the proposed schemes in real situations. In both simulation and experimental results, the proposed methods outperform the quick-and-dirty solutions often used in practice.","Gaussian processes,
Uncertainty,
Approximation methods,
Monte Carlo methods,
Robot sensing systems,
Vectors,
Mobile computing"
Measurement Bounds for Sparse Signal Ensembles via Graphical Models,"In compressive sensing, a small collection of linear projections of a sparse signal contains enough information to permit signal recovery. Distributed compressive sensing extends this framework by defining ensemble sparsity models, allowing a correlated ensemble of sparse signals to be jointly recovered from a collection of separately acquired compressive measurements. In this paper, we introduce a framework for modeling sparse signal ensembles that quantifies the intra- and intersignal dependences within and among the signals. This framework is based on a novel bipartite graph representation that links the sparse signal coefficients with the measurements obtained for each signal. Using our framework, we provide fundamental bounds on the number of noiseless measurements that each sensor must collect to ensure that the signals are jointly recoverable.","Technological innovation,
Sparse matrices,
Vectors,
Decoding,
Bipartite graph,
Compressed sensing,
Educational institutions"
On Budgeted Influence Maximization in Social Networks,"Given a fixed budget and an arbitrary cost for selecting each node, the budgeted influence maximization (BIM) problem concerns selecting a set of seed nodes to disseminate some information that maximizes the total number of nodes influenced (termed as influence spread) in social networks at a total cost no more than the budget. Our proposed seed selection algorithm for the BIM problem guarantees an approximation ratio of (1-1/√e). The seed selection algorithm needs to calculate the influence spread of candidate seed sets, which is known to be #P-complex. Identifying the linkage between the computation of marginal probabilities in Bayesian networks and the influence spread, we devise efficient heuristic algorithms for the latter problem. Experiments using both large-scale social networks and synthetically generated networks demonstrate superior performance of the proposed algorithm with moderate computation costs. Moreover, synthetic datasets allow us to vary the network parameters and gain important insights on the impact of graph structures on the performance of different algorithms.",
"Smart grid forensic science: applications, challenges, and open issues","Smart grid forensic science is a newly flourishing research area that is tightly coupled with cyber and physical security of the smart grid. Post-mortem analysis of a power system after a cyber attack or natural disaster generally provides the most accurate comprehension of the real-world vulnerabilities of the system and helps to protect the grid against similar attacks in the future as well as avoid failures during disasters. Besides increasing the security level of the smart grid, smart grid forensics aids evidence collection for the service of criminal justice. For instance, data extracted from smart meters and data collectors can provide evidence to legal proceedings in electricity theft matters. Furthermore, authentication and timestamping audio recordings using power grid frequency have been employed in several recent academic studies, as well as by the Metropolitan Police Forensic Audio Laboratory in London. Briefly, smart grid forensic science is emerging as a powerful security component of the power system. On the other hand, storage and processing of the enormous amount of data introduce significant challenges together with the privacy issue. In this article, we introduce the emerging application areas of smart grid forensic science, discuss the challenges, and outline the open issues in the topic. This article aims to serve as a roadmap for future smart grid forensic studies.",
A New Gradient Descent Approach for Local Learning of Fuzzy Neural Models,"The majority of reported learning methods for Takagi-Sugeno-Kang (TSK) fuzzy neural models to date mainly focus on improvement of their accuracy. However, one of the key design requirements in building an interpretable fuzzy model is that each obtained rule consequent must match well with the system local behavior when all the rules are aggregated to produce the overall system output. This is one of the distinctive characteristics from black-box models such as neural networks. Therefore, how to find a desirable set of fuzzy partitions and, hence, identify the corresponding consequent models which can be directly explained in terms of system behavior, presents a critical step in fuzzy neural modeling. In this paper, a new learning approach considering both nonlinear parameters in the rule premises and linear parameters in the rule consequents is proposed. Unlike the conventional two-stage optimization procedure widely practiced in the field where the two sets of parameters are optimized separately, the consequent parameters are transformed into a dependent set on the premise parameters, thereby enabling the introduction of a new integrated gradient descent learning approach. Thus, a new Jacobian matrix is proposed and efficiently computed to achieve a more accurate approximation of the cost function by using the second-order Levenberg-Marquardt optimization method. Several other interpretability issues regarding the fuzzy neural model are also discussed and integrated into this new learning approach. Numerical examples are presented to illustrate the resultant structure of the fuzzy neural models and the effectiveness of the proposed new algorithm, and compared with the results from some well-known methods.","Jacobian matrices,
Computational modeling,
Vectors,
Fuzzy neural networks,
Cost function"
A Two-Tiered On-Demand Resource Allocation Mechanism for VM-Based Data Centers,"In a shared virtual computing environment, dynamic load changes as well as different quality requirements of applications in their lifetime give rise to dynamic and various capacity demands, which results in lower resource utilization and application quality using the existing static resource allocation. Furthermore, the total required capacities of all the hosted applications in current enterprise data centers, for example, Google, may surpass the capacities of the platform. In this paper, we argue that the existing techniques by turning on or off servers with the help of virtual machine (VM) migration is not enough. Instead, finding an optimized dynamic resource allocation method to solve the problem of on-demand resource provision for VMs is the key to improve the efficiency of data centers. However, the existing dynamic resource allocation methods only focus on either the local optimization within a server or central global optimization, limiting the efficiency of data centers. We propose a two-tiered on-demand resource allocation mechanism consisting of the local and global resource allocation with feedback to provide on-demand capacities to the concurrent applications. We model the on-demand resource allocation using optimization theory. Based on the proposed dynamic resource allocation mechanism and model, we propose a set of on-demand resource allocation algorithms. Our algorithms preferentially ensure performance of critical applications named by the data center manager when resource competition arises according to the time-varying capacity demands and the quality of applications. Using Rainbow, a Xen-based prototype we implemented, we evaluate the VM-based shared platform as well as the two-tiered on-demand resource allocation mechanism and algorithms. The experimental results show that Rainbow without dynamic resource allocation (Rainbow-NDA) provides 26 to 324 percent improvements in the application performance, as well as 26 percent higher average CPU utilization than traditional service computing framework, in which applications use exclusive servers. The two-tiered on-demand resource allocation further improves performance by 9 to 16 percent for those critical applications, 75 percent of the maximum performance improvement, introducing up to 5 percent performance degradations to others, with 1 to 5 percent improvements in the resource utilization in comparison with Rainbow-NDA.",
Differential estimation in dynamic RFID systems,"Efficient estimation of tag population in RFID systems has many important applications. In this paper, we present a new problem called differential cardinality estimation, which tracks the population changes in a dynamic RFID system where tags are frequently moved in and out. In particular, we want to provide quick estimation on (1) the number of new tags that are moved in and (2) the number of old tags that are moved out, between any two consecutive scans of the system. We show that the traditional cardinality estimators cannot be applied here, and the tag identification protocols are too expensive if the estimation needs to be performed frequently in order to support real-time monitoring. This paper presents the first efficient solution for the problem of differential cardinality estimation. The solution is based on a novel differential estimation framework, and is named zero differential estimator. We show that this estimator can be configured to meet any pre-set accuracy requirement, with a probabilistic error bound that can be made arbitrarily small.","Radiofrequency identification,
Sociology,
Statistics,
Estimation error,
Accuracy,
Protocols"
Security Concerns in Popular Cloud Storage Services,"The authors provide a systematic security analysis on the sharing methods of three major cloud storage and synchronization services: Dropbox, Google Drive, and Microsoft SkyDrive. They show that all three services have security weaknesses that may result in data leakage without users' awareness.","Cloud computing,
Computer security,
Electronic mail,
Cryptography,
Storage automation,
Privacy"
Motion Estimation Using the Correlation Transform,"The zero-mean normalized cross-correlation is shown to improve the accuracy of optical flow, but its analytical form is quite complicated for the variational framework. This paper addresses this issue and presents a new direct approach to this matching measure. Our approach uses the correlation transform to define very discriminative descriptors that are pre-computed and that have to be matched in the target frame. It is equivalent to the computation of the optical flow for the correlation transforms of the images. The smoothness energy is non-local and uses a robust penalty in order to preserve motion discontinuities. The model is associated with a fast and parallelizable minimization procedure based on the projected-proximal point algorithm. The experiments confirm the strength of this model and implicitly demonstrate the correctness of our solution. The results demonstrate that the involved data term is very robust with respect to changes in illumination, especially where large illumination exists.","wavelet transforms,
correlation theory,
image matching,
image sequences,
minimisation,
motion estimation,
variational techniques"
Making Solar Cells a Reality in Every Home: Opportunities and Challenges for Photovoltaic Device Design,"Globally, the cumulative installed photovoltaic (PV) capacity has topped the 100-gigawatt (GW) milestone and is expected to reach 200 GW by the year 2015. More than 90% of the installed PV capacity employs bulk-silicon solar cells. Engineering problems that include thermal and optical challenges have not permitted the large-scale commercialization of concentration PV systems, lack of functional reliability-and the concomitant lack of economic bankability-being a major barrier. For increasing the efficiency of single-junction cells beyond the Shockley-Queisser limit, several approaches based on concepts such as multiple exciton generation, carrier multiplication, hot-carrier extraction, etc., have been proposed; however, these do not seem to be commercially viable. Since both bulk-silicon and thin-film (amorphous silicon, cadmium telluride, and copper indium gallium selenide) solar cells remain as the only two commercially viable options for terrestrial PV applications, a multi-terminal multi-junction architecture appears promising for inexpensive PV electricity generation with efficiency exceeding the currently feasible 25%. The architecture exploits the present commercial silicon solar cells along with abundant and ultra-low-cost materials such as Cu2O. With the availability of well-controlled manufacturing processes at the sub 2-nm length scale, it will become possible to manufacture ultra-high efficiency and ultra-low cost PV electricity generation modules based on silicon.","Photovoltaic cells,
Silicon,
Electricity,
Manufacturing,
Computer architecture,
Photovoltaic systems"
Intelligent Economic Operation of Smart-Grid Facilitating Fuzzy Advanced Quantum Evolutionary Method,"This paper presents an intelligent economic operation of smart grid environment facilitating an advanced quantum evolutionary method. The proposed method models the wind generation (WG) and photovoltaic (PV) generation as renewable power generation sources as a measure of global warming effect. Thermal generators (TGs) are included in this model to provide the maximum amount of energy to meet consumers' demand. On the other hand, plug-in hybrid electric vehicles (PHEVs) are capable of reducing CO 2, NO x, and gradually becoming an integral part of smart-grid infrastructure. Such integration introduces uncertainties into the system that are addressed by fuzzy-logic-based formulations. Demanded load, wind speed, solar radiation, and number of involved PHEVs are taken under fuzzy formulations. An intelligent quantum inspired evolutionary algorithm (IQEA) is proposed and applied in this model to perform the intelligent economic scheduling operation concerning scheduling and dispatching TG, WG, PV, and PHEV. IQEA features intelligent operators such as sophisticated rotation operator, differential operator, etc. The method is tested on a hypothetical power system with 10 thermal units, equivalent number of PHEVs, equivalent solar and wind farm. The simulation results will show the effectiveness of IQEA that provides excellent operational resource scheduling while reducing the production cost and emission.","Smart grids,
Fuzzy logic,
Hybrid electric vehicles,
Solar power generation,
Wind power generation"
Benefits of Network Coding for Unicast Application in Disruption-Tolerant Networks,"In this paper, we investigate the benefits of applying a form of network coding known as random linear coding (RLC) to unicast applications in disruption-tolerant networks (DTNs). Under RLC, nodes store and forward random linear combinations of packets as they encounter each other. For the case of a single group of packets originating from the same source and destined for the same destination, we prove a lower bound on the probability that the RLC scheme achieves the minimum time to deliver the group of packets. Although RLC significantly reduces group delivery delays, it fares worse in terms of average packet delivery delay and network transmissions. When replication control is employed, RLC schemes reduce group delivery delays without increasing the number of transmissions. In general, the benefits achieved by RLC are more significant under stringent resource (bandwidth and buffer) constraints, limited signaling, highly dynamic networks, and when applied to packets in the same flow. For more practical settings with multiple continuous flows in the network, we show the importance of deploying RLC schemes with a carefully tuned replication control in order to achieve reduction in average delay, which is observed to be as large as 20% when buffer space is constrained.","Routing,
Delay,
Unicast,
Encoding,
Network coding,
Vectors,
Peer to peer computing"
Precise tweet classification and sentiment analysis,"The rise of social media in couple of years has changed the general perspective of networking, socialization, and personalization. Use of data from social networks for different purposes, such as election prediction, sentimental analysis, marketing, communication, business, and education, is increasing day by day. Precise extraction of valuable information from short text messages posted on social media (Twitter) is a collaborative task. In this paper, we analyze tweets to classify data and sentiments from Twitter more precisely. The information from tweets are extracted using keyword based knowledge extraction. Moreover, the extracted knowledge is further enhanced using domain specific seed based enrichment technique. The proposed methodology facilitates the extraction of keywords, entities, synonyms, and parts of speech from tweets which are then used for tweets classification and sentimental analysis. The proposed system is tested on a collection of 40,000 tweets. The proposed methodology has performed better than the existing system in terms of tweets classification and sentiment analysis. By applying the Knowledge Enhancer and Synonym Binder module on the extracted information we have achieved increase in information gain in a range of 0.1% to 55%. The increase in information gain has enabled our proposed system to better summarize the twitter data for user sentiments regarding a keyword from a particular category.",
Wakeup scheduling for energy-efficient communication in opportunistic mobile networks,"Opportunistic mobile networks consist of mobile devices which only communicate when they opportunistically contact each other. Periodic contact probing is required to facilitate opportunistic communication, but seriously reduces the limited battery life of mobile devices. Current research efforts on reducing energy consumption of contact probing are restricted to optimize the probing interval, but are insufficient for energy-efficient opportunistic communication. In this paper, we propose novel techniques to adaptively schedule wakeup periods of mobile nodes between their inter-contact times. A node stays asleep during inter-contact times when contact probing is unnecessary, and only wakes up when a contact with another node is likely to happen. Our approach probabilistically predicts node contacts in the future, and analytically balances between energy consumption for contact probing and performance of opportunistic communication. Extensive trace-driven simulations show that our approach significantly improves energy efficiency of opportunistic communication compared to existing schemes.","Schedules,
Energy consumption,
Peer-to-peer computing,
Mobile computing,
Mobile nodes"
A Fast Rendezvous Channel-Hopping Algorithm for Cognitive Radio Networks,"Cognitive radio networks (CRNs) have emerged as a critical technique to enhance the utilization of licensed channels. In CRNs, each secondary user (SU) should not interfere the co-locate incumbent networks. For this purpose, before data transmission, SUs should rendezvous on an available channel (i.e., idle and licensed channel) for establishing a link or exchanging control information. However, implementation of rendezvous is challenging since SUs are not aware of the presence of each other before rendezvous and available channels sensed by each SU may be different. In this paper, we proposed a fast rendezvous channel hopping algorithm (FRCH), which can guarantee rendezvous within 2N2 + N timeslots under asynchronous environments, where N denotes the number of licensed channels in a CRN.","Cognitive radio,
Availability,
Sensors,
Measurement,
Adaptation models,
Radio networks,
Indexes"
A Game-Theoretic Approach to Stimulate Cooperation for Probabilistic Routing in Opportunistic Networks,"Opportunistic networking is an important technique to enable users to communicate in an environment where contemporaneous end-to-end paths are unavailable or unstable. To support end-to-end messaging in opportunistic networks, a number of probabilistic routing protocols have been proposed. However, when nodes are selfish, they may not have incentives to participate in probabilistic routing, and the system performance will degrade significantly. In this paper, we present novel incentive schemes for probabilistic routing that stimulates selfish nodes to participate. We not only rigorously prove the properties of our schemes, but also extensively evaluate our schemes using GloMoSim. Evaluation results show that there is an up to 75.8% gain in delivery ratio compared with a probabilistic routing protocol providing no incentive.","Games,
Probabilistic logic,
Routing protocols,
Routing,
Incentive schemes,
Cost accounting"
On the Convergence of Chemical Reaction Optimization for Combinatorial Optimization,"A novel general-purpose optimization method, chemical reaction optimization (CRO), is a population-based metaheuristic inspired by the phenomenon of interactions between molecules in a chemical reaction process. CRO has demonstrated its competitive edge over existing methods in solving many real-world problems. However, all studies concerning CRO have been empirical in nature and no theoretical analysis has been conducted to study its convergence properties. In this paper, we present some convergence results for several generic versions of CRO, each of which adopts different combinations of elementary reactions. We investigate the limiting behavior of CRO. By modeling CRO as a finite absorbing Markov chain, we show that CRO converges to a global optimum solution with a probability arbitrarily close to one when time tends to infinity. Our results also show that the convergence of CRO is determined by both the elementary reactions and the total energy of the system. Moreover, we also study and discuss the finite time behavior of CRO.","Convergence,
Sociology,
Statistics,
Chemicals,
Markov processes,
Cost function"
Bluetooth positioning using RSSI and triangulation methods,"Location based services are the hottest applications on mobile devices nowadays and the growth is continuing. Indoor wireless positioning is the key technology to enable location based services to work well indoors, where GPS normally could not work. Bluetooth has been widely used in mobile devices like phone, PAD etc. therefore Bluetooth based indoor positioning has great market potential. Radio Signal Strength (RSS) is a key parameter for wireless positioning. New Bluetooth standard (since version 2.1) enables RSS to be discovered without time consuming pre-connection. In this research, general wireless positioning technologies are firstly analysed. Then RSS based Bluetooth positioning using the new feature is studied. The mathematical model is established to analyse the relation between RSS and the distance between two Bluetooth devices. Three distance-based algorithms are used for Bluetooth positioning: Least Square Estimation, Three-border and Centroid Method. Comparison results are analysed and the ways to improve the positioning accuracy are discussed.","Bluetooth,
Mobile communication,
IEEE 802.11 Standards,
Mobile handsets,
Mathematical model,
Receivers,
Environmental factors"
Complementary Resistive Switching in Niobium Oxide-Based Resistive Memory Devices,"For the applications of resistive random access memory (RRAM), we study the complementary resistive switch (CRS) behavior of a bilayer Nb2O5-∞/NbOy RRAM. The CRS effect is explained by the redistribution of oxygen vacancies inside the two niobium oxide layers. Improved CRS effects were observed using W top electrode (TE) instead of Pt, which can be attributed to the oxygen barrier layer derived from a self-formed WO∞ layer between the W TE and the Nb2O5-∞ oxide film. The niobium oxide-based CRS devices within a single memory cell can be directly integrated into a crossbar memory array without the need of extra diodes; this can significantly reduce the fabrication complexity.","Arrays,
Switches,
Niobium,
Electrodes,
Materials,
Sputtering"
Generalized Mean Detector for Collaborative Spectrum Sensing,"In this paper, a unified generalized eigenvalue based spectrum sensing framework referred to as Generalized mean detector (GMD) has been introduced. The generalization of the detectors namely (i) the eigenvalue ratio detector (ERD) involving the ratio of the largest and the smallest eigenvalues; (ii) the Geometric mean detector (GEMD) involving the ratio of the largest eigenvalue and the geometric mean of the eigenvalues and (iii) the Arithmetic mean detector (ARMD) involving the ratio of the largest and the arithmetic mean of the eigenvalues is explored. The foundation of the proposed unified framework is based on the calculation of exact analytical moments of the random variables of test statistics of the respective detectors. In this context, we approximate the probability density function (PDF) of the test statistics of the respective detectors by Gaussian/Gamma PDF using the moment matching method. Finally, we derive closed-form expressions to calculate the decision threshold of the eigenvalue based detectors by exchanging the derived exact moments of the random variables of test statistics with the moments of the Gaussian/Gamma distribution function. The performance of the eigenvalue based detectors is compared with the traditional detectors such as energy detector (ED) and cyclostationary detector (CSD) and validate the importance of the eigenvalue based detectors particularly over realistic wireless cognitive environments. Analytical and simulation results show that the GEMD and the ARMD yields considerable performance advantage in realistic spectrum sensing scenarios. Moreover, our results based on proposed simple and tractable approximation approaches are in perfect agreement with the empirical results.",
A Fast-Locking All-Digital Deskew Buffer With Duty-Cycle Correction,"In this paper, a fast-locking all-digital deskew buffer with duty cycle correction is proposed and implemented. A cyclic time-to-digital converter is introduced to decrease the locking time in conventional register-controlled delay-locked loop to only two input clock cycles in coarse tuning. With the aid of the three half delay lines technique, the mismatch between half delay lines causing the duty cycle distortion can be alleviated by interpolation. A balanced edge combiner to achieve a precise 50% output clock is also presented. A test chip is fabricated in 0.18-μm technology to demonstrate the feasibility of the proposed architecture. The circuit can accept the input clock rates from 250 to 625 MHz with the duty cycle variation within 30% and 70% to generate 50% output clocks. It preserves the capability of closed-loop control with a small area and power consumption.","Delay lines,
Clocks,
Delay,
Logic gates,
Oscillators,
Hardware design languages"
Distributed Multiple-Model Estimation for Simultaneous Localization and Tracking With NLOS Mitigation,"This paper studies the problem of simultaneous localization and tracking (SLAT) in non-line-of-sight (NLOS) environments. By combining a target state and a sensor node location into an augmented vector, a nonlinear system with two jumping parameters is formulated in which two independent Markov chains are used to describe the switching of the target maneuvers and the transition of LOS/NLOS, respectively. To derive the state estimate of the proposed jump Markov nonlinear system for each sensor node, an interacting multiple-model (IMM) approach and a cubature Kalman filter (CKF) are employed. As the number of mode-conditioned filters exponentially grows with the increases in the number of active sensor nodes in the centralized fusion, a distributed scheme is adopted to reduce the computational burden, and a covariance intersection (CI) method is used to fuse sensor-based target-state estimates. A numerical example is provided, involving tracking a maneuvering target by a set of sensors, and simulation results show that the proposed filter can track the target and can estimate the positions of active sensor nodes accurately.","Target tracking,
Markov processes,
Nonlinear optics,
Covariance matrix,
Noise,
Vectors,
Nonlinear systems"
An Efficient Approach to Integrating Radius Information into Multiple Kernel Learning,"Integrating radius information has been demonstrated by recent work on multiple kernel learning (MKL) as a promising way to improve kernel learning performance. Directly integrating the radius of the minimum enclosing ball (MEB) into MKL as it is, however, not only incurs significant computational overhead but also possibly adversely affects the kernel learning performance due to the notorious sensitivity of this radius to outliers. Inspired by the relationship between the radius of the MEB and the trace of total data scattering matrix, this paper proposes to incorporate the latter into MKL to improve the situation. In particular, in order to well justify the incorporation of radius information, we strictly comply with the radius-margin bound of support vector machines (SVMs) and thus focus on the l2-norm soft-margin SVM classifier. Detailed theoretical analysis is conducted to show how the proposed approach effectively preserves the merits of incorporating the radius of the MEB and how the resulting optimization is efficiently solved. Moreover, the proposed approach achieves the following advantages over its counterparts: 1) more robust in the presence of outliers or noisy training samples; 2) more computationally efficient by avoiding the quadratic optimization for computing the radius at each iteration; and 3) readily solvable by the existing off-the-shelf MKL packages. Comprehensive experiments are conducted on University of California, Irvine, protein subcellular localization, and Caltech-101 data sets, and the results well demonstrate the effectiveness and efficiency of our approach.","Kernel,
Optimization,
Training,
Support vector machines,
Scattering,
Educational institutions,
Noise measurement"
High-Performance Silicon Nanotube Tunneling FET for Ultralow-Power Logic Applications,"To increase typically low output drive currents from tunnel field-effect transistors (FETs), we show a silicon vertical nanotube (NT) architecture-based FET's effectiveness. Using core (inner) and shell (outer) gate stacks, the silicon NT tunneling FET shows a sub-60 mV/dec subthreshold slope, ultralow off -state leakage current, higher drive current compared with gate-all-around nanowire silicon tunnel FETs.","Silicon,
Tunneling,
Logic gates,
FETs,
Performance evaluation,
Leakage current"
Polar codes for broadcast channels,"Building on polar code constructions proposed by the authors for deterministic broadcast channels, two theorems are introduced in the present paper for noisy two-user broadcast channels. The theorems establish polar code constructions for two important information-theoretic broadcast strategies: (1) Cover's superposition strategy; (2) Marton's construction. One aspect of the polar code constructions is the alignment of polarization indices via constraints placed on the auxiliary and channel-input distributions. The codes achieve capacity-optimal rates for several classes of broadcast channels (e.g., binary-input stochastically degraded channels). Applying Arıkan's original matrix kernel for polarization, it is shown that the average probability of error in decoding two private messages at the broadcast receivers decays as O(2(-nβ)) where 0 <; β <; 1/2 and n is the code length. The encoding and decoding complexities remain O(n log n). The error analysis is made possible by defining new polar code ensembles for broadcast channels.",
Dynamic Joint Resource Optimization for LTE-Advanced Relay Networks,"A dynamic optimization algorithm is proposed for the joint allocation of subframes, resource blocks, and power in the Type 1 inband relaying scheme mandatory in the LTE-Advanced standard. Following the general framework of Lyapunov optimization, we decompose the original problem into three sub-problems in the forms of convex programming, linear programming, and mixed-integer programming. We solve the last sub-problem in the Lagrange dual domain, showing that it has zero duality gap, and that a primal optimum can be obtained with probability one. The proposed algorithm dynamically adapts to traffic and channel fluctuations, it accommodates both instantaneous and average power constraints, and it obtains arbitrarily near-optimal sum utility of each user's average throughput. Simulation results demonstrate that the joint optimum can significantly outperform suboptimal alternatives.","Resource management,
Optimization,
Relays,
Joints,
Dynamic scheduling,
Long Term Evolution"
Design of a W-band Gyro-TWT Amplifier With a Lossy Ceramic-Loaded Circuit,"A pulse prototype of a W-band TE01 mode gyrotron traveling-wave tube (gyro-TWT) amplifier is designed, and it features high gain and broadband capabilities. The TE01 mode input coupler is constructed by mounting a sapphire pill-box window onto a Y-type mode converter. The high power output window will employ a triple-sapphire-disc configuration to achieve return loss lower than -30 dB over a bandwidth of 8 GHz. To suppress the spurious oscillations and realize high-average power potential, a new lossy ceramic material with weak electric conductivity is loaded in the TE01 mode cylindrical interaction waveguide. The loss-free output taper is carefully optimized to suppress oscillations and maintain broadband amplification. Employing a magnetic injection gun of beam voltage 70 kV, beam current 3 A, pitch factor 1.5, and axial-velocity spread 5%, theoretical investigation predicts that the gyro-TWT amplifier is of excellent performance, which includes being driven to saturation with input power Pin <; 0.4 W, highest efficiency of 32.4%, and the bandwidth of 4.2 GHz with output power exceeding 50 kW.","Ceramics,
Electron beams,
Oscillators,
Broadband communication,
Couplers,
Gyrotrons,
Electron tubes"
Neural Network-Based Optimal Control of Mobile Robot Formations With Reduced Information Exchange,"A novel formation control scheme for mobile robots is introduced in the context of leader-follower framework with reduced communication exchange. The dynamical controller inputs for the robots are approximated from nonlinear optimal control techniques in order to track the designed control velocities generated by the kinematic controller. The proposed nonlinear optimal control technique, referred to as adaptive dynamic programming, uses neural networks (NNs) to solve the optimal formation control problem in discrete time in the presence of unknown internal dynamics and a known control coefficient matrix. A modification to the follower's kinematic controller is used to allow the desired formation to change in order to navigate around obstacles. The proposed obstacle avoidance technique modifies the desired separation and bearing of the follower to guide the follower around obstacles. Minimal wireless communication is utilized between the leader and the follower to allow the follower to approximate and compensate for the formation dynamics. All NNs are tuned online, and the stability of the entire formation is demonstrated using Lyapunov methods. Hardware results demonstrate the effectiveness of our approach.","Robots,
Kinematics,
Feedforward neural networks,
Optimal control,
Approximation methods,
Cost function,
Artificial neural networks"
An efficient protocol for RFID multigroup threshold-based classification,"RFID technology has many applications such as object tracking, automatic inventory control, and supply chain management. They can be used to identify individual objects or count the population of each type of objects in a deployment area, no matter whether the objects are passports, retail products, books or even humans. Most existing work adopts a “flat” RFID system model and performs functions of collecting tag IDs, estimating the number of tags, or detecting the missing tags. However, in practice, tags are often attached to objects of different groups, which may represent a different product type in a warehouse, a different book category in a library, etc. An interesting problem, called multigroup threshold-based classification, is to determine whether the number of objects in each group is above or below a prescribed threshold value. Solving this problem is important for inventory tracking applications. If the number of groups is very large, it will be inefficient to measure the groups one at a time. The best existing solution for multigroup threshold-based classification is based on generic group testing, whose design is however geared towards detecting a small number of populous groups. Its performance degrades quickly when the number of groups above the threshold become large. In this paper, we propose a new classification protocol based on logical bitmaps. It achieves high efficiency by measuring all groups in a mixed fashion. In the meantime, we show that the new method is able to perform threshold-based classification with an accuracy that can be pre-set to any desirable level, allowing tradeoff between time efficiency and accuracy.","Protocols,
Radiofrequency identification,
Sociology,
Accuracy,
Maximum likelihood estimation"
New Constructions of WOM Codes Using the Wozencraft Ensemble,"In this paper, we give several new constructions of write-once-memory (WOM) codes. The novelty in our constructions is the use of the so-called Wozencraft ensemble of linear codes. Specifically, we obtain the following results. We give an explicit construction of a two-write WOM code that approaches capacity, over the binary alphabet. More formally, for every ϵ > 0, 0 <; p <; 1, and n=(1/ϵ)O(1/pϵ), we give a construction of a two-write WOM code of length n and capacity H(p)+1-p-ϵ. Since the capacity of a two-write WOM code is maxp (H(p)+1-p), we get a code that is ϵ-close to capacity. Furthermore, encoding and decoding can be done in time O(n2 ·poly (logn)) and time O(n ·poly (logn)), respectively, and in logarithmic space. In addition, we exhibit an explicit randomized encoding scheme of a two-write capacity-achieving WOM code of block length polynomial in 1/ϵ (again, ϵ is the gap to capacity), with a polynomial time encoding and decoding. We obtain a new encoding scheme for three-write WOM codes over the binary alphabet. Our scheme achieves rate 1.809-ϵ, when the block length is exp(1/ϵ). This gives a better rate than what could be achieved using previous techniques. We highlight a connection to linear seeded extractors for bit-fixing sources. In particular, we show that obtaining such an extractor with seed length O(logn) can lead to improved parameters for two-write WOM codes. We then give an application of existing constructions of extractors to the problem of designing encoding schemes for memory with defects.","Encoding,
Vectors,
Decoding,
Polynomials,
Complexity theory,
Force,
Ash"
Thermal-Constrained Task Allocation for Interconnect Energy Reduction in 3-D Homogeneous MPSoCs,"3-D technology that stacks silicon dies with through silicon vias (TSVs) is a promising solution to overcome the interconnect scaling problem in giga-scale integrated circuits (ICs). Thermal dissipation is a major challenge for 3-D integration and prior thermal-balanced task scheduling methods for 3-D multiprocessor system-on-chips (MPSoCs) typically balance power gradient across vertical stacks based on the assumption of strong thermal correlation among processing cores within a stack. On the other hand, 3-D MPSoCs typically employ network-on-chip (NoC) as the communication infrastructure which consumes a large portion of the energy budget. As TSVs consume much less energy than horizontal links in 3-D MPSoCs when transmitting the same amount data due to the reduced interconnect distance between vertical adjacent cores, it motivates to allocate heavily communicating tasks within the same vertical stack as much as possible, and thus traffic is restricted in the third dimension to reduce interconnect energy. However, aggregating active tasks within the same stack probably exacerbates the power density and result in hot spots. In this paper, we explore the tradeoff between thermal and interconnect energy when allocating tasks in 3-D Homogeneous MPSoCs, and propose an efficient heuristic. Experimental results show that the proposed technique can reduce interconnect energy by more than 25% on average with almost the same peak temperature when compared with prior thermal-balanced solutions.","Resource management,
System-on-a-chip,
Integrated circuit interconnections,
Through-silicon vias,
Computer architecture,
Power demand"
Information Theory of DNA Shotgun Sequencing,"DNA sequencing is the basic workhorse of modern day biology and medicine. Shotgun sequencing is the dominant technique used: many randomly located short fragments called reads are extracted from the DNA sequence, and these reads are assembled to reconstruct the original sequence. A basic question is: given a sequencing technology and the statistics of the DNA sequence, what is the minimum number of reads required for reliable reconstruction? This number provides a fundamental limit to the performance of any assembly algorithm. For a simple statistical model of the DNA sequence and the read process, we show that the answer admits a critical phenomenon in the asymptotic limit of long DNA sequences: if the read length is below a threshold, reconstruction is impossible no matter how many reads are observed, and if the read length is above the threshold, having enough reads to cover the DNA sequence is sufficient to reconstruct. The threshold is computed in terms of the Renyi entropy rate of the DNA sequence. We also study the impact of noise in the read process on the performance.","DNA,
Sequential analysis,
Greedy algorithms,
Assembly,
Genomics,
Bioinformatics,
Algorithm design and analysis"
Depth-Aware Image Seam Carving,"Image seam carving algorithm should preserve important and salient objects as much as possible when changing the image size, while not removing the secondary objects in the scene. However, it is still difficult to determine the important and salient objects that avoid the distortion of these objects after resizing the input image. In this paper, we develop a novel depth-aware single image seam carving approach by taking advantage of the modern depth cameras such as the Kinect sensor, which captures the RGB color image and its corresponding depth map simultaneously. By considering both the depth information and the just noticeable difference (JND) model, we develop an efficient JND-based significant computation approach using the multiscale graph cut based energy optimization. Our method achieves the better seam carving performance by cutting the near objects less seams while removing distant objects more seams. To the best of our knowledge, our algorithm is the first work to use the true depth map captured by Kinect depth camera for single image seam carving. The experimental results demonstrate that the proposed approach produces better seam carving results than previous content-aware seam carving methods.","Optimization,
Visualization,
Color,
Image edge detection,
Cameras,
Cybernetics,
Computational modeling"
SPAM: A Secure Password Authentication Mechanism for Seamless Handover in Proxy Mobile IPv6 Networks,"The Internet Engineering Task Force NETLMM Working Group recently proposed a network-based localized mobility management protocol called Proxy Mobile IPv6 (PMIPv6) to support mobility management without the participation of mobile nodes in any mobility-related signaling. Although PMIPv6 reduces the signaling overhead and the handover latency, it still suffers from packet loss problem and long authentication latency during handoff. In addition, there are many security threats to PMIPv6. In this paper, we perform a bicasting scheme for avoiding the packet loss problem, use the piggyback technique to reduce the signaling overhead, and provide a secure password authentication mechanism (SPAM) for protecting a valid user from attacks in PMIPv6 networks. SPAM provides high security properties, including anonymity, stolen-verified attack resistance, location privacy, mutual authentication, forgery attack resistance, no clock synchronization problem, modification attack resistance, replay attack resistance, fast error detection, choose and change password free, and session key agreement. Moreover, SPAM is an efficient authentication scheme that performs the authentication procedure locally and has low computational cost. From the analysis, we demonstrate that our scheme can resist various attacks and provides better performance than existing schemes.","Authentication,
Mobile communication,
Communication system security,
Internet"
IBM Streams Processing Language: Analyzing Big Data in motion,"The IBM Streams Processing Language (SPL) is the programming language for IBM InfoSphere® Streams, a platform for analyzing Big Data in motion. By “Big Data in motion,” we mean continuous data streams at high data-transfer rates. InfoSphere Streams processes such data with both high throughput and short response times. To meet these performance demands, it deploys each application on a cluster of commodity servers. SPL abstracts away the complexity of the distributed system, instead exposing a simple graph-of-operators view to the user. SPL has several innovations relative to prior streaming languages. For performance and code reuse, SPL provides a code-generation interface to C++ and Java®. To facilitate writing well-structured and concise applications, SPL provides higher-order composite operators that modularize stream sub-graphs. Finally, to enable static checking while exposing optimization opportunities, SPL provides a strong type system and user-defined operator models. This paper provides a language overview, describes the implementation including optimizations such as fusion, and explains the rationale behind the language design.","Data handling,
Information management,
Optimization,
Batch production systems,
Generators,
Syntactics,
Java,
Data processing,
Information processing"
Composable accelerator-rich microprocessor enhanced for adaptivity and longevity,"Accelerator-rich platforms demonstrate orders of magnitude improvement in performance and energy efficiency over software, yet they lack adaptivity to new algorithms and can see low accelerator utilization. To address these issues we propose CAMEL: Composable Accelerator-rich Microprocessor Enhanced for Longevity. CAMEL features programmable fabric (PF) to extend the use of ASIC composable accelerators in supporting algorithms that are beyond the scope of the baseline platform. Using a combination of hardware extensions and compiler support, we demonstrate on average 11.6X performance improvement and 13.9X energy savings across benchmarks that deviate from the original domain for our baseline platform.","Application specific integrated circuits,
Acceleration,
Resource management,
Computer architecture,
Fabrics,
Hardware,
Benchmark testing"
Sparsity-Aware Multi-Source TDOA Localization,"The problem of source localization from time-difference-of-arrival (TDOA) measurements is in general a non-convex and complex problem due to its hyperbolic nature. This problem becomes even more complicated for the case of multi-source localization where TDOAs should be assigned to their respective sources. We simplify this problem to an ℓ1-norm minimization by introducing a novel TDOA fingerprinting and grid design model for a multi-source scenario. Moreover, we propose an innovative trick to enhance the performance of our proposed fingerprinting model in terms of the number of identifiable sources. An interesting by-product of this enhanced model is that under some conditions we can convert the given underdetermined problem to an overdetermined one that could be solved using classical least squares (LS). Finally, we also tackle the problem of off-grid source localization as a case of grid mismatch. Our extensive simulation results illustrate a good performance for the introduced TDOA fingerprinting paradigm as well as a significant detection gain for the enhanced model.","time-of-arrival estimation,
convex programming,
direction-of-arrival estimation,
fingerprint identification"
Vessel Tractography Using an Intensity Based Tensor Model With Branch Detection,"In this paper, we present a tubular structure segmentation method that utilizes a second order tensor constructed from directional intensity measurements, which is inspired from diffusion tensor image (DTI) modeling. The constructed anisotropic tensor which is fit inside a vessel drives the segmentation analogously to a tractography approach in DTI. Our model is initialized at a single seed point and is capable of capturing whole vessel trees by an automatic branch detection algorithm developed in the same framework. The centerline of the vessel as well as its thickness is extracted. Performance results within the Rotterdam Coronary Artery Algorithm Evaluation framework are provided for comparison with existing techniques. 96.4% average overlap with ground truth delineated by experts is obtained in addition to other measures reported in the paper. Moreover, we demonstrate further quantitative results over synthetic vascular datasets, and we provide quantitative experiments for branch detection on patient computed tomography angiography (CTA) volumes, as well as qualitative evaluations on the same CTA datasets, from visual scores by a cardiologist expert.","Tensile stress,
Estimation,
Eigenvalues and eigenfunctions,
Image segmentation,
Diffusion tensor imaging,
Vectors,
Arteries"
Capacity of Wireless Networks with Social Behavior,"The capacity of a wireless network is studied when nodes communicate with one another in the context of social groups. All the nodes are assumed to have the same number of independent long-range social contacts, one of which each selects randomly as its destination. The Euclidean distance between a source and its social group members follows a power-law distribution and communication between any two nodes takes place only within the physical transmission range resulting in communication over multi-hop paths. The capacity order of such a composite network is derived as a function of the number of nodes, the social-group concentration, and the size of social groups. Our results demonstrate that when each node has constant number of contacts which does not increase with network size growth, and are geographically concentrated, then the network behaves similar to social networks and communication network does not have any effect on the throughput capacity. On the other hand, when the social contact population grows in time, or social connectivity among nodes is highly distributed, then the communication network is the dominant factor and the composite network behaves similar to wireless networks, i.e., the capacity is the same as Gupta and Kumar results. When neither social connectivity nor communication network is dominant, then the throughput capacity results are between these two extreme cases.",
A dynamic archive niching differential evolution algorithm for multimodal optimization,"Highly multimodal landscapes with multiple local/global optima represent common characteristics in real-world applications. Many niching algorithms have been proposed in the literature which aim to search such landscapes in an attempt to locate as many global optima as possible. However, to locate and maintain a large number of global solutions, these algorithms are substantially influenced by their parameter values, such as a large population size. Here, we propose a new niching Differential Evolution algorithm that attempts to overcome the population size influence and produce good performance almost independently of its population size. To this end, we incorporate two mechanisms into the algorithm: a control parameter adaptation technique and an external dynamic archive along with a reinitialization mechanism. The first mechanism is designed to efficiently adapt the control parameters of the algorithm, whilst the second one is responsible for enabling the algorithm to investigate unexplored regions of the search space and simultaneously keep the best solutions found by the algorithm. The proposed approach is compared with two Differential Evolution variants on a recently proposed benchmark suite. Empirical results indicate that the proposed niching algorithm is competitive and very promising. It exhibits a robust and stable behavior, whilst the incorporation of the dynamic archive seems to tackle the population size influence effectively. Moreover, it alleviates the problem of having to fine-tune the population size parameter in a niching algorithm.","Heuristic algorithms,
Sociology,
Statistics,
Accuracy,
Algorithm design and analysis,
Benchmark testing,
Vectors"
Joint Attention by Gaze Interpolation and Saliency,"Joint attention, which is the ability of coordination of a common point of reference with the communicating party, emerges as a key factor in various interaction scenarios. This paper presents an image-based method for establishing joint attention between an experimenter and a robot. The precise analysis of the experimenter's eye region requires stability and high-resolution image acquisition, which is not always available. We investigate regression-based interpolation of the gaze direction from the head pose of the experimenter, which is easier to track. Gaussian process regression and neural networks are contrasted to interpolate the gaze direction. Then, we combine gaze interpolation with image-based saliency to improve the target point estimates and test three different saliency schemes. We demonstrate the proposed method on a human-robot interaction scenario. Cross-subject evaluations, as well as experiments under adverse conditions (such as dimmed or artificial illumination or motion blur), show that our method generalizes well and achieves rapid gaze estimation for establishing joint attention.","Joints,
Estimation,
Vectors,
Robot kinematics,
Face"
FPGA Implementation of Sliding-Mode-Control Algorithm for Scaled Bilateral Teleoperation,"This paper proposes an FPGA-based sliding-mode controller for scaled bilateral teleoperation. The control algorithm is derived by using the sliding-mode-control-based design approach. The applied design procedure replaces a discontinuous control with a continuous one. Thus, it guarantees chattering-free performance whilst retaining practical robustness regarding disturbances and provides easy model-free implementation. A high control rate is strongly required in order to achieve high-performance scaled bilateral teleoperation. Hence, the control algorithm is implemented by the FPGA. In order to design a sufficient logic circuit for the FPGA, general optimization approaches are presented that aim to minimize hardware resources and to optimize the control rate. The design applies high-level programming language (LabVIEW) for rapid prototyping. The presented algorithms were validated by the 2-DoF laboratory bilateral teleoperation system.","Force,
Field programmable gate arrays,
Algorithm design and analysis,
Robustness,
Acceleration,
Hardware,
Teleoperators"
AFM-Based Robotic Nano-Hand for Stable Manipulation at Nanoscale,"One of the major limitations for Atomic Force Microscopy (AFM)-based nanomanipulation is that AFM only has one sharp tip as the end-effector, and can only apply a point force to the nanoobject, which makes it extremely difficult to achieve a stable manipulation. For example, the AFM tip tends to slip-away during nanoparticle manipulation due to its small touch area, and there is no available strategy to manipulate a nanorod in a constant posture with a single tip since the applied point force can make the nanorod rotate more easily. In this paper, a robotic nano-hand method is proposed to solve these problems. The basic idea is using a single tip to mimic the manipulation effect that multi-AFM tip can achieve through the planned high speed sequential tip pushing. The theoretical behavior models of nanoparticle and nanorod are developed, based on which the moving speed and trajectory of the AFM tip are planned artfully to form a nano-hand. In this way, the slip-away problem during nanoparticle manipulation can be get rid of efficiently, and a posture constant manipulation for nanorod can be achieved. The simulation and experimental results demonstrate the effectiveness and advantages of the proposed method.","Friction,
Force,
Nanoscale devices,
Robots,
Uncertainty,
Kinematics,
Trajectory"
Automatic Segmentation of Scaling in 2-D Psoriasis Skin Images,"Psoriasis is a chronic inflammatory skin disease that affects over 3% of the population. Various methods are currently used to evaluate psoriasis severity and to monitor therapeutic response. The PASI system of scoring is widely used for evaluating psoriasis severity. It employs a visual analogue scale to score the thickness, redness (erythema), and scaling of psoriasis lesions. However, PASI scores are subjective and suffer from poor inter- and intra-observer concordance. As an integral part of developing a reliable evaluation method for psoriasis, an algorithm is presented for segmenting scaling in 2-D digital images. The algorithm is believed to be the first to localize scaling directly in 2-D digital images. The scaling segmentation problem is treated as a classification and parameter estimation problem. A Markov random field (MRF) is used to smooth a pixel-wise classification from a support vector machine (SVM) that utilizes a feature space derived from image color and scaling texture. The training sets for the SVM are collected directly from the image being analyzed giving the algorithm more resilience to variations in lighting and skin type. The algorithm is shown to give reliable segmentation results when evaluated with images with different lighting conditions, skin types, and psoriasis types.","Skin,
Image segmentation,
Lesions,
Image color analysis,
Algorithm design and analysis,
Support vector machines,
Training"
Time Varying Autoregressive Moving Average Models for Covariance Estimation,"We consider large scale covariance estimation using a small number of samples in applications where there is a natural ordering between the random variables. The two classical approaches to this problem rely on banded covariance and banded inverse covariance structures, corresponding to time varying moving average (MA) and autoregressive (AR) models, respectively. Motivated by this analogy to spectral estimation and the well known modeling power of autoregressive moving average (ARMA) processes, we propose a novel time varying ARMA covariance structure. Similarly to known results in the context of AR and MA, we address the completion of an ARMA covariance matrix from its main band, and its estimation based on random samples. Finally, we examine the advantages of our proposed methods using numerical experiments.","instrumental variables,
Autoregressive moving average,
covariance estimation,
matrix completion"
Biometric Authentication Using Mouse Gesture Dynamics,"The mouse dynamics biometric is a behavioral biometric technology that extracts and analyzes the movement characteristics of the mouse input device when a computer user interacts with a graphical user interface for identification purposes. Most of the existing studies on mouse dynamics analysis have targeted primarily continuous authentication or user reauthentication for which promising results have been achieved. Static authentication (at login time) using mouse dynamics, however, appears to face some challenges due to the limited amount of data that can reasonably be captured during such a process. In this paper, we present a new mouse dynamics analysis framework that uses mouse gesture dynamics for static authentication. The captured gestures are analyzed using a learning vector quantization neural network classifier. We conduct an experimental evaluation of our framework with 39 users, in which we achieve a false acceptance ratio of 5.26% and a false rejection ratio of 4.59% when four gestures were combined, with a test session length of 26.9 s. This is an improvement both in the accuracy and validation sample, compared to the existing mouse dynamics approaches that could be considered adequate for static authentication. Furthermore, to our knowledge, our work is the first to present a relatively accurate static authentication scheme based on mouse gesture dynamics.",
CRSS systems for 2012 NIST Speaker Recognition Evaluation,"This paper describes the systems developed by the Center for Robust Speech Systems (CRSS), for the 2012 National Institute of Standards and Technology (NIST) Speaker Recognition Evaluation (SRE). Given that the emphasis of SRE'12 is on noisy and short duration test conditions, our system development focused on: (i) novel robust acoustic features, (ii) new feature normalization schemes, (iii) various back-end strategies utilizing multi-session and multi-condition training, and (iv) quality measure based system fusion. Noisy and short duration training/test conditions are artificially generated and effectively utilized. Active speech duration and signal-to-noise-ratio (SNR) estimates are successfully employed as quality measures for system calibration and fusion. Overall system performance was very successful for the given test conditions.","Signal to noise ratio,
Abstracts,
Mel frequency cepstral coefficient,
Filter banks,
Smoothing methods,
Cepstrum,
Training"
A Patch-Clamp ASIC for Nanopore-Based DNA Analysis,"In this paper, a fully integrated high-sensitivity patch-clamp system is proposed for single-molecule deoxyribonucleic acid (DNA) analysis using a nanopore sensor. This system is composed of two main blocks for amplification and compensation. The amplification block is composed of three stages: 1) a headstage, 2) a voltage-gain difference amplifier, and 3) a track-and-hold circuit, that amplify a minute ionic current variation sensed by the nanopore while the compensation block avoids the headstage saturation caused by the input parasitic capacitances during sensing. By employing design techniques novel for this application, such as an instrumentation-amplifier topology and a compensation switch, we minimize the deleterious effects of the input-offset voltage and the input parasitic capacitances while attaining hardware simplicity. This system is fabricated in a 0.35 μm 4M2P CMOS process and is demonstrated using an α-hemolysin protein nanopore for detection of individual molecules of single-stranded DNA that pass through the 1.5 nm-diameter pore. In future work, the refined system will functionalize single and multiple solid-state nanopores formed in integrated microfluidic devices for advanced DNA analysis, in scientific and diagnostic applications.",
Optimal Selection of Parameters for Nonuniform Embedding of Chaotic Time Series Using Ant Colony Optimization,"The optimal selection of parameters for time-delay embedding is crucial to the analysis and the forecasting of chaotic time series. Although various parameter selection techniques have been developed for conventional uniform embedding methods, the study of parameter selection for nonuniform embedding is progressed at a slow pace. In nonuniform embedding, which enables different dimensions to have different time delays, the selection of time delays for different dimensions presents a difficult optimization problem with combinatorial explosion. To solve this problem efficiently, this paper proposes an ant colony optimization (ACO) approach. Taking advantage of the characteristic of incremental solution construction of the ACO, the proposed ACO for nonuniform embedding (ACO-NE) divides the solution construction procedure into two phases, i.e., selection of embedding dimension and selection of time delays. In this way, both the embedding dimension and the time delays can be optimized, along with the search process of the algorithm. To accelerate search speed, we extract useful information from the original time series to define heuristics to guide the search direction of ants. Three geometry- or model-based criteria are used to test the performance of the algorithm. The optimal embeddings found by the algorithm are also applied in time-series forecasting. Experimental results show that the ACO-NE is able to yield good embedding solutions from both the viewpoints of optimization performance and prediction accuracy.",
Computer-Aided Detection of Cancer in Automated 3-D Breast Ultrasound,"Automated 3-D breast ultrasound (ABUS) has gained a lot of interest and may become widely used in screening of dense breasts, where sensitivity of mammography is poor. However, reading ABUS images is time consuming, and subtle abnormalities may be missed. Therefore, we are developing a computer aided detection (CAD) system to help reduce reading time and prevent errors. In the multi-stage system we propose, segmentations of the breast, the nipple and the chestwall are performed, providing landmarks for the detection algorithm. Subsequently, voxel features characterizing coronal spiculation patterns, blobness, contrast, and depth are extracted. Using an ensemble of neural-network classifiers, a likelihood map indicating potential abnormality is computed. Local maxima in the likelihood map are determined and form a set of candidates in each image. These candidates are further processed in a second detection stage, which includes region segmentation, feature extraction and a final classification. On region level, classification experiments were performed using different classifiers including an ensemble of neural networks, a support vector machine, a k-nearest neighbors, a linear discriminant, and a gentle boost classifier. Performance was determined using a dataset of 238 patients with 348 images (views), including 169 malignant and 154 benign lesions. Using free response receiver operating characteristic (FROC) analysis, the system obtains a view-based sensitivity of 64% at 1 false positives per image using an ensemble of neural-network classifiers.","Lesions,
Ultrasonic imaging,
Image segmentation,
Feature extraction,
Breast cancer"
Reconstruction Based Finger-Knuckle-Print Verification With Score Level Adaptive Binary Fusion,"Recently, a new biometrics identifier, namely finger knuckle print (FKP), has been proposed for personal authentication with very interesting results. One of the advantages of FKP verification lies in its user friendliness in data collection. However, the user flexibility in positioning fingers also leads to a certain degree of pose variations in the collected query FKP images. The widely used Gabor filtering based competitive coding scheme is sensitive to such variations, resulting in many false rejections. We propose to alleviate this problem by reconstructing the query sample with a dictionary learned from the template samples in the gallery set. The reconstructed FKP image can reduce much the enlarged matching distance caused by finger pose variations; however, both the intra-class and inter-class distances will be reduced. We then propose a score level adaptive binary fusion rule to adaptively fuse the matching distances before and after reconstruction, aiming to reduce the false rejections without increasing much the false acceptances. Experimental results on the benchmark PolyU FKP database show that the proposed method significantly improves the FKP verification accuracy.","Image reconstruction,
Feature extraction,
Fingers,
Dictionaries,
Encoding,
Biometrics (access control),
Image coding"
"Quantum Rate Distortion, Reverse Shannon Theorems, and Source-Channel Separation","We derive quantum counterparts of two key theorems of classical information theory, namely, the rate-distortion theorem and the source-channel separation theorem. The rate-distortion theorem gives the ultimate limits on lossy data compression, and the source-channel separation theorem implies that a two-stage protocol consisting of compression and channel coding is optimal for transmitting a memoryless source over a memoryless channel. In spite of their importance in the classical domain, there has been surprisingly little work in these areas for quantum information theory. In this paper, we prove that the quantum rate-distortion function is given in terms of the regularized entanglement of purification. We also determine a single-letter expression for the entanglement-assisted quantum rate-distortion function, and we prove that it serves as a lower bound on the unassisted quantum rate-distortion function. This implies that the unassisted quantum rate-distortion function is nonnegative and generally not equal to the coherent information between the source and distorted output (in spite of Barnum's conjecture that the coherent information would be relevant here). Moreover, we prove several quantum source-channel separation theorems. The strongest of these are in the entanglement-assisted setting, in which we establish a necessary and sufficient condition for transmitting a memoryless source over a memoryless quantum channel up to a given distortion.","Rate-distortion,
Quantum entanglement,
Data compression,
Channel coding,
Receivers"
"Evaluation of tunnel FET-based flip-flop designs for low power, high performance applications","As proliferation of embedded systems and mobile devices increases, power has become one of the most paramount concerns in current microprocessor designs. Technology scaling has provided many benefits in terms of dynamic power; however, static power has become the bottleneck to reducing power. We address this by evaluating Tunnel FETs (TFETs) for use in low-power, high-performance flip-flop designs. Due to the nature of TFETs, some of the flip-flop designs that are evaluated require additional modifications beyond simple device replacement-most notably the pseudo-static D flip-flop (DFF). We find that despite these additional transistors, the low voltage TFET DFF provides clear advantages in power and energy combined with performance comparable to higher voltage MOSFET and FinFET designs.","Flip-flops,
Clocks,
Logic gates,
Integrated circuit modeling,
FinFETs"
Elastic Image Registration Versus Speckle Tracking for 2-D Myocardial Motion Estimation: A Direct Comparison In Vivo,"Despite the availability of multiple solutions for assessing myocardial strain by ultrasound, little is currently known about the relative performance of the different methods. In this study, we sought to contrast two strain estimation techniques directly (speckle tracking and elastic registration) in an in vivo setting by comparing both to a gold standard reference measurement. In five open-chest sheep instrumented with ultrasonic microcrystals, 2-D images were acquired with a GE Vivid7 ultrasound system. Radial (εRR), longitudinal (εLL), and circumferential strain (εCC) were estimated during four inotropic stages: at rest, during esmolol and dobutamine infusion, and during acute ischemia. The correlation of the end-systolic strain values of a well-validated speckle tracking approach and an elastic registration method against sonomicrometry were comparable for εLL (r=0.70 versus r=0.61 , respectively; p=0.32) and εCC (r=0.73 versus r=0.80 respectively; p=0.31). However, the elastic registration method performed considerably better for εRR (r=0.64 versus r=0.85 respectively; p=0.09). Moreover, the bias and limits of agreement with respect to the reference strain estimates were statistically significantly smaller in this direction (p <; 0.001). This could be related to regularization which is imposed during the motion estimation process as opposed to an a posteriori regularization step in the speckle tracking method. Whether one method outperforms the other in detecting dysfunctional regions remains the topic of future research.","Strain,
Myocardium,
Crystals,
Speckle,
Radio frequency,
Ultrasonic imaging,
Image segmentation"
Continuous shape estimation of continuum robots using X-ray images,"We present a new method for continuously and accurately estimating the shape of a continuum robot during a medical procedure using a small number of X-ray projection images (e.g., radiographs or fluoroscopy images). Continuum robots have curvilinear structure, enabling them to maneuver through constrained spaces by bending around obstacles. Accurately estimating the robot's shape continuously over time is crucial for the success of procedures that require avoidance of anatomical obstacles and sensitive tissues. Online shape estimation of a continuum robot is complicated by uncertainty in its kinematic model, movement of the robot during the procedure, noise in X-ray images, and the clinical need to minimize the number of X-ray images acquired. Our new method integrates kinematics models of the robot with data extracted from an optimally selected set of X-ray projection images. Our method represents the shape of the continuum robot over time as a deformable surface which can be described as a linear combination of time and space basis functions. We take advantage of probabilistic priors and numeric optimization to select optimal camera configurations, thus minimizing the expected shape estimation error. We evaluate our method using simulated concentric tube robot procedures and demonstrate that obtaining between 3 and 10 images from viewpoints selected by our method enables online shape estimation with errors significantly lower than using the kinematic model alone or using randomly spaced viewpoints.","Robots,
Biomedical imaging,
Trajectory,
Niobium"
Start-up Procedure and Switching Loss Reduction for a Single-Phase Flying Capacitor Active Rectifier,"This paper describes a research conducted on a single-phase flying capacitor active rectifier. An online process that reduces the total number of switching events, which leads to a reduction of switching losses in the converter, is introduced. This method is based on redundant state selection, which is used to regulate the voltage of flying capacitors. The proposed approach is general and can be applied to flying capacitor converters with any number of levels. Furthermore, in order to control the inrush current at the start of operation and avoid extra voltage and current stress for active switches and capacitors, a start-up procedure that precharges the flying capacitors is proposed. With this precharge procedure, no additional hardware is needed. Simulation and laboratory results demonstrate these new concepts.","Capacitors,
Switches,
Switching loss,
Rectifiers,
Voltage control,
Indexes,
Logic gates"
Estimating Crowd Density in an RF-Based Dynamic Environment,"Crowd density estimating is a crucial service in many applications (e.g., smart guide, crowd control, etc.), which is often conducted using pattern recognition technologies based on video surveillance. However, these kinds of methods are high cost, and cannot work well in low-light environments. Radio frequency based technologies are adopted more and more in indoor application, since radio signal strength (RSS) can be easily obtained by various wireless devices without additional cost. In this paper, we introduce a low cost crowd density estimating method using wireless sensor networks. The proposed approach is a device-free crowd counting approach without objects carrying any assistive device. It is hard to count objects based on RSS measurement, since different number of mobile people at different positions often generates different RSS due to the multipath phenomenon. This paper utilizes the space-time relativity of crowd distribution to reduce the estimation errors. The proposed approach is an iterative process, which contains three phases: the training phase, the monitoring phase, and the calibrating phase. Our experiments are implemented based on TelosB sensor platform. We also do some large-scale simulations to verify the feasibility and the effectiveness of our crowd density estimating approach.","wireless sensor networks,
indoor communication"
Hybrid Kalman Filters for Very Short-Term Load Forecasting and Prediction Interval Estimation,"Very short-term load forecasting predicts the loads in electric power system one hour into the future in 5-min steps in a moving window manner. To quantify forecasting accuracy in real-time, the prediction interval estimates should also be produced online. Effective predictions with good prediction intervals are important for resource dispatch and area generation control, and help power market participants make prudent decisions. We previously presented a two level wavelet neural network method based on back propagation without estimating prediction intervals. This paper extends the previous work by using hybrid Kalman filters to produce forecasting with prediction interval estimates online. Based on data analysis, a neural network trained by an extended Kalman filter is used for the low-low frequency component to capture the near-linear relationship between the input load component and the output measurement, while neural networks trained by unscented Kalman filters are used for low-high and high frequency components to capture their nonlinear relationships. The overall variance estimate is then derived and evaluated for prediction interval estimation. Testing results demonstrate the effectiveness of hybrid Kalman filters for capturing different features of load components, and the accuracy of the overall variance estimate derived based on a data set from ISO New England.",
Analysis of Wireless Localization in Nonline-of-Sight Conditions,"One major concern of existing wireless localization systems is the identification of nonline-of-sight (NLOS) signal propagation, since NLOS can be considered the dominant source of localization error. Present identification methods usually assume that NLOS could make it not possible to perform localization in a consistent manner. However, the validity of the foregoing assumption has not been properly investigated. This paper presents a theoretical analysis of mobile user localization involving one or more NLOS beacons and shows the given assumption as being invalid when the estimated user location is outside the convex hull of the beacons used in the localization. It also proposes an efficient algorithm for checking whether the estimated location of a mobile user is inside the convex-hull region in both 2-D and 3-D space. Extensive localization experiments on different wireless networks demonstrate that using current NLOS identification methods and classical localization algorithms could yield localization results with grossly underestimated errors.",
A High-Efficiency Nonuniform Grating Coupler Realized With 248-nm Optical Lithography,"We describe a high-efficiency grating coupler (GC) fabricated on a silicon-on-insulator wafer with 220 nm top silicon layer. One single 60 nm shallow etch is required to define the diffractive gratings with a minimum lithographic feature size of 180 nm, which is within the limitation of 248 nm deep ultraviolet lithography. The measured average insertion loss is 3.1 ± 0.2 dB ~1550 nm with a 1 dB bandwidth of 41 ± 4 nm for TE polarization, whereas the best device exhibits 2.7 dB loss. The measured GC backreflection loss is better than 17 dB across the wafer. Cross-wafer data shows good uniformity and tolerance to fabrication variations. This is the best result reported for the commonly used 220 nm thickness Si that uses only a shallow etch step.","ultraviolet lithography,
diffraction gratings,
etching,
integrated optics,
light polarisation,
optical couplers,
optical fabrication,
optical losses,
reflectivity,
silicon-on-insulator"
Estimating Skeletal Muscle Fascicle Curvature From B-Mode Ultrasound Image Sequences,"We address the problem of tracking in vivo muscle fascicle shape and length changes using ultrasound video sequences. Quantifying fascicle behavior is required to improve understanding of the functional significance of a muscle's geometric properties. Ultrasound imaging provides a noninvasive means of capturing information on fascicle behavior during dynamic movements; to date however, computational approaches to assess such images are limited. Our approach to the problem is novel because we permit fascicles to take up nonlinear shape configurations. We achieve this using a Bayesian tracking framework that is: 1) robust, conditioning shape estimates on the entire history of image observations; and 2) flexible, enforcing only a very weak Gaussian Process shape prior that requires fascicles to be locally smooth. The method allows us to track and quantify fascicle behavior in vivo during a range of movements, providing insight into dynamic changes in muscle geometric properties which may be linked to patterns of activation and intramuscular forces and pressures.","Shape,
Ultrasonic imaging,
Muscles,
Image segmentation,
Tracking,
Approximation methods,
Training data"
Detect-and-Forward Relaying Aided Cooperative Spatial Modulation for Wireless Networks,"A novel detect-and-forward (DeF) relaying aided cooperative SM scheme is proposed, which is capable of striking a flexible tradeoff in terms of the achievable bit error ratio (BER), complexity and unequal error protection (UEP). More specifically, SM is invoked at the source node (SN) and the information bit stream is divided into two different sets: the antenna index-bits (AI-bits) as well as the amplitude and phase modulation-bits (APM-bits). By exploiting the different importance of the AI-bits and the APM-bits in SM detection, we propose three low-complexity, yet powerful relay protocols, namely the partial, the hybrid and the hierarchical modulation (HM) based DeF relaying schemes. These schemes determine the most appropriate number of bits to be re-modulated by carefully considering their potential benefits and then assigning a specific modulation scheme for relaying the message. As a further benefit, the employment of multiple radio frequency (RF) chains and the requirement of tight inter-relay synchronization (IRS) can be avoided. Moreover, by exploiting the benefits of our low-complexity relaying protocols and our inter-element interference (IEI) model, a low-complexity maximum-likelihood (ML) detector is proposed for jointly detecting the signal received both via the source-destination (SD) and relay-destination (RD) links. Additionally, an upper bound of the BER is derived for our DeF-SM scheme. Our numerical results show that the bound is asymptotically tight in the high-SNR region and the proposed schemes provide beneficial system performance improvements compared to the conventional MIMO schemes in an identical cooperative scenario.",
A proof-carrying based framework for trusted microprocessor IP,"We introduce a proof-carrying based framework for assessing the trustworthiness of third-party hardware Intellectual Property (IP), particularly geared toward microprocessor cores. This framework enables definition of and formal reasoning on security properties, which, in turn, are used to certify the genuineness and trustworthiness of the instruction set and, by extension, are used to prevent insertion of malicious functionality in the Hardware Description Language (HDL) code of an acquired microprocessor core. Security properties and trustworthiness proofs are derived based on a new formal hardware description language (formal-HDL), which is developed as part of the framework along with conversion rules to/from other HDLs to enable general applicability to IP cores independent of coding language. The proposed framework, along with the ability of a sample set of pertinent security properties to detect malicious IP modifications, is demonstrated on an 8051 microprocessor core.","Microprocessors,
Trojan horses,
Hardware,
Registers,
Hardware design languages,
Circuit synthesis"
A new hand exoskeleton device for rehabilitation using a three-layered sliding spring mechanism,"In this paper, a new hand exoskeleton device using a three-layered sliding spring mechanism is presented. In contrast to state of the art hand exoskeleton mechanisms (typically link, wire or pneumatically driven), the proposed mechanism is driven through large deformations of the compliant mechanism body. The mechanism can be made compact and lightweight by adequately positioning the compliant elements. In addition, the mechanism is designed to distribute 1-DOF actuated linear motion into three rotational motions of the finger joints, which translate into natural finger flexion/extension. The primary application of the proposed mechanism is to provide robotic support during physical therapy at the hospital (e.g. Continuous Passive Motion). However, thanks to its light and wearable structure, the proposed device could also be used at home as an assistive/therapeutic device to support activities of daily living. We introduce the mechanical structure of the three-layered sliding spring mechanism, present a prototype implementation as a hand exoskeleton device, and provide a preliminary evaluation.","Springs,
Joints,
Prototypes,
Exoskeletons,
Force,
Electronics packaging,
Blades"
Secure Source Coding With a Helper,"We consider a secure lossless source coding problem with a rate-limited helper. In particular, Alice observes an independent and identically distributed (i.i.d.) source
X
n
and wishes to transmit this source losslessly to Bob over a rate-limited link of capacity not exceeding
R
x
. A helper, say Helen, observes an i.i.d. correlated source
Y
n
and can transmit information to Bob over another link of capacity not exceeding
R
y
. A passive eavesdropper (say Eve) can observe the coded output of Alice, i.e., the link from Alice to Bob is public. The uncertainty about the source
X
n
at Eve (denoted by
Δ
) is measured by the conditional entropy
H(
X
n
|
J
x
)
n
, where
J
x
is the coded output of Alice and
n
is the block length. We completely characterize the rate-equivocation region for this secure source coding model, where we show that Slepian–Wolf binning of
X
n
with respect to the coded side information received at Bob is optimal. We next consider a modification of this model in which Alice also has access to the coded output of Helen. We call this model as the two-sided helper model. For the two-sided helper model, we characterize the rate-equivocation region. While the availability of side information at Alice does not reduce the rate of transmission from Alice, it significantly enhances the resulting equivocation at Eve. In particular, the resulting equivocation for the two-sided helper case is shown to be
min(H(X),
R
y
)
, i.e., one bit from the two-sided helper provides one bit of uncertainty at Eve. From this result, we infer that Slepian–Wolf binning of
X
is suboptimal and one can further decrease the information leakage to the eavesdropper by utilizing the side information at Alice. We, finally, generalize both of these results to the case in which there is additional uncoded side information
W
n
available at Bob and characterize the rate-equivocation regions under the assumption that
Y
n
→
X
n
→
W
n
forms a Markov chain.","Uncertainty,
Source coding,
Indexes,
Propagation losses,
Markov processes,
Zinc"
"Tunnel FET-based ultra-low power, high-sensitivity UHF RFID rectifier","Hetero-junction Tunnel FET (HTFET) for ultra-low power RF circuit design has been explored at the device and circuit level. In this paper, benchmarking and design insights for optimizing the performance of the TFET based differential drive rectifier is presented. Our evaluation of the HTFET based rectifier demonstrates its promise compared to the state-of-art passive RFIDs. With the 10-stage optimized TFET rectifier at 915 MHz, PCE of 98% with 0.5 nW power consumption, sensitivity of -24dBm for 9 μW PDC and sensitivity of -33dBm for 0.4μW PDC were achieved.","Rectifiers,
FinFETs,
Silicon,
Radio frequency,
Power generation,
Sensitivity,
Topology"
A New VSC-HVDC Model for Power Flows Using the Newton-Raphson Method,"The paper presents a new model of the VSC-HVDC aimed at power flow solutions using the Newton-Raphson method. Each converter station is made up of the series connection of a voltage source converter (VSC) and its connecting transformer which is assumed to be a tap-changing (LTC) transformer. The new model represents a paradigm shift in the way the fundamental frequency, positive sequence modeling of VSC-HVDC links are represented, where the VSCs are not treated as idealized, controllable voltage sources but rather as compound transformer devices to which certain control properties of PWM-based inverters may be linked - just as DC-to-DC converters have been linked, conceptually speaking, to step-up and step-down transformers. The VSC model, and by extension that of the VSC-HVDC, takes into account, in aggregated form, the phase-shifting and scaling nature of the PWM control. It also takes into account the VSC inductive and capacitive reactive power design limits, switching losses and ohmic losses.","Power conversion,
Mathematical model,
Equations,
Newton method,
Reactive power,
Voltage control"
Personalised learning spaces and federated online labs for STEM Education at School,"The European Commission is funding a large-scale research project on federated online laboratories (Labs) for education in Science, Technology, Engineering, and Mathematics (STEM) at School. The main educational focus is on inquiry learning and the main technological one is on personalized learning spaces. The learning spaces are offered through a single European social media portal supporting simultaneously teacher communities and student learning activities. This paper presents the general technical framework devised to support the construction and the exploitation of learning spaces, as well as the federation of online labs.","Portals,
Educational institutions,
Communities,
Engineering education,
Conferences,
Media,
Logic gates"
Novel Layout Technique for Single-Event Transient Mitigation Using Dummy Transistor,"In this paper, a novel layout technique for single-event transient (SET) mitigation based on dummy transistors is proposed. Numerical simulations using technology computer-aided design with 90-nm twin-well CMOS technology show that the proposed layout technique can efficiently reduce SET pulsewidths. This layout design methodology is thoroughly discussed for the case of the inverter cell, and the discussion is then extended to other logic cells. We also compare the proposed layout technique with the “guard ring” (for P-hit mitigation) and the “guard drain” (for N-hit mitigation) layout techniques, and we find that not only does the proposed layout technique provide the benefit of greater SET mitigation but it also presents a smaller area penalty.",
Nonconvex Dynamic Economic Power Dispatch Problems Solution Using Hybrid Immune-Genetic Algorithm,"The objective of dynamic economic dispatch (DED) problem is to determine the generation schedule of the committed generation units, which minimizes the total operating cost over a dispatch period, while satisfying a set of constraints. The effect of valve points and prohibited operating zones (POZs) in the generating units' cost functions makes the DED a highly nonlinear and nonconvex optimization problem with multiple local minima. Considering the ramp-rate limits and transmission losses makes the DED problem even more complicated. Hence, proposing an effective solution method for this optimization problem is of great interest. This paper presents a novel heuristic algorithm to solve DED problem of generating units by employing a hybrid immune-genetic algorithm. To illustrate the effectiveness of the proposed approach, four test systems that consist of different numbers of generating units are studied. The valve-point effects, POZs, and ramp-rate constraints along with transmission losses are also considered in simulation cases. The results obtained through the proposed method are compared with those reported in the literature. These results substantiate the applicability of the proposed method for solving the constrained DED problem with nonsmooth cost functions.","Heuristic algorithms,
Propagation losses,
Economics,
Optimization,
Linear programming,
Generators,
Power system dynamics"
A Broadband Unidirectional Antenna Based on Closely Spaced Loading Method,"In order to achieve broadband and unidirectional radiation, a planar printed antenna based on closely spaced loading method is proposed and fabricated. This antenna consists of a printed rectangular loop with two gaps and a metallic strip. The rectangular loop has a good direction but has a drawback of narrow band. According to the closely spaced loading theory, the impedance at the upper frequency will decrease when a metallic strip is placed at the maximum radiation direction of the rectangular loop. This improves the impedance matching. A new resonant frequency point is induced. Meanwhile, the resonant frequency point can be changed by modifying the length of the metallic strip. The impedance matching between the two resonant peaks (One peak is determined by the rectangular loop, the other is determined by the metallic strip) is improved by changing the length and the position of the metallic strip. Thus the impedance bandwidth is greatly expanded. Experimental results show good performance of the proposed antenna. It has a 40.7% measured bandwidth, ranging from 2.29 to 3.46 GHz. The measured front-to-back (F/B) ratio of the proposed antenna is larger than 10 dB in the whole frequency band.",
Error Correction for Index Coding With Side Information,"A problem of index coding with side information was first considered by Birk and Kol in 1998. In this study, a generalization of index coding scheme, where transmitted symbols are subject to errors, is studied. Error-correcting methods for such a scheme, and their parameters, are investigated. In particular, the following question is discussed: given the side information hypergraph of index coding scheme and the maximal number of erroneous symbols δ , what is the shortest length of a linear index code, such that every receiver is able to recover the required information? This question turns out to be a generalization of the problem of finding a shortest length error-correcting code with a prescribed error-correcting capability in the classical coding theory. The Singleton bound and two other bounds, referred to as the α-bound and the κ -bound, for the optimal length of a linear error-correcting index code (ECIC) are established. For large alphabets, a construction based on concatenation of an optimal index code with a maximum distance separable classical code is shown to attain the Singleton bound. For smaller alphabets, however, this construction may not be optimal. A random construction is also analyzed. It yields another inexplicit bound on the length of an optimal linear ECIC. Further, the problem of error-correcting decoding by a linear ECIC is studied. It is shown that in order to decode correctly the desired symbol, the decoder is required to find one of the vectors, belonging to an affine space containing the actual error vector. The syndrome decoding is shown to produce the correct output if the weight of the error pattern is less or equal to the error-correcting capability of the corresponding ECIC. Finally, the notion of static ECIC, which is suitable for use with a family of instances of an index coding problem, is introduced. Several bounds on the length of static ECICs are derived, and constructions for static ECICs are discussed. Connections of these codes to weakly resilient Boolean functions are established.","Indexes,
Vectors,
Encoding,
Receivers,
Error correction codes,
Decoding,
Educational institutions"
Performance Guarantees of the Thresholding Algorithm for the Cosparse Analysis Model,"The cosparse analysis model for signals assumes that the signal of interest can be multiplied by an analysis dictionary , leading to a sparse outcome. This model stands as an interesting alternative to the more classical synthesis-based sparse representation model. In this paper, we propose a theoretical study of the performance guarantee of the thresholding algorithm for the pursuit problem in the presence of noise. Our analysis reveals two significant properties of Ω, which govern the pursuit performance: the first is the degree of linear dependencies between sets of rows in Ω, depicted by the cosparsity level. The second property, termed the restricted orthogonal projection property, is the level of independence between such dependent sets and other rows in Ω. We show how these dictionary properties are meaningful and useful, both in the theoretical bounds derived and in a series of experiments that are shown to align well with the theoretical prediction.","Dictionaries,
Algorithm design and analysis,
Analytical models,
Vectors,
Sparks,
Signal to noise ratio"
The Secrecy Capacity Region of the Gaussian MIMO Broadcast Channel,"In this paper, we consider a scenario where a source node wishes to broadcast two confidential messages for two respective receivers via a Gaussian multiple-input multiple-output (MIMO) broadcast channel. An eavesdropper also receives the transmitted signal via another MIMO channel. We first consider the discrete memoryless channel and obtain the capacity region of the degraded channel. The secret dirty paper coding (SDPC) region as an achievable rate region for the general discrete channel is introduced. Relying on the results for the discrete channel, we fully characterize the secrecy capacity region of MIMO broadcast channel. It is shown that the SDPC scheme is optimal. The converse part of the proof relies on the generalized Costa's entropy power inequality and a new channel enhancement strategy in which we only need to enhance the channels of the legitimate receivers, and the channel of the eavesdropper remains unchanged.","MIMO,
Covariance matrix,
Vectors,
Receivers,
Encoding,
Transmitters,
Noise"
The Impact of X-Ray and Proton Irradiation on {\rm HfO}_2/{\rm Hf}-Based Bipolar Resistive Memories,"This paper investigates total-ionizing dose effects on the electrical characteristics of HfO2/Hf-based bipolar resistive-random-access-memory (RRAM) devices. 10-keV x-ray irradiation does not cause significant changes in resistance at levels up to 7 Mrad( SiO2). Excess carriers generated by x-ray irradiation in the HfO2 layer recombine or are trapped at defect sites in the HfO2 layer or at interfaces between layers. They have no effect, however, on the conductive path of the RRAM devices. 1.8 MeV proton irradiation causes resistance degradation through simultaneous introduction of oxygen vacancies and displacement damage. TRIM simulations are used to explain the physical mechanisms of the radiation-induced damage. The devices are promising for radiation-hardened memory applications.","Nonvolatile memory,
Radiation effects,
Protons,
Radiation hardening (electronics),
X-rays,
Hafnium compounds,
Degradation"
An ROI Privacy Protection Scheme for H.264 Video Based on FMO and Chaos,"With the increase of terrorist and criminal activities, closed circuit television (CCTV) is widely used on many occasions. However, abuse of surveillance video may result in the leakage of personal privacy. To protect the privacy in the video of CCTV, an encryption scheme for region of interest (ROI) of H.264 video based on flexible macroblock ordering (FMO) and chaos is proposed in this paper, where human face regions are selected as an example of ROI. First, the human face regions in the video are detected and extracted. Then, they are mapped into slice groups by using FMO technology in H.264. After that, these regions are encrypted using selective video encryption based on chaos. Experimental results and analysis show that the proposed scheme can effectively protect the private information of H.264 video and, therefore, can strike a good balance among the security, encryption efficiency, and coding performance. It has great potential to be used in the privacy protection of the video of CCTV.",
Dynamic Contrast-Enhanced MRI-Based Early Detection of Acute Renal Transplant Rejection,"A novel framework for the classification of acute rejection versus nonrejection status of renal transplants from 2-D dynamic contrast-enhanced magnetic resonance imaging is proposed. The framework consists of four steps. First, kidney objects are segmented from adjacent structures with a level set deformable boundary guided by a stochastic speed function that accounts for a fourth-order Markov-Gibbs random field model of the kidney/background shape and appearance. Second, a Laplace-based nonrigid registration approach is used to account for local deformations caused by physiological effects. Namely, the target kidney object is deformed over closed, equispaced contours (iso-contours) to closely match the reference object. Next, the cortex is segmented as it is the functional kidney unit that is most affected by rejection. To characterize rejection, perfusion is estimated from contrast agent kinetics using empirical indexes, namely, the transient phase indexes (peak signal intensity, time-to-peak, and initial up-slope), and a steady-phase index defined as the average signal change during the slowly varying tissue phase of agent transit. We used a kn-nearest neighbor classifier to distinguish between acute rejection and nonrejection. Performance of our method was evaluated using the receiver operating characteristics (ROC). Experimental results in 50 subjects, using a combinatoric kn-classifier, correctly classified 92% of training subjects, 100% of the test subjects, and yielded an area under the ROC curve that approached the ideal value. Our proposed framework thus holds promise as a reliable noninvasive diagnostic tool.",
Joint Optimization Toward Effective and Efficient Image Search,"The bag-of-words (BoW) model has been known as an effective method for large-scale image search and indexing. Recent work shows that the performance of the model can be further improved by using the embedding method. While different variants of the BoW model and embedding method have been developed, less effort has been made to discover their underlying working mechanism. In this paper, we systematically investigate the image search performance variation with respect to a few factors of the BoW model, and study how to employ the embedding method to further improve the image search performance. Subsequently, we summarize several observations based on the experiments on descriptor matching. To validate these observations in a real image search, we propose an effective and efficient image search scheme, in which the BoW model and embedding method are jointly optimized in terms of effectiveness and efficiency by following these observations. Our comprehensive experiments demonstrate that it is beneficial to employ these observations to develop an image search algorithm, and the proposed image search scheme outperforms state-of-the-art methods in both effectiveness and efficiency.","Embedded systems,
Large-scale systems,
Image processing"
"Human-robot cross-training: Computational formulation, modeling and evaluation of a human team training strategy","We design and evaluate human-robot cross-training, a strategy widely used and validated for effective human team training. Cross-training is an interactive planning method in which a human and a robot iteratively switch roles to learn a shared plan for a collaborative task. We first present a computational formulation of the robot's interrole knowledge and show that it is quantitatively comparable to the human mental model. Based on this encoding, we formulate human-robot cross-training and evaluate it in human subject experiments (n = 36). We compare human-robot cross-training to standard reinforcement learning techniques, and show that cross-training provides statistically significant improvements in quantitative team performance measures. Additionally, significant differences emerge in the perceived robot performance and human trust. These results support the hypothesis that effective and fluent human-robot teaming may be best achieved by modeling effective practices for human teamwork.","Cognitive science,
Training,
Service robots,
Learning (artificial intelligence),
Planning,
Robot kinematics"
Fault Node Recovery Algorithm for a Wireless Sensor Network,"This paper proposes a fault node recovery algorithm to enhance the lifetime of a wireless sensor network when some of the sensor nodes shut down. The algorithm is based on the grade diffusion algorithm combined with the genetic algorithm. The algorithm can result in fewer replacements of sensor nodes and more reused routing paths. In our simulation, the proposed algorithm increases the number of active nodes up to 8.7 times, reduces the rate of data loss by approximately 98.8%, and reduces the rate of energy consumption by approximately 31.1%.","wireless sensor networks (WSN),
Genetic algorithm,
grade diffusion (GD) algorithm,
gradient diffusion algorithm"
Micro-doppler feature extraction for wideband imaging radar based on complex image orthogonal matching pursuit decomposition,"The micro-Doppler (m-D) features induced by targets with micro-motions provide important information for automatic radar target recognition. In this study, the m-D effect induced by rotational micro-motion in wideband radar is analysed, and an algorithm for the extraction of these m-D features is proposed. By making use of the amplitude and phase information of `range-slow-time image', a dictionary with m-D signal atoms is constructed in the complex image space. The orthogonal matching pursuit algorithm in vector space is then extended to the complex image space to decompose the range-slow-time image and to extract the m-D features of the target. The proposed algorithm can extract the m-D features in the presence of migration through range cells of micro-motional scatterers, and can also work well when the sampling rate in slow-time domain is lower than the Nyquist sampling rate. Simulations are given to validate the effectiveness and robustness of the proposed method.",
Learning to Photograph: A Compositional Perspective,"In this paper, we present an intelligent photography system which can recommend the most user-favored view rectangle for arbitrary camera input, from a photographic compositional perspective. Automating this process is difficult, due to the subjectivity of human's aesthetics judgement and large variations of image contents, where heuristic compositional rules lack generality. Motivated by the recent prevalence of photo-sharing websites, e.g., Flickr.com, we develop a learning-based framework which discovers the underlying aesthetic photographic compositional structures from a large set of user-favored online sharing photographs and utilizes the implicitly shared knowledge among the professional photographers for aesthetically optimal view recommendation. In particular, we propose an Omni-Range Context method which explicitly encodes the spatial and geometric distributions of various visual elements in the photograph as well as cooccurrence characteristics of visual element pairs by using generative mixture models. Searching the optimal view rectangle is then formulated as maximum a posterior by imposing the trained prior distributions along with additional photographic constraints. The proposed system has the potential to operate in near real-time. Comprehensive user studies well demonstrate the effectiveness of the proposed framework for aesthetically optimal view recommendation.","Visualization,
Image segmentation,
Humans,
Context,
Context modeling,
Computational modeling,
Image color analysis"
A Small Dual-Band CPW-Fed Monopole Antenna for GSM and WLAN Applications,"A unique and miniaturized dual-band coplanar waveguide (CPW)-fed antenna is presented. The proposed antenna comprises a rectangular patch that is surrounded by upper and lower ground-plane sections that are interconnected by a high-impedance microstrip line. The proposed antenna structure generates two separate impedance bandwidths to cover frequency bands of GSM and Wi-Fi/WLAN. The antenna realized is relatively small in size (17\times 20\ {\hbox{mm}}^{2})
and operates over frequency ranges 1.60–1.85 and 4.95–5.80 GHz, making it suitable for GSM and Wi-Fi/WLAN applications. In addition, the antenna is circularly polarized in the GSM band. Experimental results show the antenna exhibits monopole-like radiation characteristics and a good antenna gain over its operating bands. The measured and simulated results presented show good agreement.","Wireless LAN,
Antenna measurements,
GSM,
Microstrip antennas,
Dual band,
Microstrip"
A Multiple Hypothesis Tracker for Multitarget Tracking With Multiple Simultaneous Measurements,"Typical multitarget tracking systems assume that in every scan there is at most one measurement for each target. In certain other systems such as over-the-horizon radar tracking, the sensor can generate resolvable multiple detections, corresponding to different measurement modes, from the same target. In this paper, we propose a new algorithm called multiple detection multiple hypothesis tracker (MD-MHT) to effectively track multiple targets in such multiple-detection systems. The challenge for this tracker, which follows the multiple hypothesis framework, is to jointly resolve the measurement origin and measurement mode uncertainties. The proposed tracker solves this data association problem via an extension to the multiframe assignment algorithm. Its performance is demonstrated on a simulated over-the-horizon-radar multitarget tracking scenario, which confirms the effectiveness of this algorithm.","Algorithm design and analysis,
Target tracking,
Robot localization,
Radar tracking,
Mathematical model,
Coordinate measuring machines"
Unsupervised Methods for Speaker Diarization: An Integrated and Iterative Approach,"In speaker diarization, standard approaches typically perform speaker clustering on some initial segmentation before refining the segment boundaries in a re-segmentation step to obtain a final diarization hypothesis. In this paper, we integrate an improved clustering method with an existing re-segmentation algorithm and, in iterative fashion, optimize both speaker cluster assignments and segmentation boundaries jointly. For clustering, we extend our previous research using factor analysis for speaker modeling. In continuing to take advantage of the effectiveness of factor analysis as a front-end for extracting speaker-specific features (i.e., i-vectors), we develop a probabilistic approach to speaker clustering by applying a Bayesian Gaussian Mixture Model (GMM) to principal component analysis (PCA)-processed i-vectors. We then utilize information at different temporal resolutions to arrive at an iterative optimization scheme that, in alternating between clustering and re-segmentation steps, demonstrates the ability to improve both speaker cluster assignments and segmentation boundaries in an unsupervised manner. Our proposed methods attain results that are comparable to those of a state-of-the-art benchmark set on the multi-speaker CallHome telephone corpus. We further compare our system with a Bayesian nonparametric approach to diarization and attempt to reconcile their differences in both methodology and performance.",
Dynamic Traffic Control with Fairness and Throughput Optimization Using Vehicular Communications,"Traffic congestion in modern cities seriously affects our living quality and environments. Inefficient traffic management leads to fuel wastage in volume of billion gallons per year. In this paper, we propose a dynamic traffic control framework using vehicular communications and fine-grained information, such as turning intentions and lane positions of vehicles, to maximize traffic flows and provide fairness among traffic flows. With vehicular communications, the traffic controller at an intersection can collect all fine-grained information before vehicles pass the intersection. Our proposed signal scheduling algorithm considers the flows at all lanes, allocates more durations of green signs to those flows with higher passing rates, and also gives turns to those with lower passing rates for fairness provision. Simulation results show that the proposed framework outperforms existing works by significantly increasing the number of vehicles passing an intersection while keeping average waiting time low for vehicles on non-arterial roads. In addition, we discuss our implementation of an Zigbee-based prototype and experiences.","Vehicles,
Roads,
Throughput,
Turning,
Acceleration,
Vehicle dynamics,
Aging"
Hierarchical Feature Extraction With Local Neural Response for Image Recognition,"In this paper, a hierarchical feature extraction method is proposed for image recognition. The key idea of the proposed method is to extract an effective feature, called local neural response (LNR), of the input image with nontrivial discrimination and invariance properties by alternating between local coding and maximum pooling operation. The local coding, which is carried out on the locally linear manifold, can extract the salient feature of image patches and leads to a sparse measure matrix on which maximum pooling is carried out. The maximum pooling operation builds the translation invariance into the model. We also show that other invariant properties, such as rotation and scaling, can be induced by the proposed model. In addition, a template selection algorithm is presented to reduce computational complexity and to improve the discrimination ability of the LNR. Experimental results show that our method is robust to local distortion and clutter compared with state-of-the-art algorithms.","Feature extraction,
Image coding,
Encoding,
Sparse matrices,
Robustness,
TV,
Image recognition"
Boosting-Based EMG Patterns Classification Scheme for Robustness Enhancement,"The high conventional accuracy of pattern recognition-based surface myoelectric classification in laboratory experiments does not necessarily result in high accessibility to practical protheses. An obvious reason is the effect of signals of untrained classes caused by the relatively small training dataset. In order to make the classifier robust to untrained classes, a classification scheme is developed based on boosting and random forest classifiers in this paper. Meanwhile, a threshold, the post probability of the prediction, is introduced as a balance (i.e., adjust) between the accurate classification and the rejection of the samples belonging to some untrained classes. The experiments are conducted to compare with other two schemes using linear discriminant analysis and support vector machines. Surface electromyogram signals, labeled with seven isometric movements, are collected from six healthy subjects' forearm. It is shown that the proposed scheme can reach up to about 92% accuracy in recognizing trained classes and 20% for untrained classes. Through adjusting the threshold, the accuracy of rejecting untrained classes reaches up to around 80%, with small decrease in recognizing trained classes (down to 80%). In the analysis of experiments' results, we also find that the proposed scheme has better error distribution among the classes.","support vector machines,
electromyography,
medical signal processing,
probability,
random processes,
signal classification"
"Preliminary assessment of the Mars Science Laboratory entry, descent, and landing simulation","On August 5, 2012, the Mars Science Laboratory rover, Curiosity, successfully landed inside Gale Crater. This landing was the seventh successful landing and fourth rover to be delivered to Mars. Weighing nearly one metric ton, Curiosity is the largest and most complex rover ever sent to investigate another planet. Safely landing such a large payload required an innovative Entry, Descent, and Landing system, which included the first guided entry at Mars, the largest supersonic parachute ever flown at Mars, and the novel Sky Crane landing system. A complete, end-to-end, six degree-of-freedom, multi-body computer simulation of the Mars Science Laboratory Entry, Descent, and Landing sequence was developed at the NASA Langley Research Center. In-flight data gathered during the successful landing is compared to pre-flight statistical distributions, predicted by the simulation. These comparisons provide insight into both the accuracy of the simulation and the overall performance of the Entry, Descent, and Landing system.",
Wireless MIMO Switching: Weighted Sum Mean Square Error and Sum Rate Optimization,"This paper addresses joint transceiver and relay design for a wireless multiple-input multiple-output (MIMO) switching scheme that enables data exchange among multiple users. Here, a multiantenna relay linearly precodes the received (uplink) signals from multiple users and forwards the signal in the downlink, where the purpose of precoding is to let each user receive its desired signal with interference from other users suppressed. The problem of optimizing the precoder based on various design criteria is typically nonconvex and difficult to solve. The main contribution of this paper is a unified approach to solve the weighted sum mean square error (MSE) minimization and weighted sum rate maximization problems in MIMO switching. Specifically, an iterative algorithm is proposed for jointly optimizing the relay's precoder and the users' receive filters to minimize the weighted sum MSE. It is also shown that the weighted sum rate maximization problem can be reformulated as an iterated weighted sum MSE minimization problem and can, therefore, be solved similarly to the case of weighted sum MSE minimization. With properly chosen initial values, the proposed iterative algorithms are asymptotically optimal in both high- and low-signal-to-noise-ratio regimes for MIMO switching, either with or without self-interference cancellation (a.k.a., physical-layer network coding). Numerical results show that the optimized MIMO switching scheme based on the proposed algorithms significantly outperforms existing approaches in the literature.","Relays,
MIMO,
Switches,
Minimization,
Optimization,
Vectors,
Uplink"
Maximum Average Service Rate and Optimal Queue Scheduling of Delay-Constrained Hybrid Cognitive Radio in Nakagami Fading Channels,"As a promising technique to improve achievable bandwidth efficiency, cognitive radio (CR) has attracted substantial research attention from both the academic and industrial communities. To improve the performance attained by the secondary user (SU), a novel hybrid CR system is proposed, which combines the conventional interweave and underlay paradigms to enhance the chance of the SU to access the spectrum. Queuing theory is invoked in this paper to analyze the impact of the primary user's maximum tolerable delay on the performance of the SU. Multiple queues are assumed for the SU, which is engaged in video communication. Apart from the Poisson traffic generation, we also model the classic Nakagami-m fading channel as a Poisson service process by utilizing the outage probability in the presence of cochannel interference. We optimize the hybrid interweave/underlay procedure to maximize the average service rate μS, max of the SU, as well as the queue's scheduling scheme, for the sake of minimizing the overall average delay (OAD). As a result, the OAD of the SU is reduced by up to 27% and 20%, compared with the proportion and round-robin schemes, respectively.",
Zero-Sum Two-Player Game Theoretic Formulation of Affine Nonlinear Discrete-Time Systems Using Neural Networks,"In this paper, the nearly optimal solution for discrete-time (DT) affine nonlinear control systems in the presence of partially unknown internal system dynamics and disturbances is considered. The approach is based on successive approximate solution of the Hamilton-Jacobi-Isaacs (HJI) equation, which appears in optimal control. Successive approximation approach for updating control and disturbance inputs for DT nonlinear affine systems are proposed. Moreover, sufficient conditions for the convergence of the approximate HJI solution to the saddle point are derived, and an iterative approach to approximate the HJI equation using a neural network (NN) is presented. Then, the requirement of full knowledge of the internal dynamics of the nonlinear DT system is relaxed by using a second NN online approximator. The result is a closed-loop optimal NN controller via offline learning. A numerical example is provided illustrating the effectiveness of the approach.","Equations,
Approximation methods,
Games,
Optimal control,
Taylor series,
Nonlinear systems,
Game theory"
Duality in Entanglement-Assisted Quantum Error Correction,"The dual of an entanglement-assisted quantum error-correcting (EAQEC) code is defined from the orthogonal group of a simplified stabilizer group. From the Poisson summation formula, this duality leads to the MacWilliams identities and linear programming bounds for EAQEC codes. We establish a table of upper and lower bounds on the minimum distance of any maximal-entanglement EAQEC code with length up to 15 channel qubits.","Silicon,
Quantum entanglement,
Linear programming,
Quantum computing,
Educational institutions,
Error correction codes"
Jointly Optimal Rate Control and Relay Selection for Cooperative Wireless Video Streaming,"Physical-layer cooperation allows leveraging the spatial diversity of wireless channels without requiring multiple antennas on a single device. However, most research in this field focuses on optimizing physical-layer metrics, with little consideration for network-wide and application-specific performance measures. This paper studies cross-layer design techniques for video streaming over cooperative networks. The problem of joint rate control, relay selection, and power allocation is formulated as a mixed-integer nonlinear problem, with the objective of maximizing the sum peak signal-to-noise ratio (PSNR) of a set of concurrent video sessions. A global optimization algorithm based on the branch and bound framework and on convex relaxation of nonconvex constraints is then proposed to solve the problem. The proposed algorithm can provide a theoretical upper bound on the achievable video quality and is shown to provably converge to the optimal solution. In addition, it is shown that cooperative relaying allows nodes to save energy without leading to a perceivable decrease in video quality. Based on this observation, an uncoordinated, distributed, and localized low-complexity algorithm is designed, for which we derive conditions for convergence to a Nash equlibrium (NE) of relay selection. The distributed algorithm is also shown to achieve performance comparable in practice to the optimal solution.",
Real-Time Mobile Food Recognition System,"We propose a mobile food recognition system the poses of which are estimating calorie and nutritious of foods and recording a user's eating habits. Since all the processes on image recognition performed on a smart-phone, the system does not need to send images to a server and runs on an ordinary smartphone in a real-time way. To recognize food items, a user draws bounding boxes by touching the screen first, and then the system starts food item recognition within the indicated bounding boxes. To recognize them more accurately, we segment each food item region by GrubCut, extract a color histogram and SURF-based bag-of-features, and finally classify it into one of the fifty food categories with linear SVM and fast 2 kernel. In addition, the system estimates the direction of food regions where the higher SVM output score is expected to be obtained, show it as an arrow on the screen in order to ask a user to move a smartphone camera. This recognition process is performed repeatedly about once a second. We implemented this system as an Android smartphone application so as to use multiple CPU cores effectively for real-time recognition. In the experiments, we have achieved the 81.55% classification rate for the top 5 category candidates when the ground-truth bounding boxes are given. In addition, we obtained positive evaluation by user study compared to the food recording system without object recognition.","Support vector machines,
Image color analysis,
Image recognition,
Histograms,
Kernel,
Feature extraction,
Real-time systems"
Formal Worst-Case Analysis of Crosstalk Noise in Mesh-Based Optical Networks-on-Chip,"Crosstalk noise is an intrinsic characteristic as well as a potential issue of photonic devices. In large scale optical networks-on-chips (ONoCs), crosstalk noise could cause severe performance degradation and prevent ONoC from communicating properly. The novel contribution of this paper is the systematical modeling and analysis of the crosstalk noise and the signal-to-noise ratio (SNR) of optical routers and mesh-based ONoCs using a formal method. Formal analytical models for the worst-case crosstalk noise and minimum SNR in mesh-based ONoCs are presented. The crosstalk analysis is performed at device, router, and network levels. A general 5 × 5 optical router model is proposed for router level analysis. The minimum SNR optical link candidates, which constrain the scalability of mesh-based ONoCs, are identified. It is also shown that symmetric mesh-based ONoCs have the best SNR performance. The presented formal analyses can be easily applied to other optical routers and mesh-based ONoCs. Finally, we present case studies of mesh-based ONoCs using the optimized crossbar and Crux optical routers to evaluate the proposed formal method. We find that crosstalk noise can significantly limit the scalability of mesh-based ONoCs. For example, when the mesh-based ONoC size, using optimized crossbar, is larger than 8 × 8, the optical signal power is smaller than the crosstalk noise power; when the network size is 16 × 16 and the input power is 0 dBm, in the worst-case, the signal power is -24.9 dBm and the crosstalk noise power is -11 dBm.","Optical crosstalk,
Optical waveguides,
Crosstalk,
Optical noise,
Optical fiber communication,
Signal to noise ratio"
On the Multi-User Diversity with Secrecy in Uplink Wiretap Networks,"In this letter, we consider the uplink wiretap network which consists of a base station, N legitimate users, and several eavesdroppers. We propose a novel user scheduling algorithm based on a threshold, which achieves the optimal multi-user diversity gain, i.e., log log N. To the best of our knowledge, there has been no such result in uplink wiretap networks. In order to obtain good throughput performance in the network, the threshold value needs to be carefully chosen. Through extensive simulations, we observe that the proposed user scheduling outperforms the conventional scheduling algorithms and it approaches the throughput performance of the optimal user scheduling algorithm in various scenarios.","Throughput,
Uplink,
Optimal scheduling,
Scheduling algorithms,
Signal to noise ratio,
Multiuser detection,
Fading"
Layout decomposition with pairwise coloring for multiple patterning lithography,"While double patterning lithography (DPL) is still in active development, triple or even quadruple patterning has recently been proposed for the next technology node. In this paper, we propose a pairwise coloring (PWC) method to tackle the layout decomposition problem for general multiple patterning lithography (MPL). The main idea is to reduce the problem to sets of concurrent bi-coloring problems. The overall solution is refined iteratively by applying a bi-coloring method for pairs of color sets per pass. One obvious advantage of this approach is that the existing DPL techniques can be reused seamlessly. Any improvement of them can directly benefit to the MPL counterpart. Moreover, we observe that with the help of the SPQR-tree graph division method, each pass can be fulfilled in nearly linear time. In addition, to prevent the solution getting stuck in the local minima, a randomized initialization strategy is incorporated. The PWC method is executed certain number of times with different randomized initial solutions, out of which the best solution is selected as output. We have implemented our method for particular triple patterning lithography (TPL). The experimental results show that compared with two recently published methods for TPL, our method can reduce the number of conflicts up to 33.2% and 44.9% respectively.",
Improvement of Settling Performance by Mode-Switching Control With Split Initial-Value Compensation Based on Input Shaper,"This paper presents a novel initial-value-compensation (IVC) technique for mode-switching-control approaches in the fast and precise positioning of mechatronic systems. Parameter perturbations in plant mechanism and/or actuator generally deteriorate the positioning performance. In order to realize the desired positioning performance with robust property against the perturbations, the mode-switching control with the IVC is one of the promising approaches, where the timing of the mode switching and the time interval of the IVC critically affect the compensation performance. However, the shortening in the IVC operation interval causes an increase in the input amplitude, which leads to deterioration of the positioning performance due to saturation in control input. In this paper, therefore, a split IVC based on input-shaping techniques is applied to prevent the input amplitude from being saturated and to provide adaptiveness and robustness against unknown parameter perturbations. The effectiveness of the proposed approach has been verified by experiments using a prototype of galvanoscanners.",Gain
Automated malware classification based on network behavior,"Over the past decade malware, i.e., malicious software, has become a major security threat on the Internet. Today anti-virus companies receive thousands of malicious samples every day. However the vast majority of these samples are variants of the existing malware. Due to the sheer number of malware variants it is important to accurately determine whether a sample belongs to a known malware family or exhibits a new behavior and thus requires further analysis and separate detection signature. Despite of the importance of network activity, the existing research on malware analysis does not fully leverage the malware network behavior for classification. In this paper, we propose an automated malware classification system that focuses on network behavior of malware samples. Our approach employs behavioral profiles that summarize the network behavior of malware samples. The proposed approach is applied to a real world malware corpus. Our experimental results show the effectiveness of the proposed approach in classifying malware samples only based on the network activity exhibited by the samples.",
Use of cooperative coevolution for solving large scale multiobjective optimization problems,"Many real-world multi-objective optimization problems have hundreds or even thousands of decision variables, which contrast with the current practice of multi-objective metaheuristics whose performance is typically assessed using benchmark problems with a relatively low number of decision variables (normally, no more than 30). In this paper, we propose a cooperative coevolution framework that is capable of optimizing large scale (in decision variable space) multi-objective optimization problems. We adopt a benchmark that is scalable in the number of decision variables (the ZDT test suite) and compare our proposed algorithm with respect to two state-of-the-art multi-objective evolutionary algorithms (GDE3 and NSGA-II) when using a large number of decision variables (from 200 up to 5000). The results clearly indicate that our proposed approach is effective as well as efficient for solving large scale multi-objective optimization problems.","Optimization,
Vectors,
Sociology,
Statistics,
Linear programming,
Evolutionary computation,
Collaboration"
Providing green SLAs in High Performance Computing clouds,"Demand for clean products and services is increasing as society is becoming increasingly aware of climate change. In response, many enterprises are setting explicit sustainability goals and implementing initiatives to reduce carbon emissions. Quantification and disclosure of such goals and initiatives have become important marketing tools. As enterprises and individuals shift their workloads to the cloud, this drive toward quantification and disclosure will lead to demand for quantifiable green cloud services. Thus, we argue that cloud providers should offer a new class of green services, in addition to existing (energy-source-oblivious) services. This new class would provide clients with explicit service-level agreements (which we call Green SLAs) for the percentage of renewable energy used to run their workloads. In this paper, we first propose an approach for High Performance Computing cloud providers to offer such a Green SLA service. Specifically, each client job specifies a Green SLA, which is the minimum percentage of green energy that must be used to run the job. The provider earns a premium for meeting the Green SLA, but is penalized if it accepts the job but violates the Green SLA. We then propose (1) a power distribution and control infrastructure that uses a small amount of hardware to support Green SLAs, (2) an optimization-based framework for scheduling jobs and power sources that maximizes provider profits while respecting Green SLAs, and (3) two scheduling policies based on the framework. We evaluate our framework and policies extensively through simulations. Our main results show the tradeoffs between our policies, and their advantages over simpler greedy heuristics. We conclude that a Green SLA service that uses our policies would enable the provider to attract environmentally conscious clients, especially those who require strict guarantees on their use of green energy.","Green products,
Air pollution,
Schedules,
Batteries,
Optimization,
Servers,
Software"
TOUR: Time-sensitive Opportunistic Utility-based Routing in delay tolerant networks,"In this paper, we propose a time-sensitive utility model for delay tolerant networks (DTNs), in which each message has an attached time-sensitive benefit that decays over time. The utility of a message is the benefit minus the transmission cost incurred by delivering the message. This model is analogous to the postal service in the real world, which inherently provides a good balance between delay and cost. Under this model, we propose a Time-sensitive Opportunistic Utility-based Routing (TOUR) algorithm. TOUR is a single-copy opportunistic routing algorithm, in which a time-sensitive forwarding set is maintained for each node by considering the probabilistic contacts in DTNs. By forwarding messages via nodes in these sets, TOUR can achieve the optimal expected utilities. We show the outstanding performance of TOUR through extensive simulations with several real DTN traces. To the best of our knowledge, TOUR is the first utility-based routing algorithm in DTNs.","Routing,
Nickel,
Delays,
Educational institutions,
Probabilistic logic,
Exponential distribution,
Probability density function"
A New Asymmetrical Half-Bridge Converter With Zero DC-Offset Current in Transformer,"This paper proposes an asymmetrical half-bridge (AHB) converter with a new secondary rectifier. Due to the new rectifier stage, the proposed AHB converter has a zero dc-offset current in the transformer at any operating conditions so that the transformer core loss becomes very small compared to the conventional AHB converter. This results in higher efficiency. Besides, magnetic components can be optimally utilized because maximum flux density can be applied when designing the magnetic components. It also allows a flexible design to improve the efficiency or reduce the cost. This paper presents the operation principle and relevant analysis results of the proposed converter. A 300 W, 200-400-V input, and 50-V output laboratory prototype operating at 100 kHz is built and tested to verify the effectiveness of the proposed converter.","Zero voltage switching,
Capacitors,
Stress,
Inductors,
Rectifiers,
Circuit faults,
Transformer cores"
Cloud Analytics for Capacity Planning and Instant VM Provisioning,"The popularity of cloud service spurs the increasing demands of virtual resources to the service vendors. Along with the promising business opportunities, it also brings new technique challenges such as effective capacity planning and instant cloud resource provisioning. In this paper, we describe our research efforts on improving the service quality for the capacity planning and instant cloud resource provisioning problem. We first formulate both of the two problems as a generic cost-sensitive prediction problem. Then, considering the highly dynamic environment of cloud, we propose an asymmetric and heterogeneous measure to quantify the prediction error. Finally, we design an ensemble prediction mechanism by combining the prediction power of a set of prediction techniques based on the proposed measure. To evaluate the effectiveness of our proposed solution, we design and implement an integrated prototype system to help improve the service quality of the cloud. Our system considers many practical situations of the cloud system, and is able to dynamically adapt to the changing environment. A series of experiments on the IBM Smart Cloud Enterprise (SCE) trace data demonstrate that our method can significantly improve the service quality by reducing the resource provisioning time while maintaining a low cloud overhead.",
General purpose computing on low-power embedded GPUs: Has it come of age?,"In this paper we evaluate the promise held by low-power GPUs for non-graphic workloads that arise in embedded systems. Towards this, we map and implement 5 benchmarks, that find utility in very different application domains, to an embedded GPU. Our results show that apart from accelerated performance, embedded GPUs are promising also because of their energy efficiency which is an important design goal for battery-driven mobile devices. We show that adopting the same optimization strategies as those used for programming high-end GPUs might lead to worse performance on embedded GPUs. This is due to restricted features of embedded GPUs, such as, limited or no user-defined memory, small instruction-set, limited number of registers, among others. We propose techniques to overcome such challenges, e.g., by distributing the workload between GPUs and multi-core CPUs, similar to the spirit of heterogeneous computation.","Graphics processing units,
Benchmark testing,
Instruction sets,
Kernel,
Current measurement,
Programming,
Data transfer"
Interactive Exploration of Surveillance Video through Action Shot Summarization and Trajectory Visualization,"We propose a novel video visual analytics system for interactive exploration of surveillance video data. Our approach consists of providing analysts with various views of information related to moving objects in a video. To do this we first extract each object's movement path. We visualize each movement by (a) creating a single action shot image (a still image that coalesces multiple frames), (b) plotting its trajectory in a space-time cube and (c) displaying an overall timeline view of all the movements. The action shots provide a still view of the moving object while the path view presents movement properties such as speed and location. We also provide tools for spatial and temporal filtering based on regions of interest. This allows analysts to filter out large amounts of movement activities while the action shot representation summarizes the content of each movement. We incorporated this multi-part visual representation of moving objects in sViSIT, a tool to facilitate browsing through the video content by interactive querying and retrieval of data. Based on our interaction with security personnel who routinely interact with surveillance video data, we identified some of the most common tasks performed. This resulted in designing a user study to measure time-to-completion of the various tasks. These generally required searching for specific events of interest (targets) in videos. Fourteen different tasks were designed and a total of 120 min of surveillance video were recorded (indoor and outdoor locations recording movements of people and vehicles). The time-to-completion of these tasks were compared against a manual fast forward video browsing guided with movement detection. We demonstrate how our system can facilitate lengthy video exploration and significantly reduce browsing time to find events of interest. Reports from expert users identify positive aspects of our approach which we summarize in our recommendations for future video visual analytics systems.","Interactive states,
Image segmentation,
Data visualization,
Visual analytics,
Surveillance,
Tracking,
Navigation"
Energy-Efficient Digital Signal Processing via Voltage-Overscaling-Based Residue Number System,"In this paper, we apply the voltage overscaling (VOS) technique to the residue-number-system (RNS)-based digital signal processing system for achieving high energy efficiency. To mitigate the soft errors caused by VOS, we propose a new method, called joint RNS-RPR (JRR), which is the combination of RNS and the reduced precision redundancy (RPR) technique. The JRR technology inherits the properties of RNS, including shorter critical path, low complexity, and low power. Moreover, JRR can achieve higher power reduction than RNS for VOS applications. Since the soft errors caused by VOS lead to significant performance degradation of RNS, we use the information from RNS and RPR to achieve a high recovering probability of the soft errors with low hardware complexity. From the case study of finite impulse response (FIR) filter design based on the 0.25- μm 2.5-V CMOS technology, we find that JRR can save 62% more energy compared to the traditional FIR with a less than 2-dB signal noise ratio performance loss. We also find that JRR has lower complexity and better performance than the traditional soft error mitigation methods.","Digital signal processing,
CMOS integrated circuits,
Finite impulse response filter,
Probability,
Circuit complexity,
Radiation hardening (electronics)"
Interventional Tool Tracking Using Discrete Optimization,"This work presents a novel scheme for tracking of motion and deformation of interventional tools such as guide-wires and catheters in fluoroscopic X-ray sequences. Being able to track and thus to estimate the correct positions of these tools is crucial in order to offer guidance enhancement during interventions. The task of estimating the apparent motion is particularly challenging due to the low signal-to-noise ratio (SNR) of fluoroscopic images and due to combined motion components originating from patient breathing and tool interactions performed by the physician. The presented approach is based on modeling interventional tools with B-splines whose optimal configuration of control points is determined through efficient discrete optimization. Each control point corresponds to a discrete random variable in a Markov random field (MRF) formulation where a set of labels represents the deformation space. In this context, the optimal curve corresponds to the maximum a posteriori (MAP) estimate of the MRF energy. The main motivation for employing a discrete approach is the possibility to incorporate a multi-directional search space which is robust to local minima. This is of particular interest for curve tracking under large deformation. This work analyzes feasibility of employing efficient first-order MRFs for tracking. In particular it shows how to achieve a good compromise between energy approximations and computational efficiency. Experimental results suggest to define both the external and internal energy in terms of pairwise potential functions. The method was successfully applied to the tracking of guide-wires in fluoroscopic X-ray sequences of several hundred frames which requires extremely robust techniques. Comparisons with state-of-the-art guide-wire tracking algorithms confirm the effectiveness of the proposed method.","Tracking,
Splines (mathematics),
Optimization,
Navigation,
Wires,
Aerospace electronics,
Robustness"
How Can Online Schedules Improve Communication and Estimation Tradeoff?,"We consider remote state estimation and investigate the tradeoff between the sensor-to-estimator communication rate and the remote estimation quality. It is well known that if the communication rate is one, e.g., the sensor communicates with the remote estimator at each time, then the remote estimation quality is the best. It degrades when the communication rate drops. We present one optimal offline schedule and two online schedules and show that the two online schedules provide better tradeoff between the communication rate and the estimation quality than the optimal offline schedule. Simulation examples demonstrate that significant communication savings can be achieved under the two online schedules which only introduce small increment of the estimation errors.",
Multi-Stage Non-Negative Matrix Factorization for Monaural Singing Voice Separation,"Separating singing voice from music accompaniment can be of interest for many applications such as melody extraction, singer identification, lyrics alignment and recognition, and content-based music retrieval. In this paper, a novel algorithm for singing voice separation in monaural mixtures is proposed. The algorithm consists of two stages, where non-negative matrix factorization (NMF) is applied to decompose the mixture spectrograms with long and short windows respectively. A spectral discontinuity thresholding method is devised for the long-window NMF to select out NMF components originating from pitched instrumental sounds, and a temporal discontinuity thresholding method is designed for the short-window NMF to pick out NMF components that are from percussive sounds. By eliminating the selected components, most pitched and percussive elements of the music accompaniment are filtered out from the input sound mixture, with little effect on the singing voice. Extensive testing on the MIR-1K public dataset of 1000 short audio clips and the Beach-Boys dataset of 14 full-track real-world songs showed that the proposed algorithm is both effective and efficient.","speech synthesis,
filtering theory,
matrix decomposition"
Proactive Vehicular Traffic Rerouting for Lower Travel Time,"Traffic congestion causes driver frustration and costs billions of dollars annually in lost time and fuel consumption. This paper presents five traffic rerouting strategies designed to be incorporated in a cost-effective and easily deployable vehicular traffic guidance system that reduces travel time. The proposed strategies proactively compute individually tailored rerouting guidance to be pushed to vehicles when signs of congestion are observed on their route. The five proposed strategies are the dynamic shortest path (DSP), the A* shortest path with repulsion (AR*), the random k shortest path (RkSP), the entropy-balanced kSP (EBkSP), and the flow-balanced kSP (FBkSP). Extensive simulation results show that the proposed strategies are capable of reducing the travel time as much as a state-of-the-art dynamic traffic assignment (DTA) algorithm while avoiding the issues that make DTA impractical, such as the lack of scalability and robustness, and high computation time. Furthermore, the variety of proposed strategies allows tuning the system to different levels of tradeoffs between rerouting effectiveness and computational efficiency. In addition, the proposed traffic guidance system can significantly improve the traffic even if many drivers ignore the guidance or if the system adoption rate is relatively low.",
Image Set Based Face Recognition Using Self-Regularized Non-Negative Coding and Adaptive Distance Metric Learning,"Simple nearest neighbor classification fails to exploit the additional information in image sets. We propose self-regularized nonnegative coding to define between set distance for robust face recognition. Set distance is measured between the nearest set points (samples) that can be approximated from their orthogonal basis vectors as well as from the set samples under the respective constraints of self-regularization and nonnegativity. Self-regularization constrains the orthogonal basis vectors to be similar to the approximated nearest point. The nonnegativity constraint ensures that each nearest point is approximated from a positive linear combination of the set samples. Both constraints are formulated as a single convex optimization problem and the accelerated proximal gradient method with linear-time Euclidean projection is adapted to efficiently find the optimal nearest points between two image sets. Using the nearest points between a query set and all the gallery sets as well as the active samples used to approximate them, we learn a more discriminative Mahalanobis distance for robust face recognition. The proposed algorithm works independently of the chosen features and has been tested on gray pixel values and local binary patterns. Experiments on three standard data sets show that the proposed method consistently outperforms existing state-of-the-art methods.","Measurement,
Face,
Vectors,
Image coding,
Face recognition,
Manifolds,
Optimization"
Reliability of Nonrepairable Phased-Mission Systems With Common Cause Failures,"Phased-mission systems (PMSs) are systems supporting missions characterized by multiple, consecutive, and nonoverlapping phases of operation. Examples of PMSs abound in many practical applications such as aerospace, nuclear power, and airborne weapon systems. Reliability analysis of a PMS must consider statistical dependence of component states across different phases, as well as dynamics in system structure functions and component behavior. In this paper, we propose a recursive method for exact reliability evaluation of a binary-state or multistate PMS consisting of nonidentical, binary, and nonrepairable elements. The system elements can fail individually or due to common-cause failures (CCFs) caused by some external factors. The proposed method is based on the branch-and-bound principle, and can be fully automated. The method is applicable to PMSs with nonoverlapping or overlapping sets of elements that can fail as a result of CCFs. The method is illustrated using both analytical and numerical examples.","Reliability,
Educational institutions,
Analytical models,
Cybernetics,
Indexes,
Acceleration,
Collaboration"
Relay Selection for Geographical Forwarding in Sleep-Wake Cycling Wireless Sensor Networks,"Our work is motivated by geographical forwarding of sporadic alarm packets to a base station in a wireless sensor network (WSN), where the nodes are sleep-wake cycling periodically and asynchronously. We seek to develop local forwarding algorithms that can be tuned so as to tradeoff the end-to-end delay against a total cost, such as the hop count or total energy. Our approach is to solve, at each forwarding node enroute to the sink, the local forwarding problem of minimizing one-hop waiting delay subject to a lower bound constraint on a suitable reward offered by the next-hop relay; the constraint serves to tune the tradeoff. The reward metric used for the local problem is based on the end-to-end total cost objective (for instance, when the total cost is hop count, we choose to use the progress toward sink made by a relay as the reward). The forwarding node, to begin with, is uncertain about the number of relays, their wake-up times, and the reward values, but knows the probability distributions of these quantities. At each relay wake-up instant, when a relay reveals its reward value, the forwarding node's problem is to forward the packet or to wait for further relays to wake-up. In terms of the operations research literature, our work can be considered as a variant of the asset selling problem. We formulate our local forwarding problem as a partially observable Markov decision process (POMDP) and obtain inner and outer bounds for the optimal policy. Motivated by the computational complexity involved in the policies derived out of these bounds, we formulate an alternate simplified model, the optimal policy for which is a simple threshold rule. We provide simulation results to compare the performance of the inner and outer bound policies against the simple policy, and also against the optimal policy when the source knows the exact number of relays. Observing the good performance and the ease of implementation of the simple policy, we apply it to our motivating problem, i.e., local geographical routing of sporadic alarm packets in a large WSN. We compare the end-to-end performance (i.e., average total delay and average total cost) obtained by the simple policy, when used for local geographical forwarding, against that obtained by the globally optimal forwarding algorithm proposed by Kim et al.","Relays,
Delay,
Wireless sensor networks,
Mobile computing,
Computational modeling,
Probability"
A Lumped-Element Unit Cell for Beam-Forming Networks and Its Application to a Miniaturized Butler Matrix,"A lumped-element unit cell for designing compact beam-forming networks (BFNs) is proposed. It is a reciprocal four-port network, which is lossless, isolated, and matched at all ports. The unit cell is designed to behave as planar and compact directional couplers with both arbitrary output amplitude and phase distributions, as well as crossovers with arbitrary output phase distributions. For both cases, design equations are derived. The design procedure is validated numerically and experimentally through several examples. The versatility of the unit cell allows the design of BFNs using only the proposed network topology. As an example, a 4\,\times\,
4 Butler matrix is implemented. A strong size reduction is also achieved with respect to classical designs thanks to the lumped-element implementation. The prototype footprint is approximately 25 times smaller than typical transmission-line-based Butler matrices. The structure shows also a very small area compared to state-of-the-art miniaturized 4\,\times\,
4 Butler matrix designs. Measurement results confirm the behavior of the Butler matrix as a BFN. The achieved bandwidth is approximately 8%.","Ports (Computers),
Butler matrix,
Directional couplers,
Microstrip,
Transmission line matrix methods,
Bandwidth"
Anomaly Detection Based Secure In-Network Aggregation for Wireless Sensor Networks,"Secure in-network aggregation in wireless sensor networks (WSNs) is a necessary and challenging task. In this paper, we first propose integration of system monitoring modules and intrusion detection modules in the context of WSNs. We propose an extended Kalman filter (EKF) based mechanism to detect false injected data. Specifically, by monitoring behaviors of its neighbors and using EKF to predict their future states (actual in-network aggregated values), each node aims at setting up a normal range of the neighbors' future transmitted aggregated values. This task is challenging because of potential high packet loss rate, harsh environment, and sensing uncertainty. We illustrate how to use EKF to address this challenge to create effective local detection mechanisms. Using different aggregation functions (average, sum, max, and min), we present how to obtain a theoretical threshold. We further apply an algorithm of combining cumulative summation and generalized likelihood ratio to increase detection sensitivity. To overcome the limitations of local detection mechanisms, we illustrate how our proposed local detection approaches work together with the system monitoring module to differentiate between malicious events and emergency events. We conduct experiments and simulations to evaluate local detection mechanisms under different aggregation functions.",
Information-Theoretic Outlier Detection for Large-Scale Categorical Data,"Outlier detection can usually be considered as a pre-processing step for locating, in a data set, those objects that do not conform to well-defined notions of expected behavior. It is very important in data mining for discovering novel or rare events, anomalies, vicious actions, exceptional phenomena, etc. We are investigating outlier detection for categorical data sets. This problem is especially challenging because of the difficulty of defining a meaningful similarity measure for categorical data. In this paper, we propose a formal definition of outliers and an optimization model of outlier detection, via a new concept of holoentropy that takes both entropy and total correlation into consideration. Based on this model, we define a function for the outlier factor of an object which is solely determined by the object itself and can be updated efficiently. We propose two practical 1-parameter outlier detection methods, named ITB-SS and ITB-SP, which require no user-defined parameters for deciding whether an object is an outlier. Users need only provide the number of outliers they want to detect. Experimental results show that ITB-SS and ITB-SP are more effective and efficient than mainstream methods and can be used to deal with both large and high-dimensional data sets where existing algorithms fail.","Information retrieval,
Search methods,
Mutual information,
Greedy algorithms,
Complexity theory,
Holoentropy"
Piecewise Convex Multiple-Model Endmember Detection and Spectral Unmixing,A hyperspectral endmember detection and spectral unmixing algorithm that finds multiple sets of endmembers is presented. Hyperspectral data are often nonconvex. The Piecewise Convex Multiple-Model Endmember Detection algorithm accounts for this using a piecewise convex model. Multiple sets of endmembers and abundances are found using an iterative fuzzy clustering and spectral unmixing method. The results indicate that the piecewise convex representation estimates endmembers that better represent hyperspectral imagery composed of multiple regions where each region is represented with a distinct set of endmembers.,"Hyperspectral imaging,
Image analysis,
Image segmentation,
Algorithm design and analysis"
Q-Learning Based Energy Management Policies for a Single Sensor Node with Finite Buffer,"In this paper, we consider the problem of finding optimal energy management policies in the presence of energy harvesting sources to maximize network performance. We formulate this problem in the discounted cost Markov decision process framework and apply two reinforcement learning algorithms. Prior work obtains optimal policy in the case when the conversion function mapping energy to data transmitted is linear and provides heuristic policies in the case when the same is nonlinear. Our algorithms, however, provide optimal policies regardless of the form of the conversion function. Through simulations, our policies are seen to outperform those of in the nonlinear case.","Energy management,
Cost function,
Convergence,
Energy harvesting,
Equations,
Wireless communication,
Mathematical model"
Analysis of Joint Connectivity Condition for Multiagents With Boundary Constraints,The connectivity of a group of agents in a flocking scenario is caused either by individual's local cohesion interaction mechanism or by external boundary constraints. The latter case is particularly interesting when an individual's cohesion ability is not reliable due to the limitation of communication range. The effect of external boundary constraints on the connectivity property of multiagents has been intensively investigated in natural observation and engineering simulation. A theoretical analysis is given in this paper which reveals that a group of agents in a bounded plane can be almost always jointly connected and hence form a complete flock.,
Incorporating Privileged Information Through Metric Learning,"In some pattern analysis problems, there exists expert knowledge, in addition to the original data involved in the classification process. The vast majority of existing approaches simply ignore such auxiliary (privileged) knowledge. Recently a new paradigm-learning using privileged information-was introduced in the framework of SVM+. This approach is formulated for binary classification and, as typical for many kernel-based methods, can scale unfavorably with the number of training examples. While speeding up training methods and extensions of SVM+ to multiclass problems are possible, in this paper we present a more direct novel methodology for incorporating valuable privileged knowledge in the model construction phase, primarily formulated in the framework of generalized matrix learning vector quantization. This is done by changing the global metric in the input space, based on distance relations revealed by the privileged information. Hence, unlike in SVM+, any convenient classifier can be used after such metric modification, bringing more flexibility to the problem of incorporating privileged information during the training. Experiments demonstrate that the manipulation of an input space metric based on privileged data improves classification accuracy. Moreover, our methods can achieve competitive performance against the SVM+ formulations.",
ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data,"This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.","Nerve fibers,
Data visualization,
Neuroscience,
Three-dimensional displays,
Query processing"
"Toward a reliable, secure and fault tolerant smart grid state estimation in the cloud","The collection and prompt analysis of synchrophasor measurements is a key step towards enabling the future smart power grid, in which grid management applications would be deployed to monitor and react intelligently to changing conditions. The potential exists to slash inefficiencies and to adaptively reconfigure the grid to take better advantage of renewables, coordinate and share reactive power, and to reduce the risk of catastrophic large-scale outages. However, to realize this potential, a number of technical challenges must be overcome. We describe a continuously active, timely monitoring framework that we have created, architected to support a wide range of grid-control applications in a standard manner designed to leverage cloud computing. Cloud computing systems bring significant advantages, including an elastic, highly available and cost-effective compute infrastructure well-suited for this application. We believe that by showing how challenges of reliability, timeliness, and security can be addressed while leveraging cloud standards, our work opens the door for wider exploitation of the cloud by the smart grid community. This paper characterizes a PMU-based state-estimation application, explains how the desired system maps to a cloud architecture, identifies limitations in the standard cloud infrastructure relative to the needs of this use-case, and then shows how we adapt the basic cloud platform options with sophisticated technologies of our own to achieve the required levels of usability, fault tolerance, and parallelism.","Phasor measurement units,
Cloud computing,
State estimation,
Smart grids,
Monitoring,
Power measurement,
Extraterrestrial measurements"
Signal Processing and Machine Learning with Differential Privacy: Algorithms and Challenges for Continuous Data,"Private companies, government entities, and institutions such as hospitals routinely gather vast amounts of digitized personal information about the individuals who are their customers, clients, or patients. Much of this information is private or sensitive, and a key technological challenge for the future is how to design systems and processing techniques for drawing inferences from this large-scale data while maintaining the privacy and security of the data and individual identities. Individuals are often willing to share data, especially for purposes such as public health, but they expect that their identity or the fact of their participation will not be disclosed. In recent years, there have been a number of privacy models and privacy-preserving data analysis algorithms to answer these challenges. In this article, we will describe the progress made on differentially private machine learning and signal processing.","Privacy,
Data privacy,
Signal processing algorithms,
Approximation methods,
Noise measurement,
Computer security"
Generating Erroneous Human Behavior From Strategic Knowledge in Task Models and Evaluating Its Impact on System Safety With Model Checking,"Human-automation interaction, including erroneous human behavior, is a factor in the failure of complex, safety-critical systems. This paper presents a method for automatically generating formal task analytic models encompassing both erroneous and normative human behavior from normative task models, where the misapplication of strategic knowledge is used to generate erroneous behavior. Resulting models can be automatically incorporated into larger formal system models so that safety properties can be formally verified with a model checker. This allows analysts to prove that a human-automation interactive system (as represented by the formal model) will or will not satisfy safety properties with both normative and generated erroneous human behavior. Benchmarks are reported that illustrate how this method scales. The method is then illustrated with a case study: the programming of a patient-controlled analgesia pump. In this example, a problem resulting from a generated erroneous human behavior is discovered. The method is further employed to evaluate the effectiveness of different solutions to the discovered problem. The results and future research directions are discussed.","Human factors,
System testing,
Model checking,
Human computer interaction"
CMOS Sensor Arrays for High Resolution Die Stress Mapping in Packaged Integrated Circuits,"This paper reports the design, calibration and application of multiplexed arrays of piezoresistive field-effect transistor stress sensors fabricated in a standard complementary-metal-oxide semiconductor (CMOS) process. Two complementary arrays of 256-current mirror sensor cells provide high spatial density stress mapping with approximately 300 pts/mm2 using only a 1.5 μm process. The arrays are sequentially scanned by an on-chip counter, producing efficient stress measurement, and the sensors resolve normal and shear stresses on the surface of the die with resolution below 1 MPa. The CMOS sensor chips have been used to map stress over a large portion of the die in chip-on-beam and encapsulated chip-on-beam samples, as well as a ceramic dual-in-line package with its cavity filled with underfill material. Finite-element simulation results correlate well with the measured stress distributions. The experimental results from these chips are used to validate finite-element simulation models, and the array designs can be used as subarrays in much larger test chips.","Stress,
Transistors,
Sensor arrays,
CMOS integrated circuits,
Semiconductor device measurement,
Mirrors,
Silicon"
Sparse Filter Design Under a Quadratic Constraint: Low-Complexity Algorithms,"This paper considers three problems in sparse filter design, the first involving a weighted least-squares constraint on the frequency response, the second a constraint on mean squared error in estimation, and the third a constraint on signal-to-noise ratio in detection. The three problems are unified under a single framework based on sparsity maximization under a quadratic performance constraint. Efficient and exact solutions are developed for specific cases in which the matrix in the quadratic constraint is diagonal, block-diagonal, banded, or has low condition number. For the more difficult general case, a low-complexity algorithm based on backward greedy selection is described with emphasis on its efficient implementation. Examples in wireless channel equalization and minimum-variance distortionless-response beamforming show that the backward selection algorithm yields optimally sparse designs in many instances while also highlighting the benefits of sparse design.","Algorithm design and analysis,
Equalizers,
Signal to noise ratio,
Frequency response,
Estimation,
Chebyshev approximation,
Measurement"
Efficient Image Classification via Multiple Rank Regression,"The problem of image classification has aroused considerable research interest in the field of image processing. Traditional methods often convert an image to a vector and then use a vector-based classifier. In this paper, a novel multiple rank regression model (MRR) for matrix data classification is proposed. Unlike traditional vector-based methods, we employ multiple-rank left projecting vectors and right projecting vectors to regress each matrix data set to its label for each category. The convergence behavior, initialization, computational complexity, and parameter determination are also analyzed. Compared with vector-based regression methods, MRR achieves higher accuracy and has lower computational complexity. Compared with traditional supervised tensor-based methods, MRR performs better for matrix data classification. Promising experimental results on face, object, and hand-written digit image classification tasks are provided to show the effectiveness of our method.","Vectors,
Tensile stress,
Training,
Matrix converters,
Image classification,
Optimization,
Algorithm design and analysis"
Infrastructure-assisted smartphone-based ADL recognition in multi-inhabitant smart environments,"We propose a hybrid approach for recognizing complex Activities of Daily Living that lie between the two extremes of intensive use of body-worn sensors and the use of infrastructural sensors. Our approach harnesses the power of infrastructural sensors (e.g., motion sensors) to provide additional `hidden' context (e.g., room-level location) of an individual and combines this context with smartphone-based sensing of micro-level postural/locomotive states. The major novelty is our focus on multi-inhabitant environments, where we show how spatiotemporal constraints can be used to significantly improve the accuracy and computational overhead of traditional coupled-HMM based approaches. Experimental results on a smart home dataset demonstrate that this approach improves the accuracy of complex ADL classification by over 30% compared to pure smartphone-based solutions.","Context,
Hidden Markov models,
Intelligent sensors,
Legged locomotion,
Accelerometers,
Context modeling"
Combining Multiple Classification Methods for Hyperspectral Data Interpretation,"In the past few years, Hyperspectral image analysis has been used for many purposes in the field of remote sensing and importantly for land cover classification. Land cover classification is a challenging task and the production of accurate thematic maps is a common goal among researchers. A hyperspectral image is composed of hundreds of spectral channels, where each channel refers to a specific wavelength. Such a large amount of information may lead us to a deeper investigation of the materials on Earth's surface, and thus, a more precise interpretation of them. In this work, we aim to produce a thematic map that is more accurate by combining multiple classification methods. Three feature representations based on spectral and spatial data and two learning algorithms (Support Vector Machines (SVM) and Multilayer Perceptron Neural Network (MLP)) were used to produce six different classification methods to perform the combination. Our combining approach is based on Weighted Linear Combination (WLC), in which weights are found using a Genetic Algorithm (GA)-WLC-GA. Experiments were carried out with two well-known datasets: Indian Pines and Pavia University. In order to evaluate the robustness of the proposed combiner, experiments using different training sizes were conducted. They show promising results for both datasets for our WLC-GA proposal and are better than the widely used Majority Vote (MV) and Average rules in terms of accuracy. By using only 10% of training samples, our proposal was able to find the best weights and overcome the drawbacks of the traditional combination rules.","terrain mapping,
genetic algorithms,
geophysical image processing,
hyperspectral imaging,
image classification,
learning (artificial intelligence),
multilayer perceptrons,
remote sensing,
support vector machines"
Digital bimodal function: An ultra-low energy security primitive,"We have developed a new security hardware primitive named digital bimodal function (DBF) that enables ultra low energy security protocols. DBF allows the computation of legitimate communicating sides to be compact and low-energy while it requires any attacker exponential computational effort and energy expense. Our new approach is competitive with the energy efficiency of traditional security key cryptographic security technique (e.g., AES) while more than three orders of magnitude more energy efficient than RSA. The implementation is demonstrated using the Xilinx FPGA platform.","Table lookup,
Public key,
Protocols,
Field programmable gate arrays,
Vectors,
Boolean functions"
Sampling and Reconstruction of Spatial Fields Using Mobile Sensors,"Spatial sampling is traditionally studied in a static setting where static sensors scattered around space take measurements of the spatial field at their locations. In this paper, we study the emerging paradigm of sampling and reconstructing spatial fields using sensors that move through space. We show that mobile sensing offers some unique advantages over static sensing in sensing bandlimited spatial fields. Since a moving sensor encounters such a spatial field along its path as a time-domain signal, a time-domain anti-aliasing filter can be employed prior to sampling the signal received at the sensor. Such a filtering procedure, when used by a configuration of sensors moving at constant speeds along equispaced parallel lines, leads to a complete suppression of spatial aliasing in the direction of motion of the sensors. We analytically quantify the advantage of using such a sampling scheme over a static sampling scheme by computing the reduction in sampling noise due to the filter. We also analyze the effects of nonuniform sensor speeds on the reconstruction accuracy. Using simulation examples, we demonstrate the advantages of mobile sampling over static sampling in practical problems. We extend our analysis to sampling and reconstruction schemes for monitoring time-varying bandlimited fields using mobile sensors. We demonstrate that in some situations we require a lower density of sensors when using a mobile sensing scheme instead of the conventional static sensing scheme. The exact advantage is quantified for a problem of sampling and reconstructing an audio field.","Sensors,
Mobile communication,
Noise,
Time domain analysis,
Smoothing methods,
Pollution measurement,
Noise measurement"
Cache content placement using triangular network coding,"Video is one of the main causes of the dramatic increase in data traffic over cellular networks. Caching is an effective mechanism that decreases the download rate from base stations and, as a result, the load on the base station, by storing the most popular files or videos on the caches and providing them to the users. The problem of efficient content placement on the caches is known as an NP-complete problem. In this paper, we study the role of network coding by increasing the amount of available data to the users through the cache nodes. We propose a network coding-based content placement method, and we compare it to the best uncoded content placement and the best triangular network coding strategies. Our method not only increases the amount of available data to the users, but also results in a fair distribution of data.",
Multiple Access Demodulation in the Lifted Signal Graph With Spatial Coupling,"Demodulation in a random multiple access channel is considered where the signals are chosen uniformly randomly with unit energy. It is shown that by lifting (replicating) the graph of this system and randomizing the graph connections, a simple iterative cancellation demodulator achieves the same performance as an optimal symbol-by-symbol detector of the original system. The iterative detector has a complexity that is linear in the number of users, while the direct optimal approach is known to be NP-hard. However, the maximal system load of this lifted graph is limited to \alpha < 2.07
, even for large signal-to-noise ratios (SNRs)—the system is interference limited. Spatial coupling between subsequent lifted graphs is introduced, and anchoring the initial graphs, the achievable system load \alpha
can go to infinity as the SNR goes to infinity. Our results apply to several well-documented system proposals, such as interleave-division multiple access, partitioned spreading, and certain forms of multiple-input multiple-output communications.",
Distributed Software Architecture Enabling Peer-to-Peer Communicating Controllers,"This paper presents a novel model-driven software architecture for systems with high degree of redundancy and modularity of the equipment. The architecture is based on totally decentralized control. It combines adaptability and robustness of multi-agent control architectures with portability and interoperability benefits of IEC 61499 function block architecture. The architecture has been successfully proven feasible on a number of field trials, including modeling and implementation of a medium-scale airport baggage handling control. Deployment was done on distributed networks consisting of configurations ranging from a few to dozens of communicating control nodes. The work confirmed the ability to deliver similar functional characteristics as centralized systems but in a distributed implementation. Performance testing and development verified sufficient performance and software life-cycle benefits.","IEC standards,
Routing,
Software architecture,
Peer-to-peer computing,
Intelligent control"
SCRAP: Architecture for signature-based protection from Code Reuse Attacks,"Code Reuse Attacks (CRAs) recently emerged as a new class of security exploits. CRAs construct malicious programs out of small fragments (gadgets) of existing code, thus eliminating the need for code injection. Existing defenses against CRAs often incur large performance overheads or require extensive binary rewriting and other changes to the system software. In this paper, we examine a signature-based detection of CRAs, where the attack is detected by observing the behavior of programs and detecting the gadget execution patterns. We first demonstrate that naive signature-based defenses can be defeated by introducing special “delay gadgets” as part of the attack. We then show how a software-configurable signature-based approach can be designed to defend against such stealth CRAs, including the attacks that manage to use longer-length gadgets. The proposed defense (called SCRAP) can be implemented entirely in hardware using simple logic at the commit stage of the pipeline. SCRAP is realized with minimal performance cost, no changes to the software layers and no implications on binary compatibility. Finally, we show that SCRAP generates no false alarms on a wide range of applications.","Delays,
Registers,
Libraries,
Hardware,
Software,
Detectors,
Security"
Optimal Control on Lie Groups: The Projection Operator Approach,"Many nonlinear systems of practical interest evolve on Lie groups or on manifolds acted upon by Lie groups. Examples range from aircraft and underwater vehicles to quantum mechanical systems. In this paper, we develop an algorithm for solving continuous-time optimal control problems for systems evolving on (noncompact) Lie groups. This algorithm generalizes the projection operator approach for trajectory optimization originally developed for systems on vector spaces. Notions for generalizing system theoretic tools such as Riccati equations and linear and quadratic system approximations are developed. In this development, the covariant derivative of a map between two manifolds plays a key role in providing a chain rule for the required Lie group computations. An example optimal control problem on SO(3) is provided to highlight implementation details and to demonstrate the effectiveness of the method.",
When Does Computational Imaging Improve Performance?,"A number of computational imaging techniques are introduced to improve image quality by increasing light throughput. These techniques use optical coding to measure a stronger signal level. However, the performance of these techniques is limited by the decoding step, which amplifies noise. Although it is well understood that optical coding can increase performance at low light levels, little is known about the quantitative performance advantage of computational imaging in general settings. In this paper, we derive the performance bounds for various computational imaging techniques. We then discuss the implications of these bounds for several real-world scenarios (e.g., illumination conditions, scene properties, and sensor noise characteristics). Our results show that computational imaging techniques do not provide a significant performance advantage when imaging with illumination that is brighter than typical daylight. These results can be readily used by practitioners to design the most suitable imaging systems given the application at hand.","Cameras,
Signal to noise ratio,
Multiplexing,
Lighting,
Performance gain"
A Locally Adaptive Regularization Based on Anisotropic Diffusion for Deformable Image Registration of Sliding Organs,"We propose a deformable image registration algorithm that uses anisotropic smoothing for regularization to find correspondences between images of sliding organs. In particular, we apply the method for respiratory motion estimation in longitudinal thoracic and abdominal computed tomography scans. The algorithm uses locally adaptive diffusion tensors to determine the direction and magnitude with which to smooth the components of the displacement field that are normal and tangential to an expected sliding boundary. Validation was performed using synthetic, phantom, and 14 clinical datasets, including the publicly available DIR-Lab dataset. We show that motion discontinuities caused by sliding can be effectively recovered, unlike conventional regularizations that enforce globally smooth motion. In the clinical datasets, target registration error showed improved accuracy for lung landmarks compared to the diffusive regularization. We also present a generalization of our algorithm to other sliding geometries, including sliding tubes (e.g., needles sliding through tissue, or contrast agent flowing through a vessel). Potential clinical applications of this method include longitudinal change detection and radiotherapy for lung or abdominal tumours, especially those near the chest or abdominal wall.","Smoothing methods,
Computed tomography,
Image registration,
Lungs,
Equations,
Mathematical model,
Tensile stress"
Grand Challenges in Bioengineered Nanorobotics for Cancer Therapy,"One of the grand challenges currently facing engineering, life sciences, and medicine is the development of fully functional nanorobots capable of sensing, decision making, and actuation. These nanorobots may aid in cancer therapy, site-specific drug delivery, circulating diagnostics, advanced surgery, and tissue repair. In this paper, we will discuss, from a bioinspired perspective, the challenges currently facing nanorobotics, including core design, propulsion and power generation, sensing, actuation, control, decision making, and system integration. Using strategies inspired from microorganisms, we will discuss a potential bioengineered nanorobot for cancer therapy.","Nanobioscience,
Nanoparticles,
Cancer,
Medical treatment,
Propulsion,
Payloads,
Tumors"
Kinect-Like Depth Data Compression,"Unlike traditional RGB video, Kinect-like depth is characterized by its large variation range and instability. As a result, traditional video compression algorithms cannot be directly applied to Kinect-like depth compression with respect to coding efficiency. In this paper, we propose a lossy Kinect-like depth compression framework based on the existing codecs, aiming to enhance the coding efficiency while preserving the depth features for further applications. In the proposed framework, the Kinect-like depth is reformed first by divisive normalized bilateral filter (DNBL) to suppress the depth noises caused by disparity normalization, and then block-level depth padding is implemented for invalid depth region compensation in collaboration with mask coding to eliminate the sharp variation caused by depth measurement failures. Before the traditional video coding, the inter-frame correlation of reformed depth is explored by proposed 2D+T prediction, in which depth volume is developed to simulate 3D volume to generate pseudo 3D prediction reference for depth uniqueness detection. The unique depth region, called active region is fed into the video encoder for traditional intra and inter prediction with residual coding, while the inactive region is skipped during depth coding. The experimental results demonstrate that our compression scheme can save 55%-85% in terms of bit cost and reduce coding complexity by 20%-65% in comparison with the traditional video compression algorithms. The visual quality of the 3D reconstruction is also improved after employing our compression scheme.","Encoding,
Image coding,
Cameras,
Video coding,
Real-time systems,
Servers,
Transform coding"
An Energy-Efficient ECG Processor in 45-nm CMOS Using Statistical Error Compensation,"A subthreshold ECG processor in 45-nm IBM SOI CMOS is designed to operate at the minimum energy operating point (MEOP). Statistical error compensation (SEC) is employed to further reduce energy (Emin) at the MEOP. SEC is shown to reduce Emin by 28% compared with the conventional (error-free) case while maintaining acceptable beat-detection performance. SEC enables the supply voltage to be scaled to 15% below its critical value at MEOP, while compensating for a 58% precorrection error rate pe. These results represent an improvement of 19× in beat-detection performance and 600× in pe over conventional (error-free) systems. The prototype IC consumes 14.5 fJ/cycle/1k-gate and exhibits 4.7× better energy efficiency than the state of the art while tolerating 16× more voltage variations.","Electrocardiography,
Error analysis,
Error compensation,
Robustness,
Computer architecture,
Accuracy,
Timing"
Comparison of Strategies for Enhancing Energy Capture and Reducing Loads Using LIDAR and Feedforward Control,"In this paper, we investigate strategies to enhance turbine energy capture and mitigate fatigue loads using pulsed light detection and ranging (LIDAR) system-enabled torque control strategies. To enhance energy capture when a turbine is operating below rated wind speed, three advanced LIDAR-enabled torque controllers are proposed: the disturbance tracking control (DTC) augmented with LIDAR, the optimally tracking rotor (OTR) control augmented with LIDAR, and LIDAR-based preview control. The DTC with LIDAR and LIDAR-based preview control is combined with a linear quadratic regulator in the feedback path, while OTR is a strategy adapted from a quadratic kΩ2 torque feedback control. These control strategies are simulated in turbulent wind files and their performance is compared against the baseline kΩ2 control scheme. We also consider the effects of different LIDAR update rates and range gates. It is shown that LIDAR-enabled controllers have only a small effect on energy capture at the cost of increased control action and low-speed shaft torque load. However, when considering a combination of fatigue load mitigation, power capture enhancement, and control authority requirements, the LIDAR-enabled preview controller outperforms the baseline kΩ2 controller.","wind turbines,
fatigue,
feedforward,
linear quadratic control,
optical radar,
power generation control,
shafts,
torque control"
An Explicit Nonlinear Mapping for Manifold Learning,"Manifold learning is a hot research topic in the held of computer science and has many applications in the real world. A main drawback of manifold learning methods is, however, that there are no explicit mappings from the input data manifold to the output embedding. This prohibits the application of manifold learning methods in many practical problems such as classification and target detection. Previously, in order to provide explicit mappings for manifold learning methods, many methods have been proposed to get an approximate explicit representation mapping with the assumption that there exists a linear projection between the high-dimensional data samples and their low-dimensional embedding. However, this linearity assumption may be too restrictive. In this paper, an explicit nonlinear mapping is proposed for manifold learning, based on the assumption that there exists a polynomial mapping between the high-dimensional data samples and their low-dimensional representations. As far as we know, this is the hrst time that an explicit nonlinear mapping for manifold learning is given. In particular, we apply this to the method of locally linear embedding and derive an explicit nonlinear manifold learning algorithm, which is named neighborhood preserving polynomial embedding. Experimental results on both synthetic and real-world data show that the proposed mapping is much more effective in preserving the local neighborhood information and the nonlinear geometry of the high-dimensional data samples than previous work.",
Global Manhunt Pushes the Limits of Social Mobilization,"Using social media and only the targets' mug shots, a team competing in the US State Department-sponsored Tag Challenge located three of five targeted people in five cities in the US and Europe in less than 12 hours.","Media,
Social network services,
Incentive schemes,
Particle measurements,
Government policies,
Surveillance"
Security Analysis of a Single Sign-On Mechanism for Distributed Computer Networks,"Single sign-on (SSO) is a new authentication mechanism that enables a legal user with a single credential to be authenticated by multiple service providers in a distributed computer network. Recently, Chang and Lee proposed a new SSO scheme and claimed its security by providing well-organized security arguments. In this paper, however, we demonstrative that their scheme is actually insecure as it fails to meet credential privacy and soundness of authentication. Specifically, we present two impersonation attacks. The first attack allows a malicious service provider, who has successfully communicated with a legal user twice, to recover the user's credential and then to impersonate the user to access resources and services offered by other service providers. In another attack, an outsider without any credential may be able to enjoy network services freely by impersonating any legal user or a nonexistent user. We identify the flaws in their security arguments to explain why attacks are possible against their SSO scheme. Our attacks also apply to another SSO scheme proposed by Hsu and Chuang, which inspired the design of the Chang-Lee scheme. Moreover, by employing an efficient verifiable encryption of RSA signatures proposed by Ateniese, we propose an improvement for repairing the Chang-Lee scheme. We promote the formal study of the soundness of authentication as one open problem.","Authentication,
Silicon,
Law,
Public key"
Network Interactions and Performance of a Multifunction IEC 61850 Process Bus,"New substation technology, such as nonconventional instrument transformers, and a need to reduce design and construction costs are driving the adoption of Ethernet-based digital process bus networks for high-voltage substations. Protection and control applications can share a process bus, making more efficient use of the network infrastructure. This paper classifies and defines performance requirements for the protocols used in a process bus on the basis of application. These include Generic Object Oriented Substation Event, Simple Network Management Protocol, and Sampled Values (SVs). A method, based on the Multiple Spanning Tree Protocol (MSTP) and virtual local area networks, is presented that separates management and monitoring traffic from the rest of the process bus. A quantitative investigation of the interaction between various protocols used in a process bus is described. These tests also validate the effectiveness of the MSTP-based traffic segregation method. While this paper focuses on a substation automation network, the results are applicable to other real-time industrial networks that implement multiple protocols. High-volume SV data and time-critical circuit breaker tripping commands do not interact on a full-duplex switched Ethernet network, even under very high network load conditions. This enables an efficient digital network to replace a large number of conventional analog connections between control rooms and high-voltage switchyards.",
Exploiting Multi-User Diversity and Multi-Hop Diversity in Dual-Hop Broadcast Channels,"We propose joint user-and-hop scheduling over dual-hop block-fading broadcast channels in order to exploit multi-user diversity gains and multi-hop diversity gains all together. To achieve this objective, the first and second hops are scheduled opportunistically based on the channel state information. The joint scheduling problem is formulated as maximizing the weighted sum of the long term achievable rates of the users under a stability constraint, which means that in the long term the rate received by the relay should equal the rate transmitted by it, in addition to power constraints. We show that this problem is equivalent to a single-hop broadcast channel by treating the source as a virtual user with an optimal weight that maintains the stability constraint. We show how to obtain the source weight either off-line based on channel statistics or on real-time based on channel measurements. Furthermore, we consider special cases including the maximum sum-rate scheduler and the proportional fair scheduler. We also show how to extend the scheme into one that allows multiple user scheduling via superposition coding with successive decoding. Numerical results demonstrate that our proposed joint scheduling scheme enlarges the rate region as compared to scheduling schemes that exploit the diversity gains partially.","scheduling,
broadcast channels,
diversity reception,
fading channels,
multiuser channels,
relay networks (telecommunication)"
Incentive Scheduler Algorithm for Cooperation and Coverage Extension in Wireless Networks,"In this paper, we focus on wireless coverage extension and nodes' cooperation. We propose a new protocol based on an incentive approach and a scheduling algorithm to reward cooperative nodes. The cost of cooperation can be prohibitively expensive in terms of quality of service (QoS) and energy consumption, which does not motivate some nodes to cooperate. Therefore, we introduce a percentage of cooperation and QoS parameters in the scheduling algorithm called coverage extension based on incentive scheduling to incite potential mobile relaying nodes to cooperate and, in turn, extend the wireless areas. We use the cross-layer approach to optimize the QoS parameters. The proposed solution not only incites the nodes to cooperate but enhances the QoS by increasing the average throughput and decreasing the delay as well. The simulation results show that the proposed solution not only gives better results than the well-known scheduling algorithms, such as maximum signal-to-noise ratio (MaxSNR) and weighted fair opportunistic (WFO), but allows the cooperative mobile nodes to increase their own throughput by around 114% as well. The total amount of data transmitted out of the cell to extend the coverage can be increased by around 59% compared with the scheduling algorithm MaxSNR.",
27.12 MHz large voltage gain resonant converter with low voltage stress,"This paper presents the design and implementation of a high frequency switching power converter with a large voltage gain and air core inductors. Specifically, we demonstrate a 40 W, 30 V to 300 V dc-dc converter switching at 27.12 MHz. Operating at this frequency reduces bulk energy storage over conventional low frequency designs and allows for fast transient response. We implement a resonant converter based on the Φ2 inverter of [1]. In this paper, we evaluate and compare two rectifier topologies with lower voltage stress than the class E rectifiers described in [2], to get large voltage ratios. Unique to this design is the ability to provide short bursts of high voltage while promising excellent performance and high power density.","Inverters,
Switches,
Topology,
MOSFET,
Impedance,
Semiconductor diodes,
Inductors"
Intelligence Technology for Robots That Think [Application Notes],"The ability to think has been one of the most fascinating features of robots in science fiction since the introduction of the word 'robot' by Karel Capek in his Czech science fiction play, known as 'Rossum's Universal Robots' in English [1]. Since Capek's first depiction in 1921, science fictionists generally portray robots as intelligent humanoid machines that are subservient to humans. Android is another term used for such robots in modern linguistics. However, the development of robots with the ability to think has largely been a fantasy for robot scientists and engineers. Nevertheless, the evolution of robots has come a long way since the first industrial robot 'Unimate' in 1954. Robots have transformed from large automated manufacturing facilities to applications in our homes and even into our pockets as software robots in our PDAs and smart phones [2], [3]. This paper classifies robot intelligence into six categories: cognitive intelligence, social intelligence, behavioral intelligence, ambient intelligence, collective intelligence and genetic intelligence. This classification categorizes the intelligence of robots based on the different aspects of awareness and the ability to act deliberately as a result of such awareness.",
Trust System Design Optimization in Smart Grid Network Infrastructure,"The imposed communication network brings more vulnerabilities to the evolving smart grid. Therefore, defensive techniques such as intrusion detection will need to be deployed in this already complicated system. Deployment and runtime cost due to the defensive trust systems will affect the original function of smart grid system without careful planning and design. This paper is an effort to address this important issue. In particular, the set packing algorithm is used to optimize the placement of the trust nodes of the defensive system in the multiple layer architecture of the smart grid. After the trust nodes are placed, a trust node aware optimal routing algorithm is used to find the least cost routing in the communications of the nodes. Also, an algorithm to identify new trust node(s) is presented to address the fault tolerance requirement of the smart grid system. Simulation results demonstrate that our approach is promising by providing secure, efficient, and reliable communications in the smart grid network.","Routing,
Smart grids,
Intrusion detection,
Heuristic algorithms,
Communication networks,
Wide area networks"
"Comparing FutureGrid, Amazon EC2, and Open Science Grid for Scientific Workflows","Scientists have many computing infrastructures available to conduct their research, including grids and public or private clouds. This article explores the use of these cyber-infrastructures to execute scientific workflows, an important class of scientific applications. In particular, it examines the benefits and drawbacks of cloud and grid systems using the case study of an astronomy application that analyzes data from the NASA Kepler mission to compute periodograms. The authors describe their experiences modeling the periodogram application as a scientific workflow using Pegasus and deploying it on the FutureGrid scientific cloud testbed, the Amazon EC2 commercial cloud, and the Open Science Grid. They also compare and contrast the infrastructures in terms of setup, usability, cost, resource availability, and performance.","Cloud computing,
Computer architecture,
Data transfer,
Extrasolar planets,
Grid computing,
Astronomy,
Scientific computing,
Online services"
Coevolving Game-Playing Agents: Measuring Performance and Intransitivities,"Coevolution is a natural choice for learning in problem domains where one agent's behavior is directly related to the behavior of other agents. However, there is a known tendency for coevolution to produce mediocre solutions. One of the main reasons for this is cycling, caused by intransitivities among a set of players. In this paper, we explore the link between coevolution and games, and revisit some of the coevolutionary literature in a games and measurement context. We propose a set of measurements to identify cycling in a population and a new algorithm that tries to minimize cycling in strictly competitive (zero sum) games. We experimentally verify our approach by evolving weighted piece counter value functions to play othello, a classic two-player perfect information board game. Our method is able to find extremely strong value functions of this type.",
"X-ray CT Metal Artifact Reduction Using Wavelet Domain L_{0}
Sparse Regularization","X-ray computed tomography (CT) imaging of patients with metallic implants usually suffers from streaking metal artifacts. In this paper, we propose a new projection completion metal artifact reduction (MAR) algorithm by formulating the completion of missing projections as a regularized inverse problem in the wavelet domain. The Douglas-Rachford splitting (DRS) algorithm was used to iteratively solve the problem. Two types of prior information were exploited in the algorithm: 1) the sparsity of the wavelet coefficients of CT sinograms in a dictionary of translation-invariant wavelets and 2) the detail wavelet coefficients of a prior sinogram obtained from the forward projection of a segmented CT image. A pseudo- L0 synthesis prior was utilized to exploit and promote the sparsity of wavelet coefficients. The proposed L0-DRS MAR algorithm was compared with standard linear interpolation and the normalized metal artifact reduction (NMAR) approach proposed by Meyer using both simulated and clinical studies including hip prostheses, dental fillings, spine fixation and electroencephalogram electrodes in brain imaging. The qualitative and quantitative evaluations showed that our algorithm substantially suppresses streaking artifacts and can outperform both linear interpolation and NMAR algorithms.","Computed tomography,
Metals,
Implants,
Wavelet transforms,
Image reconstruction,
Wavelet domain,
Dictionaries"
A Multichannel Markov Random Field Framework for Tumor Segmentation With an Application to Classification of Gene Expression-Based Breast Cancer Recurrence Risk,"We present a methodological framework for multichannel Markov random fields (MRFs). We show that conditional independence allows loopy belief propagation to solve a multichannel MRF as a single channel MRF. We use conditional mutual information to search for features that satisfy conditional independence assumptions. Using this framework we incorporate kinetic feature maps derived from breast dynamic contrast enhanced magnetic resonance imaging as observation channels in MRF for tumor segmentation. Our algorithm based on multichannel MRF achieves an receiver operating characteristic area under curve (AUC) of 0.97 for tumor segmentation when using a radiologist's manual delineation as ground truth. Single channel MRF based on the best feature chosen from the same pool of features as used by the multichannel MRF achieved a lower AUC of 0.89. We also present a comparison against the well established normalized cuts segmentation algorithm along with commonly used approaches for breast tumor segmentation including fuzzy C-means (FCM) and the more recent method of running FCM on enhancement variance features (FCM-VES). These previous methods give a lower AUC of 0.92, 0.88, and 0.60, respectively. Finally, we also investigate the role of superior segmentation in feature extraction and tumor characterization. Specifically, we examine the effect of improved segmentation on predicting the probability of breast cancer recurrence as determined by a validated tumor gene expression assay. We demonstrate that an support vector machine classifier trained on kinetic statistics extracted from tumors as segmented by our algorithm gives a significant improvement in distinguishing between women with high and low recurrence risk, giving an AUC of 0.88 as compared to 0.79, 0.76, 0.75, and 0.66 when using normalized cuts, single channel MRF, FCM, and FCM-VES, respectively, for segmentation.","Image segmentation,
Tumors,
Mathematical model,
Kinetic theory,
Equations,
Inference algorithms,
Belief propagation"
Online Real-Time Task Scheduling in Heterogeneous Multicore System-on-a-Chip,"Online task scheduling in heterogeneous multicore system-on-a-chip is a challenging problem due to precedence constraints and nonpreemptive task execution in the synergistic processor core. This study first proposes an online heterogeneous dual-core scheduling framework for dynamic workloads with real-time constraints. The general purpose processor core and the synergistic processor core are dedicated to separate schedulers with different scheduling policies, and precedence constraints among tasks are dealt with through interaction between the two schedulers. This framework is also configurable for low priority inversion and high system utilization. We then extend this framework to heterogeneous multicore systems with well-known dispatcher schemas. This paper presents a real case study to show the practicability of the proposed methodology, and presents a series of extensive simulations to obtain comparison studies using different workloads and scheduling algorithms.","Servers,
Processor scheduling,
Bandwidth,
Admission control,
Switches,
Context,
Scheduling"
A Fast Fixed-Frequency Adaptive-On-Time Boost Converter With Light Load Efficiency Enhancement and Predictable Noise Spectrum,"An integrated fixed-frequency adaptive-on-time (AOT) DC-DC converter with fast transient response and enhanced high light-load efficiency is presented. At both Continuous-Conduction-Mode (CCM) and Discontinuous-Conduction-Mode (DCM) operation, the on-time is adaptively controlled by a frequency locked loop so that the switching frequency tracks the reference frequency with less than ±0.5% error in the whole operating range. At CCM operation, the reference frequency is fixed at 1 MHz. At light load with DCM operation, the reference frequency hops between 1 MHz and 1 MHz/N where N = 2 i and i = 1 to 5 according to the loads without load current sensor. Frequency hopping is introduced to boost the efficiency as well as reduce the EMI noise problem. A glitch-free on-time control circuit is introduced to increase the track accuracy and speed of the frequency locked loop. A mode decision circuit with digital hysteretic window is used to ensure a smooth transition between CCM and DCM operation. An on-time generator with proper logics is used to suppress frequency bouncing during frequency hopping. A prototype with 1.8 V-3.2 V input voltage, 3.0 V-4.2 V output voltage and 0 mA-800 mA load current range has been fabricated in a 0.35 μm 2P4M CMOS process. Load transient measurements verify that 8 μs-20 μs recovery time is achieved for load current increase. Measurement results also show a maximum efficiency of 94.8% is achieved at total output power of 3.269 W, and the light load efficiency is enhanced by the proposed frequency hopping technique with a predictable noise spectrum.","Switching frequency,
Frequency control,
Voltage control,
Noise,
Inductors,
Frequency conversion,
Control systems"
Tracking Algorithms for Multiagent Systems,"This paper is devoted to the consensus tracking issue on multiagent systems. Instead of enabling the networked agents to reach an agreement asymptotically as the time tends to infinity, the consensus tracking between agents is considered to be derived on a finite time interval as accurately as possible. We thus propose a learning algorithm with a gain operator to be determined. If the gain operator is designed in the form of a polynomial expression, a necessary and sufficient condition is obtained for the networked agents to accomplish the consensus tracking objective, regardless of the relative degree of the system model of agents. Moreover, the H∞ analysis approach is introduced to help establish conditions in terms of linear matrix inequalities (LMIs) such that the resulting processes of the presented learning algorithm can be guaranteed to monotonically converge in an iterative manner. The established LMI conditions can also enable the iterative learning processes to converge with an exponentially fast speed. In addition, we extend the learning algorithm to address the relative formation problem for multiagent systems. Numerical simulations are performed to demonstrate the effectiveness of learning algorithms in achieving both consensus tracking and relative formation objectives for the networked agents.","tracking,
linear matrix inequalities,
multi-agent systems"
Code Coverage of Adaptive Random Testing,"Random testing is a basic software testing technique that can be used to assess the software reliability as well as to detect software failures. Adaptive random testing has been proposed to enhance the failure-detection capability of random testing. Previous studies have shown that adaptive random testing can use fewer test cases than random testing to detect the first software failure. In this paper, we evaluate and compare the performance of adaptive random testing and random testing from another perspective, that of code coverage. As shown in various investigations, a higher code coverage not only brings a higher failure-detection capability, but also improves the effectiveness of software reliability estimation. We conduct a series of experiments based on two categories of code coverage criteria: structure-based coverage, and fault-based coverage. Adaptive random testing can achieve higher code coverage than random testing with the same number of test cases. Our experimental results imply that, in addition to having a better failure-detection capability than random testing, adaptive random testing also delivers a higher effectiveness in assessing software reliability, and a higher confidence in the reliability of the software under test even when no failure is detected.","Testing,
Subspace constraints,
Software,
Power capacitors,
Measurement,
Software reliability"
Spatio-Temporal Traffic Scene Modeling for Object Motion Detection,"Moving object detection is an important component of a traffic surveillance system. Usual background subtraction approaches often poorly perform on a long outdoor traffic video due to vehicles waiting at an intersection and gradual changes of illumination and background shadow position. We present a fast and robust background subtraction algorithm based on unified spatio-temporal background and foreground modeling. The correlation between neighboring pixels provides high levels of detection accuracy in the dynamic background scene. Our Bayesian fusion method, which establishes the traffic scene model, combines both background and foreground models and considers prior probabilities to adapt changes of background in each frame. We explicitly model both temporal and spatial information based on the kernel density estimation (KDE) formulation for background modeling. Then, we use a Gaussian formulation to describe the spatial correlation of moving objects for foreground modeling. In the updating step, a fusion background frame is generated, and reasonable updating rates are also proposed for the traffic scene. The experimental results show that the proposed method outperforms the previous work with less computation and is better suited for the traffic scenes.","Adaptation models,
Computational modeling,
Mathematical model,
Bayesian methods,
Surveillance,
Vectors,
Vehicles"
A Low-Profile Frequency Selective Surface With Controllable Triband Characteristics,"A novel compact low-profile frequency selective surface (FSS) with controllable triband characteristics is presented. The proposed FSS consists of a stacked periodic array of square loops and complementary apertures, respectively centered within a wire grid and an aperture grid, which can create three transmission poles and two transmission zeros. Controllable triband performance is achieved, allowing the FSS to transmit the signal at 4 GHz while reflecting the signals at 6 and 9.5 GHz. Due to the compact and low-profile structure, the designed FSS has a reduced sensitivity to the incident angle compared to traditional triband FSSs. An equivalent circuit model is proposed for predicting and analyzing the frequency characteristics of this structure. For demonstration, a prototype of the proposed FSS is fabricated and measured. Good agreement between the simulated and measured results is observed.","Frequency selective surfaces,
Apertures,
Integrated circuit modeling,
Equivalent circuits,
Filtering theory,
Wires"
Backtrackless Walks on a Graph,"The aim of this paper is to explore the use of backtrackless walks and prime cycles for characterizing both labeled and unlabeled graphs. The reason for using backtrackless walks and prime cycles is that they avoid tottering, and can increase the discriminative power of the resulting graph representation. However, the use of such methods is limited in practice because of their computational cost. In this paper, we present efficient methods for computing graph kernels, which are based on backtrackless walks in a labeled graph and whose worst case running time is the same as that of kernels based on random walks. For clustering unlabeled graphs, we construct feature vectors using Ihara coefficients, since these coefficients are related to the frequencies of prime cycles in the graph. To efficiently compute the low order coefficients, we present an O(|V|3) algorithm which is better than the O(|V|6) worst case running time of previously known algorithms. In the experimental evaluation, we apply the proposed method to clustering both labeled and unlabeled graphs. The results show that using backtrackless walks and prime cycles instead of random walks can increase the accuracy of recognition.","Kernel,
Polynomials,
Vectors,
Accuracy,
Learning systems,
Computational efficiency,
Clustering algorithms"
Power Optimization in Embedded Systems via Feedback Control of Resource Allocation,"Embedded systems often operate in so variable conditions that design can only be carried out for some worst-case scenario. This leads to over-provisioned resources, and undue power consumption. Feedback control is an effective (and not yet fully explored) way to tailor resource usage online, thereby making the system behave and consume as if it was optimized for each specific utilization case. A control-theoretical methodology is here proposed to complement architecture design in a view to said tailoring. Experimental results show that a so addressed architecture meets performance requirements, while consuming less power than any fixed (i.e., uncontrolled) one capable of attaining the same goals. Also, the methodology naturally induces computationally lightweight control laws.","Computer architecture,
Encoding,
Hardware,
Power demand,
Sensors,
Actuators,
Feedback control"
Robust Segments Detector for De-Synchronization Resilient Audio Watermarking,"A robust feature points detector for invariant audio watermarking is proposed in this paper. The audio segments centering at the detected feature points are extracted for both watermark embedding and extraction. These feature points are invariant to various attacks and will not be changed much for maintaining high auditory quality. Besides, high robustness and inaudibility can be achieved by embedding the watermark into the approximation coefficients of Stationary Wavelet Transform (SWT) domain, which is shift invariant. The spread spectrum communication technique is adopted to embed the watermark. Experimental results show that the proposed Robust Audio Segments Extractor (RASE) and the watermarking scheme are not only robust against common audio signal processing, such as low-pass filtering, MP3 compression, echo addition, volume change, and normalization; and distortions introduced in Stir-mark benchmark for Audio; but also robust against synchronization geometric distortions simultaneously, such as resample time-scale modification (TSM) with scaling factors up to ±50%, pitch invariant TSM by ±50%, and tempo invariant pitch shifting by ±50%. In general, the proposed scheme can well resist various attacks by the joint RASE and SWT approach, which performs much better comparing with the existing state-of-the art methods.","Robustness,
Watermarking,
Feature extraction,
Distortion,
Synchronization,
Digital audio players"
Effective Neural Network Ensemble Approach for Improving Generalization Performance,"This paper, with an aim at improving neural networks' generalization performance, proposes an effective neural network ensemble approach with two novel ideas. One is to apply neural networks' output sensitivity as a measure to evaluate neural networks' output diversity at the inputs near training samples so as to be able to select diverse individuals from a pool of well-trained neural networks; the other is to employ a learning mechanism to assign complementary weights for the combination of the selected individuals. Experimental results show that the proposed approach could construct a neural network ensemble with better generalization performance than that of each individual in the ensemble combining with all the other individuals, and than that of the ensembles with simply averaged weights.",
Leakage and Aging Optimization Using Transmission Gate-Based Technique,"Negative bias temperature instability (NBTI), which can degrade the switching speed of PMOS transistors, has become a major reliability challenge. Reducing leakage consumption is one of the major design goals. The gate replacement (GR) technique is an effective way to reduce both the NBTI effect and leakage. This technique, however, has less flexibility because the replaced gate can only produce one output value and careful algorithms are needed to decide the output value of the replaced gate. In this paper, we propose a novel transmission gate-based technique to minimize NBTI-induced degradation and leakage. This technique, which can offer logic 1 for NBTI mitigation and logic 0 for leakage reduction, provides higher flexibility, as compared to the GR technique. Simulation results show that our proposed technique has up to 20&times; and 2.16&times;, on average, improvement on NBTI-induced degradation with comparable leakage power reduction. With a 19.19% area penalty, combining our technique and the GR can reduce 17.92% of the total leakage power and 32.36% of NBTI-induced circuit degradation.","Logic gates,
Degradation,
Delay,
Stress,
MOSFETs,
Power demand,
Optimization"
Design and Analysis of Nonuniformly Shaped Heaters for Improved MEMS-Based Electrothermal Displacement Sensing,"Conventional heaters used in microelectromechanical systems (MEMS) electrothermal displacement sensors typically feature a uniform cross section, which results in a nonuniform temperature profile. In this paper, electrothermal sensors with a shaped beam profile are introduced, with simulation results showing that a much flatter temperature distribution is achieved across the length of the heater. The proposed sensor design is implemented as the displacement sensor for a MEMS nanopositioner together with a more conventional electrothermal sensor design for comparative purposes. Experimental testing indicates that the shaped profile significantly improves upon the conventional sensor design in a number of areas, including sensitivity, linearity, and noise performance.","Temperature sensors,
Resistance heating,
Micromechanical devices,
Sensor phenomena and characterization,
Temperature distribution"
Learning swing-free trajectories for UAVs with a suspended load,"Attaining autonomous flight is an important task in aerial robotics. Often flight trajectories are not only subject to unknown system dynamics, but also to specific task constraints. This paper presents a motion planning method for generating trajectories with minimal residual oscillations (swing-free) for rotorcraft carrying a suspended loads. We rely on a finite-sampling, batch reinforcement learning algorithm to train the system for a particular load. We find criteria that allow the trained agent to be transferred to a variety of models, state and action spaces and produce a number of different trajectories. Through a combination of simulations and experiments, we demonstrate that the inferred policy is robust to noise and the unmodeled dynamics of the system. The contributions of this work are 1) applying reinforcement learning to solve the problem of finding swing-free trajectories for rotorcraft, 2) designing a problem-specific feature vector for value function approximation, 3) giving sufficient conditions for successful learning transfer to different models, state and action spaces, and 4) verification of the resulting trajectories in both simulation and autonomous control of quadrotors with suspended loads.","Robustness,
Payloads,
Switches"
TFET-based cellular neural network architectures,"It is well known that CMOS scaling trends are now accompanied by less desirable byproducts such as increased energy dissipation. To combat the aforementioned challenges, solutions are sought at both the device and architectural levels. With this context, this work focuses on embedding a low voltage device, a Tunneling Field Effect Transistor (TFET) within a Cellular Neural Network (CNN) - a low power analog computing architecture. Our study shows that TFET-based CNN systems, aside from being fully functional, also provide significant power savings when compared to the conventional resistor-based CNN. Our initial studies suggest that power savings are possible by carefully engineering lower voltage, lower current TFET devices without sacrificing performance. Moreover, TFET-based CNN reduces implementation footprints by eliminating the hardware required to realize output transfer functions. Application dynamics are verified through simulations. We conclude the paper with a discussion of desired device characteristics for CNN architectures with enhanced functionality.","Image processing,
Transfer functions,
Capacitors,
SPICE,
Low voltage,
Voltage control,
Arrays"
Inferring Group-Wise Consistent Multimodal Brain Networks via Multi-View Spectral Clustering,"Quantitative modeling and analysis of structural and functional brain networks based on diffusion tensor imaging (DTI) and functional magnetic resonance imaging (fMRI) data have received extensive interest recently. However, the regularity of these structural and functional brain networks across multiple neuroimaging modalities and also across different individuals is largely unknown. This paper presents a novel approach to inferring group-wise consistent brain subnetworks from multimodal DTI/resting-state fMRI datasets via multi-view spectral clustering of cortical networks, which were constructed upon our recently developed and validated large-scale cortical landmarks - DICCCOL (dense individualized and common connectivity-based cortical landmarks). We applied the algorithms on DTI data of 100 healthy young females and 50 healthy young males, obtained consistent multimodal brain networks within and across multiple groups, and further examined the functional roles of these networks. Our experimental results demonstrated that the derived brain networks have substantially improved inter-modality and inter-subject consistency.","Diffusion tensor imaging,
Clustering algorithms,
Laplace equations,
Eigenvalues and eigenfunctions,
Educational institutions"
Designing of Optimized All-Optical Half Adder Circuit Using Single Quantum-Dot Semiconductor Optical Amplifier Assisted Mach-Zehnder Interferometer,"A new and novel scheme for a high speed all-optical half adder based on single Quantum-dot semiconductor optical amplifier (QD-SOA) assisted Mach-Zehnder interferometer (MZI) is theoretically investigated and discussed. In this proposed scheme, pair of input data streams are simultaneously drive the switch to produce sum and carry. In this new design, only single switch can be utilized to design half adder circuit and no additional input beam is required other than two input signals. This design is simpler, smaller and compact than our previously proposed design . The impact of the peak data power as well as of the QD-SOAs current density and maximum modal gain on the ER, Q factor with current densities and electron relaxation times etc are explored and assessed by means of numerical simulations.","Optical switches,
Adders,
Optical interferometry,
Optical attenuators,
Optical pulses,
Erbium,
Current density"
Designing Template-Free Predictor for Targeting Protein-Ligand Binding Sites with Classifier Ensemble and Spatial Clustering,"Accurately identifying the protein-ligand binding sites or pockets is of significant importance for both protein function analysis and drug design. Although much progress has been made, challenges remain, especially when the 3D structures of target proteins are not available or no homology templates can be found in the library, where the template-based methods are hard to be applied. In this paper, we report a new ligand-specific template-free predictor called TargetS for targeting protein-ligand binding sites from primary sequences. TargetS first predicts the binding residues along the sequence with ligand-specific strategy and then further identifies the binding sites from the predicted binding residues through a recursive spatial clustering algorithm. Protein evolutionary information, predicted protein secondary structure, and ligand-specific binding propensities of residues are combined to construct discriminative features; an improved AdaBoost classifier ensemble scheme based on random undersampling is proposed to deal with the serious imbalance problem between positive (binding) and negative (nonbinding) samples. Experimental results demonstrate that TargetS achieves high performances and outperforms many existing predictors. TargetS web server and data sets are freely available at: http://www.csbio.sjtu.edu.cn/bioinf/TargetS/ for academic use.","Training,
Feature extraction,
Protein sequence,
Metals,
Bioinformatics"
"Cooperative Cognitive Networks: Optimal, Distributed and Low-Complexity Algorithms","This paper considers the cooperation between a cognitive system and a primary system where multiple cognitive base stations (CBSs) relay the primary user's (PU) signals in exchange for more opportunity to transmit their own signals. The CBSs use amplify-and-forward (AF) relaying and coordinated beamforming to relay the primary signals and transmit their own signals. The objective is to minimize the overall transmit power of the CBSs given the rate requirements of the PU and the cognitive users (CUs). We show that the relaying matrices have unity rank and perform two functions: Matched filter receive beamforming and transmit beamforming. We then develop two efficient algorithms to find the optimal solution. The first one has a linear convergence rate and is suitable for distributed implementation, while the second one enjoys superlinear convergence but requires centralized processing. Further, we derive the beamforming vectors for the linear conventional zero-forcing (CZF) and prior zero-forcing (PZF) schemes, which provide much simpler solutions. Simulation results demonstrate the improvement in terms of outage performance due to the cooperation between the primary and cognitive systems.",
Mobility-Aware Call Admission Control Algorithm With Handoff Queue in Mobile Hotspots,"In this paper, we propose a mobility-aware call admission control (MA-CAC) algorithm with a handoff queue (HQ) in mobile hotspots, where different admission control policies are employed, depending on the vehicle mobility. Specifically, when a vehicle is static, a handoff priority scheme with guard channels is studied to protect vehicular handoff users because handoff users may get on the vehicle. In addition, an HQ is examined during stopping to further accept handoff users. On the other hand, for a moving vehicle, no guard channels for handoff users are allocated to maximize channel utilization. By means of Markov chains, we evaluate MA-CAC with an HQ in terms of new-call blocking probability (NCBP), handoff-call dropping probability (HCDP), handoff-call waiting time in the HQ, and channel utilization. Analytical and simulation results demonstrate that MA-CAC with an HQ can lower both the HCDP and the NCBP while maintaining high channel utilization.","Mobile communication,
Vehicles,
Wireless LAN,
Call admission control,
Quality of service,
Analytical models,
Handover"
Sparse Reconstruction of the Magnetic Particle Imaging System Matrix,"Magnetic particle imaging allows to determine the spatial distribution of magnetic nanoparticles in vivo. The system matrix in magnetic particle imaging is commonly acquired in a tedious calibration scan and requires to measure the system response at numerous positions in the field-of-view. In this paper, we propose a method that significantly reduces the number of required calibration scans. It exploits the special structure of the system matrix and applies sparse reconstruction techniques. Experiments show that the number of calibration scans can be reduced by a factor often with only marginal loss of image quality.",
Outage performance of AF-based time division broadcasting protocol in the presence of co-channel interference,"In this paper, we investigate the outage performance of time division broadcasting (TDBC) protocol in independent but non-identical Rayleigh flat-fading channels, where all nodes are interfered by a finite number of co-channel interferers. We assume that the relay operates in the amplified-and-forward mode. A tight lower bound as well as the asymptotic expression of the outage probability is obtained in closed-form. Through both theoretic analyses and simulation results, we show that the achievable diversity of TDBC protocol is zero in the interference-limited scenario. Moreover, we study the impacts of interference power, number of interferers and relay placement on the outage probability. Finally, the correctness of our analytic results is validated via computer simulations.","Protocols,
Relays,
Signal to noise ratio,
Simulation,
Interchannel interference,
Broadcasting"
"Automatic Segmentation of the Pulmonary Lobes From Chest CT Scans Based on Fissures, Vessels, and Bronchi","Segmentation of the pulmonary lobes is relevant in clinical practice and particularly challenging for cases with severe diseases or incomplete fissures. In this work, an automated segmentation approach is presented that performs a marker-based watershed transformation on computed tomography (CT) scans to subdivide the lungs into lobes. A cost image for the watershed transformation is computed by combining information from fissures, bronchi, and pulmonary vessels. The lobar markers are calculated by an analysis of the automatically labeled bronchial tree. By integration of information from several anatomical structures the segmentation is made robust against incomplete fissures. For evaluation the method was compared to a recently published method on 20 CT scans with no or mild disease. The average distances to the reference segmentation were 0.69, 0.67, and 1.21 mm for the left major, right major, and right minor fissure, respectively. In addition the results were submitted to LOLA11, an international lung lobe segmentation challenge with publically available data including cases with severe diseases. The average distances to the reference for the 55 CT scans provided by LOLA11 were 0.98, 3.97, and 3.09 mm for the left major, right major, and right minor fissure. Moreover, an analysis of the relation between segmentation quality and fissure completeness showed that the method is robust against incomplete fissures.","Lungs,
Computed tomography,
Image segmentation,
Diseases,
Eigenvalues and eigenfunctions,
Manuals"
NCTU-GR 2.0: Multithreaded Collision-Aware Global Routing With Bounded-Length Maze Routing,"Modern global routers employ various routing methods to improve routing speed and quality. Maze routing is the most time-consuming process for existing global routing algorithms. This paper presents two bounded-length maze routing (BLMR) algorithms (optimal-BLMR and heuristic-BLMR) that perform much faster routing than traditional maze routing algorithms. In addition, a rectilinear Steiner minimum tree aware routing scheme is proposed to guide heuristic-BLMR and monotonic routing to build a routing tree with shorter wirelength. This paper also proposes a parallel multithreaded collision-aware global router based on a previous sequential global router (SGR). Unlike the partitioning-based strategy, the proposed parallel router uses a task-based concurrency strategy. Finally, a 3-D wirelength optimization technique is proposed to further refine the 3-D routing results. Experimental results reveal that the proposed SGR uses less wirelength and runs faster than most of other state-of-the-art global routers with a different set of parameters , , , . Compared to the proposed SGR, the proposed parallel router yields almost the same routing quality with average 2.71 and 3.12-fold speedup on overflow-free and hard-to-route cases, respectively, when running on a 4-core system.",
CORE: Augmenting regenerating-coding-based recovery for single and concurrent failures in distributed storage systems,"Data availability is critical in distributed storage systems, especially when node failures are prevalent in real life. A key requirement is to minimize the amount of data transferred among nodes when recovering the lost or unavailable data of failed nodes. This paper explores recovery solutions based on regenerating codes, which are shown to provide fault-tolerant storage and minimum recovery bandwidth. Existing optimal regenerating codes are designed for single node failures. We build a system called CORE, which augments existing optimal regenerating codes to support a general number of failures including single and concurrent failures. We theoretically show that CORE achieves the minimum possible recovery bandwidth for most cases. We implement CORE and evaluate our prototype atop a Hadoop HDFS cluster testbed with up to 20 storage nodes. We demonstrate that our CORE prototype conforms to our theoretical findings and achieves recovery bandwidth saving when compared to the conventional recovery approach based on erasure codes.","Bandwidth,
Throughput,
Nickel,
Equations,
Strips,
Encoding,
Availability"
Three-Dimensional NAND Flash Memory Based on Single-Crystalline Channel Stacked Array,"This letter describes 3-D NAND flash memory architecture having four-level stacked single-crystalline silicon nanowire channels. Previously, we designed 3-D NAND flash memory architecture based on single-crystalline channel stacked array (CSTAR). In this letter, CSTAR NAND flash memory is fabricated and its operations are verified. Successful memory operations of each stacked array of CSTAR including program/erase, retention, and endurance performances are demonstrated.","three-dimensional integrated circuits,
elemental semiconductors,
flash memories,
integrated circuit manufacture,
integrated memory circuits,
logic design,
NAND circuits,
silicon"
Differential evolution on the CEC-2013 single-objective continuous optimization testbed,"Differential evolution (DE) is one of the most powerful continuous optimizers in the field of evolutionary computation. This work systematically benchmarks a classic DE algorithm (DE/rand/1/bin) on the CEC-2013 single-objective continuous optimization testbed. We report, for each test function at different problem dimensionality, the best achieved performance among a wide range of potentially effective parameter settings. It reflects the intrinsic optimization capability of DE/rand/1/bin on this testbed and can serve as a baseline for performance comparison in future research using this testbed. Furthermore, we conduct parameter sensitivity analysis using advanced non-parametric statistical tests to discover statistically significantly superior parameter settings. This analysis provides a statistically reliable rule of thumb for choosing the parameters of DE/rand/1/bin to solve unseen problems. Moreover, we report the performance of DE/rand/1/bin using one superior parameter setting advocated by parameter sensitivity analysis.",
Enabling cost-effective data processing with smart SSD,"This paper explores the benefits and limitations of in-storage processing on current Solid-State Disk (SSD) architectures. While disk-based in-storage processing has not been widely adopted, due to the characteristics of hard disks, modern SSDs provide high performance on concurrent random writes, and have powerful processors, memory, and multiple I/O channels to flash memory, enabling in-storage processing with almost no hardware changes. In addition, offloading I/O tasks allows a host system to fully utilize devices' internal parallelism without knowing the details of their hardware configurations. To leverage the enhanced data processing capabilities of modern SSDs, we introduce the Smart SSD model, which pairs in-device processing with a powerful host system capable of handling data-oriented tasks without modifying operating system code. By isolating the data traffic within the device, this model promises low energy consumption, high parallelism, low host memory footprint and better performance. To demonstrate these capabilities, we constructed a prototype implementing this model on a real SATA-based SSD. Our system uses an object-based protocol for low-level communication with the host, and extends the Hadoop MapReduce framework to support a Smart SSD. Our experiments show that total energy consumption is reduced by 50% due to the low-power processing inside a Smart SSD. Moreover, a system with a Smart SSD can outperform host-side processing by a factor of two or three by efficiently utilizing internal parallelism when applications have light trafic to the device DRAM under the current architecture.",
Analysis and Synthesis of Speech Using an Adaptive Full-Band Harmonic Model,"Voice models often use frequency limits to split the speech spectrum into two or more voiced/unvoiced frequency bands. However, from the voice production, the amplitude spectrum of the voiced source decreases smoothly without any abrupt frequency limit. Accordingly, multiband models struggle to estimate these limits and, as a consequence, artifacts can degrade the perceived quality. Using a linear frequency basis adapted to the non-stationarities of the speech signal, the Fan Chirp Transformation (FChT) have demonstrated harmonicity at frequencies higher than usually observed from the DFT which motivates a full-band modeling. The previously proposed Adaptive Quasi-Harmonic model (aQHM) offers even more flexibility than the FChT by using a non-linear frequency basis. In the current paper, exploiting the properties of aQHM, we describe a full-band Adaptive Harmonic Model (aHM) along with detailed descriptions of its corresponding algorithms for the estimation of harmonics up to the Nyquist frequency. Formal listening tests show that the speech reconstructed using aHM is nearly indistinguishable from the original speech. Experiments with synthetic signals also show that the proposed aHM globally outperforms previous sinusoidal and harmonic models in terms of precision in estimating the sinusoidal parameters. As a perspective, such a precision is interesting for building higher level models upon the sinusoidal parameters, like spectral envelopes for speech synthesis.","speech synthesis,
discrete Fourier transforms,
signal reconstruction"
Simultaneously Identifying All True Vessels From Segmented Retinal Images,"Measurements of retinal blood vessel morphology have been shown to be related to the risk of cardiovascular diseases. The wrong identification of vessels may result in a large variation of these measurements, leading to a wrong clinical diagnosis. In this paper, we address the problem of automatically identifying true vessels as a postprocessing step to vascular structure segmentation. We model the segmented vascular structure as a vessel segment graph and formulate the problem of identifying vessels as one of finding the optimal forest in the graph given a set of constraints. We design a method to solve this optimization problem and evaluate it on a large real-world dataset of 2446 retinal images. Experiment results are analyzed with respect to actual measurements of vessel morphology. The results show that the proposed approach is able to achieve 98.9% pixel precision and 98.7% recall of the true vessels for clean segmented retinal images, and remains robust even when the segmented image is noisy.",
Nonlinear Camera Response Functions and Image Deblurring: Theoretical Analysis and Practice,"This paper investigates the role that nonlinear camera response functions (CRFs) have on image deblurring. We present a comprehensive study to analyze the effects of CRFs on motion deblurring. In particular, we show how nonlinear CRFs can cause a spatially invariant blur to behave as a spatially varying blur. We prove that such nonlinearity can cause large errors around edges when directly applying deconvolution to a motion blurred image without CRF correction. These errors are inevitable even with a known point spread function (PSF) and with state-of-the-art regularization-based deconvolution algorithms. In addition, we show how CRFs can adversely affect PSF estimation algorithms in the case of blind deconvolution. To help counter these effects, we introduce two methods to estimate the CRF directly from one or more blurred images when the PSF is known or unknown. Our experimental results on synthetic and real images validate our analysis and demonstrate the robustness and accuracy of our approaches.",
Extremely Small Two-Element Monopole Antenna for HF Band Applications,"This paper presents a novel antenna architecture to achieve an extremely small form factor for HF band applications. The approach is based on manipulating the topology of a short monopole antenna without utilizing a high index material. A new architecture incorporating two radiating elements is configured, which allows significant gain enhancement. It is shown that such architecture can render a miniaturized HF antenna on air substrate having lateral and height dimensions as small as 0.0115λ0 × 0.0115λ0 × 0.0038λ0 (150 mm× mm × 50 mm for operation at 22.9 MHz). It is found that the measured gain of such architecture can be as high as - 18.1 dBi, which is 16.7 dB higher than a reference inverted-F antenna realized on a high index material (εR = 10.2) having exactly the same dimensions. The proposed antenna architecture is composed of two in-phase radiating vertical elements connected to two inductors between which a capacitive top load is connected to achieve the desired resonant condition. The two vertical elements act effectively as a monopole having increased height. It is also shown that the gain of the antenna can be increased monotonically by increasing the quality factor (Q) of the phase shifter. High Q air-core inductors that can be accommodated in electrically small monopole antenna are designed and incorporated in the phase shifter to achieve a gain value of - 17.9 dBi. Details about the proposed design approach, simulation, and measurement results are discussed.","Inductors,
Antenna measurements,
Dipole antennas,
Substrates,
Antenna radiation patterns,
Receiving antennas"
Emotion classification using minimal EEG channels and frequency bands,"In this research we propose to use EEG signal to classify two emotions (i.e., positive and negative) elicited by pictures. With power spectrum features, the accuracy rate of SVM classifier is about 85.41%. Considering each pair of channels and different frequency bands, it shows that frontal pairs of channels give a better result than the other area and high frequency bands give a better result than low frequency bands. Furthermore, we can reduce number of pairs of channels from 7 to 5 with almost the same accuracy and can cut low frequency bands in order to save computation time. All of these are beneficial to the development of emotion classification system using minimal EEG channels in real-time.","Accuracy,
Electroencephalography,
Support vector machines,
Brain modeling,
Computers,
Educational institutions,
Feature extraction"
GreedEx: A Visualization Tool for Experimentation and Discovery Learning of Greedy Algorithms,"Several years ago we presented an experimental, discovery-learning approach to the active learning of greedy algorithms. This paper presents GreedEx, a visualization tool developed to support this didactic method. The paper states the design goals of GreedEx, makes explicit the major design decisions adopted, and describes its main characteristics in detail. It also describes the experience of use, the usability evaluations conducted, and the evolution of GreedEx in these years in response to the findings of the usability evaluations. Finally, the positive results obtained in an evaluation of educational effectiveness are shown. The paper has three main contributions. First, the GreedEx system itself is an innovative system for experimentation and discovery learning of greedy algorithms. Second, GreedEx is different from other visualization systems in its support to higher levels of learning, in particular evaluation tasks. Finally, GreedEx is an example of a medium-term research project, where an educational system was designed from explicit learning goals and was later refined in a user-centered design process involving instructors and students, before carrying out a successful evaluation of educational effectiveness.","Greedy algorithms,
Visualization,
Data visualization,
Animation,
Tin,
Algorithm design and analysis,
Optimization"
Optical Vector Network Analyzer Based on Unbalanced Double-Sideband Modulation,"An optical vector network analyzer (OVNA) based on unbalanced double-sideband (UB-DSB) modulation with improved measurement accuracy is proposed and experimentally demonstrated. It is different from an OVNA based on optical single-sideband (OSSB) modulation in which one-to-one mapping between the optical and radio frequency responses is employed to measure the magnitude and phase responses of an optical component, the proposed technique measures the magnitude and phase responses by taking into consideration of the power of the other sideband through solving two equations that are associated with the UB-DSB modulation, thus the errors due to the residual power of the other sideband in an OSSB modulation based approach are completely eliminated. A mathematical model providing the transfer function of an optical component is derived. The measurement of a phase-shifted fiber Bragg grating and a linearly chirped fiber Bragg grating is performed. Comparing with the measured results based on OSSB modulation, obvious improvement in measurement accuracy is demonstrated.","Amplitude modulation,
Optical variables measurement,
Optical filters,
Optical modulation,
Adaptive optics,
Optical interferometry"
The Public Option: A Nonregulatory Alternative to Network Neutrality,"Network neutrality and the role of regulation on the Internet have been heavily debated in recent times. Among the various definitions of network neutrality, we focus on the one that prohibits paid prioritization of content. We develop a model of the Internet ecosystem in terms of three primary players: consumers, ISPs, and content providers. We analyze this issue from the point of view of the consumer and target the desired system state that maximizes consumer utility. By analyzing various structures of an ISP market, we obtain different conclusions on the desirability of regulation. We also introduce the notion of a Public Option ISP, an ISP that carries traffic in a network-neutral manner. We find: in a monopolistic scenario, network-neutral regulations might benefit consumers, however the introduction of a Public Option ISP is even better as it aligns the interests of the monopolistic ISP with the consumer utility; and in an oligopolistic scenario, the presence of a Public Option ISP is again preferable to network-neutral regulations, although the presence of competing nonneutral ISPs provides the most desirable situation for the consumers.","Throughput,
Resource management,
Network neutrality,
Games,
Internet,
Google,
IEEE transactions"
A survey of multi-source energy harvesting systems,"Energy harvesting allows low-power embedded devices to be powered from naturally-ocurring or unwanted environmental energy (e.g. light, vibration, or temperature difference). While a number of systems incorporating energy harvesters are now available commercially, they are specific to certain types of energy source. Energy availability can be a temporal as well as spatial effect. To address this issue, ‘hybrid’ energy harvesting systems combine multiple harvesters on the same platform, but the design of these systems is not straight-forward. This paper surveys their design, including trade-offs affecting their efficiency, applicability, and ease of deployment. This survey, and the taxonomy of multi-source energy harvesting systems that it presents, will be of benefit to designers of future systems. Furthermore, we identify and comment upon the current and future research directions in this field.",
DSP-Based Evolution From Conventional TDM-PON to TDM-OFDM-PON,"Recently, digital signal processing (DSP) methods have been extensively studied and various DSP-based schemes have been proposed for next-generation passive optical network (PON). In this paper, we combine the time-division-multiplexing (TDM) architecture with advanced DSP methods to achieve high spectrum-efficiency colorless transmission. Orthogonal frequency division multiplexing (OFDM), as the original form of various DSP methods with frequency-domain equalization (FDE), is chosen for both upstream and downstream transmissions. In the TDM-PON based on OFDM (TDM-OFDM-PON) architecture, OFDM symbols are transmitted in different time slots instead of on-off-key (OOK) bits in conventional TDM-PON. This architecture can be extended for single-carrier with FDE easily. Due to the same TDMA scheme, it can achieve maximum compatibility with current TDM-PON. A DSP-based evolution scheme from conventional TDM-PON to TDM-OFDM-PON is proposed and experimentally demonstrated by upgrading the optical line terminal (OLT) to support both OOK and OFDM signals, which can maintain the current optical distribution network (ODN) and minimize the impact for the existing service and equipment.","OFDM,
Passive optical networks,
Digital signal processing,
Bit error rate,
Receivers,
Optical modulation"
"Consensus, Polarization and Clustering of Opinions in Social Networks","We consider a variation of the Deffuant-Weisbuch model introduced by Deffuant et al. in 2000, to provide new analytical insights on the opinion dynamics in a social group. We model the trust that may exist between like-minded agents through a trust function, which is a discontinuous (hard-interaction) non-increasing function of the opinion distance. In this model, agents exchange their opinions with their neighbors and move their opinions closer to each other if they are like-minded (that is, the distance between opinions is smaller than a threshold). We first study the dynamics of opinion formation under random interactions with a fixed rate of communication between pairs of agents. Our goal is to analyze the convergence properties of the opinion dynamics and explore the underlying characteristics that mark the phase transition from opinion polarization to consensus. Furthermore, we extend the hard-interaction model to a strategic interaction model by considering a time-varying rate of interaction. In this model, social agents themselves decide the time and energy that should be expended on interacting each of their neighbors, based on their utility functions. The aim is to understand how and under what conditions clustering patterns emerge in opinion space. Extensive simulations are provided to validate the analytical results of both the hard-interaction model and the strategic interaction model. We also offer evidence that suggests the validity of the proposed model, using the location and monthly survey data collected in the Social Evolution experiment over a period of nine months.","Analytical models,
Social network services,
Vectors,
Numerical models,
Approximation methods,
Convergence,
Mathematical model"
A high-performance ultrasonic system for the simultaneous transmission of data and power through solid metal barriers,"This paper presents a system capable of simultaneous high-power and high-data-rate transmission through solid metal barriers using ultrasound. By coaxially aligning a pair of piezoelectric transducers on opposite sides of a metal wall and acoustically coupling them to the barrier, an acoustic-electric transmission channel is formed which prevents the need for physical penetration. Independent data and power channels are utilized, but they are only separated by 25.4 mm to reduce the system's form factor. Commercial off-the-shelf components and evaluation boards are used to create realtime prototype hardware and the full system is capable of transmitting data at 17.37 Mbps and delivering 50 W of power through a 63.5-mm thick steel wall. A synchronous multi-carrier communication scheme (OFDM) is used to achieve a very high spectral efficiency and to ensure that there is only minor interference between the power and data channels. Also presented is a discussion of potential enhancements that could be made to greatly improve the power and data-rate capabilities of the system. This system could have a tremendous impact on improving safety and preserving structural integrity in many military applications (submarines, surface ships, unmanned undersea vehicles, armored vehicles, planes, etc.) as well as in a wide range of commercial, industrial, and nuclear systems.","OFDM,
Acoustics,
Transducers,
Digital signal processing,
Data communication,
Power transmission,
Metals"
On the Queue Dynamics of Multiuser Multichannel Cognitive Radio Networks,"For protocol and system design in cognitive radio networks (CRNs), it is essential to identify which system settings or environmental conditions have great impacts on the quality-of-service (QoS) performance for secondary users (SUs) and how they influence it, which are still open issues. In this paper, an analytical framework to quantify the queue dynamics of a multi-SU multichannel CRN is developed. In the analytical framework, we consider the important lower-layer mechanisms and settings, including spectrum sensing errors, medium-access control (MAC) protocols, link adaptation technologies such as adaptive modulation and coding (AMC) and automatic repeat request (ARQ), and limited buffer size. By modeling the queue dynamics as a discrete-time finite-state Markov chain (FSMC), we derive the analytical expressions of the average queue length, packet-dropping rate, and packet-collision rate. Based on these expressions, the QoS metrics including average queueing delay, packet-loss rate, and effective throughput are obtained. Simulation and numerical results are presented to verify the accuracy of the proposed analytical framework and investigate the QoS performance of SUs.",
Wideband Microstrip Coupled-Line Ring Hybrids for High Power-Division Ratios,"Wideband coupled-line ring hybrids are presented for high power-division ratios. For this, an equivalent circuit to make the characteristic impedance of a transmission-line section lower is firstly investigated, based on a
Π
-type lumped-element equivalent circuits. Design formulas of four types of equivalent circuits (
L
Π
-,
L
T
-,
L
S2
-, and
L
S1
-types) are then derived, and
N
is introduced for more design flexibility and wideband performance. The
L
S2
-type with
N=1
is composed of one transmission-line section and two identical series inductances at both ends, which cannot be used for the ring hybrids with the high power-division ratios. To avoid the problem, modified
L
S2
-type (
ML
S2
-type) with
N
is additionally suggested, and that with
N=1
is intensively discussed. Using two of those,
L
S1
-type with
N=2
and
ML
S2
-type with
N=1
, the coupled-line ring hybrids with 13- and 11-dB power-division ratios are fabricated. The measured results show good agreement with those predicted.",
"Folded Substrate Integrated Waveguide Based Composite Right/Left-Handed Transmission Line and Its Application to Partial
H
-Plane Filters","Composite right/left-handed (CRLH) transmission line structures based on the folded substrate integrated waveguide (FSIW) are presented and discussed in this paper. This FSIW-based CRLH (FSIW-CRLH) transmission line exhibits much lower cut-off frequencies as compared to the ordinary FSIW of the same footprint, and furthermore, it requires only one-half width of the conventional substrate integrated waveguide (SIW) based CRLH (SIW-CRLH) transmission lines while possessing the same dispersion characteristics. In addition, the proposed structure offers the advantage of a high quality factor for preventing the guided-wave circuits from radiation as suffered in the previous open CRLH transmission line structures when operated in the fast-wave region. All of the aforementioned properties lend the proposed FSIW-based CRLH transmission lines best suited to miniaturized and guided-wave microwave applications. In this paper, a comprehensive study on the FSIW-CRLH transmission structures is conducted by means of its dispersion relation and Bloch impedance. In addition, two partial H-plane filters are implemented here to demonstrate the capabilities of miniaturization and high quality factor based on the proposed FSIW-CRLH structures. The resultant filters are shown to have about 80% size reduction as compared to the conventional FSIW filters, and 59% size reduction as compared to the SIW-CRLH filters. To the best of our knowledge, it is the first time that the partial H-plane filters are implemented utilizing both the dispersion behavior of the CRLH transmission structures and the structural benefits of the FSIW configuration.","Power transmission lines,
Dispersion,
Resonant frequency,
Equivalent circuits,
Substrates,
Couplings,
Q factor"
DDoS Detection Algorithm Based on Preprocessing Network Traffic Predicted Method and Chaos Theory,"Distributed denial-of-service (DDoS) flooding attacks still pose great threats to the Internet even though various approaches and systems have been proposed. In this paper, we firstly pre-process network traffic by cumulatively averaging it with a time range, and using the simple linear AR model, and then generate the prediction of network traffic. Secondly, assuming the prediction error behaves eechaoticallyee, we use chaos theory to analyze it and then propose a novel network anomaly detection algorithm (NADA) to detect the abnormal traffic. With this abnormal traffic, we lastly train a neural network to detect DDoS attacks. Our preliminary experiments and analyses indicate that our proposed DDoS detection algorithm can accurately and effectively detect DDoS attacks.","Computer crime,
Detection algorithms,
Predictive models,
Time series analysis,
Chaotic communication,
Neural networks"
Topology Mapping and Geolocating for China's Internet,"We perform a large-scale topology mapping and geolocation study for China's Internet. To overcome the limited number of Chinese PlanetLab nodes and looking glass servers, we leverage unique features in China's Internet, including the hierarchical structure of the major ISPs and the abundance of IDC data centers. Using only 15 vantage points, we design a traceroute scheme that finds significantly more interfaces and links than iPlane with significantly fewer traceroute probes. We then consider the problem of geolocating router interfaces and end hosts in China. When examining three well-known Chinese geoIP databases, we observe frequent occurrences of null replies and erroneous entries, suggesting that there is significant room for improvement. We develop a heuristic for clustering the interface topology of a hierarchical ISP, and then apply the heuristic to the major Chinese ISPs. We show that the clustering heuristic can geolocate router interfaces with significantly more detail and consistency than can the existing geoIP databases in isolation. We show that the resulting clusters expose several characteristics of the Chinese Internet, including the major ISPs' provincial structure and the centralized interconnections among the ISPs. Finally, using the clustering heuristic, we propose a methodology for improving commercial geoIP databases and evaluate using IDC data center landmarks.","Internet,
IP networks,
Databases,
Geology,
Probes,
Topology,
Extraterrestrial measurements"
Arm inductance selection principle for modular multilevel converters with circulating current suppressing control,"With circulating current suppressing control, the dominating second-order circulating current in a modular multilevel converter (MMC) can be effectively decreased, and the arm inductance requirement based on the circulating current is thus largely reduced. This paper investigates the extent to which the arm inductance can be reduced. The circulating current at switching frequency is first explored, which is found to be a limitation for arm inductance selection when the circulating current suppressing control is implemented. The theoretical relationship between switching frequency circulating current and arm inductance is further deduced, and the arm inductance selection principle is proposed. Finally, the theoretical analysis is verified by the experiment.","power convertors,
electric current control,
inductance"
A digital watermarking approach to secure and precise range query processing in sensor networks,"Two-tiered wireless sensor networks offer good scalability, efficient power usage, and space saving. However, storage nodes are more attractive to attackers than sensors because they store sensor collected data and processing sink issued queries. A compromised storage node not only reveals sensor collected data, but also may reply incomplete or wrong query results. In this paper, we propose QuerySec, a protocol that enables storage nodes to process queries correctly while prevents them from revealing both data from sensors and queries from the sink. To protect privacy, we propose an order preserving function-based scheme to encode both sensor collected data and sink issued queries, which allows storage nodes to process queries correctly without knowing the actual values of both data and queries. To preserve integrity, we proposed a link watermarking scheme, where data items are formed into a link by the watermarks embedded in them so that any deletion in query results can be detected.","Watermarking,
Data privacy,
Privacy,
Cryptography,
Silicon,
Protocols,
Upper bound"
A Convergent Version of the Max SINR Algorithm for the MIMO Interference Channel,"The problem of designing linear transmit signaling strategies for the multiple input, multiple output (MIMO) interference channel is considered. For this problem, the best known iterative solution, in terms of maximizing signal to interference plus noise ratio (SINR) at the receivers, is the Max SINR algorithm. However, there is no proof that the Max SINR algorithm converges. In this paper, a modification to the Max SINR algorithm is proposed, in which a power control step is used to make a metric similar to the sum rate increase monotonically with each iteration, thus making the modified Max SINR algorithm convergent. It is further shown that with successive interference cancellation (SIC), the metric that the modified Max SINR algorithm optimizes is exactly the sum rate. Finally, simulations are used to demonstrate that the performance of the modified Max SINR algorithm, unlike other convergent alternatives, is nearly identical to that of the original Max SINR algorithm.","telecommunication signalling,
interference suppression,
iterative methods,
MIMO communication,
power control"
"A Fixed Point Iterative Method for Low
n
-Rank Tensor Pursuit","The linearly constrained tensor
n
-rank minimization problem is an extension of matrix rank minimization. It is applicable in many fields which use the multi-way data, such as data mining, machine learning and computer vision. In this paper, we adapt operator splitting technique and convex relaxation technique to transform the original problem into a convex, unconstrained optimization problem and propose a fixed point iterative method to solve it. We also prove the convergence of the method under some assumptions. By using a continuation technique, we propose a fast and robust algorithm for solving the tensor completion problem, which is called FP-LRTC (Fixed Point for Low
n
-Rank Tensor Completion). Our numerical results on randomly generated and real tensor completion problems demonstrate that this algorithm is effective, especially for “easy” problems.",
Spectral Derivative Features for Classification of Hyperspectral Remote Sensing Images: Experimental Evaluation,"Derivatives of spectral reflectance signatures can capture salient features of different land-cover classes. Such information has been used for supervised classification of remote sensing data along with spectral reflectance. In the paper, we study how supervised classification of hyperspectral remote sensing data can benefit from the use of derivatives of spectral reflectance without the aid of other techniques, such as dimensionality reduction and data fusion. An empirical conclusion is given based on a large amount of experimental evaluations carried out on three real hyperspectral remote sensing data sets. The experimental results show that when a training data set is of a small size or the quality of the data is poor, the use of additional first order derivatives can significantly improve classification accuracies along with original spectral features when using classifiers which can avoid the “curse of dimensionality,” such as the SVM algorithm.","Accuracy,
Support vector machines,
Training,
Training data,
Hyperspectral imaging"
Maximum White Luminous Efficacy of Radiation Versus Color Rendering Index and Color Temperature: Exact Results and a Useful Analytic Expression,"We calculate numerically the spectral power distributions (SPDs) which maximize luminous efficacies of radiation (LERs) for white light of particular color rendering indices (
R
a
's) and color temperatures (CTs). We find that, except for the very highest color rendering indices, the spectra are spiky rather than continuous. We present a useful analytic expression for the dependences of the maximum white luminous efficacy of radiation (MWLER) on
R
a
and CT and discuss these dependences. We propose that, for any white light source of a given
R
a
and CT, its absolute spectral efficiency is simply the ratio of its LER to the MWLER at that same
R
a
and CT. We discuss the absolute spectral efficiency, defined in this way, of various lighting technologies: incandescent, fluorescent, high-intensity discharge, and solid-state lighting. Finally, we discuss the possibility of alternative MWLERs based on alternative indices for color rendering quality.",
Common Nature of Learning Between Back-Propagation and Hopfield-Type Neural Networks for Generalized Matrix Inversion With Simplified Models,"In this paper, two simple-structure neural networks based on the error back-propagation (BP) algorithm (i.e., BP-type neural networks, BPNNs) are proposed, developed, and investigated for online generalized matrix inversion. Specifically, the BPNN-L and BPNN-R models are proposed and investigated for the left and right generalized matrix inversion, respectively. In addition, for the same problem-solving task, two discrete-time Hopfield-type neural networks (HNNs) are developed and investigated in this paper. Similar to the classification of the presented BPNN-L and BPNN-R models, the presented HNN-L and HNN-R models correspond to the left and right generalized matrix inversion, respectively. Comparing the BPNN weight-updating formula with the HNN state-transition equation for the specific (i.e., left or right) generalized matrix inversion, we show that such two derived learning-expressions turn out to be the same (in mathematics), although the BP and Hopfield-type neural networks are evidently different from each other a great deal, in terms of network architecture, physical meaning, and training patterns. Numerical results with different illustrative examples further demonstrate the efficacy of the presented BPNNs and HNNs for online generalized matrix inversion and, more importantly, their common natures of learning.","Vectors,
Neural networks,
Mathematical model,
Training,
Computational modeling,
Computer architecture,
Symmetric matrices"
True-MCSA: A Framework for Truthful Double Multi-Channel Spectrum Auctions,"Spectrum auctions motivate existing spectrum owners (as sellers) to lease their selected idle channels to new spectrum users (as buyers) who need the spectrum desperately. The most significant requirement is how to make the auctions economic-robust (truthful in particular) while enabling spectrum reuse. Furthermore, in practice, both sellers and buyers would require to trade multiple channels at one time, while guaranteeing their individual profitability. Unfortunately, existing designs can not meet all these requirements simultaneously. We address these requirements by proposing True-MCSA, a framework for truthful double multi-channel spectrum auctions. True-MCSA introduces novel virtual buyer group (VBG) splitting and bidding algorithms, and applies a proper winner determination and pricing mechanism to achieve truthfulness and other economic properties, meanwhile successfully dealing with multi-channel requests from both buyers and sellers and improving spectrum utilization. Our experiments show that the auction efficiency is impacted by the economic factors with efficiency degradations within 30%, under different settings. Furthermore, the experimental results indicate that we can improve the auction efficiency by choosing a proper bidding algorithm and using a positive base bid. True-MCSA makes an important contribution on enabling spectrum reuse to improve auction efficiency in multi-channel cases.","Algorithm design and analysis,
Pricing,
Resource management,
Economics,
Wireless networks,
Indexes"
High-Robustness and Low-Capacitance Silicon-Controlled Rectifier for High-Speed I/O ESD Protection,"A high-robustness and low-capacitance clamp for on-chip electrostatic discharge (ESD) protection is developed. The low capacitance is obtained by mitigating the capacitance associated with the lightly doped n-well/p-well junction. In addition to minimizing the capacitance, the high ESD robustness is achieved by optimizing independently within the same structure a silicon-controlled rectifier and a diode for the forward and reverse conduction processes, respectively. The new clamp with an area of 50 × 10 μm2 is able to handle an ESD current in excess of 1.5 A, whereas the capacitance at zero bias is kept at 94 fF.","Electrostatic discharges,
Thyristors,
Radio frequency,
Parasitic capacitance,
Voltage measurement,
Transmission line measurements"
Audio Recording Location Identification Using Acoustic Environment Signature,"An audio recording is subject to a number of possible distortions and artifacts. Consider, for example, artifacts due to acoustic reverberation and background noise. The acoustic reverberation depends on the shape and the composition of the room, and it causes temporal and spectral smearing of the recorded sound. The background noise, on the other hand, depends on the secondary audio source activities present in the evidentiary recording. Extraction of acoustic cues from an audio recording is an important but challenging task. Temporal changes in the estimated reverberation and background noise can be used for dynamic acoustic environment identification (AEI), audio forensics, and ballistic settings. We describe a statistical technique based on spectral subtraction to estimate the amount of reverberation and nonlinear filtering based on particle filtering to estimate the background noise. The effectiveness of the proposed method is tested using a data set consisting of speech recordings of two human speakers (one male and one female) made in eight acoustic environments using four commercial grade microphones. Performance of the proposed method is evaluated for various experimental settings such as microphone independent, semi- and full-blind AEI, and robustness to MP3 compression. Performance of the proposed framework is also evaluated using Temporal Derivative-based Spectrum and Mel-Cepstrum (TDSM)-based features. Experimental results show that the proposed method improves AEI performance compared with the direct method (i.e., feature vector is extracted from the audio recording directly). In addition, experimental results also show that the proposed scheme is robust to MP3 compression attack.","Background noise,
Audio recording,
Noise measurement,
Reverberation,
Microphones,
Particle filters"
An End-to-End Signal Strength Model for Underwater Optical Communications,"In this paper, we present a generic model of signal strength in underwater optical communications. The model includes light sources, detectors, amplifier and detector circuitry, optics, as well as a simple extinction model of the water channel. The end-to-end model provides insights into optimization approaches for underwater optical modems and enables relative pose estimation between underwater optical transmitters and receivers. We instantiate our model to the AquaOptical model by determining its parameters and verifying the model prediction in a suite of pool experiments.","Underwater communication,
Optical detectors,
Optical transmitters,
Optical sensors,
Optical receivers,
Optical fiber communication,
Channel models,
Underwater vehicles"
A Virtual Coiling Technique for Image-Based Aneurysm Models by Dynamic Path Planning,"Computational algorithms modeling the insertion of endovascular devices, such as coil or stents, have gained an increasing interest in recent years. This scientific enthusiasm is due to the potential impact that these techniques have to support clinicians by understanding the intravascular hemodynamics and predicting treatment outcomes. In this work, a virtual coiling technique for treating image-based aneurysm models is proposed. A dynamic path planning was used to mimic the structure and distribution of coils inside aneurysm cavities, and to reach high packing densities, which is desirable by clinicians when treating with coils. Several tests were done to evaluate the performance on idealized and image-based aneurysm models. The proposed technique was validated using clinical information of real coiled aneurysms. The virtual coiling technique reproduces the macroscopic behavior of inserted coils and properly captures the densities, shapes and coil distributions inside aneurysm cavities. A practical application was performed by assessing the local hemodynamic after coiling using computational fluid dynamics (CFD). Wall shear stress and intra-aneurysmal velocities were reduced after coiling. Additionally, CFD simulations show that coils decrease the amount of contrast entering the aneurysm and increase its residence time.","Coils,
Aneurysm,
Hemodynamics,
Computational modeling,
Heuristic algorithms,
Solid modeling,
Biomedical imaging"
Outage Performance of Opportunistic Two-Way Amplify-and-Forward Relaying with Outdated Channel State Information,"In this paper, we study the outage performance of an amplify-and-forward (AF)-based two-way relaying (TWR) system with multiple relays where a single relay selection is performed based on outdated channel state information (CSI). Specifically, we propose a single relay selection scheme in AF-based TWR system under outdated CSI conditions. With this policy, we offer a statistical analysis of the signal-to-noise ratio per hop and analyze the outage probability with asymmetric outage thresholds based on CSI-assisted AF protocol. Additionally, we provide the exact and asymptotic expressions based on the provided statistical/joint statistical analyses of a dual-hop AF transmission. Finally, we verify our analytical results with some selected computer-based simulation results.",
Octopus-inspired eight-arm robotic swimming by sculling movements,"Inspired by the octopus arm morphology and exploiting recordings of swimming octopus, we investigate the propulsive capabilities of an 8-arm robotic system under various swimming gaits, including arm sculling and arm undulations, for the generation of forward propulsion. A dynamical model of the robotic system, that considers fluid drag contributions accurately evaluated by CFD methods, was used to study the effects of various kinematic parameters on propulsion. Experiments inside a water tank with an 8-arm robotic prototype successfully demonstrated the sculling-only gaits, attaining a maximum speed of approximately 0.2 body lengths per second. Similar trends were observed, as in the simulation studies, with respect to the effect of the kinematic parameters on propulsion.","Propulsion,
Prototypes,
Manipulators,
Computational fluid dynamics,
Kinematics,
Simulation"
The Role of Technology and Engineering Models in Transforming Healthcare,"The healthcare system is in crisis due to challenges including escalating costs, the inconsistent provision of care, an aging population, and high burden of chronic disease related to health behaviors. Mitigating this crisis will require a major transformation of healthcare to be proactive, preventive, patient-centered, and evidence-based with a focus on improving quality-of-life. Information technology, networking, and biomedical engineering are likely to be essential in making this transformation possible with the help of advances, such as sensor technology, mobile computing, machine learning, etc. This paper has three themes: 1) motivation for a transformation of healthcare; 2) description of how information technology and engineering can support this transformation with the help of computational models; and 3) a technical overview of several research areas that illustrate the need for mathematical modeling approaches, ranging from sparse sampling to behavioral phenotyping and early detection. A key tenet of this paper concerns complementing prior work on patient-specific modeling and simulation by modeling neuropsychological, behavioral, and social phenomena. The resulting models, in combination with frequent or continuous measurements, are likely to be key components of health interventions to enhance health and wellbeing and the provision of healthcare.",
Variable-Fidelity Electromagnetic Simulations and Co-Kriging for Accurate Modeling of Antennas,"Accurate and fast models are indispensable in contemporary antenna design. In this paper, we describe the low-cost antenna modeling methodology involving variable-fidelity electromagnetic (EM) simulations and co-Kriging. Our approach exploits sparsely sampled accurate (high-fidelity) EM data as well as densely sampled coarse-discretization (low-fidelity) EM simulations that are accommodated into one model using the co-Kriging technique. By using coarse-discretization simulations, the computational cost of creating the antenna model is greatly reduced compared to conventional approaches, where high-fidelity simulations are directly used to set up the model. At the same time, the modeling accuracy is not compromised. The proposed technique is demonstrated using three examples of antenna structures. Comparisons with conventional modeling based on high-fidelity data approximation, as well as applications for antenna design, are also discussed.","Computational modeling,
Data models,
Antennas,
Correlation,
Integrated circuit modeling,
Radio frequency,
Training"
A survey on content based image retrieval,"Literature survey is most important for understanding and gaining much more knowledge about specific area of a subject. In this paper a survey on content based image retrieval presented. Content Based Image Retrieval (CBIR) is a technique which uses visual features of image such as color, shape, texture, etc... to search user required image from large image database according to user's requests in the form of a query image. We consider Content Based Image Retrieval viz. labelled and unlabelled images for analyzing efficient image for different image retrieval process viz. D-EM, SVM, RF, etc. To determining the efficient imaging for Content Based Image Retrieval, We performance literature review by using principles of Content Based Image Retrieval based unlabelled images. And also give some recommendations for improve the CBIR system using unlabelled images.","Image retrieval,
Support vector machines,
Radio frequency,
Pattern recognition,
Supervised learning"
Segmentation of Dermoscopy Images Using Wavelet Networks,"This paper introduces a new approach for the segmentation of skin lesions in dermoscopic images based on wavelet network (WN). The WN presented here is a member of fixed-grid WNs that is formed with no need of training. In this WN, after formation of wavelet lattice, determining shift and scale parameters of wavelets with two screening stage and selecting effective wavelets, orthogonal least squares algorithm is used to calculate the network weights and to optimize the network structure. The existence of two stages of screening increases globality of the wavelet lattice and provides a better estimation of the function especially for larger scales. R, G, and B values of a dermoscopy image are considered as the network inputs and the network structure formation. Then, the image is segmented and the skin lesions exact boundary is determined accordingly. The segmentation algorithm were applied to 30 dermoscopic images and evaluated with 11 different metrics, using the segmentation result obtained by a skilled pathologist as the ground truth. Experimental results show that our method acts more effectively in comparison with some modern techniques that have been successfully used in many medical imaging problems.","Image segmentation,
Vectors,
Lattices,
Lesions,
Medical diagnostic imaging,
Image color analysis"
Integrating cache related pre-emption delay analysis into EDF scheduling,"Cache memories have been introduced into embedded systems to prevent memory access times from becoming an unacceptable performance bottleneck. Memory and cache are split into blocks containing instructions and data. During a pre-emption, blocks from the pre-empting task can evict those of the pre-empted task. When the pre-empted task is resumed, if it then has to re-load the evicited blocks, cache related pre-emption delays (CRPD) are introduced which then affect schedulability of the task. In this paper, we show how existing approaches for calculating CRPD for FP scheduling can be adapted and integrated into schedulability analysis for EDF. We then compare the performance of the different approaches against an existing approach for calculating CRPD for EDF. Using a case study and empirical evaluation, we show the benefits of our CRPD analysis.","Schedules,
Scheduling algorithms,
Equations,
Mathematical model,
Algorithm design and analysis,
Indexes,
Scheduling"
A Scalable Transitive Human-Verifiable Authentication Protocol for Mobile Devices,"The man-in-the-middle (MITM) attack is the major threat for handheld devices to agree on a session key in which they do not share any prior secret in advance, even if these devices are physically located in the same place. Apart from insecurely typing passwords into handheld devices or comparing long hexadecimal keys displayed on the devices' screens, many other human-verifiable protocols have been proposed in the literature to solve the problem. Unfortunately, most of these schemes are unscalable to more users. Even when there are only three entities attempting to agree on a session key, these protocols need to be rerun three times. In this paper, we present a bipartite and a tripartite authentication protocol using a temporary confidential channel. Besides, we further extend the system into a transitive authentication protocol that allows multiple handheld devices to establish a conference key securely and efficiently. In addition, we provide a formal proof to our protocol to demonstrate our scheme is indeed secure. We also implement the prototype of the system on a mobile phone with satisfying performance.",
Constant Modulus Algorithm for Peak-to-Average Power Ratio (PAPR) Reduction in MIMO OFDM/A,"A new peak-to-average power ratio (PAPR) reduction approach for MIMO-OFDM/A is developed based on the well-known constant modulus algorithm (CMA). This combines two ideas: 1) time domain signals from “resource blocks” (consisting of several subcarriers) may be linearly combined using precoding weights, transparent to the receiver; 2) the precoding weights can be designed to minimize the modulus variations of the resulting signal, leading generally to a reduction in PAPR. This technique is compatible with various beamforming modes in single antenna and MIMO systems. Simulation results show a noticeable improvement relative to the Partial Transmit Sequences (PTS) technique with significantly less complexity.","Peak to average power ratio,
MIMO,
Signal processing algorithms,
Complexity theory,
Bit error rate,
Vectors"
Cooperative cell outage detection in Self-Organizing femtocell networks,"The vision of Self-Organizing Networks (SON) has been drawing considerable attention as a major axis for the development of future networks. As an essential functionality in SON, cell outage detection is developed to autonomously detect macrocells or femtocells that are inoperative and unable to provide service. Previous cell outage detection approaches have mainly focused on macrocells while the outage issue in the emerging femtocell networks is less discussed. However, due to the two-tier macro-femto network architecture and the small coverage nature of femtocells, it is challenging to enable outage detection functionality in femtocell networks. Based on the observation that spatial correlations among users can be extracted to cope with these challenges, this paper proposes a Cooperative femtocell Outage Detection (COD) architecture which consists of a trigger stage and a detection stage. In the trigger stage, we design a trigger mechanism that leverages correlation information extracted through collaborative filtering to efficiently trigger the detection procedure without inter-cell communications. In the detection stage, to improve the detection accuracy, we introduce a sequential cooperative detection rule to process the spatially and temporally correlated user statistics. In particular, the detection problem is formulated as a sequential hypothesis testing problem, and the analytical results on the detection performance are derived. Numerical studies for a variety of femtocell deployments and configurations demonstrate that COD outperforms the existing scheme in both communication overhead and detection accuracy.",
Improving feature location practice with multi-faceted interactive exploration,"Feature location is a human-oriented and information-intensive process. When performing feature location tasks with existing tools, developers often feel it difficult to formulate an accurate feature query (e.g., keywords) and determine the relevance of returned results. In this paper, we propose a feature location approach that supports multi-faceted interactive program exploration. Our approach automatically extracts and mines multiple syntactic and semantic facets from candidate program elements. Furthermore, it allows developers to interactively group, sort, and filter feature location results in a centralized, multi-faceted, and intelligent search User Interface (UI). We have implemented our approach as a web-based tool MFIE and conducted an experimental study. The results show that the developers using MFIE can accomplish their feature location tasks 32% faster and the quality of their feature location results (in terms of F-measure) is 51% higher than that of the developers using regular Eclipse IDE.",
Stackelberg Game Based Cooperative User Relay Assisted Load Balancing in Cellular Networks,"We propose a Stackelberg game based cooperative user relay assisted load balancing (LB) scheme to tackle SNR degradation problem of shifted cell-edge users which commonly occurs in a conventional direct handover LB scheme. In the proposed scheme, users from a lightly loaded cell can be selected as cooperative user-relays and will be paid by the shifted cell-edge users. Stackelberg game theory is applied to optimize the strategies of both the user relays and shifted cell-edge users, in order to maximize both of their utilities in terms of SNR and payment. Theoretical analysis and simulation study are undertaken to show the effectiveness of the proposed scheme.","Relays,
Game theory,
Games,
Signal to noise ratio"
4D Reconstruction of the Beating Embryonic Heart From Two Orthogonal Sets of Parallel Optical Coherence Tomography Slice-Sequences,"Current methods to build dynamic optical coherence tomography (OCT) volumes of the beating embryonic heart involve synchronization of 2D+time slice-sequences acquired over separate heartbeats. Temporal registration of these sequences is performed either through gating or postprocessing. While synchronization algorithms that exclusively rely on image-intrinsic signals allow forgoing external gating hardware, they are prone to error accumulation, require operator-supervised correction, or lead to nonisotropic resolution. Here, we propose an image-based, retrospective reconstruction technique that uses two sets of parallel 2D+T slice-sequences, acquired perpendicularly to each other, to yield accurate and automatic reconstructions with isotropic resolution. The method utilizes the similarity of the data at the slice intersections to spatio-temporally register the two sets of slice sequences and fuse them into a high-resolution 4D volume. We characterize our method by using 1) simulated heart phantom datasets and 2) OCT datasets acquired from the beating heart of live cultured E9.5 mouse and E10.5 rat embryos. We demonstrate that while our method requires greater acquisition and reconstruction time compared to methods that use slices from a single direction, it produces more accurate and self-validating reconstructions since each set of reconstructed slices acts as a reference for the slices in the perpendicular set.","Synchronization,
Image reconstruction,
Heart beat,
Image resolution,
Phantoms"
An Unsupervised Approach to Cochannel Speech Separation,"Cochannel (two-talker) speech separation is predominantly addressed using pretrained speaker dependent models. In this paper, we propose an unsupervised approach to separating cochannel speech. Our approach follows the two main stages of computational auditory scene analysis: segmentation and grouping. For voiced speech segregation, the proposed system utilizes a tandem algorithm for simultaneous grouping and then unsupervised clustering for sequential grouping. The clustering is performed by a search to maximize the ratio of between- and within-group speaker distances while penalizing within-group concurrent pitches. To segregate unvoiced speech, we first produce unvoiced speech segments based on onset/offset analysis. The segments are grouped using the complementary binary masks of segregated voiced speech. Despite its simplicity, our approach produces significant SNR improvements across a range of input SNR. The proposed system yields competitive performance in comparison to other speaker-independent and model-based methods.","Speech,
Hidden Markov models,
Clustering algorithms,
Time frequency analysis,
Computational modeling,
Algorithm design and analysis,
Signal to noise ratio"
On Effective Through-Silicon Via Repair for 3-D-Stacked ICs,"3-D-stacked integrated circuits (ICs) that employ through-silicon vias (TSVs) to connect multiple dies vertically have gained wide-spread interest in the semiconductor industry. In order to be commercially viable, the assembly yield for 3-D-stacked ICs must be as high as possible, requiring TSVs to be reparable. Existing techniques typically assume TSV faults to be uniformly distributed and use neighboring TSVs to repair faulty ones, if any. In practice, however, clustered TSV faults are quite common due to the fact that the TSV bonding quality depends on surface roughness and cleanness of silicon dies, rendering prior TSV redundancy solutions less effective. Furthermore, existing techniques consume a lot of redundant TSVs that are still costly in the current TSV process. This inefficient TSV redundancy can limit the amount of TSVs that is allowed to use and may even become the obstacle to commercial production. To resolve this problem, we present a novel TSV repair framework, including a hardware redundancy architecture that enables faulty TSVs to be repaired by redundant TSVs that are farther apart, the corresponding repair algorithm and the redundancy architecture construction. By doing so, the manufacturing yield for 3-D-stacked ICs can be dramatically improved, as demonstrated in our experimental results.","Through-silicon vias,
Maintenance engineering,
Redundancy,
Switches,
Circuit faults,
Ports (Computers),
Timing"
Vectorial Phase Retrieval of 1-D Signals,"Reconstruction of signals from measurements of their spectral intensities, also known as the phase retrieval problem, is of fundamental importance in many scientific fields. In this paper we present a novel framework, denoted as vectorial phase retrieval, for reconstruction of pairs of signals from spectral intensity measurements of the two signals and of their interference. We show that this new framework can alleviate some of the theoretical and computational challenges associated with classical phase retrieval from a single signal. First, we prove that for compactly supported signals, in the absence of measurement noise, this new setup admits a unique solution. Next, we present a statistical analysis of vectorial phase retrieval and derive a computationally efficient algorithm to solve it. Finally, we illustrate via simulations, that our algorithm can accurately reconstruct signals even at considerable noise levels.","Phase measurement,
Noise,
Noise measurement,
Extraterrestrial measurements,
Image reconstruction,
Interference,
Robustness"
Accelerating solvers for global atmospheric equations through mixed-precision data flow engine,"One of the most essential and challenging components in a climate system model is the atmospheric model. To solve the multi-physical atmospheric equations, developers have to face extremely complex stencil kernels. In this paper, we propose a hybrid CPU-FPGA algorithm that applies single and multiple FPGAs to compute the upwind stencil for the global shallow water equations. Through mixed-precision arithmetic, we manage to build a fully pipelined upwind stencil design on a single FPGA, which can perform 428 floating-point and 235 fixed-point operations per cycle. The CPU-FPGA algorithm using one Virtex-6 FPGA provides 100 times speedup over a 6-core CPU and 4 times speedup over a hybrid node with 12 CPU cores and a Fermi GPU card. The algorithm using four FPGAs provides 330 times speedup over a 6-core CPU; it is also 14 times faster and 9 times more power efficient than the hybrid CPU-GPU node.","Field programmable gate arrays,
Atmospheric modeling,
Mathematical model,
Algorithm design and analysis,
Equations,
Computational modeling,
Bandwidth"
Adaptive Seeding in Social Networks,"The algorithmic challenge of maximizing information diffusion through word-of-mouth processes in social networks has been heavily studied in the past decade. While there has been immense progress and an impressive arsenal of techniques has been developed, the algorithmic frameworks make idealized assumptions regarding access to the network that can often result in poor performance of state-of-the-art techniques. In this paper we introduce a new framework which we call Adaptive Seeding. The framework is a two-stage stochastic optimization model designed to leverage the potential that typically lies in neighboring nodes of arbitrary samples of social networks. Our main result is an algorithm which provides a constant factor approximation to the optimal adaptive policy for any influence function in the Triggering model.","Adaptation models,
Approximation methods,
Approximation algorithms,
Social network services,
Stochastic processes,
Optimization,
Algorithm design and analysis"
Objective Skill Evaluation for Laparoscopic Training Based on Motion Analysis,"Performing laparoscopic surgery requires several skills, which have never been required for conventional open surgery. Surgeons experience difficulties in learning and mastering these techniques. Various training methods and metrics have been developed to assess and improve surgeon's operative abilities. While these training metrics are currently widely being used, skill evaluation methods are still far from being objective in the regular laparoscopic skill education. This study proposes a methodology of defining a processing model that objectively evaluates surgical movement performance in the routine laparoscopic training course. Our approach is based on the analysis of kinematic data describing the movements of surgeon's upper limbs. An ultraminiaturized wearable motion capture system (Waseda Bioinstrumentation system WB-3), therefore, has been developed to measure and analyze these movements. The data processing model was trained by using the subjects' motion features acquired from the WB-3 system and further validated to classify the expertise levels of the subjects with different laparoscopic experience. Experimental results show that the proposed methodology can be efficiently used both for quantitative assessment of surgical movement performance, and for the discrimination between expert surgeons and novices.","Training,
Surgery,
Laparoscopes,
Educational institutions,
Instruments,
Hidden Markov models,
Principal component analysis"
Simplification of the Nanosilver Sintering Process for Large-Area Semiconductor Chip Bonding: Reduction of Hot-Pressing Temperature Below 200/spl deg/C,"Die attach by low-temperature sintering of nanoparticles of silver is an emerging lead-free joining solution for electronic packaging because of the high thermal/electrical conductivity and high reliability of silver. For bonding small chips, the attachment can be achieved by a simple heating profile under atmospheric pressure. However, for bonding chips with an area , an external pressure of a few MPa is reported necessary at the sintering temperature of ~ 250 °C. This hot-pressing process in excess of 200 °C can add significant complexity and costs to manufacturing and maintenance. In this paper, we conduct a fractional factorial design of experiments aimed at lowering the temperature at which pressure is required for the die-attach process. In particular, we examine the feasibility of applying pressure only during the drying stage of the process when the temperature is still at 180 °C. The experiments help to identify the importance and interaction of various processing parameters, such as pressure, temperature, and time, on the bonding strength and microstructure of sintered nanosilver joints. In addition, the positive effect of pressure applied during drying on the bonding quality is observed. With the results, a simpler process, consisting of pressure drying at 180 °C under 3 MPa pressure, followed by sintering at 275 °C under atmospheric pressure, is found to produce attachments with die-shear strengths in excess of 30 MPa.","Silver,
Bonding,
Heating,
Joints,
X-ray imaging,
Temperature,
Microstructure"
Wafer-Level Integration of High-Quality Bulk Piezoelectric Ceramics on Silicon,"In this paper, we present a new post-CMOS-compatible piezoelectric thin/thick film technology that allows wafer-level integration of bulk piezoelectric ceramics such as lead zirconium titanate (PZT) and lead magnesium niobate-lead titanate (PMN-PT) on silicon substrates with precisely determined final film thickness of 5-100 μm while preserving the original material quality. We bond commercially available bulk piezoelectric substrates to silicon using reliable and low-temperature (200°C) gold-indium (Au-In) diffusion bonding or parylene bonding. An enhanced fixed-abrasive lapping/polishing process thins the piezoelectric layer to the desired thickness with high precision and wafer-level uniformity (±0.5 μm). The fabricated films have bond interface shear strength of 1.5-4.5 MPa and average surface roughness of 43 nm, with bulk ferroelectric/piezoelectric properties preserved, such as remnant polarization (37.7 μC/cm2), coercive field (1.95 kV/mm), and effective longitudinal piezoelectric strain coefficients (140-840 pm/V). In addition, extensions of this process show the feasibility of fabricating bimorph layers via successive bonding/thinning, and of forming suspended structures on silicon via surface micromachining. The flexible process can easily be adapted for batch-mode silicon integration of a variety of other electroceramics.","Silicon,
Bonding,
Substrates,
Lapping,
Surface treatment,
Metals"
3-D Face Recognition Under Occlusion Using Masked Projection,"With advances in sensor technology, the three-dimensional (3-D) face has become an emerging biometric modality, preferred especially in high security applications. However, dealing with occlusions covering the facial surface is a great challenge, which should be handled to enable applicability to fully automatic security systems. In this paper, we propose a fully automatic 3-D face recognition system which is robust to occlusions. We basically consider two problems: 1) occlusion handling for surface registration, and 2) missing data handling for classification based on subspace analysis techniques. For the alignment problem, we employ an adaptively-selected-model-based registration scheme, where a face model is selected for an occluded face such that only the valid nonoccluded patches are utilized. After registering to the model, occlusions are detected and removed. In the classification stage, a masking strategy, which we call masked projection, is proposed to enable the use of subspace analysis techniques with incomplete data. Furthermore, a regional scheme suitable for occlusion handling is incorporated in classification to improve the overall results. Experimental results on two databases with realistic facial occlusions, namely, the Bosphorus and the UMB-DB, are reported. Experimental results confirm that registration based on the adaptively selected model together with the masked subspace analysis classification offer an occlusion robust face recognition system.","Face,
Nose,
Face recognition,
Adaptation models,
Probes,
Vectors,
Computational modeling"
Optimal Online Sensing Sequence in Multichannel Cognitive Radio Networks,"We address the problem of rapidly discovering spectrum opportunities for seamless service provisioning in cognitive radio networks (CRNs). In particular, we focus on multichannel communications via channel-bonding with heterogeneous channel characteristics of ON/OFF patterns, sensing time, and channel capacity. Using dynamic programming (DP), we derive an optimal online sensing sequence incurring a minimal opportunity-discovery delay, and propose a suboptimal sequence that presents a near-optimal performance while incurring significantly less computational overhead than the DP algorithm. To facilitate fast opportunity discovery, we also propose a channel-management strategy that maintains a list of backup channels to be used at building the optimal sequence. A hybrid of maximum likelihood (ML) and Bayesian inference is introduced as well for flexible estimation of ON/OFF channel-usage patterns, which selectively chooses the better between the two according to the frequency of sensing and ON/OFF durations. The performance of the proposed schemes, in terms of the opportunity-discovery delay, is evaluated via in-depth simulation, and for the scenarios we considered, the proposed suboptimal sequence achieves a near-optimal performance with only an average of 0.5 percent difference from the optimal delay, and outperforms the previously proposed probabilistic scheme by up to 50.1 percent. In addition, the backup channel update scheme outperforms the no-update case by up to 49.9 percent.","Sensors,
Delay,
Channel capacity,
Bayesian methods,
Channel estimation,
Bandwidth,
Maximum likelihood estimation"
Regularized Discriminative Spectral Regression Method for Heterogeneous Face Matching,"Face recognition is confronted with situations in which face images are captured in various modalities, such as the visual modality, the near infrared modality, and the sketch modality. This is known as heterogeneous face recognition. To solve this problem, we propose a new method called discriminative spectral regression (DSR). The DSR maps heterogeneous face images into a common discriminative subspace in which robust classification can be achieved. In the proposed method, the subspace learning problem is transformed into a least squares problem. Different mappings should map heterogeneous images from the same class close to each other, while images from different classes should be separated as far as possible. To realize this, we introduce two novel regularization terms, which reflect the category relationships among data, into the least squares approach. Experiments conducted on two heterogeneous face databases validate the superiority of the proposed method over the previous methods.","Face,
Face recognition,
Optimization,
Learning systems,
Training,
Databases,
Laplace equations"
Cooperative Relaying of Superposition Coding with Simple Feedback for Layered Source Transmission,"We consider a relay network that delivers a Gaussian source by employing successive refinement source coding and superposition coding of layers at the source node and successive decoding at the relay and destination nodes. For the network, making use of the decoding results at the relay and destination nodes of the first transmission, an efficient relaying strategy of layers is proposed to minimize the expected distortion (ED) when only the average channel state information is available at the source node. Three types of the proposed scheme, defined as Prop-DF, using decode-and-forward signals, Prop-AF, using amplify-and-forward signals, and Prop-MF, using mixed-forward signals, are addressed and analyzed in terms of the outage probability and distortion exponent. Unlike other studies, we have also taken the relay location into account in deriving the distortion exponent showing the high SNR behavior of the ED. The results show that the proposed scheme increases the distortion exponent up to twice that of the conventional relaying schemes when the relay is close to the source node, and that Prop-MF provides the best performance for most relay locations.",
Enabling Mobile Devices for Home Automation Using ZigBee,"Home automation systems are collections of interconnected devices for controlling various functions within a house, such as light control, heating, air conditioning, etc. Mobile devices are ideal in providing a user interface in a home automation system, due to their portability and their wide range of capabilities. They can communicate with a home automation network through an Internet gateway, but cannot directly communicate with devices in the network, as these devices usually implement low power communication protocols, such as ZigBee. We investigate several methods to equip an Android device with a dongle capable of ZigBee communication. We propose a scalable architecture, with three abstraction layers, that scales over multiple communication channels, such as the TCP channel, for communication with the gateway, and the USB channel, for direct communication with devices through the dongle. We test the application with two client devices running Android 4.0 and a mock home automation network consisting of a couple of ZigBee devices and a PC as gateway. We estimate the energy consumption of WiFi transfers over several typical use cases and we conclude that using ZigBee can prove beneficial in some cases, both in terms of functionality and performance.","Home automation,
Zigbee,
Universal Serial Bus,
IEEE 802.11 Standards,
Bluetooth,
Mobile handsets,
IEEE 802.15 Standards"
Photonic Generation of a Phase-Coded Microwave Waveform With Ultrawide Frequency Tunable Range,"Photonic generation of a phase-coded microwave waveform with ultrawide frequency tunable range using two polarization modulators (PolMs) is proposed and experimentally demonstrated. The first PolM (PolM1) is used to control the polarization direction of a linearly polarized light wave to have an angle of 45° or 135 ° relative to one principal axis of the second PolM (PolM2). PolM2 operates in conjunction with a polarization controller and a polarizer as an equivalent Mach-Zehnder modulator (MZM). Depending on the polarization direction of the incident light wave, the equivalent MZM is biased at the opposite slopes of the transfer function. Thus, by applying a binary coding signal with a switching voltage of Vπ to PolM1, a π phase-coded microwave waveform is generated. The key significance of the technique is that a phase-coded microwave waveform with an ultrawide frequency tunable range can be generated. The technique is experimentally evaluated. The generation of a frequency-tunable phase-coded microwave waveform with a frequency at 10, 20, 30, and 40 GHz is demonstrated.","Microwave filters,
Microwave photonics,
Microwave amplifiers,
Switches,
Optical polarization"
Simultaneous Truth and Performance Level Estimation Through Fusion of Probabilistic Segmentations,"Recent research has demonstrated that improved image segmentation can be achieved by multiple template fusion utilizing both label and intensity information. However, intensity weighted fusion approaches use local intensity similarity as a surrogate measure of local template quality for predicting target segmentation and do not seek to characterize template performance. This limits both the usefulness and accuracy of these techniques. Our work here was motivated by the observation that the local intensity similarity is a poor surrogate measure for direct comparison of the template image with the true image target segmentation. Although the true image target segmentation is not available, a high quality estimate can be inferred, and this in turn allows a principled estimate to be made of the local quality of each template at contributing to the target segmentation. We developed a fusion algorithm that uses probabilistic segmentations of the target image to simultaneously infer a reference standard segmentation of the target image and the local quality of each probabilistic segmentation. The concept of comparing templates to a hidden reference standard segmentation enables accurate assessments of the contribution of each template to inferring the target image segmentation to be made, and in practice leads to excellent target image segmentation. We have used the new algorithm for the multiple-template-based segmentation and parcellation of magnetic resonance images of the brain. Intensity and label map images of each one of the aligned templates are used to train a local Gaussian mixture model based classifier. Then, each classifier is used to compute the probabilistic segmentations of the target image. Finally, the generated probabilistic segmentations are fused together using the new fusion algorithm to obtain the segmentation of the target image. We evaluated our method in comparison to other state-of-the-art segmentation methods. We demonstrated that our new fusion algorithm has higher segmentation performance than these methods.",
Emotion recognition in speech using MFCC and wavelet features,"Recognition of emotions from speech is one of the most important sub domains in the field of affective computing. Six basic emotional states are considered for classification of emotions from speech in this work. In this work, features are extracted from audio characteristics of emotional speech by Mel-frequency Cepstral Coefficient (MFCC), and Subband based Cepstral Parameter (SBC) method. Further these features are classified using Gaussian Mixture Model (GMM). SAVEE audio database is used in this work for testing of Emotions. In the experimental results, SBC method out performs with 70% in recognition compared to 51% of recognition in MFCC algorithm.","Mel frequency cepstral coefficient,
Feature extraction,
Speech,
Speech recognition,
Training,
Accuracy,
Emotion recognition"
Distributed Classification of Traffic Anomalies Using Microscopic Traffic Variables,"This paper proposes a novel anomaly classification algorithm that can be deployed in a distributed manner and utilizes microscopic traffic variables shared by neighboring vehicles to detect and classify traffic anomalies under different traffic conditions. The algorithm, which incorporates multiresolution concepts, is based on the likelihood estimation of a neural network output and a bisection-based decision threshold. We show that, when applied to real-world traffic scenarios, the proposed algorithm can detect all the traffic anomalies of the reference test data set; this result represents a significant improvement over our previously proposed algorithm. We also show that the proposed algorithm can effectively detect and classify traffic anomalies even when the following two cases occur: 1) the microscopic traffic variables are available from only a fraction of the vehicle population, and 2) some microscopic traffic variables are lost due to degradation in vehicle-to-vehicle (V2V) or vehicle-to-infrastructure communications (V2I).","Vehicles,
Microscopy,
Classification algorithms,
Discrete wavelet transforms,
Feature extraction,
Detectors,
Algorithm design and analysis"
A survey on energy and power consumption models for Greener Cloud,"The growing demand of computation, large data storage needed for running a high performance computing enterprise and high dimensional data based web application increases the energy and power consumed by large infrastructure. Cloud computing is providing a solution as part of the Green IT initiative to reduce the adverse environmental impacts and save energy. Our paper describes important metrics of cloud computing which makes it greener. We discuss the various power and energy models and identify major challenges to build a model for Green Cloud. We also discuss the ways to reduce power and energy in terms of cloud computing services. Our work surveys the various models and helps understand the road map for a greener cloud.","Green products,
Cloud computing,
Servers,
Computational modeling,
Energy consumption,
Power demand,
Energy efficiency"
Fault-tolerant virtual network mapping to provide Content Connectivity in optical networks,We define Content Connectivity as the reachability of every content from any point of an optical network. We propose a scheme for virtual network mapping and content placement to ensure content connectivity after failures.,
Analytical Thermal Model for Self-Heating in Advanced FinFET Devices With Implications for Design and Reliability,"A rigorous analytical thermal model has been formulated for the analysis of self-heating effects in FinFETs, under both steady-state and transient stress conditions. 3-D self-consistent electrothermal simulations, tuned with experimentally measured electrical characteristics, were used to understand the nature of self-heating in FinFETs and calibrate the proposed model. The accuracy of the model has been demonstrated for a wide range of multifin devices by comparing it against finite element simulations. The model has been applied to carry out a detailed sensitivity analysis of self-heating with respect to various FinFET parameters and structures, which are critical for improving circuit performance and electrical overstress/electrostatic discharge (ESD) reliability. The transient model has been used to estimate the thermal time constants of these devices and predict the sensitivity of power-to-failure to various device parameters, for both long and short pulse ESD situations. Suitable modifications to the model are also proposed for evaluating the thermal characteristics of production level FinFET (or Tri-gate FET) structures involving metal-gates, body-tied bulk FinFETs, and trench contacts.","FinFETs,
Heating,
Solid modeling,
Integrated circuit modeling,
Analytical models,
Thermal conductivity,
Conductivity"
Energy-efficient Low Power Listening for wireless sensor networks in noisy environments,"Low Power Listening (LPL) is a common MAC-layer technique for reducing energy consumption in wireless sensor networks, where nodes periodically wakeup to sample the wireless channel to detect activity. However, LPL is highly susceptible to false wakeups caused by environmental noise being detected as activity on the channel, causing nodes to spuriously wakeup in order to receive nonexistent transmissions. In empirical studies in residential environments, we observe that the false wakeup problem can significantly increase a node's duty cycle, compromising the benefit of LPL. We also find that the energy-level threshold used by the Clear Channel Assessment (CCA) mechanism to detect channel activity has a significant impact on the false wakeup rate. We then design AEDP, an adaptive energy detection protocol for LPL, which dynamically adjusts a node's CCA threshold to improve network reliability and duty cycle based on application-specified bounds. Empirical experiments in both controlled tests and real-world environments showed AEDP can effectively mitigate the impact of noise on radio duty cycles, while maintaining satisfactory link reliability.","Portable document format,
IEEE Xplore"
"Lightweight, Flexible, Polarization-Insensitive, Highly Absorbing Meta-Films","An absorbing metafilm is proposed that is based on a dual-concentric-ring resonator design on a flexible substrate. Detailed simulations and parameter studies demonstrate that it has no polarization dependence and has strong absorption performance even at highly oblique angles of incidence. To explain its behavior, the design and its properties are related to the origin of the physical processes of absorption that occur in naturally occurring materials. Variations of this metafilm absorber design are presented that enhance its performance characteristics and its potential for use in several practical applications.","Absorption,
Resonant frequency,
Substrates,
Metamaterials,
Couplings,
Antennas"
An Analytical Placement Framework for 3-D ICs and Its Extension on Thermal Awareness,"In this paper, we present a high-quality analytical 3-D placement framework. We propose using a Huber-based local smoothing technique to work with a Helmholtz-based global smoothing technique to handle the nonoverlapping constraints. The experimental results show that this analytical approach is effective for achieving tradeoffs between the wirelength and the through-silicon-via (TSV) number. Compared to the state-of-the-art 3-D placer ntuplace3d, our placer achieves more than 20% wirelength reduction, on average, with a similar number of TSVs. Furthermore, we extend this analytical 3-D placement framework with thermal awareness. While 2-D thermal-aware placement simply follows uniform power distribution to minimize temperature, we show that the same criterion does not work for 3-D ICs. Instead, we are able to prove that when the TSV area in each bin is proportional to the lumped power consumption of that bin and the bins in all tiers directly above it, the peak temperature is minimized. Based on this criterion, we implement thermal awareness in our analytical 3-D placement framework. Compared with a TSV oblivious method, which only results in an 8% peak temperature reduction, our method reduces the peak temperature by 34%, on average, with slightly less wirelength overhead. These results suggest that considering the thermal effects of TSVs is necessary and effective during the placement stage.","Through-silicon vias,
Smoothing methods,
Thermal analysis,
Optimization,
Approximation methods,
Heating"
Automatic Segmentation and Classification of Human Intestinal Parasites From Microscopy Images,"Human intestinal parasites constitute a problem in most tropical countries, causing death or physical and mental disorders. Their diagnosis usually relies on the visual analysis of microscopy images, with error rates that may range from moderate to high. The problem has been addressed via computational image analysis, but only for a few species and images free of fecal impurities. In routine, fecal impurities are a real challenge for automatic image analysis. We have circumvented this problem by a method that can segment and classify, from bright field microscopy images with fecal impurities, the 15 most common species of protozoan cysts, helminth eggs, and larvae in Brazil. Our approach exploits ellipse matching and image foresting transform for image segmentation, multiple object descriptors and their optimum combination by genetic programming for object representation, and the optimum-path forest classifier for object recognition. The results indicate that our method is a promising approach toward the fully automation of the enteroparasitosis diagnosis.","Impurities,
Shape,
Pipelines,
Image segmentation,
Microscopy,
Humans,
Image color analysis"
Reverse engineering digital circuits using functional analysis,"Integrated circuits (ICs) are now designed and fabricated in a globalized multi-vendor environment making them vulnerable to malicious design changes, the insertion of hardware trojans/malware and intellectual property (IP) theft. Algorithmic reverse engineering of digital circuits can mitigate these concerns by enabling analysts to detect malicious hardware, verify the integrity of ICs and detect IP violations. In this paper, we present a set of algorithms for the reverse engineering of digital circuits starting from an unstructured netlist and resulting in a high-level netlist with components such as register files, counters, adders and subtracters. Our techniques require no manual intervention and experiments show that they determine the functionality of more than 51% and up to 93% of the gates in each of the practical test circuits that we examine.","Algorithm design and analysis,
Logic gates,
Radiation detectors,
Latches,
Reverse engineering,
Shift registers,
Random access memory"
An Interactive Approach to Multiobjective Clustering of Gene Expression Patterns,"Some recent studies have posed the problem of data clustering as a multiobjective optimization problem, where several cluster validity indices are simultaneously optimized to obtain tradeoff clustering solutions. A number of cluster validity index measures are available in the literature. However, none of the measures can perform equally well in all kinds of datasets. Depending on the dataset properties and its inherent clustering structure, different cluster validity measures perform differently. Therefore, it is important to find the best set of validity indices that should be optimized simultaneously to obtain good clustering results. In this paper, a novel interactive genetic algorithm-based multiobjective approach is proposed that simultaneously finds the clustering solution as well as evolves the set of validity measures that are to be optimized simultaneously. The proposed method interactively takes the input from the human decision maker (DM) during execution and adaptively learns from that input to obtain the final set of validity measures along with the final clustering result. The algorithm is applied for clustering real-life benchmark gene expression datasets and its performance is compared with that of several other existing clustering algorithms to demonstrate its effectiveness. The results indicate that the proposed method outperforms the other existing algorithms for all the datasets considered here.","Clustering algorithms,
Linear programming,
Indexes,
Biological cells,
Sociology,
Statistics,
Optimization"
Cold Start Approach for Data-Driven Fault Detection,"A typical assumption in supervised fault detection is that abundant historical data are available prior to model learning, where all types of faults have already been observed at least once. This assumption is likely to be violated in practical settings as new fault types can emerge over time. In this paper we study this often overlooked cold start learning problem in data-driven fault detection, where in the beginning only normal operation data are available and faulty operation data become available as the faults occur. We explored how to leverage strengths of unsupervised and supervised approaches to build a model capable of detecting faults even if none are still observed, and of improving over time, as new fault types are observed. The proposed framework was evaluated on the benchmark Tennessee Eastman Process data. The proposed fusion model performed better on both unseen and seen faults than the stand-alone unsupervised and supervised models.",
Intelligent home-appliance recognition over IoT cloud network,"In recent years, under the concern of energy crisis, the government has actively cooperated with research institutions in developing smart meters. As the Internet of Things (IoT) and home energy management system become popular topics, electronic appliance recognition technology can help users identifying the electronic appliances being used, and further improving power usage habits. However, according to the power usage habits of home users, it is possible to simultaneously switch on and off electronic appliances. Therefore, this study discusses electronic appliance recognition in a parallel state, i.e. recognition of electronic appliances switched on and off simultaneously. This study also proposes a non-invasive smart meter system that considers the power usage habits of users unfamiliar with electronic appliances, which only requires inserting a smart meter into the electronic loop. Meanwhile, this study solves the problem of large data volume of the current electronic appliance recognition system by building a database mechanism, electronic appliance recognition classification, and waveform recognition. In comparison to other electronic appliance recognition systems, this study uses a low order embedded system chip to provide low power consumption, which have high expandability and convenience. Differing from previous studies, the experiment of this study considers electronic appliance recognition and the power usage habits of general users. The experimental results showed that the total recognition rate of a single electronic appliance can reach 96.14%, thus proving the feasibility of the proposed system.","Home appliances,
Consumer electronics,
Character recognition,
Computers,
Smart grids,
Databases,
Signal processing algorithms"
Linear Coherent Estimation With Spatial Collaboration,"A power-constrained sensor network that consists of multiple sensor nodes and a fusion center (FC) is considered, where the goal is to estimate a random parameter of interest. In contrast to the distributed framework, the sensor nodes may be partially connected, where individual nodes can update their observations by (linearly) combining observations from other adjacent nodes. The updated observations are communicated to the FC by transmitting through a coherent multiple access channel. The optimal collaborative strategy is obtained by minimizing the expected mean-square error subject to power constraints at the sensor nodes. Each sensor can utilize its available power for both collaboration with other nodes and transmission to the FC. Two kinds of constraints, namely the cumulative and individual power constraints, are considered. The effects due to imperfect information about observation and channel gains are also investigated. The resulting performance improvement is illustrated analytically through the example of a homogeneous network with equicorrelated parameters. Assuming random geometric graph topology for collaboration, numerical results demonstrate a significant reduction in distortion even for a moderately connected network, particularly in the low local signal-to-noise ratio regime.","Collaboration,
Estimation,
Topology,
Network topology,
Noise measurement,
Signal to noise ratio"
Emotion Recognition from EEG during Self-Paced Emotional Imagery,"Here we present an analysis of a 12-subject electroencephalographic (EEG) data set in which participants were asked to engage in prolonged, self-paced episodes of guided emotion imagination with eyes closed. Our goal is to correctly predict, given a short EEG segment, whether the participant was imagining a positive respectively negative-valence emotional scenario during the given segment using a predictive model learned via machine learning. The challenge lies in generalizing to novel (i.e., previously unseen) emotion episodes from a wide variety of scenarios including love, awe, frustration, anger, etc. based purely on spontaneous oscillatory EEG activity without stimulus event-locked responses. Using a variant of the Filter-Bank Common Spatial Pattern algorithm, we achieve an average accuracy of 71.3% correct classification of binary valence rating across 12 different emotional imagery scenarios under rigorous block-wise cross-validation.",
Low-complexity FPGA implementation of compressive sensing reconstruction,"Compressive sensing (CS) is a novel technology which allows sampling of sparse signals under sub-Nyquist rate and reconstructing the image using computational intensive algorithms. Reconstruction algorithms are complex and software implementation of these algorithms is extremely slow and power consuming. In this paper, a low complexity architecture for the reconstruction of compressively sampled signals is proposed. The algorithm used here is Orthogonal Matching Pursuit (OMP) which can be divided into two major processes: optimization problem and least square problem. The most complex part of OMP is to solve the least square problem and a scalable Q-R decomposition (QRD) core is implemented to perform this. A novel thresholding method is used to reduce the processing time for the optimization problem by at least 25 %. The proposed architecture reconstructs a 256-length signal with maximum sparsity of 8 and using 64 measurements. Implementation on Xilinx Virtex-5 FPGA runs at two clock rates (85 MHz and 69 MHz), and occupies an area of 15% slices and 80% DSP cores. The total reconstruction for a 128-length signal takes 7.13 μs which is 3.4 times faster than the state-of-art-implementation.","Image reconstruction,
Hardware,
Matching pursuit algorithms,
Indexes,
Computer architecture,
Compressed sensing,
Field programmable gate arrays"
Verifiable private multi-party computation: Ranging and ranking,"The existing work on distributed secure multi-party computation, e.g., set operations, dot product, ranking, focus on the privacy protection aspects, while the verifiability of user inputs and outcomes are neglected. Most of the existing works assume that the involved parties will follow the protocol honestly. In practice, a malicious adversary can easily forge his/her input values to achieve incorrect outcomes or simply lie about the computation results to cheat other parities. In this work, we focus on the problem of verifiable privacy preserving multiparty computation. We thoroughly analyze the attacks on existing privacy preserving multi-party computation approaches and design a series of protocols for dot product, ranging and ranking, which are proved to be privacy preserving and verifiable. We implement our protocols on laptops and mobile phones. The results show that our verifiable private computation protocols are efficient both in computation and communication.",
"A CMOS-Compatible, Low-Loss, and Low-Crosstalk Silicon Waveguide Crossing","We demonstrated a waveguide crossing for submicron silicon waveguides with average insertion loss of 0.18±0.03 dB and crosstalk of -41±2 dB, uniform across an 8-inch wafer. The device was fabricated in a CMOS-compatible process using 248 nm lithography, with only one patterning step.",
A Normalized Least Mean Squares Algorithm With a Step-Size Scaler Against Impulsive Measurement Noise,"This brief introduces the concept of a step-size scaler by investigating and modifying the tanh cost function for adaptive filtering with impulsive measurement noise. The step-size scaler instantly scales down the step size of gradient-based adaptive algorithms whenever impulsive measurement noise appears, which eliminates a possibility of updating weight vector estimates based on wrong information due to impulsive noise. The most attractive feature of the step-size scaler is that this is easily applicable to various gradient-based adaptive algorithms. Several representative gradient-based adaptive algorithms are performed without or with the step-size scaler in impulsive-noise environments, which shows the improvement of robustness against impulsive noise.","signal processing,
adaptive filters,
impulse noise,
least mean squares methods"
Target Localization and Tracking for an Isogradient Sound Speed Profile,"In an underwater medium the sound speed is not constant, but varies with depth. This phenomenon upsets the linear dependency of the distance traveled by an acoustic wave to the time it takes for the wave to travel that distance, and therefore makes existing distance-based localization algorithms less effective in an underwater environment. This paper addresses the problems of localizing a fixed node and tracking a mobile target from acoustic time-of-flight (ToF) measurements in a three-dimensional underwater environment with an isogradient sound speed profile. To solve these problems we first analytically relate the acoustic wave ToF between two nodes to their positions. After obtaining sufficient ToF measurements, we then adopt the Gauss-Newton algorithm to localize the fixed node in an iterative manner, and we utilize the extended Kalman filter for tracking the mobile target in a recursive manner. Through several simulations, we will illustrate that the proposed algorithms perform superb since they meet the Cramér-Rao bound (CRB) for localization and posterior CRB for tracking.","Signal processing algorithms,
Target tracking,
Ray tracing,
Temperature measurement,
Acoustic measurements,
Ocean temperature,
Trajectory"
ProHet: A Probabilistic Routing Protocol with Assured Delivery Rate in Wireless Heterogeneous Sensor Networks,"Due to different requirements in applications, sensors with different capacities are deployed. How to design efficient, reliable and scalable routing protocols in such wireless heterogeneous sensor networks (WHSNs) with intermittent asymmetric links is a challenging task. In this paper, we propose ProHet: a distributed probabilistic routing protocol for WHSNs that utilizes asymmetric links to reach assured delivery rate with low overhead. The ProHet protocol first produces a bidirectional routing abstraction by finding a reverse path for every asymmetric link. Then, it uses a probabilistic strategy to choose forwarding nodes based on historical statistics using local information. Analysis shows that ProHet can achieve assured delivery rate ρ if ρ is set within its upper-bound. Extensive simulations are conducted to verify its efficiency.",
A Wideband Dual-Polarized Slot Antenna,"In this letter, we have proposed a dual-polarized planar circular slot antenna for wideband application. Two orthogonal polarizations were achieved by adopting different feeding mechanisms with high ports isolation. The horizontal polarization is excited by a meander-line coupled slot, and the vertical polarization is fed by a stepped monopole. The prototype of the proposed antenna has been built and tested. The proposed design obtained a fairly wide bandwidth (1.70-2.71 GHz) and a high isolation (> 33 dB) over the entire band. The gain of the dual polarizations is also measured and discussed.","Slot antennas,
Ports (Computers),
Antenna measurements,
Broadband antennas,
Wideband"
Not-so-humble raspberry pi gets big ideas,"As the Raspberry Pi celebrates its first birthday, designs intended for the hobbyist are getting mainstream attention from developers of 'grown up' applications. Few items of electronic hardware have engendered quite as much enthusiasm as the compact, single-board computer developed by the Raspberry Pi Foundation with the aim of encouraging basic computer science in schools. Had it had been for sale in shops, the queues would probably have outstripped those around Apple stores in the earlier days of the iPhone and iPad. The Pi - and other hardware like it - is reinvigorating the world of electronic design; but the project started out with fairly limited ambitions, with its founders hoping that it would simply fill a gap in education. As the Raspberry Pi celebrates its first birthday - and one million units shipped - there are several indications that its value is being readily exploited by developers of 'grown up' products who see it as a cheap (circa £25) and effective way of getting compute power into a range of commercial-class solutions requirements.",
Semi-Blind Key-Agreement over MIMO Fading Channels,"In this paper, we study the fundamental limits of secret-key agreement over MIMO quasi-static fading channels. We provide closed-form expressions for the secret-key capacity in both the asymptotic high-power and low-power regimes. The optimal signaling strategy for the low-power regime is shown to be independent of the eavesdropper's channel and secret-key capacity is achieved by transmitting random Gaussian symbols along the direction corresponding to the maximal eigenvalue of the legitimate channel matrix. Hence, by beamforming and waterfilling over the main channel alone, one obtains a semi-blind key-agreement strategy in which the knowledge of the eavesdropper's channel is only required for privacy amplification. We also derive the probability that a target secret-key rate is not achieved by the optimal low-power signaling when assuming only statistical CSI about the eavesdropper's channel.",
Playing Transportation Seriously: Applications of Serious Games to Artificial Transportation Systems,A discussion of the potential integration of serious games into the conceptual framework of artificial transportation systems focuses on behavior elicitation through peer-designed agents to model and simulate artificial societies on a participative basis.,
A Sparse Structure Learning Algorithm for Gaussian Bayesian Network Identification from High-Dimensional Data,"Structure learning of Bayesian Networks (BNs) is an important topic in machine learning. Driven by modern applications in genetics and brain sciences, accurate and efficient learning of large-scale BN structures from high-dimensional data becomes a challenging problem. To tackle this challenge, we propose a Sparse Bayesian Network (SBN) structure learning algorithm that employs a novel formulation involving one L1-norm penalty term to impose sparsity and another penalty term to ensure that the learned BN is a Directed Acyclic Graph (DAG)&#x2014;a required property of BNs. Through both theoretical analysis and extensive experiments on 11 moderate and large benchmark networks with various sample sizes, we show that SBN leads to improved learning accuracy, scalability, and efficiency as compared with 10 existing popular BN learning algorithms. We apply SBN to a real-world application of brain connectivity modeling for Alzheimer's disease (AD) and reveal findings that could lead to advancements in AD research.","Algorithm design and analysis,
Bayesian methods,
Input variables,
Machine learning,
Accuracy,
Brain models"
Local Structure-Based Image Decomposition for Feature Extraction With Applications to Face Recognition,"This paper presents a robust but simple image feature extraction method, called image decomposition based on local structure (IDLS). It is assumed that in the local window of an image, the macro-pixel (patch) of the central pixel, and those of its neighbors, are locally linear. IDLS captures the local structural information by describing the relationship between the central macro-pixel and its neighbors. This relationship is represented with the linear representation coefficients determined using ridge regression. One image is actually decomposed into a series of sub-images (also called structure images) according to a local structure feature vector. All the structure images, after being down-sampled for dimensionality reduction, are concatenated into one super-vector. Fisher linear discriminant analysis is then used to provide a low-dimensional, compact, and discriminative representation for each super-vector. The proposed method is applied to face recognition and examined using our real-world face image database, NUST-RWFR, and five popular, publicly available, benchmark face image databases (AR, Extended Yale B, PIE, FERET, and LFW). Experimental results show the performance advantages of IDLS over state-of-the-art algorithms.","vectors,
decomposition,
face recognition,
feature extraction,
image representation,
image sampling,
regression analysis"
Hardware Implementation of a Fast and Efficient Haze Removal Method,"In this letter, a fast and efficient haze removal method is presented. We employ an extremum approximate method to extract the atmospheric light and propose a contour preserving estimation to obtain the transmission by using edge-preserving and mean filters alternately. Our method can efficiently avoid the halo artifact generated in the recovered image. To meet the requirement of real-time applications, an 11-stage pipelined hardware architecture for our haze removal method is presented. It can achieve 200 MHz with 12.8 K gate counts by using TSMC 0.13- μm technology. Simulation results indicate that our design can obtain comparable results with the least execution time compared to previous algorithms and is suitable for low-cost high-performance hardware implementation for haze removal.","Hardware,
Table lookup,
Estimation,
Image edge detection,
Real-time systems,
Atmospheric modeling"
An Efficient Security System for CABAC Bin-Strings of H.264/SVC,"The distribution of copyrighted scalable video content to differing digital devices requires protection during rendering and transmission. In this paper, we propose a complete security system for H.264/scalable video coding (SVC) video codec and present a solution for the bit-rate and format compliance problems by careful selection of entropy coder syntax elements (bin-strings) for selective encryption (SE), and the problem of managing multiple layer encryption keys for scalable video distribution. A standard key management protocol, multimedia Internet keying protocol, is implemented for the hierarchical key generation mechanism, in which a subscriber has only one encryption key to unlock all scalable layers that have been subscribed to. The evaluation demonstrates the resulting video quality degradation arising from SE for many CIF and 4CIF test video sequences, without there being any impact upon the bit-rate or format compliancy, and with small computational delay. The security and statistical analysis performed further verify the effectiveness of the proposed security system for H.264/SVC. The proposed system is highly suitable for video distribution to users who have subscribed to a varying degree of video quality on devices with medium to high computational resources.","Encryption,
Static VAr compensators,
Syntactics,
Encoding,
Protocols"
Complex Eye Movement Pattern Biometrics: The Effects of Environment and Stimulus,"This paper presents an objective evaluation of the effects of eye tracking specification and stimulus presentation on the biometric viability of complex eye movement patterns. Six spatial accuracy tiers (0.5°, 1.0°, 1.5°, 2.0°, 2.5°, 3.0°), six temporal resolution tiers (1000, 500, 250, 120, 75, 30 Hz), and five stimulus types (simple, complex, cognitive, textual, random) are evaluated to identify acceptable conditions under which to collect eye movement data. The results suggest the use of eye tracking equipment capable of at least 0.5° spatial accuracy and 250 Hz temporal resolution for biometric purposes, whereas stimulus had little effect on the biometric viability of eye movements.","Accuracy,
Iris recognition,
Biometrics (access control),
Visual systems,
Eyes,
Pattern analysis"
Anatomical Labeling of the Circle of Willis Using Maximum A Posteriori Probability Estimation,"Anatomical labeling of the cerebral arteries forming the Circle of Willis (CoW) enables inter-subject comparison, which is required for geometric characterization and discovering risk factors associated with cerebrovascular pathologies. We present a method for automated anatomical labeling of the CoW by detecting its main bifurcations. The CoW is modeled as rooted attributed relational graph, with bifurcations as its vertices, whose attributes are characterized as points on a Riemannian manifold. The method is first trained on a set of pre-labeled examples, where it learns the variability of local bifurcation features as well as the variability in the topology. Then, the labeling of the target vasculature is obtained as maximum a posteriori probability (MAP) estimate where the likelihood of labeling individual bifurcations is regularized by the prior structural knowledge of the graph they span. The method was evaluated by cross-validation on 50 subjects, imaged with magnetic resonance angiography, and showed a mean detection accuracy of 95%. In addition, besides providing the MAP, the method can rank the labelings. The proposed method naturally handles anatomical structural variability and is demonstrated to be suitable for labeling arterial segments of the CoW.",
Heterojunction-Free GaN Nanochannel FinFETs With High Performance,"Heavily doped GaN nanochannel fin-shaped field-effect transistors (FinFETs) without heterojunction have been fabricated and characterized for the first time. Simplified pragmatical technology for GaN epitaxial growth and FinFET process was used to achieve nanodevices with a channel width from 40 to 100 nm and a gate length of 1 μm. They exhibit excellent on-state performance, such as maximum drain current of 670 mA/mm and maximum transconductance of 168 mS/mm. Record off-state performance was measured: extremely low leakage current of ~ 10-11 mA and source-drain breakdown voltage of ~280 V. The subthreshold slope of 68 mV/decade is close to the theoretical limit (60 mV/decade, so far achieved only in SOI MOSFETs) and leads to very high Ion/Ioff ratio of 108 - 109. The proposed heterojunction-free nanochannel GaN FinFET is a very promising candidate not only for high-performance and high-speed integrated circuits but also for high-power applications.",
Multiple-Window Anomaly Detection for Hyperspectral Imagery,"Due to advances of hyperspectral imaging sensors many unknown and subtle targets that cannot be resolved by multispectral imagery can now be uncovered by hyperspectral imagery. These targets generally cannot be identified by visual inspection or prior knowledge, but yet provide crucial and vital information for data exploitation. One such type of targets is anomalies which have recently received considerable interest in hyperspectral image analysis. Many anomaly detectors have been developed and most of them are based on the most widely used Reed-Yu's algorithm, called RX detector (RXD). However, a key issue in making RX detector-like anomaly detectors effective is how to effectively utilize the spectral information provided by data samples, e.g., sample covariance matrix used by RXD. Recently, a dual window-based eigen separation transform (DWEST) was developed to address this issue. This paper extends the concept of DWEST to develop a new approach, to be called multiple-window anomaly detection (MWAD) by making use of multiple windows to perform anomaly detection adaptively. As a result, MWAD is able to detect anomalies of various sizes using multiple windows so that local spectral variations can be characterized and extracted by different window sizes. By virtue of this newly developed MWAD, many existing RXD-like anomaly detectors including DWEST can be derived as special cases of MWAD.",
Models for the Diffusion of Beliefs in Social Networks: An Overview,"Our article compared models for social learning and opinion diffusion in the context of economics and social science with those used in signal processing over networks of sensors, explaining how learning emerges or fails to emerge in both scenarios. It also critically discusses how the advent of the Internet and of smartphones is generating a wealth of data and enhancing the decision-making capabilities of social agents in ways that were never conceivable before. The article also argues that more engineering research is needed to advance modeling and inference algorithms and enhance even further the cyberinteractions of social agents. This area has tremendous potential as well as carries tremendous risks. Consumers lose their privacy and can be influenced in undesired ways. Hence, a critical consideration to make in expanding our understanding on this subject is to what extent it is safe to increase the ability of hardware and software to capture contextual data about the customers.","Complex networks,
Information extraction,
Social network services,
Adaptation models,
Diffusion processes,
Mathematical model,
Biological system modeling"
Model Checking of Linear-Time Properties Based on Possibility Measure,"Using possibility measure, we study model checking of linear-time properties in possibilistic Kripke structures. First, the notion of possibilistic Kripke structures and the related possibility measure are introduced, and then, model checking of reachability and repeated reachability linear-time properties in finite possibilistic Kripke structures are studied. Standard safety properties and ω-regular properties in possibilistic Kripke structures are introduced; the verification of regular safety properties and ω-regular properties using finite automata are thoroughly studied. It has been shown that the verification of regular safety properties and ω-regular properties in a finite possibilistic Kripke structure can be transformed into the verification of reachability properties and repeated reachability properties in the product possibilistic Kripke structure that is introduced in this paper. Several examples are given to illustrate the methods that are presented in this paper.","Biomedical measurements,
Safety,
Uncertainty,
Algebra,
Computational modeling,
Probabilistic logic"
Real-Time GPU-Based Ultrasound Simulation Using Deformable Mesh Models,"This paper presents a real-time capable graphics processing unit (GPU)-based ultrasound simulator suitable for medical education. The main focus of the simulator is to synthesize realistic looking ultrasound images in real-time including artifacts, which are essential for the interpretation of this data. The simulation is based on a convolution-enhanced ray-tracing approach and uses a deformable mesh model. Deformations of the mesh model are calculated using the PhysX engine. Our method advances the state of the art for real-time capable ultrasound simulators by following the path of the ultrasound pulse, which enables better simulation of ultrasound-specific artifacts. An evaluation of our proposed method in comparison with recent generative slicing-based strategies as well as real ultrasound images is performed. Hereby, a gelatin ultrasound phantom containing syringes filled with different media is scanned with a real transducer. The obtained images are then compared to images which are simulated using a slicing-based technique and our proposed method. The particular benefit of our method is the accurate simulation of ultrasound-specific artifacts, like range distortion, refraction and acoustic shadowing. Several test scenarios are evaluated regarding simulation time, to show the performance and the bottleneck of our method. While being computationally more intensive than slicing techniques, our simulator is able to produce high-quality images in real-time, tracing over 5000 rays through mesh models with more than 2 000 000 triangles of which up to 200 000 may be deformed each frame.","Ultrasonic imaging,
Deformable models,
Transducers,
Ray tracing,
Real-time systems,
Solid modeling,
Computational modeling"
On MLMDA/Butterfly Compressibility of Inverse Integral Operators,"The multilevel matrix decomposition algorithm (MLMDA) is shown to permit effective compression of inverse integral operators pertinent to the analysis of scattering from electrically large structures. Observed compression ratios exceed those realized by low-rank (LR) compression methods, leading to substantial memory savings and a faster application of the inverse operator, and suggesting a new application for schemes traditionally used for compressing forward integral operators.","Memory management,
Matrix decomposition,
Approximation methods,
Integral equations,
Educational institutions,
Electromagnetic scattering"
A Rank Correlation Based Detection against Distributed Reflection DoS Attacks,"DDoS presents a serious threat to the Internet since its inception, where lots of controlled hosts flood the victim site with massive packets. Moreover, in Distributed Reflection DoS (DRDoS), attackers fool innocent servers (reflectors) into flushing packets to the victim. But most of current DRDoS detection mechanisms are associated with specific protocols and cannot be used for unknown protocols. It is found that because of being stimulated by the same attacking flow, the responsive flows from reflectors have inherent relations: the packet rate of one converged responsive flow may have linear relationships with another. Based on this observation, the Rank Correlation based Detection (RCD) algorithm is proposed. The preliminary simulations indicate that RCD can differentiate reflection flows from legitimate ones efficiently and effectively, thus can be used as a useable indicator for DRDoS.",
Accelerated and Localized Newton Schemes for Faster Dynamic Simulation of Large Power Systems,"This paper proposes two methods to speed up the demanding time-domain simulations of large power system models. First, the sparse linear system to solve at each Newton iteration is decomposed according to its bordered block diagonal structure in order to solve only those parts that need to be solved and update only submatrices of the Jacobian that need to be updated. This brings computational savings without degradation of accuracy. Next, the Jacobian structure is further exploited to localize the system response, i.e., involve only the components identified as active, with an acceptable and controllable decrease in accuracy. The accuracy and computational savings are assessed on a large-scale test system.","Mathematical model,
Jacobian matrices,
Power system dynamics,
Equations,
Acceleration,
Computational modeling,
Vectors"
Volcanic earthquake timing using wireless sensor networks,"Recent years have witnessed pilot deployments of inexpensive wireless sensor networks (WSNs) for active volcano monitoring. This paper studies the problem of picking arrival times of primary waves (i.e., P-phases) received by seismic sensors, one of the most critical tasks in volcano monitoring. Two fundamental challenges must be addressed. First, it is virtually impossible to download the real-time high-frequency seismic data to a central station for P-phase picking due to limited wireless network bandwidth. Second, accurate P-phase picking is inherently computation-intensive, and is thus prohibitive for many low-power sensor platforms. To address these challenges, we propose a new P-phase picking approach for hierarchical volcano monitoring WSNs where a large number of inexpensive sensors are used to collect fine-grained, real-time seismic signals while a small number of powerful coordinator nodes process collected data and pick accurate P-phases. We develop a suite of new in-network signal processing algorithms for accurate P-phase picking, including lightweight signal pre-processing at sensors, sensor selection at coordinators as well as signal compression and reconstruction algorithms. Testbed experiments and extensive simulations based on real data collected from a volcano show that our approach achieves accurate P-phase picking while only 16% of the sensor data are transmitted.","Sensors,
Earthquakes,
Wireless sensor networks,
Signal processing algorithms,
Volcanoes,
Timing,
Discrete wavelet transforms"
A Survey on Identity Management for the Future Network,"The Internet as a platform for ubiquitous communication has quickly advanced in the last years. New services have emphasized the limits of the current Internet and motivated the development of the Future Internet. Future communication infrastructures intend to be more distributed and, ideally, more secure, resulting in high complexity. Further, as new technologies emerge, new requirements and security issues are highlighted. These issues reinforce the importance of Identity Management systems for the network infrastructure in the Future Internet, termed Future Network, to provide adequate dynamic services in relation to user's personal data and requirements. Hence, this survey presents the state of the art of Identity Management systems for the Future Network. It highlights the existing architectures, specific devices applied, challenges and future perspectives.","Internet,
Authentication,
Network architecture,
Mobile communication,
Authorization,
Identity management"
Trends in energy-efficient computing: A perspective from the Green500,"A recent study shows that computation per kilowatt-hour has doubled every 1.57 years, akin to Moore's Law. While this trend is encouraging, its implications to high-performance computing (HPC) are not yet clear. For instance, DARPA's target of a 20-MW exaflop system will require a 56.8-fold performance improvement with only a 2.4-fold increase in power consumption, which seems unachievable in light of the above trend. To provide a more comprehensive perspective, we analyze current trends in energy efficiency from the Green500 and project expectations for the near future. Specifically, we first provide an analysis of energy efficiency trends in HPC systems from the Green500. We then model and forecast the energy efficiency of future HPC systems. Next, we present exascalar - a holistic metric to measure the distance from the exaflop goal. Finally, we discuss our efforts to standardize power measurement methodologies in order to provide the community with reliable and accurate efficiency data.","Green products,
Computers,
Lead"
"A Near-Threshold, 0.16 nJ/b OOK-Transmitter With 0.18 nJ/b Noise-Cancelling Super-Regenerative Receiver for the Medical Implant Communications Service","A 0.16 nJ/b MICS transmitter and 0.18 nJ/b super-regenerative receiver are demonstrated, where each is specifically designed to operate in the near-threshold region. The low-VDD transmitter utilizes a sub-harmonic injection-locked ring oscillator, edge combiner for frequency multiplication, and class-C power amplifier. The low-VDD receiver introduces a replica super-regenerative receiver as a method to reject common-mode noise sources, such as supply/substrate coupling, thereby reducing undesired self-oscillations and improving BER. Designed in a 90-nm CMOS process, the test-chip measurements show a sensitivity of -80 dBm at 500 kb/s and -65 dBm at 1 Mb/s, respectively, at a BER less than 10-3, with 340 μW total power.",
An event-driven power management scheme for mobile consumer electronics,"Dynamic processor power management based on periodic monitoring of processor load is being widely used to enhance battery life of mobile consumer electronics. The existing power management schemes, however, often lead to poor user-perceived responsiveness, which is a crucial factor for the quality of user experiences, by making inadequate or delayed decisions on the processor performance level. This paper presents a novel event-driven scheme of the processor power management to guarantee high responsiveness while minimizing ineffective energy consumption. The proposed scheme exploits the characteristic of an interactive event, which is triggered by a user input instead of a periodic timer interrupt. The prototype of the proposed event-driven scheme is implemented for an application launch event as an example. In order to quantify user-perceived responsiveness and energy consumption simultaneously, this paper introduces a latency measurement benchmark program. In the evaluation with the benchmark, the proposed power management scheme showed comparable responsiveness with higher energy savings up to 20 % than the existing dynamic schemes when the interactive workload is mixed with a CPU-intensive background task.","Mobile communication,
Consumer electronics,
Clocks,
Energy consumption,
Browsers,
Time factors,
Multicore processing"
Who Am I? Analyzing Digital Personas in Cybercrime Investigations,The Isis toolkit offers the sophisticated capabilities required to analyze digital personas and provide investigators with clues to the identity of the individual or group hiding behind one or more personas.,"Computer security,
Computer crime,
Digital forensics,
Human factors,
Behavioral science,
Identity management"
An Efficient Prony-Based Solution Procedure for Tracking of Power System Voltage Variations,"Magnitude and duration are important characteristics when performing tracking of voltage variations. Accurate characterization of voltage variations relies much on the precise identification of frequencies of the measured signals. Although the Prony's method can provide high resolution for frequency estimation, the computational burden in the root-finding process is a crucial problem. A modified Prony-based solution procedure for voltage variation tracking is proposed in this paper. By providing a set of filters, the transfer polynomial with high estimation order in Prony's model can be efficiently reduced. The performance of the proposed method is validated by testing the generated and actual measured voltage signals. Results are compared with those obtained by typical Prony's method, namely, fast Fourier transform, adaptive linear neural network, and Kalman filtering. It shows that the proposed method is more accurate regardless of interferences of the power system frequency deviation, harmonics, and interharmonics, where both voltage variations and harmonics can be simultaneously detected.","Polynomials,
Estimation,
Power systems,
Frequency estimation,
Band pass filters,
Synchronization,
Frequency synchronization"
High power factor vernier permanent magnet machines,"Vernier permanent magnet (VPM) machines are well known for high torque density but low power factor. This paper deals with the low power factor of VPM machines. The goal is not obtained by reducing the electrical loading or adjusting current advance angle but proposing a novel vernier topology-dual-stator, spoke-array (DSSA) VPM topology. In this paper, the characteristics, such as active part, auxiliary mechanical structure and rotor anisotropy, of the DSSA VPM topology are analyzed in detail. Performances, including power factor, torque density, and cogging torque etc., are evaluated based on finite element analysis (FEA). The analysis results show that the DSSA VPM topology exhibits high power factor viz.,~0.9 and significantly high torque capability. Finally, the prototype machine has been designed, built, and is under testing. The verification of the mechanical structure scheme is done in this paper, and the experimental results will be presented in the near future.","Reactive power,
Torque,
Rotors,
Decision support systems,
Stator windings,
Magnetic flux leakage"
Sketch based face recognition: Forensic vs. composite sketches,"Facial sketches are widely used by law enforcement agencies to assist in the identification and apprehension of suspects involved in criminal activities. Sketches used in forensic investigations are either drawn by forensic artists (forensic sketches) or created with computer software (composite sketches) following the verbal description provided by an eyewitness or the victim. These sketches are posted in public places and in media in hopes that some viewers will provide tips about the identity of the suspect. This method of identifying suspects is slow and tedious and may not lead to apprehension of the suspect. Hence, there is a need for a method that can automatically and quickly match facial sketches to large police mugshot databases. We address the problem of automatic facial sketch to mugshot matching and, for the first time, compare the effectiveness of forensic sketches and composite sketches. The contributions of this paper include: (i) a database containing mugshots and corresponding forensic and composite sketches that will be made available to interested researchers; (ii) a comparison of holistic facial representations versus component based representations for sketch to mugshot matching; and (iii) an analysis of the effect of filtering a mugshot gallery using three sources of demographic information (age, gender and race/ethnicity). Our experimental results show that composite sketches are matched with higher accuracy than forensic sketches to the corresponding mugshots. Both of the face representations studied here yield higher sketch to photo matching accuracy compared to a commercial face matcher.","Forensics,
Face,
Face recognition,
Accuracy,
Law enforcement,
Software,
Databases"
Automated extraction of non-functional requirements in available documentation,"While all systems have non-functional requirements (NFRs), they may not be explicitly stated in a formal requirements specification. Furthermore, NFRs may also be externally imposed via government regulations or industry standards. As some NFRs represent emergent system proprieties, those NFRs require appropriate analysis and design efforts to ensure they are met. When the specified NFRs are not met, projects incur costly re-work to correct the issues. The goal of our research is to aid analysts in more effectively extracting relevant non-functional requirements in available unconstrained natural language documents through automated natural language processing. Specifically, we examine which document types (data use agreements, install manuals, regulations, request for proposals, requirements specifications, and user manuals) contain NFRs categorized to 14 NFR categories (e.g. capacity, reliability, and security). We measure how effectively we can identify and classify NFR statements within these documents. In each of the documents evaluated, we found NFRs present. Using a word vector representation of the NFRs, a support vector machine algorithm performed twice as effectively compared to the same input to a multinomial naïve Bayes classifier. Our k-nearest neighbor classifier with a unique distance metric had an F1 measure of 0.54, outperforming in our experiments the optimal naïve Bayes classifier which had a F1 measure of 0.32. We also found that stop word lists beyond common determiners had no minimal performance effect.","Natural languages,
Classification algorithms,
Measurement,
Documentation,
Standards,
Security,
Machine learning algorithms"
Adaptive Negotiation Agent for Facilitating Bi-Directional Energy Trading Between Smart Building and Utility Grid,"Smart and green buildings have attracted much attention in recent years. Development of an effective negotiation model for facilitating the bi-directional energy trading between the utility grid and the building is important for enhancing the building intelligence. In this paper, a negotiation agent based on adaptive attitude bidding strategy (AABS) is proposed. A comprehensive set of factors for the integrated smart building and utility grid system is taken into account in developing the negotiation model. The AABS based negotiation agent turns out to be able to dynamically adjust its behavior in response to varying attitudes in the negotiation process. In addition, an improved particle swarm optimization-adaptive attitude bidding strategy (PSO-AABS) based negotiation agent is developed for adaptively adjusting the trader's decisions according to the opponent's behaviors. It turns out to be capable of making rational deals in bi-directional energy trading by maximizing the trader's payoffs with reduced negotiation time. The feasibility of the proposed negotiation agents is evaluated by the simulation results.","Smart buildings,
Batteries,
Bidirectional control,
Adaptation models,
Renewable energy resources,
Particle swarm optimization"
A Study of Energy-Aware Traffic Grooming in Optical Networks: Static and Dynamic Cases,"Less attention has been given to energy aware optical counterparts, compared to the research in energy-aware wireless and ethernet networks. In this paper, we consider energy-aware traffic grooming problems in optical networks for both static and dynamic cases. Rather than simply considering a logical architecture of an optical node, we specifically look further into the modular physical architecture. We show that by reusing already active physical components during request allocations, we can significantly reduce the total number of active components and, hence, total energy consumption in the network, especially when traffic load is low. Since energy usage is an important element of operational expenditure, this approach provides the financial motivation for service providers along with the desired environmental motivation. We present a mathematical formulation of the problems, propose auxiliary graph based heuristics, and justify our cases compared to traditional approaches, based on simulation results.","Optical switches,
Optical fiber networks,
Topology,
Energy consumption,
Power demand,
Photonics,
Indexes"
Path sensitive static analysis of web applications for remote code execution vulnerability detection,"Remote code execution (RCE) attacks are one of the most prominent security threats for web applications. It is a special kind of cross-site-scripting (XSS) attack that allows client inputs to be stored and executed as server side scripts. RCE attacks often require coordination of multiple requests and manipulation of string and non-string inputs from the client side to nullify the access control protocol and induce unusual execution paths on the server side. We propose a path- and context-sensitive interprocedural analysis to detect RCE vulnerabilities. The analysis features a novel way of analyzing both the string and non-string behavior of a web application in a path sensitive fashion. It thoroughly handles the practical challenges entailed by modeling RCE attacks. We develop a prototype system and evaluate it on ten real-world PHP applications. We have identified 21 true RCE vulnerabilities, with 8 unreported before.","Servers,
Access control,
Cognition,
Semantics,
Standards,
Context"
Linear Tracking for 3-D Medical Ultrasound Imaging,"As the clinical application grows, there is a rapid technical development of 3-D ultrasound imaging. Compared with 2-D ultrasound imaging, 3-D ultrasound imaging can provide improved qualitative and quantitative information for various clinical applications. In this paper, we proposed a novel tracking method for a freehand 3-D ultrasound imaging system with improved portability, reduced degree of freedom, and cost. We designed a sliding track with a linear position sensor attached, and it transmitted positional data via a wireless communication module based on Bluetooth, resulting in a wireless spatial tracking modality. A traditional 2-D ultrasound probe fixed to the position sensor on the sliding track was used to obtain real-time B-scans, and the positions of the B-scans were simultaneously acquired when moving the probe along the track in a freehand manner. In the experiments, the proposed method was applied to ultrasound phantoms and real human tissues. The results demonstrated that the new system outperformed a previously developed freehand system based on a traditional six-degree-of-freedom spatial sensor in phantom and in vivo studies, indicating its merit in clinical applications for human tissues and organs.","Ultrasonic imaging,
Probes,
Image reconstruction,
Calibration,
Computers,
Phantoms"
On Construction of Quality Fault-Tolerant Virtual Backbone in Wireless Networks,"In this paper, we study the problem of computing quality fault-tolerant virtual backbone in homogeneous wireless network, which is defined as the k-connected m-dominating set problem in a unit disk graph. This problem is NP-hard, and thus many efforts have been made to find a constant factor approximation algorithm for it, but never succeeded so far with arbitrary k ≥ 3 and m ≥ 1 pair. We propose a new strategy for computing a smaller-size 3-connected m-dominating set in a unit disk graph with any m ≥ 1. We show the approximation ratio of our algorithm is constant and its running time is polynomial. We also conduct a simulation to examine the average performance of our algorithm. Our result implies that while there exists a constant factor approximation algorithm for the k-connected m-dominating set problem with arbitrary k ≤ 3 and m ≥ 1 pair, the k-connected m-dominating set problem is still open with k > 3.",
An interoperable architecture for mobile smart services over the internet of energy,"The Internet of Energy (IoE) for Electric Mobility is an European research project that aims at deploying a communication infrastructure to facilitate and support the operations of Electric Vehicles (EVs). In this paper, we present three research contributions of IoE. First, we describe a software architecture to support the deployment of mobile and smart services over an Electric Mobility (EM) scenario. The proposed architecture relies on an ontology-based data representation, on a shared repository of information (Service Information Broker), and on software modules (called Knowledge Processors -KPs) for standardized data access/management. As a result, information sharing among the different stakeholders of the EM scenario (i.e. EVs, EVSEs, City Services, etc) is enabled, and the interoperability of smart services offered by heterogeneous providers is guaranteed by the common ontology. Second, we rely on the proposed architecture to develop a remote charging reservation system, that runs on top of mobile smarthphones, and allows drivers to monitor the current state-of-charge of their EV, and to reserve a charging slot at a specific EVSE. Finally, we validate our architecture through a benchmark framework, that supports the embedding of mobile EV applications and of real KPs into a simulated vehicular scenario, including realistic traffic, wireless communication and battery models. Evaluation results confirm the scalability of our architecture, and the ability to support EVs charging operations on a large-scale scenario (i.e. the downtown of Bologna).","Mobile communication,
Cities and towns,
Computer architecture,
Vehicles,
Ontologies,
Batteries,
Smart phones"
Learning Context Cues for Synapse Segmentation,"We present a new approach for the automated segmentation of synapses in image stacks acquired by electron microscopy (EM) that relies on image features specifically designed to take spatial context into account. These features are used to train a classifier that can effectively learn cues such as the presence of a nearby post-synaptic region. As a result, our algorithm successfully distinguishes synapses from the numerous other organelles that appear within an EM volume, including those whose local textural properties are relatively similar. Furthermore, as a by-product of the segmentation, our method flawlessly determines synaptic orientation, a crucial element in the interpretation of brain circuits. We evaluate our approach on three different datasets, compare it against the state-of-the-art in synapse segmentation and demonstrate our ability to reliably collect shape, density, and orientation statistics over hundreds of synapses.","Context,
Image segmentation,
Eigenvalues and eigenfunctions,
Feature extraction,
Manuals,
Microscopy,
Tensile stress"
Attenuation Correction for the HRRT PET-Scanner Using Transmission Scatter Correction and Total Variation Regularization,"In the standard software for the Siemens high-resolution research tomograph (HRRT) positron emission tomography (PET) scanner the most commonly used segmentation in the μ-map reconstruction for human brain scans is maximum a posteriori for transmission (MAP-TR). Bias in the lower cerebellum and pons in HRRT brain images have been reported. The two main sources of the problem with MAP-TR are poor bone/soft tissue segmentation below the brain and overestimation of bone mass in the skull. Method: We developed the new transmission processing with total variation (TXTV) method that introduces scatter correction in the μ-map reconstruction and total variation filtering to the transmission processing. Results: Comparing MAP-TR and the new TXTV with gold standard CT-based attenuation correction, we found that TXTV has less bias as compared to MAP-TR. We also compared images acquired at the HRRT scanner using TXTV to the GE Advance scanner images and found high quantitative correspondence. TXTV has been used to reconstruct more than 4000 HRRT scans at seven different sites with no reports of biases. Conclusion: TXTV-based reconstruction is recommended for human brain scans on the HRRT.","Positron emission tomography,
Image reconstruction,
Phantoms,
Computed tomography,
Attenuation,
Standards,
Image resolution"
Polar Codes: Speed of Polarization and Polynomial Gap to Capacity,"We prove that, for all binary-input symmetric memory less channels, polar codes enable reliable communication at rates within ε > 0 of the Shannon capacity with a block length, construction complexity, and decoding complexity all bounded by a polynomial in 1/ε. Polar coding gives the first known explicit construction with rigorous proofs of all these properties. We give an elementary proof of the capacity achieving property of polar codes that does not rely on the martingale convergence theorem. As a result, we are able to explicitly show that polar codes can have block length (and consequently also encoding and decoding complexity) that is bounded by a polynomial in the gap to capacity. The generator matrix of such polar codes can be constructed in polynomial time using merging of channel output symbols to reduce the alphabet size of the channels seen at the decoder.","Decoding,
Convergence,
Error probability,
Polynomials,
Complexity theory,
Entropy,
Encoding"
A Traffic Distribution Technique to Minimize Packet Delivery Delay in Multilayered Satellite Networks,"Multi-Layered Satellite Networks (MLSNs) have enormous potential to provide a ubiquitous wireless environment due to their advantages, such as extensive coverage, high network capacity, and lower delay performance. Since MLSNs are flexible and can be expanded easily to construct useful communication networks, researchers have paid a great deal of attention to find out how to use them efficiently. However, traffic congestion may occur in such networks since the distribution of MLSN users is heavily influenced by geographical restrictions, and they may often lead to severe communication delay and throughput degradation. Traditional research has proposed a counter-measure for avoiding traffic congestion caused by traffic flow on each layer. However, they do not consider congestion due to the inter-layer traffic that may, indeed, occur in MLSNs. Therefore, to effectively resolve the problem of traffic congestion, we propose a new MLSN model by envisioning a method to distribute the flow of packets between the two layers of the considered MLSNs for minimizing the packet delivery delay of the network. Moreover, we analyze the effect of the method on the packet delivery delay by considering propagation and queuing latencies. The analysis clearly shows the advantage of our proposed model. Furthermore, computer-based simulation results validate our analysis and demonstrate the effectiveness of our proposed model.",
"Material and Device Characteristics of Metamorphic
In
0.53
Ga
0.47
As
MOSHEMTs Grown on GaAs and Si Substrates by MOCVD","We report a comparison of material and device characteristics of metamorphic In0.53Ga0.47As channel metal-oxide-semiconductor high-electron mobility transistors (MOSHEMTs) grown on GaAs and Si substrates by metal-organic chemical vapor deposition. A gate-last process was developed to simplify the fabrication of nanoscale channel length devices. Selective source/drain regrowth was incorporated to reduce parasitic resistances. Post-metallization annealing (PMA) was utilized to mitigate the weakened gate electrostatic control in the buried channel. The effect of PMA on the Ti/Al2O3 gate-stack was investigated in detail. Record-low ON-state resistance of 132 and 129 Ω·μm has been achieved in enhancement-mode InGaAs MOSHEMT on GaAs and on Si substrate, respectively. A 120-nm channel length device on GaAs exhibited a figure of merit Q(gm/SS) of 12, whereas a 60-nm channel length In0.53Ga0.47As MOSHEMT on Si demonstrated Q up to 14.","Gallium arsenide,
Silicon,
Substrates,
Indium phosphide,
Logic gates,
Aluminum oxide,
Indium gallium arsenide"
A Fast and Accurate Feature-Matching Algorithm for Minimally-Invasive Endoscopic Images,"The ability to find image similarities between two distinct endoscopic views is known as feature matching, and is essential in many robotic-assisted minimally-invasive surgery (MIS) applications. Differently from feature-tracking methods, feature matching does not make any restrictive assumption about the chronological order between the two images or about the organ motion, but first obtains a set of appearance-based image matches, and subsequently removes possible outliers based on geometric constraints. As a consequence, feature-matching algorithms can be used to recover the position of any image feature after unexpected camera events, such as complete occlusions, sudden endoscopic-camera retraction, or strong illumination changes. We introduce the hierarchical multi-affine (HMA) algorithm, which improves over existing feature-matching methods because of the larger number of image correspondences, the increased speed, and the higher accuracy and robustness. We tested HMA over a large (and annotated) dataset with more than 100 MIS image pairs obtained from real interventions, and containing many of the aforementioned sudden events. In all of these cases, HMA outperforms the existing state-of-the-art methods in terms of speed, accuracy, and robustness. In addition, HMA and the image database are made freely available on the internet.","Feature extraction,
Robustness,
Accuracy,
Training,
Clustering algorithms,
Cameras,
Estimation"
Visual Analytics for Multimodal Social Network Analysis: A Design Study with Social Scientists,"Social network analysis (SNA) is becoming increasingly concerned not only with actors and their relations, but also with distinguishing between different types of such entities. For example, social scientists may want to investigate asymmetric relations in organizations with strict chains of command, or incorporate non-actors such as conferences and projects when analyzing coauthorship patterns. Multimodal social networks are those where actors and relations belong to different types, or modes, and multimodal social network analysis (mSNA) is accordingly SNA for such networks. In this paper, we present a design study that we conducted with several social scientist collaborators on how to support mSNA using visual analytics tools. Based on an openended, formative design process, we devised a visual representation called parallel node-link bands (PNLBs) that splits modes into separate bands and renders connections between adjacent ones, similar to the list view in Jigsaw. We then used the tool in a qualitative evaluation involving five social scientists whose feedback informed a second design phase that incorporated additional network metrics. Finally, we conducted a second qualitative evaluation with our social scientist collaborators that provided further insights on the utility of the PNLBs representation and the potential of visual analytics for mSNA.","Social network services,
Visual analytics,
Data visualization,
Complexity theory,
Design methodology,
User centered design"
HoWiES: A holistic approach to ZigBee assisted WiFi energy savings in mobile devices,"We propose HoWiES, a system that saves energy consumed by WiFi interfaces in mobile devices with the assistance of ZigBee radios. The core component of HoWiES is a WiFiZigBee message delivery scheme that enables WiFi radios to convey different messages to ZigBee radios in mobile devices. Based on the WiFi-ZigBee message delivery scheme, we design three protocols that target at three WiFi energy saving opportunities in scanning, standby and wakeup respectively. We have implemented the HoWiES system with two mobile devices platforms and two AP platforms. Our real-world experimental evaluation shows that our system can convey thousands of different messages from WiFi radios to ZigBee radios with an accuracy over 98%, and our energy saving protocols, while maintaining the comparable wakeup delay to that of the standard 802.11 power save mode, save 88% and 85% of energy consumed in scanning state and standby state respectively.","IEEE 802.11 Standards,
Zigbee,
Power demand,
Protocols,
Smart phones,
Decoding"
Ready-to-use activity recognition for smartphones,"In this study, every day activities are recognized from data collected using smartphones accelerometer sensors. Offline experiments are made to show that the presented method is user- and body position-independent. In addition, it is shown that the features used in the classification are not dependent on the calibration of the phone. The recognition models trained using the offline data are also tested online. A mobile application running these models is built for two operating systems: Symbian^3 and Android. Real-time experiments using these applications are made to show that the presented method can be implemented to any operating system and hardware variations do not affect recognition results. High recognition accuracies are obtained, in the offline study, the average recognition rate is almost 99% and, also, in the online study, the average recognition accuracy is over 90%.","Smart phones,
Hardware,
Calibration,
Feature extraction,
Accelerometers,
Operating systems,
Sensors"
Schottky-Contact Technology in InAlN/GaN HEMTs for Breakdown Voltage Improvement,"In this paper, we demonstrate a 253% improvement in the off-state breakdown voltage (BV) of the lattice-matched In0.17Al0.83 N/GaN high-electron-mobility transistors (HEMTs) by using a new Schottky-contact technology. Based on this concept, the Schottky-source/drain and Schottky-source (SS) InAlN/GaN HEMTs are proposed. The proposed InAlN/GaN HEMTs with an LGD of 15 μm showed a three-terminal BV of more than 600 V, while the conventional InAlN/GaN HEMTs of the same geometry showed a maximum BV of 184 V. Without using any field plate, the BV of 650 V was measured in the SS InAlN/GaN HEMTs with LGD = 15 μm, which is the highest BV ever achieved on InAlN/GaN HEMT. The corresponding specific on-resistance (Rsp, on) is as low as 3.4 mΩ·cm2. A BV of 118 V was also obtained in SS InAlN/GaN HEMTs with LGD = 1 μm, which is the highest BV in GaN-based HEMTs featuring such a short LGD with GaN buffer. The improvement of the BV relies on the effective suppression of source carrier injection into the GaN buffer under the SS due to the smooth metal morphology and elimination of metal spikes in the Schottky metallization.","HEMTs,
MODFETs,
Gallium nitride,
Ohmic contacts,
Schottky barriers,
Aluminum gallium nitride"
Low-Latency Polling Schemes for Long-Reach Passive Optical Networks,"The increased propagation delay of future long-reach passive optical networks (LR-PONs) may lead to a significantly increased idle time and delay if optical network units (ONUs) use conventional report-grant mechanisms. Sophisticated and efficient bandwidth allocation mechanisms are required to cope with the imposed propagation delay in LR-PONs. In this study, we evaluate three dynamic bandwidth allocation (DBA) frameworks in terms of frame (packet) delay; namely, we consider conventional (interleaved) polling for traditional PON and two recently introduced scheduling paradigms for next generation LR-PON, i.e., multi-thread polling (MT-P) and real-time polling (RT-P). We enhance MT-P and RT-P by applying the just-in-time framework. Next, we provide an analytical framework for evaluating the end-to-end frame delay in our enhanced MT-P and RT-P frameworks. We compare their performance with conventional polling and double-phase polling and investigate their shortcomings and advantages in an LR-PON setting. The simulation results closely match the analysis for this framework. Also, our results indicate that RT-P significantly reduces frame delay in LR-PONs compared to MT-P and conventional polling frameworks.","Optical network units,
Delays,
Logic gates,
Passive optical networks,
Real-time systems,
Message systems,
Propagation delay"
Assessment of Cardiac Motion Effects on the Fiber Architecture of the Human Heart In Vivo,"The use of diffusion tensor imaging (DTI) for studying the human heart in vivo is very challenging due to cardiac motion. This paper assesses the effects of cardiac motion on the human myocardial fiber architecture. To this end, a model for analyzing the effects of cardiac motion on signal intensity is presented. A Monte-Carlo simulation based on polarized light imaging data is then performed to calculate the diffusion signals obtained by the displacement of water molecules, which generate diffusion weighted (DW) images. Rician noise and in vivo motion data obtained from DENSE acquisition are added to the simulated cardiac DW images to produce motion-induced datasets. An algorithm based on principal components analysis filtering and temporal maximum intensity projection (PCATMIP) is used to compensate for motion-induced signal loss. Diffusion tensor parameters derived from motion-reduced DW images are compared to those derived from the original simulated DW images. Finally, to assess cardiac motion effects on in vivo fiber architecture, in vivo cardiac DTI data processed by PCATMIP are compared to those obtained from one trigger delay (TD) or one single phase acquisition. The results showed that cardiac motion produced overestimated fractional anisotropy and mean diffusivity as well as a narrower range of fiber angles. The combined use of shifted TD acquisitions and postprocessing based on image registration and PCATMIP effectively improved the quality of in vivo DW images and subsequently, the measurement accuracy of fiber architecture properties. This suggests new solutions to the problems associated with obtaining in vivo human myocardial fiber architecture properties in clinical conditions.","Diffusion tensor imaging,
In vivo,
Heart,
Tensile stress,
Silicon,
Myocardium"
A variational approach to JPEG anti-forensics,"The objective of JPEG anti-forensics is to remove all the possible footprints left by JPEG compression. By contrary, there exist detectors that attempt to identify any telltale of the image tampering operation of JPEG compression and JPEG anti-forensic processing. This paper makes contribution on improving the undetectability of JPEG anti-forensics, with a higher visual quality of processed images. The employment of constrained total variation based minimization for deblocking successfully fools the forensic methods detecting JPEG blocking, and another advanced JPEG forensic detector. Calibration-based detector is also defeated by conducting a further feature value optimization. Experimental results show that the proposed method outperforms the state-of-the-art methods in a better trade-off between forensic undetectability and visual quality of processed images.","Transform coding,
Detectors,
Image coding,
Discrete cosine transforms,
Forensics,
Quantization (signal),
Visualization"
Pics-on-wheels: Photo surveillance in the vehicular cloud,"Cloud computing allows user to access remote hardware, data and software through the network. However, many of these resources today are found on mobiles. For example, modern vehicles provide powerful platforms for computation, data delivery, storage, and sensing. This paper introduces the notion of Mobile Cloud computing to tap mobile resources. As an example, we describe the Pies-on-Wheels service, a Vehicular Cloud service that delivers images on demand to citizens by using vehicles' on board cameras. A server (eg taxi dispatcher or Navigator Server) accepts requests from members and assigns the photo clicking task to vehicles close to the target. The feasibility of the Pies-on-Wheels service is demonstrated in a San Francisco scenario using published taxicab routes.","Vehicles,
Servers,
Cloud computing,
Navigation,
Mobile communication,
Accidents,
Forensics"
Load balance vs energy efficiency in traffic engineering: A game Theoretical Perspective,"In this paper, we study the tradeoff between two important traffic engineering objectives: load balance and energy efficiency. Although traditional commonly used multi-objective optimization methods can yield a Pareto efficient solution, they need to construct an aggregate objective function (AOF) or model one of the two objectives as a constraint in the optimization problem formulation. As a result, it is difficult to achieve a fair tradeoff between these two objectives. Accordingly, we induce a Nash bargaining framework which treats the two objectives as two virtual players in a game theoretic model, who negotiate how traffic should be routed in order to optimize both objectives. During the negotiation, each of them announces its performance threat value to reduce its cost, so the model is regarded as a threat value game. Our analysis shows that no agreement can be achieved if each player sets its threat value selfishly. To avoid such a negotiation break-down, we modify the threat value game to have a repeated process and design a mechanism to not only guarantee an agreement, but also generate a fair solution. In addition, the insights from this work are also useful for achieving a fair tradeoff in other multi-objective optimization problems.",
Generation of Synthetic but Visually Realistic Time Series of Cardiac Images Combining a Biophysical Model and Clinical Images,"We propose a new approach for the generation of synthetic but visually realistic time series of cardiac images based on an electromechanical model of the heart and real clinical 4-D image sequences. This is achieved by combining three steps. The first step is the simulation of a cardiac motion using an electromechanical model of the heart and the segmentation of the end diastolic image of a cardiac sequence. We use biophysical parameters related to the desired condition of the simulated subject. The second step extracts the cardiac motion from the real sequence using nonrigid image registration. Finally, a synthetic time series of cardiac images corresponding to the simulated motion is generated in the third step by combining the motion estimated by image registration and the simulated one. With this approach, image processing algorithms can be evaluated as we know the ground-truth motion underlying the image sequence. Moreover, databases of visually realistic images of controls and patients can be generated for which the underlying cardiac motion and some biophysical parameters are known. Such databases can open new avenues for machine learning approaches.","Myocardium,
Biological system modeling,
Image sequences,
Heart,
Magnetic resonance imaging,
Computational modeling,
Biomedical imaging"
Widely Tunable Single Longitudinal Mode Fiber Laser With Cascaded Fiber-Ring Secondary Cavity,"A widely tunable single longitudinal mode (SLM) fiber laser with cascaded Type I and Type II fiber ring secondary cavities, which uses a tunable fiber Bragg grating (FBG) as the mode-restricting and wavelength-tuning element, is proposed and demonstrated. Since the cascaded fiber rings can effectively expand the pass-band spacing to make the mode selection with the FBG easier, the stability of SLM oscillation can be improved by suitably optimizing the coupling ratio of optical couplers in Type II fiber ring to ensure that at least one and only one longitudinal mode dominates in the selected pass-band. When the fiber ring lengths are designed to make their expanded pass-band spacing be a value from 0.5 to 1 times of the 3-dB bandwidth of the FBG, the mode competitions between both neighboring pass-bands and main cavity modes, may be effectively eliminated, making the laser maintain mode-hop-free SLM oscillations while it is widely tuned.","Cavity resonators,
Bandwidth,
Laser modes,
Ring lasers,
Tuning,
Oscillators,
Bragg gratings"
CloudMoV: Cloud-Based Mobile Social TV,"The rapidly increasing power of personal mobile devices (smartphones, tablets, etc.) is providing much richer contents and social interactions to users on the move. This trend however is throttled by the limited battery lifetime of mobile devices and unstable wireless connectivity, making the highest possible quality of service experienced by mobile users not feasible. The recent cloud computing technology, with its rich resources to compensate for the limitations of mobile devices and connections, can potentially provide an ideal platform to support the desired mobile services. Tough challenges arise on how to effectively exploit cloud resources to facilitate mobile services, especially those with stringent interaction delay requirements. In this paper, we propose the design of a Cloud-based, novel Mobile sOcial tV system (CloudMoV). The system effectively utilizes both PaaS (Platform-as-a-Service) and IaaS (Infrastructure-as-a-Service) cloud services to offer the living-room experience of video watching to a group of disparate mobile users who can interact socially while sharing the video. To guarantee good streaming quality as experienced by the mobile users with time-varying wireless connectivity, we employ a surrogate for each user in the IaaS cloud for video downloading and social exchanges on behalf of the user. The surrogate performs efficient stream transcoding that matches the current connectivity quality of the mobile user. Given the battery life as a key performance bottleneck, we advocate the use of burst transmission from the surrogates to the mobile users, and carefully decide the burst size which can lead to high energy efficiency and streaming quality. Social interactions among the users, in terms of spontaneous textual exchanges, are effectively achieved by efficient designs of data storage with BigTable and dynamic handling of large volumes of concurrent messages in a typical PaaS cloud. These various designs for flexible transcoding capabilities, battery efficiency of mobile devices and spontaneous social interactivity together provide an ideal platform for mobile social TV services. We have implemented CloudMoV on Amazon EC2 and Google App Engine and verified its superior performance based on real-world experiments.","Mobile communication,
Streaming media,
TV,
Cloud computing,
Batteries,
Smart phones"
On hypercontractivity and the mutual information between Boolean functions,"Hypercontractivity has had many successful applications in mathematics, physics, and theoretical computer science. In this work we use recently established properties of the hypercontractivity ribbon of a pair of random variables to study a recent conjecture regarding the mutual information between binary functions of the individual marginal sequences of a sequence of pairs of random variables drawn from a doubly symmetric binary source.","Random variables,
Joints,
Mutual information,
Boolean functions,
Educational institutions,
Markov processes,
Data processing"
"Design, fabrication and characterization of a high-bandwidth 2DOF MEMS nanopositioner","There is a need for 2 DOF scanners in a variety of applications in nanotechnology, particularly in the Atomic Force Microscope (AFM). An ideal AFM stage should have a high resonance frequency, low cross coupling between the two perpendicular axes of motion and be capable of moving over a large range in either direction. To achieve these specifications, which are crucial in obtaining high quality images at high scan speeds, various designs have been proposed in the literature. The use of Microelectromechanical Systems (MEMS) technology and silicon as the structural material has resulted in the achievement of higher resonance frequencies in nanopositioning stages compared to many other conventional technologies. In this paper we report the design of a 2 DOF MEMS stage, fabricated using a Silicon on Insulator process. The scan table has dimensions of 1.6mm×1.6mm. To move the stage in two orthogonal directions, a parallel kinematic mechanism utilizing electrostatic comb actuators is used. Electrothermal sensors are incorporated to detect displacements of the stage in these directions. Characterization of the device reveals a displacement range of ±6μm and a first resonance frequency of approximately 5200 Hz in the X and Y directions.","Micromechanical devices,
Nanopositioning,
Silicon,
Insulators,
Fingers,
Substrates"
Ranking on Data Manifold with Sink Points,"Ranking is an important problem in various applications, such as Information Retrieval (IR), natural language processing, computational biology, and social sciences. Many ranking approaches have been proposed to rank objects according to their degrees of relevance or importance. Beyond these two goals, diversity has also been recognized as a crucial criterion in ranking. Top ranked results are expected to convey as little redundant information as possible, and cover as many aspects as possible. However, existing ranking approaches either take no account of diversity, or handle it separately with some heuristics. In this paper, we introduce a novel approach, Manifold Ranking with Sink Points (MRSPs), to address diversity as well as relevance and importance in ranking. Specifically, our approach uses a manifold ranking process over the data manifold, which can naturally find the most relevant and important data objects. Meanwhile, by turning ranked objects into sink points on data manifold, we can effectively prevent redundant objects from receiving a high rank. MRSP not only shows a nice convergence property, but also has an interesting and satisfying optimization explanation. We applied MRSP on two application tasks, update summarization and query recommendation, where diversity is of great concern in ranking. Experimental results on both tasks present a strong empirical performance of MRSP as compared to existing ranking approaches.","Ranking systems,
Diversity reception,
Convergence,
Query processing,
Eigenvalues and eigenfunctions,
Redundancy,
Algorithm design and analysis"
When 3G Meets VANET: 3G-Assisted Data Delivery in VANETs,"In this paper, we consider a sensory data gathering application of a vehicular ad hoc network (VANET) in which vehicles produce sensory data, which should be gathered for data analysis and making decisions. Data delivery is particularly challenging because of the unique characteristics of VANETs, such as fast topology change, frequent disruptions, and rare contact opportunities. Through empirical study based on real vehicular traces, we find an important observation that a noticeable percentage of data packets cannot be delivered within time-to-live. In this paper, we explore the problem of 3G-assisted data delivery in a VANET with a budget constraint of 3G traffic. A packet can either be delivered via multihop transmissions in the VANET or via 3G. The main challenge for solving the problem is twofold. On the one hand, there is an intrinsic tradeoff between delivery ratio and delivery delay when using the 3G. On the other hand, it is difficult to decide which set of packets should be selected for 3G transmissions and when to deliver them via 3G. In this paper, we propose an approach called 3GDD for 3G-assisted data delivery in a VANET. We construct a utility function to explore the tradeoff between delivery ratio and delivery delay, which provides a unified framework to reflect the two factors. We formulate the 3G-assisted data delivery as an optimization problem in which the objective is to maximize the overall utility under the 3G budget constraint. To circumvent the high complexity of this optimization problem, we further transition the original optimization problem as an integer linear programming problem (ILP). Solving this ILP, we derive the 3G allocation over different time stages. Given the 3G budget at each time stage, those packets that are most unlikely delivered via the VANET are selected for 3G transmissions. We comprehensively evaluate our 3GDD using both synthetic vehicular traces and real vehicular 3G traces. Evaluation results show that our approach outperforms other schemes under a wide range of utility function deflations and network configurations.","vehicular ad hoc networks,
3G mobile communication,
integer programming,
linear programming"
Partial-Duplicate Image Retrieval via Saliency-Guided Visual Matching,"This article proposes a novel partial-duplicate image-retrieval scheme based on saliency-guided visual matching, where the localization of duplicates is done simultaneously. The image is abstracted by visually salient and rich regions (VSRRs), which are of visual saliency and contain rich visual content. Furthermore, to refine the retrieval, a relative saliency ordering constraint is constructed that captures the robust relative saliency layout of the VSRRs. The authors propose an efficient algorithm to embed this constraint into the index system so as to speed up retrieval. Comparison experiments with state-of-the-art methods on five databases show the efficiency and effectiveness of the proposed approach.","Multimedia communication,
Image representation,
Information retrieval,
Information analysis,
Media"
Annealing Effects of Ti/Au Contact on n-MgZnO/p-Si Ultraviolet-B Photodetectors,"Effects of postannealing on Ti/Au-MgZnO contact and n-MgZnO/p-Si heterojunction ultraviolet-B photodetector's performance are investigated. It is found that the out diffusion of oxygen from MgZnO and its bonding with Ti at the interface have significant influences on the properties of Ti/MgZnO interface and photodetector. The persistent photocurrent observed in the annealed device is attributed to the oxygen vacancies near the interface, consistent with the theoretical calculations. It is revealed that the reaction at metal/MgZnO interface possibly plays a key role and even dominates the MgZnO p-n heterojunction ultraviolet detectors' performances.","Annealing,
Detectors,
Zinc oxide,
Gold,
Photoconductivity,
Photodetectors,
Electrodes"
Interactive Segmentation for Change Detection in Multispectral Remote-Sensing Images,"In this letter, we propose to solve the change detection (CD) problem in multitemporal remote-sensing images using interactive segmentation methods. The user needs to input markers related to change and no-change classes in the difference image. Then, the pixels under these markers are used by the support vector machine classifier to generate a spectral-change map. To enhance further the result, we include the spatial contextual information in the decision process using two different solutions based on Markov random field and level-set methods. While the former is a region-driven method, the latter exploits both region and contour for performing the segmentation task. Experiments conducted on a set of four real remote-sensing images acquired by low as well as very high spatial resolution sensors and referring to different kinds of changes confirm the attractive capabilities of the proposed methods in generating accurate CD maps with simple and minimal interaction.","Support vector machines,
Remote sensing,
Image segmentation,
Spatial resolution,
Training,
Sensors"
A Genetic Fuzzy Linguistic Combination Method for Fuzzy Rule-Based Multiclassifiers,"Fuzzy set theory has been widely and successfully used as a mathematical tool to combine the outputs provided by the individual classifiers in a multiclassification system by means of a fuzzy aggregation operator. However, to the best of our knowledge, no fuzzy combination method has been proposed, which is composed of a fuzzy rule-based system. We think this can be a very promising research line as it allows us to benefit from the key advantage of fuzzy systems, i.e., their interpretability. By using a fuzzy linguistic rule-based classification system as a combination method, the resulting classifier ensemble would show a hierarchical structure, and the operation of the latter component would be transparent to the user. Moreover, for the specific case of fuzzy multiclassification systems, the new approach could also become a smart way to allow standard fuzzy classifiers to deal with high-dimensional problems, avoiding the curse of dimensionality, as the chance to perform classifier selection at class level is also incorporated, into the method. We conduct comprehensive experiments considering 20 UCI datasets with different dimensionality, where our approach improves or at least maintains accuracy, while reducing complexity of the system, and provides some interpretability insight into the multiclassification system reasoning mechanism. The results obtained show that this approach is able to compete with the state-of-the-art multiclassification system selection and fusion methods in terms of accuracy, thus providing a good interpretability-accuracy tradeoff.",
MOMBI: A new metaheuristic for many-objective optimization based on the R2 indicator,"The incorporation of performance indicators as the selection mechanism of a multi-objective evolutionary algorithm (MOEA) is a topic that has attracted increasing interest in the last few years. This has been mainly motivated by the fact that Pareto-based selection schemes do not perform properly when solving problems with four or more objectives. The indicator that has been most commonly used for being incorporated in the selection mechanism of a MOEA has been the hypervolume. Here, however, we explore the use of the R2 indicator, which presents some advantages with respect to the hypervolume, the main one being its low computational cost. In this paper, we propose a new MOEA called Many-Objective Metaheuristic Based on the R2 Indicator (MOMBI), which ranks individuals using a utility function. The proposed approach is compared with respect to MOEA/D (based on scalarization) and SMS-EMOA (based on hypervolume) using several benchmark problems. Our preliminary experimental results indicate that MOMBI obtains results of similar quality to those produced by SMS-EMOA, but at a much lower computational cost. Additionally, MOMBI outperforms MOEA/D in most of the test instances adopted, particularly when dealing with high-dimensional problems having complicated Pareto fronts. Thus, we believe that our proposed approach is a viable alternative for solving many-objective optimization problems.","Sociology,
Vectors,
Linear programming,
Pareto optimization,
Approximation methods"
Blind Modulation Classification over Fading Channels Using Expectation-Maximization,"We propose a blind modulation classification algorithm when the channel coefficient, the noise power and the energy of the transmitted signal are unknown at the receiver. First, under each candidate modulation scheme, we evaluate the unknown parameters using the iterative expectation maximization algorithm. Modulation classification is then accomplished by minimizing the distance between the log-likelihood of the received data and the expected log-likelihood under each candidate modulation scheme. Results are presented from simulations in terms of detection probability vs. SNR for the class of BPSK, QPSK, 16QAM and 64QAM modulation schemes. The results show a significant improvement over QHLRT and are very close to the upper bound ALRT-UB [1].","Signal to noise ratio,
Fading,
Binary phase shift keying,
Parameter estimation"
"Error Probability Analysis of Interleaved SC-FDMA Systems Over Nakagami-
m
Frequency-Selective Fading Channels","In this paper, we present an analytical study of the average bit error probability (ABEP) for interleaved single-carrier frequency-division multiple-access (SC-FDMA) systems over independent but not necessarily identically distributed Nakagami-m fading channels with fading parameters {m} being integers when either zero-forcing (ZF) or minimum-mean-square-error (MMSE) frequency-domain equalization (FDE) is applied. Under the assumption of independence among channel frequency responses (CFRs) at the allocated subcarriers for a specific user, accurate and closed-form numerical ABEP computations of the generalized hierarchical M -ary pulse amplitude and square/rectangular M-ary quadrature amplitude modulations for both ZF-FDE and MMSE-FDE are developed by exploiting the derived statistics of the equalized noise, including the probability density function and cumulative distribution function. More importantly, the ABEP derivation is based on the real distribution of the CFRs without applying the widely used Nakagami-m approximation of the CFRs in previous literature, resulting in a more accurate ABEP analysis.",
TDoA for Passive Localization: Underwater versus Terrestrial Environment,"The measurement of an emitter's position using electronic support passive sensors is termed passive localization and plays an important part both in electronic support and electronic attack. The emitting target could be in terrestrial or underwater environment. In this paper, we propose a time difference of arrival (TDoA) algorithm for passive localization in underwater and terrestrial environment. In terrestrial environment, it is assumed that a Rician flat fading model should be used because there exists line of sight. In underwater environment, we apply a modified UWB Saleh-Valenzuela (S-V) model to characterize the underwater acoustic fading channel. We propose the TDoA finding algorithm via estimating the delay of two correlated channels, and compare it with the existing approach. Simulations were conducted for terrestrial and underwater environment, and simulation results show that our TDoA algorithm performs much better than the cross-correlation-based TDoA algorithm with a lower level of magnitude in terms of average TDoA error and root-mean-square error (RMSE). Compared to the TDoA performance in terrestrial environment, the TDoA performance in underwater environment is much worse. This is because the underwater channel has clusters and rays, which introduces memory and uncertainties. For the two scenarios in underwater environment, the performance in rich scattering underwater environment is worse than that in less scattering underwater environment, because the latter has less clusters and rays, which would cause less uncertainties in TDoA.","Rician channels,
Channel estimation,
Fading,
Delay,
Wireless communication,
Underwater acoustics,
Receivers"
Estimation of Soft Tissue Mechanical Parameters From Robotic Manipulation Data,"Robotic motion planning algorithms used for task automation in robotic surgical systems rely on the availability of accurate models of target soft tissue's deformation. Relying on generic tissue parameters in constructing the tissue deformation models is problematic because biological tissues are known to have very large (inter- and intrasubject) variability. A priori mechanical characterization (e.g., uniaxial bench test) of the target tissues before a surgical procedure is also not usually practical. In this paper, a method for estimating mechanical parameters of soft tissue from sensory data collected during robotic surgical manipulation is presented. The method uses force data collected from a multiaxial force sensor mounted on the robotic manipulator, and tissue deformation data collected from a stereo camera system. The tissue parameters are then estimated using an inverse finite element method. The effects of measurement and modeling uncertainties on the proposed method are analyzed in simulation. The results of experimental evaluation of the method are also presented.","Deformable models,
Biological tissues,
Robot sensing systems,
Materials,
Parameter estimation,
Estimation"
Hardware Trojans in wireless cryptographic ICs: Silicon demonstration & detection method evaluation,"We present a silicon implementation of a hardware Trojan, which is capable of leaking the secret key of a wireless cryptographic integrated circuit (IC) consisting of an Advanced Encryption Standard (AES) core and an Ultra-Wide-Band (UWB) transmitter. With its impact carefully hidden in the transmission specification margins allowed for process variations, this hardware Trojan cannot be detected by production testing methods of either the digital or the analog part of the IC and does not violate the transmission protocol or any system-level specifications. Nevertheless, the informed adversary, who knows what to look for in the transmission power waveform, is capable of retrieving the 128-bit AES key, which is leaked with every 128-bit ciphertext block sent by the UWB transmitter. Using silicon measurements from 40 chips fabricated in TSMC's 0.35μm technology, we also assess the effectiveness of a side channel-based statistical analysis method in detecting this hardware Trojan.","Hardware,
Trojan horses,
Integrated circuits,
Wireless communication,
Cryptography,
Transmitters,
Radio frequency"
Windowed Decoding of Spatially Coupled Codes,"Spatially coupled codes have been of interest recently owing to their superior performance over memoryless binary-input channels. The performance is good both asymptotically, since the belief propagation thresholds approach the Shannon limit, as well as for finite lengths, since degree-2 variable nodes that result in high error floors can be completely avoided. However, to realize the promised good performance, one needs large blocklengths. This in turn implies a large latency and decoding complexity. For the memoryless binary erasure channel, we consider the decoding of spatially coupled codes through a windowed decoder that aims to retain many of the attractive features of belief propagation, while trying to reduce complexity further. We characterize the performance of this scheme by defining thresholds on channel erasure rates that guarantee a target erasure rate. We give analytical lower bounds on these thresholds and show that the performance approaches that of belief propagation exponentially fast in the window size. We give numerical results including the thresholds computed using density evolution and the erasure rate curves for finite-length spatially coupled codes.","Decoding,
Complexity theory,
Equations,
Couplings,
Iterative decoding,
Vectors"
Bayesian Wavelet Shrinkage With Heterogeneity-Adaptive Threshold for SAR Image Despeckling Based on Generalized Gamma Distribution,"Synthetic aperture radar (SAR) images are inherently affected by multiplicative speckle noise, which will degrade the human interpretation and computer-aided scene analysis. In this paper, we propose a novel Bayesian multiscale method for SAR image despeckling in the non-homomorphic framework. To address the multiplicative nature, we first make the speckle contribution additive by a linear decomposition. Then, in the stationary wavelet transform domain, a two-sided generalized Gamma distribution (GTD) is introduced as a prior to capture the heavy-tailed nature of wavelet coefficients of the noise-free reflectivity. By exploiting this prior together with a Gaussian likelihood, an analytical wavelet shrinkage function is derived based on maximum a posteriori criteria, which further adopts heterogeneity-adaptive thresholding technique to achieve better estimates of noise-free wavelet coefficients. Moreover, a pilot-signal-assisted strategy is proposed to estimate the parameters of two-sided GTD with the estimator based on second-kind cumulants. Finally, experimental results, carried out on the synthetic and actual SAR images, are given to demonstrate the validity of the proposed despeckling method.","Speckle,
Synthetic aperture radar,
Wavelet transforms,
Bayesian methods,
Noise,
Additives,
Wavelet analysis"
Analysing the performance of dynamic multi-objective optimisation algorithms,"Dynamic multi-objective optimisation problems (DMOOPs) have more than one objective, with at least one objective changing over time. Since at least two of the objectives are normally in conflict with one another, a single solution does not exist and the goal of the algorithm is to track a set of tradeoff solutions over time. Analysing the performance of a dynamic multi-objective optimisation algorithm (DMOA) is not a trivial task. For each environment (before a change occurs) the DMOA has to find a set of solutions that are both diverse and as close as possible to the optimal trade-off solution set. In addition, the DMOA has to track the changing set of trade-off solutions over time. Approaches used to analyse the performance of dynamic single-objective optimisation algorithms (DSOAs) and DMOAs do not provide any information about the ability of the algorithms to track the changing optimum. Therefore, this paper introduces a new approach to analyse the performance of DMOAs and applies this approach to the results obtained by five DMOAs. In addition, it compares the new analysis approach to another approach that does not take the tracking ability of the DMOAs into account. The results indicate that the new analysis approach provide additional information, measuring the ability of the algorithm to find good performance measure values while tracking the changing optima.","Heuristic algorithms,
Loss measurement,
Algorithm design and analysis,
Vectors,
Time measurement,
Optimization,
Optical fibers"
Induction of Shadowed Sets Based on the Gradual Grade of Fuzziness,"The existing methods of determining an α-cut of a fuzzy set to construct its underlying shadowed set do not fully comply with the concept of shadowed sets, namely, a retention of the total amount of fuzziness and its localized redistribution throughout a universe of discourse. Moreover, no closed formula to calculate the corresponding α-cut is available. This paper proposes analytical formulas to calculate threshold values required in the construction of shadowed sets. We introduce a new algorithm to design a shadowed set from a given fuzzy set. The proposed algorithm, which adheres to the main premise of shadowed sets of capturing the essence of fuzzy sets, helps localize fuzziness present in a given fuzzy set. We represent the fuzziness of a fuzzy set as a gradual number. Through defuzzification of the gradual number of fuzziness, we determine the required threshold (i.e., some α-cut) used in the formation of the shadowed set. We show that the shadowed set obtained in this way comes with a measure of fuzziness that is equal to the one characterizing the original fuzzy set.",
Towards a scalable HDFS architecture,"Cloud computing infrastructures allow corporations to reduce costs by outsourcing computations on-demand. One of the areas cloud computing is increasingly being utilized for is large scale data processing. Apache Hadoop is one of these large scale data processing projects that supports data-intensive distributed applications. Hadoop applications utilize a distributed file system for data storage called Hadoop Distributed File System (HDFS). HDFS architecture, by design, has only a single master node called ame ode, which manages and maintains the metadata of storage nodes, called Datanodes, in its RAM. Hence, HDFS Datanodes' metadata is restricted by the capacity of the RAM of the HDFS's single-point-of-failure ame ode. This paper proposes a fault tolerant, highly available and widely scalable HDFS architecture. The proposed architecture provides a distributed ame ode space eliminating the drawbacks of the current HDFS architecture. This is achieved by integrating the Chord protocol into the HDFS architecture.",
On the Performance of Hybrid-ARQ with Incremental Redundancy and with Code Combining over Relay Channels,"In this paper, we consider a relay network consisting of a source, a relay, and a destination. The source transmits a message to the destination using hybrid automatic repeat request (HARQ). The relay overhears the transmitted messages over the different HARQ rounds and tries to decode the data packet. In case of successful decoding at the relay, both the relay and the source cooperate to transmit the message to the destination. The channel realizations are independent for different HARQ rounds. We assume that the transmitter has no channel state information (CSI). Under such conditions, power and rate adaptation are not possible. To overcome this problem, HARQ allows the implicit adaptation of the transmission rate to the channel conditions by the use of feedback. There are two major HARQ techniques, namely HARQ with incremental redundancy (IR) and HARQ with code combining (CC). We investigate the performance of HARQ-IR and HARQ-CC over a relay channel from an information theoretic perspective. Analytical expressions are derived for the information outage probability, the average number of transmissions, and the average transmission rate. We illustrate through our investigation the benefit of relaying. We also compare the performance of HARQ-IR and HARQ-CC and show that HARQ-IR outperforms HARQ-CC.","wireless channels,
automatic repeat request,
decoding,
diversity reception,
feedback,
probability,
radio transmitters,
relay networks (telecommunication),
telecommunication network reliability"
Handwritten Chinese/Japanese Text Recognition Using Semi-Markov Conditional Random Fields,"This paper proposes a method for handwritten Chinese/Japanese text (character string) recognition based on semi-Markov conditional random fields (semi-CRFs). The high-order semi-CRF model is defined on a lattice containing all possible segmentation-recognition hypotheses of a string to elegantly fuse the scores of candidate character recognition and the compatibilities of geometric and linguistic contexts by representing them in the feature functions. Based on given models of character recognition and compatibilities, the fusion parameters are optimized by minimizing the negative log-likelihood loss with a margin term on a training string sample set. A forward-backward lattice pruning algorithm is proposed to reduce the computation in training when trigram language models are used, and beam search techniques are investigated to accelerate the decoding speed. We evaluate the performance of the proposed method on unconstrained online handwritten text lines of three databases. On the test sets of databases CASIA-OLHWDB (Chinese) and TUAT Kondate (Japanese), the character level correct rates are 95.20 and 95.44 percent, and the accurate rates are 94.54 and 94.55 percent, respectively. On the test set (online handwritten texts) of ICDAR 2011 Chinese handwriting recognition competition, the proposed method outperforms the best system in competition.",
Feasibility of a Millimeter-Wave MIMO System for Short-Range Wireless Communications in an Underground Gold Mine,"The performance of multiple-input-multiple-output (MIMO) system operating at the 60 GHz band is investigated based on experimental data in a real underground mine gallery. However, the millimeter wave (mmW) channels face some challenges such as high propagation loss. In order to overcome this issue, a planar microstrip antenna array has been designed, and fabricated. Moreover, the effect of miners' activity in the vicinity of the short-range wireless link is studied. Statistical parameters of the propagation channel, such as RMS delay spread, path loss, K-factor, channel correlation and capacity are extracted and analyzed. Results suggest that miners presence substantially affects both received power and time dispersion parameters and should therefore be considered when developing underground mine wireless networks in the unlicensed 60-GHz band.",
Road Geometry Classification by Adaptive Shape Models,"Vision-based road detection is important for different applications in transportation, such as autonomous driving, vehicle collision warning, and pedestrian crossing detection. Common approaches to road detection are based on low-level road appearance (e.g., color or texture) and neglect of the scene geometry and context. Hence, using only low-level features makes these algorithms highly depend on structured roads, road homogeneity, and lighting conditions. Therefore, the aim of this paper is to classify road geometries for road detection through the analysis of scene composition and temporal coherence. Road geometry classification is proposed by building corresponding models from training images containing prototypical road geometries. We propose adaptive shape models where spatial pyramids are steered by the inherent spatial structure of road images. To reduce the influence of lighting variations, invariant features are used. Large-scale experiments show that the proposed road geometry classifier yields a high recognition rate of 73.57% ± 13.1, clearly outperforming other state-of-the-art methods. Including road shape information improves road detection results over existing appearance-based methods. Finally, it is shown that invariant features and temporal information provide robustness against disturbing imaging conditions.","Roads,
Geometry,
Shape,
Adaptation models,
Hidden Markov models,
Lighting,
Training"
Kinetics and Design of a Mechanically Dithered Ring Laser Gyroscope Position and Orientation System,"The motion compensation based on ring laser gyroscope (RLG) position and orientation system (POS) is a key technology to improve the imaging quality and efficiency of airborne Earth observation system. However, RLG POS faces great problems in the vibration environment, where the mechanical dither of RLG causes the adverse disturbance to inertial measurement unit (IMU) which should be eliminated, and the external vibration must be accurately measured with high bandwidth and low noise. To solve the problem, a kinetics model of RLG IMU is established based on a vibration response mechanism in this paper. An optimized design method of mechanically dithered RLG IMU with a vibration-damping system is proposed that can reduce the measurement error. In addition, the size-effect error and optimization method of RLG IMU are analyzed. Based on finite-element analysis software, a high-precision mechanically dithered RLG POS is designed and developed to be used in various imaging payloads. The experimental results show that the inertial navigation errors of RLG POS are 0.196 (σ), 0.659 (σ), and 0.707 kn (σ) for static, vehicle, and airborne experiments, respectively. It contributes to realize high-quality image of airborne interferential synthetic aperture radar and 1 : 500 scale map of camera without ground control marks. The precision of developed RLG POS is close to that of the most advanced production POS/AV610.","Kinetic theory,
Gyroscopes,
Vibrations,
Acceleration,
Payloads,
Torque,
Damping"
Hardware implementation and control design of generator emulator in multi-converter system,"In this project to develop a reconfigurable electrical grid emulator, a Hardware Test-Bed (HTB) is being developed that emulates large scale power system generators and loads by using power electronic converters. Source converters in the HTB system are designed to emulate generators. A synchronous generator model is implemented in the converter to calculate the voltage references in the dq axis, and a voltage controller is added to achieve zero steady state error. A traditional cascade controller with inner current control and outer voltage control brings additional output impedance to the generator model, and causes voltage tracking error during transients. To minimize the controller output impedance and eliminate controller influence on the generator model, a single voltage loop with current differential feedback is proposed in this paper. Combined with rescaled generator parameters, circulating current elimination, and dead time compensation, simulation and experiments are performed in the HTB. The results verify the effectiveness of the controller and demonstrate the dynamic generator emulator behavior.",
Learning Semantic Signatures for 3D Object Retrieval,"In this paper, we propose two kinds of semantic signatures for 3D object retrieval (3DOR). Humans are capable of describing an object using attribute terms like “symmetric” and “flyable”, or using its similarities to some known object classes. We convert such qualitative descriptions into attribute signature (AS) and reference set signature (RSS), respectively, and use them for 3DOR. We also show that AS and RSS can be understood as two different quantization methods of the same semantic space of human descriptions of objects. The advantages of the semantic signatures are threefold. First, they are much more compact than low-level shape features yet working with comparable retrieval accuracy. Therefore, the proposed semantic signatures require less storage space and computation cost in retrieval. Second, the high-level signatures are a good complement to low-level shape features. As a result, by incorporating the signatures we can improve the performance of state-of-the-art 3DOR methods by a large margin. To the best of our knowledge, we obtain the best results on two popular benchmarks. Third, the AS enables us to build a user-friendly interface, with which the user can trigger a search by simply clicking attribute bars instead of finding a 3D object as the query. This interface is of great significance in 3DOR considering the fact that while searching, the user usually does not have a 3D query at hand that is similar to his/her targeted objects in the database.","Shape,
Semantics,
Humans,
Databases,
Detectors,
Search problems,
Educational institutions"
Interfacing Issues in Multiagent Simulation for Smart Grid Applications,"This paper discusses design and application of the multiagent simulation technology aiming to meet smart grid requirements. The difference between multiagent systems and multiagent simulation in smart grid applications is clarified. The state-of-the-art applications of multiagent simulation in power and energy systems are classified based on the simulation environment. The paper also addresses the interface issues including synchronization and data distribution for multiagent co-simulation. In addition, the emerging research paradigms in smart grid multiagent simulation are identified.",
SPaC: A segment-based parallel compression for backup acceleration in nonvolatile processors,"Nonvolatile processor (NVP) has become an emerging topic in recent years. The conventional NV processor equips each flip-flop with a nonvolatile storage for data backup, which results in much faster backup speed with significant area overheads. A compression based architecture (PRLC) solved the area problem but with a nontrivial increasing on backup time. This paper provides a segment-based parallel compression (SPaC) architecture to achieve tradeoffs between area and backup speed. Furthermore, we use an off-line and online hybrid method to balance the workloads of different compression modules in SPaC. Experimental results show that SPaC can achieve 76% speed up against PRLC and meanwhile reduces the area by 16% against conventional NV processors.",
A Cognitive Platform for Mobile Cloud Gaming,"Mobile cloud gaming provides a whole new service model for the video game industry to overcome the intrinsic restrictions of mobile devices and piracy issues. However, the diversity of end-user devices and frequent changes in network quality of service and cloud responses result in unstable Quality of Experience (QoE) for game players. A cognitive cloud gaming platform, which could overcome the above problem by learning about the game player's environment and adapting the cloud gaming service accordingly, does not currently exist. To fill this void, we design and implement a component-based gaming platform that supports click-and-play, intelligent resource allocation and partial offline execution, to provide cognitive capabilities across the cloud gaming system. Extensive experiments have been performed to show that intelligent partitioning leads to better system performance, such as overall latency.","Games,
Mobile communication,
Mobile handsets,
Streaming media,
Servers,
Cloud computing,
Browsers"
A real-time scheduling service for parallel tasks,"The multi-core revolution presents both opportunities and challenges for real-time systems. Parallel computing can yield significant speedup for individual tasks (enabling shorter deadlines, or more computation within the same deadline), but unless managed carefully may add complexity and overhead that could potentially wreck real-time performance. There is little experience to date with the design and implementation of realtime systems that allow parallel tasks, yet the state of the art cannot progress without the construction of such systems. In this work we describe the design and implementation of a scheduler and runtime dispatcher for a new concurrency platform, RT-OpenMP, whose goal is the execution of real-time workloads with intra-task parallelism.","Real-time systems,
Runtime,
Instruction sets,
Parallel processing,
Dispatching,
Schedules,
Synchronization"
Real-time prediction of battery power requirements for electric vehicles,"A battery management system (BMS) is responsible for protecting the battery from damage, predicting battery life, and maintaining the battery in an operational condition. In this paper, we propose an efficient way of predicting the power requirements of electric vehicles (EVs) based on a history of their power consumption, speed, and acceleration, as well as the road information from a pre-downloaded map. The predicted power requirement is then used by the BMS to prevent the damage of battery cells that might result from high discharge rates. This prediction also helps BMS efficiently schedule and allocate battery cells in real time to meet an EV's power demands. For accurate prediction of power requirements, we need an accurate model for the power requirement of each given application. We generate this model in real time by collecting and using historical data of power consumption, speed, acceleration, and road information such as slope and speed limit. By using this information and the operator's driving pattern, the model extracts the vehicle's history of speed and acceleration, which, in turn, enables the prediction of the vehicle's (immediate) future power requirements. That is, the power requirement prediction is achieved by combining a real-time power requirement model and the estimation of the vehicle's acceleration and speed. The proposed approach predicts closer to the actual required power than a widely-used heuristic approach that uses measured power demand, by up to 69.2%.","Acceleration,
Batteries,
Roads,
Vehicles,
Predictive models,
Real-time systems,
Power demand"
Generative software-based memory error detection and correction for operating system data structures,"Recent studies indicate that the number of system failures caused by main memory errors is much higher than expected. In contrast to the commonly used hardware-based countermeasures, for example using ECC memory, software-based fault-tolerance measures are much more flexible and can exploit application knowledge, such as the criticality of specific data structures. This paper presents a software-based memory error protection approach, which we used to harden the eCos operating system in a case study. The main benefits of our approach are the flexibility to choose from an extensible toolbox of easily pluggable error detection and correction schemes as well as its very low runtime overhead, which totals in a range of 0.09-1.7 %. The implementation is based on aspect-oriented programming and exploits the object-oriented program structure of eCos to identify well-suited code locations for the insertion of generative fault-tolerance measures.","Data structures,
Computer crashes"
Effect of Pulsed Power on Particle Matter in Diesel Engine Exhaust Using a DBD Plasma Reactor,"Nonthermal plasma (NTP) treatment of exhaust gas is a promising technology for both nitrogen oxides
(
NO
X
)
and particulate matter (PM) reduction by introducing plasma into the exhaust gases. This paper considers the effect of NTP on PM mass reduction, PM size distribution, and PM removal efficiency. The experiments are performed on real exhaust gases from a diesel engine. The NTP is generated by applying high-voltage pulses using a pulsed power supply across a dielectric barrier discharge (DBD) reactor. The effects of the applied high-voltage pulses up to 19.44 kVpp with repetition rate of 10 kHz are investigated. In this paper, it is shown that the PM removal and PM size distribution need to be considered both together, as it is possible to achieve high PM removal efficiency with undesirable increase in the number of small particles. Regarding these two important factors, in this paper, 17-kVpp voltage level is determined to be an optimum point for the given configuration. Moreover, particles deposition on the surface of the DBD reactor is found to be a significant phenomenon, which should be considered in all plasma PM removal tests.","Diesel engines,
Pulsed power supplies ,
Voltage measurement,
Particle measurements"
MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation,"We present MotionExplorer, an exploratory search and analysis system for sequences of human motion in large motion capture data collections. This special type of multivariate time series data is relevant in many research fields including medicine, sports and animation. Key tasks in working with motion data include analysis of motion states and transitions, and synthesis of motion vectors by interpolation and combination. In the practice of research and application of human motion data, challenges exist in providing visual summaries and drill-down functionality for handling large motion data collections. We find that this domain can benefit from appropriate visual retrieval and analysis support to handle these tasks in presence of large motion data. To address this need, we developed MotionExplorer together with domain experts as an exploratory search system based on interactive aggregation and visualization of motion states as a basis for data navigation, exploration, and search. Based on an overview-first type visualization, users are able to search for interesting sub-sequences of motion based on a query-by-example metaphor, and explore search results by details on demand. We developed MotionExplorer in close collaboration with the targeted users who are researchers working on human motion synthesis and analysis, including a summative field study. Additionally, we conducted a laboratory design study to substantially improve MotionExplorer towards an intuitive, usable and robust design. MotionExplorer enables the search in human motion capture data with only a few mouse clicks. The researchers unanimously confirm that the system can efficiently support their work.","Visual analytics,
Data visualization,
Time series analysis,
Databases,
Data collection"
Evaluating source code summarization techniques: Replication and expansion,"During software evolution a developer must investigate source code to locate then understand the entities that must be modified to complete a change task. To help developers in this task, Haiduc et al. proposed text summarization based approaches to the automatic generation of class and method summaries, and via a study of four developers, they evaluated source code summaries generated using their techniques. In this paper we propose a new topic modeling based approach to source code summarization, and via a study of 14 developers, we evaluate source code summaries generated using the proposed technique. Our study partially replicates the original study by Haiduc et al. in that it uses the objects, the instruments, and a subset of the summaries from the original study, but it also expands the original study in that it includes more subjects and new summaries. The results of our study both support the findings of the original and provide new insights into the processes and criteria that developers use to evaluate source code summaries. Based on our results, we suggest future directions for research on source code summarization.","Vectors,
Large scale integration,
Indexing,
Software,
Semantics,
Matrix decomposition,
Probability distribution"
Benchmarks for dynamic multi-objective optimisation,"When algorithms solve dynamic multi-objective optimisation problems (DMOOPs), benchmark functions should be used to determine whether the algorithm can overcome specific difficulties that can occur in real-world problems. However, for dynamic multi-objective optimisation (DMOO) there are no standard benchmark functions that are used. This article proposes characteristics of an ideal set of DMOO benchmark functions, as well as suggested DMOOPs for each characteristic. The limitations of current DMOOPs and studies of dynamic multi-objective optimisation algorithms (DMOAs) are highlighted. In addition, new DMOO benchmark functions with complicated Pareto-optimal sets (POSs) and approaches to develop DMOOPs with either an isolated or deceptive Pareto-optimal front (POF) are introduced to address identified limitations of current DMOOPs.","Optical fibers,
Benchmark testing,
Vectors,
Optimization,
Linear programming,
Heuristic algorithms,
Equations"
Utility-based cooperative spectrum sensing scheduling in cognitive radio networks,"In this paper, we consider the problem of cooperative spectrum sensing scheduling (C3S) in a cognitive radio network when there exist multiple primary channels. Deviated from the existing research our work focuses on a scenario in which each secondary user has the freedom to decide whether or not to participate in cooperative spectrum sensing; if not, the SU becomes a free rider who can eavesdrop the decision about the channel status made by others. Such a mechanism can conserve the energy for spectrum sensing at a risk of scarifying the spectrum sensing performance. To overcome this problem, we address the following two questions: “which action (contributing to spectrum sensing or not) to take?” and “which channel to sense?” To answer the first question, we model our framework as an evolutionary game in which each SU makes its decision based on its utility history, and takes an action more frequently if it brings a relatively higher utility. We also develop an entropy based coalition formation algorithm to answer the second question, where each SU always chooses the coalition (channel) that brings the most information regarding the status of the corresponding channel. All the SUs selecting the same channel to sense form a coalition. Our simulation study indicates that the proposed scheme can guarantee the detection probability at a low false alarm rate.",
Cross-media topic detection: A multi-modality fusion framework,"Detecting topics from Web data attracts increasing attention in recent years. Most previous works on topic detection mainly focus on the data from single medium, however, the rich and complementary information carried by multiple media can be used to effectively enhance the topic detection performance. In this paper, we propose a flexible data fusion framework to detect topics that simultaneously exist in different mediums. The framework is based on a multi-modality graph (MMG), which is obtained by fusing two single-modality graphs together: a text graph and a visual graph. Each node of MMGrepresents a multi-modal data and the edge weight between two nodes jointly measures their content and upload-time similarities. Since the data about the same topic often have similar content and are usually uploaded in a similar period of time, they would naturally form a dense (namely, strongly connected) subgraph in MMG. Such dense subgraph is robust to noise and can be efficiently detected by pair-wise clustering methods. The experimental results on single-medium and cross-media datasets demonstrate the flexibility and effectiveness of our method.",Abstracts
Polynomial Test for Stochastic Diagnosability of Discrete-Event Systems,"Two types of diagnosability of stochastic discrete-event systems (DESs) were introduced by Thorsley in 2005, where a necessary and sufficient condition for Strong Stochastic (SS)-Diagnosability (referred as A-diagnosability by Thorsley and Teneketzis, 2005), and a sufficient condition for Stochastic (S)-Diagnosability (referred as AA-diagnosability by Thorsley and Teneketzis, 2005), both with exponential complexity, were reported. In this paper, we present polynomial complexity tests for checking: (i) necessity and sufficiency of SS-Diagnosability; (ii) sufficiency of S-Diagnosability; and (iii) sufficiency as well as necessity of S-Diagnosability; the latter requires an additional notion of probabilistic equivalence. Thus, the work presented improves the accuracy as well as the complexity of verifying stochastic diagnosability.","Polynomials,
Complexity theory,
Discrete-event systems,
Markov processes,
Stochastic processes"
A comparison of phase disposition and phase shift PWM strategies for modular multilevel converters,"Modular Multilevel Converter (MMC) has proved to be an effective solution for high power applications, supplying low distorted output voltage and high fault tolerance. This paper presents a detailed performance comparison between phase disposition PWM (PDPWM) and phase shift PWM (PSPWM) schemes under normal condition, over-modulation, as well as carrier non-synchronization condition. Compared to the PSPWM strategy, the PDPWM has smaller line-to-line voltage distortion under normal condition, when the carrier frequencies are adjusted to achieve the same number of switch transitions over one fundamental cycle. In addition, the capacitor voltages are able to keep balanced without additional controllers. Under over-modulation condition, PDPWM can still achieve smaller voltage distortion without capacitor voltage deviation, while obvious voltage differences are observed with PSPWM, which shows an opposite trend toward that of normal condition. Moreover, asynchronous carriers have different impacts on the harmonic cancellation, which needs to be carefully considered in a hardware implementation. Simulation results for a three-phase nine-level inverter system generated with the Matlab/Simulink software are provided to support the theoretical considerations.",
Toward Fully Automatic Detection of Changes in Suburban Areas From VHR SAR Images by Combining Multiple Neural-Network Models,"Recent X-band SAR missions, such as COSMO-SkyMed (CSK), which is able to provide very high spatial resolution images of an area of interest with a short revisit time, are expected to be quite useful sources of information for monitoring the terrestrial environment and its changes. On the other hand, the huge amount of data involved, as well as the need to promptly act in case of emergency, requires the development of automatic change detection tools. This paper reports on a novel automatic change detection algorithm combining multilayer perceptron neural networks (NNs) and pulse coupled NNs, which has been implemented and tested on pairs of Stripmap and Spotlight CSK images acquired on the Tor Vergata University area in the southeast outskirts of Rome, Italy, where a significant and continuous urbanization process is occurring.",
Multiple-Rendezvous Multichannel MAC Protocol Design for Underwater Sensor Networks,"Compared with traditional terrestrial radio transmissions in wireless sensor networks, the challenges of transmissions in underwater sensor networks (UWSNs) include lower transmission rate, longer delay time, and higher power consumption. In such a circumstance, the negative effects of transmission collisions deteriorate. Most of the existing UWSN medium access control (MAC) protocols handle the collision problem in a single-hop or light-loaded environment. They fail to function effectively in a multihop network consisting of more sensor nodes with heavier traffic loads. Using the concept of cyclic quorum systems, we propose a distributed multiple-rendezvous multichannel MAC protocol, MM-MAC, in this paper to reduce collision probability. The advantages of the proposed protocol are threefold: 1) Only one modem is needed for each node to solve the missing receiver problem which is often encountered in multichannel protocols; 2) multiple sensor node pairs can complete their channel negotiations on different channels simultaneously; and 3) data packets will not be collided by control packets and vice versa. Simulation results verify that our protocol can reduce collision probability significantly which enhances the network performance in a multihop UWSN.","Media Access Protocol,
Switches,
Receivers,
Acoustics,
Transceivers,
Propagation delay"
Introducing Willmore Flow Into Level Set Segmentation of Spinal Vertebrae,"Segmentation of spinal vertebrae in 3-D space is a crucial step in the study of spinal related disease or disorders. However, the complexity of vertebrae shapes, with gaps in the cortical bone and boundaries, as well as noise, inhomogeneity, and incomplete information in images, has made spinal vertebrae segmentation a difficult task. In this paper, we introduce a new method for an accurate spinal vertebrae segmentation that is capable of dealing with noisy images with missing information. This is achieved by introducing an edge-mounted Willmore flow, as well as a prior shape kernel density estimator, to the level set segmentation framework. While the prior shape model provides much needed prior knowledge when information is missing from the image, and draws the level set function toward prior shapes, the edge-mounted Willmore flow helps to capture the local geometry and smoothes the evolving level set surface. Evaluation of the segmentation results with ground-truth validation demonstrates the effectiveness of the proposed approach: an overall accuracy of 89.32±1.70% and 14.03±1.40&nbsp;mm are achieved based on the Dice similarity coefficient and Hausdorff distance, respectively, while the inter- and intraobserver variation agreements are 92.11±1.97%, 94.94±1.69%, 3.32±0.46, and 3.80±0.56 mm.","Shape,
Image segmentation,
Level set,
High definition video,
Image edge detection,
Computed tomography,
Bones"
DC and RF Performance of Gate-Last AlN/GaN MOSHEMTs on Si With Regrown Source/Drain,"This paper presents the fabrication and characteristics of self-aligned gate-last AlN/GaN metal-oxide-semiconductor high electron mobility transistors (MOSHEMTs) featuring regrown source/drain for low ON-state resistance (RON). Previously, we demonstrated conventional enhancement-mode AlN/GaN MOSHEMTs on Si substrate with excellent DC performance but limited RF characteristics by large parasitic gate-to-source/drain overlap capacitance. In this paper, the self-aligned gate-last process was developed to minimize the parasitic capacitance. SiNx sidewall and supporting layer were inserted to separate the gate head and source/drain. In the gate-last devices, fT has been improved to be ~40 GHz with a channel length (Lg) of 210 nm. Delay time analysis showed that drain delay was relatively small compared with gate transit and parasitic charging time because of the self-aligned structure.","Logic gates,
III-V semiconductor materials,
Gallium nitride,
Delays,
Radio frequency,
HEMTs,
MODFETs"
Convex relaxation for optimal power flow problem: Mesh networks,"This paper is concerned with a fundamental resource allocation problem for electrical power networks. This problem, named optimal power flow (OPF), is nonconvex due to the nonlinearities imposed by the laws of physics, and has been studied since 1962. We have recently shown that a convex relaxation based on semidefinite programming (SDP) is able to find a global solution of OPF for IEEE benchmark systems, and moreover this technique is guaranteed to work over acyclic (distribution) networks. The present work studies the potential of the SDP relaxation for OPF over cyclic (transmission) networks. Given an arbitrary weakly-cyclic network with cycles of size 3, it is shown that the injection region is convex in the lossless case and that the Pareto front of the injection region is convex in the lossy case. It is also proved that the SDP relaxation of OPF is exact for this type of network. Moreover, it is shown that if the SDP relaxation is not exact for a general mesh network, it would still have a low-rank solution whose rank depends on the structure of the network. Finally, a heuristic method is proposed to recover a rank-1 solution for the SDP relaxation whenever the relaxation is not exact.","Vectors,
Mesh networks,
Generators,
Mathematical model,
Power system stability,
Upper bound,
Symmetric matrices"
A learning framework for online class imbalance learning,"Online learning has been showing to be very useful for a large number of applications in which data arrive continuously and a timely response is required. In many online cases, the data stream can have very skewed class distributions, known as class imbalance, such as fault diagnosis of realtime control monitoring systems and intrusion detection in computer networks. Classifying imbalanced data streams poses new challenges, which have attracted very little attention so far. As the first work that formally addresses this problem, this paper looks into the underlying issues, clarifies the research questions, and proposes a framework for online class imbalance learning that decomposes the learning task into three modules. Within the framework, we use a time decay function to capture the imbalance rate dynamically. Then, we propose a class imbalance detection method, in order to decide the current imbalance status in data streams. According to this information, two resampling-based online learning algorithms are developed to tackle class imbalance in data streams. Three basic types of class imbalance change are discussed in our studies. The results suggest the usefulness of the learning framework. The proposed methods are shown to be effective on both minority-class accuracy and overall performance in all three cases we considered.","Detectors,
Accuracy,
Training,
Learning systems,
Bagging,
Monitoring,
Prediction algorithms"
Enhanced Quench Propagation in Bi_{2}Sr_{2}CaCu_{2}O_{x} and YBa_{2}Cu_{3}O_{7-x} Coils via a Nanoscale Doped-Titania-Based Thermally Conducting Electrical Insulator,"The significant amount of energy stored in a large high-field superconducting magnet can be sufficient to destroy the coil in the event of an unprotected quench. For magnets based on high-temperature superconductors (HTSs), such as Bi2Sr2CaCu2Ox (Bi2212) and YBa2Cu3O7-x (YBCO), quench protection is particularly challenging due to slow normal zone propagation. A previous computational study showed that the quench behavior of HTS magnets is significantly improved if the turn-to-turn electrical insulation is thermally conducting, enhancing 3-D normal zone propagation. Here, a new doped-titania electrical insulation with high thermal conductivity is evaluated. The thermal conductivity of the insulation is measured at cryogenic temperatures, and its chemical compatibility with Bi2212 round wires is determined. Thin layers of the insulation are deposited onto the surface of Bi2212 and YBCO wires, which are then wound into small coils to study the quench behavior. Results show that the critical current and homogeneity of Bi2212 coils are improved relative to coils reacted with mullite insulation. Relative to similar coils with conventional insulation (mullite for Bi2212 and Kapton for YBCO), the turn-to-turn quench propagation is increased by a factor of 2.8 in Bi2212 coils at 4.2 K and self-field and by a factor of 2.5 in YBCO coils at 4.2 K and 5 T. These results indicate that doped-titania insulation may significantly improve Bi2212 and YBCO coils. Increased normal zone propagation velocity enhances quench detection and quench protection, and the thinness of the insulation relative to the most common alternatives increases the magnet winding pack current density and reduces the coil specific heat.","Coils,
Wires,
Insulation,
Temperature measurement,
Yttrium barium copper oxide,
Thermal conductivity,
Heating"
Iterative Learning Control Based on Relaxed 2-D Systems Stability Criteria,"This brief develops a new algorithm for the design of iterative learning control law algorithms in a 2-D systems setting. This algorithm enables control law design for error convergence and performance, and is actuated by process output information only. Results are also given from the experimental application to a gantry robot.","Asymptotic stability,
Stability criteria,
Vectors,
Linear systems,
State-space methods,
Process control"
Design and Performance Evaluation of Overhearing-Aided Data Caching in Wireless Ad Hoc Networks,"Wireless ad hoc network is a promising networking technology to provide users with Internet access anywhere anytime. To cope with resource constraints of wireless ad hoc networks, data caching is widely used to efficiently reduce data access cost. In this paper, we propose an efficient data caching algorithm which makes use of the overhearing property of wireless communication to improve caching performance. Due to the broadcast nature of wireless links, a packet can be overheard by a node within the transmission range of the transmitter, even if the node is not the intended target. Our proposed algorithm explores the overheard information, including data request and data reply, to optimize cache placement and cache discovery. To the best of our knowledge, this is the first work that considers the overhearing property of wireless communications in data caching. The simulation results show that, compared with one representative algorithm and a naive overhearing algorithm, our proposed algorithm can significantly reduce both message cost and access delay.","Mobile ad hoc networks,
Wireless communication,
Data structures,
Cooperative caching,
Auditory system,
Algorithm design and analysis"
Optimal Byzantine attacks on distributed detection in tree-based topologies,"This paper considers the problem of optimal Byzantine attacks or data falsification attacks on distributed detection mechanism in tree-based topologies. First, we show that when more than a certain fraction of individual node decisions are falsified, the decision fusion scheme becomes completely incapable. Second, under the assumption that there is a cost associated with attacking each node (which represent resources invested in capturing a node or cloning a node in some cases), we address the problem of minimum cost Byzantine attacks and formulate it as the bounded knapsack problem (BKP). An algorithm to solve our problem in polynomial time is presented. Numerical results provide insights into our solution.","Nickel,
Silicon,
Conferences,
Government,
Decision support systems,
Bismuth"
Smoothing the energy consumption: Peak demand reduction in smart grid,"Assume that a set of Demand Response Switch (DRS) devices are deployed in smart meters for autonomous demand side management within one house. The DRS devices are able to sense and control the activity of each appliance. We propose a set of appliance scheduling algorithms to 1) minimize the peak power consumption under a fixed delay requirement, and 2) minimize the delay under a fixed peak demand constraint. For both problems, we first prove that they are NP-Hard. Then we propose a set of approximation algorithms with constant approximation ratios. We conduct extensive simulations using both real-life appliance energy consumption data trace and synthetic data to evaluate the performance of our algorithms. Extensive evaluations verify that the schedules obtained by our methods significantly reduce the peak demand or delay compared with naive greedy algorithm or randomized algorithm.","Schedules,
Delays,
Minimization,
Approximation algorithms,
Energy consumption,
Home appliances,
Strips"
Evaluation of a UML-Based Versus an IEC 61131-3-Based Software Engineering Approach for Teaching PLC Programming,"A field experiment investigated the evaluation, teaching, and application of two different approaches to automatic control in programmable logic controllers, in particular comparing the Unified Modeling Language (UML) to the classic procedural paradigm (IEC 61131-3). A total of 85 apprentices from a vocational school for production engineering with a specialization in mechatronics took part in the training and the experiment. This paper details the results of the training using both approaches, and the correlations found between the modeling and/or programming performance and cognitive abilities, interest, workload, expertise, and school grades. In general, the results show that students can be trained to carry out authentic programming tasks within one and a half days, even for beginners in programming. The data distinguish the two approaches. Function Block Diagram programming (IEC 61131-3) can be best predicted by the grade in mathematics, programming experience, and cognitive demand. For performance in UML class diagram and state chart (UML/CD+SC) modeling, the grade in mathematics plays an even more prominent role; this explains the greater variance in modeling performance in the UML group than in the 61131/Function Block Diagram group. With respect to other findings, the paper concludes that special problem-solving skills and skills for abstract thinking should be taught when teaching UML-based modeling approaches.",
Approximation Schemes for Maximum Weight Independent Set of Rectangles,"In the Maximum Weight Independent Set of Rectangles (MWISR) problem we are given a set of n axis-parallel rectangles in the 2D-plane, and the goal is to select a maximum weight subset of pairwise non-overlapping rectangles. Due to many applications, e.g. in data mining, map labeling and admission control, the problem has received a lot of attention by various research communities. We present the first (1 + ε)-approximation algorithm for the MWISR problem with quasipolynomial running time 2poly(log n/ε). In contrast, the best known polynomial time approximation algorithms for the problem achieve superconstant approximation ratios of O(log log n) (unweighted case) and O(log n/log log n) (weighted case). Key to our results is a new geometric dynamic program which recursively subdivides the plane into polygons of bounded complexity. We provide the technical tools that are needed to analyze its performance. In particular, we present a method of partitioning the plane into small and simple areas such that the rectangles of an optimal solution are intersected in a very controlled manner. Together with a novel application of the weighted planar graph separator theorem due to Arora et al. [4] this allows us to upper bound our approximation ratio by 1 + ε. Our dynamic program is very general and we believe that it will be useful for other settings. In particular, we show that, when parametrized properly, it provides a polynomial time (1 + ε)-approximation for the special case of the MWISR problem when each rectangle is relatively large in at least one dimension. Key to this analysis is a method to tile the plane in order to approximately describe the topology of these rectangles in an optimal solution. This technique might be a useful insight to design better polynomial time approximation algorithms or even a PTAS for the MWISR problem. In particular, note that our results imply that the MWISR problem is not APX-hard, unless NP ⊆ DTIME(2polylog (n)).",
Distributed Automatic Generation Control Using Flatness-Based Approach for High Penetration of Wind Generation,"To allow for high penetration of distributed generation and alternative energy units, it is critical to minimize the complexity of generator controls and the need for close coordination across regions. We propose that existing controls be replaced by a two-tier structure of local control operating within a global context of situational awareness. Flatness as an extension of controllability for nonlinear systems is a key to enable planning and optimization at various levels of the grid in this structure. In this study, flatness-based control for automatic generation control (AGC) of a multi-machine system with high penetration of wind energy is investigated. The local control tracks the reference phase which is obtained through economic dispatch at the global control level. As a result of applying the flatness-based method, the n machine system is decoupled into n linear controllable systems in canonical form. Therefore, the control strategy results in a distributed AGC formulation which is significantly easier to design and implement compared to conventional AGC. Practical constraints such as generator ramping rates can be considered in designing the local controllers. The proposed strategy demonstrates promising performance in mitigating frequency deviations and the overall structure could facilitate operation of other nontraditional generators.","wind power,
distributed power generation,
machine control,
nonlinear control systems,
power distribution control,
power generation control,
power generation dispatch,
power system economics"
Deep hierarchical bottleneck MRASTA features for LVCSR,"Hierarchical Multi Layer Perceptron (MLP) based long-term feature extraction is optimized for TANDEM connectionist large vocabulary continuous speech recognition (LVCSR) system within the QUAERO project. Training the bottleneck MLP on multi-resolutional RASTA filtered critical band energies, more than 20% relative word error rate (WER) reduction over standard MFCC system is observed after optimizing the number of target labels. Furthermore, introducing a deeper structure in the hierarchical bottleneck processing the relative gain increases to 25%. The final system based on deep bottleneck TANDEM features clearly outperforms the hybrid approach, even if the long-term features are also presented to the deep MLP acoustic model. The results are also verified on evaluation data of the year 2012, and about 20% relative WER improvement over classical cepstral system is measured even after speaker adaptive training.",
Accelerating Ordered Subsets Image Reconstruction for X-ray CT Using Spatially Nonuniform Optimization Transfer,"Statistical image reconstruction algorithms in X-ray computed tomography (CT) provide improved image quality for reduced dose levels but require substantial computation time. Iterative algorithms that converge in few iterations and that are amenable to massive parallelization are favorable in multiprocessor implementations. The separable quadratic surrogate (SQS) algorithm is desirable as it is simple and updates all voxels simultaneously. However, the standard SQS algorithm requires many iterations to converge. This paper proposes an extension of the SQS algorithm that leads to spatially nonuniform updates. The nonuniform (NU) SQS encourages larger step sizes for the voxels that are expected to change more between the current and the final image, accelerating convergence, while the derivation of NU-SQS guarantees monotonic descent. Ordered subsets (OS) algorithms can also accelerate SQS, provided suitable “subset balance” conditions hold. These conditions can fail in 3-D helical cone-beam CT due to incomplete sampling outside the axial region-of-interest (ROI). This paper proposes a modified OS algorithm that is more stable outside the ROI in helical CT. We use CT scans to demonstrate that the proposed NU-OS-SQS algorithm handles the helical geometry better than the conventional OS methods and “converges” in less than half the time of ordinary OS-SQS.","Convergence,
Acceleration,
Computed tomography,
Optimization,
Image reconstruction,
X-ray imaging,
Standards"
Dynamic Constrained Optimization with offspring repair based Gravitational Search Algorithm,"Dynamic Constrained Optimization Problems (DCOP) are a unique class of optimization problems where the objective function as well as the constraint functions change with respect to time. Conventional DCO algorithms involve Genetic Algorithms (GAs) accompanied by a separate constraint-handling technique e.g., a repair method, or a penalty function. However, ordinary repair methods with elitism significantly decrease the diversity of the population during the exploitation stage and penalty functions cannot properly deal with disconnected feasible regions. In this paper, we propose a new approach based on the Gravitational Search Algorithm as well as a modified version of a repair method that produces improved results. The proposed approach incorporates knowledge-reusing and knowledge-restarting in order to produce a quick recovery and faster convergence.","Heuristic algorithms,
Sociology,
Statistics,
Optimization,
Maintenance engineering,
Linear programming,
Aerodynamics"
Resilient control of cyber-physical systems against Denial-of-Service attacks,"The integration of control systems with modern information technologies has posed potential security threats for critical infrastructures. The communication channels of the control system are vulnerable to malicious jamming and Denial-of-Service (DoS) attacks, which lead to severe time-delays and degradation of control performances. In this paper, we design resilient controllers for cyber-physical control systems under DoS attacks. We establish a coupled design framework which incorporates the cyber configuration policy of Intrusion Detection Systems (IDSs) and the robust control of dynamical system. We propose design algorithms based on value iteration methods and linear matrix inequalities for computing the optimal cyber security policy and control laws. We illustrate the design principle with an example from power systems. The results are corroborated by numerical examples and simulations.","Computer crime,
Games,
Physical layer,
Delays,
Libraries,
Optimal control"
Building Recognition Using Local Oriented Features,"Building recognition is an important task for a wide range of computer vision applications, e.g., surveillance and intelligent navigation aid. However, it is also challenging since each building can be viewed from different angles or under different lighting conditions, for example, resulting in a large variability among building images. A number of building recognition systems have been proposed in recent years. However, most of them are based on a complex feature extraction process. In this paper, we present a new building recognition model based on local oriented features with an arbitrary orientation. Although the newly proposed model is very simple, it offers a modular, computationally efficient, and effective alternative to other building recognition techniques. According to a comparison of experimental results with the state-of-the-art building recognition systems, it is shown that the newly proposed SFBR model can obtain very satisfactory recognition accuracy despite its simplicity.","Buildings,
Feature extraction,
Image recognition,
Computational efficiency,
Image color analysis,
Maximum likelihood detection,
Nonlinear filters"
Ultrasound perfusion analysis combining bolus-tracking and burst-replenishment,"A new signal model and processing method for quantitative ultrasound perfusion analysis is presented, called bolus-and-burst. The method has the potential to provide absolute values of blood flow, blood volume, and mean transit time. Furthermore, it provides an estimate of the local arterial input function which characterizes the arterial tree, allowing accurate estimation of the bolus arrival time. The method combines two approaches to ultrasound perfusion analysis: bolus-tracking and burst-replenishment. A pharmacokinetic model based on the concept of arterial input functions and tissue residue functions is used to model both the bolus and replenishment parts of the recording. The pharmacokinetic model is fitted to the data using blind deconvolution. A preliminary assessment of the new perfusion-analysis method is presented on clinical recordings.","Ultrasonic imaging,
Arteries,
Blood,
Blood flow,
Estimation,
Imaging,
Deconvolution"
Design and Implementation of an Integrated Performance Monitoring Tool for Swimming to Extract Stroke Information at Real Time,"Current methods used to monitor performance for swimming do not offer real-time feedback to coaches and significantly increase post session analysis times. The aim of the research outlined in this paper is to design and implement a novel performance analysis tool to measure swimmer performance using wireless technology previously developed at Loughborough University. The Computer Integrated Manufacturing Open System Architecture (CIMOSA) has been coupled with a software architecture based on object-oriented techniques to formalize and structure the development of a computer integrated real-time monitoring system. Filtering and signal-processing algorithms are applied to extract performance indicators in real time, hence allowing faster access of feedback that can be used to enhance the swimming performance during each training session.","Monitoring,
Computer architecture,
Performance evaluation,
Real-time systems,
Software architecture,
Accelerometers,
Software"
Multiscale Entropy Analysis of Different Spontaneous Motor Unit Discharge Patterns,"This study explores a novel application of multiscale entropy (MSE) analysis for characterizing different patterns of spontaneous electromyogram (EMG) signals including sporadic, tonic and repetitive spontaneous motor unit discharges, and normal surface EMG baseline. Two algorithms for MSE analysis, namely, the standard MSE and the intrinsic mode entropy (IMEn) (based on the recently developed multivariate empirical mode decomposition method), were applied to different patterns of spontaneous EMG. Significant differences were observed in multiple scales of the standard MSE and IMEn analyses (<;i>p<;/i> <; 0.001) for any two of the spontaneous EMG patterns, while such significance may not be observed from the single-scale entropy analysis. Compared to the standard MSE, the IMEn analysis facilitates usage of a relatively low scale number to discern entropy difference among various patterns of spontaneous EMG signals. The findings from this study contribute to our understanding of the nonlinear dynamic properties of different spontaneous EMG patterns, which may be related to spinal motoneuron or motor unit health.","Entropy,
Electromyography,
Standards,
Time series analysis,
Discharges (electric),
Algorithm design and analysis,
Firing"
PROBE: Prediction-based optical bandwidth scaling for energy-efficient NoCs,"Optical interconnect is a disruptive technology solution that can overcome the power and bandwidth limitations of traditional electrical Networks-on-Chip (NoCs). However, the static power dissipated in the external laser may limit the performance of future optical NoCs by dominating the stringent network power budget. From the analysis of real benchmarks for multicores, it is observed that high static power is consumed due to the external laser even for low channel utilization. In this paper, we propose PROBE: Prediction-based Optical Bandwidth Scaling for Energy-efficient NoCs by exploiting the latency/bandwidth trade-off to reduce the static power consumption by increasing the average channel utilization. With a lightweight prediction technique, we scale the bandwidth adaptively to the changing traffic demands while maintaining reasonable performance. The performance on synthetic and real traffic (PARSEC, Splash2) for 64-cores indicate that our proposed bandwidth scaling technique can reduce optical power by about 60% with at most 11% throughput penalty.","Bandwidth,
Optical waveguides,
Tiles,
Optical ring resonators,
Power lasers,
Waveguide lasers,
Optical buffering"
Mobility based energy efficient and multi-sink algorithms for consumer home networks,"With the fast development of the Internet, wireless communications and semiconductor devices, home networking has received significant attention. Consumer products can collect and transmit various types of data in the home environment. Typical consumer sensors are often equipped with tiny, irreplaceable batteries and it therefore of the utmost importance to design energy efficient algorithms to prolong the home network lifetime and reduce devices going to landfill. Sink mobility is an important technique to improve home network performance including energy consumption, lifetime and end-to-end delay. Also, it can largely mitigate the hot spots near the sink node. The selection of optimal moving trajectory for sink node(s) is an NP-hard problem jointly optimizing routing algorithms with the mobile sink moving strategy is a significant and challenging research issue. The influence of multiple static sink nodes on energy consumption under different scale networks is first studied and an Energy-efficient Multi-sink Clustering Algorithm (EMCA) is proposed and tested. Then, the influence of mobile sink velocity, position and number on network performance is studied and a Mobile-sink based Energy-efficient Clustering Algorithm (MECA) is proposed. Simulation results validate the performance of the proposed two algorithms which can be deployed in a consumer home network environment1.","Sensors,
Mobile communication,
Energy consumption,
Clustering algorithms,
Home automation,
Energy efficiency,
Wireless sensor networks"
Temporally Consistent Probabilistic Detection of New Multiple Sclerosis Lesions in Brain MRI,"Detection of new Multiple Sclerosis (MS) lesions on magnetic resonance imaging (MRI) is important as a marker of disease activity and as a potential surrogate for relapses. We propose an approach where sequential scans are jointly segmented, to provide a temporally consistent tissue segmentation while remaining sensitive to newly appearing lesions. The method uses a two-stage classification process: 1) a Bayesian classifier provides a probabilistic brain tissue classification at each voxel of reference and follow-up scans, and 2) a random-forest based lesion-level classification provides a final identification of new lesions. Generative models are learned based on 364 scans from 95 subjects from a multi-center clinical trial. The method is evaluated on sequential brain MRI of 160 subjects from a separate multi-center clinical trial, and is compared to 1) semi-automatically generated ground truth segmentations and 2) fully manual identification of new lesions generated independently by nine expert raters on a subset of 60 subjects. For new lesions greater than 0.15 cc in size, the classifier has near perfect performance (99% sensitivity, 2% false detection rate), as compared to ground truth. The proposed method was also shown to exceed the performance of any one of the nine expert manual identifications.","Lesions,
Magnetic resonance imaging,
Image segmentation,
Joints,
Bayes methods,
Manuals,
Probabilistic logic"
A flexible hash table design for 10GBPS key-value stores on FPGAS,"Common web infrastructure relies on distributed main memory key-value stores to reduce access load on databases, thereby improving both performance and scalability of web sites. As standard cloud servers provide sub-linear scalability and reduced power efficiency to these kinds of scale-out workloads, we have investigated a novel dataflow architecture for key-value stores with the aid of FPGAs which can deliver consistent 10Gbps throughput. In this paper, we present the design of a novel hash table which forms the centre piece of this dataflow architecture. The fully pipelined design can sustain consistent 10Gbps line-rate performance by deploying a concurrent mechanism to handle hash collisions. We address problems such as support for a broad range of key sizes without stalling the pipeline through careful matching of lookup time with packet reception time. Finally, the design is based on a scalable architecture that can be easily parametrized to work with different memory types operating at different access speeds and latencies. We deployed this hash table in a memcached prototype to index 2 million entries in 24GBytes of external DDR3 DRAM while sustaining 13 million requests per second for UDP binary encoded memcached packets which is the maximum packet rate that can be achieved with memcached on a 10Gbps link.","Computer architecture,
Pipelines,
Throughput,
Indexes,
Field programmable gate arrays,
Bandwidth,
Prototypes"
Adhesion and Proliferation of Osteoblast-Like Cells on Anodic Porous Alumina Substrates With Different Morphology,"We have fabricated nanoporous alumina surfaces by means of anodization in oxalic acid in different conditions and used them as the substrates for the growth of cells from a human osteoblast-like cell line. The rough nanoporous alumina substrates have been compared both with smooth standard Petri dishes used as the control and with commercial substrates of similar material. The viability of the cells has been assessed at different culture times of 4, 11, 18, and 25 days in vitro. It turned out that the porous side of the galvanostatically fabricated alumina performed similar to the control and better than the commercial porous alumina, whereas the potentiostatically fabricated porous alumina performed better than all the other substrates at all times, and in particular at the two shortest time periods of 4 and 11 days in vitro. The best performance of the substrates is associated with intermediate surface roughness and feature spacing.","surface roughness,
adhesion,
alumina,
anodisation,
biological techniques,
biomechanics,
cellular biophysics,
nanofabrication,
porous materials,
statistical analysis,
substrates,
surface morphology"
Local power distribution with nanogrids,"Matching electricity demand to supply will be a growing challenge in the future. We argue for the need for further research into local power distribution with a focus on “nanogrids”. We define a nanogrid as a small electricity domain with distinct voltage, price, reliability, quality, and administration. We seek to improve upon existing nanogrids (such as USB and PoE) by the addition of electricity price information to enable power distribution to be managed in a distributed bottom-up and fair manner to optimally match demand to supply, and to more easily and efficiently integrate local generation and storage. This approach, modeled on Internet principles, offers the possibility of moving to a less reliable utility grid, providing quality and reliability at the edge, and saving capital and energy. We illustrate the operation of a simple nanogrid driven by rules governing controller and load behavior in response to varying electricity availability from a renewable source.",
An Adaptive System Based on Roadmap Profiling to Enhance Warning Message Dissemination in VANETs,"In recent years, new applications, architectures, and technologies have been proposed for vehicular ad hoc networks (VANETs). Regarding traffic safety applications for VANETs, warning messages have to be quickly and smartly disseminated in order to reduce the required dissemination time and to increase the number of vehicles receiving the traffic warning information. In the past, several approaches have been proposed to improve the alert dissemination process in multihop wireless networks, but none of them were tested in real urban scenarios, adapting its behavior to the propagation features of the scenario. In this paper, we present the Profile-driven Adaptive Warning Dissemination Scheme (PAWDS) designed to improve the warning message dissemination process. With respect to previous proposals, our proposed scheme uses a mapping technique based on adapting the dissemination strategy according to both the characteristics of the street area where the vehicles are moving and the density of vehicles in the target scenario. Our algorithm reported a noticeable improvement in the performance of alert dissemination processes in scenarios based on real city maps.","Vehicles,
Cities and towns,
Protocols,
Layout,
Storms,
Buildings,
Junctions"
Joint Clock Synchronization and Ranging: Asymmetrical Time-Stamping and Passive Listening,"A fully asynchronous network with one sensor and M anchors (nodes with known locations) is considered in this letter. We propose a novel asymmetrical time-stamping and passive listening (ATPL) protocol for joint clock synchronization and ranging. The ATPL protocol exploits broadcast to not only reduce the number of active transmissions between the nodes, but also to obtain more information. This is used in a simple estimator based on least-squares (LS) to jointly estimate all the unknown clock-skews, clock-offsets, and pairwise distances of the sensor to each anchor. The Cramér-Rao lower bound (CRLB) is derived for the considered problem. The proposed estimator is shown to be asymptotically efficient, meets the CRLB, and also performs better than the available clock synchronization algorithms.","Synchronization,
Protocols,
Clocks,
Distance measurement,
Joints,
Signal processing algorithms,
Wireless sensor networks"
Linking Brain Responses to Naturalistic Music Through Analysis of Ongoing EEG and Stimulus Features,"This study proposes a novel approach for the analysis of brain responses in the modality of ongoing EEG elicited by the naturalistic and continuous music stimulus. The 512-second long EEG data (recorded with 64 electrodes) are first decomposed into 64 components by independent component analysis (ICA) for each participant. Then, the spatial maps showing dipolar brain activity are selected in terms of the residual dipole variance through a single dipole model in brain imaging, and clustered into a pre-defined number (estimated by the minimum description length) of clusters. Subsequently, the temporal courses of the EEG theta and alpha oscillations of each component for each cluster are produced and correlated with the temporal courses of tonal and rhythmic features of the music. Using this approach, we found that the extracted temporal courses of the theta and alpha oscillations along central and occipital area of scalp in two of the selected clusters significantly correlated with the musical features representing progressions in the rhythmic content of the stimulus. We suggest that this demonstrates that with the proposed approach, we have managed to discover what kinds of brain responses were elicited when a participant was listening continuously to the long piece of naturalistic music.",
Fuzzy logic-based adaptive gravitational search algorithm for optimal tuning of fuzzy-controlled servo systems,"This study proposes an adaptive gravitational search algorithm (AGSA) which carries out adaptation of depreciation law of the gravitational constant and of a parameter in the weighted sum of all forces exerted from the other agents to the iteration index. The adaptation is ensured by a simple single input-two output (SITO) fuzzy block in the algorithm-s structure. SITO fuzzy block operates in the iteration domain, the iteration index is the input variable and the gravitational constant and the parameter in the weighted sum of all forces are the output variables. AGSA-s convergence is guaranteed by a theorem derived from Popov-s hyperstability analysis results. AGSA is embedded in an original design and tuning method for Takagi-Sugeno proportional-integral fuzzy controllers (T-S PI-FCs) dedicated to servo systems modelled by second-order models with an integral component and variable parameters. AGSA solves a minimisation-type optimisation problem based on an objective function which depends on the sensitivity function with respect to process gain variations, therefore a reduced process gain sensitivity is offered. AGSA is validated by a case study that optimally tunes a T-S PI-FC for position control of a laboratory servo system.Representative experimental results are presented.","servomechanisms,
adaptive control,
control system synthesis,
fuzzy control,
fuzzy logic,
iterative methods,
minimisation,
optimal control"
Increasing the Automation of a 2D-3D Registration System,"Routine clinical use of 2D-3D registration algorithms for Image Guided Surgery remains limited. A key aspect for routine clinical use of this technology is its degree of automation, i.e., the amount of necessary knowledgeable interaction between the clinicians and the registration system. Current image-based registration approaches usually require knowledgeable manual interaction during two stages: for initial pose estimation and for verification of produced results. We propose four novel techniques, particularly suited to vertebra-based registration systems, which can significantly automate both of the above stages. Two of these techniques are based upon the intraoperative “insertion” of a virtual fiducial marker into the preoperative data. The remaining two techniques use the final registration similarity value between multiple CT vertebrae and a single fluoroscopy vertebra. The proposed methods were evaluated with data from 31 operations (31 CT scans, 419 fluoroscopy images). Results show these methods can remove the need for manual vertebra identification during initial pose estimation, and were also very effective for result verification, producing a combined true positive rate of 100% and false positive rate equal to zero. This large decrease in required knowledgeable interaction is an important contribution aiming to enable more widespread use of 2D-3D registration technology.","Computed tomography,
Surgery,
Estimation,
Accuracy,
Automation,
Tracking,
Indexes"
HMM-Based Malicious User Detection for Robust Collaborative Spectrum Sensing,"Collaborative spectrum sensing improves the spectrum state estimation accuracy but is vulnerable to the potential attacks from malicious secondary cognitive radio (CR) users, and thus raises security concerns. One promising malicious user detection method is to identify their abnormal statistical spectrum sensing behaviors. From this angle, two hidden Markov models (HMMs) corresponding to honest and malicious users respectively are adopted in this paper to characterize their different sensing behaviors, and malicious user detection is achieved via detecting the difference in the corresponding HMM parameters. To obtain the HMM estimates, an effective inference algorithm that can simultaneously estimate two HMMs without requiring separated training sequences is also developed. By using these estimates, high malicious user detection accuracy can be achieved at the fusion center, leading to more robust and reliable collaborative spectrum sensing performance (substantially enlarged operational regions) in the presence of malicious users, as compared to the baseline approaches. Different fusion methods are also discussed and compared.","Hidden Markov models,
Sensors,
Collaboration,
Inference algorithms,
Estimation,
Robustness,
Training"
Calculation of Intravascular Signal in Dynamic Contrast Enhanced-MRI Using Adaptive Complex Independent Component Analysis,"Assessing tumor response to therapy is a crucial step in personalized treatments. Pharmacokinetic (PK) modeling provides quantitative information about tumor perfusion and vascular permeability that are associated with prognostic factors. A fundamental step in most PK analyses is calculating the signal that is generated in the tumor vasculature. This signal is usually inseparable from the extravascular extracellular signal. It was shown previously using in vivo and phantom experiments that independent component analysis (ICA) is capable of calculating the intravascular time-intensity curve in dynamic contrast enhanced (DCE)-MRI. A novel adaptive complex independent component analysis (AC-ICA) technique is developed in this study to calculate the intravascular time-intensity curve and separate this signal from the DCE-MR images of tumors. The use of the complex-valued DCE-MRI images rather than the commonly used magnitude images satisfied the fundamental assumption of ICA, i.e., linear mixing of the sources. Using an adaptive cost function in ICA through estimating the probability distribution of the tumor vasculature at each iteration resulted in a more robust and accurate separation algorithm. The AC-ICA algorithm provided a better estimate for the intravascular time-intensity curve than the previous ICA-based method. A simulation study was also developed in this study to realistically simulate DCE-MRI data of a leaky tissue mimicking phantom. The passage of the MR contrast agent through the leaky phantom was modeled with finite element analysis using a diffusion model. Once the distribution of the contrast agent in the imaging field of view was calculated, DCE-MRI data was generated by solving the Bloch equation for each voxel at each time point. The intravascular time-intensity curve calculation results were compared to the previously proposed ICA-based intravascular time-intensity curve calculation method that applied ICA to the magnitude of the DCE-MRI data (Mag-ICA) using both simulated and experimental tissue mimicking phantoms. The AC-ICA demonstrated superior performance compared to the Mag-ICA method. AC-ICA provided more accurate estimate of intravascular time-intensity curve, having smaller error between the calculated and actual intravascular time-intensity curves compared to the Mag-ICA. Furthermore, it showed higher robustness in dealing with datasets with different resolution by providing smaller variation between the results of each datasets and having smaller difference between the intravascular time-intensity curves of various resolutions. Thus, AC-ICA has the potential to be used as the intravascular time-intensity curve calculation method in PK analysis and could lead to more accurate PK analysis for tumors.","Tumors,
Mathematical model,
Extracellular,
Probability density function,
Phantoms,
Equations,
Magnetic resonance imaging"
A Fuzzy Measure Similarity Between Sets of Linguistic Summaries,"In this paper, we consider the problem of evaluating the similarity of two sets of linguistic summaries of sensor data. Huge amounts of available data cause a dramatic need for summarization. In continuous monitoring, it is useful to compare one time interval of data with another, for example, to detect anomalies or to predict the onset of a change from a normal state. Assuming that summaries capture the essence of the data, it is sufficient to compare only those summaries, i.e., they are descriptive features for recognition. In previous work, we developed a similarity measure between two individual summaries and proved that the associated dissimilarity is a metric. Additionally, we proposed some basic methods to combine these similarities into an aggregate value. Here, we develop a novel parameter free method, which is based on fuzzy measures and integrals, to fuse individual similarities that will produce a closeness measurement between sets of summaries. We provide a case study from the eldercare domain where the goal is to compare different nighttime patterns for change detection. The reasons for studying linguistic summaries for eldercare are twofold: First, linguistic summaries are the natural communication tool for health care providers in a decision support system, and second, due to the extremely large volume of raw data, these summaries create compact features for an automated reasoning for detection and prediction of health changes as part of the decision support system.","Pragmatics,
Prototypes,
Medical services,
Time series analysis,
Measurement,
Equations,
Monitoring"
Provably correct continuous control for high-level robot behaviors with actions of arbitrary execution durations,"Formal methods have recently been successfully applied to construct verifiable high-level robot control. Most approaches use a discrete abstraction of the underlying continuous domain, and make simplifying assumptions about the physical execution of actions given a discrete implementation. Relaxing these assumptions unearths a number of challenges in the continuous implementation of automatically-synthesized hybrid controllers. This paper describes a controller-synthesis framework that ensures correct continuous behaviors by explicitly modeling the activation and completion of continuous low-level controllers. The synthesized controllers exhibit desired properties like immediate reactiveness to sensor events and guaranteed safety of physical executions. The approach extends to any number of robot actions with arbitrary relative timings.","Cameras,
Robot vision systems,
Automata,
Safety,
Turning"
Cooperative sparsity pattern recovery in distributed networks via distributed-OMP,"In this paper, we address the problem of sparsity pattern recovery of a sparse signal with multiple measurement data in a distributed network. We consider that each node in the network makes measurements via random projections regarding the same sparse signal. We propose a distributed greedy algorithm based on Orthogonal Matching Pursuit (OMP) in which the locations of non zero coefficients of the sparse signal are estimated iteratively while performing fusion of estimates at distributed nodes. In the proposed distributed framework, each node has to perform less number of iterations of OMP compared to the sparsity index of the sparse signal. With each node having a very small number of compressive measurements, a significant performance gain in sparsity pattern detection is achieved via the proposed collaborative scheme compared to the case where each node estimates the sparsity pattern independently and then fusion is performed to get a global estimate. We further extend the algorithm to a binary hypothesis testing framework, where the algorithm first detects the presence of a sparse signal collaborating among nodes with a fewer number of iterations of OMP and then increases the number of iterations to estimate the sparsity pattern only if the signal is detected.","Vectors,
Indexes,
Collaboration,
Signal processing,
Estimation,
Signal processing algorithms,
Cognitive radio"
What Should Secondary Users Do Upon Incumbents' Return?,"In a cognitive radio network (CRN), secondary users (SUs) opportunistically utilize idle licensed spectrum bands. We address the natural questions that arise when the incumbents or primary users (PUs) return to the channel the SUs are using opportunistically. Instead of immediately switching to another idle channel as proposed in almost all existing approaches, the SUs may opt to wait silently in their current channel until the PUs depart. This option would be beneficial to the SUs if the returned PUs stay at the channel only for a short period of time and the SUs' channel-switching incurs a non-negligible overhead. We determine how long the SUs should wait in their current channel before switching to a new idle channel. The SUs should also occasionally sense those (called em out-of-band) channels currently not in use for sensing the availability of spectrum opportunities. We propose an efficient, adaptive spectrum-sensing technique to detect when a busy out-of-band channel becomes idle. We also present a spectrum-management architecture that integrates the SUs' strategies and facilitates fast discovery of spectrum opportunities.","Sensors,
Switches,
Hazards,
Markov processes,
Databases,
Approximation methods,
Dynamic programming"
Regular Functions and Cost Register Automata,"We propose a deterministic model for associating costs with strings that is parameterized by operations of interest (such as addition, scaling, and minimum), a notion of regularity that provides a yardstick to measure expressiveness, and study decision problems and theoretical properties of resulting classes of cost functions. Our definition of regularity relies on the theory of string-to-tree transducers, and allows associating costs with events that are conditioned on regular properties of future events. Our model of cost register automata allows computation of regular functions using multiple “write-only” registers whose values can be combined using the allowed set of operations. We show that the classical shortest-path algorithms as well as the algorithms designed for computing discounted costs can be adapted for solving the min-cost problems for the more general classes of functions specified in our model. Cost register automata with the operations of minimum and increment give a deterministic model that is equivalent to weighted automata, an extensively studied nondeterministic model, and this connection results in new insights and new open problems.",
Peer-Assisted On-Demand Streaming: Characterizing Demands and Optimizing Supplies,"Nowadays, there has been significant deployment of peer-assisted on-demand streaming services over the Internet. Two of the most unique and salient features in a peer-assisted on-demand streaming system are the differentiation in the demand (or request) and the prefetching capability with caching. In this paper, we develop a theoretical framework based on queuing models, in order to 1) justify the superiority of service prioritization based on a taxonomy of requests, and 2) understand the fundamental principles behind optimal prefetching and caching designs in peer-assisted on-demand streaming systems. The focus is to instruct how limited uploading bandwidth resources and peer caching capacities can be utilized most efficiently to achieve better system performance. To achieve these objectives, we first use priority queuing analysis to prove how service quality and user experience can be statistically guaranteed, by prioritizing requests in the order of significance, including urgent playback (e.g., random seeks or initial startup), normal playback, and prefetching. We then proceed to construct a fine-grained stochastic supply-demand model to investigate peer caching and prefetching as a global optimization problem. This not only provides insights in understanding the fundamental characterization of demand, but also offers guidelines toward optimal prefetching and caching strategies in peer-assisted on-demand streaming systems.",
Safety-Aware Semi-Supervised Classification,"Though semi-supervised classification learning has attracted great attention over past decades, semi-supervised classification methods may show worse performance than their supervised counterparts in some cases, consequently reducing their confidence in real applications. Naturally, it is desired to develop a safe semi-supervised classification method that never performs worse than the supervised counterparts. However, to the best of our knowledge, few researches have been devoted to safe semi-supervised classification. To address this problem, in this paper, we invent a safety-control mechanism for safe semi-supervised classification by adaptive tradeoff between semi-supervised and supervised classification in terms of unlabeled data. In implementation, based on our recent semi-supervised classification method based on class memberships (SSCCM), we develop a safety-aware SSCCM (SA-SSCCM). SA-SSCCM, on the one hand, exploits the unlabeled data to help learning (as SSCCM does) under the assumption that unlabeled data can help learning, and on the other hand, restricts its prediction to approach that of its supervised counterpart least-square support vector machine (LS-SVM) under the assumption that unlabeled data can hurt learning. Therefore, prediction by SA-SSCCM becomes a tradeoff between those by semi-supervised SSCCM and supervised LS-SVM, respectively, in terms of the unlabeled data. As in SSCCM, the optimization problem in SA-SSCCM can be efficiently solved by the alternating iterative strategy, and the iteration convergence can theoretically be guaranteed. Experiments over several real datasets show the promising performance of SA-SSCCM compared with LS-SVM, SSCCM, and off-the-shelf safe semi-supervised classification methods.","support vector machines,
learning (artificial intelligence),
least squares approximations,
optimisation,
pattern classification"
DEHEMS: creating a digital environment for large-scale energy management at homes,"Located at the consumer-end of the Smart Grid, domestic energy monitoring and management systems aim to provide direct energy feedback whilst (or shortly after) consumption occurs, so as to persuade users to achieve energy saving and efficiency. However, existing solutions are challenged by the lack of large-scale practice and study on user behaviours and preferences. In this paper, we present a domestic energy management system (DEHEMS), which deploys electricity and gas monitoring in European-wide homes. The system has been developed in three cycles in order for households to participate and contribute. Results based on both qualitative and quantitative data analysis show that less energy has been consumed using the system. Additionally, positive behavioural changes have been achieved among households.","Monitoring,
Energy consumption,
Energy management,
Sensors,
Educational institutions,
Logic gates,
Electricity"
Write intensity prediction for energy-efficient non-volatile caches,"This paper presents a novel concept called write intensity prediction for energy-efficient non-volatile caches as well as the architecture that implements the concept. The key idea is to correlate write intensity of cache blocks with addresses of memory access instructions that incur cache misses of those blocks. The predictor keeps track of instructions that tend to load write-intensive blocks and utilizes that information to predict write intensity of blocks. Based on this concept, we propose a block placement strategy driven by write intensity prediction for SRAM/STT-RAM hybrid caches. Experimental results show that the proposed approach reduces write energy consumption by 55% on average compared to the existing hybrid cache architecture.","Random access memory,
Radiation detectors,
Energy consumption,
Nonvolatile memory,
Correlation,
Memory management"
A Data-Driven Iterative Feedback Tuning Approach of ALINEA for Freeway Traffic Ramp Metering With PARAMICS Simulations,"In this work, a new iterative feedback tuning approach is proposed to tune ALINEA's controller gain automatically when there is not enough prior information available to select a proper feedback gain of ALINEA. It is a data-driven method and the ALINEA controller is auto-tuned only depending on the input and output data collected from closed-loop experiments. To mimic a real traffic environment, a simulator is built on the PARAMICS platform. The flow-based ALINEA controller is also considered to illustrate the good tuning performance of IFT comprehensively. The effectiveness of the proposed methods is verified through PARAMICS based simulations.","Traffic control,
Tuning,
Adaptive control,
Iterative methods,
Data models"
Year,,
Study of clear channel assessment mechanism for ZigBee packet transmission under Wi-Fi interference,"Recent studies have shown that low-power ZigBee based wireless sensor networks (WSN) are vulnerable to the interference generated by Wi-Fi nodes. In this study, the effects of energy detection (ED) mechanism in clear channel assessment (CCA) of ZigBee transmitter under 802.11g Wi-Fi interference have been evaluated through experimentation. To improve the performance of ZigBee packet transmission, a preliminary adaptive mechanism is implemented and evaluated in our testbed.","Zigbee,
IEEE 802.11 Standards,
Interference,
Packet loss,
IEEE 802.15 Standards,
Wireless sensor networks"
Negative Correlation Ensemble Learning for Ordinal Regression,"In this paper, two neural network threshold ensemble models are proposed for ordinal regression problems. For the first ensemble method, the thresholds are fixed a priori and are not modified during training. The second one considers the thresholds of each member of the ensemble as free parameters, allowing their modification during the training process. This is achieved through a reformulation of these tunable thresholds, which avoids the constraints they must fulfill for the ordinal regression problem. During training, diversity exists in different projections generated by each member is taken into account for the parameter updating. This diversity is promoted in an explicit way using a diversity-encouraging error function, extending the well-known negative correlation learning framework to the area of ordinal regression, and inheriting many of its good properties. Experimental results demonstrate that the proposed algorithms can achieve competitive generalization performance when considering four ordinal regression metrics.","regression analysis,
generalisation (artificial intelligence),
learning (artificial intelligence),
neural nets"
Geometrical FLIRT phrases for large scale place recognition in 2D range data,"Place recognition, i.e., the problem of recognizing if the robot is navigating in an already visited place, is a fundamental problem in mobile robot navigation. Efficient solutions to this problem are relevant for effectively localizing robots and for creating maps in real time. Relatively few methods have been proposed to efficiently solve this problem in very large environments using 2D range data. In this paper, we introduce geometrical FLIRT phrases (GFPs) as a novel retrieval method for very efficient and precise place recognition. GFPs perform approximate 2D range data matching, have low computational cost, can handle complicated partial matching patterns and are robust to noise. Experiments carried out with publicly available datasets demonstrate that GFPs largely outperform state-of-the-art approaches in 2D range-based place recognition in terms of efficiency and recall. We obtain retrieval performances with more than 85% recall at 99% precision in less than a second, even on data sets obtained from several kilometer long runs.",
Energy-Efficient High-Throughput Montgomery Modular Multipliers for RSA Cryptosystems,"Modular exponentiation in the Rivest, Shamir, and Adleman cryptosystem is usually achieved by repeated modular multiplications on large integers. To speed up the encryption/decryption process, many high-speed Montgomery modular multiplication algorithms and hardware architectures employ carry-save addition to avoid the carry propagation at each addition operation of the add-shift loop. In this paper, we propose an energy-efficient algorithm and its corresponding architecture to not only reduce the energy consumption but also further enhance the throughput of Montgomery modular multipliers. The proposed architecture is capable of bypassing the superfluous carry-save addition and register write operations, leading to less energy consumption and higher throughput. In addition, we also modify the barrel register full adder (BRFA) so that the gated clock design technique can be applied to significantly reduce the energy consumption of storage elements in BRFA. Experimental results show that the proposed approaches can achieve up to 60% energy saving and 24.6% throughput improvement for 1024-bit Montgomery multiplier.","Computer architecture,
Registers,
Clocks,
Hardware,
Energy consumption,
Throughput,
Adders"
Survey on cooperative medium access control protocols,"In the past decade, there has been ever-increasing research attention to user cooperation in the wireless communication networks. The unique challenges of wireless networks such as channel fading and variation can be addressed well by taking advantage of relaying among cooperating mobile terminals. There are many studies on cooperative communications at the physical layer to exploit spatial diversity for improving channel capacity. In recent years, user cooperation from the perspective of the medium access control (MAC) layer becomes a promising new research area. In this study, the authors present a comprehensive survey on the mainstream cooperative MAC protocols in the literature. Focusing on the contention-based solutions, the authors classify the well-known proposals according to how they address two fundamental questions for user cooperation, that is, when to cooperation and whom to cooperate with. In addition to analysing the essential features of classic cooperative MAC protocols, the authors also discuss the major research challenges and project future research directions for MAC-layer cooperation.","wireless channels,
access protocols,
radio networks"
SPREAD: A Streaming-Based Partially Reconfigurable Architecture and Programming Model,"Partially reconfigurable systems are promising computing platforms for streaming applications, which demand both hardware efficiency and reconfigurable flexibility. To realize the full potential of these systems, a streaming-based partially reconfigurable architecture and unified software/hardware multithreaded programming model (SPREAD) is presented in this paper. SPREAD is a reconfigurable architecture with a unified software/hardware thread interface and high throughput point-to-point streaming structure. It supports dynamic computing resource allocation, runtime software/hardware switching, and streaming-based multithreaded management at the operating system level. SPREAD is designed to provide programmers of streaming applications with a unified view of threads, allowing them to exploit thread, data, and pipeline parallelism; it enhances hardware efficiency while simplifying the development of streaming applications for partially reconfigurable systems. Experimental results targeting cryptography applications demonstrate the feasibility and superior performance of SPREAD. Moreover, the parallelized Advanced Encryption Standard (AES), Data Encryption Standard (DES), and Triple DES (3DES) hardware threads on field-programmable gate arrays show 1.61-4.59 times higher power efficiency than their implementations on state-of-the-art graphics processing units.","Instruction sets,
Hardware,
Switches,
Runtime,
Operating systems,
Parallel processing"
A UAV based system for real time flash flood monitoring in desert environments using Lagrangian microsensors,"Floods are the most common natural disasters, causing thousands of casualties every year in the world. In particular, flash flood events are particularly deadly because of the short timescales on which they occur. Most casualties could be avoided with advance warning, for which real time monitoring is critical. While satellite-based high resolution weather forecasts can help predict floods to a certain extent, they are not reliable enough, as flood models depend on a large number of parameters that cannot be estimated beforehand. In this article, we present a novel flood sensing architecture to monitor large scale desert hydrological basins surrounding metropolitan areas, based on unmanned air vehicles. The system relies on Lagrangian (mobile) microsensors, that are released by a swarm of UAVs. A preliminary testbed implementing this technology is briefly described, and future research directions and problems are discussed.","Monitoring,
Microsensors,
Real-time systems,
Estimation,
Mathematical model,
Meteorology"
Design and Analysis of Dual-Mode Digital-Control Step-Up Switched-Capacitor Power Converter With Pulse-Skipping and Numerically Controlled Oscillator-Based Frequency Modulation,"This paper presents a 3 V-to-5 V integrated dual-mode digital-control step-up switched-capacitor (SC) power converter. The feedback control circuit is equipped with a low-power analog-to-digital converter which monitors and feeds the output voltage to a digital controller. With light loading, the control loop operates in a pulse-skipping mode. With heavy loading, the control loop operates in a frequency modulation mode (FMM) based on a numerically controlled oscillator whose switching frequency varies from 31.25 kHz to 1 MHz. The design is fabricated in a 0.5- μm digital CMOS process. With multiplierless implementation, the controller requires a gate count of less than 300. The whole design occupies a total active area of 0.23 mm2. From silicon measurement, with a 330-nF external flying capacitor, the design delivers a regulated 5 V output with an output current up to 25 mA from a 3 V supply, delivering an output power greater than 100 mW. The load regulation is measured to be 0.14%. A remarkable efficiency of 80% or above on average under various loading conditions is achieved. Dynamic characteristic and stability analysis of the SC converter in the FMM are presented. Comparisons with existing designs demonstrate the excellence of the proposed design.","Capacitors,
Voltage control,
Switching frequency,
Clocks,
Loading,
Switches"
Skyline Processing on Distributed Vertical Decompositions,"We assume a data set that is vertically decomposed among several servers, and a client that wishes to compute the skyline by obtaining the minimum number of points. Existing solutions for this problem are restricted to the case where each server maintains exactly one dimension. This paper proposes a general solution for vertical decompositions of arbitrary dimensionality. We first investigate some interesting problem characteristics regarding the pruning power of points. Then, we introduce vertical partition skyline (VPS), an algorithmic framework that includes two steps. Phase 1 searches for an anchor point Panc that dominates, and hence eliminates, a large number of records. Starting with Panc, Phase 2 constructs incrementally a pruning area using an interesting union-intersection property of dominance regions. Servers do not transmit points that fall within the pruning area in their local subspace. Our experiments confirm the effectiveness of the proposed methods under various settings.","Servers,
Lattices,
Partitioning algorithms,
Query processing"
Metafora: A Web-Based Platform for Learning to Learn Together in Science and Mathematics,"This paper presents Metafora, both a platform for integrated tools as well as an emerging pedagogy for supporting Learning to Learn Together in science and mathematics education. Our goal is to design technology that brings education to a higher level; a level where students not only learn subject matter, but also gain a set of critical skills needed to engage in and self-regulate collaborative learning experiences in science and math education. To achieve this goal, we need to understand how educational technology can bring students' attention to, and promote these higher level skills. We first discuss the core skills that students need as they learn to learn together. We then present a platform and pedagogy to support the acquisition of the critical skills. Finally, we present an example use of our system based on results from pilot studies. This example demonstrates interaction with the platform to highlight potential benefits and limitations of our approach to promoting the associated skills.","Planning,
Reflection,
Context,
Mathematics,
Collaboration,
Collaborative work,
Software"
"Low-Complexity Multiplier for
GF(
2
m
)
Based on All-One Polynomials","This paper presents an area-time-efficient systolic structure for multiplication over GF(2m) based on irreducible all-one polynomial (AOP). We have used a novel cut-set retiming to reduce the duration of the critical-path to one XOR gate delay. It is further shown that the systolic structure can be decomposed into two or more parallel systolic branches, where the pair of parallel systolic branches has the same input operand, and they can share the same input operand registers. From the application-specific integrated circuit and field-programmable gate array synthesis results we find that the proposed design provides significantly less area-delay and power-delay complexities over the best of the existing designs.",
CloudPD: Problem determination and diagnosis in shared dynamic clouds,"In this work, we address problem determination in virtualized clouds. We show that high dynamism, resource sharing, frequent reconfiguration, high propensity to faults and automated management introduce significant new challenges towards fault diagnosis in clouds. Towards this, we propose CloudPD, a fault management framework for clouds. CloudPD leverages (i) a canonical representation of the operating environment to quantify the impact of sharing; (ii) an online learning process to tackle dynamism; (iii) a correlation-based performance models for higher detection accuracy; and (iv) an integrated end-to-end feedback loop to synergize with a cloud management ecosystem. Using a prototype implementation with cloud representative batch and transactional workloads like Hadoop, Olio and RUBiS, it is shown that CloudPD detects and diagnoses faults with low false positives (<; 16%) and high accuracy of 88%, 83% and 83%, respectively. In an enterprise trace-based case study, CloudPD diagnosed anomalies within 30 seconds and with an accuracy of 77%, demonstrating its effectiveness in real-life operations.",
STEAM-Powered Computing Education: Using E-Textiles to Integrate the Arts and STEM,"Incorporating novel, cross-disciplinary technologies such as e-textiles in computing education can broaden participation, particularly by women, and improve learning outcomes.","Computer science education,
Education,
Textile industry,
Art,
Gender issues,
Wearable computing"
Sampling High-Dimensional Bandlimited Fields on Low-Dimensional Manifolds,"Consider the task of sampling and reconstructing a bandlimited spatial field in R2 using moving sensors that take measurements along their path. It is inexpensive to increase the sampling rate along the paths of the sensors but more expensive to increase the total distance traveled by the sensors per unit area, which we call the path density. In this paper, we introduce the problem of designing sensor trajectories that are minimal in path density subject to the condition that the measurements of the field on these trajectories admit perfect reconstruction of bandlimited fields. We study various possible designs of sampling trajectories. Generalizing some ideas from the classical theory of sampling on lattices, we obtain necessary and sufficient conditions on the trajectories for perfect reconstruction. We show that a single set of equispaced parallel lines has the lowest path density from certain restricted classes of trajectories that admit perfect reconstruction. We then generalize some of our results to higher dimensions. We first obtain results on designing sampling trajectories in higher dimensional fields. Further, interpreting trajectories as 1-D manifolds, we extend some of our ideas to higher dimensional sampling manifolds. We formulate the problem of designing κ-dimensional sampling manifolds for d-dimensional spatial fields that are minimal in manifold density, a natural generalization of the path density. We show that our results on sampling trajectories for fields in R2 can be generalized to analogous results on d-dimensional sampling manifolds for d-dimensional spatial fields.","Trajectory,
Sensors,
Lattices,
Manifolds,
Measurement,
Image reconstruction,
Vectors"
Dynamic Mix-Zone for Location Privacy in Vehicular Networks,"Location privacy is an important issue in vehicular networks since knowledge of a vehicle's location can result in leakage of sensitive information. In this paper, we propose a method, named Dynamic Mix-zone for Location Privacy (DMLP). With DMLP, a vehicle' s mix-zone is dynamically formed at the time the vehicle requests it. The size of the mix-zone is determined by the vehicle's predicted location, the traffic statistics and the level of vehicle's privacy requirement. In order to provide unlinkability of new and old pseudonyms and locations, DMLP encrypts messages when transmitted while the vehicle is within the mix-zone. Simulation based analysis shows that DMLP offers a high level of location privacy and can be used regardless of the nature of the road at the location of the vehicle,e.g. highway, rural road or street in the downtown area of a city.","Vehicles,
Privacy,
Safety,
Roads,
Encryption,
Monitoring"
Image-Based Model of Atrial Anatomy and Electrical Activation: A Computational Platform for Investigating Atrial Arrhythmia,"Computer models provide a powerful platform for investigating mechanisms that underlie atrial rhythm disturbances. We have used novel techniques to build a structurally-detailed, image-based model of 3-D atrial anatomy. A volume image of the atria from a normal sheep heart was acquired using serial surface macroscopy, then smoothed and down-sampled to 50 μm3 resolution. Atrial surface geometry was identified and myofiber orientations were estimated throughout by eigen-analysis of the 3-D image structure tensor. Sinus node, crista terminalis, pectinate muscle, Bachman's bundle, and pulmonary veins were segmented on the basis of anatomic characteristics. Heterogeneous electrical properties were assigned to this structure and electrical activation was simulated on it at 100 μm3 resolution, using both biophysically-detailed and reduced-order cell activation models with spatially-varying membrane kinetics. We confirmed that the model reproduced key features of the normal spread of atrial activation. Furthermore, we demonstrate that vulnerability to rhythm disturbance caused by structural heterogeneity in the posterior left atrium is exacerbated by spatial variation of repolarization kinetics across this region. These results provide insight into mechanisms that may sustain paroxysmal atrial fibrillation. We conclude that image-based computer models that incorporate realistic descriptions of atrial myofiber architecture and electrophysiologic properties have the potential to analyse and identify complex substrates for atrial fibrillation.",
A User-Customizable Urban Traffic Information Collection Method Based on Wireless Sensor Networks,"Traffic monitoring can efficiently promote urban planning and encourage better use of public transport. Efficient traffic information collection is one important part of traffic monitoring systems. Based on a technique using wireless sensor networks (WSNs), this paper provides a flexible framework for regional traffic information collection in accordance with user request. This framework serves as a basis for future research in designing and implementing traffic monitoring applications. A two-layer network architecture is established for traffic information acquisition in the context of a WSN environment. In addition, a user-customizable data-centric routing scheme is proposed for traffic information delivery, in which multiple routing-related information is considered for decision-making to meet different user requirements. Simulations have shown good performance of the proposed routing scheme compared with other traditional routing schemes on a real-world urban traffic network.","wireless sensor networks,
automated highways,
decision making,
telecommunication network routing,
telecommunication traffic,
traffic information systems"
A Novel Strategy for Three-Phase/Switch/Level (Vienna) Rectifier Under Severe Unbalanced Grids,"Unbalanced grids introduce performance deterioration for Vienna rectifier topology by producing twice fundamental frequency ripples in dc-link voltage and input active/reactive power. A common current reference generation for the purpose of eliminating the input power ripple, such as dual-frame hybrid vector control, can maintain constant input power and eliminate ripples in dc-link voltage under light voltage unbalanced grids. Under severe unbalanced grids, this type of a control method will fail to work. This paper first analyzes the theoretical operation area of a constant power control method under unbalanced grids, and then a novel control method is proposed. The proposed control method can work under severe unbalanced grids by injecting a small amount of input power ripple and balance the performance of working area and output dc voltage ripples. Finally, the experiment results using the constant power control method are given and validate the performance of the proposed control method.","Vectors,
Rectifiers,
Voltage control,
Power control,
Switches,
Equations,
Modulation"
Accounting for Localized Defects in the Optoelectronic Design of Thin-Film Solar Cells,Controlled nanostructuring of thin-film solar cells offers a promising route toward increased efficiency through improved light trapping. Many such light trapping designs involve structuring of the active region itself. Optimization of these designs is aided by the use of computer simulations that account for both the optics and electronics of the device. We describe such a simulation-based approach that accounts for experimental tradeoffs between high-aspect ratio structuring and electronic material quality. Our model explicitly accounts for localized regions of degraded material quality that is induced by light trapping structures in n-i-p a-Si:H solar cells. We find that the geometry of the defects couples to the geometry of light absorption profiles in the active region and that this coupling impacts the spectral response of the device. Our approach yields insights into the nanoscale device physics that is associated with localized geometry-induced defects and provides a framework for full optoelectronic optimization.,"Materials,
Lighting,
Charge carrier processes,
Photovoltaic cells,
Physics,
Geometry,
Mathematical model"
Generating Synthetic Mammograms From Reconstructed Tomosynthesis Volumes,"Digital breast tomosynthesis (DBT) is a promising 3-D modality that may replace mammography in the future. However, lesion search is likely to require more time in DBT volumes, while comparisons between views from different projections and prior exams might be harder to make. This may make screening with DBT cumbersome. A solution may be provided by synthesizing 2-D mammograms from DBT, which may then be used to guide the search for abnormalities. In this work we focus on synthesizing mammograms in which masses and architectural distortions are optimally visualized. Our approach first determines relevant points in a DBT volume with a computer-aided detection system and then renders a mammogram from the intersection of a surface fitted through these points and the DBT volume. The method was evaluated in a pilot observer study where three readers reported mass findings in 87 patients (25 malignant, 62 normal) for which both DBT and digital mammograms were available. We found that on average, diagnostic accuracy in the synthetic mammograms was higher (Az=0.85) than in conventional mammograms (Az=0.81), although the difference was not statistically significant. Preliminary results suggest that the synthesized mammograms are an acceptable alternative for real mammograms regarding the detection of mass lesions.","Design automation,
Lesions,
Three-dimensional displays,
Cancer,
Breast,
Observers,
Sensitivity"
Capacity and Security of Heterogeneous Distributed Storage Systems,"The capacity of heterogeneous distributed storage systems under repair dynamics is studied. Examples of these systems include peer-to-peer storage clouds, wireless, and Internet caching systems. Nodes in a heterogeneous system can have different storage capacities and different repair bandwidths. Lower and upper bounds on the system capacity are given. These bounds depend on either the average resources per node, or on a detailed knowledge of the node characteristics. Moreover, the case in which nodes may be compromised by an adversary (passive or active) is addressed and bounds on the secure capacity of the system are derived. One implication of these new results is that symmetric repair maximizes the capacity of a homogeneous system, which justifies the model widely used in the literature.","Maintenance engineering,
Decision support systems,
Network security,
Peer-to-peer computing,
Upper bound,
Distributed processing,
Cloud computing"
Toward practical MAC design for underwater acoustic networks,"Recently, various Medium Access Control (MAC) protocols have been proposed for underwater acoustic networks. These protocols have significantly improved the performance of MAC layer in theory. However, two critical characteristics, low transmission rates and long preambles, found in the commercial modem-based real systems, drastically degrade the performance of existing MAC protocols in the real world. A new practical MAC design is demanded. Toward a proper approach, this paper analyzes the impact of the two newly found modem characteristics on the random access-based MAC and handshakebased MAC, which are two major types of MAC protocols for underwater acoustic networks. We further develop the nodal throughput and collision probability models for representative solutions of these two MAC protocol types. Based on the analysis, we believe time sharing-based MAC is very promising. Along this line, we propose a time sharing-based MAC and analyze its nodal throughput. Both analytical and simulation results show that the time sharing-based solution can achieve significantly better performance.","Media Access Protocol,
Modems,
Throughput,
Propagation delay,
Delays,
Underwater acoustics"
TAMES: A Truthful Auction Mechanism for heterogeneous spectrum allocation,"Spectrums are heterogeneous, especially from the aspect of their central frequency. According to signal propagation properties, low-frequency spectrum generally has lower path loss, thus longer transmission range, compared with high-frequency spectrum. Cellular operators with different targeted cell size will have different preferences for spectrums with different frequencies. Furthermore, the transmission range also affects the interference relationships among transmitters. Transmitters who can reuse the same high-frequency spectrum may interfere with each other when reusing the low-frequency spectrum, so it is difficult to decide how to construct the interference graph to exploit spectrum reusability among transmitters. Auction is considered as an efficient way for spectrum allocation. However, most of the previous works only considered homogenous spectrum auction, failing to address the problem of spectrum heterogeneity. In this paper, we propose TAMES, a Truthful Auction Mechanism for hEterogeneous Spectrum allocation, which allows buyers to freely express their different preferences towards different spectrums. Frequency-specific interference graphs are constructed to determine buyer groups. The proposed heterogeneous spectrum auction is theoretically proved to be truthful and individual rational. The simulation results verifies that the proposed auction mechanism outperforms other auction mechanisms with homogenous bid or homogenous interference graph. The proposed auction mechanism is able to yield higher buyers' satisfaction, seller's revenue and spectrum utilization.","Interference,
Cost accounting,
Resource management,
Transmitters,
Economics,
Educational institutions,
Simulation"
EMG Signal Decomposition Using Motor Unit Potential Train Validity,"A system to resolve an intramuscular electromyographic (EMG) signal into its component motor unit potential trains (MUPTs) is presented. The system is intended mainly for clinical applications where several physiological parameters of motor units (MUs), such as their motor unit potential (MUP) templates and mean firing rates, are of interest. The system filters an EMG signal, detects MUPs, and clusters and classifies the detected MUPs into MUPTs. Clustering is partially based on the K-means algorithm, and the supervised classification is implemented using a certainty-based algorithm. Both clustering and supervised classification algorithms use MUP shape and MU firing pattern information along with signal dependent assignment criteria to obtain robust performance across a variety of EMG signals. During classification, the validity of extracted MUPTs are determined using several supervised classifiers; invalid trains are corrected and the assignment threshold for each train is adjusted based on the estimated validity (i.e., adaptive classification). Performance of the developed system in terms of accuracy (Ae), assignment rate (Ar), correct classification rate (CCr), and the error in estimating the number of MUPTs represented in the set of detected MUPs (ENMUPTs) was evaluated using 32 simulated and 30 real EMG signals comprised of 3-11 and 3-15 MUPTs, respectively. The developed system, with average CCr of 86.4% for simulated and 96.4% for real data, outperformed a previously developed EMG decomposition system, with average CCr of 71.6% and 89.7% for simulated and real data, by 14.7% and 6.7%, respectively. In terms of ENMUPTs, the new system, with average ENMUPTs of 0.3 and 0.2 for simulated and real data respectively, was better able to estimate the number of MUPTs represented in a set of detected MUPs than the previous system, with average ENMUPTs of 2.2 and 0.8 for simulated and real data respectively. For both the simulated and real data used, variations in Ac, Ar, and ENMUPTs for the newly developed system were lower than for the previous system, which demonstrates that the new system can successfully adjust the assignment criteria based on the characteristics of a given signal to achieve robust performance across a wide variety of EMG signals, which is of paramount importance for successfully promoting the clinical application of EMG signal decomposition techniques.",
Design and dynamics model of a lightweight series elastic tendon-driven robot arm,"This paper presents the design of a lightweight robot arm intended for safe physical human-robot interaction. The robot arm design combines tendon actuation with elasticity in the tendons to achieve a significant reduction in mass and passive compliant behavior. The use of elastic tendons in all joints in order to gain maximum safety and performance properties, however, results in a significant increase of the model complexity with oscillatory behavior and kinematic coupling of the joint equilibrium positions. Therefore, special effort needs to be made to model the robot arm dynamics, which is an essential basis for model-based algorithms utilizing and fully exploiting the particular properties of the robot arm. This paper therefore derives the full dynamics model of the robot arm with focus on the nonlinear elastic tendon actuators, the kinematic tendon coupling, and modeling complexity reduction by reflecting all model parameters to the joint space. The resulting model is validated by comparing the identified simulation model with experimental data of an application-related pick-and-place trajectory and a trajectory with undamped oscillating motions of the robot arm.","Joints,
Tendons,
Robots,
Springs,
Actuators,
Pulleys,
Couplings"
Pricing crowdsourcing-based software development tasks,"Many organisations have turned to crowdsource their software development projects. This raises important pricing questions, a problem that has not previously been addressed for the emerging crowdsourcing development paradigm. We address this problem by introducing 16 cost drivers for crowdsourced development activities and evaluate 12 predictive pricing models using 4 popular performance measures. We evaluate our predictive models on TopCoder, the largest current crowdsourcing platform for software development. We analyse all 5,910 software development tasks (for which partial data is available), using these to extract our proposed cost drivers. We evaluate our predictive models using the 490 completed projects (for which full details are available). Our results provide evidence to support our primary finding that useful prediction quality is achievable (Pred(30)>0.8). We also show that simple actionable advice can be extracted from our models to assist the 430,000 developers who are members of the TopCoder software development market.","Software,
Predictive models,
Pricing,
Software engineering,
Unified modeling language,
Educational institutions,
Linear regression"
A dual-band wireless energy transfer protocol for heterogeneous sensor networks powered by RF energy harvesting,"Radio frequency (RF) energy harvesting promises to realize battery-less sensor networks by converting energy contained in electromagnetic waves into useful electrical energy. We consider a network architecture that allows heterogeneous frequency harvesting. One class of sensors harvests RF energy on the DTV band (614 MHz) while another uses the 915 MHz ISM band. We study the effective energy transfer that is achieved under these circumstances, and then design a link layer protocol called RF-HSN that optimizes the energy delivery to energy-hungry sensors with the optimal duty cycle. To the best of our knowledge, this is the first wireless energy transfer protocol for heterogeneous frequency RF energy harvesting, and through a combination of experimentation and simulation studies, we demonstrate over 59% higher duty cycle and 66% average network throughput improvement over the classical CSMA MAC protocol.","Radio frequency,
Energy harvesting,
Protocols,
Capacitors,
Energy exchange,
Multiaccess communication,
Wireless sensor networks"
On the Throughput and Energy Efficiency of Cognitive MIMO Transmissions,"In this paper, throughput and energy efficiency of cognitive multiple-input-multiple-output (MIMO) systems operating under quality-of-service (QoS) constraints, interference limitations, and imperfect channel sensing are studied. It is assumed that transmission power and covariance of the input signal vectors are varied, depending on the sensed activities of primary users (PUs) in the system. Interference constraints are applied on the transmission power levels of cognitive radios (CRs) to provide protection for the PUs, whose activities are modeled as a Markov chain. Considering the reliability of the transmissions and channel sensing results, a state transition model is provided. Throughput is determined by formulating the effective capacity. The first derivative of the effective capacity is derived in the low-power regime, and the minimum bit energy requirements in the presence of QoS limitations and imperfect sensing results are identified. Minimum energy per bit is shown to be achieved by beamforming in the maximal-eigenvalue eigenspace of certain matrices related to the channel matrix. In a special case, wideband slope is determined for a more refined analysis of energy efficiency. Numerical results are provided for the throughput for various levels of buffer constraints and different number of transmit and receive antennas. The impact of interference constraints and benefits of multiple-antenna transmissions are determined. It is shown that increasing the number of antennas when the interference power constraint is stringent is generally beneficial. On the other hand, it is shown that, under relatively loose interference constraints, increasing the number of antennas beyond a certain level does not lead to much increase in throughput.","Sensors,
MIMO,
Quality of service,
Throughput,
Interference constraints,
Cognitive radio"
Unified Framework for the Synchronization of Flexible Multicarrier Communication Signals,"This paper presents a unified framework for the formulation of synchronization algorithms dealing with the general class of Filter-Bank Multi-Carrier (FBMC) communication signals. This is a wide family of signaling formats that includes Orthogonal Frequency Division Multiplexing (OFDM), for instance, as just one of many particular cases. One of the main contributions of this work is the proposal of a novel matrix signal model for so-called flexible FBMC signals, in which no restrictions are imposed on the signal design parameters (i.e., pulse shaping, symbol rate, carrier spacing, sampling frequency, etc.), unlike the type of multicarrier signals currently deployed. As an example of application of the proposed matrix signal model, blind joint time-delay and frequency estimators will be derived under both the Conditional Maximum Likelihood (CML) and the low-SNR Unconditional Maximum Likelihood (UML) principles, for any FBMC signal propagating through an arbitrary multipath channel. These estimators will be specialized first for the case of critically sampled cyclic-prefix OFDM (CP-OFDM) signals in frequency flat fading, leading to simple architectures amenable to a hardware implementation. Later on, and for the low-SNR UML principle, the special case of critically sampled CP-OFDM in multipath channels will be addressed, where a novel synchronizer will be proposed.","OFDM,
Synchronization,
Unified modeling language,
Maximum likelihood estimation,
Multipath channels,
Modulation,
Matrices"
Large-Signal Performance and Modeling of Intrinsically Switchable Ferroelectric FBARs,"This paper presents the large-signal performance of intrinsically switchable ferroelectric thin-film bulk acoustic resonators (FBARs), as well as their modeling procedure. There has been a growing interest in ferroelectric FBARs due to their electric-field-dependent permittivity and electric-field-induced piezoelectricity. Ferroelectric barium-strontium-titanate (BaxSr(1-x)TiO3) FBARs are intrinsically switchable, namely, they have resonances that switch on with the application of a dc-bias voltage. In this paper, the large-signal performance and nonlinear behavior of ferroelectric BST FBARs are investigated. Measurement results show that the device nonlinearity can be reduced by applying higher dc-bias voltages. Moreover, a large-signal model that accurately describes the dc-bias voltage, as well as RF power-dependent performance of BST FBARs is developed. Large-signal simulation results obtained from this model at different bias voltages and RF power levels show good agreement with the measurement results.","Film bulk acoustic resonators,
Voltage measurement,
Radio frequency,
Mathematical model,
Power measurement,
Integrated circuit modeling,
Resonant frequency"
Downlink Scheduling and Resource Allocation for Cognitive Radio MIMO Networks,"Cognitive radio is regarded as the ideal candidate for enhancing the efficiency of spectrum usage for next-generation wireless systems. In fact, this emerging technology allows unlicensed cognitive users to transmit over frequency bands that are initially owned by license holders through the use of dynamic spectrum sharing. In this paper, we propose a novel algorithm that efficiently solves the problem of spectrum sharing and user scheduling in a cognitive downlink multi-input-multi-output system (MIMO). We study the scenario where primary receivers do not allow any interference from a multiantenna cognitive base station, which serves cognitive users. Using graph theory, we model, formulate, and develop an algorithm that finds near-optimal spectrum sharing with the objective of approaching the maximum achievable secondary sum rate. Since the formulated graph-coloring problem is shown to be NP-hard, we design a low-complexity greedy algorithm. Following, we add the well-known proportional fairness to the proposed algorithm to ensure time-based fairness and to efficiently resolve the fairness/sum rate tradeoff. The problem is also formulated as a binary integer programming problem to find the optimal coloring solution. Computer simulations show that the proposed algorithm is able to achieve near-optimal performances with low computational complexity.","Receivers,
Vectors,
Interference,
Color,
MIMO,
Greedy algorithms,
Array signal processing"
Circular Reranking for Visual Search,"Search reranking is regarded as a common way to boost retrieval precision. The problem nevertheless is not trivial especially when there are multiple features or modalities to be considered for search, which often happens in image and video retrieval. This paper proposes a new reranking algorithm, named circular reranking, that reinforces the mutual exchange of information across multiple modalities for improving search performance, following the philosophy that strong performing modality could learn from weaker ones, while weak modality does benefit from interacting with stronger ones. Technically, circular reranking conducts multiple runs of random walks through exchanging the ranking scores among different features in a cyclic manner. Unlike the existing techniques, the reranking procedure encourages interaction among modalities to seek a consensus that are useful for reranking. In this paper, we study several properties of circular reranking, including how and which order of information propagation should be configured to fully exploit the potential of modalities for reranking. Encouraging results are reported for both image and video retrieval on Microsoft Research Asia Multimedia image dataset and TREC Video Retrieval Evaluation 2007-2008 datasets, respectively.","Visualization,
Search engines,
Convergence,
Complexity theory,
Boosting,
Search problems,
Materials"
A case study of trajectory transfer through non-rigid registration for a simplified suturing scenario,"Suturing is an important yet time-consuming part of surgery. A fast and robust autonomous procedure could reduce surgeon fatigue, and shorten operation times. It could also be of particular importance for suturing in remote tele-surgery settings where latency can complicate the master-slave mode control that is the current practice for robotic surgery with systems like the da Vinci®. We study the applicability of the trajectory transfer algorithm proposed in [12] to the automation of suturing. The core idea of this procedure is to first use non-rigid registration to find a 3D warping function which maps the demonstration scene onto the test scene, then use this warping function to transform the robot end-effector trajectory. Finally a robot joint trajectory is generated by solving a trajectory optimization problem that attempts to find the closest feasible trajectory, accounting for external constraints, such as joint limits and obstacles. Our experiments investigate generalization from a single demonstration to differing initial conditions. A first set of experiments considers the problem of having a simulated Raven II system [5] suture two flaps of tissue together. A second set of experiments considers a PR2 robot performing sutures in a scaled-up experimental setup. The simulation experiments were fully autonomous. For the real-world experiments we provided human input to assist with the detection of landmarks to be fed into the registration algorithm. The success rate for learning from a single demonstration is high for moderate perturbations from the demonstration's initial conditions, and it gradually decreases for larger perturbations.",
Actively linking learning outcomes and competencies to course design and delivery: Experiences from an undergraduate Information Systems program in Singapore,"While numerous Engineering education programs seem to have learning outcomes or competencies defined, in many cases, those learning outcomes or competencies do not have any practical relevance for the course design and delivery lifecycle. This conference contribution reports on curriculum and course design and delivery experiences made within the Bachelor of Science (Information Systems Management) degree program (BSc (ISM)) offered by the School of Information Systems (SIS) at the Singapore Management University (SMU). In particular, this paper focuses on the ongoing efforts to actively link program educational objectives, program level learning outcomes and course level competencies to the actual course design and delivery. Using a large third year core course of the BSc (ISM) program (called Enterprise Web Solutions course) as an example, this paper shows how the learning outcomes defined at the program level enable the cross-course alignment within the program, how the course level competencies support the inner-course content alignment, assessment component design and feedback delivery, and how the actual course delivery process enforces changes in course competencies and even changes in the program level learning outcomes.","Educational institutions,
Information systems,
Engineering education,
Context,
Phase change materials,
Conferences"
FMRI Signal Analysis Using Empirical Mean Curve Decomposition,"Functional magnetic resonance imaging (fMRI) time series is nonlinear and composed of components at multiple temporal scales, which presents significant challenges to its analysis. In the literature, significant effort has been devoted into model-based fMRI signal analysis, while much less attention has been directed to data-driven fMRI signal analysis. In this paper, we present a novel data-driven multiscale signal decomposition framework named empirical mean curve decomposition (EMCD). Targeted on functional brain mapping, the EMCD optimizes mean envelopes from fMRI signals and iteratively extracts coarser-to-finer scale signal components. The EMCD framework was applied to infer meaningful low-frequency information from blood oxygenation level-dependent signals from resting-state fMRI, task-based fMRI, and natural stimulus fMRI, and promising results are obtained.",
SVM Training Phase Reduction Using Dataset Feature Filtering for Malware Detection,"N-gram analysis is an approach that investigates the structure of a program using bytes, characters, or text strings. A key issue with N-gram analysis is feature selection amidst the explosion of features that occurs when N is increased. The experiments within this paper represent programs as operational code (opcode) density histograms gained through dynamic analysis. A support vector machine is used to create a reference model, which is used to evaluate two methods of feature reduction, which are “area of intersect” and “subspace analysis using eigenvectors.” The findings show that the relationships between features are complex and simple statistics filtering approaches do not provide a viable approach. However, eigenvector subspace analysis produces a suitable filter.","Malware,
Support vector machines,
Kernel,
Training,
Materials,
Filtering"
Obtaining ground-truth software architectures,"Undocumented evolution of a software system and its underlying architecture drives the need for the architecture's recovery from the system's implementation-level artifacts. While a number of recovery techniques have been proposed, they suffer from known inaccuracies. Furthermore, these techniques are difficult to evaluate due to a lack of “ground-truth” architectures that are known to be accurate. To address this problem, we argue for establishing a suite of ground-truth architectures, using a recovery framework proposed in our recent work. This framework considers domain-, application-, and context-specific information about a system, and addresses an inherent obstacle in establishing a ground-truth architecture - the limited availability of engineers who are closely familiar with the system in question. In this paper, we present our experience in recovering the ground-truth architectures of four open-source systems. We discuss the primary insights gained in the process, analyze the characteristics of the obtained ground-truth architectures, and reflect on the involvement of the systems' engineers in a limited but critical fashion. Our findings suggest the practical feasibility of obtaining ground-truth architectures for large systems and encourage future efforts directed at establishing a large scale repository of such architectures.","Computer architecture,
Documentation,
Java,
Protocols,
Web servers,
Software systems"
Continuous Authentication Using Behavioral Biometrics,"A continuous behaviometric authentication system is tested on 99 users over 10 weeks, focusing on keystroke dynamics, mouse movements, application usage, and the system footprint. In the process, a new trust model was created to enable continuous evaluation of the behaviometric data. Tests targeted keystroke dynamics, mouse movements, application usage, and the system footprint. Keystroke dynamics was found most appropriate for continuous behaviometric authentication, with no false rejects. This article is part of a special issue on security.",
Non-determinism and overcount on modern hardware performance counter implementations,"Ideal hardware performance counters provide exact deterministic results. Real-world performance monitoring unit (PMU) implementations do not always live up to this ideal. Events that should be exact and deterministic (such as retired instructions) show run-to-run variation and overcount on ×86_64 machines, even when run in strictly controlled environments. These effects are non-intuitive to casual users and cause difficulties when strict determinism is desirable, such as when implementing deterministic replay or deterministic threading libraries. We investigate eleven different x86 64 CPU implementations and discover the sources of divergence from expected count totals. Of all the counter events investigated, we find only a few that exhibit enough determinism to be used without adjustment in deterministic execution environments. We also briefly investigate ARM, IA64, POWER and SPARC systems and find that on these platforms the counter events have more determinism. We explore various methods of working around the limitations of the ×86_64 events, but in many cases this is not possible and would require architectural redesign of the underlying PMU.",
3D-2D Registration of Cerebral Angiograms: A Method and Evaluation on Clinical Images,"Endovascular image-guided interventions (EIGI) involve navigation of a catheter through the vasculature followed by application of treatment at the site of anomaly using live 2D projection images for guidance. 3D images acquired prior to EIGI are used to quantify the vascular anomaly and plan the intervention. If fused with the information of live 2D images they can also facilitate navigation and treatment. For this purpose 3D-2D image registration is required. Although several 3D-2D registration methods for EIGI achieve registration accuracy below 1 mm, their clinical application is still limited by insufficient robustness or reliability. In this paper, we propose a 3D-2D registration method based on matching a 3D vasculature model to intensity gradients of live 2D images. To objectively validate 3D-2D registration methods, we acquired a clinical image database of 10 patients undergoing cerebral EIGI and established “gold standard” registrations by aligning fiducial markers in 3D and 2D images. The proposed method had mean registration accuracy below 0.65 mm, which was comparable to tested state-of-the-art methods, and execution time below 1 s. With the highest rate of successful registrations and the highest capture range the proposed method was the most robust and thus a good candidate for application in EIGI.","Image segmentation,
Solid modeling,
Feature extraction,
Robustness,
Gold,
Standards,
X-ray imaging"
"Degrees of Freedom of MIMO
X
Networks: Spatial Scale Invariance and One-Sided Decomposability","We show that an M×N user MIMO X network with A antennas at each node has A(MN/(M+N-1)) degrees of freedom (DoF), thus resolving in this case a discrepancy between the spatial scale invariance conjecture (scaling the number of antennas at each node by a constant factor will scale the total DoF by the same factor) and a decomposability property of overconstrained wireless networks. While the best previously known general DoF outer bound is consistent with the spatial invariance conjecture, the best previously known general DoF inner bound, inspired by the K user MIMO interference channel, was based on the decomposition of every transmitter and receiver into multiple single antenna nodes, transforming the network into an AM×AN user SISO X network. While such a decomposition is DoF optimal for the K user MIMO interference channel, a gap remained between the best inner and outer bounds for the MIMO X channel. Here we close this gap with the new insight that the MIMO X network is only one-sided decomposable, i.e., either all the transmitters or all the receivers (but not both) can be decomposed by splitting multiple antenna nodes into multiple single antenna nodes without loss of DoF. The result is extended to SIMO and MISO X networks as well and in each case the DoF results satisfy the spatial scale invariance property.","MIMO,
Interference,
Receiving antennas,
Transmitting antennas"
Finding connected components in map-reduce in logarithmic rounds,"Given a large graph G = (V, E) with millions of nodes and edges, how do we compute its connected components efficiently? Recent work addresses this problem in map-reduce, where a fundamental trade-off exists between the number of map-reduce rounds and the communication of each round. Denoting d the diameter of the graph, and n the number of nodes in the largest component, all prior techniques for map-reduce either require a linear, Θ(d), number of rounds, or a quadratic, Θ (n|V| + |E|), communication per round. We propose here two efficient map-reduce algorithms: (i) Hash-Greater-to-Min, which is a randomized algorithm based on PRAM techniques, requiring O(log n) rounds and O(|V | + |E|) communication per round, and (ii) Hash-to-Min, which is a novel algorithm, provably finishing in O(log n) iterations for path graphs. The proof technique used for Hash-to-Min is novel, but not tight, and it is actually faster than Hash-Greater-to-Min in practice. We conjecture that it requires 2 log d rounds and 3(|V| + |E|) communication per round, as demonstrated in our experiments. Using secondary sorting, a standard map-reduce feature, we scale Hash-to-Min to graphs with very large connected components. Our techniques for connected components can be applied to clustering as well. We propose a novel algorithm for agglomerative single linkage clustering in map-reduce. This is the first map-reduce algorithm for clustering in at most O(log n) rounds, where n is the size of the largest cluster. We show the effectiveness of all our algorithms through detailed experiments on large synthetic as well as real-world datasets.",
Spatiotemporal Smoothing as a Basis for Facial Tissue Tracking in Thermal Imaging,"Accurate tracking of facial tissue in thermal infrared imaging is challenging because it is affected not only by positional but also physiological (functional) changes. This paper presents a particle filter tracker driven by a probabilistic template function with both spatial and temporal smoothing components, which is capable of adapting to abrupt positional and physiological changes. The method was tested on tracking facial regions of subjects under varying physiological and environmental conditions in 25 thermal clips. It demonstrated robustness and accuracy, outperforming other strategies. This new method promises improved performance in a number of biomedical applications that involve physiological measurements on the face, such as unobtrusive sleep and stress studies.","Target tracking,
Physiology,
Imaging,
Visualization,
Stress,
Cost function"
TESLA-Based Homomorphic MAC for Authentication in P2P System for Live Streaming with Network Coding,"Recently, the peer-to-peer (P2P) live streaming system has benefited from the advent of network coding. However, it was demonstrated that malicious nodes could significantly reduce the network throughput by launching pollution attacks or entropy attacks. In this paper, we propose an efficient symmetric-key based authentication scheme for P2P live streaming system with network coding, to provide in-network detection against pollution attacks and entropy attacks simultaneously. Since the nature of P2P live streaming requires that the detection scheme has high computation efficiency and small communication overheads, we firstly propose a homomorphic message authentication code (MAC), called as PMAC, which has small key size and low computation overhead. Then, the proposed PMAC and the delayed key disclosure technique are employed to make sure that the peers could not only detect the corrupted blocks, but also upload blocks in accordance with random linear network coding. Furthermore, the performance evaluation demonstrates that the proposed scheme has both low communication and computation overheads.","Peer-to-peer computing,
Network coding,
Games,
Pollution,
Authentication,
Vectors,
Entropy"
Phasor measurement units for the distribution grid: Necessity and benefits,"High penetration levels of distributed energy resources (DER) and active loads in the distribution grid can change the traditional grid from a slower-changing radial network to a multi-source network with faster dynamics. Although overall system reliability and quality of supply can in principle be improved under this paradigm, new control and protection challenges could arise that may not be adequately addressed using the traditional approaches. The conventional control and management of the distribution grid where only voltage magnitudes are measured and utilized at the control center could undermine these new dynamics and may potentially lead to severe complications in grid operation. A system-wide dynamic analysis and control of the distribution grid therefore seems crucial for optimal system operation. This would require new phasor data, coming from Phasor Measurement Units (PMU), to be incorporated into the functions of Distribution Management System (DMS). This paper discusses the potential applications within the DMS that can benefit from PMU data.","Phasor measurement units,
Voltage measurement,
Vehicle dynamics,
Wind,
Density estimation robust algorithm,
Current measurement,
Load modeling"
Intrinsic Image Decomposition Using Optimization and User Scribbles,"In this paper, we present a novel high-quality intrinsic image recovery approach using optimization and user scribbles. Our approach is based on the assumption of color characteristics in a local window in natural images. Our method adopts a premise that neighboring pixels in a local window having similar intensity values should have similar reflectance values. Thus, the intrinsic image decomposition is formulated by minimizing an energy function with the addition of a weighting constraint to the local image properties. In order to improve the intrinsic image decomposition results, we further specify local constraint cues by integrating the user strokes in our energy formulation, including constant-reflectance, constant-illumination, and fixed-illumination brushes. Our experimental results demonstrate that the proposed approach achieves a better recovery result of intrinsic reflectance and illumination components than the previous approaches.","Lighting,
Image decomposition,
Image color analysis,
Optimization,
Brushes,
Equations,
Image sequences"
Feature Denoising Using Joint Sparse Representation for In-Car Speech Recognition,"We address reducing the mismatch between training and testing conditions for hands-free in-car speech recognition. It is well known that the distortions caused by background noise, channel effects, etc., are highly nonlinear in the log-spectral or cepstral domain. This letter introduces a joint sparse representation (JSR) to estimate the underlying clean feature vector from a noisy feature vector. Performing a joint dictionary learning by sharing the same representation coefficients, the proposed method intends to capture the complex relationships (or mapping functions) between clean and noisy speech. Speech recognition experiments on realistic in-car data demonstrate that the proposed method shows excellent recognition performance with a relative improvement of 39.4% compared with the “baseline” frontends.","Speech,
Noise measurement,
Speech recognition,
Dictionaries,
Training,
Joints,
Testing"
The use of a mobile sink for quality data collection in energy harvesting sensor networks,"In this paper we study data collection in an energy harvesting sensor network where sensors are deployed along a given path and a mobile sink travels along the path periodically for data collection. Such a typical application scenario is to employ a mobile vehicle for traffic surveillance of a given highway. As the sensors in this network are powered by renewable energy sources, the time-varying characteristics of energy harvesting poses great challenges on the design of efficient routing protocols for data collection in harvesting sensor networks. In this paper we first formulate a novel optimization problem as a network utility maximization problem, by incorporating multi-rate communication mechanism between sensors and the mobile sink and show the NP-hardness of the problem. We then devise a novel centralized algorithm for it, assuming that the global knowledge of the entire network is available. We also develop a distributed solution to the problem without the global knowledge assumption. We finally conduct extensive experiments by simulations to evaluate the performance of the proposed algorithms. The experimental results demonstrate that the proposed algorithms are promising and very efficient.","Mobile communication,
Mobile computing,
Energy harvesting,
Data collection,
Energy consumption,
Knowledge engineering,
Resource management"
Various Approaches for Driver and Driving Behavior Monitoring: A Review,"In recent years, driver drowsiness and distraction have been important factors in a large number of accidents because they reduce driver perception level and decision making capability, which negatively affect the ability to control the vehicle. One way to reduce these kinds of accidents would be through monitoring driver and driving behavior and alerting the driver when they are drowsy or in a distracted state. In addition, if it were possible to predict unsafe driving behavior in advance, this would also contribute to safe driving. In this paper, we will discuss various monitoring methods for driver and driving behavior as well as for predicting unsafe driving behaviors. In respect to measurement methods of driver drowsiness, we discussed visual and non-visual features of driver behavior, as well as driving performance behaviors related to vehicle-based features. Visual feature measurements such as eye related measurements, yawning detection, facial expression are discussed in detail. As for non-visual features, we explore various physiological signals and possible drowsiness detection methods that use these signals. As for vehicle-based features, we describe steering wheel movement and the standard deviation of lateral position. To detect driver distraction, we describe head pose and gaze direction methods. To predict unsafe driving behavior, we explain predicting methods based on facial expressions and car dynamics. Finally, we discuss several issues to be tackled for active driver safety systems. They are 1) hybrid measures for drowsiness detection, 2) driving context awareness for safe driving, 3) the necessity for public data sets of simulated and real driving conditions.","Vehicles,
Feature extraction,
Monitoring,
Accidents,
Visualization,
Head,
Wheels"
"Efficient, High Directivity, Large Front-to-Back-Ratio, Electrically Small, Near-Field-Resonant-Parasitic Antenna","Enhancements of the directivity and front-to-back ratio (FTBR) of a metamaterial-inspired electrically small, linearly polarized, coaxially-fed Egyptian axe dipole antenna are considered. They are accomplished with a particular augmentation of the original near-field-resonant-parasitic (NFRP) antenna with an additional NFRP element, a small disc conductor modified with two meanderline-shaped slots. The entire system is evaluated numerically with two independent computational electromagnetics simulators. The optimized results demonstrate an electrically small antenna (i.e., ka <; 1.0) with a reasonably low profile (i.e., height ~ λ/10) that improves the directivity from 1.77 to 6.32 dB, increases the FTBR from 0 to > 20 dB, and maintains large half-power beamwidths, while having a radiation efficiency over 80% with nearly complete matching to a 50 Ω source.","Slot antennas,
Dipole antennas,
Metamaterials,
Resonant frequency,
Antenna measurements,
Bandwidth,
Polarization,
Parasitic capacitance"
Design and verification of smart and scalable DC microgrids for emerging regions,"Roughly 1.3 billion people in developing countries still live without access to reliable electricity. As expanding access using current technologies will accelerate global climate change, there is a strong need for novel solutions that displace fossil fuels and are financially viable for developing regions. A novel DC microgrid solution that is geared at maximizing efficiency and reducing system installation cost is described in this paper. Relevant simulation and experimental results, as well as a proposal for undertaking field-testing of the technical and economic viability of the microgrid system are presented.","Phasor measurement units,
Microgrids,
Voltage control,
Bridge circuits,
Batteries,
Home appliances,
Aggregates"
Universal Chroma Subsampling Strategy for Compressing Mosaic Video Sequences With Arbitrary RGB Color Filter Arrays in H.264/AVC,"In this paper, we propose a universal chroma subsampling strategy for compressing mosaic video sequences with arbitrary red-green-blue (RGB) color filter arrays (CFAs), which are widely used in the single sensor imaging pipeline, in H.264/AVC. We first develop a modified universal demosaicing scheme, which specifically recovers the G component in the color difference domain, to recover the missing color components in the input mosaic image frames. Then, based on the transform between the RGB and the YUV color spaces, the proposed universal subsampling strategy automatically samples, by considering the significance of the U and V components for reconstructing R and B pixels, the proper U and V chroma components according to the corresponding mosaic structure. To the best of our knowledge, this is the first universal chroma subsampling strategy designed specifically for mosaic video sequences with arbitrary RGB-CFAs. Experimental results on mosaic video sequences with seven common types of the RGB-CFAs demonstrate that the proposed universal chroma subsampling strategy is superior to the conventional strategy of H.264/AVC. Moreover, integrating the proposed universal demosaicing scheme and the chroma subsampling strategy can deliver better video sequence quality.","Image color analysis,
Video sequences,
Image reconstruction,
Image coding,
Decoding,
Frequency modulation,
Cameras"
Interactive CT-Video Registration for the Continuous Guidance of Bronchoscopy,"Bronchoscopy is a major step in lung cancer staging. To perform bronchoscopy, the physician uses a procedure plan, derived from a patient's 3D computed-tomography (CT) chest scan, to navigate the bronchoscope through the lung airways. Unfortunately, physicians vary greatly in their ability to perform bronchoscopy. As a result, image-guided bronchoscopy systems, drawing upon the concept of CT-based virtual bronchoscopy (VB), have been proposed. These systems attempt to register the bronchoscope's live position within the chest to a CT-based virtual chest space. Recent methods, which register the bronchoscopic video to CT-based endoluminal airway renderings, show promise but do not enable continuous real-time guidance. We present a CT-video registration method inspired by computer-vision innovations in the fields of image alignment and image-based rendering. In particular, motivated by the Lucas-Kanade algorithm, we propose an inverse-compositional framework built around a gradient-based optimization procedure. We next propose an implementation of the framework suitable for image-guided bronchoscopy. Laboratory tests, involving both single frames and continuous video sequences, demonstrate the robustness and accuracy of the method. Benchmark timing tests indicate that the method can run continuously at 300 frames/s, well beyond the real-time bronchoscopic video rate of 30 frames/s. This compares extremely favorably to the ≥1 s/frame speeds of other methods and indicates the method's potential for real-time continuous registration. A human phantom study confirms the method's efficacy for real-time guidance in a controlled setting, and, hence, points the way toward the first interactive CT-video registration approach for image-guided bronchoscopy. Along this line, we demonstrate the method's efficacy in a complete guidance system by presenting a clinical study involving lung cancer patients.","Bronchoscopy,
Cameras,
Streaming media,
Computed tomography,
Navigation,
Real-time systems"
Energy-Efficient Scheduling in Nonpreemptive Systems With Real-Time Constraints,"In the past decade, the development of mobile and embedded systems has demanded energy efficiency for improving the lifetime of embedded devices. To avoid preemption overhead or ease timing verification, nonpreemptive scheduling has been deemed useful or necessary in meeting system timing requirements for certain applications built on embedded devices. In this paper, our aim is to design nonpreemptive scheduling algorithms that ensure timing correctness and optimize energy consumption on a processor with variable speeds. We propose a representative algorithm, ISA, which can produce lower speeds for a variety of nonpreemptive task sets than other comparable methods, and hence resulting in significant energy savings. When combined with a selective frequency-inheritance policy we design to efficiently determine if processor speedup can be disabled without jeopardizing any task deadlines, ISA can achieve even larger gains, up to 30% reduction in energy consumption. Finally, we propose a dynamic slack reclamation policy built on ISA, namely ISA-DR, which can result in additional energy savings when a task consumes less than its worst-case execution time.","Processor scheduling,
Silicon,
Job shop scheduling,
Algorithm design and analysis,
Partial discharges,
Energy consumption"
Distributed Antenna Systems in Fractional-Frequency-Reuse-Aided Cellular Networks,"Distributed antenna system (DAS)-aided unity frequency reuse (UFR) and fractional frequency reuse (FFR) transmission scenarios are investigated in this paper, employing the classic multiobjective of nondominated sorting genetic algorithm II (NSGA-II) for maximizing cell throughput and the coverage. More specifically, coordinated multipoint (CoMP) cooperation is invoked among the distributed antennas (DAs) and the base station (BS) in support of the mobile stations (MSs) roaming at the cell edge, while considering a range of practical impairments. We demonstrate that the received signal-to-interference ratio (SIR) of non-CoMP transmissions follows the lognormal distribution by taking into account both fast fading and large-scale shadowing and path-loss effects. Our simulation results demonstrate that DAS-aided cooperation is capable of achieving a fivefold increased throughput over that of the traditional arrangement. Explicitly, an average throughput per channel of 6.61 bits/symbol may be achieved.","Computer architecture,
Microprocessors,
Throughput,
Optimization,
Approximation methods"
Evaluation of Breast Cancer Susceptibility Using Improved Genetic Algorithms to Generate Genotype SNP Barcodes,"Genetic association is a challenging task for the identification and characterization of genes that increase the susceptibility to common complex multifactorial diseases. To fully execute genetic studies of complex diseases, modern geneticists face the challenge of detecting interactions between loci. A genetic algorithm (GA) is developed to detect the association of genotype frequencies of cancer cases and noncancer cases based on statistical analysis. An improved genetic algorithm (IGA) is proposed to improve the reliability of the GA method for high-dimensional SNP-SNP interactions. The strategy offers the top five results to the random population process, in which they guide the GA toward a significant search course. The IGA increases the likelihood of quickly detecting the maximum ratio difference between cancer cases and noncancer cases. The study systematically evaluates the joint effect of 23 SNP combinations of six steroid hormone metabolisms, and signaling-related genes involved in breast carcinogenesis pathways were systematically evaluated, with IGA successfully detecting significant ratio differences between breast cancer cases and noncancer cases. The possible breast cancer risks were subsequently analyzed by odds-ratio (OR) and risk-ratio analysis. The estimated OR of the best SNP barcode is significantly higher than 1 (between 1.15 and 7.01) for specific combinations of two to 13 SNPs. Analysis results support that the IGA provides higher ratio difference values than the GA between breast cancer cases and noncancer cases over 3-SNP to 13-SNP interactions. A more specific SNP-SNP interaction profile for the risk of breast cancer is also provided.","Breast cancer,
Genetic algorithms,
Genetics,
Cancer,
Classification"
Successive AF/DF Relaying in the Cooperative DS-CDMA Uplink: Capacity Analysis and Its System Architecture,"A successive-relaying-aided network (SRAN) is designed for a multiuser spread-spectrum scenario conceived for noncoherent (NC) detection to convert the typical 50% half-duplex relaying induced throughput loss to a potential user-load reduction of the code-division multiple-access (CDMA) system, where the NC allows us to avoid the extra power consumption imposed by channel estimation. We commence by evaluating the NC discrete-input-continuous-output memoryless channel (DCMC) capacity of both the amplify-and-forward-based (AF) and decode-and-forward-based (DF) SRANs in the direct-sequence CDMA (DS-CDMA) uplink (UL). While NC detection has the added benefit of eliminating both the pilot overhead and the power-hungry channel estimation, it tends to form an error floor at high Doppler frequencies. We mitigate this problem using multiple-symbol detection, which increases the detection complexity upon extending the detection window. Finally, a relay-aided soft-input-soft-output multiple-symbol differential sphere detection (SISO-MSDSD) CDMA regime is proposed, which significantly reduces the system's complexity without sacrificing its performance.","Multiaccess communication,
Interference,
Noise,
Tin,
Relays,
Vectors"
Rate-Distortion Optimized Rate Control for Depth Map-Based 3-D Video Coding,"In this paper, a novel rate control scheme with optimized bits allocation for the 3-D video coding is proposed. First, we investigate the R-D characteristics of the texture and depth map of the coded view, as well as the quality dependency between the virtual view and the coded view. Second, an optimal bit allocation scheme is developed to allocate target bits for both the texture and depth maps of different views. Meanwhile, a simplified model parameter estimation scheme is adopted to speed up the coding process. Finally, the experimental results on various 3-D video sequences demonstrate that the proposed algorithm achieves excellent R-D efficiency and bit rate accuracy compared to benchmark algorithms.","Bit rate,
Video coding,
Receivers,
Encoding,
PSNR,
Approximation methods,
Video sequences"
Achieving Efficient Flooding by Utilizing Link Correlation in Wireless Sensor Networks,"Although existing flooding protocols can provide efficient and reliable communication in wireless sensor networks on some level, further performance improvement has been hampered by the assumption of link independence, which requires costly acknowledgments (ACKs) from every receiver. In this paper, we present collective flooding (CF), which exploits the link correlation to achieve flooding reliability using the concept of collective ACKs. CF requires only 1-hop information at each node, making the design highly distributed and scalable with low complexity. We evaluate CF extensively in real-world settings, using three different types of testbeds: a single-hop network with 20 MICAz nodes, a multihop network with 37 nodes, and a linear outdoor network with 48 nodes along a 326-m-long bridge. System evaluation and extensive simulation show that CF achieves the same reliability as state-of-the-art solutions while reducing the total number of packet transmission and the dissemination delay by 30%-50% and 35%-50%, respectively.","Receivers,
Correlation,
Protocols,
Reliability,
Wireless sensor networks,
Probabilistic logic,
IEEE 802.15 Standards"
Real-Time Detection System of Driver Distraction Using Machine Learning,"There is accumulating evidence that driver distraction is a leading cause of vehicle crashes and incidents. In particular, increased use of so-called in-vehicle information systems (IVIS) and partially autonomous driving assistance systems (PADAS) have raised important and growing safety concerns. Thus, detecting the driver's state is of paramount importance, to adapt IVIS and PADAS accordingly, therefore avoiding or mitigating their possible negative effects. The purpose of this paper is to show a method for the nonintrusive and real-time detection of visual distraction, using vehicle dynamics data and without using the eye-tracker data as inputs to classifiers. Specifically, we present and compare different models that are based on well-known machine learning (ML) methods. Data for training the models were collected using a static driving simulator, with real human subjects performing a specific secondary task [i.e., a surrogate visual research task (SURT)] while driving. Different training methods, model characteristics, and feature selection criteria have been compared. Based on our results, using a support vector machine (SVM) has outperformed all the other ML methods, providing the highest classification rate for most of the subjects. Potential applications of this paper include the design of an adaptive IVIS and of a “smarter” PADAS.","Vehicles,
Visualization,
Fuzzy logic,
Artificial neural networks,
Training,
Safety,
Real-time systems"
Detection of Correlated Alarms Based on Similarity Coefficients of Binary Data,"This paper studies the statistical analysis for alarm signals in order to detect whether two alarm signals are correlated. First, a similarity measurement, namely, Sorgenfrei coefficient, is selected among 22 similarity coefficients for binary data in the literature. The selection is based on the desired properties associated with specialities of alarm signals. Second, the distribution of a so-called correlation delay is shown to be indispensable and effective for the detection of correlated alarms. Finally, a novel method for detection of correlated alarms is proposed based on Sorgenfrei coefficient and distribution of the correlation delay. Numerical and industrial examples are provided to illustrate and validate the obtained results.","Correlation,
Random variables,
Statistical analysis,
Alarm systems,
Monte Carlo methods"
Reinforced Similarity Integration in Image-Rich Information Networks,"Social multimedia sharing and hosting websites, such as Flickr and Facebook, contain billions of user-submitted images. Popular Internet commerce websites such as Amazon.com are also furnished with tremendous amounts of product-related images. In addition, images in such social networks are also accompanied by annotations, comments, and other information, thus forming heterogeneous image-rich information networks. In this paper, we introduce the concept of (heterogeneous) image-rich information network and the problem of how to perform information retrieval and recommendation in such networks. We propose a fast algorithm heterogeneous minimum order k-SimRank (HMok-SimRank) to compute link-based similarity in weighted heterogeneous information networks. Then, we propose an algorithm Integrated Weighted Similarity Learning (IWSL) to account for both link-based and content-based similarities by considering the network structure and mutually reinforcing link similarity and feature weight learning. Both local and global feature learning methods are designed. Experimental results on Flickr and Amazon data sets show that our approach is significantly better than traditional methods in terms of both relevance and speed. A new product search and recommendation system for e-commerce has been implemented based on our algorithm.","Complexity theory,
Semantics,
Mathematical model,
Visualization,
Information retrieval,
Image edge detection,
Information networks,
Ranking systems"
A General Adaptive Digital Predistortion Architecture for Stand-Alone RF Power Amplifiers,"This paper presents a general architecture of adaptive digital predistorter (DPD) for stand-alone radio frequency (RF) power amplifiers (PAs). The input and output of the proposed architecture are both RF signals, which is compatible with a stand-alone PA. This DPD system consists of three parts: the RF PA for linearization, RF front-ends with two down-conversion paths and one up-conversion path, and a field-programmable gate array (FPGA) board with ADC/DACs. This architecture enjoys the cost and performance advantages of the adaptive digital baseband predistortion while extending the DPD coverage to the general PA applications with direct RF input and output. A DPD prototype for stand-alone PAs is implemented. Performance improvement of the proposed architecture is validated by measurement results on a typical base-station PA. Experimental results demonstrate the generality of the proposed DPD architecture by comparing the performance with the conventional DPD system.","Radio frequency,
Estimation,
Baseband,
Predistortion,
Delays,
Computer architecture,
Adaptation models"
Classification of Time Series of Multispectral Images With Limited Training Data,"Image classification usually requires the availability of reliable reference data collected for the considered image to train supervised classifiers. Unfortunately when time series of images are considered, this is seldom possible because of the costs associated with reference data collection. In most of the applications it is realistic to have reference data available for one or few images of a time series acquired on the area of interest. In this paper, we present a novel system for automatically classifying image time series that takes advantage of image(s) with an associated reference information (i.e., the source domain) to classify image(s) for which reference information is not available (i.e., the target domain). The proposed system exploits the already available knowledge on the source domain and, when possible, integrates it with a minimum amount of new labeled data for the target domain. In addition, it is able to handle possible significant differences between statistical distributions of the source and target domains. Here, the method is presented in the context of classification of remote sensing image time series, where ground reference data collection is a highly critical and demanding task. Experimental results show the effectiveness of the proposed technique. The method can work on multimodal (e.g., multispectral) images.","time series,
geophysical image processing,
image classification,
remote sensing,
statistical distributions"
A modulation reconfiguration based fault-tolerant control scheme for modular multilevel converters,A modulation reconfiguration based fault-tolerant method is proposed for the modular multilevel converter (MMC) system. A practical method to reconfigure the reference sine wave is proposed from the point of view that the output line-to-line voltages should be guaranteed to be well regulated and not vary. Voltage balancing for sub-module capacitors is achieved while using carrier rotation algorithm based multicarrier pulse width modulation. Experimental results obtained from the laboratory system verified the validity and reliability of the proposed fault-tolerant control algorithm in the MMC application.,"resource allocation,
capacitors,
fault tolerance,
PWM power convertors"
Compiler assisted dynamic register file in GPGPU,"The large Register File (RF) in General Purpose Graphic Processing Units (GPGPUs) demands tremendous chip area and energy consumption. For a sustainable growth of the size of RF in future GPGPUs, emerging on-chip memory technologies such as embedded-DRAM (eDRAM) have been proposed to replace the conventional SRAM for higher density and lower leakage but with the possible penalty from the periodic refresh operations. This paper explicitly shows that the refresh penalty can be effectively mitigated by leveraging the uniqueness of GPGPU operations. A compiler assisted refresh rescheduling policy can greatly reduce the refresh overhead for maintaining the correctness of the RF operations. The proposed scheme adequately exploits the features in both architecture and compilation, and delivers comparable performance to the SRAM counterpart. At the same time, the energy savings via the removal of large SRAM leakage well compensate for the additional refresh energy. This study promotes the eDRAM-based RF as a promising alternative that enables larger capacity and better power efficiency for future GPGPUs.","Radio frequency,
Registers,
Random access memory,
Hardware,
Pipelines,
Energy consumption,
Runtime"
Rolling Friction Model-Based Analyses and Compensation for Slow Settling Response in Precise Positioning,"This paper presents rolling friction model-based analyses and compensation for slow settling responses in the precise positioning of linear motor-driven table systems. Rolling friction in the table drive mechanisms generates nonlinear elastic friction force in the micro displacement region. The nonlinear behavior causes slow responses at the settling region, deteriorating the fine positioning performance. Effects of the rolling friction on the positioning, therefore, should be analytically examined and compensated to provide the desired control performance. In this research, therefore, a rolling friction model-based analyses and compensation for the slow settling response are presented to improve the precise positioning performance. The proposed examinations and friction compensation for the slow settling response have been verified by numerical simulations and experiments using a prototype of table drive systems.","Friction,
Rheology,
Gain,
Resonant frequency,
Poles and zeros,
Vibrations,
Transient analysis"
Efficient Signcryption for Heterogeneous Systems,"Privacy and authentication are the two main security goals in secure communications. To solve the secure communications problem between two heterogeneous systems, we propose two efficient signcryption schemes that can simultaneously achieve confidentiality, integrity, authentication, and nonrepudiation in a logical single step. The first scheme allows a sender in a public key infrastructure (PKI) to send a message to a receiver in an identity-based cryptosystem (IBC) and the second scheme allows a sender in the IBC system to send a message to a receiver in the PKI system. We prove that the first scheme has indistinguishability against adaptive chosen ciphertext attacks (IND-CCA2) under the q-bilinear Diffie-Hellman inversion problem (q-BDHIP) and existential unforgeability against adaptive chosen messages attacks (EUF-CMA) under the Diffie-Hellman inversion problem in the random oracle model. We also prove that the second scheme has the IND-CCA2 property under the BDHIP and EUF-CMA property under the q-strong Diffie- Hellman problem (q-SDHP) in the random oracle model.","Receivers,
Public key,
Games,
Generators,
Authentication"
Automatic recovery from runtime failures,"We present a technique to make applications resilient to failures. This technique is intended to maintain a faulty application functional in the field while the developers work on permanent and radical fixes. We target field failures in applications built on reusable components. In particular, the technique exploits the intrinsic redundancy of those components by identifying workarounds consisting of alternative uses of the faulty components that avoid the failure. The technique is currently implemented for Java applications but makes little or no assumptions about the nature of the application, and works without interrupting the execution flow of the application and without restarting its components. We demonstrate and evaluate this technique on four mid-size applications and two popular libraries of reusable components affected by real and seeded faults. In these cases the technique is effective, maintaining the application fully functional with between 19% and 48% of the failure-causing faults, depending on the application. The experiments also show that the technique incurs an acceptable runtime overhead in all cases.","Libraries,
Redundancy,
Runtime,
Java,
Software,
Encapsulation"
Design and implementation of a group-based RO PUF,"The silicon physical unclonable functions (PUF) utilize the uncontrollable variations during integrated circuit (IC) fabrication process to facilitate security related applications such as IC authentication. In this paper, we describe a new framework to generate secure PUF secret from ring oscillator (RO) PUF with improved hardware efficiency. Our work is based on the recently proposed group-based RO PUF with the following novel concepts: an entropy distiller to filter the systematic variation; a simplified grouping algorithm to partition the ROs into groups; a new syndrome coding scheme to facilitate error correction; and an entropy packing method to enhance coding efficiency and security. Using RO PUF dataset available in the public domain, we demonstrate these concepts can create PUF secret that can pass the NIST randomness and stability tests. Compared to other state-of-the-art RO PUF design, our approach can generate an average of 72% more PUF secret with the same amount of hardware.","Error correction codes,
Security,
Encoding,
Frequency measurement,
Fabrication,
Systematics,
Temperature measurement"
Transparent computing: Spatio-temporal extension on von Neumann architecture for cloud services,"The rapid advancements in hardware, software, and computer networks have facilitated the shift of the computing paradigm from mainframe to cloud computing, in which users can get their desired services anytime, anywhere, and by any means. However, cloud computing also presents many challenges, one of which is the difficulty in allowing users to freely obtain desired services, such as heterogeneous OSes and applications, via different light-weight devices. We have proposed a new paradigm by spatio-temporally extending the von Neumann architecture, called transparent computing, to centrally store and manage the commodity programs including OS codes, while streaming them to be run in non-state clients. This leads to a service-centric computing environment, in which users can select the desired services on demand, without concern for these services' administration, such as their installation, maintenance, management, and upgrade. In this paper, we introduce a novel concept, namely Meta OS, to support such program streaming through a distributed 4VP+ platform. Based on this platform, a pilot system has been implemented, which supports Windows and Linux environments. We verify the effectiveness of the platform through both real deployments and testbed experiments. The evaluation results suggest that the 4VP+ platform is a feasible and promising solution for the future computing infrastructure for cloud services.","Transparent computing,
Computer architecture,
Cloud computing,
Computational modeling,
Central Processing Unit,
Maintenance engineering"
A closed-loop training approach for massive MIMO beamforming systems,"There has been a growing interest in wireless systems that employ a very large number of transmit antennas. Some theoretical results have shown that substantial improvements in network capacity are possible. Despite this work, a major challenge is how these large transmit arrays should perform training to allow receiver channel estimation. Without new techniques, the heavy burden of training could overwhelm the system and mitigate any possible improvements, especially in systems using frequency division duplexing (FDD) where channel reciprocity cannot be exploited. In this work, we propose the use of closed-loop training. In this framework, the transmitted training signal is optimized to improve data communications performance by using prior information about the current channel obtained from past channel estimates. The work focuses on block-fading channels with temporal and spatial correlation. Simulation results show improved performance.","Training,
Signal to noise ratio,
MIMO,
Channel estimation,
Transmitters,
Array signal processing,
Fading"
Prototyping and Testing of a 15 kV/1.2 kA Saturable Core HTS Fault Current Limiter,"The fault current limiter is considered a viable solution for reducing the fault current in the power line. In the U.S., great effort has been reported in academia and industry in developing such devices. However, demonstrating a fault current limiter in the live power grid is challenging not only technologically but regulatory. This paper reports a joint effort of academia, industry, and utility on prototyping and testing of saturable core high temperature superconductive fault current limiters (HTS FCLs). This device is the first fully operational HTS FCL installed on the commercial medium voltage distribution grid in the U.S.",
Interactive Medical Image Segmentation Using PDE Control of Active Contours,"Segmentation of injured or unusual anatomic structures in medical imagery is a problem that has continued to elude fully automated solutions. In this paper, the goal of easy-to-use and consistent interactive segmentation is transformed into a control synthesis problem. A nominal level set partial differential equation (PDE) is assumed to be given; this open-loop system achieves correct segmentation under ideal conditions, but does not agree with a human expert's ideal boundary for real image data. Perturbing the state and dynamics of a level set PDE via the accumulated user input and an observer-like system leads to desirable closed-loop behavior. The input structure is designed such that a user can stabilize the boundary in some desired state without needing to understand any mathematical parameters. Effectiveness of the technique is illustrated with applications to the challenging segmentations of a patellar tendon in magnetic resonance and a shattered femur in computed tomography.","Image segmentation,
Level set,
Biomedical imaging,
Computed tomography,
Magnetic resonance imaging,
Narrowband,
Labeling"
Sentiment analysis on tweets for social events,"Sentiment analysis or opinion mining is an important type of text analysis that aims to support decision making by extracting and analyzing opinion oriented text, identifying positive and negative opinions, and measuring how positively or negatively an entity (i.e., people, organization, event, location, product, topic, etc.) is regarded. As more and more users express their political and religious views on Twitter, tweets become valuable sources of people's opinions. Tweets data can be efficiently used to infer people's opinions for marketing or social studies. This paper proposes a Tweets Sentiment Analysis Model (TSAM) that can spot the societal interest and general people's opinions in regard to a social event. In this paper, Australian federal election 2010 event was taken as an example for sentiment analysis experiments. We are primarily interested in the sentiment of the specific political candidates, i.e., two primary minister candidates - Julia Gillard and Tony Abbot. Our experimental results demonstrate the effectiveness of the system.","Semantics,
Feature extraction,
Twitter,
Nominations and elections,
Analytical models,
Educational institutions"
Proximity-Fed Circularly Polarized Slotted Patch Antenna for RFID Handheld Reader,"A novel, compact X-shaped slotted square-patch antenna is proposed for circularly polarized (CP) radiation. A cross-strip is embedded along the X-shaped slot for a novel proximity-fed technique to produce CP radiation in the UHF band. In the proposed design, two pairs of T-shaped slots are etched orthogonally on the square patch, connected to the center of the X-shaped slot for CP radiation and antenna size reduction. Proper adjustment of the length and coupling gap of the cross-strip will excite two orthogonal modes with 90 ° phase difference for good CP radiation. Simulated and measured results indicate that the proposed structure can achieve circular polarization. A measured impedance bandwidth (VSWR ≤ 2) of about 3.0% (909-937 MHz) and a 3-dB axial-ratio (AR) bandwidth of about 1.3% (917-929 MHz) were obtained.","Radiofrequency identification,
Antenna measurements,
Patch antennas,
Frequency measurement,
Resonant frequency,
Loss measurement"
Improving the mapping of reversible circuits to quantum circuits using multiple target lines,"The efficient synthesis of quantum circuits is an active research area. Since many of the known quantum algorithms include a large Boolean component (e.g. the database in the Grover search algorithm), quantum circuits are commonly synthesized in a two-stage approach. First, the desired function is realized as a reversible circuit making use of existing synthesis methods for this domain. Afterwards, each reversible gate is mapped to a functionally equivalent quantum gate cascade. In this paper, we propose an improved mapping of reversible circuits to quantum circuits which exploits a certain structure of many reversible circuits. In fact, it can be observed that reversible circuits are often composed of similar gates which only differ in the position of their target lines. We introduce an extension of reversible gates which allow multiple target lines in a single gate. This enables a significantly cheaper mapping to quantum circuits. Experiments show that considering multiple target lines leads to improvements of up to 85% in the resulting quantum cost.",
A Branch-and-Bound Algorithm for Quadratically-Constrained Sparse Filter Design,"This paper presents an exact algorithm for sparse filter design under a quadratic constraint on filter performance. The algorithm is based on branch-and-bound, a combinatorial optimization procedure that can either guarantee an optimal solution or produce a sparse solution with a bound on its deviation from optimality. To reduce the complexity of branch-and-bound, several methods are developed for bounding the optimal filter cost. Bounds based on infeasibility yield incrementally accumulating improvements with minimal computation, while two convex relaxations, referred to as linear and diagonal relaxations, are derived to provide stronger bounds. The approximation properties of the two relaxations are characterized analytically as well as numerically. Design examples involving wireless channel equalization and minimum-variance distortionless-response beamforming show that the complexity of obtaining certifiably optimal solutions can often be significantly reduced by incorporating diagonal relaxations, especially in more difficult instances. In the case of early termination due to computational constraints, diagonal relaxations strengthen the bound on the proximity of the final solution to the optimum.","Algorithm design and analysis,
Optimization,
Complexity theory,
Approximation methods,
Approximation algorithms,
Context,
Array signal processing"
Low-Cost FIR Filter Designs Based on Faithfully Rounded Truncated Multiple Constant Multiplication/Accumulation,Low-cost finite impulse response (FIR) designs are presented using the concept of faithfully rounded truncated multipliers. We jointly consider the optimization of bit width and hardware resources without sacrificing the frequency response and output signal precision. Nonuniform coefficient quantization with proper filter order is proposed to minimize total area cost. Multiple constant multiplication/accumulation in a direct FIR structure is implemented using an improved version of truncated multipliers. Comparisons with previous FIR design approaches show that the proposed designs achieve the best area and power results.,"multiplying circuits,
FIR filters"
Survivable multipath routing and spectrum allocation in OFDM-based flexible optical networks,"Compared with traditional WDM networks, orthogonal frequency-division multiplexing (OFDM)-based flexible optical networks are able to provide better spectral efficiency due to their flexible allocation of requests on fine granularity subcarriers. Survivability is a crucial issue in OFDM-based flexible optical networks. In this paper, we present a survivable multipath provisioning scheme that provides flexible protection levels in OFDM-based flexible optical networks. We define the Static Survivable Multipath Routing and Spectrum Allocation (SM-RSA) problem, which aims to accommodate a given set of demands with minimum utilized spectrum. We show that the static SMRSA problem is NP-hard and provide an integer linear programming formulation for it. Also, an efficient heuristic algorithm is given to solve the problem. Our simulation results show that the proposed multipath provisioning scheme achieves higher spectral efficiency than the traditional single-path provisioning scheme.","Optical fiber networks,
Resource management,
Indexes,
Equations,
Heuristic algorithms,
Routing,
Algorithm design and analysis"
Extreme Precise Motion Tracking of Piezoelectric Positioning Stage Using Sampled-Data Iterative Learning Control,"Positioning stages using piezoelectric stack actuators have been widely used in industrial applications. In this brief, we explore practical control algorithms that can achieve extreme precision motion tracking. Extreme precision is defined as the acquisition of tracking accuracy up to the hardware limit of a control system, for instance, the sensor resolution, the actuator resolution, the quantization limit of analog-to-digital converters (ADC), the limit of sampling interval, and the system repeatability. Sampled-data feedback control algorithms are unable to achieve such extreme precision tracking because of actuator saturation and stability margin. In this brief, we apply an iterative learning control (ILC) approach that can achieve the extreme precision for motion tracking tasks that repeat. ILC is essentially a feedforward control approach that fully utilizes the past control information, and hence is able to overcome the limit of feedback algorithms. The ILC algorithm used is simple in design and implementation, and fast in learning convergence. The sampled-data ILC is implemented on a piezoelectric positioning stage, in which the ADC device has a limited quantization of 49 nm. With only a few iterations of learning, the extreme precision motion tracking is achieved monotonically. Compared to well-tuned open-loop and proportional integral control algorithms, ILC can further reduce the tracking error by at least fourfold.","Convergence,
Tracking,
Actuators,
Hardware,
Pi control,
Accuracy,
Algorithm design and analysis"
Development of a smart-grid cyber-physical systems testbed,"Emerging future smart grids will substantially increase the sophistication and diversity of control, communications, and power systems technologies. While many of these technologies are well established in their particular area, the interactions that result when combining them into a fully functioning cyber-physical system can result in many unexpected behaviors. Therefore, appropriate test platforms will become necessary to evaluate the performance of these systems in order to reveal unintended and potentially harmful interactions between subsystems before deploying such technologies in the field. In this paper, we discuss the design and development of a testbed to evaluate various smart-grid based control technologies through the use of controller hardware-in-the-Ioop real-time simulation. In particular, the focus of this testbed is to examine various “intelligent” and distributed control algorithms. The relevance of the testbed is illustrated through a case-study of a smart-grid solution known as the Distributed Grid Intelligence (DGI), which is part of the Future Renewable Electrical Energy Delivery and Management (FREEDM) project. In this case-study, we describe the impacts of various interactions such as communication timings, available computational resources, and distribution and decentralization of higher-level control on a microgrid's operations. Based on the case study, this paper concludes with recommendations for future expansion and improvements to the test bed in order to better serve the smart grid research community.","Smart grids,
Peer-to-peer computing,
Data communication,
Real-time systems,
Software,
Power electronics"
Task Allocation on Nonvolatile-Memory-Based Hybrid Main Memory,"In this paper, we consider the task allocation problem on a hybrid main memory composed of nonvolatile memory (NVM) and dynamic random access memory (DRAM). Compared to the conventional memory technology DRAM, the emerging NVM has excellent energy performance since it consumes orders of magnitude less leakage power. On the other hand, most types of NVMs come with the disadvantages of much shorter write endurance and longer write latency as opposed to DRAM. By leveraging the energy efficiency of NVM and long write endurance of DRAM, this paper explores task allocation techniques on hybrid memory for multiple objectives such as minimizing the energy consumption, extending the lifetime, and minimizing the memory size. The contributions of this paper are twofold. First, we design the integer linear programming (ILP) formulations that can solve different objectives optimally. Then, we propose two sets of heuristic algorithms including three polynomial time offline heuristics and three online heuristics. Experiments show that compared to the optimal solutions generated by the ILP formulations, the offline heuristics can produce near-optimal results.","Phase change random access memory,
Nonvolatile memory,
Energy consumption,
Resource management,
Memory management,
Educational institutions"
Optimal Graph Search Based Segmentation of Airway Tree Double Surfaces Across Bifurcations,"Identification of both the luminal and the wall areas of the bronchial tree structure from volumetric X-ray computed tomography (CT) data sets is of critical importance in distinguishing important phenotypes within numerous major lung diseases including chronic obstructive pulmonary diseases (COPD) and asthma. However, accurate assessment of the inner and outer airway wall surfaces of a complete 3-D tree structure is difficult due to their complex nature, particularly around the branch areas. In this paper, we extend a graph search based technique (LOGISMOS) to simultaneously identify multiple inter-related surfaces of branching airway trees. We first perform a presegmentation of the input 3-D image to obtain basic information about the tree topology. The presegmented image is resampled along judiciously determined paths to produce a set of vectors of voxels (called voxel columns). The resampling process utilizes medial axes to ensure that voxel columns of appropriate lengths and directions are used to capture the object surfaces without interference. A geometric graph is constructed whose edges connect voxels in the resampled voxel columns and enforce validity of the smoothness and separation constraints on the sought surfaces. Cost functions with directional information are employed to distinguish inner and outer walls. The assessment of wall thickness measurement on a CT-scanned double-wall physical phantom (patterned after an in vivo imaged human airway tree) achieved highly accurate results on the entire 3-D tree. The observed mean signed error of wall thickness ranged from -0.09 ±0.24 mm to 0.07 ±0.23 mm in bifurcating/nonbifurcating areas. The mean unsigned errors were 0.16±0.12 mm to 0.20±0.11 mm. When the airway wall surface was partitioned into meaningful subregions, the airway wall thickness accuracy was the same in most tested bifurcation/nonbifurcation and carina/noncarina regions (p=NS). Once validated on phantoms, our method was applied to human in vivo volumetric CT data to demonstrate relationships of airway wall thickness as a function of luminal dimension and airway tree generation. Wall thickness differences between the bifurcation/nonbifurcation regions were statistically significant (p <; 0.05) for tree generations 6, 7, 8, and 9. In carina/noncarina regions, the wall thickness was statistically different in generations 1, 4, 5, 6, 7, and 8.","Image segmentation,
Bifurcation,
Topology,
Computed tomography,
Search problems,
Lungs,
Surface treatment"
Overlapping coalition formation games for cooperative interference management in small cell networks,"In this paper, we study the problem of cooperative interference management in an OFDMA two-tier small cell network. In particular, we propose a new approach for allowing the small cells to cooperate, so as to optimize their sum-rate, while cooperatively satisfying their maximum transmit power constraints. Unlike existing works which assume that only disjoint groups of cooperative small cells can emerge, we formulate the small cells' cooperation problem as an overlapping coalition formation game. In this game, each small cell base station can choose to participate in one or more cooperative groups (or coalitions) simultaneously, so as to optimize the tradeoff between the benefits and costs associated with cooperation. We study the properties of the proposed game and we show that it exhibits negative externalities due to interference. Then, we propose a novel decentralized algorithm that allows the small cell base stations to interact and self-organize into a stable overlapping coalitional structure. Simulation results show that the proposed algorithm results in a notable performance advantage in terms of the total system sum-rate, relative to the noncooperative case and the classical algorithms for coalitional games with nonoverlapping coalitions.","Scattering,
Games,
Interference,
Switches,
Base stations,
History,
Educational institutions"
Anytime solution optimization for sampling-based motion planning,"Recent work in sampling-based motion planning has yielded several different approaches for computing good quality paths in high degree of freedom systems: path shortcutting methods that attempt to shorten a single solution path by connecting non-consecutive configurations, a path hybridization technique that combines portions of two or more solutions to form a shorter path, and asymptotically optimal algorithms that converge to the shortest path over time. This paper presents an extensible meta-algorithm that incorporates a traditional sampling-based planning algorithm with offline path shortening techniques to form an anytime algorithm which exhibits competitive solution lengths to the best known methods and optimizers. A series of experiments involving rigid motion and complex manipulation are performed as well as a comparison with asymptotically optimal methods which show the efficacy of the proposed scheme, particularly in high-dimensional spaces.",
Proactive drive failure prediction for large scale storage systems,"Most of the modern hard disk drives support Self-Monitoring, Analysis and Reporting Technology (SMART), which can monitor internal attributes of individual drives and predict impending drive failures by a thresholding method. As the prediction performance of the thresholding algorithm is disappointing, some researchers explored various statistical and machine learning methods for predicting drive failures based on SMART attributes. However, the failure detection rates of these methods are only up to 50% ~ 60% with low false alarm rates (FARs). We explore the ability of Backpropagation (BP) neural network model to predict drive failures based on SMART attributes. We also develop an improved Support Vector Machine (SVM) model. A real-world dataset concerning 23,395 drives is used to verify these models. Experimental results show that the prediction accuracy of both models is far higher than previous works. Although the SVM model achieves the lowest FAR (0.03%), the BP neural network model is considerably better in failure detection rate which is up to 95% while keeping a reasonable low FAR.","Support vector machines,
Predictive models,
Neural networks,
Accuracy,
Training,
Prediction algorithms,
Educational institutions"
Optimal Alarm Signal Processing: Filter Design and Performance Analysis,"Accuracy and efficiency of alarm systems are of paramount importance in safe operations of industrial processes. Accuracy is measured by false and missed alarm rates (probabilities); while efficiency relates to the detection delay and complexity of the technique used. Moving average filters are often employed in industry for improved alarm accuracy. Can one do better than moving average filters? The following two problems are studied in this paper: First, given both normal and abnormal statistic distributions, how to design an optimal alarm filter (of fixed complexity) for best alarm accuracy, minimizing a weighted sum of false and missed alarm rates? Second, in what cases are moving average filters optimal? For the first problem, design of optimal linear FIR alarm filters is studied, and a numerical optimization based procedure is proposed. For the second problem, a sufficient condition is given under which the moving average filters are optimal.","Finite impulse response filter,
Linear programming,
Alarm systems,
Delay,
Industries,
Optimization,
Accuracy"
Online SOC and SOH estimation for multicell lithium-ion batteries based on an adaptive hybrid battery model and sliding-mode observer,"This paper proposes an adaptive hybrid battery model-based high-fidelity state of charge (SOC) and state of health (SOH) estimation method for rechargeable multicell batteries. The hybrid battery model consists of an enhanced Coulomb counting algorithm for SOC estimation and an electrical circuit battery model. A variable-length sliding window least squares (VSWLS)-based online parameter identification algorithm is designed to estimate the electrical parameters of the electrical battery model, which are then used as the parameters of an adaptive discrete-time sliding-mode observer (ADSMO) for terminal and open-circuit voltage estimation of a battery cell. The error of the SOC estimated from the enhanced Coulomb counting algorithm is then corrected by using the SOC obtained from the ADSMO-estimated open-circuit voltage. This leads to an accurate, robust real-time SOC estimation. In addition, the maximum capacity of the cell is estimated to determine the SOH of the cell. The proposed method is validated by simulation and experimental results for a four-cell cylindrical lithium-ion battery pack.","System-on-chip,
Batteries,
Estimation,
Integrated circuit modeling,
Adaptation models,
Real-time systems,
Computational modeling"
EHE-LEACH: Enhanced heterogeneous LEACH protocol for lifetime enhancement of wireless SNs,"Wireless Sensor Network (WSNs) are collection of small Sensor Nodes (SNs) which are capable of performing multiple tasks such as data aggregation, processing and communication either to other SNs or to the Base Station (BS). As SNs are battery operated, so efficient utilization of energy during various operations in WSNs is one of the major issues which requires special attention. It has been observed in literature that Hierarchical clustering and the node heterogeneity are the two parameters by which the lifetime of WSNs can be enhanced. Keeping in view of the above, in this paper, we propose an Enhanced Heterogeneous LEACH (EHE-LEACH) Protocol for Lifetime Enhancement of SNs. A fixed distance based threshold is used for the bifurcation of direct communication and cluster based communication in the proposed scheme. SNs near to the BS communicate directly and those which are far away from the BS use cluster based communication. To evaluate the performance of the proposed scheme two key parameters known as: Half Nodes Alive (HNA) and Last Node Alive (LNA) are selected. By selecting the distance based threshold with the ratio of 1:9 between direct communication and cluster based communication it has been observed that EHE-LEACH has better network lifetime with respect to various parameters in comparison to the other well known proposals such as LEACH and SEP.",
Energy management via pricing in LQ dynamic games,"This paper investigates the use of pricing mechanisms as a means to achieve a desired feedback control strategy among selfish agents in the context of HVAC resource allocation in buildings. We pose the problem of resource allocation as a linear-quadratic game with many dynamically coupled zone occupants(agents) and an uncoupled social planner. The social planner influences the game by choosing the quadratic dependence on control actions for each agent's cost function. We propose a neighborhood-based simplification of the dynamic game that results in a more realistic and scalable framework than is considered in standard dynamic game theory. In addition, we construct the pricing design problem as a convex feasibility problem and apply our method to an eight zone building model.","Pricing,
Buildings,
Nickel,
Nash equilibrium,
Vectors,
Games,
Heat transfer"
Supero: A sensor system for unsupervised residential power usage monitoring,"As a key technology of home area networks in smart grids, fine-grained power usage monitoring may help conserve electricity. Several existing systems achieve this goal by exploiting appliances' power usage signatures identified in labor-intensive in situ training processes. Recent work shows that autonomous power usage monitoring can be achieved by supplementing a smart meter with distributed sensors that detect the working states of appliances. However, sensors must be carefully installed for each appliance, resulting in high installation cost. This paper presents Supero - the first ad hoc sensor system that can monitor appliance power usage without supervised training. By exploiting multisensor fusion and unsupervised machine learning algorithms, Supero can classify the appliance events of interest and autonomously associate measured power usage with the respective appliances. Our extensive evaluation in five real homes shows that Supero can estimate the energy consumption with errors less than 7.5%. Moreover, non-professional users can quickly deploy Supero with considerable flexibility.","Home appliances,
Acoustics,
Monitoring,
Acoustic sensors,
Vectors,
Training"
The Molecular Control Toolkit: Controlling 3D molecular graphics via gesture and voice,"Three-dimensional (3D) molecular graphic systems are widely used in the life sciences, both for research and communication. These systems need to enable a rich set of 3D operations, including three-axis rotation and translation, selection of parts of macromolecules, and the ability to redefine the center of rotation. As a result, graphical interfaces for these systems typically require users to learn complex keyboard and mouse combinations. This can be a significant barrier for new or occasional users, and even for experts, precise control of 3D molecular structures can be challenging. To help address these challenges, we developed the Molecular Control Toolkit to support multiple consumer gesture and voice recognition devices, and provide an API that allows adaption to multiple molecular graphics systems. The toolkit allows intuitive control, almost as if users are directly manipulating 3D objects in their hands. We applied the toolkit to the Kinect and Leap Motion devices, and to the Aquaria molecular graphics system. We did a pilot user study with 18 life scientists to test the resulting system in different scenarios. Overall, users gave quite favorable ratings to using the Kinect and Leap Motion gesture devices to control molecular graphics, even though these devices initially proved less efficient for common 3D control tasks, compared to the more familiar mouse/keyboard. To our knowledge, this is the first toolkit for macromolecular graphics that supports multiple devices with a set of controls sufficiently rich to be useful in the day-to-day work of a broad range of life scientists. The Molecular Control Toolkit and Aquaria can be accessed at http://aquaria.ws.","Graphics,
Mice,
Three-dimensional displays,
Keyboards,
Connectors,
Monitoring,
Australia"
Initialization methods for large scale global optimization,"Several population initialization methods for evolutionary algorithms (EAs) have been proposed previously. This paper categorizes the most well-known initialization methods and studies the effect of them on large scale global optimization problems. Experimental results indicate that the optimization of large scale problems using EAs is more sensitive to the initial population than optimizing lower dimensional problems. Statistical analysis of results show that basic random number generators, which are the most commonly used method for population initialization in EAs, lead to the inferior performance. Furthermore, our study shows, regardless of the size of the initial population, choosing a proper initialization method is vital for solving large scale problems.","Sociology,
Statistics,
Generators,
Chaos,
Optimization,
Design methodology,
Benchmark testing"
Adaptive Inverse Control of Neural Spatiotemporal Spike Patterns With a Reproducing Kernel Hilbert Space (RKHS) Framework,"The precise control of spiking in a population of neurons via applied electrical stimulation is a challenge due to the sparseness of spiking responses and neural system plasticity. We pose neural stimulation as a system control problem where the system input is a multidimensional time-varying signal representing the stimulation, and the output is a set of spike trains; the goal is to drive the output such that the elicited population spiking activity is as close as possible to some desired activity, where closeness is defined by a cost function. If the neural system can be described by a time-invariant (homogeneous) model, then offline procedures can be used to derive the control procedure; however, for arbitrary neural systems this is not tractable. Furthermore, standard control methodologies are not suited to directly operate on spike trains that represent both the target and elicited system response. In this paper, we propose a multiple-input multiple-output (MIMO) adaptive inverse control scheme that operates on spike trains in a reproducing kernel Hilbert space (RKHS). The control scheme uses an inverse controller to approximate the inverse of the neural circuit. The proposed control system takes advantage of the precise timing of the neural events by using a Schoenberg kernel defined directly in the space of spike trains. The Schoenberg kernel maps the spike train to an RKHS and allows linear algorithm to control the nonlinear neural system without the danger of converging to local minima. During operation, the adaptation of the controller minimizes a difference defined in the spike train RKHS between the system and the target response and keeps the inverse controller close to the inverse of the current neural circuit, which enables adapting to neural perturbations. The results on a realistic synthetic neural circuit show that the inverse controller based on the Schoenberg kernel outperforms the decoding accuracy of other models based on the conventional rate representation of neural signal (i.e., spikernel and generalized linear model). Moreover, after a significant perturbation of the neuron circuit, the control scheme can successfully drive the elicited responses close to the original target responses.","Kernel,
Decoding,
Adaptation models,
MIMO,
Vectors,
Timing,
Integrated circuit modeling"
Implementation of Artifact Detection in Critical Care: A Methodological Review,"Artifact detection (AD) techniques minimize the impact of artifacts on physiologic data acquired in critical care units (CCU) by assessing quality of data prior to clinical event detection (CED) and parameter derivation (PD). This methodological review introduces unique taxonomies to synthesize over 80 AD algorithms based on these six themes: 1) CCU; 2) physiologic data source; 3) harvested data; 4) data analysis; 5) clinical evaluation; and 6) clinical implementation. Review results show that most published algorithms: a) are designed for one specific type of CCU; b) are validated on data harvested only from one OEM monitor; c) generate signal quality indicators (SQI) that are not yet formalized for useful integration in clinical workflows; d) operate either in standalone mode or coupled with CED or PD applications; e) are rarely evaluated in real-time; and f) are not implemented in clinical practice. In conclusion, it is recommended that AD algorithms conform to generic input and output interfaces with commonly defined data: 1) type; 2) frequency; 3) length; and 4) SQIs. This shall promote: a) reusability of algorithms across different CCU domains; b) evaluation on different OEM monitor data; c) fair comparison through formalized SQIs; d) meaningful integration with other AD, CED and PD algorithms; and e) real-time implementation in clinical workflows.","Monitoring,
Biomedical monitoring,
Algorithm design and analysis,
Real-time systems,
Electrocardiography,
Feature extraction"
Object Detection Via Structural Feature Selection and Shape Model,"In this paper, we propose an approach for object detection via structural feature selection and part-based shape model. It automatically learns a shape model from cluttered training images without need to explicitly use bounding boxes on objects. Our approach first builds a class-specific codebook of local contour features, and then generates structural feature descriptors by combining context shape information. These descriptors are robust to both within-class variations and scale changes. Through exploring pairwise image matching using fast earth mover's distance, feature weights can be iteratively updated. Those discriminative foreground features are assigned high weights and then selected to build a part-based shape model. Finally, object detection is performed by matching each testing image with this model. Experiments show that the proposed method is very effective. It has achieved comparable performance to the state-of-the-art shape-based detection methods, but requires much less training information.","Feature extraction,
Shape analysis,
Object detection,
Robustness"
Poisson Coordinates,"Harmonic functions are the critical points of a Dirichlet energy functional, the linear projections of conformal maps. They play an important role in computer graphics, particularly for gradient-domain image processing and shape-preserving geometric computation. We propose Poisson coordinates, a novel transfinite interpolation scheme based on the Poisson integral formula, as a rapid way to estimate a harmonic function on a certain domain with desired boundary values. Poisson coordinates are an extension of the Mean Value coordinates (MVCs) which inherit their linear precision, smoothness, and kernel positivity. We give explicit formulas for Poisson coordinates in both continuous and 2D discrete forms. Superior to MVCs, Poisson coordinates are proved to be pseudoharmonic (i.e., they reproduce harmonic functions on n-dimensional balls). Our experimental results show that Poisson coordinates have lower Dirichlet energies than MVCs on a number of typical 2D domains (particularly convex domains). As well as presenting a formula, our approach provides useful insights for further studies on coordinates-based interpolation and fast estimation of harmonic functions.","Interpolation,
Harmonic analysis,
Kernel,
Equations,
Integral equations,
Closed-form solutions,
Image processing"
Cyberphysical Elements of Disaster-Prepared Smart Environments,"Intelligent Guards against Disasters (iGaDs) could process and respond to alert and warning messages from responsible authorities and thus help in preparing to respond to disasters, but making such smart devices and systems dependable and affordable enough for pervasive use in future smart living environments will require strong standards.","Earthquakes,
Tornadoes,
Information technology,
Power generation,
Sensor arrays,
Disaster management"
Performance analysis of transform in uncoded wireless visual communication,"In wireless scenarios where the channel condition may vary drastically, visual communication systems using source and channel coding generally suffer from threshold effect. An uncoded transmission scheme called SoftCast [1]-[3], however, was recently shown to provide both graceful quality transition and competitive performance. In SoftCast, image signal is directly modulated to a dense constellation using proper power for transmission, solely after employing a transform for energy compaction, leaving out conventional quantization, entropy coding and channel coding. The received signal is lossy in nature, with its noise level commensurate with the channel condition. This paper presents a theoretical analysis for uncoded visual communication, focusing on the role of transform and the quantitative measurement of transform gain in a generalized uncoded transmission framework with optimal power allocation. Our analysis reveal that the energy distribution among signal elements plays an important role in the power-distortion performance. Further analysis show that the energy compaction capability of decorrelation transform can bring significant gain by boosting the energy diversity in signal representation. Numerical analysis results are reported for Markov random signals and natural images, respectively. The performance of typical transforms, e.g. KLT, DCT and DWT, and the effect of different transform sizes or levels are evaluated. These analysis results are verified by simulations.","Gain,
Discrete wavelet transforms,
Discrete cosine transforms,
Decorrelation,
Correlation,
Markov processes"
Participatory bluetooth sensing: A method for acquiring spatio-temporal data about participant mobility and interactions at large scale events,Acquisition of data to capture human mobility and interactions during large-scale events is a challenging task. In this paper we discuss a mobile sensing method for mapping the mobility of crowds at large scale events using a participatory Bluetooth sensing approach. This non-invasive technique for collecting spatio-temporal data about participant mobility and social interactions uses the capabilities of Bluetooth capable smartphones carried by participants. As a proof-of-concept we present a field study with deployment of the method in a large music festival with 130000 participants where a small subset of participants installed Bluetooth sensing apps on their personal smartphones. Our software module uses location and Bluetooth scans to utilize smartphones as provisional scanners that are present with higher frequency in regions with high density of participants. We discuss the initial results obtained and outline opportunities and challenges introduced by this methodology along with opportunities for future pervasive systems and applications.,"Bluetooth,
Sensors,
Smart phones,
Mobile communication,
Libraries,
Atmospheric measurements"
Tunable Microwave Photonic Filter With a Narrow and Flat-Top Passband,"A frequency-tunable microwave photonic filter (MPF) with a narrow and flat-top passband implemented using a phase modulator (PM) and a superstructured fiber Bragg grating (SFBG) is proposed and experimentally demonstrated. The key component in the MPF is the SFBG, which is designed and fabricated based on the equivalent phase shift (EPS) technique. Two phase shifts are introduced, and the combination of the two phase shifts would lead to a flat-bottom notch in the reflection band. By incorporating the SFBG into the MPF, a frequency response with a narrow and flat-top passband is achieved. The reflection bandwidth and the notch width of the SFBG, which determine the frequency tunable range and passband width, can be controlled by the length and maximum index modulation (MIM) of the SFBG. An experiment is performed. An MPF with a 3 dB bandwidth of 143 MHz, a 20 dB bandwidth of 370 MHz, and a tunable range from 0.4 to 6.4 GHz is demonstrated.","optical fibre filters,
Bragg gratings,
microwave filters"
Mobile-based relay selection schemes for multi-hop cellular networks,"Multi-hop cellular networks (MCNs), which reduce the transmit power, mitigate the inter-cell interference, and improve the system performance, have been widely studied nowadays. The relay selection scheme is a key technique that achieves these advantages, and inappropriate relay selection causes frequent relay switchings, which deteriorates the overall performance. In this study, we analyze the conditions for relay switching in MCNs and obtain the expressions for the relay switching rate and relay activation time. Two mobile-based relay selection schemes are proposed on the basis of this analysis. These schemes select the relay node with the longest relay activation time and minimal relay switching rate through mobility prediction of the mobile node requiring relay and available relay nodes. We compare the system performances via simulation and analyze the impact of various parameters on the system performance. The results show that the two proposed schemes can obtain a lower relay switching rate and longer relay activation time when there is no reduction in the system throughput as compared with the existing schemes.","Relays,
Switches,
Spread spectrum communication,
Measurement,
Computer architecture,
Cellular networks"
Aging-aware timing analysis considering combined effects of NBTI and PBTI,"Transistor aging due to Bias Temperature Instability (BTI) and Hot Carrier Injection (HCI) is one of the major reliability issues of VLSI circuits fabricated at nanometer technology nodes. Transistor aging increases the circuit delay over the time and ultimately leads to lifetime reduction of VLSI chips. Accurate aging-aware timing analysis is a key requirement to consider these effects in the design cycle. Our analysis shows that a separate (independent) analysis of different sources of aging leads to significant overestimation of post-aging delay. To overcome the problem of existing methods, we propose a new aging-aware gate delay model that precisely captures the combined effect of different aging sources on delay. Our results obtained from a set of benchmark circuits show that, our proposed gate-delay model estimates the aging-induced Δdelay by 7.8% (translating to 36.0% MTTF) more accurately in comparison to prior techniques. Moreover, we present a flow for integrating the proposed gate delay model with commercial timing analysis tools.","Logic gates,
Transistors,
Stress,
Delays,
Very large scale integration,
Integrated circuit modeling,
Integrated circuit reliability"
Unreconciled Collisions Uncover Cloning Attacks in Anonymous RFID Systems,"Cloning attacks threaten radio-frequency identification (RFID) applications but are hard to prevent. Existing cloning attack detection methods are enslaved to the knowledge of tag identifiers (IDs). Tag IDs, however, should be protected to enable and secure privacy-sensitive applications in anonymous RFID systems. In a first step, this paper tackles cloning attack detection in anonymous RFID systems without requiring tag IDs as a priori. To this end, we leverage unreconciled collisions to uncover cloning attacks. An unreconciled collision is probably due to responses from multiple tags with the same ID, exactly the evidence of cloning attacks. This insight inspires GREAT, our pioneer protocol for cloning attack detection in anonymous RFID systems. We evaluate the performance of GREAT through theoretical analysis and extensive simulations. The results show that GREAT can detect cloning attacks in anonymous RFID systems fairly fast with required accuracy. For example, when only six out of 50,000 tags are cloned, GREAT can detect the cloning attack in 75.5 s with a probability of at least 0.99.",
Visualization of fine-grained code change history,"Conventional version control systems save code changes at each check-in. Recently, some development environments retain more fine-grain changes. However, providing tools for developers to use those histories is not a trivial task, due to the difficulties in visualizing the history. We present two visualizations of fine-grained code change history, which actively interact with the code editor: a timeline visualization, and a code history diff view. Our timeline and filtering options allow developers to navigate through the history and easily focus on the information they need. The code history diff view shows the history of any particular code fragment, allowing developers to move through the history simply by dragging the marker back and forth through the timeline to instantly see the code that was in the snippet at any point in the past. We augment the usefulness of these visualizations with richer editor commands including selective undo and search, which are all implemented in an Eclipse plug-in called “Azurite”. Azurite helps developers with answering common questions developers ask about the code change history that have been identified by prior research. In addition, many of users' backtracking tasks can be achieved using Azurite, which would be tedious or error-prone otherwise.","History,
Visualization,
Software,
Filtering,
Layout,
Navigation,
Real-time systems"
Real-time optimization-based planning in dynamic environments using GPUs,"We present a novel algorithm to compute collision-free trajectories in dynamic environments. Our approach is general and does not require a priori knowledge about the obstacles or their motion. We use a replanning framework that interleaves optimization-based planning with execution. Furthermore, we describe a parallel formulation that exploits a high number of cores on commodity graphics processors (GPUs) to compute a high-quality path in a given time interval. We derive bounds on how parallelization can improve the responsiveness of the planner and the quality of the trajectory.",Trajectory
Selective source power converter for improved photovoltaic power utilization,"This work proposes a new power conversion system suitable for supplying power to both ac and dc loads simultaneously from both ac sources, such as the power grid, and dc sources, such as a photovoltaic (PV) panel. First, an introduction of the motivation for proposing the new system and the objectives of the new system is given. Next, the new system and its building blocks are introduced. Then, the technical details about a built prototype conversion system are presented. Finally, a number of experimental results are provided to demonstrate the performance of the proposed system.","Voltage control,
Maximum power point trackers,
Inverters,
Power conversion,
Power harmonic filters,
Photovoltaic systems"
Energy-aware task replication to manage reliability for periodic real-time applications on multicore platforms,"Energy and reliability management are important design constraints for real-time embedded systems. We consider the problem of achieving a given reliability target for a set of periodic real-time applications running on a multi-core system with minimum energy consumption. Specifically, we observe that the emerging multicore platforms provide ample opportunities to use task replication to achieve reliability targets and mitigate the negative impact of Dynamic Voltage Scaling (DVS) on the rate of transient faults leading to soft errors. However, while it allows using lower execution frequencies, replication may also increase overall energy consumption due to additional task copies. Our objective is to determine the level of replication and frequency assignment for each task, as well as task-to-core allocations, in such a way to achieve the target reliability levels with minimum energy consumption. We first identify the subtle interplay between the processing frequency, replication level, reliability, and energy consumption on DVS-enabled multicore systems. Then we show that the problem is intractable in the general case and propose our energy-efficient replication (EER) algorithm as an approximate solution. We also show how the framework can be extended to tolerate a given number of permanent faults affecting processing cores. We evaluate the performance of our proposed scheme through extensive simulations. The simulation results indicate that through our algorithm, a very broad spectrum of reliability targets can be achieved with minimum energy consumption through the judicious use of replica and frequency assignment.","Reliability,
Energy consumption,
Multicore processing,
Transient analysis,
Circuit faults,
Time-frequency analysis,
Voltage control"
List-Mode PET Motion Correction Using Markerless Head Tracking: Proof-of-Concept With Scans of Human Subject,"A custom designed markerless tracking system was demonstrated to be applicable for positron emission tomography (PET) brain imaging. Precise head motion registration is crucial for accurate motion correction (MC) in PET imaging. State-of-the-art tracking systems applied with PET brain imaging rely on markers attached to the patient's head. The marker attachment is the main weakness of these systems. A healthy volunteer participating in a cigarette smoking study to image dopamine release was scanned twice for 2 h with 11C-racolopride on the high resolution research tomograph (HRRT) PET scanner. Head motion was independently measured, with a commercial marker-based device and the proposed vision-based system. A list-mode event-by-event reconstruction algorithm using the detected motion was applied. A phantom study with hand-controlled continuous random motion was obtained. Motion was time-varying with long drift motions of up to 18 mm and regular step-wise motion of 1-6 mm. The evaluated measures were significantly better for motion-corrected images compared to no MC. The demonstrated system agreed with a commercial integrated system. Motion-corrected images were improved in contrast recovery of small structures.","Positron emission tomography,
Tracking,
Head,
Image reconstruction,
Humans,
Phantoms"
Comparison of three scattering models for ultrasound blood characterization,"Ultrasonic backscattered signals from blood contain frequency-dependent information that can be used to obtain quantitative parameters reflecting the aggregation level of red blood cells (RBCs). The approach is based on estimating structural aggregate parameters by fitting the spectrum of the backscattered radio-frequency echoes from blood to an estimated spectrum considering a theoretical scattering model. In this study, three scattering models were examined: a new implementation of the Gaussian model (GM), the structure factor size estimator (SFSE), and the new effective medium theory combined with the structure factor model (EMTSFM). The accuracy of the three scattering models in determining mean aggregate size and compactness was compared by 2-D and 3-D computer simulations in which RBC structural parameters were controlled. Two clustering conditions were studied: 1) the aggregate size varied and the aggregate compactness was fixed in both 2-D and 3-D cases, and 2) the aggregate size was fixed and the aggregate compactness varied in the 2-D case. For both clustering conditions, the EMTSFM was found to be more suitable than GM and SFSE for characterizing RBC aggregation.","Aggregates,
Scattering,
Blood,
Computational modeling,
Impedance,
Solid modeling,
Plasmas"
Magnetic resonance image synthesis through patch regression,"Magnetic resonance imaging (MRI) is widely used for analyzing human brain structure and function. MRI is extremely versatile and can produce different tissue contrasts as required by the study design. For reasons such as patient comfort, cost, and improving technology, certain tissue contrasts for a cohort analysis may not have been acquired during the imaging session. This missing pulse sequence hampers consistent neuroanatomy research. One possible solution is to synthesize the missing sequence. This paper proposes a data-driven approach to image synthesis, which provides equal, if not superior synthesis compared to the state-of-the-art, in addition to being an order of magnitude faster. The synthesis transformation is done on image patches by a trained bagged ensemble of regression trees. Validation was done by synthesizing T2-weighted contrasts from T1-weighted scans, for phantoms and real data. We also synthesized 3 Tesla T1-weighted magnetization prepared rapid gradient echo (MPRAGE) images from 1.5 Tesla MPRAGEs to demonstrate the generality of this approach.","Histograms,
Regression tree analysis,
Magnetic resonance imaging,
Training,
Image generation,
Noise,
Phantoms"
Radio Map Update Automation for WiFi Positioning Systems,"This paper presents a novel method to reduce the recalibration costs of a radio map by automatically updating the radio map. The appearance frequencies of access points (APs) detected from user feedback data are mainly used for the update. The proposed method appeared superior to previous methods, especially in its ability to update newly installed APs in the radio map. According to the experiment conducted for the radio map of 233 Seoul subway stops, the proposed method was effective for updating APs with weak as well as strong signal strengths.","IEEE 802.11 Standards,
Accuracy,
Manuals,
Smart phones,
Automation,
Servers,
Databases"
Self-Heating Temperature and AC Hysteresis of Magnetic Iron Oxide Nanoparticles and Their Dependence on Secondary Particle Size,"Magnetic nanoparticles are expected to be used as hyperthermia agents. The mechanism of self-heating of the magnetic nanoparticles under an ac magnetic field is different according to their size. In this study, the temperature rise for the ac/dc hysteresis loops of magnetic nanoparticles were evaluated to clarify the contribution of the Néel and Brownian relaxations to heat dissipation. The samples were dextran-coated magnetic iron oxide nanoparticles of different hydrodynamic diameters (40, 54, and 86 nm), but the same primary diameter of 10 nm. From these diameters, the peak frequencies for the Brownian and Néel relaxations were calculated. The Néel relaxation time, determined by the primary particle size, is much shorter than the Brownian relaxation time for these samples. Although the Néel relaxation is dominant, the self-heating temperature rise of the 86 nm sample was higher than that of the 40 and 54 nm samples. These results suggest that the effect of the magnetic interaction between the nanoparticles depends on the hydrodynamic diameter.","Magnetic hysteresis,
Magnetic resonance imaging,
Saturation magnetization,
Temperature measurement,
Heating,
Magnetic susceptibility,
Nanoparticles"
"Analysis of Failure Mechanisms and Extraction of Activation Energies
(
E
a
)
in 21-nm nand Flash Cells","In this letter, we point out the methodological problem of the conventional temperature-accelerated life-test method of nand Flash memory. We confirm that the generally assumed Arrhenius law is inconsistent with extrapolation of data-retention time-to-failure of nand Flash memory since several failure mechanisms come up together. For the first time, we completely separated three main failure mechanisms and extracted each activation energy (Ea) in 21-nm nand Flash memory. From the results, we assured that each failure mechanism follows the Arrhenius law. In order to estimate the lifetime of nand Flash memory accurately, each failure mechanism should be considered.","Flash memory,
Failure analysis,
Electron traps,
Temperature,
Tunneling,
Temperature dependence"
Unifying FSM-inference algorithms through declarative specification,"Logging system behavior is a staple development practice. Numerous powerful model inference algorithms have been proposed to aid developers in log analysis and system understanding. Unfortunately, existing algorithms are difficult to understand, extend, and compare. This paper presents InvariMint, an approach to specify model inference algorithms declaratively. We applied InvariMint to two model inference algorithms and present evaluation results to illustrate that InvariMint (1) leads to new fundamental insights and better understanding of existing algorithms, (2) simplifies creation of new algorithms, including hybrids that extend existing algorithms, and (3) makes it easy to compare and contrast previously published algorithms. Finally, algorithms specified with InvariMint can outperform their procedural versions.","Inference algorithms,
Postal services,
Approximation algorithms,
Algorithm design and analysis,
Doped fiber amplifiers,
Educational institutions,
Electronic mail"
Performance Analysis of Linear Cooperative Multi-Hop Networks Subject to Composite Shadowing-Fading,"We consider a cooperative multi-hop line network, where a group of nodes cooperatively transmits the same message to another group of nodes, and model the transmission from one group to another as a discrete-time quasi-stationary Markov process. We derive the transition probability matrix of the Markov chain by considering the wireless channel exhibiting composite shadowing-fading. The shadowing is modeled as a log-normal random variable (RV) and the multipath fading as a Rayleigh RV, where the multiplicative model for the mixture distribution known as Suzuki (Rayleigh-lognormal) distribution has been considered. The sum distribution of the multiple Suzuki RVs is approximated by a single log-normal RV by using the moment generating function (MGF)-based technique. This MGF-based technique uses Gauss-Hermite integration to present the sum distribution in closed form. We quantify the signal-to-noise ratio (SNR) margin required to achieve a certain quality of service (QoS) under standard deviation of the shadowing. We also provide the optimal level of cooperation required for obtaining maximum coverage of a line network under a given QoS. Two topologies for linear network are considered and the performance of each topology under various system parameters is provided. The analytical results have been validated by matching with the simulation results.",
The Fokker-Planck Equation for Power System Stability Probability Density Function Evolution,"This paper presents an analysis of the evolution of the probability density function of the dynamic trajectories of a single machine infinite bus power system. The probability density function can be used to determine the impact of random (stochastic) load perturbations on system stability. The evolution of the state probability density function over time leads to several interesting observations regarding stability regions as a function of damping parameter. The Fokker-Planck equation (FPE) is used to describe the evolution of the probability density of the states. The FPE is solved numerically using PDE solvers (such as finite difference method). Based on the results, the qualitative changes of the stationary density produce peak-like, ridge-like and other complicated shapes. Lastly, the numerical FPE solution combined with SMIB equivalent techniques lay the framework extended to the multimachine system.",
A Protein-Based Electrochemical Biosensor Array Platform for Integrated Microsystems,"This paper elucidates challenges in integrating different classes of proteins into a microsystem and presents an electrochemical array strategy for heterogeneous protein-based biosensors. The overlapping requirements and limitations imposed by biointerface formation, electrochemical characterization, and microsystem fabrication are identified. A planar electrode array is presented that synergistically resolves these requirements using thin film Au and Ag/AgCl electrodes on a dielectric substrate. Using molecular self-assembly, electrodes were modified by nano-structures of two diverse proteins, alkali ion-channel protein and alcohol dehydrogenase enzyme. Electrochemical impedance spectroscopy and cyclic voltammetry measurements were performed to characterize sensor response to alkali ion and alcohol, respectively. This work demonstrates the viability of the electrochemical microsystem platform for heterogeneous protein-based biosensor interfaces.",
RSS-Ratio for enhancing performance of RSS-based applications,"RSS (Received Signal Strength) has been widely utilized in wireless applications. It is, however, susceptible to environmental unknowns from both temporal and spatial domains. As a result, the fluctuation of RSS may degrade performance of RSS based applications. In this work, we propose a novel RSS processing method at the receiver for three antenna based systems. The output of our approach is `RSS-Ratio', which eliminates the environmental unknowns and thus is a more stable variable compared to RSS itself. To validate the efficacy of the proposed method, we conduct a series of experiments in a range of wireless scenarios, including indoor laptop based measurement, indoor software defined radio - WARP based measurement, and outdoor wireless measurement. In addition, we also give an analysis to the relationship between the location of transmitter and the value of RSS-Ratio, and examine the accuracy of the estimated RSS-Ratio value via both simulations and experiments. All the experimental, analytical, and simulated results demonstrate that RSS-Ratio will be a better replacement for RSS to improve the performance of RSS based applications.",
Common Information and Unique Disjointness,"We provide a new framework for establishing strong lower bounds on the nonnegative rank of matrices by means of common information, a notion previously introduced in [1]. Common information is a natural lower bound for the nonnegative rank of a matrix and by combining it with He linger distance estimations we can compute the (almost) exact common information of UDISJ partial matrix. We also establish robustness of this estimation under various perturbations of the UDISJ partial matrix, where rows and columns are randomly or adversarially removed or where entries are randomly or adversarially altered. This robustness translates, via a variant of Yannakakis' Factorization Theorem, to lower bounds on the average case and adversarial approximate extension complexity. We present the first family of polytopes, the hard pair introduced in [2] related to the CLIQUE problem, with high average case and adversarial approximate extension complexity. We also provide an information theoretic variant of the fooling set method that allows us to extend fooling set lower bounds from extension complexity to approximate extension complexity.","Complexity theory,
Random variables,
Linear matrix inequalities,
Linear programming,
Entropy,
Information theory,
Correlation"
Efficient Space Management Techniques for Large-Scale Interconnect Capacitance Extraction With Floating Random Walks,"In the capacitance extraction with the floating random walk (FRW) algorithm, the space management approach is required to facilitate finding the nearest conductor. The Octree and grid-based spatial structures have been used to decompose the whole domain into cells and to store information of local conductors. In this letter, the techniques with the distance limit of cell and only searching in cell's neighbor region are proposed to accelerate the construction of the spatial structures. A fast inquiry technique is proposed to fasten the nearest conductor query. We also propose a grid-Octree hybrid structure, which has advantages over existing structures. Experiments on large very large scale integration structures with up to 484441 conductors have validated the efficiency of the proposed techniques. The improved FRW algorithm is faster than RWCap for thousands times while extracting a single net, and several to tens times while extracting 100 nets.","Conductors,
Capacitance,
Octrees,
Very large scale integration,
Algorithm design and analysis,
Acceleration,
Dielectrics"
Riemannian Distances for Signal Classification by Power Spectral Density,"Signal classification is an important issue in many branches of science and engineering. In signal classification, a feature of the signals is often selected for similarity comparison. A distance metric must then be established to measure the dissimilarities between different signal features. Due to the natural characteristics of dynamic systems, the power spectral density (PSD) of a signal is often used as a feature to facilitate classification. We reason in this paper that PSD matrices have structural constraints and that they describe a manifold in the signal space. Thus, instead of the widely used Euclidean distance (ED), a more appropriate measure is the Riemannian distance (RD) on the manifold. Here, we develop closed-form expressions of the RD between two PSD matrices on the manifold and study some of the properties. We further show how an optimum weighting matrix can be developed for the application of RD to signal classification. These new distance measures are then applied to the classification of electroencephalogram (EEG) signals for the determination of sleep states and the results are highly encouraging.","Manifolds,
Measurement,
Vectors,
Closed-form solutions,
Eigenvalues and eigenfunctions,
Feature extraction,
Libraries"
Minimum-Latency Broadcast Scheduling for Cognitive Radio Networks,"Cognitive Radio Networks (CRNs) introduce a new communication paradigm which enable unlicensed users to opportunistically access spectrum bands assigned to licensed users. Interestingly, the broadcast problem, which is one of the most fundamental operations in CRNs, has not been well studied. Existing works for the broadcast issue in CRNs are either heuristic solutions without performance guarantee or with performance far from the optimal solution. In this paper, we study the Minimum-Latency Broadcast Scheduling (MLBS) issue for CRNs. Our contributions are threefold. Firstly, we propose a Mixed Broadcasting Scheduling (MBS) algorithm under the Unit Disk Graph (UDG) model, denoted by MBS-UDG. MBSUDG finishes a broadcast task by employing mixed unicast and broadcast communication modes in two phases. We show that the latency performance of MBS-UDG is O(ħ+ΔT) when ΔT ≤ 1/p, or O(ħ+log1-p 1/(pΔT)) when ΔT > 1/p, where ħ and ΔT are the height and the maximum number of leaf nodes connected by a SU of the broadcasting tree, respectively, and p is the spectrum opportunity for a secondary communication. Furthermore, the redundancy performance of MBS-UDG is analyzed. Secondly, we extend MBS-UDG to a more general MBS algorithm under the protocol interference model and analyze its latency and redundancy performance. Finally, simulations are conducted to validate MBS, which indicate that MBS significantly improves existing algorithms with respect to both latency and redundancy.","Interference,
Broadcasting,
Redundancy,
Algorithm design and analysis,
Sensors,
Scheduling,
Protocols"
Channel Aware Encryption and Decision Fusion for Wireless Sensor Networks,"In wireless sensor networks (WSNs), security and energy consumption have been considered as long-lasting technical challenges as sensors usually suffer from complexity and energy constraints. In this paper, we study a simple and efficient physical-layer security to provide data confidentiality in a distributed detection scenario. In particular, to prevent passive eavesdropping on transmitting data from sensors to an ally fusion center (AFC), we propose a novel encryption scheme and decision fusion rules for a parallel access channel model. The proposed scheme takes advantage of a free natural resource, i.e., randomness of wireless channels, to encrypt the binary local decision of each sensor in such a way that the binary local decision is flipped according to instantaneous channel gain between the sensor and AFC. The location-specific and reciprocal properties of wireless channels enable the sensor and AFC to share the inherent randomness of wireless channels which are not available to an eavesdropper. Furthermore, it is shown that the scheme is well-suited to a low complexity and energy efficient modulation technique, noncoherent binary frequency shift keying. To evaluate performances of the proposed scheme, log-likelihood-ratio-based decision fusion strategies at the AFC are analyzed, and comparisons of decision performances are carried out. In addition, we prove that the proposed scheme achieves perfect secrecy with a simple structure that is suited for sensors of limited complexity.","Sensors,
Frequency control,
Wireless sensor networks,
Encryption,
Wireless communication"
Design of a Real-Time FPGA-Based Data Acquisition Architecture for the LabPET II: An APD-Based Scanner Dedicated to Small Animal PET Imaging,"The LabPET II detector block was designed to achieve submillimeter spatial resolution in small animal PET imaging. Each detection block consists of two arrays of 4 × 8 avalanche photodiodes (APD) individually coupled to an 8 × 8 scintillator array, to form 64 independent detectors with parallel readout channels. This new detection block entails an eightfold increase in pixel density compared to the LabPET I. A 64-channel mixed-signal application-specific integrated circuit (ASIC) was designed to extract relevant PET data in real time from the LabPET II detection blocks. In order to interface the ASICs forming the PET camera with the storage units, a real-time FPGA-based digital data acquisition (DAQ) system was designed. The DAQ system allows event harvesting, processing and transmission to a host computer for data storage as well as system programming and calibration. Real-time event processing embedded in the DAQ includes time trigger, energy computation using a time-over-threshold (TOT) conversion scheme, timing corrections, and event sorting trees. In the standard DAQ mode, a real-time coincidence engine analyzes events and only keeps relevant information to minimize data throughput and post-acquisition data processing. The architecture consists of three FPGA-based electronic layers wired through gigabit links: a Front-End layer extracts time and energy along with the pixel address, a custom Hub layer chronologically sorts incoming events, and a Coincidence engine matches coincident events and computes an estimate of the random events rate. Every FPGA in the different layers is accessible through an Ethernet link. The real-time digital architecture sustains the required throughput of ~ 111 million events/s for a ~ 37000-channel scanner configuration.","Application specific integrated circuits,
Real-time systems,
Data acquisition,
Positron emission tomography,
Engines,
Field programmable gate arrays,
Computer architecture"
Truthful Mechanisms for Secure Communication in Wireless Cooperative System,"To ensure security in data transmission is one of the most important issues for wireless relay networks, and physical layer security is an attractive alternative solution to address this issue. In this paper, we consider a cooperative network, consisting of one source node, one destination node, one eavesdropper node, and a number of relay nodes. Specifically, the source may select several relays to help forward the signal to the corresponding destination to achieve the best security performance. However, the relays may have the incentive not to report their true private channel information in order to get more chances to be selected and gain more payoff from the source. We propose a Vickey-Clark-Grove (VCG) based mechanism and an Arrow-d'Aspremont-Gerard-Varet (AGV) based mechanism into the investigated relay network to solve this cheating problem. In these two different mechanisms, we design different ""transfer payment"" functions to the payoff of each selected relay and prove that each relay gets its maximum (expected) payoff when it truthfully reveals its private channel information to the source. And then, an optimal secrecy rate of the network can be achieved. After discussing and comparing the VCG and AGV mechanisms, we prove that the AGV mechanism can achieve all of the basic qualifications (incentive compatibility, individual rationality and budget balance) for our system. Moreover, we discuss the optimal quantity of relays that the source node should select. Simulation results verify efficiency and fairness of the VCG and AGV mechanisms, and consolidate these conclusions.",
Enabling the Femtocells: A Cooperation Framework for Mobile and Fixed-Line Operators,"Femtocells' ability to improve the in-building coverage and capacity in a cost-efficient way has drawn significant attention from mobile operators. However, a mobile operator may lack a fixed-line network infrastructure, which is indispensable for enabling femtocell service. In this paper, we propose a hybrid cooperation framework where a mobile operator can collaborate with a fixed-line operator (as a virtual integrated operator) to provide femtocell service to indoor users. The framework consists of sequential game and Nash bargaining. The sequential game models the interactions of the operator and users. Specifically, the operator announces the price for wireless services first and then the users decide their spectrum demands in response to the given price. Then the two operators divide the cooperation benefit according to the Nash bargaining model, which makes the profit sharing fair and cooperation framework amenable to operators. We theoretically derive the unique closed-form equilibrium for the framework as well as the conditions that promote the cooperation. The simulation results verify that the cooperation framework can make more revenue for the operators and the spectrum efficiency is significantly improved.","Femtocells,
Bandwidth,
Games,
Mobile communication,
Aggregates,
Wireless communication,
Approximation methods"
Reduced-Complexity Near-Capacity Joint Channel Estimation and Three-Stage Turbo Detection for Coherent Space-Time Shift Keying,"We propose a low-complexity joint channel estimation (CE) and three-stage iterative demapping-decoding scheme for near-capacity coherent space-time shift keying (CSTSK) based multiple-input multiple-output (MIMO) systems. In the proposed scheme, only a minimum number of space-time shift keying training blocks are employed for generating an initial least square channel estimate, which is then used for initial data detection. As usual, the detected soft information is first exchanged a number of times within the inner turbo loop between the unity-rate-code (URC) decoder and the CSTSK soft-demapper, and the information gleaned from the inner URC decoder is then iteratively exchanged with the outer decoder in the outer turbo loop. Our CE scheme is embedded into the outer turbo loop, which exploits the a posteriori information produced by the CSTSK soft-demapper to select a sufficient number of high-quality decisions only for CE. Since the CE is embedded into the iterative three-stage demapping-decoding process, no additional iterative loop is required for exchanging information between the decision-directed channel estimator and the three-stage turbo detector. Hence, the computational complexity of the proposed joint CE and three-stage turbo detection remains similar to that of the three-stage turbo detection-decoding scheme with the given channel estimate. Moreover, our proposed low-complexity semi-blind scheme is capable of approaching the optimal maximum likelihood turbo detection performance attained with the aid of perfect channel state information, with the same low number of turbo iterations as the latter, as confirmed by our extensive simulation results.","Channel estimation,
Decoding,
Joints,
Training,
MIMO,
Vectors,
Iterative decoding"
Quaternion-Based Impulse Noise Removal From Color Video Sequences,"In this paper, a new quaternion vector filter for removal of random impulse noise in color video sequences is presented. First, luminance distances and chromaticity differences that are represented in quaternion form are combined together to measure color distances between color pixels. Then, based on this new color distance mechanism, the samples along horizontal, vertical, and diagonal directions in current frame and the samples of adjacent frames on motion trajectory are used to detect whether each pixel is noisy or not. By analyzing the spatiotemporal order-statistic information about these directional samples, the video pixels are classified into noise free and noisy. Finally, 3-D weighted vector median filtering is performed on the pixels that are judged as noisy, and the other pixels remain unchanged. The experimental results show that the proposed algorithm significantly outperforms other state-of-the-art video denoising methods in terms of both objective measure and visual evaluation.","Image color analysis,
Vectors,
Colored noise,
Quaternions,
Noise measurement,
Filtering"
An Experimental Vestibular Neural Prosthesis: Design and Preliminary Results With Rhesus Monkeys Stimulated With Modulated Pulses,A vestibular neural prosthesis was designed on the basis of a cochlear implant for treatment of Meniere's disease and other vestibular disorders. Computer control software was developed to generate patterned pulse stimuli for exploring optimal parameters to activate the vestibular nerve. Two rhesus monkeys were implanted with the prototype vestibular prosthesis and they were behaviorally evaluated post implantation surgery. Horizontal and vertical eye movement responses to patterned electrical pulse stimulations were collected on both monkeys. Pulse amplitude modulated (PAM) and pulse rate modulated (PRM) trains were applied to the lateral canal of each implanted animal. Robust slow-phase nystagmus responses following the PAM or PRM modulation pattern were observed in both implanted monkeys in the direction consistent with the activation of the implanted canal. Both PAM and PRM pulse trains can elicit a significant amount of in-phase modulated eye velocity changes and they could potentially be used for efficiently coding head rotational signals in future vestibular neural prostheses.,"Electrodes,
Animals,
Irrigation,
Software,
Prosthetics,
Cochlear implants,
Arrays"
Memetic Algorithm for Real-Time Combinatorial Stochastic Simulation Optimization Problems With Performance Analysis,"A three-phase memetic algorithm (MA) is proposed to find a suboptimal solution for real-time combinatorial stochastic simulation optimization (CSSO) problems with large discrete solution space. In phase 1, a genetic algorithm assisted by an offline global surrogate model is applied to find N good diversified solutions. In phase 2, a probabilistic local search method integrated with an online surrogate model is used to search for the approximate corresponding local optimum of each of the N solutions resulted from phase 1. In phase 3, the optimal computing budget allocation technique is employed to simulate and identify the best solution among the N local optima from phase 2. The proposed MA is applied to an assemble-to-order problem, which is a real-world CSSO problem. Extensive simulations were performed to demonstrate its superior performance, and results showed that the obtained solution is within 1% of the true optimum with a probability of 99%. We also provide a rigorous analysis to evaluate the performance of the proposed MA.","Computational modeling,
Biological cells,
Search methods,
Optimization,
Vectors,
Stochastic processes,
Probabilistic logic"
Optimal Power Allocation for CR Networks with Direct and Relay-Aided Transmissions,"Cognitive radio (CR) technology has been developed to solve the spectrum-underutilization problem. In CR networks, the CR users have opportunities to access the licensed spectrum bands assigned to the primary users (PUs). Since the PUs have priorities to use the bands, the CR users are not allowed to generate unacceptable interference to them. In this paper, we investigate power allocation schemes for CR networks with both direct and relay-aided transmissions. We first formulate an overall rate optimization problem with interference constraints to the PU and peak power constraints at each node and obtain solutions by theoretical analysis. To take the fairness among CR users into consideration, we further investigate the overall rate optimization problem with an additional sum power constraint and achieve fairness between two CR users by adjusting the sum power threshold. Numerical results are provided to show the impact of the relay node and the PU locations on power allocation solutions.",
Visual terrain classification for selecting energy efficient gaits of a hexapod robot,"Legged robots need to be able to classify and recognize different terrains to adapt their gait accordingly. Recent works in terrain classification use different types of sensors (like stereovision, 3D laser range, and tactile sensors) and their combination. However, such sensor systems require more computing power, produce extra load to legged robots, and/or might be difficult to install on a small size legged robot. In this work, we present an online terrain classification system. It uses only a monocular camera with a feature-based terrain classification algorithm which is robust to changes in illumination and view points. For this algorithm, we extract local features of terrains using either Scale Invariant Feature Transform (SIFT) or Speed Up Robust Feature (SURF). We encode the features using the Bag of Words (BoW) technique, and then classify the words using Support Vector Machines (SVMs) with a radial basis function kernel. We compare this feature-based approach with a color-based approach on the Caltech-256 benchmark as well as eight different terrain image sets (grass, gravel, pavement, sand, asphalt, floor, mud, and fine gravel). For terrain images, we observe up to 90% accuracy with the feature-based approach. Finally, this online terrain classification system is successfully applied to our small hexapod robot AMOS II. The output of the system providing terrain information is used as an input to its neural locomotion control to trigger an energy-efficient gait while traversing different terrains.","Robot sensing systems,
Feature extraction,
Transforms,
Robustness,
Asphalt,
Floors"
Exponential and Power Law Distribution of Contact Duration in Urban Vehicular Ad Hoc Networks,"Contact duration between moving vehicles is one of the key metrics in vehicular ad hoc networks (VANETs), that critically influences the design of routing schemes and network throughput. Due to prohibitive costs to collect enough realistic contact records, little experimental work has been conducted to study the contact duration in urban VANETs. In this work, we carry out an extensive experiment involving tens of thousands of operational taxis in Beijing city. Based on studying this newly collected Beijing trace and the existing Shanghai trace, we find an invariant characteristic that there exists a characteristic time point, up to which the contact duration obeys an exponential distribution that includes at least 80% of the whole distribution, while beyond which it decays as a power law one. This property is in sharp contrast to the recent empirical data studies based on human mobility, where the contact duration exhibits a power law distribution. Our observations thus provide fundamental guidelines for the design of new urban VANETs' routing protocols and their performance evaluation.",
Conflict-aware optimal scheduling of prioritised code clone refactoring,"Duplicated or similar source code, also known as code clones, are possible malicious 'code smells' that may need to be removed through refactoring to enhance maintainability. Among many potential refactoring opportunities, the choice and order of a set of refactoring activities may have distinguishable effect on the design/code quality measured in terms of software metrics. Moreover, there may be dependencies and conflicts among those refactorings of different priorities. Addressing all the conflicts, priorities and dependencies, a manual formulation of an optimal refactoring schedule is very expensive, if not impossible. Therefore an automated refactoring scheduler is necessary to 'maximise benefit and minimise refactoring effort'. However, the estimation of the efforts required to perform code clone refactoring is a challenging task. This study makes two contributions. First, the authors propose an effort model for the estimation of code clone refactoring efforts. Second, the authors propose a constraint programming (CP) approach for conflict-aware optimal scheduling of code clone refactoring. A qualitative evaluation of the effort model from the developers' perspective suggests that the model is complete and useful for code clone refactoring effort estimation. The authors also quantitatively compared their refactoring scheduler with other wellknown scheduling techniques such as the genetic algorithm, greedy approaches and linear programming. The authors' empirical study suggests that the proposed CP-based approach outperforms other approaches they considered.",
Matched Filtering From Limited Frequency Samples,"In this paper, we study a simple correlation-based strategy for estimating the unknown delay and amplitude of a signal based on a small number of noisy, randomly chosen frequency-domain samples. We model the output of this “compressive matched filter” as a random process whose mean equals the scaled, shifted autocorrelation function of the template signal. Using tools from the theory of empirical processes, we prove that the expected maximum deviation of this process from its mean decreases sharply as the number of measurements increases, and we also derive a probabilistic tail bound on the maximum deviation. Putting all of this together, we bound the minimum number of measurements required to guarantee that the empirical maximum of this random process occurs sufficiently close to the true peak of its mean function. We conclude that for broad classes of signals, this compressive matched filter will successfully estimate the unknown delay (with high probability and within a prescribed tolerance) using a number of random frequency-domain samples that scales inversely with the signal-to-noise ratio and only logarithmically in the observation bandwidth and the possible range of delays.",
Sensation of Realness From High-Resolution Images of Real Objects,"We performed subjective assessments to quantify the sensation of realness for images at various angular resolutions and that of their real-object counterparts using a paired-comparison procedure. Both the images and real objects were viewed through a synopter, which removed horizontal disparity and presented the same images to both eyes. The size, perspective, luminance, and chromaticity of the images were reproduced to be identical to those of the real objects. Eighty-two observers with normal vision were asked to choose the viewed image that appeared most similar to the real object for each pair of images. The results indicated that the realness of images increased steadily as the image resolution increased up to around 60 cycles per degree, whereafter it gradually approached that of the real objects.","Visualization,
Image color analysis,
Observers,
Spatial resolution,
Imaging,
Adaptive optics"
Source Transmit Antenna Selection for MIMO Decode-and-Forward Relay Networks,"Transmit antenna selection (TAS) is usually applied to multiple-input multiple-output (MIMO) systems because it does not require additional radio frequency (RF) chains which are quite expensive. In MIMO decode-and-forward (DF) relay networks, both source-destination and source-relay-destination paths should be simultaneously considered to find an effective source TAS (STAS). In this paper, a new STAS is proposed based on both channel state information and transmission scheme for the MIMO DF relay networks. It is also shown that the proposed STAS which selects
M
SS
antennas among
M
S
transmit antennas at the source can achieve full diversity regardless of the value of
M
SS
. Simulation results show that the proposed STAS has better average bit error probability (BEP) performance than other STASs. Also, the proposed STAS with
M
SS
=1
has lower cost, complexity, overhead, and BEP than the STAS with
M
SS
>1
using full-rate full-diversity space-time block codes with the same total transmit power.","Relays,
Transmitting antennas,
MIMO,
Symmetric matrices,
Upper bound,
Signal to noise ratio"
On the Stability and Control of Continuous-Time TSK Fuzzy Systems,"This paper introduces a new stability test and control design methodology for type-1 and type-2 continuous-time (CT) Takagi-Sugeno-Kang systems. Unlike methods based on a common Lyapunov function, our stability results apply for systems with unstable consequents, and our controllers can be designed for systems with unstabilizable consequents. The stability results are derived using the comparison principle with a discontinuous function and the upper right-hand derivative. The control results include CT fuzzy proportional controllers and fuzzy proportional-integral controllers that can be obtained by solving linear matrix inequalities. We provide several examples to demonstrate our stability testing and controller design and compare our results to available methods in the literature. Our results compare favorably with results available in the literature and provide stability tests and controllers where earlier approaches fail.",
Interactive Multimodal Visual Search on Mobile Device,"This paper describes a novel multimodal interactive image search system on mobile devices. The system, the Joint search with ImaGe, Speech, And Word Plus (JIGSAW
+
), takes full advantage of the multimodal input and natural user interactions of mobile devices. It is designed for users who already have pictures in their minds but have no precise descriptions or names to address them. By describing it using speech and then refining the recognized query by interactively composing a visual query using exemplary images, the user can easily find the desired images through a few natural multimodal interactions with his/her mobile device. Compared with our previous work JIGSAW, the algorithm has been significantly improved in three aspects: 1) segmentation-based image representation is adopted to remove the artificial block partitions; 2) relative position checking replaces the fixed position penalty; and 3) inverted index is constructed instead of brute force matching. The proposed JIGSAW
+
is able to achieve 5% gain in terms of search performance and is ten times faster.","Visualization,
Speech recognition,
Mobile handsets,
Mobile communication,
Speech,
Databases,
Internet"
Software Defined Networking across Distributed Datacenters over Cloud,"Cloud computing, in particular its system spread across several data centers, poses a unique set of networking challenges and management problems. This paper presents our design, implementation, and experience in tackling these challenges by using the concepts and technologies of software-defined network (SDN). We define a network abstraction to incorporate the physical and virtual data plane within a data center. We propose a new network primitive to address the interconnection issues among multiple data centers. A policy plane consolidating these mechanisms provides a programmable interface to enable a wide range of policies and new networking mechanisms. We present the performance result on a real deployment over the production networks. The experience and initial performance results demonstrate that the SDN is a promising solution to cloud networking.",
Comparative study between HDP and PSS on DFIG damping control,"In this paper, heuristic dynamic programming (HDP) based supplementary control is compared with the power system stabilizer (PSS) based supplementary control for doubly-fed induction generators (DFIG), namely, the active power damping control. The traditional design of PSS control on DFIG damping is based on eigenvalue analysis. For such analysis, disturbances are considered sufficiently small to permit the nonlinear model representing the power system to be linearized and expressed in state space form. When the disturbance or the system configuration changes, this kind of design is easy to become entrapped in local minimal and the robust ability of the controller is not guaranteed. On the other side, the HDP based supplementary damping controller analyzed in this paper is “model-free” with on-line learning capability: once a system state is observed, an action will be subsequently produced based on the performance index function. The obtained results by such a HDP supplementary controller on a benchmark power system are compared with the traditional PSS controller, demonstrating the improved control performance and robustness.",
Optimization of interconnects between accelerators and shared memories in dark silicon,"Application-specific accelerators provide orders-of-magnitude improvement in energy-efficiency over CPUs, and accelerator-rich computing platforms are showing promise in the dark silicon age. Memory sharing among accelerators leads to huge transistor savings, but needs novel designs of interconnects between accelerators and shared memories. Accelerators run 100x faster than CPUs and post a high demand on data. This leads to resource-consuming interconnects if we follow the same design rules as those for interconnects between CPUs and shared memories, and simply duplicate the interconnect hardware to meet the accelerator data demand. In this work we develop a novel design of interconnects between accelerators and shared memories and exploit three optimization opportunities that emerge in accelerator-rich computing platforms: 1) The multiple data ports of the same accelerators are powered on/off together, and the competition for shared resources among these ports can be eliminated to save interconnect transistor cost; 2) In dark silicon, the number of active accelerators in an accelerator-rich platform is usually limited, and the interconnects can be partially populated to just fit the data access demand limited by the power budget; 3) The heterogeneity of accelerators leads to execution patterns among accelerators and, based on the probability analysis to identify these patterns, interconnects can be optimized for the expected utilization. Experiments show that our interconnect design outperforms prior work that was optimized for CPU cores or signal routing.","Switches,
Ports (Computers),
Optimization,
Acceleration,
Silicon,
Memory management,
Transistors"
A Distributed Localization Algorithm for Wireless Sensor Networks Based on the Solutions of Spatially-Constrained Local Problems,"We present a distributed localization algorithm for wireless sensor networks. Each sensor estimates its position by iteratively solving a set of local spatially-constrained programs. The constraints allow sensors to update their positions simultaneously and collaboratively using range and position estimates to those neighbors within their communications range. Moreover, the algorithm is designed for implementation with resource-limited devices. Since the exchange of information among sensors is a key component for this method, we introduce a stopping criterion to monitor the wireless transmissions for the whole network in order to significantly reduce energy consumption with minimal impact on localization accuracy. Experimental results show that we can determine the best tradeoff between wireless transmissions and accuracy. The performance of the proposed scheme is very competitive when compared with similar and more computationally demanding schemes.","Sensors,
Wireless sensor networks,
Wireless communication,
Accuracy,
Silicon,
Global Positioning System,
Optimization"
Plasma Science and Technology in the Limit of the Small: Microcavity Plasmas and Emerging Applications,"Over approximately the past decade, a subfield of plasma science has arisen that is redefining frontiers in the physics of low temperature plasma and its applications. Concerned with the confinement of weakly ionized, nonequilibrium plasma to cavities having mesoscopic dimensions, the emerging area of microcavity plasmas has advanced rapidly in surpassing several milestones, primarily with respect to electron density and cavity geometries, and is establishing new avenues of research. To date, peak electron densities above 1017 cm-3, cavity dimensions as small as 3 μm , microchannel aspect ratios (length: width) of 103:1 , plasma packets propagating at velocities up to 20 km s-1 , and coupling between e--h+ and e--ion plasmas have all been observed, but every indication is that these results are only a foretaste of the future. This review describes several recent device geometries and provides a synopsis of the physics. Promising applications of this technology in chemical processing, lighting, water disinfection, and medicine are also discussed briefly.","plasma devices,
electron density,
microcavities,
micromechanical devices,
plasma applications,
plasma confinement,
plasma density"
VoteTrust: Leveraging friend invitation graph to defend against social network Sybils,"Online social networks (OSNs) currently face a significant challenge by the existence and continuous creation of fake user accounts (Sybils), which can undermine the quality of social network service by introducing spam and manipulating online rating. Recently, there has been much excitement in the research community over exploiting social network structure to detect Sybils. However, they rely on the assumption that Sybils form a tight-knit community, which may not hold in real OSNs. In this paper, we present VoteTrust, a Sybil detection system that further leverages user interactions of initiating and accepting links. VoteTrust uses the techniques of trust-based vote assignment and global vote aggregation to evaluate the probability that the user is a Sybil. Using detailed evaluation on real social network (Renren), we show VoteTrust's ability to prevent Sybils gathering victims (e.g., spam audience) by sending a large amount of unsolicited friend requests and befriending many normal users, and demonstrate it can significantly outperform traditional ranking systems (such as TrustRank or BadRank) in Sybil detection.","Communities,
Upper bound,
Security,
Equations,
Mathematical model,
Facebook"
Image denoising using NL-means via smooth patch ordering,"In our recent work we proposed an image denoising scheme based on reordering of the noisy image pixels to a one dimensional (1D) signal, and applying linear smoothing filters on it. This algorithm had two main limitations: It did not take advantage of the distances between the noisy image patches, which were used in the reordering process; and the smoothing filters required a separate training set to be learned from. In this work, we propose an image denoising algorithm, which applies similar permutations to the noisy image, but overcomes the above two shortcomings. We eliminate the need for learning filters by employing the nonlocal means (NL-means) algorithm. We estimate each pixel as a weighted average of noisy pixels in union of neighborhoods obtained from different global pixel permutations, where the weights are determined by distances between the patches. We show that the proposed scheme achieves results which are close to the state-of-the-art.","Noise measurement,
Noise reduction,
Image denoising,
Smoothing methods,
Vectors,
PSNR"
RaSMaLai: A Randomized Switching algorithm for Maximizing Lifetime in tree-based wireless sensor networks,"In most wireless sensor network (WSN) applications, data are typically gathered by the sensor nodes and reported to a data collection point, called the sink. In order to support such data collection, a tree structure rooted at the sink is usually defined. Based on different aspects, including the actual WSN topology and the available energy budget, the energy consumption of nodes belonging to different paths in the data collection tree may vary significantly. This affects the overall network lifetime, defined in terms of when the first node in the network runs out of energy. In this paper, we address the problem of lifetime maximization of WSNs in the context of data collection trees. In particular, we propose a novel and efficient algorithm, called Randomized Switching for Maximizing Lifetime (RaSMaLai) that aims at maximizing the lifetime of WSNs through load balancing with a low time complexity. We further design a distributed version of our algorithm, called D-RaSMaLai. Simulation results show that both the proposed algorithms outperform several existing approaches in terms of network lifetime. Moreover, RaSMaLai offers lower time complexity while the distributed version, D-RaSMaLai, is very efficient in terms of energy expenditure.","Switches,
Data collection,
Wireless sensor networks,
Load management,
Time complexity,
Oscillators,
Educational institutions"
A non-negative sparse promoting algorithm for high resolution hyperspectral imaging,"Promoting the spatial resolution of off-the-shelf hyperspectral sensors is expected to improve typical computer vision tasks, such as target tracking and image classification. In this paper, we investigate the scenario in which two cameras, one with a conventional RGB sensor and the other with a hyperspectral sensor, capture the same scene, attempting to extract redundant and complementary information. We propose a non-negative sparse promoting framework to integrate the hyperspectral and RGB data into a high resolution hyperspectral set of data. The formulated problem is in the form of a sparse non-negative matrix factorization with prior knowledge on the spectral and spatial transform responses, and it can be handled by alternating optimization where each subproblem is solved by efficient convex optimization solvers; e.g., the alternating direction method of multipliers. Experiments on a public database show that our method achieves much lower average reconstruction errors than other state-of-the-art methods.",
An iterative double auction for mobile data offloading,"Mobile data offloading through complementary network technologies such as WiFi and femtocell can significantly alleviate network congestion and enhance users' QoS. In this paper we consider a market where mobile network operators (MNOs) lease third-party deployed WiFi or femtocell access points (APs) to dynamically offload the traffic of their mobile users. We assume that each MNO can employ multiple APs and each AP can concurrently serve traffic from multiple MNOs. We design an iterative double auction mechanism that ensures the efficient operation of the market, where MNOs maximize their offloading benefits and APs minimize their offloading costs. Such a mechanism incorporates the special characteristics of the wireless network, such as the coupling of MNOs' offloading decisions and APs' capacity constraints. The proposed market scheme does not require full information about the MNOs and APs, incurs minimum communication overhead, and creates non-negative revenue for the market broker.","Mobile communication,
Mobile computing,
Vectors,
IEEE 802.11 Standards,
Resource management,
Ad hoc networks,
Optimization"
Optimal Liveness-Enforcing Control for a Class of Petri Nets Arising in Multithreaded Software,"We investigate the synthesis of optimal liveness-enforcing control policies for Gadara nets, a special class of Petri nets that arises in the modeling of the execution of multithreaded computer programs for the purpose of deadlock avoidance. We consider maximal permissiveness as the notion of optimality. Deadlock-freeness of a multithreaded program corresponds to liveness of its Gadara net model. We present a new control synthesis algorithm for liveness enforcement of Gadara nets that need not be ordinary. The algorithm employs structural analysis of the net and synthesizes monitor places to prevent the formation of a special class of siphons, termed resource-induced deadly-marked siphons. The algorithm also accounts for uncontrollable transitions in the net in a minimally restrictive manner. The algorithm is generally an iterative process and converges in a finite number of iterations. It exploits a covering of the unsafe states that is updated at each iteration. The proposed algorithm is shown to be correct and maximally permissive with respect to the goal of liveness enforcement.",
Zero-copy I/O processing for low-latency GPU computing,"Cyber-physical systems (CPS) aim to monitor and control complex real-world phenomena where the computational cost and real-time constraints could be a major challenge. Manycore hardware accelerators such as graphics processing units (GPUs) promise to enhancing computation, leveraging the data parallelism often found in real-world scenarios of CPS, but performance is limited by the overhead of the data transfer between the host and the device memory. For example, plasma control in the HBT-EP Tokamak device at Columbia University [11, 18] must execute the control algorithm in a few microseconds, but may take tens of microseconds to copy the data set between the host and the device memory. This paper presents a zero-copy I/O processing scheme that maps the I/O address space of the system to the virtual address space of the compute device, allowing sensors and actuators to transfer data to and from the compute device directly. Experiments using the plasma control system show a 33% reduction in computational cost, and microbenchmarks with more generic matrix operations show a 34% reduction, while in both cases, effective data throughput remains at least as good as the current best performers.","Graphics processing units,
Data transfer,
Aerospace electronics,
Plasmas,
Control systems,
Real-time systems,
Bars"
Explainers: Expert Explorations with Crafted Projections,"This paper introduces an approach to exploration and discovery in high-dimensional data that incorporates a user's knowledge and questions to craft sets of projection functions meaningful to them. Unlike most prior work that defines projections based on their statistical properties, our approach creates projection functions that align with user-specified annotations. Therefore, the resulting derived dimensions represent concepts defined by the user's examples. These especially crafted projection functions, or explainers, can help find and explain relationships between the data variables and user-designated concepts. They can organize the data according to these concepts. Sets of explainers can provide multiple perspectives on the data. Our approach considers tradeoffs in choosing these projection functions, including their simplicity, expressive power, alignment with prior knowledge, and diversity. We provide techniques for creating collections of explainers. The methods, based on machine learning optimization frameworks, allow exploring the tradeoffs. We demonstrate our approach on model problems and applications in text analysis.",
Reliable communication envelopes of molecular diffusion channels,"Radio frequency communications are not always possible in hostile electromagnetic environments, and the molecular diffusion channel is considered as an information channel. A binary concentration modulated channel is considered and treated is the uncertain arrival time of particles as the main source of inter-symbol interference. The analysis derives the bit-error-rate and data rate expressions for a diffusion channel with zero drift. The minimum error rate and maximum data rate are derived analytically. It is also found that in order for reliable communications to be possible, the delay time must be greater than a threshold that is proportional to the square of the communication distance.","wireless channels,
error statistics,
intersymbol interference,
modulation,
molecular communication (telecommunication),
radiofrequency interference,
telecommunication network reliability"
Design of NCL gates with the ASCEnD flow,"Silicon technologies advances brought the possibility of integrating billions of transistors in a die. However, as transistors get smaller, some of the aspects that were negligible in previous technologies emerge as difficulties for the design in current and future technology nodes. In this context, fully synchronous circuits are harder to be built, as timing closure constraints become difficult to be met, and the asynchronous paradigm gains interest in the research community for its ability to cope with current technologies issues. AS-CEnD was proposed as a standard cell library for supporting standard-cell based design of asynchronous circuits and comprises a design flow for asynchronous components. This work presents the use of the ASCEnD flow to design NCL gates, which enable design improvement opportunities for some asynchronous templates. A total of 14 different NCL gates were designed at the layout level and had their electrical behavior characterized. As a result, electrical and physical models of these gates are now part of the ASCEnD library.","Logic gates,
Delays,
Adders,
Libraries,
Transistors,
Asynchronous circuits,
Layout"
Precision tracking with sparse 3D and dense color 2D data,"Precision tracking is important for predicting the behavior of other cars in autonomous driving. We present a novel method to combine laser and camera data to achieve accurate velocity estimates of moving vehicles. We combine sparse laser points with a high-resolution camera image to obtain a dense colored point cloud. We use a color-augmented search algorithm to align the dense color point clouds from successive time frames for a moving vehicle, thereby obtaining a precise estimate of the tracked vehicle's velocity. Using this alignment method, we obtain velocity estimates at a much higher accuracy than previous methods. Through pre-filtering, we are able to achieve near real time results. We also present an online method for real-time use with accuracies close to that of the full method. We present a novel approach to quantitatively evaluate our velocity estimates by tracking a parked car in a local reference frame in which it appears to be moving relative to the ego vehicle. We use this evaluation method to automatically quantitatively evaluate our tracking performance on 466 separate tracked vehicles. Our method obtains a mean absolute velocity error of 0.27 m/s and an RMS error of 0.47 m/s on this test set. We can also qualitatively evaluate our method by building color 3D car models from moving vehicles. We have thus demonstrated that our method can be used for precision car tracking with applications to autonomous driving and behavior modeling.","Vehicles,
Three-dimensional displays,
Tracking,
Accuracy,
Cameras,
Interpolation,
Lasers"
On reconfigurable Single-Electron Transistor arrays synthesis using reordering techniques,"Power consumption has become one of the primary challenges in meeting Moore's law. Fortunately, Single-Electron Transistor (SET) at room temperature has been demonstrated as a promising device for extending Moore's law due to its ultra low power consumption during operation. An automated mapping approach for the SET architecture has been proposed recently for facilitating design realization. In this paper, we propose an enhanced approach consisting of variable reordering, product term reordering, and mapping constraint relaxation techniques to minimizing the area of mapped SET arrays. The experimental results show that our enhanced approach, on average, saves 40% in area and 17% in mapping time compared to the state-of-the-art approach for a set of MCNC and IWLS 2005 benchmarks.","Boolean functions,
Data structures,
Fabrics,
Image edge detection,
Benchmark testing,
Educational institutions,
Logic gates"
Quantum Rate-Distortion Coding With Auxiliary Resources,"We extend quantum rate-distortion theory by considering auxiliary resources that might be available to a sender and receiver performing lossy quantum data compression. The first setting we consider is that of quantum rate-distortion coding with the help of a classical side channel. Our result here is that the regularized entanglement of formation characterizes the quantum rate-distortion function, extending earlier work of Devetak and Berger. We also combine this bound with the entanglement-assisted bound from our prior work to obtain the best known bounds on the quantum rate-distortion function for an isotropic qubit source. The second setting we consider is that of quantum rate-distortion coding with quantum side information (QSI) available to the receiver. In order to prove results in this setting, we first state and prove a quantum reverse Shannon theorem with QSI (for tensor-power states), which extends the known tensor-power quantum reverse Shannon theorem. The achievability part of this theorem relies on the quantum state redistribution protocol, while the converse relies on the fact that the protocol can cause only a negligible disturbance to the joint state of the reference and the receiver's QSI. This quantum reverse Shannon theorem with QSI naturally leads to quantum rate-distortion theorems with QSI, with or without entanglement assistance.","Rate-distortion,
Quantum entanglement,
Channel coding,
Mutual information,
Educational institutions"
Energy efficient computing- Green cloud computing,"Moving towards Cloud Computing, high performance computing usage of huge data center (DC) and huge cluster is increasing day by day and energy consumption by these DC and energy dissipation in environment by these DC is also rising day by day. The large amount of CO2 dissipation in environment has generated the necessity of Green computing (saving energy by recycling it and reusing it over a period of time and minimizing the wastage in terms of usage of resources). More processor chips generates more heat, more heat requires more cooling and cooling again generates heats and thus we come to a stage where we want to balance the system by getting the same computing speed at decreased energy consumption. In this paper we proposed different ideas towards green cloud computing approach.","Cooling,
Servers,
Cloud computing,
Green products,
Power demand,
Energy efficiency,
Air pollution"
An Achievable Rate Region for the Broadcast Channel With Feedback,"A single-letter achievable rate region is proposed for the two-receiver discrete memoryless broadcast channel with generalized feedback. The coding strategy involves block-Markov superposition coding using Marton's coding scheme for the broadcast channel without feedback as the starting point. If the message rates in the Marton scheme are too high to be decoded at the end of a block, each receiver is left with a list of messages compatible with its output. Resolution information is sent in the following block to enable each receiver to resolve its list. The key observation is that the resolution information of the first receiver is correlated with that of the second. This correlated information is efficiently transmitted via joint source-channel coding, using ideas similar to the Han-Costa coding scheme. Using the result, we obtain an achievable rate region for the stochastically degraded additive white Gaussian noise broadcast channel with noisy feedback from only one receiver. It is shown that this region is strictly larger than the no-feedback capacity region.","Receivers,
Encoding,
Random variables,
Joints,
Noise measurement,
Transmitters,
Vectors"
Surface Versus Untargeted Intramuscular EMG Based Classification of Simultaneous and Dynamically Changing Movements,"The pattern recognition-based myoelectric control scheme is in the process of being implemented in clinical settings, but it has been mainly tested on sequential and steady state data. This paper investigates the ability of pattern recognition to resolve movements that are simultaneous and dynamically changing and compares the use of surface and untargeted intramuscular EMG signals for this purpose. Ten able-bodied subjects participated in the study. Both EMG types were recorded concurrently from the right forearm. The subjects were instructed to track dynamic contraction profiles using single and combined degrees of freedom in three trials. During trials one and two, the amplitude and the frequency of the profile were kept constant (nonmodulated data), and during trial three, the two parameters were modulated (modulated data). The results showed that the performance was up to 93% for nonmodulated tasks, but highly depended on the nature of the data used. Surface and untargeted intramuscular EMG had equal performance for data of similar nature (nonmodulated), but the performance of intramuscular EMG decreased, compared to surface, when tested on modulated data. However, the results of intramuscular recordings obtained in this study are promising for future use of implantable electrodes, because, besides the value added in terms of potential chronic implantation, the performance is theoretically the same as for surface EMG provided that enough information is captured in the recordings. Nevertheless, care should be taken when training the system since data obtained from selective recordings probably need more training data to generalize to new signals.",
Computational Homogenization for Laminated Ferromagnetic Cores in Magnetodynamics,"In this paper, we investigate the modeling of ferromagnetic multiscale materials. We propose a computational homogenization technique based on the heterogeneous multiscale method (HMM) that includes both eddy-current and hysteretic losses at the mesoscale. The HMM comprises: 1) a macroscale problem that captures the slow variations of the overall solution; 2) many mesoscale problems that allow to determine the constitutive law at the macroscale. As application example, a laminated iron core is considered.","Magnetic hysteresis,
Lamination,
Materials,
Hidden Markov models,
Magnetostatics,
Magnetic domains,
Computational modeling"
Comparing Supervised Learning Techniques on the Task of Physical Activity Recognition,"The objective of this study was to compare the performance of base-level and meta-level classifiers on the task of physical activity recognition. Five wireless kinematic sensors were attached to each subject (n = 25) while they completed a range of basic physical activities in a controlled laboratory setting. Subjects were then asked to carry out similar self-annotated physical activities in a random order and in an unsupervised environment. A combination of time-domain and frequency-domain features was extracted from the sensor data including the first four central moments, zero-crossing rate, average magnitude, sensor cross correlation, sensor autocorrelation, spectral entropy, and dominant frequency components. A reduced feature set was generated using a wrapper subset evaluation technique with a linear forward search and this feature set was employed for classifier comparison. The meta-level classifier AdaBoostM1 with C4.5 Graft as its base-level classifier achieved an overall accuracy of 95%. Equal sized datasets of subject-independent data and subject-dependent data were used to train this classifier and high recognition rates could be achieved without the need for user specific training. Furthermore, it was found that an accuracy of 88% could be achieved using data from the ankle and wrist sensors only.","Accuracy,
Wrist,
Feature extraction,
Sensor phenomena and characterization,
Support vector machines,
Training"
Scalable Channel Allocation and Access Scheduling for Wireless Internet-of-Things,"Wireless communication channels are a scarce resource shared among multiple users in either scheduled or randomized fashions. We challenge a few design aspects of the widely used IEEE 802.11 MAC in wireless sensor networks (WSNs), such as the use of RTS, CTS, and ACK handshaking and the binary exponential backoff mechanisms, and argue that these key mechanisms incur high channel overhead and cannot effectively eliminate hidden terminal problems in multi-hop scenarios. Instead, we propose a set of efficient grid-based channel allocation and access scheduling algorithms using Latin squares, called as GAALS, for scalable WSNs with single-radio multi-channel communication capabilities. Using nodal location information and forming grids over the WSN deployment area, GAALS maps Latin squares to the grids, and dynamically assigns multiple channels to the WSN grids for channel access scheduling purposes. The fairness and scalability of GAALS are analyzed and evaluated in multiflow multihop WSNs with multi-channel capabilities. The results show that GAALS achieves much better performance than other multichannel protocols.",
Acceleration Closed-Loop Control on a Switched Reluctance Linear Launcher,"In this paper we describe a developed switched reluctance linear launcher system with diagrams and photographs, which consists of a three-phase 6/4 structure simple side-switched reluctance linear motor, a three-phase asymmetric bridge power converter, and a TMS320F28335 DSP digital controller. The acceleration closed-loop control of the mover is proposed and verified for the first time. The acceleration closed-loop control of the mover is implemented by a fuzzy control algorithm. The turn-on angle and the turn-off angle of the main switches in the power converter are fixed, and the triggering signals of the main switches are modulated by the pulse width modulation (PWM) signal. The deviation of the acceleration between the given acceleration and the feedback practical acceleration, and the variation from the deviation of the acceleration are the two input control parameters. The increment of the duty ratio of the PWM signal is the output control parameter. The duty ratio of the PWM signal is regulated based on the fuzzy control algorithm. Flow diagrams of the software, such as the main program, the encoder unit time interrupt subroutine, analog-to-digital converter interrupt subroutine, and the fuzzy control algorithm subroutine are given. The developed prototype is tested experimentally. It is shown that the velocity response of the mover is satisfactory.","Acceleration,
Reluctance motors,
Switches,
Pulse width modulation,
Windings"
Secure Data Discovery and Dissemination based on Hash Tree for Wireless Sensor Networks,"Wireless sensor networks (WSNs) are widely applicable in monitoring and control of environment parameters. It is sometimes necessary to disseminate data through wireless links after they are deployed in order to adjust configuration parameters of sensors or distribute management commands and queries to sensors. Several approaches have been proposed recently for data discovery and dissemination in WSNs. However, they all focus on how to ensure reliability and usually overlook security vulnerabilities. This paper identifies the security vulnerabilities in data discovery and dissemination when used in WSNs. Such vulnerabilities allow an adversary to update a network with undesirable values, erase critical variables, or launch denial-of-service (DoS) attacks. To address these vulnerabilities, this paper presents the design, implementation, and evaluation of a secure, lightweight, and DoS-resistant data discovery and dissemination protocol named SeDrip for WSNs. Our protocol takes into consideration the limited resources of sensor nodes, packet loss and out-of-sequence packet delivery. Also, it can provide instantaneous authentication without packet buffering delay, and tolerate node compromise. Besides the theoretical analysis that demonstrates the security and performance of SeDrip, this paper also reports the experimental evaluation of SeDrip in a network of resource-limited sensor nodes, which shows its efficiency in practice.",
A High Efficiency Orthogonally Switching Passive Charge Pump Rectifier for Energy Harvesters,"The design and analytical modeling of a high efficiency energy harvester comprising a passive voltage-boosting network (VBN) and a switching charge pump rectifier (CPR) is presented in this paper. To improve the power conversion efficiency (PCE), the VBN increases the voltage at the input of the CPR and provides control signals for switching. Unlike traditional Schottky and diode-connected MOS transistor rectifiers, the proposed orthogonally switching CPR (OS-CPR) comprises MOS transistors as voltage-controlled switches. Analytical models for the OS-CPR are developed and presented. Circuit-level optimization techniques are employed to reduce conduction and switching losses. Simulated in a 90 nm standard CMOS technology (IBM 9RF), a 5-stage 915 MHz OS-CPR achieves a dc voltage of 1.35 V and a PCE of 11.9% with a 1 MΩ load at -18.2 dBm available input power (PS,AV). To show technology scalability of the design, the OS-CPR is also validated using AMS 0.18 μm high-voltage (HV) CMOS technology. When benchmarked with traditional rectifiers, the OS-CPR (under similar conditions) achieves a higher PCE and a higher output dc voltage. The OS-CPR is easily scalable to operate over multiple sub-GHz ISM frequency bands.","MOSFETs,
Charge pumps,
Approximation methods,
Switches,
Radio frequency,
Switching circuits,
Schottky diodes"
Error Analysis of Stochastic Gradient Descent Ranking,"Ranking is always an important task in machine learning and information retrieval, e.g., collaborative filtering, recommender systems, drug discovery, etc. A kernel-based stochastic gradient descent algorithm with the least squares loss is proposed for ranking in this paper. The implementation of this algorithm is simple, and an expression of the solution is derived via a sampling operator and an integral operator. An explicit convergence rate for leaning a ranking function is given in terms of the suitable choices of the step size and the regularization parameter. The analysis technique used here is capacity independent and is novel in error analysis of ranking learning. Experimental results on real-world data have shown the effectiveness of the proposed algorithm in ranking tasks, which verifies the theoretical analysis in ranking error.","Algorithm design and analysis,
Error analysis,
Kernel,
Convergence,
Hilbert space,
Approximation error"
Modeling Power Consumption of NAND Flash Memories Using FlashPower,"Flash is the most popular solid-state memory technology used today. A range of consumer electronics products, such as cell-phones and music players, use flash memory for storage and flash memory is increasingly displacing hard disk drives as the primary storage device in laptops, desktops, and servers. There is a rich microarchitectural design space for flash memory, and there are several architectural options for incorporating flash into the memory hierarchy. Exploring this design space requires detailed insights into the power characteristics of flash memory. In this paper, we present FlashPower, a detailed power model for the two most popular variants of NAND flash, namely, the single-level cell (SLC) and 2-bit Multi-Level Cell (MLC) based flash memory chips. FlashPower is built on top of CACTI, a widely used tool in the architecture community for studying various memory organizations. FlashPower takes several parameters like the device technology, microarchitectural layout, bias voltages and workload parameters as input to estimate the power consumption of a flash chip during its various operating modes. We validate FlashPower against chip power measurements from several different manufacturers and show that our results are comparable to the actual chip measurements. We illustrate the versatility of the tool in a design space exploration of power optimal flash memory array configurations.",
360 PPI Flip-Chip Mounted Active Matrix Addressable Light Emitting Diode on Silicon (LEDoS) Micro-Displays,"In this paper, we describe the design and fabrication of 360 PPI flip-chip mounted active matrix (AM) addressable light emitting diode on silicon (LEDoS) micro-displays. The LEDoS micro-displays are self-emitting devices which have higher light efficiency than liquid crystal based displays (LCDs) and longer lifetime than organic light emitting diodes (OLEDs) based displays . The LEDoS micro-displays were realized by integrating monolithic LED micro-arrays and silicon-based integrated circuit using a flip-chip bonding technique. The active matrix driving scheme was designed on the silicon to provide sufficient driving current and individual controllability of each LED pixel. Red, green, blue and Ultraviolet (UV) LEDoS micro-displays with a pixel size of 50 μm and pixel pitch of 70 μm were demonstrated. With a peripheral driving board, the LEDoS micro-display panels were programmed to show representative images and animations.",
In-vehicle hand activity recognition using integration of regions,"In this paper, we focus on the analysis of naturalistic driver behavior using hand activity. To that end, a dataset of color and depth images under varying operating modes and illumination settings was collected. The proposed framework provides a robust solution for localizing the hands by partitioning visible and depth images into disjoint sub-regions which may be of interest for studying the state of the driver: wheel, lap, hand rest, gear, and infotainment region. Different feature extraction methods are proposed and thoroughly studied in terms of speed and performance for each of the five regions. A model for hand presence is learned for each region separately, and these are integrated using a second-stage classifier. As the appearance of hands varies among regions and the hands can only be found in a subset of the regions chosen, the technique leverages information and confidence from multiple regions to produce hand activity classification.","Wheels,
Vehicles,
Skin,
Support vector machines,
Lighting,
Feature extraction,
Image color analysis"
A privacy-preserving social-assisted mobile content dissemination scheme in DTNs,"Mobile content dissemination is very useful for many mobile applications in delay tolerant networks (DTNs), like instant messaging, file sharing, and advertisement dissemination, etc. Recently, social-based approaches, which attempt to exploit social behaviors of DTN users to forward time-insensitive data, such as family photos and friends' sightseeing video clips, have attracted intensive attentions in designing routing schemes in DTNs. Most social-based schemes leverage users' contact history and social information (e.g., community and friendship) as metrics to improve the dissemination performance. In these schemes, users need to obtain others' social information to determine their dissemination strategy, which apparently compromises others users' privacy. Moreover, the owner of mobile contents may only want to disclose his/her data to a particular group of users rather than revealing it to the public. In this paper, we propose a privacy-preserving social-assisted mobile content dissemination scheme in DTNs. We apply users' verifiable attributes to establish their potential social relationships in terms of identical attributes in a privacy-preserving way. Besides, to provide the confidentiality of mobile contents, our approach enables users to encrypt contents before the dissemination process, and only allows users who have particular attributes to decrypt them. By trace-driven simulations and experiments, we show the security and efficiency of our proposed scheme.","Mobile communication,
Privacy,
Routing,
Encryption,
Protocols"
A mono-camera and scanning laser range finder based UAV indoor navigation system,"This paper presents a comprehensive control and navigation scheme for an indoor UAV system. In addition to the inertial measurement unit commonly used onboard of most UAVs, the testbed quadrotor platform is also equipped with a mono-camera looking downwards and a laser range finder capable of scanning a level plane. With this setup, the UAV is able to estimate its own velocity and position robustly, while flying along the internal walls of a room without collision. The whole system does not require any remote sensory information or off-line computational power. All algorithms are self-sustained and running onboard in real time. Complete flight tests have been carried out to verify the solution.","Sensors,
Cameras,
Navigation,
Optical imaging,
Aerodynamics,
Transfer functions,
Robustness"
"High-Performance Green and Yellow LEDs Grown on
SiO
2
Nanorod Patterned GaN/Si Templates","High-performance GaN-based green and yellow light-emitting diodes (LEDs) are grown on SiO2 nanorod patterned GaN/Si templates by metalorganic chemical vapor deposition. The high-density SiO2 nanorods are prepared by nonlithographic HCl-treated indium tin oxide and dry etching. The dislocation density of GaN is significantly reduced by nanoscale epitaxial lateral overgrowth. In addition to the much improved green LED (505 and 530 nm) results, the fabricated yellow (565 nm) InGaN/GaN-based multiquantum well (MQW) LEDs on Si substrates are demonstrated for the first time. High-quality GaN buffer and localized states in MQWs are correlated to obtaining high-efficiency long-wavelength emission in our devices.",
NetSimplex: Controller Fault Tolerance Architecture in Networked Control Systems,"The assurance of reliability becomes increasingly challenging as the complexity of networked control systems (NCS) rapidly increases. Simplex architecture was designed to tolerate control software design and implementation. This architecture consists of a high assurance controller (HAC) and a high performance controller (HPC). The HAC uses the linear state feedback control to create a large maximum stability region (MSR). The HPC aims at achieving a better control performance and may use any design. However, the plant's states under HPC must stay within the MSR, or the control is switched to HAC.","Delay,
Computer architecture,
Stability analysis,
Switches,
Networked control systems"
Early Detection of Collaboration Conflicts and Risks,"Conflicts among developers' inconsistent copies of a shared project arise in collaborative development and can slow progress and decrease quality. Identifying and resolving such conflicts early can help. Identifying situations which may lead to conflicts can prevent some conflicts altogether. By studying nine open-source systems totaling 3.4 million lines of code, we establish that conflicts are frequent, persistent, and appear not only as overlapping textual edits but also as subsequent build and test failures. Motivated by this finding, we develop a speculative analysis technique that uses previously unexploited information from version control operations to precisely diagnose important classes of conflicts. Then, we design and implement Crystal, a publicly available tool that helps developers identify, manage, and prevent conflicts. Crystal uses speculative analysis to make concrete advice unobtrusively available to developers.","Crystals,
Collaboration,
History,
Open source software,
Control systems,
Terminology,
Computer science"
Control architecture for Cybernetic Transportation Systems in urban environments,"Nowadays, the insertion of Intelligent Transportation System (ITS) in the society is a fact, due to a big number of projects, demonstrations and researches that have been carried out around the world. The Cybernetic Transportation Systems (CTS) are part of the ITS, and these have especial attention thanks to its versatility, adaptability and clean energy characteristics. This paper aims to describe the evolution of the on-demand door-to-door transport systems, with Cybercars, in the framework of the IMARA team. A review of different approaches and the description of the last projects and scenarios with CTSs are considered. This work focuses in a new approach that contemplates a modular architecture, which allows parametric curve generation in real time, considering the different environment conditions-obstacle detections, shape of the road, among others. This architecture has been tested in simulations. These results promise good behavior for its future implementation in real urban scenarios, in the framework of the CityMobil2 project 1.","Trajectory,
Vehicles,
Computer architecture,
Real-time systems,
Planning,
Roads"
SmokeGrenade: An Efficient Key Generation Protocol With Artificial Interference,"Leveraging a wireless multipath channel as the source of common randomness, many key generation methods have been proposed according to the information-theory security. However, existing schemes suffer a low generation rate and a low entropy, and mainly rely on nodes' mobility. To overcome this limitation, we present a key generation protocol with known artificial interference, named SmokeGrenade, a new physical-layer approach for secret key generation in a narrowband fading channel. Our scheme utilizes artificial interference to contribute to the change of measured values on channel states. Our theoretical analysis shows that the key generation rate increases with the increment of the interference power. Particularly, the achievable key rate of SmokeGrenade gains three times better than that of the traditional key generation schemes when the average interference power is normalized to 1. Simulation results also demonstrate that SmokeGrenade achieves a higher generation rate and entropy compared with some state-of-the-art approaches.",
Managing technical debt: An industrial case study,"Technical debt is the consequence of trade-offs made during software development to ensure speedy releases. The research community lacks rigorously evaluated guidelines to help practitioners characterize, manage and prioritize debt. This paper describes a study conducted with an industrial partner during their implementation of Agile development practices for a large software development division within the company. The report contains our initial findings based on ethnographic observations and semi-structured interviews. The goal is to identify the best practices regarding managing technical debt so that the researchers and the practitioners can further evaluate these practices to extend their knowledge of the technical debt metaphor. We determined that the developers considered their own taxonomy of technical debt based on the type of work they were assigned and their personal understanding of the term. Despite management's high-level categories, the developers mostly considered design debt, testing debt and defect debt. In addition to developers having their own taxonomy, assigning dedicated teams for technical debt reduction and allowing other teams about 20% of time per sprint for debt reduction are good initiatives towards lowering technical debt. While technical debt has become a well-regarded concept in the Agile community, further empirical evaluation is needed to assess how to properly apply the concept for various development organizations.","Software,
Interviews,
Organizations,
Encoding,
Taxonomy,
Maintenance engineering,
Training"
Overcoming the Limitations of Utility Design for Multiagent Systems,"Cooperative control focuses on deriving desirable collective behavior in multiagent systems through the design of local control algorithms. Game theory is beginning to emerge as a valuable set of tools for achieving this objective. A central component of this game theoretic approach is the assignment of utility functions to the individual agents. Here, the goal is to assign utility functions within an “admissible” design space such that the resulting game possesses desirable properties. Our first set of results illustrates the complexity associated with such a task. In particular, we prove that if we restrict the class of utility functions to be local, scalable, and budget-balanced then 1) ensuring that the resulting game possesses a pure Nash equilibrium requires computing a Shapley value, which can be computationally prohibitive for large-scale systems, and 2) ensuring that the allocation which optimizes the system level objective is a pure Nash equilibrium is impossible. The last part of this paper demonstrates that both limitations can be overcome by introducing an underlying state space into the potential game structure.",
Low SNR Capacity of FSO Links over Gamma-Gamma Atmospheric Turbulence Channels,"In this paper, we study the ergodic capacity of free space optical communication systems over Gamma-Gamma atmospheric turbulence fading channels with perfect channel state information at both the transmitter and the receiver. In our framework, we mainly focus on the low signal-to-noise ratio range and show that the ergodic capacity scales proportionally to SNR log4(1/SNR). We show also that one-bit CSI feedback at the transmitter is enough to achieve this capacity using an on-off power control scheme.","Signal to noise ratio,
Optical transmitters,
Optical receivers,
Optical feedback,
Radio frequency,
Fading"
Multi-queued network processors for packets with heterogeneous processing requirements,"Modern network processors (NPs) increasingly deal with packets with heterogeneous processing requirements. In this work, we consider the fundamental problem of managing a bounded size buffer at the input queue of an NP. Incoming traffic consists of packets, each packet requiring several rounds of processing before it can be transmitted out of the queue. The objective is to maximize the total number of successfully transmitted packets. In such an environment, it is well known that Shortest-Remaining-Processing-Time (SRPT) first scheduling with push-out is optimal [1]. However, it is hard to implement both priority queueing (PQ) by remaining processing and the push-out mechanism simultaneously in an NP. We explore alternatives for this architecture, addressing the simplicity vs. performance system design tradeoffs. We design a simplified architecture and provide worst-case guarantees for its throughput performance in different settings. We also conduct a comprehensive simulation study that validates our results.","Optimized production technology,
Throughput,
Additives,
Program processors,
Scheduling,
Process control,
Switches"
An IoT-based appliance control system for smart homes,"With the development of the social economy, more and more appliances have been presented in a house. It comes out a problem that how to manage and control these increasing various appliances efficiently and conveniently so as to achieve more comfortable, security and healthy space at home. In this paper, a smart control system base on the technologies of internet of things has been proposed to solve the above problem. The smart home control system uses a smart central controller to set up a radio frequency 433 MHz wireless sensor and actuator network (WSAN). A series of control modules, such as switch modules, radio frequency control modules, have been developed in the WSAN to control directly all kinds of home appliances. Application servers, client computers, tablets or smart phones can communicate with the smart central controller through a wireless router via a Wi-Fi interface. Since it has WSAN as the lower control layer, a appliance can be added into or withdrawn from the control system very easily. The smart control system embraces the functions of appliance monitor, control and management, home security, energy statistics and analysis.","Home appliances,
Control systems,
Smart homes,
Wireless communication,
Wireless sensor networks,
Radio frequency,
Security"
Evaluating Plasmonic Light Trapping With Photoluminescence,"We use photoluminescence measurements to quantify the light trapping for a range of plasmonic structures. By combining Ag nanoparticles as a scattering structure and diffuse white paint as a back surface reflector (BSR) on silicon wafers, we can achieve absorption enhancement of 62% of the Lambertian value, which is comparable with literature values for inverted pyramids of 67%. Through measurements of the effective carrier lifetime, we also establish that plasmonic Ag particles do not degrade the electrical properties of the passivation layer.",
A Quadratic-Complexity Observability-Constrained Unscented Kalman Filter for SLAM,"This paper addresses two key limitations of the unscented Kalman filter (UKF) when applied to the simultaneous localization and mapping (SLAM) problem: the cubic computational complexity in the number of states and the inconsistency of the state estimates. To address the first issue, we introduce a new sampling strategy for the UKF, which has constant computational complexity. As a result, the overall computational complexity of UKF-based SLAM becomes of the same order as that of the extended Kalman filter (EKF)-based SLAM, i.e., quadratic in the size of the state vector. Furthermore, we investigate the inconsistency issue by analyzing the observability properties of the linear-regression-based model employed by the UKF. Based on this analysis, we propose a new algorithm, termed observability-constrained (OC)-UKF, which ensures the unobservable subspace of the UKF's linear-regression-based system model is of the same dimension as that of the nonlinear SLAM system. This results in substantial improvement in the accuracy and consistency of the state estimates. The superior performance of the OC-UKF over other state-of-the-art SLAM algorithms is validated by both Monte-Carlo simulations and real-world experiments.","state estimation,
computational complexity,
Kalman filters,
path planning,
regression analysis,
SLAM (robots)"
Extracting secret key from wireless link dynamics in vehicular environments,"A crucial component of vehicular network security is to establish a secure wireless channel between any two vehicles. In this paper, we propose a scheme to allow two cars to extract a secret key from RSSI (Received Signal Strength Indicator) values in such a way that nearby cars cannot obtain the same secret. Our solution can be executed in noisy, outdoor vehicular environments. We also propose an online parameter learning mechanism to adapt to different channel conditions. We conduct extensive realworld experiments to validate our solution.",
A Topology-Based Miniaturization of Circularly Polarized Patch Antennas,"A novel approach for the miniaturization of circularly polarized patch antennas is presented. This enables a size reduction of as high as 75%, compared to a conventional corner-truncated circularly polarized patch antenna. The proposed design procedure consists of a number of intermediate steps, each of which produces antenna miniaturization as well as the desired polarization and impedance matching properties. This is very challenging in miniaturizing circularly polarized probe-fed patch antennas. It is shown that two resonant frequencies can be tuned independently to produce a dual band antenna with two orthogonal polarizations. Finally, two circularly polarized miniaturized patch antennas with different miniaturization factors are fabricated, and their input impedances, radiation patterns and axial ratios are discussed.","Microstrip antennas,
Resonant frequency,
Microstrip,
Antenna measurements,
Antenna radiation patterns,
Topology"
Hierarchical Information Fusion for Global Displacement Estimation in Microsensor Motion Capture,"This paper presents a novel hierarchical information fusion algorithm to obtain human global displacement for different gait patterns, including walking, running, and hopping based on seven body-worn inertial and magnetic measurement units. In the first-level sensor fusion, the orientation for each segment is achieved by a complementary Kalman filter (CKF) which compensates for the orientation error of the inertial navigation system solution through its error state vector. For each foot segment, the displacement is also estimated by the CKF, and zero velocity update is included for the drift reduction in foot displacement estimation. Based on the segment orientations and left/right foot locations, two global displacement estimates can be acquired from left/right lower limb separately using a linked biomechanical model. In the second-level geometric fusion, another Kalman filter is deployed to compensate for the difference between the two estimates from the sensor fusion and get more accurate overall global displacement estimation. The updated global displacement will be transmitted to left/right foot based on the human lower biomechanical model to restrict the drifts in both feet displacements. The experimental results have shown that our proposed method can accurately estimate human locomotion for the three different gait patterns with regard to the optical motion tracker.","Estimation,
Humans,
Biomechanics,
Acceleration,
Vectors,
Biological system modeling,
Gyroscopes"
Mining medical data to identify frequent diseases using Apriori algorithm,"The data mining is a process of analyzing a huge data from different perspectives and summarizing it into useful information. The information can be converted into knowledge about historical patterns and future trends. Data mining plays a significant role in the field of information technology. Health care industry today generates large amounts of complex data about patients, hospitals resources, diseases, diagnosis methods, electronic patients records, etc,. The data mining techniques are very useful to make medicinal decisions in curing diseases. The healthcare industry collects huge amount of healthcare data which, unfortunately, are not “mined” to discover hidden information for effective decision making. The discovered knowledge can be used by the healthcare administrators to improve the quality of service. In this paper, authors developed a method to identify frequency of diseases in particular geographical area at given time period with the aid of association rule based Apriori data mining technique.",
Autonomous place naming system using opportunistic crowdsensing and knowledge from crowdsourcing,"A user's location information is commonly used in diverse mobile services, yet providing the actual name or semantic meaning of a place is challenging. Previous works required manual user interventions for place naming, such as searching by additional keywords and/or selecting place in a list. We believe that applying mobile sensing techniques to this problem can greatly reduce user intervention. In this paper, we present an autonomous place naming system using opportunistic crowdsensing and knowledge from crowdsourcing. Our goal is to provide a place name from a person's perspective: that is, functional name (e.g., food place, shopping place), business name (e.g., Starbucks, Apple Store), or personal name (e.g., my home, my workplace). The main idea is to bridge the gap between crowdsensing data from smartphone users and location information in social network services. The proposed system automatically extracts a wide range of semantic features about the places from both crowdsensing data and social networks to model a place name. We then infer the place name by linking the crowdsensing data with knowledge in social networks. Extensive evaluations with real deployments show that the proposed system outperforms the related approaches and greatly reduces user intervention for place naming.","Feature extraction,
Social network services,
Sensors,
Business,
Educational institutions,
Data mining,
History"
Trajectory generator for autonomous vehicles in urban environments,"Nowadays, some developments in the vehicle industry permit a safe and comfortable driving. However, several manufactures and research groups are still working in the improvement of the control strategies and path smoothing algorithms. In this paper, a new trajectory generation approach for autonomous vehicles in urban scenarios, considering parametric equations, is proposed. An algorithm that considers Bezier curves and circumference parametric equations for a real vehicle, specifically in roundabout and urban intersections is presented. This approach is generated in real time and can be adapted to dynamic changes in the route. A smooth trajectory generator computationally efficient and easily implementable is proposed. Moreover, this new trajectory generator reduces the control actions, generated with to a fuzzy controller. Some trials have been performed in an urban circuit with promising performance.",
cTrust: Trust Management in Cyclic Mobile Ad Hoc Networks,"Mobility model and network topology play important roles in mobile ad hoc networks (MANETs). Most existing trust and reputation management systems in a MANET do not address mobility issues adequately. In this paper, we study the trust management problem in a MANET with cyclic movement patterns. In a cyclic MANET (cMANET) where nodes periodically move, we formulate trust management problems and propose the cTrust scheme to handle trust establishment and aggregation issues. Unlike trust management in conventional schemes, trust management in cMANET involves not only neighbor trust relationships but location and time factors as well. We model trust relations as a trust graph in cMANET to enhance accuracy and efficiency of trust establishment among nodes. Leveraging the distributed Bellman-Ford algorithm and stochastic Markov chain process for fast and lightweight aggregation of trust scores, the cTrust scheme is a decentralized and self-configurable trust aggregation scheme. To evaluate the performance, we implement the proposed cTrust scheme. We use the student contact patterns on the National University of Singapore (NUS) campus and Seattle metro bus traces as case studies for our cMANET communication model. The simulation results demonstrate the features of trust relationship dissemination in real environments and the efficiency, accuracy, scalability, and robustness of the cTrust scheme. With increasing scales of ad hoc networks and complexities of trust topologies, cTrust scales well with marginal overheads.","Mobile ad hoc networks,
Peer to peer computing,
Educational institutions,
Transfer functions,
Network topology,
Vectors,
Markov processes"
Super-fit Multicriteria Adaptive Differential Evolution,"This paper proposes an algorithm to solve the CEC2013 benchmark. The algorithm, namely Super-fit Multicriteria Adaptive Differential Evolution (SMADE), is a Memetic Computing approach based on the hybridization of two algorithmic schemes according to a super-fit memetic logic. More specifically, the Covariance Matrix Adaptive Evolution Strategy (CMAES), run at the beginning of the optimization process, is used to generate a solution with a high quality. This solution is then injected into the population of a modified Differential Evolution, namely Multicriteria Adaptive Differential Evolution (MADE). The improved solution is super-fit as it supposedly exhibits a performance a way higher than the other population individuals. The super-fit individual then leads the search of the MADE scheme towards the optimum. Unimodal or mildly multimodal problems, even when non-separable and ill-conditioned, tend to be solved during the early stages of the optimization by the CMAES. Highly multi-modal optimization problems are efficiently tackled by SMADE since the MADE algorithm (as well as other Differential Evolution schemes) appears to work very well when the search is led by a super-fit individual.","Sociology,
Covariance matrices,
Optimization,
Vectors,
Signal processing algorithms,
Memetics"
Applying Auxiliary Array to Suppress Mainlobe Interference for Ground-Based Radar,"When ground-based radar is applied to the detection of long-range targets, the interference around the target is located primarily in the radar mainlobe, such that the radar detection capabilities are significantly degraded. Conventional methods of interference suppression mainly focus on sidelobe interference suppression. In the presence of mainlobe interference, sidelobe interference suppression methods will distort and offset the mainlobe peak, so that mainlobe interference could not be effectively suppressed. However, there is currently no suitable mainlobe interference suppression method. In this letter, based on a large aperture auxiliary array, a technique of mainlobe interference suppression is proposed for ground-based radar. The geometry of auxiliary array with uniform array spacing is designed based on conventional sidelobe interference cancellation theory at first. Then, two adaptive beamforming methods for mainlobe interference suppression are presented based on the rules of minimum mean square error (MMSE) and maximum signal-to-interference-plus-noise ratio (MSINR). Since sparse large aperture auxiliary array with uniform array spacing results in high grating lobes, the array spacing is redesigned based on a modified genetic algorithm to reduce the grating lobes. The effectiveness of proposed methods is illustrated by simulations.","Arrays,
Radar antennas,
Gratings,
Interference suppression,
Radar detection"
Smart electric vehicle charging: Security analysis,"This paper provides a comprehensive security analysis of the Electric Vehicle (EV) charging service in Smart Grid (SG) environment (i.e. the “smart” EV charging application). It first describes three EV charging scenarios, at home, at work and at public places. Based on these use-case scenarios, the paper presents a model for smart EV charging, consisted of application entities and interactions among them. It then illustrates potential message types communicated among these entities. Based on this model and the exchanged messages, the paper analyses security problems and potential security threats imposed on the entities, which leads to the specification of a set of security and privacy requirements. These requirements could be used to guide the future design of solutions for secure smart EV charging systems and/or a risk/impact assessment of such systems.","Electricity,
Security,
Companies,
Batteries,
Analytical models,
Privacy,
Electric potential"
Max-Min Fairness Linear Transceiver Design Problem for a Multi-User SIMO Interference Channel is Polynomial Time Solvable,"Consider the linear transceiver design problem for a multi-user single-input multi-output (SIMO) interference channel. Assuming perfect channel knowledge, we formulate this problem as one of maximizing the minimum signal to interference plus noise ratio (SINR) among all the users, subject to individual power constraints at each transmitter. We prove in this letter that the max-min fairness linear transceiver design problem for the SIMO interference channel can be solved to global optimality in polynomial time. We further propose a low-complexity inexact cyclic coordinate ascent algorithm (ICCAA) to solve this problem. Numerical simulations show the proposed algorithm can efficiently find the global optimal solution of the considered problem.",
Transsituational Individual-Specific Biopsychological Classification of Emotions,"The goal of automatic biopsychological emotion recognition of companion technologies is to ensure reliable and valid classification rates. In this paper, emotional states were induced via a Wizard-of-Oz mental trainer scenario, which is based on the valence-arousal-dominance model. In most experiments, classification algorithms are tested via leave-out cross-validation of one situation. These studies often show very high classification rates, which are comparable with those in our experiment (92.6%). However, in order to guarantee robust emotion recognition based on biopsychological data, measurements have to be taken across several situations with the goal of selecting stable features for individual emotional states. For this purpose, our mental trainer experiment was conducted twice for each subject with a 10-min break between the two rounds. It is shown that there are robust psychobiological features that can be used for classification (70.1%) in both rounds. However, these are not the same as those that were found via feature selection performed only on the first round (classification: 53.0%).","Emotion recognition,
Electromyography,
Robustness,
Visualization,
Cybernetics,
Heart rate"
Real-World Empirical Studies on Multi-Channel Reliability and Spectrum Usage for Home-Area Sensor Networks,"Home area networks (HANs) consisting of wireless sensors have emerged as the enabling technology for important applications such as smart energy. These applications impose unique network management constraints, requiring low data rates but high network reliability in the face of unpredictable wireless environments. This paper presents two in-depth empirical studies on wireless channels in real homes, providing key design guidelines for meeting the network management constraints of HAN applications. The spectrum study analyzes spectrum usage in the 2.4 GHz band where HANs based on the IEEE 802.15.4 standard must coexist with existing wireless devices. We characterize the ambient wireless environment in six apartments through passive spectrum analysis across the entire 2.4 GHz band over seven days in each apartment. We find that the wireless conditions in these residential environments are much more complex and varied than in a typical office environment. Moreover, while 802.11 signals play a significant role in spectrum usage, there also exists non-negligible noise from non-802.11 devices. The multi-channel link study measures the reliability of different 802.15.4 channels through active probing with motes in ten apartments. We find that there is not always a persistently reliable channel over 24 hours, and that link reliability does not exhibit cyclic behavior at daily or weekly timescales. Nevertheless, reliability can be maintained through infrequent channel hopping, suggesting dynamic channel hopping as a key tool for meeting the network management requirements of HAN applications. Our empirical studies provide important guidelines and insights in designing HANs for residential environments.","Wireless communication,
Wireless sensor networks,
IEEE 802.11 Standards,
Reliability,
IEEE 802.15 Standards,
Interference"
Improved dynamic performance of wind energy conversion system by UPFC,"There is a continuously growing demand for wind power generation capacity. This situation forces the revision of the grid codes requirements, to remain connected during grid faults, i.e., to ride through the faults, and contribute to system stability during fault condition. In a typical fault condition, the voltage at the Point of Common Coupling (PCC) drops below 80% immediately and the rotor speed of induction generators becomes unstable. In this paper, Unified Power Flow Controller (UPFC) is used to improve the low voltage ride- through (LVRT) of wind energy conversion system (WECS) and to damp the rotor speed oscillations of induction generator under fault conditions. By controlling the UPFC as a virtual inductor, we aims to increase the voltage at the terminals of the wind energy conversion system (WECS) and thereby mitigate the destabilizing electrical torque and power during the fault. The WECS is considered as a fixed-speed system, equipped with a squirrel-cage induction generator. The simulation results show that UPFC can improve the LVRT and rotor stability of the WECS.","Induction generators,
Circuit faults,
Voltage control,
Torque,
Wind turbines,
Reactive power,
Rotors"
A genealogy of information spreading on microblogs: A Galton-Watson-based explicative model,"In this paper, we study the process of information diffusion in a microblog service developing Galton-Watson with Killing (GWK) model. Microblog services offer a unique approach to online information sharing allowing microblog users to forward messages to others. We describe an information propagation as a discrete GWK process based on Galton-Watson model which models the evolution of family names. Our model explains the interaction between the topology of the social graph and the intrinsic interest of the message. We validate our model on dataset collected from Sina Weibo and Twitter microblog. Sina Weibo is a Chinese microblog web service which reached over 100 million users as for January 2011. Our Sina Weibo dataset contains over 261 thousand tweets which have retweets and 2 million retweets from 500 thousand users. Twitter dataset contains over 1.1 million tweets which have retweets and 3.3 million retweets from 4.3 million users. The results of the validation show that our proposed GWK model fits the information diffusion of microblog service very well in terms of the number of message receivers. We show that our model can be used in generating tweets load and also analyze the relationships between parameters of our model and popularity of the diffused information. To the best of our knowledge, this paper is the first to give a systemic and comprehensive analysis for the information diffusion on microblog services, to be used in tweets-like load generators while still guaranteeing popularity distribution characteristics.","Twitter,
Integrated circuit modeling,
Analytical models,
Load modeling,
Predictive models,
Media"
A survey of unmanned aerial vehicles (UAVs) for traffic monitoring,"The focus of this paper is on surveying UAV-based systems for traffic monitoring and management. Although there has been voluminous research on the subject, unmanned aerial vehicles (UAVs) are proven to be a viable and less time-consuming alternative to real-time traffic monitoring and management, providing the eye-in-the-sky solution to the problem.",
Model Predictive Control applied for Quasi-Z-source inverter,This paper presents a Model Predictive Control (MPC) algorithm applied to a Quasi-Z-source inverter (qZSI). This control is based mainly on the measurement of the qZSI capacitor voltage and the AC load currents. These measured values are used to predict the future values of the capacitor voltage and load current. This task is based on the determination of each possible voltage vector generated by the qZSI which can ensure the tracking of the capacitor voltage and the output current references. This control is implemented under MATLAB/SIMULINK program; the obtained results are validated with real time simulation using dSPACE 1103 ControlDesk. The real time simulation results have been provided for principle validation.,"voltage measurement,
electric current measurement,
invertors,
predictive control"
Constrained Blind Source Extraction of Readiness Potentials From EEG,"One of the changes seen in electroencephalography (EEG) data preceding human voluntary movement is a cortical potential called readiness potential (RP). Detection of this potential can benefit researchers in clinical neurosciences for rehabilitation of malfunctioning brain and those working on brain-computer interfacing to develop a suitable mechanism to detect the intention of movement. Here, a constrained blind source extraction (CBSE) is attempted for detection of RP. A suitable constraint is defined and applied. The results are also compared with those of the traditional blind source separation in terms of true positive rate, false positive rate, and computation time. The results show that the CBSE approach in overall has superior performance.","Electroencephalography,
Cost function,
Source separation,
Electrodes,
Feature extraction,
Brain modeling,
Humans"
Deterministic Feature Selection for K-Means Clustering,"We study feature selection for k-means clustering. Although the literature contains many methods with good empirical performance, algorithms with provable theoretical behavior have only recently been developed. Unfortunately, these algorithms are randomized and fail with, say, a constant probability. We present the first deterministic feature selection algorithm for k-means clustering with relative error guarantees. At the heart of our algorithm lies a deterministic method for decompositions of the identity and a structural result which quantifies some of the tradeoffs in dimensionality reduction.","Clustering algorithms,
Approximation algorithms,
Approximation methods,
Vectors,
Partitioning algorithms,
Feature extraction,
Linear programming"
Search-Based Testing of Relational Schema Integrity Constraints Across Multiple Database Management Systems,"There has been much attention to testing applications that interact with database management systems, and the testing of individual database management systems themselves. However, there has been very little work devoted to testing arguably the most important artefact involving an application supported by a relational database - the underlying schema. This paper introduces a search-based technique for generating database table data with the intention of exercising the integrity constraints placed on table columns. The development of a schema is a process open to flaws like any stage of application development. Its cornerstone nature to an application means that defects need to be found early in order to prevent knock-on effects to other parts of a project and the spiralling bug-fixing costs that may be incurred. Examples of such flaws include incomplete primary keys, incorrect foreign keys, and omissions of NOT NULL declarations. Using mutation analysis, this paper presents an empirical study evaluating the effectiveness of our proposed technique and comparing it against a popular tool for generating table data, DBMonster. With competitive or faster data generation times, our method outperforms DBMonster in terms of both constraint coverage and mutation score.",
Optimization Studies of Two-Phosphor-Coated White Light-Emitting Diodes,"Three-hump InGaN-based white light-emitting diodes (LEDs) precoated with traditional yellow/green phosphors and red-emitting quantum dots (QDs), have been numerically investigated. Under variations of eight correlated color temperatures (CCTs), three wavelengths, two bandwidths, and two peak heights, optimal results of luminous efficacy radiation (LER) and color rendering index (CRI) are identified and retained through filtering off billions of unqualified candidates. These results include LER = 390 lm/W and CRI = 90 [chromaticity difference (Duv)<;0.0054] at CCT = 3000 K. In addition, our photometric and colorimetric sensitivity studies provide the dependence of LER, CRI, CCT, and Duv on LED spectral parameters affected by operating temperatures. Finally, we have discovered that higher instabilities may be induced for cool white LEDs (CCT = 6500 K) than for warm white LEDs (CCT = 3000 K) within the analysis of CCT versus spectral parameters.","Light emitting diodes,
Color,
Phosphors,
Indexes,
Rendering (computer graphics),
Niobium,
Temperature measurement"
Connectivity Weakness Impacts on Coordination in Wireless Sensor and Actor Networks,"The combination of sensor and actor nodes in wireless sensor actor networks (WSANs) has created new challenges notably in coordination. In this paper, we survey, categorize, and bring into perspective existing researches on weak connectivity and its impacts on coordination ranging from a node failure to disability of actor nodes to communicate with other actors permanently. We present challenges in each category alongside existing provisions and approaches in the context of the proposed coordination-oriented connectivity categorization. Alongside explanation of general concepts for a communication generalist, we compare the proposed protocols using parameters related to weak connectivity and coordination. Powerful actors can help weaker sensors in many aspects such as routing and data forwarding and many sensors can help few actors in the regions that actors are sparsely deployed. Actors can carry, move and charge sensors while sensors can detect partitions of inter-actor network. Considering lessons learned from surveyed works, we show that actor and sensor nodes in a WSAN must cooperate to provide an integrated network when network connectivity is weak.",
Overlapping coalitional games for collaborative sensing in cognitive radio networks,"Collaborative spectrum sensing (CSS) has been shown to be able to highly improve the performance of spectrum sensing in cognitive radio networks. However, most existing works focused on either centralized approaches that rely on a global fusion center, thus requiring significant overhead, or on distributed approaches that rely on disjoint coalitions of secondary users (SUs) in which an SU can only cooperate with a single, selected coalition, hence limiting the performance gains of CSS. In this paper, a novel, coalition-based approach to CSS is proposed in which an SU can share its sensing results with more than one coalition. The problem is formulated using a novel class of cooperative games, known as overlapping coalitional games, which enables the SUs to decide, in a distributed manner, on the number of coalitions in which they wish to cooperate, depending on the associated benefit and cost tradeoffs. To solve this game, a novel, distributed algorithm is proposed using which the SUs can self-organize into a stable overlapping coalitional structure. Simulation results show that our proposed algorithm significantly improves the performance in terms of both the average probability of misdetection and the convergence time, relative to the noncooperative case and the state-of-art cooperative CSS with non-overlapping coalitions.","Sensors,
Cascading style sheets,
Games,
Partitioning algorithms,
Collaboration,
Fading,
Educational institutions"
Juzzy - A Java based toolkit for Type-2 Fuzzy Logic,"In this paper we introduce a Java based toolkit for the development of type-1, interval type-2 and (zSlices based) general type-2 Fuzzy Logic Systems (FLSs) which is available as a free download. We describe our motivation for the release of such a toolkit in Java - to improve the accessibility to specifically type-2 FLSs to users both in industry and academia beyond the fuzzy logic research community, as well as to facilitate the application of FLSs in real world applications from web and cloud based deployments to multi-agent based control, for example in smart buildings. To the best of our knowledge it is the first package or toolkit that enables the straightforward design and implementation of type-1, interval and general type-2 FLSs. We showcase and review the toolkit's features and provide sample implementations of the different FLSs, together with explanations and source code. Finally, we conclude with future developments and a call for feedback and contributions to drive the further development of the toolkit.",
ENVELOP Antenna: A Class of Very Low Profile UWB Directive Antennas for Radar and Communication Diversity Applications,"In this paper we present the concept of new electrically narrow very low profile (ENVELOP) directive antennas for low frequency radars and diversity communication applications. The basic structure consists of a short TEM horn combined with an inductive loop antenna. The proposed antenna height is 0.063 where is the minimum operating wavelength and has good matching and radiation characteristics over more than an octave. It is based on the principle of crossed electric and magnetic dipoles with a TEM horn as the electric dipole and a sheet loop as the magnetic dipole. However, unlike the standard structures, the proposed structure is designed to enhance the radiation in a direction perpendicular to the TEM horn axis. This limits the maximum pattern bandwidth to about one octave but allows the antenna height along the direction of maximum radiation to be very small which is very important for airborne radars and in low frequency military communications that require conformal antennas. Three different variations of the basic structure are also presented which offer improved pattern characteristics and/or pattern and polarization diversity. Two antennas were fabricated and measured. The measured results agreed well with the simulation results and both showed that the antenna can operate over 1-2 GHz with consistent radiation pattern, low dispersion and input impedance matching performance.","Directive antennas,
Antenna radiation patterns,
Ultra wideband antennas,
Radar antennas,
Horn antennas,
Bandwidth"
Comparison of Complementary and Modular Linear Flux-Switching Motors With Different Mover and Stator Pole Pitch,"Linear flux-switching permanent magnet (LFSPM) motors with both permanent magnets and armature windings on the short primary mover have attracted considerable attention due to their simple and cheap stator which only consists of iron. Hence, this kind of liner motor is very suitable for long stator applications such as in urban rail transportations. However, the conventional LFSPM motors directly split from rotary FSPM motor suffer from drawbacks such as unbalanced magnetic circuit of end coil, heavy mover, and bigger cogging force and force ripple. Modular LFSPM (MLFSPM) motors can mitigate the problem of unbalanced magnetic circuit of end coil. But some MLFSPM motors with different stator/mover pole pitch τs/τm=12/14, 12/10 don't have complementary phase armature windings, which will lead to asymmetrical and non-sinusoidal back-electromotive force, bigger cogging force and thrust force ripple. The key of this paper is to propose, investigate, and compare four complementary and modular structures for the LFSPM motors with different τs/τm . The electromagnetic performance and dimensions of the proposed complementary MLFSPM motors with different τs/τm are investigated, compared and confirmed by the means of finite element analysis and experimental results. Based on the analysis results, two complementary MLFSPM motors with τs/τm=12/13 are chosen to be the two best motors, which can offer the biggest thrust force, relatively smaller cogging force and thrust force ripple, and shorter mover length.","Coils,
Force,
Permanent magnet motors,
Stators,
Induction motors,
Reluctance motors"
EMBA: An Efficient Multihop Broadcast Protocol for Asynchronous Duty-Cycled Wireless Sensor Networks,"In this paper, we propose an efficient multihop broadcast protocol for asynchronous duty-cycled wireless sensor networks (EMBA) where each node independently wakes up according to its own schedule. EMBA adopts two techniques of the forwarder's guidance and the overhearing of broadcast messages and ACKs. A node transmits broadcast messages with guidance to neighbor nodes. The guidance presents how the node forwards the broadcast message to neighbor nodes by using unicast transmissions. This technique significantly reduces redundant transmissions and collisions. The overhearing of broadcast messages and ACKs helps to reduce the number of transmissions, thus it minimizes the active time of nodes. We implement EMBA and conventional protocols of ADB and RI-MAC broadcast in ns-2 simulator to compare their performance. The simulation results show that EMBA outperforms ADB and RI-MAC broadcast in both sparse and dense networks. EMBA achieves lower message cost than the conventional protocols and significantly improves the energy efficiency in terms of both duty cycle and energy consumption.","Wireless sensor networks,
Protocols,
Spread spectrum communication,
Receivers,
Schedules,
Wireless communication,
Energy consumption"
Providing probabilistic guarantees on the time of information spread in opportunistic networks,"A variety of mathematical tools have been developed for predicting the spreading patterns in a number of varied environments including infectious diseases, computer viruses, and urgent messages broadcast to mobile agents (e.g., humans, vehicles, and mobile devices). These tools have mainly focused on estimating the average time for the spread to reach a fraction (e.g., α) of the agents, i.e., the so-called average completion time E(Tα). We claim that providing probabilistic guarantee on the time for the spread Tα rather than only its average gives a much better understanding of the spread, and hence could be used to design improved methods to prevent epidemics or devise accelerated methods for distributing data. To demonstrate the benefits, we introduce a new metric Gα,β that denotes the time required to guarantee α completion with probability β, and develop a new framework to characterize the distribution of Tα for various spread parameters such as number of seeds, level of contact rates, and heterogeneity in contact rates. We apply our technique to an experimental mobility trace of taxies in Shanghai and show that our framework enables us to allocate resources (i.e., to control spread parameters) for acceleration of spread in a far more efficient way than the state-of-the-art.",
Sign language recognition using Microsoft Kinect,"In last decade lot of efforts had been made by research community to create sign language recognition system which provide a medium of communication for differently-abled people and their machine translations help others having trouble in understanding such sign languages. Computer vision and machine learning can be collectively applied to create such systems. In this paper, we present a sign language recognition system which makes use of depth images that were captured using a Microsoft Kinect® camera. Using computer vision algorithms, we develop a characteristic depth and motion profile for each sign language gesture. The feature matrix thus generated was trained using a multi-class SVM classifier and the final results were compared with existing techniques. The dataset used is of sign language gestures for the digits 0-9.","Gesture recognition,
Assistive technology,
Training,
Support vector machines,
Kernel,
Accuracy,
Feature extraction"
A New Method for Knowledge and Information Management Domain Ontology Graph Model,"A new ontology learning model called domain ontology graph (DOG) is proposed in this paper. There are two key components in the DOG, i.e., the definition of the ontology graph and the ontology learning process. The former defines the ontology and knowledge conceptualization model from the domain-specific text documents; the latter offers the necessary method of semiautomatic domain ontology learning and generates the corresponding ontology graphs. Two kinds of ontological operations are also defined based on the proposed DOG, i.e., document ontology graph generation and ontology-graph-based text classification. The simulation studies focused upon Chinese text data are used to demonstrate the potential effectiveness of our proposed strategy. This is accomplished by generating DOGs to represent the domain knowledge and conducting the text classifications based on the generated ontology graph. The experimental results show that the new method can produce significantly better classification accuracy (e.g., with 92.3% in f-measure) compared with other methods (such as 86.8% in f-measure for the term-frequency-inverse-document-frequency approach). The high performance demonstrates that our presented ontological operations based on the ontology graph knowledge model are effectively developed.","Ontologies,
Humans,
Learning systems,
Accuracy,
Dogs,
Computational modeling,
Dictionaries"
Hermite Spectral Method to 1-D Forward Kolmogorov Equation and Its Application to Nonlinear Filtering Problems,"In this paper, we investigate the Hermite spectral method (HSM) to numerically solve the forward Kolmogorov equation (FKE). A useful guideline of choosing the scaling factor of the generalized Hermite functions is given in this paper. It greatly improves the resolution of HSM. The convergence rate of HSM to FKE is analyzed in the suitable function space and has been verified by the numerical simulation. As an important application and our primary motivation to study the HSM to FKE, we work on the implementation of the nonlinear filtering (NLF) problems with a real-time algorithm developed by S.-T. Yau and the second author in 2008. The HSM to FKE is served as the off-line computation in this algorithm. The translating factor of the generalized Hermite functions and the moving-window technique are introduced to deal with the drifting of the posterior conditional density function of the states in the on-line experiments. Two numerical experiments of NLF problems are carried out to illustrate the feasibility of our algorithm. Moreover, our algorithm surpasses the particle filters as a real-time solver to NLF.","Mathematical model,
Guidelines,
Polynomials,
Real-time systems,
Convergence,
Finite wordlength effects"
"Low Latency Systolic Montgomery Multiplier for Finite Field GF(2^{m})
Based on Pentanomials","In this paper, we present a low latency systolic Montgomery multiplier over GF(2m) based on irreducible pentanomials. An efficient algorithm is presented to decompose the multiplication into a number of independent units to facilitate parallel processing. Besides, a novel so-called “pre-computed addition” technique is introduced to further reduce the latency. The proposed design involves significantly less area-delay and power-delay complexities compared with the best of the existing designs. It has the same or shorter critical-path and involves nearly one-fourth of the latency of the other in case of the National Institute of Standards and Technology recommended irreducible pentanomials.",
Neural network-based adaptive event-triggered control of affine nonlinear discrete time systems with unknown internal dynamics,"In this paper, the design of a neural network (NN) based adaptive model-based event-triggered control of an uncertain single input single output (SISO) nonlinear discrete time system in affine form is presented. The controller uses an adaptive estimator consisting of a single-layer NN not only to approximate the internal dynamics of an affine nonlinear discrete-time system but also to provide an estimate of the state vector during inter event interval. The NN weights of the adaptive NN estimator are tuned in a aperiodic manner at the event trigger instants unlike periodic updates in standard adaptive neural network (NN) control. A dead zone operator is used to reset the event trigger error to zero as long as the system states continue to remain in a bounded region due to NN reconstruction errors. Lyapunov method is used to derive the event trigger condition, prove uniform ultimate boundedness (UUB) of the NN weight estimation error and system states.","Artificial neural networks,
Approximation methods,
Adaptation models,
Vectors,
Symmetric matrices,
Lyapunov methods"
Prototyping energy harvesting active networked tags (EnHANTs),"This paper focuses on a new type of wireless devices in the domain between RFIDs and sensor networks - Energy Harvesting Active Networked Tags (EnHANTs). Future EnHANTs will be small, flexible, and self-powered devices that can be attached to objects that are traditionally not networked (e.g., books, toys, clothing), thereby providing the infrastructure for novel tracking applications. We present the design considerations for the EnHANT prototypes, developed over the past 3 years. The prototypes harvest indoor light energy using custom organic solar cells, communicate and form multihop networks using ultralow-power Ultra-Wideband Impulse Radio (UWB-IR) transceivers, and adapt their communications and networking patterns to the energy harvesting and battery states. We also describe a small scale EnHANTs testbed that uniquely allows evaluating different algorithms with trace-based light energy inputs.",
Electroanatomical Characterization of Atrial Microfibrosis in a Histologically Detailed Computer Model,"Fibrosis is thought to play an important role in the formation and maintenance of atrial fibrillation (AF). The propensity of fibrosis to increase AF vulnerability depends not only on its amount, its texture plays a crucial role as well. While the detection of fibrotic tissue patches in the atria with extracellular recordings is feasible based on the analysis of electrogram fractionation, as used in clinical practice to identify ablation targets, the classification of fibrotic texture is a more challenging problem. This study seeks to establish a method for the electroanatomical characterization of the fibrotic textures based on the analysis of electrogram fractionation. The proposed method exploits the dependence of fractionation patterns on the incidence direction of wavefronts which differs significantly as a function of texture. A histologically detailed computer model of the right atrial isthmus was developed for testing the method. A stimulation protocol was conceived which generated various incidence directions for any given recording site where electrograms were computed. A classification method is derived then for discriminating three types of fibrosis, no fibrosis (control), diffuse, and patchy fibrosis. Simulation results showed that electrogram fractionation and amplitudes and their dependence upon incidence direction allow a robust discrimination between different classes of fibrosis. Finally, to minimize the technical effort, sensitivity analysis was performed to identify a minimum number of incidence directions required for robust classification.",
Minimum Near-Convex Shape Decomposition,"Shape decomposition is a fundamental problem for part-based shape representation. We propose the minimum near-convex decomposition (MNCD) to decompose arbitrary shapes into minimum number of ""near-convex"" parts. The near-convex shape decomposition is formulated as a discrete optimization problem by minimizing the number of nonintersecting cuts. Two perception rules are imposed as constraints into our objective function to improve the visual naturalness of the decomposition. With the degree of near-convexity a user-specified parameter, our decomposition is robust to local distortions and shape deformation. The optimization can be efficiently solved via binary integer linear programming. Both theoretical analysis and experiment results show that our approach outperforms the state-of-the-art results without introducing redundant parts and thus leads to robust shape representation.",
Cooperative QoS Control Scheme Based on Scheduling Information in FiWi Access Network,"Fiber-wireless (FiWi) access networks comprising wireless local area networks (WLANs) and passive optical networks (PONs) have attracted much attention recently for future cyber-physical systems (CPSs). Because of the explosive growth of smart devices such as smart phones and sensors, the number of such devices has also grown phenomenally that require real time communication demanding quality of service (QoS)-centric applications for CPSs, such as smart grid, medical, and traffic control systems, which construct smart society. To deal with such situations, the FiWi access networks may be a suitable choice since they are capable of providing both wide bandwidth and flexibility. However, combining the WLAN and PON in FiWi that are inherently different networking technologies leads to inefficient data transmission in the point of junction of the WLAN and PON. Therefore, the QoS of real time communication degrades significantly. In this paper, we address this problem involving QoS degradation in the FiWi networks, and propose a QoS control scheme, which is based on cooperation between the WLAN and PON. Through computer-based simulations, we demonstrate that our proposed scheme can significantly improve the QoS performance of the FiWi access networks for CPSs.","Quality of service,
Optical network units,
Passive optical networks,
Bandwidth,
Wireless LAN,
IEEE 802.11e Standard,
Wireless communication"
Automated Fault Diagnosis for an Autonomous Underwater Vehicle,"This paper reports our results in using a discrete fault diagnosis system Livingstone 2 (L2), onboard an autonomous underwater vehicle (AUV) Autosub 6000. Due to the difficulty of communicating between an AUV and its operators, AUVs can benefit particularly from increased autonomy, of which fault diagnosis is a part. However, they are also restricted in their power consumption. We show that a discrete diagnosis system can detect and identify a number of faults that would threaten the health of an AUV, while also being sufficiently lightweight computationally to be deployed onboard the vehicle. Since AUVs also often have their missions designed just before deployment in response to data from previous missions, a diagnosis system that monitors the software as well as the hardware of the system is also very useful. We show how a software diagnosis model can be built automatically that can be integrated with the hardware model to diagnose the complete system. We show empirically that on Autosub 6000 this allows us to diagnose real vehicle faults that could potentially lead to the loss of the vehicle.",
An Efficient Homomorphic MAC with Small Key Size for Authentication in Network Coding,"Recently, homomorphic message authentication code (MAC) schemes have been proposed to resist against pollution attacks in network coding. However, existing methods face a common challenge: the generated MAC t belongs to a small finite field Fq, which means that an adversary could attack by randomly guessing the value of t, and succeed with probability 1/q. Since q is a predetermined system parameter which is typically set as 28, the resulted security 1/256 could be unsatisfactory in practice. In this paper, we propose an efficient homomorphic MAC for authentication in network coding. The proposed method achieves a reliable security parameter 1/ql using only one key, where l could be chosen according to different security requirements. Compared with previous approaches that using multiple tags, the proposed homomorphic MAC has both low computation and communication overheads.","Games,
Vectors,
Equations,
Network coding,
Authentication,
Pollution"
Empirical software engineering research with industry: Top 10 challenges,"Software engineering research can be done in many ways, in particular it can be done in different ways when it comes to working with industry. This paper presents a list of top 10 challenges to work with industry based on our experience from working with industry in a very close collaboration with continuous exchange of knowledge and information. The top 10 list is based on a large number of research projects and empirical studies conducted with industrial research partners since 1983. It is concluded that close collaboration is a long-term undertaking and a large investment. The importance of addressing the top 10 challenges is stressed, since they form the basis for a long-term sustainable and successful collaboration between industry and academia.","Industries,
Collaboration,
Software engineering,
Companies,
Software,
Joints,
Technology transfer"
Multi-agent residential demand response based on load forecasting,"Improving the efficiency of the smart grid, and in particular efficient integration of energy from renewable sources, is the key to sustainability of electricity provision. In order to optimize energy usage, efficient demand response mechanisms are needed to shift energy usage to periods of low demand, or to periods of high availability of renewable energy. In this paper we propose a multi-agent approach that uses load forecasting for residential demand response. Electrical devices in a household are controlled by reinforcement learning agents which, using the information on current electricity load and load prediction for the next 24 hours, learn how to meet their electricity needs while ensuring that the overall demand stays within the available transformer limits. Simulations are performed in a small neighbourhood consisting of 9 homes each with an agent-controlled electric vehicle. Performance of agents with 24-hour load prediction is compared to the performance of those with current load information only and those which do not have any load information.","Batteries,
Vehicles,
Electricity,
Load management,
Availability,
Conferences,
Learning (artificial intelligence)"
What's new for QoS in IEEE 802.11?,"Two amendments to IEEE 802.11 have recently been published: 802.11aa and 802.11ae. Both enhance Quality of Service (QoS) provisioning in Wi-Fi networks by providing support for multicast transmission, enhanced audio video streaming, coping with inter-network interference, and improved prioritization of management frames. The proposed solutions either extend mechanisms already existing in the standard or introduce new ones. Therefore, it is important for researchers to understand the new functionalities. To this end we provide the first description of these latest mechanisms: we present the motivation behind them, explain their design principles, provide examples of usage, and comment on compatibility issues. Finally, we identify new research challenges related to the two new amendments.","Quality of service,
Streaming media,
IEEE 802.11e Standard,
Multimedia communication"
C-FOREST: Parallel Shortest Path Planning With Superlinear Speedup,"C-FOREST is a parallelization framework for single-query sampling-based shortest path-planning algorithms. Multiple search trees are grown in parallel (e.g., 1 per CPU). Each time a better path is found, it is exchanged between trees so that all trees can benefit from its data. Specifically, the path's nodes increase the other trees' configuration space visibility, while the length of the path is used to prune irrelevant nodes and to avoid sampling from irrelevant portions of the configuration space. Experiments with a robotic team, a manipulator arm, and the alpha benchmark demonstrate that C-FOREST achieves significant superlinear speedup in practice for shortest path-planning problems (team and arm), but not for feasible path panning (alpha).",
A Comparative Study of Water Electrodes Versus Metal Electrodes for Excitation of Nanosecond-Pulse Homogeneous Dielectric Barrier Discharge in Open Air,"Atmospheric pressure low-temperature plasmas produced by dielectric barrier discharge (DBD) provide a promising approach for civilian application of pulsed power technology. In this paper, repetitive nanosecond pulses were generated using a magnetic compression solid-state pulsed power generator, and the rise time and pulse duration of the nanosecond pulse are ~30 and 70 ns, respectively. The DBD in open air is created using two kinds of electrodes, i.e., water and metal electrodes. The electrical, luminous, and optical characteristics of the DBDs under these two electrodes are studied and compared. The experimental results show that no filaments are observed and the discharge is homogeneous when water electrodes are used. The DBD still behaves in a filamentary mode when the discharge gap is extended to 4 cm in the case of metal electrodes. The results are validated by fast images taken by an intensified charge-coupled device camera. In addition, some discussion about the experimental results is presented. Improvement of discharge uniformity is due to the effect of resistive stabilization using water electrodes.","Electrodes,
Discharges (electric),
Metals,
Plasmas,
Dielectrics,
Generators,
Voltage measurement"
Two-stage PV inverter system emulator in converter based power grid emulation system,"This paper proposes a method of modeling and emulation of a two-stage photovoltaic (PV) inverter system by using a single power converter. The PV emulator is intended to be used in a converter-based power grid emulation system - Hardware Test-bed (HTB), in order to investigate the influence of solar energy sources on the power grid. Both physical components and control strategies of the two-stage PV inverter system are modeled in the converter controller, which enables the emulator to represent the behaviors of the two-stage PV inverter system accurately. The performance of the two-stage PV inverter system emulator in both the MPPT mode and the reserved power control mode under variable solar irradiance circumstances is illustrated by both simulation and experiments in the HTB environment, which verifies the effectiveness of the emulation.",
A Job Interview Simulation: Social Cue-Based Interaction with a Virtual Character,"This paper presents an approach that makes use of a virtual character and social signal processing techniques to create an immersive job interview simulation environment. In this environment, the virtual character plays the role of a recruiter which reacts and adapts to the user's behavior thanks to a component for the automatic recognition of social cues (conscious or unconscious behavioral patterns). The social cues pertinent to job interviews have been identified using a knowledge elicitation study with real job seekers. Finally, we present two user studies to investigate the feasibility of the proposed approach as well as the impact of such a system on users.","Interviews,
Magnetic heads,
Speech,
Sensors,
Signal processing,
Software,
Context"
An empirical study of gamification impact on e-Learning environment,"Effective e-Learning requires students to be active, thus, creating an environment that engages the students is one of the challenges. One of the ways to build an engaging e-Learning environment is by applying gamification concept. It improves user engagement by enriching the system with the game design elements. This research aims to analyze the impact of gamification environment on e-Learning system by looking at student's quantitative interaction. 38 students from different high schools were voluntarily joined to test out two different system. This experiment focus on observing the impact of removing and adding gamification on the existing e-Learning system. The result shows that removing gamification causes significant decrement on student participation while adding gamification had no significant impact.",
Investigation of a Wideband BiCMOS Fully On-Chip W-Band Bowtie Slot Antenna,"Design and implementation of a W-band on-chip bowtie-shaped slot antenna fabricated in 180-nm BiCMOS process is presented, and its performance and limitations are discussed. This antenna has a measured impedance bandwidth (S11 <; -10 dB) across the W-band frequency range and a very wide gain bandwidth, making it a candidate for wideband applications. The measured gain for this antenna is 0-1 dBi at 94 GHz. This letter also analyzes the influence of the RF probe to the on-chip antenna performance.","slot antennas,
BiCMOS integrated circuits,
bow-tie antennas,
broadband antennas,
field effect MIMIC,
millimetre wave antennas"
Supervised model training for overlapping sound events based on unsupervised source separation,"Sound event detection is addressed in the presence of overlapping sounds. Unsupervised sound source separation into streams is used as a preprocessing step to minimize the interference of overlapping events. This poses a problem in supervised model training, since there is no knowledge about which separated stream contains the targeted sound source. We propose two iterative approaches based on EM algorithm to select the most likely stream to contain the target sound: one by selecting always the most likely stream and another one by gradually eliminating the most unlikely streams from the training. The approaches were evaluated with a database containing recordings from various contexts, against the baseline system trained without applying stream selection. Both proposed approaches were found to give a reasonable increase of 8 percentage units in the detection accuracy.","Training,
Hidden Markov models,
Event detection,
Acoustics,
Accuracy,
Source separation,
Context"
Two-stage power conversion architecture for an LED driver circuit,"This paper presents a merged-two-stage circuit topology suitable for efficient LED drivers operating from either wide-range dc input voltage or ac line voltage. This two-stage topology is based on a soft-charged switched-capacitor pre-regulator/transformation stage and a high-frequency magnetic regulator stage. Soft charging of the switched capacitor circuit, zero voltage switching of the high-frequency regulator circuit, and time-based indirect scale current control are used to maintain high efficiency, high power density, and high power factor. Two implementations of the proposed architecture are demonstrated: a wide input voltage range dc-dc converter and a line interfaced ac-dc converter. The dc-dc converter shows 85-95% efficiency at 20 W power across 25-200 V input voltage range, and the ac-dc converter achieves 88% efficiency with 0.93 power factor at 8.4 W average power.","Switches,
Voltage control,
Capacitors,
Light emitting diodes,
Switching circuits,
Threshold voltage"
A Sub-nW Multi-stage Temperature Compensated Timer for Ultra-Low-Power Sensor Nodes,"Accurate measurement of synchronization cycle time is required for ultra-low power wireless sensor nodes with stringent power budgets. A multi-stage gate-leakage-based timer with boosted charging is proposed to address the high jitter of prior-art gate-leakage-based timers. The key approaches are faster load capacitor charging, wider voltage swing, and an improved gain sensing inverter. The proposed timer reduces RMS jitter by 8.1× and synchronization uncertainty by 4.1×, which allows hourly tracking with 200 ms uncertainty while consuming 660 pW. A novel closed-loop temperature compensation scheme with dynamic leakage adjustment is also proposed to achieve temperature sensitivity of 31 ppm/°C.","Temperature sensors,
Logic gates,
Uncertainty,
Oscillators,
Temperature dependence,
Temperature measurement,
Jitter"
Intestinal Flow of a Couple Stress Nanofluid in Arteries,"The current article discusses the influence of nanofluid on the peristaltic flow of an incompressible couple stress fluid in a two-dimensional uniform tube. The problem formulation is accessible in an upsurge structure of orientation for equations of momentum, energy, and concentrations. The continuity, linear momentum, energy, and nanoparticle equations lead to the mathematical development. HPM is used to get the solutions for velocity, temperature, nanoparticle, and pressure gradient. The solutions contain the Brownian motion number Nb, thermophoresis number Nt, local temperature Grashof number Br, and local nanoparticle Grashof number Gr. The physical features of different embedded parameters are analyzed and discussed physically in detail.","Nanofluidics,
Perturbation methods,
Heat transfer,
Nanoparticles,
Brownian motion"
Analytic Model of S/D Series Resistance in Trigate FinFETs With Polygonal Epitaxy,"In this paper, a simple but accurate model is presented to analyze source/drain (S/D) series resistance in trigate fin field-effect transistors, particularly on triangular or pentagonal rather than rectangular epitaxy. The model includes the contribution of spreading, sheet, and contact resistances. Although the spreading and sheet resistances are evaluated modifying standard models, the contact resistance is newly modeled using equivalent models of lossy transmission lines and transformations of 3-D to 2-D geometry. Compared with series resistance extracted from 3-D numerical simulations, the model shows excellent agreement, even when the S/D geometry, silicide contact resistivity, and S/D doping concentration are varied. We find that the series resistance is influenced more by contact surface area than by carrier path from the S/D extension to the silicide contact. To meet the series resistance targeted in the semiconductor roadmap, both materials and geometry will need to be optimized, i.e., lowering the silicide contact resistivity and keeping high doping concentration as well as maximizing the contact surface area, respectively.","Semiconductor process modeling,
Epitaxial growth,
Resistance,
Silicides,
Numerical models,
Geometry,
FinFETs"
Performance Improvement of Switched-Based Interference Mitigation for Channel Assignment in Over-Loaded Small-Cell Networks,"This paper proposes adequate methods to improve the interference mitigation capability of a recently investigated switched-based interference reduction scheme for single downlink channel assignment in over-loaded small-cell networks. The model assumes that the available orthogonal channels for small cells are distributed among access points in close vicinity, where each access point knows its allocated channels a priori. Each cell has a single antenna, employs the open access strategy, and can reuse its allocated channels simultaneously, while scheduling concurrent service requests. Moreover, the access points can not coordinate their transmissions, and can receive limited feedback from active users. The paper presents low-complexity schemes to identify a suitable channel to serve the scheduled user by maintaining the interference power level within a tolerable range. They attempt to either complement the switched-based scheme by minimum interference channel selection or adopt different interference thresholds on available channels, while reducing the channel examination load. The optimal thresholds for interference mitigation at the desired receive station are quantified for various performance criteria. The performance and processing load of the proposed schemes are obtained analytically, and then compared to those of the single-threshold scheme via numerical and simulation results.",
Real Parameter Single Objective Optimization using self-adaptive differential evolution algorithm with more strategies,"A new differential evolution algorithm for single objective optimization is presented in this paper. The proposed algorithm uses a self-adaptation mechanism for parameter control, divides its population into more subpopulations, applies more DE strategies, promotes population diversity, and eliminates the individuals that are not changed during some generations. The experimental results obtained by our algorithm on the benchmark consisting of 25 test functions with dimensions D = 10, D = 30, and D = 50 as provided for the CEC 2013 competition and special session on Real Parameter Single Objective Optimization are presented.","Sociology,
Statistics,
Optimization,
Vectors,
Benchmark testing,
Indexes,
Aging"
Effects of Anonymity in Group Discussion on Peer Interaction and Learning Achievement,"When students learn collaboratively, they generally learn better when they complement one another in knowledge. Both cooperative and collaborative learning strategies involve group discussions. However, when group members meet face to face, they may be influenced by interpersonal relationships and peer pressure, which can cause group members to interact in less desirable ways. The purpose of this study is to investigate whether peers engaged in group discussions for the purpose of collaborative learning interact differently in face-to-face or anonymous conditions. The study examines how peers assess one another, to identify group interaction patterns. Different interaction patterns may result in different learning achievements, and this study shows that anonymous group discussions tend to generate better results.","Interactive systems,
Collaborative work,
Computer mediated communication,
Social factors,
Cultural differences"
Improved Average-Case Lower Bounds for DeMorgan Formula Size,"We give an explicit function h: {0, 1}n → {0, 1} such that every deMorgan formula of size n3-o(1)/r2 agrees with h on at most a fraction of 1/2+2-Ω(r) of the inputs. This improves the previous average-case lower bound of Komargodski and Raz (STOC, 2013). Our technical contributions include a theorem that shows that the ""expected shrinkage"" result of Haastad (SIAM J. Comput., 1998) actually holds with very high probability (where the restrictions are chosen from a certain distribution that takes into account the structure of the formula), combining ideas of both Impagliazzo, Meka and Zuckerman (FOCS, 2012) and Komargodski and Raz. In addition, using a bit-fixing extractor in the construction of h allows us to simplify a major part of the analysis of Komargodski and Raz1.","Correlation,
Boolean functions,
Vectors,
Computational modeling,
Approximation methods,
Input variables,
Indexes"
Numerical Analysis and Design of Single-Source Multicoil TMS for Deep and Focused Brain Stimulation,"Transcranial magnetic stimulation (TMS) is a tool for noninvasive stimulation of neuronal tissue used for research in cognitive neuroscience and to treat neurological disorders. Many TMS applications call for large electric fields to be sharply focused on regions that often lie deep inside the brain. Unfortunately, the fields generated by present-day TMS coils diffuse and decay rapidly as they penetrate into the head. As a result, they tend to stimulate relatively large regions of tissue near the brain surface. Earlier studies suggested that a focused TMS excitation can be attained using multiple nonuniformly fed coils in a multichannel array. We propose a systematic, genetic algorithm-based technique for synthesizing multichannel arrays that minimize the volume of the excited region required to achieve a prescribed penetration depth and maintain realistic values for the input driving currents. Because multichannel arrays are costly to build, we also propose a method to convert the multichannel arrays into single-channel ones while minimally materially deteriorating performance. Numerical results show that the new multi- and single-channel arrays stimulate tissue 2.4 cm into the head while exciting 3.0 and 2.6 times less volume than conventional Figure-8 coils, respectively.",
Genetic optimization of a fuzzy control system for energy flow management in micro-grids,"In this paper we present an interesting application of Computational Intelligence techniques for the power demand side and flow management optimization in a microgrid. In particular, we used a Fuzzy Logic Controller (FLC) for Time-of use Cost Management program in the microgrid. FLC can either sell and buy energy from outside the microgrid making use of an aggregate of energy storage capacity realized with lithium ion batteries. According to the hybrid Fuzzy-GA paradigm, the Fuzzy Logic Controller that operates decision making on energy flows is optimized by a Genetic Algorithm. The experimental results show that the proposed control system can manage effectively the energy trade with the main grid on the basis of real time prices.","Microgrids,
Optimization,
Batteries,
Fuzzy logic,
Decision making,
Genetic algorithms"
Impact of planar transformer winding capacitance on Si-based and GaN-based LLC resonant converter,"Transformer loss, comprised of core loss and winding loss, is a critical part in the LLC resonant converter loss. Different winding structures lead to different winding losses and winding capacitances. High winding capacitance will impact the design of the LLC resonant converter. The reason is that high winding capacitance means high winding charge, which must be moved during the dead time to realize the device zero voltage turn-on. As a result, the dead time and magnetizing current will be changed, and the converter loss will be changed as well. This paper first discusses the transformer loss including core loss and winding loss. Then, four different winding structures are analyzed based on a selected core, which show the decrease of AC resistance and the increase of winding capacitance. After that, the winding capacitance model is discussed generally. Finally, the impact of winding capacitance on the design and performance of LLC resonant converter is studied. Two 48 V-12 V, 300 W Si-based and GaN-based LLC resonant converters are designed as platforms to evaluate the impact of winding capacitance. The results indicate that the GaN-based converter is well suited to the transformer with lowest winding loss but highest winding capacitance, since the GaN device's output capacitance is much lower than that of the Si device.","wide band gap semiconductors,
elemental semiconductors,
gallium compounds,
III-V semiconductors,
losses,
resonant power convertors,
silicon,
transformer windings"
A Suction Detection System for Rotary Blood Pumps Based on the Lagrangian Support Vector Machine Algorithm,"The left ventricular assist device is a rotary mechanical pump that is implanted in patients with congestive heart failure to help the left ventricle in pumping blood in the circulatory system. However, using such a device may result in a very dangerous event, called ventricular suction, that can cause ventricular collapse due to overpumping of blood from the left ventricle when the rotational speed of the pump is high. Therefore, a reliable technique for detecting ventricular suction is crucial. This paper presents a new suction detection system that can precisely classify pump flow patterns, based on a Lagrangian support vector machine (LSVM) model that combines six suction indices extracted from the pump flow signal to make a decision about whether the pump is in suction, approaching suction, or not in suction. The proposed method has been tested using in vivo experimental data based on two different pumps. The simulation results show that the system can produce superior performance in terms of classification accuracy, stability, learning speed, and good robustness compared to three other existing suction detection methods and the original support vector machine (SVM) algorithm. The ability of the proposed algorithm to detect suction provides a reliable platform for the development of a feedback control system to control the speed of the pump while at the same time ensuring that suction is avoided.",
Online sensor transmission power schedule for remote state estimation,"We propose an online sensor transmission power schedule for remote state estimation. A sensor sends its local state estimate to a remote estimator through an unreliable wireless channel, which introduces random data packet drops. The packet dropout rate is related to the transmission power which is allocated by the sensor under an energy constraint. The sensor chooses the transmission power based on the relative importance of the local estimate at each time. We prove that the proposed power schedule preserves the Gaussian distribution of the local estimate innovation, which enable us to obtain a closed-form solution of the expected state estimation error covariance. Comparisons with alternative offline schedules are provided, which demonstrate significant performance improvement by the online schedule.","Schedules,
State estimation,
Technological innovation,
Gaussian distribution,
Wireless communication,
Wireless sensor networks,
Kalman filters"
Modeling of radiation-induced single event transients in SOI FinFETS,This work presents the transient charge collection induced by energetic particles in sub-100 nm SOI FinFET technologies with the aim of estimating the SEU (Single Event Upset) and MBU (Multiple Event Upset) sensitivities. The estimates are performed with the dynamic charge transport and collection model of the MUSCA SEP3 platform and compared to TCAD simulations. The predictive platform works with a multi-scales modeling and physics-based Monte-Carlo approach and provides the device sensitivity but also investigates evolving technologies and emerging SEE mechanisms.,"FinFETs,
Logic gates,
Transient analysis,
Integrated circuit modeling,
SRAM cells"
A Utility Maximization Framework for Fair and Efficient Multicasting in Multicarrier Wireless Cellular Networks,"Multicast/broadcast is regarded as an efficient technique for wireless cellular networks to transmit a large volume of common data to multiple mobile users simultaneously. To guarantee the quality of service for each mobile user in such single-hop multicasting, the base-station transmitter usually adapts its data rate to the worst channel condition among all users in a multicast group. On one hand, increasing the number of users in a multicast group leads to a more efficient utilization of spectrum bandwidth, as users in the same group can be served together. On the other hand, too many users in a group may lead to unacceptably low data rate at which the base station can transmit. Hence, a natural question that arises is how to efficiently and fairly transmit to a large number of users requiring the same message. This paper endeavors to answer this question by studying the problem of multicasting over multicarriers in wireless orthogonal frequency division multiplexing (OFDM) cellular systems. Using a unified utility maximization framework, we investigate this problem in two typical scenarios: namely, when users experience roughly equal path losses and when they experience different path losses, respectively. Through theoretical analysis, we obtain optimal multicast schemes satisfying various throughput-fairness requirements in these two cases. In particular, we show that the conventional multicast scheme is optimal in the equal-path-loss case regardless of the utility function adopted. When users experience different path losses, the group multicast scheme, which divides the users almost equally into many multicast groups and multicasts to different groups of users over nonoverlapping subcarriers, is optimal .",
SybilShield: An agent-aided social network-based Sybil defense among multiple communities,"Lacking trusted central authority, distributed systems have received serious security threats from Sybil attack, where an adversary forges identities of more than one node and attempts to control the system. By utilizing the real-world trust relationships between users, social network-based defense schemes have been proposed to mitigate the impact of Sybil attacks. These solutions are mostly built on the assumption that the social network graph can be partitioned into two loosely linked regions - a tightly connected non-Sybil region and a Sybil region. Although such an assumption may hold in certain settings, studies have shown that the real-world social connections tend to divide users into multiple inter-connected small worlds instead of a single uniformly connected large region. Given this fact, the applicability of existing schemes would be greatly undermined for inability to distinguish Sybil users from valid ones in the small non-Sybil regions. This paper addresses this problem and presents SybilShield, the first protocol that defends against Sybil attack utilizing multi-community social network structure in real world. Our scheme leverages the sociological property that the number of cutting edges between a non-Sybil community and a Sybil community, which represent human-established trust relationships, is much smaller than that among non-Sybil communities. With the help of agent nodes, SybilShield greatly reduces false positive rate of non-Sybils among multiple communities, while effectively identifying Sybil nodes. Analytical results prove the superiority of SybilShield. Our experiments on a real-world social network graph with 100,000 nodes also validate the effectiveness of SybilShield.",
Through Silicon Via Aware Design Planning for Thermally Efficient 3-D Integrated Circuits,"3-D integrated circuits (3-D ICs) offer performance advantages due to their increased bandwidth and reduced wire-length enabled by through-silicon-via structures (TSVs). Traditionally TSVs have been considered to improve the thermal conductivity in the vertical direction. However, the lateral thermal blockage effect becomes increasingly important for TSV via farms (a cluster of TSV vias used for signal bus connections between layers) because the TSV size and pitch continue to scale in μm range and the metal to insulator ratio becomes smaller. Consequently, dense TSV farms can create lateral thermal blockages in thinned silicon substrate and exacerbate the local hotspots. In this paper, we propose a thermal-aware via farm placement technique for 3-D ICs to minimize lateral heat blockages caused by dense signal bus TSV structures. By incorporating thermal conductivity profile of via farm blocks in the design flow and enabling placement/aspect ratio optimization, the corresponding hotspots can be minimized within the wire-length and area constraints.","Through-silicon vias,
Heating,
Thermal conductivity,
Conductivity,
Optimization,
Silicon,
Thermal resistance"
Reimagining the Scientific Visualization Interaction Paradigm,"The technological building blocks are in place to address six major challenges for natural visualization interfaces to enable an exciting future where natural interfaces powerfully strengthen and expand the use of visualizations in science, engineering, art, and the humanities.","Data visualization,
Visualization,
User interfaces"
"Security Threats in ZigBee-Enabled Systems: Vulnerability Evaluation, Practical Experiments, Countermeasures, and Lessons Learned","In this paper, two practical attacks against ZigBee security are proposed and the latter one is also carried out in our laboratory environment. The attack scenarios are based on utilizing several vulnerabilities found from the main security components of ZigBee technology. The first attack is based on sabotaging the ZigBee End-Device by sending a special signal that makes it wake-up constantly until the battery runs out. The second attack is based on exploiting the key exchange process in ZigBee when using the Standard Security level defined by the ZigBee specification: we also demonstrate with experimental figures that attacks against ZigBee-enabled devices become practical by using our attack scenario. In addition, countermeasures that render the proposed attacks impractical, although not totally eliminating their potential danger, are devised. Moreover, some new ideas that will be used in our future research work are proposed.","Zigbee,
Batteries,
Standards,
Radiation detectors,
Computer crime"
A survey on heuristic malware detection techniques,"Malware is a malicious code which is developed to harm a computer or network. The number of malwares is growing so fast and this amount of growth makes the computer security researchers invent new methods to protect computers and networks. There are three main methods used to malware detection: Signature based, Behavioral based and Heuristic ones. Signature based malware detection is the most common method used by commercial antiviruses but it can be used in the cases which are completely known and documented. Behavioral malware detection was introduced to cover deficiencies of signature based method. However, because of some shortcomings, the heuristic methods have been introduced. In this paper, we discuss the state of the art heuristic malware detection methods and briefly overview various features used in these methods such as API Calls, OpCodes, N-Grams etc. and discuss their advantages and disadvantages.","Malware,
Feature extraction,
Encryption,
Computers,
Algorithms,
Flow graphs"
Distributed Reference-Free Fault Detection Method for Autonomous Wireless Sensor Networks,"Compact and low-cost sensors used in wireless sensor networks are vulnerable to deterioration and failure. As the number and scale of sensor deployments grow, the failure of sensors becomes an increasingly paramount issue. This paper presents a distributed, reference-free fault detection algorithm that is based on local pair-wise verification between sensors monitoring the same physical system. Specifically, a linear relationship is shown to exist between the outputs of a pair of sensors measuring the same system. Using this relationship, faulty sensors may be detected within subsystems of the global system. Moreover, faulty sensors suffering from sparse spikes in their measurements can be identified with spike magnitudes and times accurately estimated. An appealing feature of the proposed method is that the need for reference sensors and complete knowledge of the system input are not required. Due to the pair-wise nature of the proposed algorithm, it can also be performed in a completely decentralized fashion. This ensures the method can be scaled to large sensor networks and lead to significant energy savings derived from reduced wireless communication compared to centralized approaches.","Sensor systems,
Fault detection,
Wireless sensor networks,
Sensor phenomena and characterization,
Noise,
Training"
A Variational Approach for Pan-Sharpening,"Pan-sharpening is a process of acquiring a high resolution multispectral (MS) image by combining a low resolution MS image with a corresponding high resolution panchromatic (PAN) image. In this paper, we propose a new variational pan-sharpening method based on three basic assumptions: 1) the gradient of PAN image could be a linear combination of those of the pan-sharpened image bands; 2) the upsampled low resolution MS image could be a degraded form of the pan-sharpened image; and 3) the gradient in the spectrum direction of pan-sharpened image should be approximated to those of the upsampled low resolution MS image. An energy functional, whose minimizer is related to the best pan-sharpened result, is built based on these assumptions. We discuss the existence of minimizer of our energy and describe the numerical procedure based on the split Bregman algorithm. To verify the effectiveness of our method, we qualitatively and quantitatively compare it with some state-of-the-art schemes using QuickBird and IKONOS data. Particularly, we classify the existing quantitative measures into four categories and choose two representatives in each category for more reasonable quantitative evaluation. The results demonstrate the effectiveness and stability of our method in terms of the related evaluation benchmarks. Besides, the computation efficiency comparison with other variational methods also shows that our method is remarkable.","image sampling,
image resolution"
Comparative causality: Explaining the differences between executions,"We propose a novel fine-grained causal inference technique. Given two executions and some observed differences between them, the technique reasons about the causes of such differences. The technique does so by state replacement, i.e. replacing part of the program state at an earlier point to observe whether the target differences can be induced. It makes a number of key advances: it features a novel execution model that avoids undesirable entangling of the replaced state and the original state; it properly handles differences of omission by symmetrically analyzing both executions; it also leverages a recently developed slicing technique to limit the scope of causality testing while ensuring that no relevant state causes can be missed. The application of the technique on automated debugging shows that it substantially improves the precision and efficiency of causal inference compared to state of the art techniques.",
From Nominal to True A Posteriori Probabilities: An Exact Bayesian Theorem Based Probabilistic Data Association Approach for Iterative MIMO Detection and Decoding,"It was conventionally regarded that the approximate Bayesian theorem based existing probabilistic data association (PDA) algorithms output the estimated symbol-wise a posteriori probabilities (APPs) as soft information. In our recent work, however, we demonstrated that these probabilities are not the true APPs in the rigorous mathematical sense, but a type of nominal APPs, which are unsuitable for the classic architecture of iterative detection and decoding (IDD) aided receivers. To circumvent this predicament, in this paper we propose an exact Bayesian theorem based logarithmic domain PDA (EB-Log-PDA) method, whose output has similar characteristics to the true APPs, and hence it is readily applicable to the classic IDD architecture of multiple-input-multiple-output (MIMO) systems using the general M-ary modulation. Furthermore, we investigate the impact of the EB-Log-PDA algorithm's inner iteration on the design of EB-Log-PDA aided IDD receiver. We demonstrate that introducing inner iterations into EB-Log-PDA, which is common practice in conventional-PDA aided uncoded MIMO systems, would actually degrade the IDD receiver's performance, despite significantly increasing the overall computational complexity of the IDD receiver. Finally, we investigate the relationship between the extrinsic log-likelihood ratios (LLRs) of the proposed EB-Log-PDA and of the approximate Bayesian theorem based logarithmic domain PDA (AB-Log-PDA) reported in our previous work. Despite their difference in extrinsic LLRs, we also show that the IDD schemes employing the EB-Log-PDA and the AB-Log-PDA without incorporating any inner PDA iterations have a similar achievable performance close to that of the optimal maximum a posteriori (MAP) detector based IDD receiver, while imposing a significantly lower computational complexity in the scenarios considered.","MIMO,
Detectors,
Bayes methods,
Personal digital assistants,
Receivers,
Decoding,
Fading"
Visual Analytics for Model Selection in Time Series Analysis,"Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.","Time series analysis,
Analytical models,
Autoregressive processes,
Mathematical model,
Data models"
Coalitional Game for Community-Based Autonomous Web Services Cooperation,"Web services (WSs) can cooperate with each other to provide more valuable WSs. Current approaches for WS cooperation have typically assumed that WSs are always willing to participate in some form of cooperation, and have undermined the fact that WSs are autonomous in this open environment. This assumption, however, becomes more problematic in community-based WS cooperation due to the dynamic nature of WS community. It is, therefore, important to devise a cooperation scheme respecting WS autonomy for community-based WS cooperation. In this paper, we model the community-based cooperation among autonomous WSs as a coalitional game in graph form. We show this game is non-cohesive and design a distributed coalition formation algorithm. We prove that the proposed algorithm can lead to an individually stable coalition partition, which indicates that every WS can maximize its benefit through cooperation without decreasing other WSs' benefit. We also conduct extensive simulations, and the results show that the proposed algorithm can greatly improve the average payoff per WS and average availability per coalition when compared with other cooperation schemes.",
Joint rewriting and error correction in write-once memories,"Both rewriting and error correction are important technologies for non-volatile memories, especially flash memories. However, coding schemes that combine them have been limited. This paper presents a new coding scheme that combines rewriting and error correction for the write-once memory model. Its construction is based on polar codes, and it supports any number of rewrites and corrects a substantial number of errors. The code is analyzed for the binary symmetric channel, and experimental results verify its performance. The results can be extended to multi-level cells and more general noise models.","Decoding,
Encoding,
Noise measurement,
Error correction codes,
Noise,
Error probability"
Generation Dependence of Retention Characteristics in Extremely Scaled NAND Flash Memory,"We compare three dominant mechanisms in two generations of NAND Flash main chips for mass production. In addition, we analyze the charge loss behaviors of each mechanism according to cycling times. As a result, we confirm that as NAND Flash memory is scaled down, the portion of the interface trap recovery mechanism increases and the sensitivity of cycling times also increases. In the detrapping mechanism, while the charge loss of next generation is more sensitive on cycling times, the amplitude of the charge loss is larger in the current generation. Simultaneously, when the program operation is performed, the number of electrons injected into the floating gate decreases as the physical size of the device decreases. It lowers the portion of the trap-assisted tunneling mechanism and its trend is also accelerated actively as the cycling times increase.","Next generation networking,
Flash memories,
Electron traps,
Ash,
Tunneling,
Market research"
A 1.2-V 165-/spl mu/W 0.29-mm2 Multibit Sigma-Delta ADC for Hearing Aids Using Nonlinear DACs and With Over 91 dB Dynamic-Range,"This paper describes the design and experimental evaluation of a multibit Sigma-Delta (ΣΔ) modulator (ΣΔM) with enhanced dynamic range (DR) through the use of nonlinear digital-to-analog converters (DACs) in the feedback paths. This nonlinearity imposes a trade-off between DR and distortion, which is well suited to the intended hearing aid application. The modulator proposed here uses a fully-differential self-biased amplifier and a 4-bit quantizer based on fully dynamic comparators employing MOS parametric pre-amplification to improve both energy and area efficiencies. A test chip was fabricated in a 130 nm digital CMOS technology, which includes the proposed modulator with nonlinear DACs and a modulator with conventional linear DACs, for comparison purposes. The measured results show that the ΣΔM using nonlinear DACs achieves an enhancement of the DR around 8.4 dB (to 91.4 dB). Power dissipation and silicon area are about the same for the two cases. The performance achieved is comparable to that of the best reported multibit ΣΔ ADCs, with the advantage of occupying less silicon area (7.5 times lower area when compared with the most energy efficient ΣΔM).",
A Probabilistic Model to Predict the Survivability of SCADA Systems,"Recent spate of cyber attacks against critical infrastructure systems, which are vital to society, have shown that in addition to be infeasible to stop every possible attack it is imperative to keep such systems running. Survivability models and tools are good to evaluate system's capacity to handling undesired events. Current survivability measurement techniques are limited, since they only use performance to model system behavior, and do not take into account service interdependencies. This paper introduces a probabilistic model that offers a new direction in measuring survivability. The proposed model solves the issues with current models by combining the formalism of Bayesian networks with information diversity. Service interdependencies are properly taken into account and the information diversity metric is used to represent service behavior. In addition, the model is evaluated through a simulation of a SCADA system, where the entire process to construct and to use the model is detailed.","Bayes methods,
SCADA systems,
Security,
Protocols,
Probabilistic logic"
Automatic multiple Kinect cameras setting for simple walking posture analysis,"We propose an automatic setting of multiple skeletal tracking Kinect cameras, in lieu of mere using a single camera, to capture a human skeleton because of possible viewing occlusions. Using multiple cameras from different angles gives a more complete whole body; however, more required steps are needed in combining multiple skeletons into one final skeleton. One camera is used as a reference for the other cameras to transform their coordinates into the reference camera's coordinate system. Once every view is in the same coordinate, one skeleton is able to be composed. Due to camera's sensory errors, nevertheless, the supposedly same joint of the skeleton, which is obtained from the transformations, may not be exactly located at the same position. Therefore, average joints are used for the composed skeleton. The skeleton is then used to analyze the walking posture of a human subject in order to check whether or not the walking is balanced.",
A Generalized Markov Graph Model: Application to Social Network Analysis,"In this paper we propose a generalized Markov Graph model for social networks and evaluate its application in social network synthesis, and in social network classification. The model reveals that the degree distribution, the clustering coefficient distribution as well as a newly discovered feature, a crowding coefficient distribution, are fundamental to characterizing a social network. The application of this model to social network synthesis leads to a capacity to generate networks dominated by the degree distribution and the clustering coefficient distribution. Another application is a new social network classification method based on comparing the statistics of their degree distributions and clustering coefficient distributions as well as their crowding coefficient distributions. In contrast to the widely held belief that a social network graph is solely defined by its degree distribution, the novelty of this paper consists in establishing the strong dependence of social networks on the degree distribution, the clustering coefficient distribution and the crowding coefficient distribution, and in demonstrating that they form minimal information to classify social networks as well as to design a new social network synthesis tool. We provide numerous experiments with published data and demonstrate very good performance on both counts.","Social network services,
Markov processes,
Mathematical model,
Signal processing algorithms,
Signal processing,
Adaptation models,
Physics"
A Reliability-Oriented Placement Algorithm for Reconfigurable Digital Microfluidic Biochips Using 3-D Deferred Decision Making Technique,"In recent studies, digital microfluidic biochips (DMFBs) have been a promising solution for lab-on-a-chip and bio-assay experiments because of their flexible application and low fabrication cost. However, the reliability problem is an imperative issue to guarantee the valid function of DMFBs. The reliability of DMFBs decreases when electrodes are excessively actuated, preventing droplets on DMFBs controlled successfully. Because the placement for bio-assays in DMFBs is a key step in generating corresponding actuating signals, the reliability of DMFBs must be considered during biochip placement to avoid excessive actuation. Although researchers have proposed several DMFB placement algorithms, they have failed to consider the reliability issue. In addition, previous algorithms were all based on the simulated-annealing (SA) method, which is time consuming and does not guarantee to obtain an optimal solution. This paper proposes the first reliability-oriented non-SA placement algorithm for DMFBs. This approach considers the reliability problem during placement, and uses the 3-D deferred decision making (3D-DDM) technique to enumerate only possible placement solutions. Large-scale DMFB placement can be synthesized efficiently by partitioning the operation sequential graph of bioassays. Experimental results demonstrate that the proposed technique can achieve reliability-oriented placement for DMFBs without excessive actuation in each electrode, while optimizing bioassay completion time.","Electrodes,
Reliability,
Vegetation,
Partitioning algorithms,
Merging,
Complexity theory,
Decision making"
Using semantics in the selection mechanism in Genetic Programming: A simple method for promoting semantic diversity,"Research on semantics in Genetic Programming (GP) has increased over the last number of years. Results in this area clearly indicate that its use in GP considerably increases performance. Many of these semantic-based approaches rely on a trial-and-error method that attempts to find offspring that are semantically different from their parents over a number of trials using the crossover operator (crossover-semantics based - CSB). This, in consequence, has a major drawback: these methods could evaluate thousands of nodes, resulting in paying a high computational cost, while attempting to improve performance by promoting semantic diversity. In this work, we propose a simple and computationally inexpensive method, named semantics in selection, that eliminates the computational cost observed in CSB approaches. We tested this approach in 14 GP problems, including continuous- and discrete-valued fitness functions, and compared it against a traditional GP and a CSB approach. Our results are equivalent, and in some cases, superior than those found by the CSB approach, without the necessity of using a “brute force” mechanism.","Semantics,
Sociology,
Statistics,
Vectors,
Genetic programming,
Computational efficiency,
Context"
Interdigitated 3-D Silicon Ring Microelectrodes for DEP-Based Particle Manipulation,"This paper describes the design, the fabrication, and the characterization of an interdigitated 3-D silicon (Si) ring microelectrodes for dielectrophoretic (DEP) manipulation of particles. The 3-D microelectrodes are derived from a high-aspect-ratio comb structure etched in a doped single crystal Si on an insulating dielectric (silicon-on-insulator). Fingers of the comb are evolved into ring microelectrodes once perforated with a linear array of well-defined round lateral constrictions. This is achieved by the segmented finger layout and the Si dry release strategy borrowed from inertial microelectromechanical systems. The fingers and their interspaces are sealed with a cover layer forming a microfluidic flow chamber surrounded by 3-D microelectrodes and accessible via single inlet/outlet. The functionality of the device has been verified on 2- and 10-μm polystyrene microspheres in pressure-driven flow through the ring microelectrodes at 3.3 μL/min effectively focusing them into streams or trapping them around the fingers at moderate voltage levels (20-40 Vpp).","Silicon,
Microelectrodes,
Force,
Etching,
Structural rings,
Fabrication"
Simultaneous Excitation of Electric and Magnetic Dipole Modes in a Resonant Core-Shell Particle at Infrared Frequencies to Achieve Minimal Backscattering,"Plasmonic nanoparticles have been the focus of much interest in recent years, especially core-shell particles that pair a negative permittivity material with a dielectric layer to promote tunability of the resulting plasmon resonances. Nearly all nanoparticle designs have been considered in the optical regime where metals provide readily available negative permittivities, but where high-index dielectrics are uncommon. By moving to the infrared regime, high-index dielectrics can be used, which allow a greater variety of core-shell designs by admitting the appearance of magnetic resonances. By properly designing a core-shell nanoparticle to engineer the simultaneous excitation of both the magnetic and electric resonances with appropriate amplitudes, highly resonant particles with minimal backscattering can be achieved. Configurations that integrate these minimal backscattering designs with interfaces lead to potential thermal emission control surfaces.","Scattering,
Magnetic cores,
Silicon carbide,
Magnetic resonance,
Permittivity,
Materials,
Magnetic resonance imaging"
Image Analysis: Focus on Texture Similarity,"Texture is an important visual attribute both for human perception and image analysis systems. We review recently proposed texture similarity metrics and applications that critically depend on such metrics, with emphasis on image and video compression and content-based retrieval. Our focus is on natural textures and structural texture similarity metrics (STSIMs). We examine the relation of STSIMs to existing models of texture perception, texture analysis/synthesis, and texture segmentation. We emphasize the importance of signal characteristics and models of human perception, both for algorithm development and testing/validation.","Texture analysis,
Image color analysis,
Image segmentation,
Image analysis,
Visualization,
Image coding"
Is programming knowledge related to age? An exploration of stack overflow,"Becoming an expert at programming is thought to take an estimated 10,000 hours of deliberate practice. But what happens after that? Do programming experts continue to develop, do they plateau, or is there a decline at some point? A diversity of opinion exists on this matter, but many seem to think that aging brings a decline in adoption and absorption of new programming knowledge. We develop several research questions on this theme, and draw on data from StackOverflow (SO) to address these questions. The goal of this research is to support career planning and staff development for programmers by identifying age-related trends in SO data. We observe that programmer reputation scores increase relative to age well into the 50's, that programmers in their 30's tend to focus on fewer areas relative to those younger or older in age, and that there is not a strong correlation between age and scores in specific knowledge areas.","Programming profession,
Aging,
Sociology,
Statistics,
Software,
Data mining"
Fully CMOS-Compatible 1T1R Integration of Vertical Nanopillar GAA Transistor and Oxide-Based RRAM Cell for High-Density Nonvolatile Memory Application,"A fully CMOS-compatible vertical nanopillar gate-all-around transistor integrated with a transition-oxide-based resistive random access memory cell to realize 4F2 footprint has been demonstrated and systematically characterized. The nanopillar transistor exhibits excellent transfer characteristics with diameter scaled down to a few tens of nanometer. Three types of resistive switching behavior have been observed in the fabricated one-transistor one-resistor cell, namely, preforming ultralow-current switching, unipolar switching, and bipolar switching after forming process. A reset current of only 200 pA has been observed in the preforming ultralow-current switching, while for the unipolar and bipolar switching modes after forming process, good memory performance and operation parameter uniformity are demonstrated. Furthermore, reset current is found to decrease with reducing nanopillar transistor design diameter, which is beneficial for circuit power consumption consideration.","Switches,
Transistors,
Computer architecture,
Logic gates,
Microprocessors,
Hafnium compounds,
Nanoscale devices"
Compensation of input current distortion in three-phase buck rectifiers,"An overlap time for two commutating switches is necessary to prevent current interruption in a three-phase buck rectifier, but it may cause input current distortion. In this paper, a modified pulse-based compensation method is proposed to compensate for the overlap time. In addition to the traditional method which places the overlap time based on the voltage polarity, this new method first minimizes the overlap time to reduce its effect and then compensates the pulse width according to the sampled voltage and current. It is verified by experiments that the proposed method has better performance than the traditional method, especially when the line-to-line voltage crosses zero. Another distortion comes from the irregular pulse distribution when two sectors change in a 12-sector space vector PWM. This paper proposes two compensation methods for that scenario as well, compensating the duty cycle and increasing switching frequency near the boundaries of two sectors. It is shown through experiments that both methods can reduce the input current distortion in the buck rectifier.","Logic gates,
Rectifiers,
Vectors,
MOSFET,
Inductors,
Capacitors,
Modulation"
A Relay-Assisted Protocol for Spectrum Mobility and Handover in Cognitive LTE Networks,"Most of the licensed and license-exempt bands are underused while usage in some unlicensed bands is increasing. This trend has driven unlicensed users, equipped with cognitive radios, to opportunistically and dynamically access the spectrum not used by licensed users. Relaying techniques are an important issue for coverage and capacity extension. In this paper, we describe a relay-assisted protocol for spectrum mobility and handover with minimum expected transmission times in cognitive long-term evolution networks, which allows unlicensed users access to not only the previous base stations but also the next base station, with the assistance of relay nodes. Performance analysis of the proposed handover protocol is investigated, and simulation results of the proposed handover protocol are presented, which illustrate a significant reduction in total transmission time and spectrum mobility ratio, and increases in throughput.","Relays,
Protocols,
Signal to noise ratio,
OFDM,
Base stations"
Unsupervised Spatiotemporal Analysis of FMRI Data Using Graph-Based Visualizations of Self-Organizing Maps,"We present novel graph-based visualizations of self-organizing maps for unsupervised functional magnetic resonance imaging (fMRI) analysis. A self-organizing map is an artificial neural network model that transforms high-dimensional data into a low-dimensional (often a 2-D) map using unsupervised learning. However, a postprocessing scheme is necessary to correctly interpret similarity between neighboring node prototypes (feature vectors) on the output map and delineate clusters and features of interest in the data. In this paper, we used graph-based visualizations to capture fMRI data features based upon 1) the distribution of data across the receptive fields of the prototypes (density-based connectivity); and 2) temporal similarities (correlations) between the prototypes (correlation-based connectivity). We applied this approach to identify task-related brain areas in an fMRI reaction time experiment involving a visuo-manual response task, and we correlated the time-to-peak of the fMRI responses in these areas with reaction time. Visualization of self-organizing maps outperformed independent component analysis and voxelwise univariate linear regression analysis in identifying and classifying relevant brain regions. We conclude that the graph-based visualizations of self-organizing maps help in advanced visualization of cluster boundaries in fMRI data enabling the separation of regions with small differences in the timings of their brain responses.","Data visualization,
Prototypes,
Vectors,
Timing,
Lattices,
Correlation,
Noise"
Temperature Drift of Offset and Sensitivity in Full-Bridge Magnetoresistive Sensors,"A typical commercially available magnetoresistive sensor, and particularly an anisotropic magnetoresistive sensor, employs a full bridge of the Wheatstone type formed by two complementary magnetoresistive elements in each branch. This configuration provides linearized response and enlarged sensitivity compared to any other configuration made up of the same elements. Since in a large scale production it is practically impossible to adjust the zero-field resistances of all the four elements to an exactly identical value, there is always some zero-field offset present at the bridge output diagonal even when the sensor is placed in the zero magnetic field. The sensitivity of the sensor, i.e., the ratio of the output voltage change to the change of the measured field H, is associated with the sensitivity of the individual elements. The change of the output voltage is determined by the change of the resistance ΔR of the individual elements. Both the offset and the sensitivity of a full-bridge magnetoresistive sensor is dependent on the zero-field resistances Ri of the elements. However, as in most metallic material, the resistivity of a magnetoresistive element is influenced by temperature. Hence, both the offset and the sensitivity of a real magnetoresistive sensor is temperature dependent. It can be shown that, theoretically speaking, the offset is temperature independent when the bridge is supplied with a constant voltage (but the sensitivity in that case is temperature dependent), and the sensitivity is temperature independent when the bridge is supplied with a constant current (but the offset in that case is temperature dependent). This hypothesis has been verified on KMZ52 sensor (albeit in small temperature range-about 25°C-45°C).","Temperature sensors,
Temperature measurement,
Bridge circuits,
Sensitivity,
Magnetic sensors,
Temperature dependence"
Making sense of online code snippets,"Stack Overflow contains a large number of high-quality source code snippets. The quality of these snippets has been verified by users marking them as solving a specific problem. Stack Overflow treats source code snippets as plain text and searches surface snippets as they would any other text. Unfortunately, plain text does not capture the structural qualities of these snippets; for example, snippets frequently refer to specific API (e.g., Android), but by treating the snippets as text, linkage to the Android API is not always apparent. We perform snippet analysis to extract structural information from short plain-text snippets that are often found in Stack Overflow. This analysis is able to identify 253,137 method calls and type references from 21,250 Stack Overflow code snippets. We show how identifying these structural relationships from snippets could perform better than lexical search over code blocks in practice.","Androids,
Humanoid robots,
Data mining,
Java,
Libraries,
Documentation,
Educational institutions"
Trading Optimality for Scalability in Large-Scale Opportunistic Routing,"Opportunistic routing utilizes the broadcast nature of wireless networks, significantly promoting the unicast throughput. Many variations of opportunistic routing designs have been proposed, although all of the current designs consistently rely on all of the topology information to construct forwarder lists and process data forwarding, which indeed restricts the application in large-scale wireless networks, where collecting global optimal information is very costly. In this paper, we propose the localized opportunistic routing (LOR) protocol, which utilizes the distributed minimum transmission selection (MTS-B) algorithm to partition the topology into several nested close-node-sets (CNSs) using local information. LOR can locally realize the optimal opportunistic routing for a large-scale wireless network with low control overhead cost. Since it does not use global topology information, LOR highlights an interesting tradeoff between the global optimality of the used forwarder lists and scalability inferred from the incurred overhead. Extensive simulation results show that LOR dramatically improves performances over extremely opportunistic routing (ExOR) and MAC-independent opportunistic routing protocol (MORE), which are two well-known designs from the literature, in terms of control overhead, end-to-end delay, and throughputs. It also exhibits promising performance in vehicular ad hoc networks (VANETs).",
Multiple-sink placement strategies in wireless sensor networks,"Multiple sinks are deployed in large-scale wireless sensor networks (WSNs) to minimize transmission delay and energy consumption and also to extend the network life time. Since the data collected by sensor nodes are forwarded to the sink, therefore proper placement of sinks has a great impact on the performance of the WSNs. This paper introduces two sink placement strategies and discusses their advantages and disadvantages in comparison with an existing strategy. The two strategies are compared with the Geographic Sink Placement (GSP) [3] strategy which is used as a benchmark. Both GSP and proposed two strategies are implemented and evaluated in a simulation environment. Performances of these strategies are analyzed and analysis results are presented in this paper. It has been observed that the proposed strategies exhibit better performances with respect to energy usage and lifetime in comparison with GSP.",
"Asynchronous Communication: Exact Synchronization, Universality, and Dispersion","Recently, Tchamkerten and coworkers proposed a novel variation of the problem of joint synchronization and error correction. This paper considers a strengthened formulation that requires the decoder to estimate both the message and the location of the codeword exactly. Such a scheme allows for transmitting data bits in the synchronization phase of the communication, thereby improving bandwidth and energy efficiencies. It is shown that the capacity region remains unchanged under the exact synchronization requirement. Furthermore, asynchronous capacity can be achieved by universal (channel independent) codes. Comparisons with earlier results on another (delay compensated) definition of rate are made. The finite blocklength regime is investigated and it is demonstrated that even for moderate blocklengths, it is possible to construct capacity-achieving codes that tolerate exponential level of asynchronism and experience only a rather small loss in rate compared to the perfectly synchronized setting; in particular, the channel dispersion does not suffer any degradation due to asynchronism. For the binary symmetric channel, a translation (coset) of a good linear code is shown to achieve the capacity-synchronization tradeoff.",
Clock synchronization for wireless sensor network with communication delay,"In this work, the clock synchronization problem for wireless sensor networks is addressed. In our scenario, we consider a wireless sensor network where nodes are equipped with a local clock hardware and communicate in order to achieve a common sense of time. This work introduces a novel synchronization algorithm able to ensure a good level of synchronization even in the presence of random bounded communication delays. A theoretical analysis of the robustness of the proposed algorithm is proposed along with simulations to corroborate the theoretical finding.",
Rebalancing the rebalancers: optimally routing vehicles and drivers in mobility-on-demand systems,"In this paper we study rebalancing strategies for a mobility-on-demand urban transportation system blending customer-driven vehicles with a taxi service. In our system, a customer arrives at one of many designated stations and is transported to any other designated station, either by driving themselves, or by being driven by an employed driver. When some origins and destinations are more popular than others, vehicles will become unbalanced, accumulating at some stations and becoming depleted at others. This problem is addressed by employing rebalancing drivers to drive vehicles from the popular destinations to the unpopular destinations. However, with this approach the rebalancing drivers themselves become unbalanced, and we need to “rebalance the rebalancers” by letting them travel back to the popular destinations with a customer. In this paper we study how to optimally route the rebalancing vehicles and drivers so that the number of waiting customers remains bounded while minimizing the number of rebalancing vehicles traveling in the network and the number of rebalancing drivers needed; surprisingly, these two objectives are aligned, and one can find the optimal rebalancing strategy by solving two decoupled linear programs. We determine the minimum number of drivers and minimum number of vehicles needed to ensure stability in the system. Our simulations suggest that, in Euclidean network topologies, one would need between 1/3 and 1/4 as many drivers as vehicles.","Vehicles,
Optimization,
Stability analysis,
Vehicle dynamics,
Mathematical model,
Asymptotic stability,
Routing"
Fairness issue in message delivery in delay- and Disruption-Tolerant Networks for disaster areas,"Delay- and Disruption-Tolerant Network (DTN) is a promising solution which allows us to communicate to each other even in disaster areas where a large number of users lose network connectivity due to significant damages on network infrastructures by earthquakes, tsunami, tornadoes, and so on. In DTN where messages are transferred from source nodes to destination nodes through other nodes, the communication performance largely depends on the employed routing scheme which determines the feature of the message distribution over the network. A lot of researchers have dedicated their significant efforts to develop an advanced routing algorithm which is superior in terms of message delivery ratio, message deliver delay, and/or efficiency. However, they have not taken into account a criterion, i.e., the fairness in message delivery, which is much more important for users as a service in disaster areas, where DTN takes a role of the access network conveying messages from a huge number of users to a few base stations connected to external networks. In this paper, we first point out that the fairness issue is critical in disaster areas where many-to-one traffic flow exists; messages originating from users in DTN converge on the gateway. Then the performance of existing routing algorithms is evaluated through extensive computer simulations in terms of the fairness in message delivery as well as traditional criteria. The results of performance comparison show that no routing algorithm can achieve the fair message delivery ratio, and the development of advanced routing algorithm is now still an open issue.",
Input voltage control of SEPIC for maximum power point tracking,"The SEPIC (Single Ended Primary Inductor Converter) topology is an excellent choice for a maximum power point tracking (MPPT) converter in small solar energy systems. To achieve MPPT, the input voltage of the SEPIC, corresponding to the photovoltaic (PV) module's output voltage, must be regulated. In this paper, a model is derived with the voltage on the input capacitor as the plant output. The model is used to design a closed-loop controller to regulate the PV module voltage to match the output of an MPPT algorithm. Simulation and experimental validation are given.",
On Computing Puiseux Series for Multiple Imaginary Characteristic Roots of LTI Systems With Commensurate Delays,"Obtaining the Puiseux series of multiple imaginary (characteristic) roots (MIRs) is a fundamental issue in the stability analysis of time-delay systems. However, to the best of the authors' knowledge, this issue has not been fully investigated up to date. This note focuses on the Puiseux series expansion of MIRs of linear time-invariant systems including commensurate delays. For an MIR of any multiplicity, we propose an algorithm for defining the structure of the Puiseux series, as well as the explicit computation of the corresponding coefficients. By using the proposed method, we can find all the Puiseux series corresponding to all the root loci.",
Differential Forms for Target Tracking and Aggregate Queries in Distributed Networks,"Consider mobile targets in a plane and their movements being monitored by a network such as a field of sensors. We develop distributed algorithms for in-network tracking and range queries for aggregated data (for example, returning the number of targets within any user given region). Our scheme stores the target detection information locally in the network and answers a query by examining the perimeter of the given range. The cost of updating data about mobile targets is proportional to the target displacement. The key insight is to maintain in the sensor network a function with respect to the target detection data on the graph edges that is a differential form such that the integral of this form along any closed curve C gives the integral within the region bounded by C. The differential form has great flexibility, making it appropriate for tracking mobile targets. The basic range query can be used to find a nearby target or any given identifiable target with cost O(d), where d is the distance to the target in question. Dynamic insertion, deletion, coverage holes, and mobility of sensor nodes can be handled with only local operations, making the scheme suitable for a highly dynamic network. It is extremely robust and capable of tolerating errors in sensing and target localization. Targets do not need to be identified for the tracking, thus user privacy can be preserved. In this paper, we only elaborate the advantages of differential forms in tracking of mobile targets. Similar routines can be applied for organizing many other types of information-for example, streaming scalar sensor data (such as temperature data field)-to support efficient range queries. We demonstrate through analysis and simulations that this scheme compares favorably to existing schemes that use location services for answering aggregate range queries of target detection data.","Target tracking,
Sensors,
Mobile communication,
Image edge detection,
Aggregates,
Mobile computing"
A Neural Network-based method for continuous blood pressure estimation from a PPG signal,"There is a relation, not always linear, between the blood pressure and the pulse duration, obtained from photoplethysmography (PPG) signal. In order to estimate the blood pressure from the PPG signal, in this paper the Artificial Neural Networks (ANNs) are used. Training data were extracted from the Multiparameter Intelligent Monitoring in Intensive Care waveform database for better representation of possible pulse and pressure variation. In total there were analyzed more than 15000 heartbeats and 21 parameters were extracted from each of them that define the input vector for the ANN. The comparison between estimated and reference values shows better accuracy than the linear regression method and satisfy the American National Standards of the Association for the Advancement of Medical Instrumentation.","Blood pressure,
Biomedical monitoring,
Artificial neural networks,
Estimation,
Neurons,
Linear regression,
Monitoring"
An Augmented Reality System for Epidural Anesthesia (AREA): Prepuncture Identification of Vertebrae,"We propose an augmented reality system to identify lumbar vertebral levels to assist in spinal needle insertion for epidural anesthesia. These procedures require careful placement of a needle to ensure effective delivery of anesthetics and to avoid damaging sensitive tissue such as nerves. In this system, a trinocular camera tracks an ultrasound transducer during the acquisition of a sequence of B-mode images. The system generates an ultrasound panorama image of the lumbar spine, automatically identifies the lumbar levels in the panorama image, and overlays the identified levels on a live camera view of the patient's back. Validation is performed to test the accuracy of panorama generation, lumbar level identification, overall system accuracy, and the effect of changes in the curvature of the spine during the examination. The results from 17 subjects demonstrate the feasibility and capability of achieving an error within clinically acceptable range for epidural anaesthesia.","Ultrasonic imaging,
Cameras,
Transducers,
Ultrasonic variables measurement,
Biomedical measurement,
Anesthesia,
Standards"
ABC: Adaptive Binary Cuttings for Multidimensional Packet Classification,"Decision tree-based packet classification algorithms are easy to implement and allow the tradeoff between storage and throughput. However, the memory consumption of these algorithms remains quite high when high throughput is required. The Adaptive Binary Cuttings (ABC) algorithm exploits another degree of freedom to make the decision tree adapt to the geometric distribution of the filters. The three variations of the adaptive cutting procedure produce a set of different-sized cuts at each decision step, with the goal to balance the distribution of filters and to reduce the filter duplication effect. The ABC algorithm uses stronger and more straightforward criteria for decision tree construction. Coupled with an efficient node encoding scheme, it enables a smaller, shorter, and well-balanced decision tree. The hardware-oriented implementation of each variation is proposed and evaluated extensively to demonstrate its scalability and sensitivity to different configurations. The results show that the ABC algorithm significantly outperforms the other decision tree-based algorithms. It can sustain more than 10-Gb/s throughput and is the only algorithm among the existing well-known packet classification algorithms that can compete with TCAMs in terms of the storage efficiency.","Decision trees,
Throughput,
Encoding,
Software algorithms,
Memory management,
Indexes,
Data structures"
Time Series Modeling of Nano-Gold Immunochromatographic Assay via Expectation Maximization Algorithm,"In this paper, the expectation maximization (EM) algorithm is applied to the modeling of the nano-gold immunochromatographic assay (nano-GICA) via available time series of the measured signal intensities of the test and control lines. The model for the nano-GICA is developed as the stochastic dynamic model that consists of a first-order autoregressive stochastic dynamic process and a noisy measurement. By using the EM algorithm, the model parameters, the actual signal intensities of the test and control lines, as well as the noise intensity can be identified simultaneously. Three different time series data sets concerning the target concentrations are employed to demonstrate the effectiveness of the introduced algorithm. Several indices are also proposed to evaluate the inferred models. It is shown that the model fits the data very well.","time series,
biochemistry,
chromatography,
expectation-maximisation algorithm,
gold,
medical signal processing,
nanomedicine,
noise,
patient diagnosis,
stochastic processes"
On Convergence of Kronecker Graphical Lasso Algorithms,"This paper studies iteration convergence of Kronecker graphical lasso (KGLasso) algorithms for estimating the covariance of an i.i.d. Gaussian random sample under a sparse Kronecker-product covariance model and MSE convergence rates. The KGlasso model, originally called the transposable regularized covariance model by Allen [“Transposable regularized covariance models with an application to missing data imputation,” Ann. Appl. Statist., vol. 4, no. 2, pp. 764–790, 2010], implements a pair of
ℓ
1
penalties on each Kronecker factor to enforce sparsity in the covariance estimator. The KGlasso algorithm generalizes Glasso, introduced by Yuan and Lin [“Model selection and estimation in the Gaussian graphical model,” Biometrika, vol. 94, pp. 19–35, 2007] and Banerjee [“Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data,” J. Mach. Learn. Res., vol. 9, pp. 485–516, Mar. 2008], to estimate covariances having Kronecker product form. It also generalizes the unpenalized ML flip-flop (FF) algorithm of Dutilleul [“The MLE algorithm for the matrix normal distribution,” J. Statist. Comput. Simul., vol. 64, pp. 105–123, 1999] and Werner [“On estimation of covariance matrices with Kronecker product structure,” IEEE Trans. Signal Process., vol. 56, no. 2, pp. 478–491, Feb. 2008] to estimation of sparse Kronecker factors. We establish that the KGlasso iterates converge pointwise to a local maximum of the penalized likelihood function. We derive high dimensional rates of convergence to the true covariance as both the number of samples and the number of variables go to infinity. Our results establish that KGlasso has significantly faster asymptotic convergence than Glasso and FF. Simulations are presented that validate the results of our analysis. For example, for a sparse 10
000
×
10
000 covariance matrix equal to the Kronecker product of two 100
×
100 matrices, the root mean squared error of the inverse covariance estimate using FF is 2 times larger than that obtainable using KGlasso for sample size of
n=100
.","Convergence,
Covariance matrix,
Symmetric matrices,
Maximum likelihood estimation,
Signal processing algorithms,
Sparse matrices"
Investigation of Photo-Induced Hysteresis and Off-Current in Amorphous In-Ga-Zn Oxide Thin-Film Transistors Under UV Light Irradiation,"We investigated the hysteresis and off-current (Ioff) of amorphous In-Ga-Zn oxide thin-film transistors illuminated by 400 nm light at various intensities. Both hysteresis and Ioff are induced by the ionized oxygen vacancy (Vo2+) that forms at the interface between the gate insulator and active layer. In our measurements, Ioff was much less than the estimated photocurrent. Ioff showed a rapid nonlinear increase with light intensity, while the photocurrent of a conventional crystalline semiconductor is expected to show a linear relationship. Furthermore, a numerical analysis suggested that the response time of Vo2+ should be considered when analyzing the hysteresis of these devices.","zinc compounds,
amorphous semiconductors,
gallium compounds,
indium compounds,
thin film transistors"
Image Size Invariant Visual Cryptography for General Access Structures Subject to Display Quality Constraints,"Conventional visual cryptography (VC) suffers from a pixel-expansion problem, or an uncontrollable display quality problem for recovered images, and lacks a general approach to construct visual secret sharing schemes for general access structures. We propose a general and systematic approach to address these issues without sophisticated codebook design. This approach can be used for binary secret images in non-computer-aided decryption environments. To avoid pixel expansion, we design a set of column vectors to encrypt secret pixels rather than using the conventional VC-based approach. We begin by formulating a mathematic model for the VC construction problem to find the column vectors for the optimal VC construction, after which we develop a simulated-annealing-based algorithm to solve the problem. The experimental results show that the display quality of the recovered image is superior to that of previous papers.","simulated annealing,
computer displays,
cryptography,
image coding"
Why did this code change?,"When a developer works on code that is shared with other developers, she needs to know why the code has been changed in particular ways to avoid reintroducing bugs. A developer looking at a code change may have access to a short commit message or a link to a bug report which may provide detailed information about how the code changed but which often lacks information about what motivated the change. This motivational information can sometimes be found by piecing together information from a set of relevant project documents, but few developers have the time to find and read the right documentation. We propose the use of multi-document summarization techniques to generate a concise natural language description of why code changed so that a developer can choose the right course of action.",
Genetic neural network based data mining in prediction of heart disease using risk factors,"Data mining techniques have been widely used in clinical decision support systems for prediction and diagnosis of various diseases with good accuracy. These techniques have been very effective in designing clinical support systems because of their ability to discover hidden patterns and relationships in medical data. One of the most important applications of such systems is in diagnosis of heart diseases because it is one of the leading causes of deaths all over the world. Almost all systems that predict heart diseases use clinical dataset having parameters and inputs from complex tests conducted in labs. None of the system predicts heart diseases based on risk factors such as age, family history, diabetes, hypertension, high cholesterol, tobacco smoking, alcohol intake, obesity or physical inactivity, etc. Heart disease patients have lot of these visible risk factors in common which can be used very effectively for diagnosis. System based on such risk factors would not only help medical professionals but it would give patients a warning about the probable presence of heart disease even before he visits a hospital or goes for costly medical checkups. Hence this paper presents a technique for prediction of heart disease using major risk factors. This technique involves two most successful data mining tools, neural networks and genetic algorithms. The hybrid system implemented uses the global optimization advantage of genetic algorithm for initialization of neural network weights. The learning is fast, more stable and accurate as compared to back propagation. The system was implemented in Matlab and predicts the risk of heart disease with an accuracy of 89%.",
Online Sensor Activation for Detectability of Discrete Event Systems,"In this paper, we investigate online sensor activation to ensure detectability of discrete event systems. Detectability requires that states of a system can be determined or certain pairs of states can be distinguished by an external observer eventually or periodically. Since minimal sensor activation policies for detectability may not exist, two new concepts are introduced: 1)
k
-step distinguishability is introduced for strong detectability and 2) information-preserving is introduced for strong periodic detectability. The online sensor activation is then proposed and is based on the best state estimate available at the time of decision making. Three algorithms are developed for online sensor activation. The first two algorithms are for strong detectability. They minimize sensor activation while preserving
k
-step distinguishability. The third algorithm deals with strong periodic detectability. It minimizes sensor activation while preserving state information.","Discrete event systems,
Observability,
Observers,
Heuristic algorithms,
Automata,
Polynomials"
Learning Saliency by MRF and Differential Threshold,"Saliency detection has been an attractive topic in recent years. The reliable detection of saliency can help a lot of useful processing without prior knowledge about the scene, such as content-aware image compression, segmentation, etc. Although many efforts have been spent in this subject, the feature expression and model construction are far from perfect. The obtained saliency maps are therefore not satisfying enough. In order to overcome these challenges, this paper presents a new psychologic visual feature based on differential threshold and applies it in a supervised Markov-random-field framework. Experiments on two public data sets and an image retargeting application demonstrate the effectiveness, robustness, and practicability of the proposed method.",
Capacity Region Bounds and Resource Allocation for Two-Way OFDM Relay Channels,"Most of the existing works on two-way frequency division multiplexing (OFDM) relay channels was centered on per-subcarrier decode-and-forward (DF) relaying, where each subcarrier is treated as a separate channel, and channel coding is performed separately over each subcarrier. In this paper, we show that this per-subcarrier DF relay strategy is suboptimal. More specifically, we present a multi-subcarrier DF relay strategy which achieves a larger rate region by adopting cross-subcarrier channel coding. Then we develop an optimal resource allocation algorithm to characterize the achievable rate region of the proposed multi-subcarrier DF relay strategy. Compared to standard Lagrangian duality optimization algorithms, our algorithm has a much smaller computational complexity due to the use of the structure property of the optimal resource allocation solution. We further prove that our multi-subcarrier DF relay strategy tends to achieve the capacity region of the two-way OFDM relay channels in the low signal-to-noise ratio (SNR) regime, and the amplify-and-forward (AF) relay strategy tends to achieve the multiplexing gain region of the two-way OFDM relay channels in the high SNR regime. Our theoretical analysis and numerical results demonstrate that DF relaying has better performance in the low to moderate SNR regime, while AF relaying is more appropriate in the high SNR regime.","wireless channels,
amplify and forward communication,
channel capacity,
channel coding,
communication complexity,
decode and forward communication,
duality (mathematics),
OFDM modulation,
optimisation,
relay networks (telecommunication)"
A Unified Graphics and Vision Processor With a 0.89 /spl mu/W/fps Pose Estimation Engine for Augmented Reality,"A unified vision and graphics processor with three layers is shown to provide a fast pipeline for augmented reality. In the image-level layer, a 153.6 GOPS massively parallel processing unit with eight SIMD processors, each containing 128 processing elements, performs highly data-parallel operations. In the sub-image layer, a rasterizer and a pixel arranger respectively generate and reduce data-level parallelism. In the descriptor-level layer, a pose estimation engine executes sequential programs. Our processor can provide images for augmented reality at 100 fps, for a power consumption of 413 mW. This is 39% faster than a comparable smartphone implementation. Our chip is fabricated in a 0.18 μm CMOS process and contains 0.95 M gates.","Estimation,
Parallel processing,
Pipelines,
Augmented reality,
Engines"
Image Texture in Dental Panoramic Radiographs as a Potential Biomarker of Osteoporosis,"Previous studies have shown an association between osteoporosis and automatic measurements of mandibular cortical width on dental panoramic radiographs (DPRs). In this study, we show that additional image texture features increase this association and propose the combined features as a potential biomarker for osteoporosis. We used an existing dataset of 663 DPRs of female patients with bone mineral density (BMD) measurements. The mandibular cortex was located using a previously described computer algorithm. Texture features, based on co-occurrence matrices and fractal dimension, were measured in the bone within the cortex and also in the superior basal bone above the cortex. These, augmented by cortical width measurements, were used by a random forest classifier to identify osteoporosis at femoral neck, total hip, and lumbar spine. Classification performance was assessed by ROC analysis. Area-under-curve (AUC) values for identifying osteoporosis at femoral neck were 0.830, 0.824, and 0.872 using, respectively, cortical width alone, cortical texture (co-occurrence matrix features) alone, and combined width and texture. At 80% sensitivity, these classifiers produced specificity values of 74.4%, 73.6%, and 80.0%, respectively. Fractal dimension was a less effective texture feature. Prediction of osteoporosis at the lumbar spine was poorer, but a combined width and superior basal bone texture classifier gave a significant improvement in AUC at over the use of width alone.","Bones,
Fractals,
Osteoporosis,
Dentistry,
Biomedical measurement,
Vegetation,
Image texture"
Enhancing fairness and congestion control in multipath TCP,"With the advancement in technology, today most of the end-host devices are equipped with multiple wired/wireless interfaces and capable of using them in parallel. This has led to research in taking advantage of utilizing additional available network resources simultaneously such as multiple paths between the multi-homed end devices to achieve better performance. In this regard, new multipath transport protocols such as Multipath TCP and Concurrent Multipath Transfer SCTP are being designed and developed. On one hand these new protocols need to optimize the usage of the available multiple paths efficiently with a suitable scheduler while on the other hand they should be also fair to the existing transport protocols like TCP and SCTP, especially in a congested environment. This paper illustrates and compares the solutions that have been proposed to ascertain that Multipath TCP can yield an improved performance while being fair to standard TCP. In addition, this paper highlights improvements to two of the proposed congestion control solutions-Dynamic Window Coupling and Opportunistic Linked Increases Algorithm. A brief look into hybrid scheduling mechanisms is also provided with a special interest in minimizing the overall reordering delay and to capture the dependency on the receiver buffer size. It is shown that the proposed solutions give good performance in most of the different bottleneck scenarios while staying friendly to legacy transport protocols.","Delays,
Equations,
Throughput,
Mathematical model,
Inspection,
Heuristic algorithms,
Standards"
CMOS Small-Signal and Thermal Noise Modeling at High Frequencies,"In this paper, the behavior of radio frequency (RF) CMOS noise up to 24 GHz is analyzed and verified with measurements over a wide range of bias voltages and channel lengths. For the first time, approaches for excess noise factor modeling are validated versus measurements. Furthermore, important RF CMOS figures of merit are examined over many CMOS generations. With the scaling of CMOS technology, optimum RF performance is shown to be shifted from higher moderate toward lower moderate inversion, providing important guidelines for RFIC design. The results are validated with the charge-based EKV3 compact model, which considers short-channel effects such as channel length modulation, velocity saturation, and carrier heating.","Noise,
Thermal noise,
Logic gates,
Semiconductor device modeling,
Radio frequency,
CMOS integrated circuits,
Noise measurement"
Multipath de-fragmentation: Achieving better spectral efficiency in elastic optical path networks,"In elastic optical networks, the spectrum consecutive and continuous constraints may cause the so-called spectrum fragmentation issue, degrading spectrum utilization, which is especially critical under dynamic traffic scenarios. In this paper, we propose a novel multipath de-fragmentation method which aggregates spectrum fragments instead of reconfiguring existing spectrum paths. We propose an optimization model based on Integer Linear Programming (ILP) and heuristic algorithms and discuss the practical feasibility of the proposed method. We show that multipath routing is an effective de-fragmentation method, as it improves spectral efficiency and reduces blocking under dynamic traffic conditions. We also show that the differential delay issue does not present an obstacle to the application of multipath de-fragmentation in elastic optical networks.",
Bug report assignee recommendation using activity profiles,"One question which frequently arises within the context of artifacts stored in a bug tracking repository is: “who should work on this bug report?” A number of approaches exist to semi-automatically identify and recommend developers, e.g. using machine learning techniques and social networking analysis. In this work, we propose a new approach for assignee recommendation leveraging user activities in a bug tracking repository. Within the bug tracking repository, an activity profile is created for each user from the history of all his activities (i.e. review, assign, and resolve). This profile, to some extent, indicates the user's role, expertise, and involvement in this project. These activities influence and contribute to the identification and ranking of suitable assignees. In order to evaluate our work, we apply it to bug reports of three different projects. Our results indicate that the proposed approach is able to achieve an average hit ratio of 88%. Comparing this result to the LDA-SVM - based assignee recommendation technique, it was found that the proposed approach performs better.","Mathematical model,
History,
Equations,
Databases,
Open source software,
Data mining"
"Broadband Measurements of S
-Parameters Utilizing 4 \,\times\,
4 Butler Matrices","A novel application of 4
×
4 Butler matrices in a multiport measurement technique has been investigated. The proposed measuring system consists of two standard Butler matrices. By application of numerical procedure in measurement system calibration, an enhanced accuracy has been achieved. An influence of power detectors' uncertainty and imperfect Butler matrix parameters on calibration procedure and measurement results has been investigated. The proposed measuring system has been verified by measurements of scattering parameters of two attenuators and a narrowband bandpass filter in frequency range of 2–3 GHz. It has been shown that the proposed system allows for achieving results corresponding closely to the measurements obtained with the commercial vector network analyzer.","Butler matrix,
Power measurement,
Calibration,
Uncertainty,
Measurement uncertainty,
Accuracy,
Ports (Computers)"
Low-Pressure Joining of Large-Area Devices on Copper Using Nanosilver Paste,"Low-temperature joining technology using nanosilver paste has been widely demonstrated for attaching power chips on silver or gold metallized substrates. In this paper, we investigate the processing conditions of nanosilver paste for bonding large-area chips on a plain copper surface. A double-print, low-pressure-assisted sintering process is developed for attaching the chips on copper. An evaluation criterion used in the process development is the bond strength of mechanical chips that are made of alumina and sintered on direct-bond-copper (DBC) substrates. The bond strength, measured by the die-shear test, is found to be in excess of 40 and 77 MPa at sintering pressures of 3 and 12 MPa, respectively, during sintering. Characterization of the bondline microstructure reveals a void-free sintered joint, the density of which increases, with increasing sintering pressure. Sintering in air causes partial oxidation of the copper surface, but the oxide can be easily removed by dipping in 1% hydrochloric acid solution. To evaluate the impact of the bonding and acid-cleaning process on device characteristics, a large-area insulated-gate-bipolar-transistor (IGBT) chip is bonded to DBC substrate and then wire-bonded for electrical testing. Test results shows that the die-attach process does not alter the IGBT performance.",
Error-correcting codes for multipermutations,Multipermutations appear in various applications in information theory. New applications such as rank modulation for flash memories and voting have suggested the need to consider error-correcting codes for multipermutations. The construction of codes is challenging when permutations are considered and it becomes even a harder problem for multipermutations. In this paper we discuss the general problem of error-correcting codes for multipermutations. We present some tight bounds on the size of error-correcting codes for several families of multipermutations. We find the capacity of the channels of multipermutations and characterize families of perfect codes in this metric which we believe are the only such perfect codes.,"Error correction codes,
Vectors,
Upper bound,
Modulation,
Tin,
Measurement"
Experimental Realization of a Nanomagnet Full Adder Using Slanted-Edge Magnets,"We present the experimental realization of a full adder circuit using Nanomagnet Logic (NML). The circuit relies heavily on the properties of asymmetric slant magnets that allow robust operation and reduced footprint. We demonstrate stand-alone NML majority gates and wires, and interconnect these components into an NML full adder that functions properly for all 8 input combinations. To our knowledge, this is the first working implementation of an NML full adder from in-plane magnetized nanomagnets, and one of the very few existing non-electrical, room temperature nanoscale computing units.","Magnetic resonance imaging,
Logic gates,
Magnetic separation,
Wires,
Adders,
Magnetic circuits,
Magnetization"
Semi-formal and formal interface specification for system of systems architecture,"The independence of the constituent systems of a system of systems presents a key challenge to the discipline of system of systems (SoS) engineering. The fact that constituent systems can and do function independently of the SoS means that engineers of a constituent system cannot rely on the behaviour of other constituent systems. This paper advocates a model-based approach to SoS engineering that requires the interfaces to constituent systems to be specified. We propose an use of an interface design pattern for interface specification that uses the industry standard notation, SysML.We also indicate a translation of these specifications to a formal notation, CML, in order to extend the range of analytic techniques available to the SoS engineer.",
Inferring likely mappings between APIs,"Software developers often need to port applications written for a source platform to a target platform. In doing so, a key task is to replace an application's use of methods from the source platform API with corresponding methods from the target platform API. However, this task is challenging because developers must manually identify mappings between methods in the source and target APIs, e.g., using API documentation. We develop a novel approach to the problem of inferring mappings between the APIs of a source and target platform. Our approach is tailored to the case where the source and target platform each have independently-developed applications that implement similar functionality. We observe that in building these applications, developers exercised knowledge of the corresponding APIs. We develop a technique to systematically harvest this knowledge and infer likely mappings between the APIs of the source and target platform. The output of our approach is a ranked list of target API methods or method sequences that likely map to each source API method or method sequence. We have implemented this approach in a prototype tool called Rosetta, and have applied it to infer likely mappings between the Java2 Platform Mobile Edition and Android graphics APIs.","Random variables,
Androids,
Humanoid robots,
Games,
Probability distribution,
Databases,
Inference algorithms"
Composable Parallel Patterns with Intel Cilk Plus,Intel Cilk Plus extends C and C++ to enable writing composable deterministic parallel software that can exploit both the thread and vector parallelism commonly available in modern hardware.,"Parallel processing,
Vectors,
Message systems,
Program processors,
Programming,
Scientific computing"
Nearly Maximum Flows in Nearly Linear Time,"We introduce a new approach to the maximum flow problem in undirected, capacitated graphs using congestion-approximators: easy-to-compute functions that approximate the congestion required to route single-commodity demands in a graph to within some factor α. Our algorithm maintains an arbitrary flow that may have some residual excess and deficits, while taking steps to minimize a potential function measuring the congestion of the current flow plus an over-estimate of the congestion required to route the residual demand. Since the residual term over-estimates, the descent process gradually moves the contribution to our potential function from the residual term to the congestion term, eventually achieving a flow routing the desired demands with nearly minimal congestion after Õ(α2ε-2 log2 n) iterations. Our approach is similar in spirit to that used by Spielman and Teng (STOC 2004) for solving Laplacian systems, and we summarize our approach as trying to do for ℓ∞-flows what they do for ℓ∞-flows. Together with a nearly linear time construction of a no(1)-congestion-approximator, we obtain 1 + ε-optimal singlecommodity flows undirected graphs in time m1+o(1)ε-2, yielding the fastest known algorithm for that problem. Our requirements of a congestion-approximator are quite low, suggesting even faster and simpler algorithms for certain classes of graphs. For example, an α-competitive oblivious routing tree meets our definition, even without knowing how to route the tree back in the graph. For graphs of conductance φ, a trivial φ-1-congestionapproximator gives an extremely simple algorithm for finding Õ(mφ-1).",
Analysis and construction of functional regenerating codes with uncoded repair for distributed storage systems,"Modern distributed storage systems apply redundancy coding techniques to stored data. One form of redundancy is based on regenerating codes, which can minimize the repair bandwidth, i.e., the amount of data transferred when repairing a failed storage node. Existing regenerating codes mainly require surviving storage nodes encode data during repair. In this paper, we study functional minimum storage regenerating (FMSR) codes, which enable uncoded repair without the encoding requirement in surviving nodes, while preserving the minimum repair bandwidth guarantees and also minimizing disk reads. Under double-fault tolerance settings, we formally prove the existence of FMSR codes, and provide a deterministic FMSR code construction that can significantly speed up the repair process. We further implement and evaluate our deterministic FMSR codes to show the benefits. Our work is built atop a practical cloud storage system that implements FMSR codes, and we provide theoretical validation to justify the practicality of FMSR codes.",
Combining supervised and unsupervised learning for zero-day malware detection,"Malware is one of the most damaging security threats facing the Internet today. Despite the burgeoning literature, accurate detection of malware remains an elusive and challenging endeavor due to the increasing usage of payload encryption and sophisticated obfuscation methods. Also, the large variety of malware classes coupled with their rapid proliferation and polymorphic capabilities and imperfections of real-world data (noise, missing values, etc) continue to hinder the use of more sophisticated detection algorithms. This paper presents a novel machine learning based framework to detect known and newly emerging malware at a high precision using layer 3 and layer 4 network traffic features. The framework leverages the accuracy of supervised classification in detecting known classes with the adaptability of unsupervised learning in detecting new classes. It also introduces a tree-based feature transformation to overcome issues due to imperfections of the data and to construct more informative features for the malware detection task. We demonstrate the effectiveness of the framework using real network data from a large Internet service provider.","Malware,
Feature extraction,
Kernel,
Support vector machines,
Training,
Payloads,
Unsupervised learning"
Learning-Automaton-Based Online Discovery and Tracking of Spatiotemporal Event Patterns,"Discovering and tracking of spatiotemporal patterns in noisy sequences of events are difficult tasks that have become increasingly pertinent due to recent advances in ubiquitous computing, such as community-based social networking applications. The core activities for applications of this class include the sharing and notification of events, and the importance and usefulness of these functionalities increase as event sharing expands into larger areas of one's life. Ironically, instead of being helpful, an excessive number of event notifications can quickly render the functionality of event sharing to be obtrusive. Indeed, any notification of events that provides redundant information to the application/user can be seen to be an unnecessary distraction. In this paper, we introduce a new scheme for discovering and tracking noisy spatiotemporal event patterns, with the purpose of suppressing reoccurring patterns, while discerning novel events. Our scheme is based on maintaining a collection of hypotheses, each one conjecturing a specific spatiotemporal event pattern. A dedicated learning automaton (LA)-the spatiotemporal pattern LA (STPLA)-is associated with each hypothesis. By processing events as they unfold, we attempt to infer the correctness of each hypothesis through a real-time guided random walk. Consequently, the scheme that we present is computationally efficient, with a minimal memory footprint. Furthermore, it is ergodic, allowing adaptation. Empirical results involving extensive simulations demonstrate the superior convergence and adaptation speed of STPLA, as well as an ability to operate successfully with noise, including both the erroneous inclusion and omission of events. An empirical comparison study was performed and confirms the superiority of our scheme compared to a similar state-of-the-art approach. In particular, the robustness of the STPLA to inclusion as well as to omission noise constitutes a unique property compared to other related approaches. In addition, the results included, which involve the so-called “ presence sharing” application, are both promising and, in our opinion, impressive. It is thus our opinion that the proposed STPLA scheme is, in general, ideal for improving the usefulness of event notification and sharing systems, since it is capable of significantly, robustly, and adaptively suppressing redundant information.",
Designing a Sustainable and Distributed Generation System for Semiconductor Wafer Fabs,"Driven by wind and solar photovoltaics technology, the power industry is shifting towards a distributed generation (DG) paradigm. A key challenge in deploying a renewable DG system is the power volatility. This study proposes a visionary energy concept and further presents a mathematical model that could help the large industry consumers adopt this new energy technology. The study seeks to design a grid-connected DG system that is capable of providing the necessary electricity for wafer fabs. Simulation-based optimization algorithm was applied to determine the equipment type and capacity aiming to minimize the DG lifecycle cost. The proposed method was demonstrated on fab facilitates located in three different regions in the US.","Load modeling,
Planning,
Wind speed,
Random variables,
Electricity,
Substations,
Distributed power generation"
NetClust: A Framework for Scalable and Pareto-Optimal Media Server Placement,"Effective media server placement strategies are critical for the quality and cost of multimedia services. Existing studies have primarily focused on optimization-based algorithms to select server locations from a small pool of candidates based on the entire topological information and thus these algorithms are not scalable due to unavailability of the small pool of candidates and low-efficiency of gathering the topological information in large-scale networks. To overcome this limitation, a novel scalable framework called NetClust is proposed in this paper. NetClust takes advantage of the latest network coordinate technique to reduce the workloads when obtaining the global network information for server placement, adopts a new K-means-clustering-based algorithm to select server locations and identify the optimal matching between clients and servers. The key contribution of this paper is that the proposed framework optimizes the trade-off between the service delay performance and the deployment cost under the constraints of client location distribution and the computing/storage/bandwidth capacity of each server simultaneously. To evaluate the performance of the proposed framework, a prototype system is developed and deployed in a real-world large-scale Internet. Experimental results demonstrate that 1) NetClust achieves the lower deployment cost and lower delay compared to the traditional server selection method; and 2) NetClust offers a practical and feasible solution for multimedia service providers.",
Adaptive Inverse Optimal Neuromuscular Electrical Stimulation,"Neuromuscular electrical stimulation (NMES) is a prescribed treatment for various neuromuscular disorders, where an electrical stimulus is provided to elicit a muscle contraction. Barriers to the development of NMES controllers exist because the muscle response to an electrical stimulation is nonlinear and the muscle model is uncertain. Efforts in this paper focus on the development of an adaptive inverse optimal NMES controller. The controller yields desired limb trajectory tracking while simultaneously minimizing a cost functional that is positive in the error states and stimulation input. The development of this framework allows tradeoffs to be made between tracking performance and control effort by putting different penalties on error states and control input, depending on the clinical goal or functional task. The controller is examined through a Lyapunov-based analysis. Experiments on able-bodied individuals are provided to demonstrate the performance of the developed controller.","Muscles,
Fatigue,
Stability analysis,
Electrical stimulation,
Trajectory,
Artificial neural networks,
Joints"
Classification of Bacterial Contamination Using Image Processing and Distributed Computing,"Disease outbreaks due to contaminated food are a major concern not only for the food-processing industry but also for the public at large. Techniques for automated detection and classification of microorganisms can be a great help in preventing outbreaks and maintaining the safety of the nation's food supply. Identification and classification of foodborne pathogens using colony scatter patterns is a promising new label-free technique that utilizes image-analysis and machine-learning tools. However, the feature-extraction tools employed for this approach are computationally complex, and choosing the right combination of scatter-related features requires extensive testing with different feature combinations. In this study, we used computer clusters to speed up the feature-extraction process, which enables us to analyze the contribution of different scatter-based features to the overall classification accuracy. A set of 1000 scatter patterns representing ten different bacterial strains was used. Zernike and Chebyshev moments as well as Haralick texture features were computed from the available light-scatter patterns. The most promising features were first selected using Fisher's discriminant analysis, and subsequently a support-vector-machine classifier with a linear kernel was used. With extensive testing, we were able to identify a small subset of features that produced the desired results in terms of classification accuracy and execution speed. The use of distributed computing for scatter-pattern analysis, feature extraction, and selection provides a feasible mechanism for large-scale deployment of a light scatter-based approach to bacterial classification.","Feature extraction,
Microorganisms,
Chebyshev approximation,
Polynomials,
Distributed computing,
Accuracy,
Lasers"
The Web Science Observatory,"To understand and enable the evolution of the Web and to help address grand societal challenges, the Web must be observable at scale across space and time. That requires a globally distributed and collaborative Web Observatory.",
Max-Min Optimality of Service Rate Control in Closed Queueing Networks,"In this technical note, we discuss the optimality properties of service rate control in closed Jackson networks. We prove that when the cost function is linear to a particular service rate, the system performance is monotonic w.r.t. (with respect to) that service rate and the optimal value of that service rate can be either maximum or minimum (we call it Max-Min optimality); When the second-order derivative of the cost function w.r.t. a particular service rate is always positive (negative), which makes the cost function strictly convex (concave), the optimal value of such service rate for the performance maximization (minimization) problem can be either maximum or minimum. To the best of our knowledge, this is the most general result for the optimality of service rates in closed Jackson networks and all the previous works only involve the first conclusion. Moreover, our result is also valid for both the state-dependent and load-dependent service rates, under both the time-average and customer-average performance criteria.","Servers,
Cost function,
Difference equations,
System performance,
Mathematical model,
Markov processes"
An extended visual cryptography scheme without pixel expansion for halftone images,"Visual cryptography is a secret sharing scheme which uses images distributed as shares such that, when the shares are superimposed, a hidden secret image is revealed. In extended visual cryptography, the share images are constructed to contain meaningful cover images, thereby providing opportunities for integrating visual cryptography and biometric security techniques. In this paper, we propose a method for processing halftone images that improves the quality of the share images and the recovered secret image in an extended visual cryptography scheme for which the size of the share images and the recovered image is the same as for the original halftone secret image. The resulting scheme maintains the perfect security of the original extended visual cryptography approach.","Visualization,
Cryptography,
Gray-scale,
Biomedical imaging,
Stacking,
Clustering algorithms"
Exploring the Connectome: Petascale Volume Visualization of Microscopy Data Streams,"Recent advances in high-resolution microscopy let neuroscientists acquire neural-tissue volume data of extremely large sizes. However, the tremendous resolution and the high complexity of neural structures present big challenges to storage, processing, and visualization at interactive rates. A proposed system provides interactive exploration of petascale (petavoxel) volumes resulting from high-throughput electron microscopy data streams. The system can concurrently handle multiple volumes and can support the simultaneous visualization of high-resolution voxel segmentation data. Its visualization-driven design restricts most computations to a small subset of the data. It employs a multiresolution virtual-memory architecture for better scalability than previous approaches and for handling incomplete data. Researchers have employed it for a 1-teravoxel mouse cortex volume, of which several hundred axons and dendrites as well as synapses have been segmented and labeled.","Data visualization,
Neuroscience,
Image resolution,
Rendering (computer graphics),
Microscopy,
Streaming media,
Medical image processing"
Sensor Network Navigation without Locations,"We propose a pervasive usage of the sensor network infrastructure as a cyber-physical system for navigating internal users in locations of potential danger. Our proposed application differs from previous work in that they typically treat the sensor network as a media of data acquisition while in our navigation application, in-situ interactions between users and sensors become ubiquitous. In addition, human safety and time factors are critical to the success of our objective. Without any preknowledge of user and sensor locations, the design of an effective and efficient navigation protocol faces nontrivial challenges. We propose to embed a road map system in the sensor network without location information so as to provide users navigating routes with guaranteed safety. We accordingly design efficient road map updating mechanisms to rebuild the road map in the event of changes in dangerous areas. In this navigation system, each user only issues local queries to obtain their navigation route. The system is highly scalable for supporting multiple users simultaneously. We implement a prototype system with 36 TelosB motes to validate the effectiveness of this design. We further conduct comprehensive and large-scale simulations to examine the efficiency and scalability of the proposed approach under various environmental dynamics.","Roads,
Navigation,
Safety,
Humans,
Routing protocols,
Logic gates,
Wireless sensor networks"
Dynamic Iterative Reconstruction for Interventional 4-D C-Arm CT Perfusion Imaging,"Tissue perfusion measurement using C-arm angiography systems capable of CT-like imaging (C-arm CT) is a novel technique with potentially high benefit for catheter guided treatment of stroke in the interventional suite. However, perfusion C-arm CT (PCCT) is challenging: the slow C-arm rotation speed only allows measuring samples of contrast time attenuation curves (TACs) every 5-6 s if reconstruction algorithms for static data are used. Furthermore, the peak values of the TACs in brain tissue typically lie in a range of 5-30 HU, thus perfusion imaging is very sensitive to noise. We present a dynamic, iterative reconstruction (DIR) approach to reconstruct TACs described by a weighted sum of basis functions. To reduce noise, a regularization technique based on joint bilateral filtering (JBF) is introduced. We evaluated the algorithm with a digital dynamic brain phantom and with data from six canine stroke models. With our dynamic approach, we achieve an average Pearson correlation (PC) of the PCCT canine blood flow maps to co-registered perfusion CT maps of 0.73. This PC is just as high as the PC achieved in a recent PCCT study, which required repeated injections and acquisitions.","Image reconstruction,
Vectors,
Splines (mathematics),
Noise,
Computed tomography,
Heuristic algorithms"
Logarithmic Sobolev inequalities and strong data processing theorems for discrete channels,"The noisiness of a channel can be measured by comparing suitable functionals of the input and output distributions. For instance, if we fix a reference input distribution, then the worst-case ratio of output relative entropy to input relative entropy for any other input distribution is bounded by one, by the data processing theorem. However, for a fixed reference input distribution, this quantity may be strictly smaller than one, giving so-called strong data processing inequalities (SDPIs). This paper shows that the problem of determining both the best constant in an SDPI and any input distributions that achieve it can be addressed using so-called logarithmic Sobolev inequalities, which relate input relative entropy to certain measures of input-output correlation. Another contribution is a proof of equivalence between SDPIs and a limiting case of certain strong data processing inequalities for the Rényi divergence.","Data processing,
Entropy,
Markov processes,
Correlation,
Information theory,
Limiting,
Equations"
Smart Home System Based on IOT Technologies,The idea of applying IOT technologies to smart home system is introduced. An original architecture of the integrated system is analyzed with its detailed introduction. This architecture has great scalability. Based on this proposed architecture many applications can be integrated into the system through uniform interface. Agents are proposed to communicate with appliances through RFID tags. Key issues to be solved to promote the development of smart home system are also discussed.,"Smart homes,
Home appliances,
Certification,
Computer architecture,
RFID tags,
Internet,
Monitoring"
Stochastic Virtual Population of Subjects With Type 1 Diabetes for the Assessment of Closed-Loop Glucose Controllers,"Closed-loop glucose control is an emerging treatment approach to manage type 1 diabetes. Closed-loop systems consist of a continuous glucose monitor, an insulin infusion pump, and a dosing algorithm that directs insulin delivery based on sensor levels. Testing of dosing algorithms in computer simulations may replace animal testing, accelerates development, and saves resources. We propose here a novel approach to generate a virtual population, to be used in metabolic simulators, from routine experimental data through the process that we term “stochastic e-cloning.” We build on a nonlinear physiologically motivated time-varying model of glucose regulation. We adopt the Bayesian approach to estimate model parameters and to obtain the joint posterior probability distribution of time-invariant and time-varying parameters with the use of the Markov chain Monte Carlo methodology. The estimation process combines prior knowledge and experimental data to generate a sample from the posterior distribution, which can be subsequently used to conduct in silico experiments reflecting population and individual variability, and associated uncertainty as closely as possible. The approach is exemplified using data collected in 12 young subjects with type 1 diabetes. We demonstrate unbiased fit to the data, physiological plausibility of parameter estimates, and results of in silico testing using a stochastic virtual subject.","Insulin,
Sugar,
Plasmas,
Diabetes,
Absorption,
Data models,
Kinetic theory"
Unsupervised Nosologic Imaging for Glioma Diagnosis,"In this letter a novel approach to create nosologic images of the brain using magnetic resonance spectroscopic imaging (MRSI) data in an unsupervised way is presented. Different tissue patterns are identified from the MRSI data using nonnegative matrix factorization and are then coded as different primary colors (i.e. red, green, and blue) in an RGB image, so that mixed tissue regions are automatically visualized as mixtures of primary colors. The approach is useful in assisting glioma diagnosis, where several tissue patterns such as normal, tumor, and necrotic tissue can be present in the same voxel/spectrum. Error-maps based on linear least squares estimation are computed for each nosologic image to provide additional reliability information, which may help clinicians in decision making. Tests on in vivo MRSI data show the potential of this new approach.",
Development of High-Reliability EV and HEV IM Propulsion Drive With Ultra-Low Latency HIL Environment,"This paper proposes an improved and robust method of minimizing the error in propulsion-drive line-currents that are reconstructed from a single dc-link current measurement. The proposed algorithm extends and then shortens the relevant phase pulse-widths in order to provide optimal sampling of the dc-link currents in two consecutive pulsewidth modulation (PWM) periods. The proposed PWM pattern control enables an improved sampling method which cancels offset jitter-like waveform errors present in all three reconstructed line-currents, which is due to a specific combination of nonsimultaneously sampled dc-link current and line-current PWM ripple. The improvement in induction motor drive accuracy using a single current-sensor and no shaft sensor (as proposed in this paper), over that of conventional methods, is shown. Thanks to an ultra-low latency hardware-in-the loop (HIL) emulator, the proposed algorithm, its implementation on a DSP processor, code optimization and “laboratory” testing were all merged into one development step. In order to perform final tests of the proposed current-reconstruction algorithm and to verify the usefulness of the developed HIL platform by means of comparison, experimental results obtained on a real hardware setup are provided.","Pulse width modulation,
Vectors,
Current measurement,
Reliability,
Induction motors,
Stator windings,
Power electronics"
Effect of coupling on the epidemic threshold in interconnected complex networks: A spectral analysis,"In epidemic spreading models, if the infection strength is higher than a certain critical value - which we define as the epidemic threshold - then the epidemic spreads through the population. For a single arbitrary graph representing the contact network of the population under consideration, the epidemic threshold turns out to be equal to the inverse of the spectral radius of the contact graph. However, in a real world scenario, it is not possible to isolate a population completely: there is always some interconnection with another network, which partially overlaps with the contact network. In this paper, we study the spreading process of a susceptible-infected-susceptible (SIS) epidemic model in an interconnected network of two generic graphs with generic interconnection and different epidemic-related parameters. Using bifurcation theory and spectral graph theory, we find the epidemic threshold of one network as a function of the infection strength of the other coupled network and adjacency matrices of each graph and their interconnection, and provide a quantitative measure to distinguish weak and strong interconnection topology. These results have implications for the broad field of epidemic modeling and control.","Topology,
Couplings,
Equations,
Sociology,
Statistics,
Network topology,
Mathematical model"
3D Lacunarity in Multifractal Analysis of Breast Tumor Lesions in Dynamic Contrast-Enhanced Magnetic Resonance Imaging,"Dynamic contrast-enhanced magnetic resonance (DCE-MR) of the breast is especially robust for the diagnosis of cancer in high-risk women due to its high sensitivity. Its specificity may be, however, compromised since several benign masses take up contrast agent as malignant lesions do. In this paper, we propose a novel method of 3D multifractal analysis to characterize the spatial complexity (spatial arrangement of texture) of breast tumors at multiple scales. Self-similar properties are extracted from the estimation of the multifractal scaling exponent for each clinical case, using lacunarity as the multifractal measure. These properties include several descriptors of the multifractal spectra reflecting the morphology and internal spatial structure of the enhanced lesions relatively to normal tissue. The results suggest that the combined multifractal characteristics can be effective to distinguish benign and malignant findings, judged by the performance of the support vector machine classification method evaluated by receiver operating characteristics with an area under the curve of 0.96. In addition, this paper confirms the presence of multifractality in DCE-MR volumes of the breast, whereby multiple degrees of self-similarity prevail at multiple scales. The proposed feature extraction and classification method have the potential to complement the interpretation of the radiologists and supply a computer-aided diagnosis system.","Fractals,
Lesions,
Breast,
Estimation,
Feature extraction,
Cancer"
UV-CDAT: Analyzing Climate Datasets from a User's Perspective,"The Ultra-scale Visualization Climate Data Analysis Tools (UV-CDAT) is a new tool for analyzing and visualizing climate data. Here we provide some pointers, background information, and examples to show how the system works.","Data visualization,
Meteorology,
Biological system modeling,
Data models,
Data analysis,
Graphical user interfaces"
On the stability and robustness of model predictive direct current control,"Model predictive direct current control (MPDCC) has emerged as a promising control scheme for high-power power electronic applications, achieving very low current distortion levels and fast dynamic responses. This is achieved by addressing the current control and the modulation problems in one computational stage. For MPDCC the issue of closed-loop stability has not yet been investigated. In this paper, it will be shown that the MPDCC algorithm guarantees stability, i.e. the load currents are moved into given bounds and kept inside of these bounds. It will also be shown that-by slightly modifying the MPDCC algorithm-robustness to parameter uncertainties can be established.","Switches,
Vectors,
Predictive models,
Stability analysis,
Current control,
Computational modeling,
Load modeling"
A New Construction of Zero-Difference Balanced Functions and Its Applications,"In this paper, a new construction of zero-difference balanced functions defined on is given, where is an odd positive integer. Based on the generic constructions proposed by Ding, optimal constant composition codes and perfect difference systems of sets with new parameters can be generated from the zero-difference balanced functions constructed in this paper.","Spread spectrum communication,
Educational institutions,
Encoding,
Computer science,
Computer aided instruction,
Vectors"
Convexity Properties of Detection Probability Under Additive Gaussian Noise: Optimal Signaling and Jamming Strategies,"In this correspondence, we study the convexity properties for the problem of detecting the presence of a signal emitted from a power constrained transmitter in the presence of additive Gaussian noise under the Neyman-Pearson (NP) framework. It is proved that the detection probability corresponding to the α-level likelihood ratio test (LRT) is either strictly concave or has two inflection points such that the function is strictly concave, strictly convex, and finally strictly concave with respect to increasing values of the signal power. In addition, the analysis is extended from scalar observations to multidimensional colored Gaussian noise corrupted signals. Based on the convexity results, optimal and near-optimal time sharing strategies are proposed for average/peak power constrained transmitters and jammers. Numerical methods with global convergence are also provided to obtain the parameters for the proposed strategies.","signalling,
AWGN,
jamming,
radio transmitters"
Comparison of Bulk-Oxide Trap Models: Lumped Versus Distributed Circuit,"Lumped- and distributed-circuit models for bulk-oxide traps are compared in terms of their fitting of p and n-type InGaAs MOS dispersion data. It is shown that the lumped-circuit model produces a distinct curvature in the capacitance versus log (frequency) plot-inconsistent with MOS data. Distributed-circuit model is able to fit both capacitance and conductance dispersions with a single, uniform oxide trap density, but the lumped-circuit model cannot. It is also shown that Hasegawa and Sawada's lumped-circuit model with an exponentially decaying distribution of border traps deviates even farther from the dispersion data.",
Perceptual Calibration for Immersive Display Environments,"The perception of objects, depth, and distance has been repeatedly shown to be divergent between virtual and physical environments. We hypothesize that many of these discrepancies stem from incorrect geometric viewing parameters, specifically that physical measurements of eye position are insufficiently precise to provide proper viewing parameters. In this paper, we introduce a perceptual calibration procedure derived from geometric models. While most research has used geometric models to predict perceptual errors, we instead use these models inversely to determine perceptually correct viewing parameters. We study the advantages of these new psychophysically determined viewing parameters compared to the commonly used measured viewing parameters in an experiment with 20 subjects. The perceptually calibrated viewing parameters for the subjects generally produced new virtual eye positions that were wider and deeper than standard practices would estimate. Our study shows that perceptually calibrated viewing parameters can significantly improve depth acuity, distance estimation, and the perception of shape.",
Prior Zero Forcing for Cognitive Relaying,"Relaying primary signals by cognitive base-stations (CBSs) can help the primary system and thus win CBSs a higher chance to transmit their own signals. For this purpose, conventional zero-forcing (CZF) beamforming is a straightforward solution where the primary and cognitive signals are transmitted from a multi-antenna CBS without causing interference to each other. However, with CZF, no priority is given to the primary user (PU), which is not consistent with the idea of cognitive radio. In this paper, we shall propose a prior ZF (PZF) scheme which gives priority to the PU by transmitting primary signals without considering their interference to the cognitive users (CUs), while cognitive signals are not allowed to generate interference to the PU. As a result, PZF provides a better channel for the CBS-PU link than CZF but the same channel gain for the CBS-CU links as CZF. We compare PZF and CZF by considering both the transmit power with given target rates and the outage performance with given transmit power, where closed-form conditions are derived to indicate their respective advantages. One of the important contributions of this paper is to prove that, with one CU, a target rate of 1 bit/s/Hz for the CU is the key point that differentiates PZF and CZF, which is independent of the number of CBS-antennas, the channel distributions, and the signal-to-noise power ratio (SNR).","Interference,
Array signal processing,
Vectors,
Signal to noise ratio,
Quality of service,
Relays,
Wireless communication"
Enterprise Architecture Documentation: Empirical Analysis of Information Sources for Automation,"Over the past decade, Enterprise Architecture (EA) management emerged to a mature discipline commonly applied to realize cost saving potentials while increasing effectiveness of IT in organizations. Typically, EA management starts by documenting the current state in an EA model and deriving future planned states heading towards an optimized EA. In practice, organizations struggle with the documentation of their current state due to the complexity of their enterprise architecture and its frequent changes. Current research activities seek to automate the data collection process by integrating existing EA information sources of operative systems. However, a comprehensive analysis of possible information sources and their appropriateness for EA is not yet provided. To build an empirical basis, this paper presents findings of a survey conducted on the key problems in EA documentation as well as the appropriateness of specific EA information sources for automation with respect to provided data types and data quality.","Documentation,
Organizations,
Automation,
Computer architecture,
Data models,
Industries"
Power-optimized stiffness and nonlinear position control of an actuator with Variable Torsion Stiffness,"Introducing compliant actuation to robotic joints is an approach to ensure safety in closer human-machine interaction. Further, the possibility to adjust stiffness can be beneficial considering energy storage and the power consumption required to track certain trajectories. The subject of this paper is the stiffness and position control of the Variable Torsion Stiffness (VTS) actuator for application in compliant robotic joints. For the realization of a variable rotational stiffness, the active length of a torsional elastic element in serial configuration between drive and link is adjusted in VTS. After the deduction of an extended drive train model, this paper gives an advanced power analysis clarifying power-optimal settings from previous basic models and identifying additional settings that allow for a more versatile operation. Based on these results that can be generalized to other variable elastic actuator concepts, an optimized strategy for setting stiffness is determined considering the whole system dynamics including natural frequencies as well as antiresonance effects. For position control of VTS in a prototypical implementation, a nonlinear position controller is designed by means of feedback linearization. Although the system is modified significantly by changing drive train stiffness, the stiffness adaptation of the controller ensures the required tracking performance.",Robots
A Feature-Metric-Based Affinity Propagation Technique for Feature Selection in Hyperspectral Image Classification,"Relevant component analysis has shown effective in metric learning. It finds a transformation matrix of the feature space using equivalence constraints. This paper explores this idea for constructing a feature metric (FM) and develops a novel semisupervised feature-selection technique for hyperspectral image classification. Two feature measures referred to as band correlation metric (BCM) and band separability metric (BSM) are derived for the FM. The BCM can measure the spectral correlation among the bands, while the BSM can assess the class discrimination capability of a single band. The proposed feature-metric-based affinity propagation (AP) (FM-AP) technique utilizes exemplar-based clustering, i.e., AP, to group bands from original spectral channels with the FM. Experimental results are conducted on two hyperspectral images and show the advantages of the proposed technique over traditional feature-selection methods.","Accuracy,
Frequency modulation,
Hyperspectral imaging,
Measurement,
Availability"
Empirical Formula of Cavity Dominant Mode Frequency for 60-GHz Cavity-Backed Wide Slot Antenna,"An empirical formula of the dominant mode resonant frequency of the cavity which is used to back a wide slot antenna is presented. The antenna is formed by etching a wide slot onto the broad wall of a substrate integrated waveguide (SIW) cavity fed by an SIW through an inductive coupling window. The widely slotted cavity resonates at the dominant mode when the wide slot radiates. Based on the analysis of the field distribution in the slotted-cavity, an empirical formula is derived to determine the dominant mode resonant frequency of the cavity with respect to the width to length ratio (WLR) of the etched slot. The empirical formula is numerically verified at a 60-GHz band.",
A Unary Error Correction Code for the Near-Capacity Joint Source and Channel Coding of Symbol Values from an Infinite Set,"A novel Joint Source and Channel Code (JSCC) is proposed, which we refer to as the Unary Error Correction (UEC) code. Unlike existing JSCCs, our UEC facilitates the practical encoding of symbol values that are selected from a set having an infinite cardinality. Conventionally, these symbols are conveyed using Separate Source and Channel Codes (SSCCs), but we demonstrate that the residual redundancy that is retained following source coding results in capacity loss. This loss is found to have a value of 1.11 dB in a particular practical scenario, where Quaternary Phase Shift Keying (QPSK) modulation is employed for transmission over an uncorrelated narrowband Rayleigh fading channel. By contrast, the proposed UEC code can eliminate this capacity loss, or reduce it to an infinitesimally small value. Furthermore, the UEC code has only a moderate complexity, facilitating its employment in practical low-complexity applications.",
Communicating the Sum of Sources Over a Network,"We consider the network communication scenario, over directed acyclic networks with unit capacity edges in which a number of sources si each holding independent unit-entropy information Xi wish to communicate the sum ΣXi to a set of terminals tj. We show that in the case in which there are only two sources or only two terminals, communication is possible if and only if each source terminal pair si/tj is connected by at least a single path. For the more general communication problem in which there are three sources and three terminals, we prove that a single path connecting the source terminal pairs does not suffice to communicate ΣXi. We then present an efficient encoding scheme which enables the communication of ΣXi for the three sources, three terminals case, given that each source terminal pair is connected by two edge disjoint paths.","Network coding,
Encoding,
Multicast communication,
Vectors,
Joining processes,
Entropy,
Network topology"
High-Q Backside Silicon-Embedded Inductor for Power Applications in /spl mu/H and MHz Range,"In this paper, a set of backside silicon-embedded inductors (BSEIs) is fabricated and characterized for potential applications in next-generation fully integrated power electronics. The fabrication technology of the BSEI is very similar to the through-silicon-via technology and has a high potential for post-CMOS integration. Without using magnetic material, an inductance as high as 13.8 μH is achieved with an effective inductance density of 0.6 μH/mm2. For the 4.5 mm × 4.5 mm BSEIs with a high substrate resistivity, an inductance between 2 and 4 μH, a dc resistance of 0.6-1.4 Ω , and a peak quality factor ranging from 18 to 23 occurring at 2-5 MHz are experimentally demonstrated. The effects of various physical design parameters are also experimentally studied, including coil outer dimension, metal width/spacing/pitch, coil shape, and silicon resistivity. These measurement results illustrate the design flexibility of the proposed BSEI technology to allow tradeoffs of key electrical properties for meeting different requirements of various integrated power electronics.",
An emg-based robotic hand exoskeleton for bilateral training of grasp,"This work presents the development and the preliminary experimental assessment of a novel EMG-driven robotic hand exoskeleton for bilateral active training of grasp motion in stroke. The system allows to control the grasping force required to lift a real object with an impaired hand, through the active guidance provided by a hand active exoskeleton, whose force is modulated by the EMG readings acquired on the opposite unimpaired arm. To estimate the grasping force, the system makes use of surface EMG recordings during grasping, developed on the opposite unimpaired arm, and of a neural network to classify the information. The design, integration and experimental characterization of the system during the grasp of two cylindrical objects is presented. The experimental results show that an optimal force tracking of the interaction force with the object can be achieved.","Force,
Grasping,
Thumb,
Training,
Electromyography,
Exoskeletons"
A Family of Three-Switch Three-State Single-Phase Z -Source Inverters,"This paper proposes a new family of three-switch three-state single-phase Z-source inverters (TSTS-ZSIs) that can be classified into two groups, boost-based TSTS-ZSI and buck-boost-based TSTS-ZSI, according to the step-up circuit. All of the topologies have the merits of buck-boost capability and low voltage stress, and some of them have the feature of dual grounding. In addition, the step-up in dc side and inversion in ac side is completely decoupled in the proposed topologies. In terms of a linear voltage gain, the conventional linear control methods can be used, which makes the control system very simple. The operating principles of the two types of topologies are described, respectively, and the comprehensive comparison between them is provided. Finally, the theoretical analysis and comparison of the proposed topologies are verified by the simulation and experimental results.","Inverters,
Topology,
Stress,
Voltage control,
Switches,
Low voltage"
Design criteria of digital filters for synchrophasor estimation,"In the near future electrical waveforms in power networks are expected to exhibit strong amplitude and phase fluctuations caused by dynamic network topology changes and variable energy flows between loads and generators. Such fluctuations need to be constantly and accurately monitored both to optimize energy distribution and for safety and protection reasons. Nowadays, this task is typically accomplished by the so called Phasor Measurement Units (PMU), which measure the phasor of voltage and current waveforms on a common timescale synchronized to the Coordinated Universal Time (UTC). One of the most typical techniques for phasor estimation is based on digital down-conversion and filtering. This approach, although not explicitly recommended, is described in Annex C of Standard IEEE C37.118.1-2011, namely one of the main reference document for synchrophasor measurement in power systems. The same standard also reports two possible examples of filters for P-class and M-class phasor estimation. However, no specific filter design methods are provided. In this paper some guidelines for filter design are proposed on the basis of a model describing the behavior of a power waveform in both static and dynamic conditions. The reported design criteria are supported by some simulation results.","Finite impulse response filters,
Power harmonic filters,
Harmonic analysis,
Standards,
Estimation,
Frequency modulation,
Fluctuations"
Multiview Coding Mode Decision With Hybrid Optimal Stopping Model,"In a generic decision process, optimal stopping theory aims to achieve a good tradeoff between decision performance and time consumed, with the advantages of theoretical decision-making and predictable decision performance. In this paper, optimal stopping theory is employed to develop an effective hybrid model for the mode decision problem, which aims to theoretically achieve a good tradeoff between the two interrelated measurements in mode decision, as computational complexity reduction and rate-distortion degradation. The proposed hybrid model is implemented and examined with a multiview encoder. To support the model and further promote coding performance, the multiview coding mode characteristics, including predicted mode probability and estimated coding time, are jointly investigated with inter-view correlations. Exhaustive experimental results with a wide range of video resolutions reveal the efficiency and robustness of our method, with high decision accuracy, negligible computational overhead, and almost intact rate-distortion performance compared to the original encoder.","Encoding,
Computational complexity,
Computational modeling,
Educational institutions,
Correlation,
Bit rate,
Accuracy"
Transfer learning to account for idiosyncrasy in face and body expressions,"In this paper we investigate the use of the Transfer Learning (TL) framework to extract the commonalities across a set of subjects and also to learn the way each individual instantiates these commonalities to model idiosyncrasy. To implement this we apply three variants of Multi Task Learning, namely: Regularized Multi Task Learning (RMTL), Multi Task Feature Learning (MTFL) and Composite Multi Task Feature Learning (CMTFL). Two datasets are used; the first is a set of point based facial expressions with annotated discrete levels of pain. The second consists of full body motion capture data taken from subjects diagnosed with chronic lower back pain. A synchronized electromyographic signal from the lumbar paraspinal muscles is taken as a pain-related behavioural indicator. We compare our approaches with Ridge Regression which is a comparable model without the Transfer Learning property; as well as with a subtractive method for removing idiosyncrasy. The TL based methods show statistically significant improvements in correlation coefficients between predicted model outcomes and the target values compared to baseline models. In particular RMTL consistently outperforms all other methods; a paired t-test between RMTL and the best performing baseline method returned a maximum p-value of 2.3 × 10-4.","Pain,
Vectors,
Calibration,
Training,
Face,
Muscles,
Correlation"
Design of a Wideband Balun Using Parallel Strips,"A wideband balun designed by exact synthesis is presented in this letter. The designed balun has a symmetrical four-port structure with one port open-ended. It consists of a wideband impedance transformer and a broadband phase inverter, which is realized by connecting bottom and top layer parallel strip through two via holes. To design the wideband impedance transformer, an S-plane highpass prototype has been exactly synthesized with third-order Chebyshev response. The proposed design procedure is very flexible, and it can be easily scaled for other frequency bands. A wideband parallel strip balun operating from 0.72 to 2.05 GHz is fabricated and tested to verify the design concepts. The measured results match well with the design theory.","Impedance matching,
Wideband,
Transmission line measurements,
Inverters,
Strips,
Prototypes,
Power transmission lines"
Miniaturised slot antenna for biomedical applications,"An implantable slot antenna with a miniaturised size of 139.7 mm3 (10 × 11 × 1.27 mm) for biomedical applications is proposed. Operating at the Medical Implant Communications Service (MICS) band, miniaturisation of the antenna is realised by etching a meandered slot on the top metal with one end open. A microstrip line is utilised as excitation with a shorting connected to the radiator. In addition, two U-shaped stubs are adopted to match the feeding impedance to 50 Ω. The antenna is simulated in a one-layer skin model as well as in the arm of a human model and measured in skin-mimicking tissue. Good agreements can be obtained and the measurement results show that a broad bandwidth of 28.3% (from 354 to 469 MHz) for |S11| less than - 10 dB can be achieved.","slot antennas,
antenna radiation patterns,
biological tissues,
impedance matching,
microstrip antennas,
microstrip lines,
prosthetics"
Efficient Semisupervised MEDLINE Document Clustering With MeSH-Semantic and Global-Content Constraints,"For clustering biomedical documents, we can consider three different types of information: the local-content (LC) information from documents, the global-content (GC) information from the whole MEDLINE collections, and the medical subject heading (MeSH)-semantic (MS) information. Previous methods for clustering biomedical documents are not necessarily effective for integrating different types of information, by which only one or two types of information have been used. Recently, the performance of MEDLINE document clustering has been enhanced by linearly combining both the LC and MS information. However, the simple linear combination could be ineffective because of the limitation of the representation space for combining different types of information (similarities) with different reliability. To overcome the limitation, we propose a new semisupervised spectral clustering method, i.e., SSNCut, for clustering over the LC similarities, with two types of constraints: must-link (ML) constraints on document pairs with high MS (or GC) similarities and cannot-link (CL) constraints on those with low similarities. We empirically demonstrate the performance of SSNCut on MEDLINE document clustering, by using 100 data sets of MEDLINE records. Experimental results show that SSNCut outperformed a linear combination method and several well-known semisupervised clustering methods, being statistically significant. Furthermore, the performance of SSNCut with constraints from both MS and GC similarities outperformed that from only one type of similarities. Another interesting finding was that ML constraints more effectively worked than CL constraints, since CL constraints include around 10% incorrect ones, whereas this number was only 1% for ML constraints.","Bioinformatics,
Genomics,
Vectors,
Indexing,
Educational institutions,
Thesauri,
Clustering algorithms"
Acoustic interference cancellation for a voice-driven interface in smart TVs,"A novel method is proposed to improve the voice recognition performance by suppressing acoustic interferences that add nonlinear distortion to a target recording signal when received by the recognition device. The proposed method is expected to provide the best performance in smart TV environments, where a remote control collects command speech by the internal microphone and performs automatic voice recognition, and the secondary microphone equipped in a TV set provides the reference signal for the background noise source. Due to the transmission channel, the original interference is corrupted nonlinearly, and the conventional speech enhancement techniques such as beamforming and blind signal separation are not applicable. The proposed method first equalizes the interference in the two microphones by maximizing the instantaneous correlation between the nonlinearly related target recording and reference signal, and suppresses the equalized interference. To obtain an optimal estimation of the equalization filter, a method for detecting instantaneous activity of interference is also proposed. The validity of the proposed method is proved by the improvement in automatic voice recognition performance in a simulated TV room where loud TV sounds or babbling speech interfere in a user's commanding speech.","Speech recognition,
Microphones,
Interference,
TV,
Speech,
Wiener filters,
Noise"
Requirements Bazaar: Social requirements engineering for community-driven innovation,"The innovation potential of niche communities often remains inaccessible to service providers due to a lack of awareness and effective negotiation between these two groups. Requirements Bazaar, a browser-based social software for Social Requirements Engineering (SRE), aims at bringing together communities and service providers into such a negotiation process. Communities should be supported to express and trace their requirements and eventually receive a realization. Service providers should be supported in discovering relevant innovative requirements to maximize impact with a realization. In this paper we present Requirements Bazaar with focus on four aspects: requirements specification, a workflow for co-creation, workspace integration and personalizable requirements prioritization.","Communities,
Technological innovation,
Software,
Computer science,
Educational institutions,
Uncertainty,
Prototypes"
Domain ontology based semantic search for efficient information retrieval through automatic query expansion,"To achieve semantic search, a search engine is needed which can interpret the meaning of a user's query and the relations among the concepts that a document contains with respect to a particular domain. We are presenting the skeleton of such a system based on ontology. In this system, a user enters a query from which the meaningful concepts are extracted; using these concepts and domain ontology, query expansion is performed. For all the terms (expanded and initial query terms), SPARQL query is built and then it is fired on the knowledge base that finds appropriate RDF triples in knowledge Base. Web documents relevant to the requested concepts and individuals specified in these triples are then retrieved. Finally, the retrieved documents are ranked according to their relevance to the user's query and then are sent to the user. If a user wants to find specific information; can search with another module of our system that works without query expansion. The approach of query expansion makes use of query concepts as well as synonyms of these concepts and the new terms relate with the original query terms within a threshold.","Semantics,
Ontologies,
Search engines,
Resource description framework,
Java,
Signal processing algorithms"
Testing a Commercial MRAM Under Neutron and Alpha Radiation in Dynamic Mode,"Academic and industrial research interest in terrestrial radiation effects of electronic devices has expanded over the last years from avionics and military applications to commercial applications as well. At the same time, the need for faster and more reliable memories has given growth to new memory technologies such as Magnetic (magneto-resistive) Random Access Memories (MRAM), a promising new non-volatile memory technology that will probably replace in the future the current SRAM and FLASH based memories. In this paper, we evaluate the soft error resilience of a commercial toggle MRAM in static and dynamic test mode, under neutron radiation with energies of 25, 50 and 80 MeV as well as under a Californium (Cf-252) alpha source.",
Residential electrical demand forecasting in very small scale: An evaluation of forecasting methods,"Applications such as generator scheduling, household smart device scheduling, transmission line overload management and microgrid islanding autonomy all play key roles in the smart grid ecosystem. Management of these applications could benefit from short-term load prediction, which has been successfully achieved on large-scale systems such as national grids. However, the scale of the data for analysis is much smaller, similar to the load of a single transformer, making prediction difficult. This paper examines several prediction approaches for day and week ahead electrical load of a community of houses that are supplied by a common residential transformer, in particular: artificial neural networks; fuzzy logic; auto-regression; auto-regressive moving average; auto-regressive integrated moving average; and wavelet neural networks. In our evaluation, the methods use pre-recorded electrical load data with added weather information. Data is recorded from a smart-meter trial that took place during 2009-2010 in Ireland, which registered individual household consumption for 17 months. Two different scenarios are investigated, one with 90 houses, and another with 230 houses. Results for the two scenarios are compared and the performances of the evaluated prediction methods are discussed.","Electricity,
Training,
Artificial neural networks,
Humidity,
Forecasting,
Communities"
Characterization of SiCN Ceramic Material Dielectric Properties at High Temperatures for Harsh Environment Sensing Applications,"A novel method is presented in this paper to precisely characterize the dielectric properties of silicon carbon nitride (SiCN) ceramic materials at high temperatures for wireless passive sensing applications. This technique is based on a high quality factor (Q) dielectrically loaded cavity resonator, which allows for accurate characterization of both dielectric constant and loss tangent. The dielectric properties of SiCN ceramics are characterized from 25 °C to 1000 °C. Two different metallization processes are implemented for the measurements with the highest temperatures of 500 °C and 1000 °C, respectively. A custom-made thru-reflect-line calibration kit is used to maximize the measurement accuracy at every temperature point. It is observed that the dielectric constant and loss tangent of the SiCN sample without Boron doping increase from 3.707 to 3.883 and from 0.0038 to 0.0213, respectively, when the temperature is raised from 25 °C to 500 °C, and for the SiCN with Boron doping (SiBCN), the dielectric constant and loss tangent increase from 4.817 to 5.132 and from 0.0020 to 0.0186, respectively, corresponding to the temperature ranging from 25 °C to 1000 °C. Experimental uncertainties for extracted εr and tanδ are no more than 0.0004 and 0.0001, respectively. The temperature dependency of Si(B)CN dielectric properties, as well as the dielectrically loaded cavity resonator structure, provides the basis for the development of wireless passive temperature sensors for high-temperature applications.","Materials,
Cavity resonators,
Temperature measurement,
Dielectric measurements,
Temperature,
Temperature sensors,
Dielectrics"
Open vocabulary handwriting recognition using combined word-level and character-level language models,"In this paper, we present a unified search strategy for open vocabulary handwriting recognition using weighted finite state transducers. Additionally to a standard word-level language model we introduce a separate n-gram character-level language model for out-of-vocabulary word detection and recognition. The probabilities assigned by those two models are combined into one Bayes decision rule. We evaluate the proposed method on the IAM database of English handwriting. An improvement from 22.2% word error rate to 17.3% is achieved comparing to the closed-vocabulary scenario and the best published result.",
Finite rate of innovation based modeling and compression of ECG signals,"Mobile health is gaining increasing importance for society and the quest for new power efficient devices sampling biosignals is becoming critical. We discuss a new scheme called Variable Pulse Width Finite Rate of Innovation (VPW-FRI) to model and compress ECG signals. This technique generalizes classical FRI estimation to enable the use of a sum of asymmetric Cauchy-based pulses for modeling electrocardiogram (ECG) signals. We experimentally show that VPW-FRI indeed models ECG signals with increased accuracy compared to current standards. In addition, we study the compression efficiency of the method: compared with various widely used compression schemes, we showcase improvements in terms of compression efficiency as well as sampling rate.","Electrocardiography,
Heart beat,
Databases,
Technological innovation,
Accuracy,
Noise"
Brokering Algorithms for Optimizing the Availability and Cost of Cloud Storage Services,"In recent years, cloud storage providers have gained popularity for personal and organizational data, and provided highly reliable, scalable and flexible resources to cloud users. Although cloud providers bring advantages to their users, most cloud providers suffer outages from time-to-time. Therefore, relying on a single cloud storage services threatens service availability of cloud users. We believe that using multi-cloud broker is a plausible solution to remove single point of failure and to achieve very high availability. Since highly reliable cloud storage services impose enormous cost to the user, and also as the size of data objects in the cloud storage reaches magnitude of exabyte, optimal selection among a set of cloud storage providers is a crucial decision for users. To solve this problem, we propose an algorithm that determines the minimum replication cost of objects such that the expected availability for users is guaranteed. We also propose an algorithm to optimally select data centers for striped objects such that the expected availability under a given budget is maximized. Simulation experiments are conducted to evaluate our algorithms, using failure probability and storage cost taken from real cloud storage providers.","Availability,
Cloud computing,
Heuristic algorithms,
Quality of service,
Google,
Linear programming"
Review based on data clustering algorithms,"A review based on different types of clustering algorithms with their corresponding data sets has been proposed. In this paper, we have given a complete comparative statistical analysis of various clustering algorithms. Clustering algorithms usually employ distance metric or similarity metric to cluster the data set into different partitions. Well known clustering algorithms have been widely used in various disciplines. Type of clustering algorithm used depends upon the application and data set used in that field. Numerical data set is comparatively easy to implement as data are invariably real number and can be used for statistical applications. Others type of data set such as categorical, time series, boolean, and spatial, temporal have limited applications. By viewing the statistical analysis, it is observed that there is no optimal solution for handling problems with large data sets of mixed and categorical attributes. Some of the algorithms can be applied but their performance degrades as the size of data keeps on increasing.",
Time-Efficient Protocols for Neighbor Discovery in Wireless Ad Hoc Networks,"Neighbor discovery (ND) is a basic and crucial step for initializing wireless ad hoc networks. A fast, precise, and energy-efficient ND protocol has significant importance to subsequent operations in wireless networks. However, many existing protocols have a high probability of generating idle slots in their neighbor discovering processes, which prolongs the executing duration, thus compromising their performance. In this paper, we propose a novel randomized protocol FRIEND, which is a prehandshaking ND protocol, to initialize synchronous full-duplex wireless ad hoc networks. By introducing a prehandshaking strategy to help each node be aware of activities of its neighborhood, we significantly reduce the probabilities of generating idle slots and collisions. Moreover, with the development of single-channel full-duplex communication technology, we further decrease the processing time needed in FRIEND and construct the first fullduplex ND protocol. Our theoretical analysis proves that FRIEND can decrease the duration of ND by up to 48% in comparison with classical ALOHA-like protocols. In addition, we propose HD-FRIEND for half-duplex networks and variants of FRIEND for multihop and duty-cycled networks. Both theoretical analysis and simulation results show that FRIEND can adapt to various scenarios and significantly decrease the duration of ND.","Protocols,
Mobile ad hoc networks,
Wireless networks,
Upper bound,
Nominations and elections,
Synchronization,
Sun"
Automated doorway detection for assistive shared-control wheelchairs,"This work presents an algorithm for rapid, automated detection of open doorways using 3D point cloud data. The algorithm has been developed in the context of shared-control powered wheelchairs in which adaptive assistance is provided to individuals who otherwise might not possess the fine motor control necessary to handle potentially challenging activities, such as doorway traversal. In this context it is important to go beyond the 2D laser scanner for open doorway detection, for both safety reasons as well as opportunities for improved shared-control behavior development. We evaluate the doorway detection by systematically testing the performance on several doors and door configurations from varied view points, using point clouds generated by a Microsoft Kinect.","Wheelchairs,
Robot sensing systems,
Three-dimensional displays,
Navigation,
Cameras,
Context"
Voice Activity Detection Via Noise Reducing Using Non-Negative Sparse Coding,"This letter presents a voice activity detection (VAD) approach using non-negative sparse coding to improve the detection performance in low signal-to-noise ratio (SNR) conditions. The basic idea is to use features extracted from a noise-reduced representation of original audio signals. We decompose the magnitude spectrum of an audio signal on a speech dictionary learned from clean speech and a noise dictionary learned from noise samples. Only coefficients corresponding to the speech dictionary are considered and used as the noise-reduced representation of the signal for feature extraction. A conditional random field (CRF) is used to model the correlation between feature sequences and voice activity labels along audio signals. Then, we assign the voice activity labels for a given audio by decoding the CRF. Experimental results demonstrate that our VAD approach has a good performance in low SNR conditions.","Speech,
Feature extraction,
Dictionaries,
Encoding,
Signal to noise ratio,
Vectors"
Monitoring YouTube QoE: Is Your Mobile Network Delivering the Right Experience to your Customers?,"YouTube, the killer application of today's Internet, is changing the way ISPs and network operators manage quality monitoring and provisioning on their IP networks. YouTube is currently the most consumed Internet application, accounting for more than 30% of the overall Internet's traffic worldwide. Coupling such an overwhelming traffic volume with the ever intensifying competition among ISPs is pushing operators to integrate Quality of Experience (QoE) paradigms into their traffic management systems. The need for automatic QoE assessment solutions becomes even more critical in mobile broadband networks, where over-provisioning solutions can not be foreseen and bad user experience translates into churning clients. This paper presents a complete study on the problem of YouTube Quality of Experience monitoring and assessment in mobile networks. The paper considers not only the QoE analysis, modeling and assessment based on real users' experience, but also the passive monitoring of the quality provided by the ISP to its end-customers in a large mobile broadband network.","YouTube,
Streaming media,
Monitoring,
Mobile communication,
Mobile computing,
Broadband communication,
Internet"
Adding Active Learning to LWR for Ping-Pong Playing Robot,"In this brief, we consider the problem of controlling the racket attached to the ping-pong playing robot, so that the incoming ball is returned to a desired position. The maps that are used to calculate the racket's initial parameters are described. They are implemented with the locally weighted regression (LWR). An active learning approach based on the fuzzy cerebellar model articulation controller (FCMAC) is proposed, and then it is added to the LWR, which is regarded as lazy learning. A learning algorithm that is used for updating the experience data in the fuzzy CMAC according to the errors between the actual and desired landing positions is presented. A series of experiments has been performed to demonstrate the applicability of the proposed method.",
Wideband Receiver for a Three-Dimensional Ranging LADAR System,"A low-noise, high-gain, wide-linear-dynamic-range, wide-band receiver for a pulsed, direct, three-dimensional ranging LADAR system has been designed and implemented in a 0.13 μm CMOS technology. Specific design techniques, including gain control scheme to widen linear dynamic range, gain allocating between blocks and noise minimization to improve SNR, frequency response compensation to extend bandwidth and ensure system stability, and output voltage swing boosting, have been proposed to achieve challenging design goals with linear dynamic range of 1:1600, equivalent input-referred current noise of less than 5.6 pA/√Hz, high gain of 78 dBΩ, maximum output swing of at least 500 mV, bandwidth of at least 500 MHz, and low sensitivity to temperature variation over the range from -10°C to 60°C, in the presence of 2 pF photodiode parasitic capacitance.",
Augmenting a Modified Egyptian Axe Dipole Antenna With Non-Foster Elements to Enlarge Its Directivity Bandwidth,"Non-Foster elements are introduced to augment an Egyptian axe dipole (EAD) antenna-based system in order to expand its directivity bandwidth. The frequency-agile properties of the original antenna system are investigated near 300 MHz by linearly and discretely changing the values of its internal reactive element. The curve-fit reactance versus frequency curve is established. It is reproduced approximately by augmenting the antenna system with two non-Foster elements implemented internally in one of its near-field parasitic elements and with negative impedance convertor (NIC) designs. It is demonstrated that the resulting electrically small antenna system is capable of achieving excellent unidirectional radiation performance, including a broadside directivity in the range from 5.78 to 6.24 dB with more than a 20 dB front-to-back ratio (FTBR) over a 13% instantaneous fractional bandwidth. The corresponding half-power beamwidths in the E- and H-planes, respectively, are 78° and 138°; the radiation efficiency exceeds 65%.","Antennas,
Bandwidth,
Resistance,
Resonant frequency,
Capacitors,
Inductors"
Performance of Fully Recessed AlGaN/GaN MOSFET Prepared on GaN Buffer Layer Grown With AlSiC Precoverage on Silicon Substrate,"A crack-free AlGaN/GaN heterostrucure is grown on 4-in Si (111) substrate with AlSiC precoverage layer. Covering the Si surface with the AlSiC layer, until the growth of the AlN wetting buffer layer, is found to be effective in compensating the strong tensile stress in the GaN layer grown on Si substrate. The metal-oxide-semiconductor field-effect transistor, fabricated on this AlGaN/GaN heterostructure, exhibits excellent normally-off characteristics with threshold voltage of 7.2 V, maximum drain current of 120 mA/mm, ON/OFF current ratio of ~ 108, and subthreshold slope of 80 mV/decade.","wetting,
aluminium compounds,
buffer layers,
gallium compounds,
III-V semiconductors,
MOSFET,
silicon"
Mobile app development and usability research to help dementia and Alzheimer patients,"Caregiver anecdotes attest that music and photographs play an important role for family members diagnosed with Alzheimer's disease (AD), even those with severe AD. Tablets and iPads, which are prevalent, can be utilized with dementia patients in portraying favorite music and family photographs via apps developed in close partnership with geriatric facilities. Anecdotal research has shown that non-verbal late-stage dementia patients have become stimulated when iPods played their beloved tunes. There is an unmet need in geriatric facilities for stimulating dementia patients, as well providing hard-core data for proving increased cognitive abilities with technology. Technology can help bridge the gap between patients and staff to improve the quality of life for the cognitively impaired. This study addresses cognitive functioning and quality of life for people diagnosed with dementia via technology. In recent times, the influx of older adults suffering from Alzheimer's or dementia related illness has impacted the U.S. Healthcare system. Cognition significantly declines in older adults with AD or dementia over the course of the disease, causing most to be dependent on caregivers, thus routinely institutionalized. Caregivers are often required to focus their attention on addressing the agitation or discomfort of the AD or dementia patient. Research has shown that technology instruments such as iPods, help stimulate those with dementia. This study focuses on innovative devices such as iPads and tablets, which are mainstream and easy to use, cannot only help determine stage of dementia, but also provide stimulation to improve cognitive functioning. It is hoped that this research will analyze that specially created apps and existing assistive software can be used to decrease the symptoms and improve cognition of older adults suffering from AD or other dementia related diseases. Via service-learning courses, students developed an easy-to-use application for tablets to help older adults with disabilities more readily use the technology. Student programmers produced apps and performed usability tests with the dementia patients, as well as met with geriatric facility personnel to produce application software that meets the patients, family, and caregiver needs and expectations. For example, a student term project produced an application entitled Candoo that utilizes Google's voice recognition and synthesis engine to navigate the web, provide the weather, and supply pill reminder alerts. Another application example included one that allows families to electronically send photographs, video clips, and favorite music from anywhere to loved ones for enjoyment. Furthermore, older adults were assessed by nursing students for cognitive functioning before, and after the semester's intervention. Such mobile apps could allow dementia persons to become less agitated and stay in their homes longer, while also providing awareness and positive change of attitude by those of another generation towards the elderly. This research will discuss student developed mobile applications in the scope of helping improve the quality of life of patients with AD or dementia.","Dementia,
Mobile communication,
Sociology,
Statistics,
Animals,
Tablet computers"
Improved Efficiency of Backward-Wave Oscillator With an Inclined Electron Beam,"The possibility of the efficient operation of a backward-wave oscillator (BWO) with an electron beam inclined with respect to the surface of a periodic structure-a clinotron-is analyzed here. The beam inclination provides the possibility of effective interaction by all particles of a thick electron beam with the slow evanescent harmonic of the cavity modes. The problem of electron-beam-wave interaction is treated in a self-consistent formulation. A theoretical analysis shows that the inclination of the electron beam to the grating surface decreases the demand of the clinotron for magnetic field magnitude and beam velocity spread compared to a conventional BWO. It is demonstrated that, for an optimal inclination angle and an optimal beam thickness, the clinotron efficiency exceeds the efficiency of a conventional BWO considerably given the same electron beam parameters. The developed multimode theory results are in satisfactory agreement with the theory of a BWO in terms of reflections and particle-in-cell simulations.",
Ballistic I-V Characteristics of Short-Channel Graphene Field-Effect Transistors: Analysis and Optimization for Analog and RF Applications,"With the recent upsurge in experimental efforts toward fabrication of short-channel graphene field-effect transistors (GFETs) for analog and high-frequency RF applications-where the advantages of distinctive intrinsic properties of gapless graphene are expected to be leveraged-a critical understanding of the factors affecting both output and transfer characteristics is necessary for device optimization. Analyzing the device characteristics through ballistic electronic transport simulations within the nonequilibrium Green's function formalism, we show that a doping in the drain underlap region can significantly improve the quasi-saturation behavior in the GFET output characteristics and, hence, the output resistance and intrinsic gain. From this understanding, we provide a unified and coherent explanation for seemingly disparate phenomena-quasi-saturation and the recently reported three-terminal negative differential resistance in GFETs. We also investigate the scaling behavior of cutoff frequency and comment on some of the observed scaling trends in recent experiments.","Doping,
Logic gates,
Electric potential,
Tunneling,
Graphene,
Resistance,
Electrostatics"
DeBAR: Deflection based adaptive router with minimal buffering,"Energy efficiency of the underlying communication framework plays a major role in the performance of multicore systems. NoCs with buffer-less routing are gaining popularity due to simplicity in the router design, low power consumption, and load balancing capacity. With minimal number of buffers, deflection routers evenly distribute the traffic across links. In this paper, we propose an adaptive deflection router, DeBAR, that uses a minimal set of central buffers to accommodate a fraction of mis-routed flits. DeBAR incorporates a hybrid flit ejection mechanism that gives the effect of dual ejection with a single ejection port, an innovative adaptive routing algorithm, and a selective flit buffering based on flit marking. Our proposed router design reduces the average flit latency and the deflection rate, and improves the throughput with respect to the existing minimally buffered deflection routers without any change in the critical path.","Ports (Computers),
Pipelines,
Benchmark testing,
Video recording,
Routing,
Silver,
Registers"
Distributed Processing of Probabilistic Top-k Queries in Wireless Sensor Networks,"In this paper, we introduce the notion of sufficient set and necessary set for distributed processing of probabilistic top-k queries in cluster-based wireless sensor networks. These two concepts have very nice properties that can facilitate localized data pruning in clusters. Accordingly, we develop a suite of algorithms, namely, sufficient set-based (SSB), necessary set-based (NSB), and boundary-based (BB), for intercluster query processing with bounded rounds of communications. Moreover, in responding to dynamic changes of data distribution in the network, we develop an adaptive algorithm that dynamically switches among the three proposed algorithms to minimize the transmission cost. We show the applicability of sufficient set and necessary set to wireless sensor networks with both two-tier hierarchical and tree-structured network topologies. Experimental results show that the proposed algorithms reduce data transmissions significantly and incur only small constant rounds of data communications. The experimental results also demonstrate the superiority of the adaptive algorithm, which achieves a near-optimal performance under various conditions.",
Multijunction Solar Cell Designs Using Silicon Bottom Subcell and Porous Silicon Compliant Membrane,"A novel approach to the design of multijunction solar cells on silicon substrates for 1-sun applications is described. Models for device simulation, including porous silicon layers, are presented. A silicon bottom subcell is formed by diffusion of dopants into a silicon wafer. The top of the wafer is porosified to create a compliant layer, and a III-V buffer layer is then grown epitaxially, followed by middle and top subcells. Because of the resistivity of the porous material, these designs are best suited to high-efficiency 1-sun applications. Numerical simulations of a multijunction solar cell that incorporates a porous silicon-compliant membrane indicate an efficiency of 30.7% under AM1.5G, 1-sun for low-threading dislocation density, decreasing to 23.7% for a TDD of 107 cm-2.","solar cells,
diffusion,
dislocation density,
electrical resistivity,
elemental semiconductors,
membranes,
numerical analysis,
semiconductor device models,
silicon"
An Efficient and Fair MAC Protocol Robust to Reactive Interference,"Interference constitutes a major challenge to availability for communication networks operating over a shared medium. This paper proposes the medium access (MAC) protocol AntiJam, which achieves a high and fair throughput even in harsh environments. Our protocol mitigates internal interference, requiring no knowledge about the number of participants in the network. It is also robust to intentional and unintentional external interference, e.g., due to coexisting networks or jammers. We model external interference using a powerful reactive adversary that can jam a (1-ε) -portion of the time-steps, where 0 <; ε ≤ 1 is an arbitrary constant. The adversary uses carrier sensing to make informed decisions on when it is most harmful to disrupt communications. Moreover, we allow the adversary to be adaptive and to have complete knowledge of the entire protocol history. AntiJam makes efficient use of the nonjammed time periods and achieves, if ε is constant, a Θ(1)-competitive throughput. In addition, AntiJam features a low convergence time and has excellent fairness properties, such that channel access probabilities do not differ among nodes by more than a small constant factor.","Jamming,
Media Access Protocol,
Interference,
Robustness,
Throughput,
Aggregates"
Low voltage DCI based low power VLSI circuit implementation on FPGA,"In this paper, we study the effect of using digitally controlled impedance IO Standard in memory interface design in terms of power consumption. In this work, we achieved 50% dynamic power reduction at 1.5V output driver voltage, 35.2% dynamic power reduction at 1.8V output driver voltage in comparison to 2.5V output driver voltage in DCI based IO standard implementation on input or output port in target design. Target device XC6VLX75TFF484-1 is a Virtex-6 FPGA of -1 speed grade and 484 pins is used for implementation of this design. Target Design is RAM-UART memory interface. XPower 13.4 is used for power analysis of our low power memory interface design. ISim is simulator to generate waveform. Planahead is used for design, synthesis and implementation.","Power demand,
Impedance,
Field programmable gate arrays,
Standards,
Clocks,
Random access memory,
System-on-chip"
Impact of Temperature Variations on the Device and Circuit Performance of Tunnel FET: A Simulation Study,"The paper presents a comprehensive comparison study of p-i-n and p-n-p-n tunnel field-effect transistor (TFET) architectures and the impact of temperature on their dc and circuit performance. The impact of a hetero-gate (HG) dielectric on the circuit performance also forms the part of the study. The device performance of p-i-n and p-n-p-n TFET with high-k dielectric and HG dielectric and the effect of temperature on the drain current characteristics, Ion/Ioff, and threshold voltage has been investigated and compared with MOSFET. Furthermore, the variations in the inverter (n-TFET with resistive load) transient characteristics and the fall delay due to temperature variations are studied using mixed mode simulations carried out with ATLAS device simulation software. Results reveal that TFET exhibits weak temperature dependence when the current conduction is band-to-band tunneling dominated, while the temperature dependence increases in the off-state regime, and the fall delay of resistive load n-TFET inverter decreases with increasing temperature.","PIN photodiodes,
MOSFET,
Temperature dependence,
Temperature,
Logic gates,
Threshold voltage,
Computer architecture"
Stable multiuser channel allocations in opportunistic spectrum access,"We consider the distributed channel allocation problem in an asymmetrical opportunistic spectrum access (OSA) system where each secondary user possibly has different channel reward even in the same channel due to geographic dispersion. We formulate this problem as a Gale-Shapley stable theorem using game theory to optimize the sum reward of all secondary users. It is challenging to achieve the stable matching of user-channel pairs without centralized control and prior knowledge of channel availability statistics. In this paper, we present a novel decentralized order-optimal learning Gale-Shapley scheme (OLGS) in which secondary users learn from their local history data and individually adjust their behaviors in a time-varying OSA system. The proposed scheme eliminates collisions among secondary users by a one-to-one user-channel matching policy. It also achieves stable spectral allocations using learning method without assuming known channel parameters and independent of information exchange among secondary users. Simulation results show that the system regret of the OLGS solution grows with time at the logarithmic order with low complexity.","Throughput,
Resource management,
Sensors,
Convergence,
Heuristic algorithms,
Information exchange,
Simulation"
Gamification of a Software Engineering course and a detailed analysis of the factors that lead to it's failure,"This paper describes the setup for a gamified classroom for the subject of Software Engineering. A series of papers have resulted from this work: “Understanding Student Motivation” at CSEDU 2013 [1] and “Bridging the Motivation Gap”, an IGIP SPEED Young Scientist award paper here at ICL 2013 [2]. The intention behind gamifying the course was to increase student engagement and motivation by allowing for independent learning with flexible speed and choice of emphasis. Daniel Pink's [3] motivational theory, which is also found in gamification factors, outlines that autonomy, mastery and purpose lead to these goals. The adopted approach also deals nicely with the vast differences regarding background knowledge and the spread of interest of each of the students. During the latter part of the course a student survey was conducted. Out of 90 students, 59 answered. As a general rule, students did not receive the gamification ideas in a positive light. We examine what went wrong regarding the gamification factors and propose changes for the next iteration of the course.","Games,
Educational institutions,
Materials,
Software engineering,
Conferences,
Collaborative work,
Collaboration"
Cooperative Strategies for Energy-Aware Ad Hoc Networks: A Correlated-Equilibrium Game-Theoretical Approach,"Energy efficiency is a crucial requirement for energy-aware ad hoc networks. Cooperative communications can be applied to significantly reduce and balance energy consumption. However, this advantage mainly depends on efficient cooperative strategies, i.e., the joint issue of relay node selection and transmit power control. In this paper, we propose a cooperative behavior control scheme, which determines cooperative strategies by using the correlated equilibrium (CE). Specifically, we first model a cooperative behavior control game where the individual utility function is derived from the energy efficiency in terms of the global max-min fairness with the outage performance constraint. Since the CE can achieve better performance by helping the noncooperative players to coordinate their strategies, we employ the CE to analyze the proposed game. Next, we derive the condition under which the CE is Pareto optimal and employ linear programming duality to show its closed-form expression. Furthermore, we design a linear programming method and a distributed learning algorithm based on the regret matching procedure to achieve the CE, respectively. Simulation results demonstrate that our scheme achieves good convergence, Pareto optimality, and max-min fairness.","Relays,
Games,
Linear programming,
Pareto optimization,
Ad hoc networks,
Joints"
Optimal Design of Grid-Connected PEV Charging Systems With Integrated Distributed Resources,"The penetration of plug-in electric vehicles and renewable distributed generation is expected to increase over the next few decades. Large scale unregulated deployment of either technology can have a detrimental impact on the electric grid. However, appropriate pairing of these technologies along with some storage could mitigate their individual negative impacts. This paper presents a framework and an optimization methodology for designing grid-connected systems that integrate plug-in electric vehicle chargers, distributed generation and storage. To demonstrate its usefulness, this methodology is applied to the design of optimal architectures for a residential charging case. It is shown that, given current costs, maximizing grid power usage minimizes system lifecycle cost. However, depending upon the location's solar irradiance patterns, architectures with solar photovoltaic generation can be more cost effective than architectures without. Additionally, Li-ion storage technology and micro wind turbines are not yet cost effective when compared to alternative solutions.","Linear programming,
Mathematical model,
Vectors,
Power generation,
Energy storage,
Optimization,
Vehicles"
Chaos PSO algorithm driven alternately by two different chaotic maps - An initial study,"In this paper, a new approach for chaos driven PSO algorithm is proposed. Two different chaotic maps are alternately used as pseudorandom number generators and switched over during the run of chaos driven PSO algorithm. The motivation for this research came from the previous successful experiments with PSO algorithm driven by different chaotic maps. Promising results of this innovative approach are presented in the results section and briefly analyzed.","Chaos,
Generators,
Optimization,
Switches,
Standards,
History,
Algorithm design and analysis"
High-Resolution Acoustic-Radiation-Force-Impulse Imaging for Assessing Corneal Sclerosis,"In ophthalmology, detecting the biomechanical properties of the cornea can provide valuable information about various corneal pathologies, including keratoconus and the phototoxic effects of ultraviolet radiation on the cornea. Also, the mechanical properties of the cornea can be used to evaluate the recovery from corneal refractive surgeries. Therefore, noninvasive and high-resolution estimation of the stiffness distribution in the cornea is important in ophthalmic diagnosis. The present study established a method for high-resolution acoustic-radiation-force-impulse (ARFI) imaging based on a dual-frequency confocal transducer in order to obtain a relative stiffness map, which was used to assess corneal sclerosis. An 11-MHz pushing element was used to induce localized displacements of tissue, which were monitored by a 48-MHz imaging element. Since the tissue displacements are directly correlated with the tissue elastic properties, the stiffness distribution in a tiny region of the cornea can be found by a mechanical B/D scan. The experimental system was verified using tissue-mimicking phantoms that included different geometric structures. Ex vivo cornea experiments were carried out using fresh porcine eyeballs. Corneas with localized sclerosis were created artificially by the injection of a formalin solution. The phantom experiments showed that the distributions of stiffness within different phantoms can be recognized clearly using ARFI imaging, and the measured lateral and axial resolutions of this imaging system were 177 and 153 μm, respectively. The ex vivo experimental results from ARFI imaging showed that a tiny region of localized sclerosis in the cornea could be distinguished. All of the obtained results demonstrate that high-resolution ARFI imaging has considerable potential for the clinical diagnosis of corneal sclerosis.","Cornea,
Phantoms,
Transducers,
Ultrasonic imaging,
Force,
Acoustics"
Equivalent Transmission Line Model With a Lumped X-Circuit for a Metalayer Made of Pairs of Planar Conductors,"We present an equivalent X-shaped lumped circuit network to be interposed in the transmission line (TL) modelling reflection and transmission through a recently proposed metalayer in planar technology. The metalayer consists of arrayed pairs of planar conductors that support two main resonant modes, corresponding to either a symmetric or an antisymmetric current distribution in the pairs. The antisymmetric mode is associated with artificial magnetism. We show that reflection and transmission features of a metalayer are accurately predicted by this simple but effective TL model. We also make a clear distinction for the first time between transmission peaks and resonance frequencies, and their relations are investigated in detail. This paper clearly defines the concept of magnetic resonance and identifies the analytical conditions corresponding to total reflection and transmission through a metalayer made of pairs of conductors supporting symmetric and antisymmetric modes.","Magnetic resonance,
Conductors,
RLC circuits,
Reflection,
Impedance,
Integrated circuit modeling"
CloudMTD: Using real options to manage technical debt in cloud-based service selection,"In cloud marketplace, cloud-based system architectures can be composed of web services, which are leased or bought off the cloud. These architectures can add value to its composition by switching and substituting its constituent services. The value-added can relate to improved Quality of Service (QoS), new revenue streams by enabling new business models, reduced operational cost and so forth. The selection and substitution decisions may introduce a technical debt, however. We specifically look at the debt of substitution decisions in support for scaling up scenarios. This debt may need to be managed, cleared and transformed to value-added. We take an option-based approach to inform the selection of candidate web services with varying debt. For every selection, we quantify the extent to which it can clear the debt and provide future options.","Web services,
Quality of service,
Investment,
Uncertainty,
Cost accounting,
Scalability"
Direct EIT Reconstructions of Complex Admittivities on a Chest-Shaped Domain in 2-D,"Electrical impedance tomography (EIT) is a medical imaging technique in which current is applied on electrodes on the surface of the body, the resulting voltage is measured, and an inverse problem is solved to recover the conductivity and/or permittivity in the interior. Images are then formed from the reconstructed conductivity and permittivity distributions. In the 2-D geometry, EIT is clinically useful for chest imaging. In this work, an implementation of a D-bar method for complex admittivities on a general 2-D domain is presented. In particular, reconstructions are computed on a chest-shaped domain for several realistic phantoms including a simulated pneumothorax, hyperinflation, and pleural effusion. The method demonstrates robustness in the presence of noise. Reconstructions from trigonometric and pairwise current injection patterns are included.","Electrodes,
Image reconstruction,
Conductivity,
Voltage measurement,
Permittivity,
Reconstruction algorithms"
Understanding Processing Overheads of Network Coding-Based Content Distribution in VANETs,"Content distribution in vehicular networks, such as multimedia file sharing and software updates, poses a great challenge due to network dynamics and high-speed mobility. In recent years, network coding has been shown to efficiently support distribution of content in such dynamic environments, thereby considerably enhancing the performance. However, the related work in the literature has mostly focused on theoretic or algorithmic aspects of network coding so far. In this paper, we provide an in-depth analysis on the implementation issues of network coding in wireless networks. In particular, we study the impact of resource constraints (namely CPU, disk, memory, and bandwidth) on the performance of network coding in the content distribution application. The contribution of this paper is twofold. First, we develop an abstract model of a general network coding process and evaluate the validity of the model via several experiments on real systems. This model enables us to find the key resource constraints that influence the network coding strategy and thus to efficiently configure network coding parameters in wireless networks. Second, we propose schemes that considerably improve the performance of network coding under resource constrained environments. We implement our overhead model in the QualNet network simulator and evaluate these schemes in a large-scale vehicular network. Our results show that the proposed schemes can significantly improve the network coding performance by reducing the coding overhead.","Network coding,
Encoding,
Peer to peer computing,
Computational modeling,
Vectors,
Vehicles,
Random access memory"
Enhancements to FPMIPv6 for improved seamless vertical handover between LTE and heterogeneous access networks,"Fast handovers for proxy mobile IPv6 (FPMIPv6) was created to reduce packet-delay that occurs during proxy mobile IPv6 (PMIPv6) handover. Based on vertical handover (VHO) experiments conducted between Long Term Evolution (LTE) and heterogeneous accesses over the evolved packet core (EPC) using FPMIPv6, it was recognized that consistently reliable seamless VHO operations were difficult to accomplish due to limitations in FPMIPv6. Noticeably, VHO performance degradation resulted from the serving network (SN) lacking information of the target network (TN) when the TN is a heterogeneous protocol domain, packet congestion and loss problems occurring on specific network gateway interfaces, and also from using long packet-forwarding paths. In this article, an enhanced FPMIPv6 technique is proposed to solve these problems and improve the VHO operation by using shorter data-paths and improved coordination of buffered packet-forwarding and TN switching, which results in a significantly reduced packet-delay.","Handover,
Mobile communication,
WiMAX,
Mobile computing,
Logic gates,
Long Term Evolution,
Wireless networks"
A novel 6T SRAM cell with asymmetrically gate underlap engineered FinFETs for enhanced read data stability and write ability,"A new FinFET memory circuit technique based on asymmetrically gate underlap engineered bitline access transistors is proposed in this paper. The strengths of the asymmetrical bitline access transistors are weakened during read operations while enhanced during write operations as the direction of current flow is reversed. With the proposed asymmetrical six-FinFET SRAM cell, the read data stability and write ability are both enhanced by up to 6.12x and 58%, respectively, without causing any area overhead as compared to the standard symmetrical six-FinFET SRAM cells in a 15nm FinFET technology. The leakage power consumption is also reduced by up to 96.5% with the proposed asymmetrical FinFET SRAM cell as compared to the standard six-FinFET SRAM cells with symmetrical bitline access transistors.",
Global trajectory tracking for a class of underactuated vehicles,"In this paper, we address the problem of trajectory tracking for a class of underactuated vehicles with full torque actuation and only one dimensional force actuation (thrust). For this class of vehicles, the desired thrust is defined by a saturated control law that achieves global asymptotic stabilization of the position tracking error. The proposed control law also assures that the third component of the angular velocity is regulated to zero. To accomplish this task we propose a hybrid controller that is designed using backstepping techniques and recent developments on synergistic Lyapunov functions. Simulations validating the results are also provided.","Vehicles,
Trajectory,
Quaternions,
Lyapunov methods,
Vectors,
Torque,
Simulation"
Feasibility Study of Optically Transparent CPW-Fed Monopole Antenna at 60-GHz ISM Bands,"This paper presents a feasibility study on an optically transparent planar monopole lozenge antenna at the 60-GHz industrial-scientific-medical (ISM) band. The feeding of this antenna is composed of a 50-
Ω
meshed coplanar waveguide. The size of the proposed antenna is around 2.3
×
2.3 mm
2
. The transparent and conductive material used to fabricate the proposed antenna is made of a gold grid layer deposited on a 0.2-mm-thick fused silica 7980 Corning substrate. The theoretical transparency equals 83% with a sheet resistance of 0.44
Ω
/sq. The simulated and measured results of the transparent monopole antenna are compared to a nontransparent (but identical) antenna. It was found that both antennas have the same performances in terms of bandwidth, radiation pattern, and gain. The measurements show the same behavior for transparent and nontransparent antennas. These results confirm the absence of ohmic and skin depth losses in the gold grid layer at 60-GHz ISM bands and provide the possibility of implementing transparent antennas with performances absolutely identical to the nontransparent ones, with the advantage of a soft visual impact.","Antennas,
Gold,
Antenna measurements,
Substrates,
Resistance,
Microstrip"
Automated classification of contact lens type in iris images,"Textured cosmetic lenses have long been known to present a problem for iris recognition. It was once believed that clear, soft contact lenses did not impact iris recognition accuracy. However, it has recently been shown that persons wearing clear, soft contact lenses experience an increased false non-match rate relative to persons not wearing contact lenses. Iris recognition systems need the ability to automatically determine if a person is (a) wearing no contact lens, (b) wearing a clear prescription lens, or (c), wearing a textured cosmetic lens. This work presents results of the first attempt that we are aware of to solve this three-class classification problem. Results show that it is possible to identify with high accuracy (96.5%) the images in which a textured cosmetic contact lens is present, but that correctly distinguishing between no lenses and soft lenses is a challenging problem.","Lenses,
Iris recognition,
Iris,
Feature extraction,
Accuracy,
Training"
Recent Advances on GPU Computing in Operations Research,"In the last decade, Graphics Processing Units(GPUs) have gained an increasing popularity as accelerators for High Performance Computing (HPC) applications. Recent GPUs are not only powerful graphics engines but also highly threaded parallel computing processors that can achieve sustainable speedup as compared with CPUs. In this context, researchers try to exploit the capability of this architecture to solve difficult problems in many domains in science and engineering. In this article, we present recent advances on GPU Computing in Operations Research. We focus in particular on Integer Programming and Linear Programming.","Graphics processing units,
Linear programming,
Instruction sets,
Computer architecture,
Programming,
Dynamic programming"
CUBIC-FIT: A High Performance and TCP CUBIC Friendly Congestion Control Algorithm,"With the recent popularity of Linux-based HTTP servers, TCP CUBIC, the default Linux congestion control algorithm, is close to the new de facto standard algorithm for the Internet congestion control. A need for new congestion control technologies for the TCP CUBIC-dominated Internet is therefore emerging. To cater to this trend, this paper proposes a novel TCP congestion control algorithm, CUBIC-FIT. Compared with TCP CUBIC and other state-of-the-art TCP algorithms, CUBIC-FIT can improve performance over a large range of network conditions and maintain graceful fairness with the widely deployed TCP CUBIC servers. Analytical and experimental studies over emulators and real networks validate the proposed algorithm and its performance.","Throughput,
Servers,
Packet loss,
Bandwidth,
Delays,
Algorithm design and analysis"
A Switching Control Strategy for the Reduction of Torque Ripple for PMSM,"This paper proposes the field-programmable gate array (FPGA) implementation of a variable structure system predictive sequential switching control strategy, as applied to a permanent magnet synchronous machine. In the case of ac motor drives, in contrast to conventional vector control where the inverter is not taken into consideration by the controller, the proposed control integrates the inverter model and the inverter states. It allows obtaining faster torque dynamics than vector control algorithms. The main design specifications are a reduced switching frequency and simple hardware implementation. A predictive sliding mode controller has been developed, designed as finite-state machine, and implemented with a FPGA. This new logic FPGA torque and speed controller has been developed, analyzed, and experimentally verified.","Switches,
Vectors,
Inverters,
Stators,
Torque,
Field programmable gate arrays"
Dense Delta-Sigma Phased Arrays,"The high cost of high-resolution phase shifters required to maintain precise control over the array beam pattern in traditional phased arrays preclude their use in a variety of emerging millimeter-wave applications. We develop a phased array architecture that obviates the need for such precise phase shifters, based on the use of sub-half-wavelength array element spacing and novel spatial domain delta-sigma processing. We characterize the performance of this architecture in terms of the array signal-to-quantization-noise ratio (SQNR) and the array power transfer efficiency, and demonstrate a tradeoff between these two metrics. As an illustrative design, we show that when constrained to two-bit phase shifters, a four-fold increase in the array density can provide a roughly 6 dB improvement in SQNR over standard design techniques, with an average efficiency loss of less than 1.5 dB with respect to a perfectly tuned ideal array. In our analysis, we account for the effects of mutual coupling, and describe a simple, practical impedance matching network for this architecture. The resulting framework allows a system designer with a given set of circuit, device, and antenna fabrication and integration technologies to choose from a spectrum of tradeoffs between array density and RF component complexity.","Phased arrays,
Quantization,
Phase shifters,
Mutual coupling,
Couplings,
Array signal processing"
The design of bug fixes,"When software engineers fix bugs, they may have several options as to how to fix those bugs. Which fix they choose has many implications, both for practitioners and researchers: What is the risk of introducing other bugs during the fix? Is the bug fix in the same code that caused the bug? Is the change fixing the cause or just covering a symptom? In this paper, we investigate alternative fixes to bugs and present an empirical study of how engineers make design choices about how to fix bugs. Based on qualitative interviews with 40 engineers working on a variety of products, data from 6 bug triage meetings, and a survey filled out by 326 engineers, we found a number of factors, many of them non-technical, that influence how bugs are fixed, such as how close to release the software is. We also discuss several implications for research and practice, including ways to make bug prediction and localization more accurate.","Interviews,
Computer bugs,
Software,
Protocols,
Data analysis,
Encoding,
Buildings"
Efficient implementation of the Riccati recursion for solving linear-quadratic control problems,"In both Active-Set (AS) and Interior-Point (IP) algorithms for Model Predictive Control (MPC), sub-problems in the form of linear-quadratic (LQ) control problems need to be solved at each iteration. The solution of these sub-problems is typically the main computational effort at each iteration. In this paper, we compare a number of solvers for an extended formulation of the LQ control problem: a Riccati recursion based solver can be considered the best choice for the general problem with dense matrices. Furthermore, we present a novel version of the Riccati solver, that makes use of the Cholesky factorization of the Pn matrices to reduce the number of flops. When combined with regularization and mixed precision, this algorithm can solve large instances of the LQ control problem up to 3 times faster than the classical Riccati solver.","Sparse matrices,
Complexity theory,
Heuristic algorithms,
Equations,
Tin,
Vectors,
Approximation methods"
Statistical analysis of BTI in the presence of process-induced voltage and temperature variations,"In nano-scale regime, there are various sources of uncertainty and unpredictability of VLSI designs such as transistor aging mainly due to Bias Temperature Instability (BTI) as well as Process-Voltage-Temperature (PVT) variations. BTI exponentially varies by temperature and the actual supply voltage seen by the transistors within the chip which are functions of leakage power. Leakage power is strongly impacted by PVT and BTI which in turn results in thermal-voltage variations. Hence, neglecting one or some of these aspects can lead to a considerable inaccuracy in the estimated BTI-induced delay degradation. However, a holistic approach to tackle all these issues and their interdependence is missing. In this paper, we develop an analytical model to predict the probability density function and covariance of temperatures and voltage droops of a die in the presence of the BTI and process variation. Based on this model, we propose a statistical method that characterizes the life-time of the circuit affected by BTI in the presence of process-induced temperature-voltage variations. We observe that for benchmark circuits, treating each aspect independently and ignoring their intrinsic interactions results in 16% over-design, translating to unnecessary yield and performance loss.","Mathematical model,
Delays,
Logic gates,
Threshold voltage,
Equations,
Transistors,
Degradation"
Spectrum Sensing Over MIMO Channels Using Generalized Likelihood Ratio Tests,"Spectrum sensing is a key function of cognitive radios and is used to determine whether a primary user is present in the channel or not. Many approaches have been proposed when both primary user and secondary user employ a single antenna. Recently several techniques have also been proposed assuming that the the secondary user employs multiple antennas. In this paper, we formulate and solve the generalized likelihood ratio test (GLRT) for spectrum sensing when both primary user transmitter and the secondary user receiver are equipped with multiple antennas. We do not assume any prior information about the channel statistics or the primary user's signal structure. Two cases are considered when the secondary user is aware of the energy of the noise and when it is not. The final test statistics derived from GLRT are based on the eigenvalues of the sample covariance matrix. Through analysis we exhibit the role of the eigenvalues in characterizing the signal+noise and noise subspaces in the received data. Simulation results are presented in terms of the receiver operating characteristics and detection probabilities for several cases of interest.","Noise,
Eigenvalues and eigenfunctions,
Sensors,
Receiving antennas,
Transmitting antennas"
Arm Stiffness During Assisted Movement After Stroke: The Influence of Visual Feedback and Training,"Spasticity and muscular hypertonus are frequently found in stroke survivors and may have a significant effect on functional impairment. These abnormal neuro-muscular properties, which are quantifiable by the net impedance of the hand, have a direct consequence on arm mechanics and are likely to produce anomalous motor paths. Literature studies quantifying limb impedance in stroke survivors have focused on multijoint static tasks and single joint movements. Despite this research, little is known about the role of sensory motor integration in post-stroke impedance modulation. The present study elucidates this role by integrating an evaluation of arm impedance into a robotically mediated therapy protocol. Our analysis had three specific objectives: 1) obtaining a reliable measure for the mechanical proprieties of the upper limb during robotic therapy; 2) investigating the effects of robot-assisted training and visual feedback on arm stiffness and viscosity; 3) determining if the stiffness measure and its relationship with either training or visual feedback depend on arm position, speed, and level of assistance. This work demonstrates that the performance improvements produced by minimally assistive robot training are associated with decreased viscosity and stiffness in stroke survivors' paretic arm and that these mechanical impedance components are partially modulated by visual feedback.","Force,
Visualization,
Training,
Impedance,
Muscles,
Robot sensing systems"
Non-asymptotic and second-order achievability bounds for source coding with side-information,We present a novel achievability bound for the Wyner-Ahlswede-Körner (WAK) problem of lossless source coding with rate-limited side-information. This bound is proved using ideas from channel simulation and channel resolvability. The bound improves on all previous non-asymptotic bounds on the error probability of the WAK problem. We also present achievable second-order coding rates by applying the multidimensional Berry-Essèen theorem to our new non-asymptotic bound.,"Error probability,
Source coding,
Educational institutions,
Decoding,
Joints"
VFT: A virtualization and fault tolerance approach for cloud computing,"Fault tolerance in cloud computing is a grand challenge problem now a days. The main fault tolerance issues in cloud computing are detection and recovery. To combat with these problems, many fault tolerance techniques have been designed to reduce the faults. In this paper, we have proposed a Virtualization and Fault Tolerance (VFT) technique to reduce the service time and to increase the system availability. A Cloud Manager (CM) module and a Decision Maker (DM) are used in our scheme to manage the virtualization, load balancing and to handle the faults. In the first step virtualization and load balancing are done and in the second step fault tolerance is achieved by redundancy, checkpointing and fault handler. VFT is mainly designed to provide reactive fault tolerance. In our proposed approach a fault handler is included in the virtualization part. Fault handler blocks the unrecoverable faulty nodes along with their virtual nodes for future requests and removes the temporary software faults from the recoverable faulty nodes and makes them available for the future requests.","Servers,
Fault tolerant systems,
Fault tolerance,
Virtualization,
Cloud computing,
Computational modeling,
Virtual machine monitors"
Semantics of Directly Manipulating Spatializations,"When high-dimensional data is visualized in a 2D plane by using parametric projection algorithms, users may wish to manipulate the layout of the data points to better reflect their domain knowledge or to explore alternative structures. However, few users are well-versed in the algorithms behind the visualizations, making parameter tweaking more of a guessing game than a series of decisive interactions. Translating user interactions into algorithmic input is a key component of Visual to Parametric Interaction (V2PI) [13]. Instead of adjusting parameters, users directly move data points on the screen, which then updates the underlying statistical model. However, we have found that some data points that are not moved by the user are just as important in the interactions as the data points that are moved. Users frequently move some data points with respect to some other 'unmoved' data points that they consider as spatially contextual. However, in current V2PI interactions, these points are not explicitly identified when directly manipulating the moved points. We design a richer set of interactions that makes this context more explicit, and a new algorithm and sophisticated weighting scheme that incorporates the importance of these unmoved data points into V2PI.","Data visualization,
Cognitive science,
Mathematical model,
Algorithm design and analysis,
Semantics"
Synchronization Probability in Large Complex Networks,"In a generalized framework, where multistate and interstate linkages are allowed, the synchronization of oscillators in random networks is investigated. A sufficient condition for the stability of synchronization is derived, which explicitly relates the network structure and the local and coupling dynamics to synchronization stability. This condition is then translated into a lower bound on the probability of stability of synchrony for large Erdös-Rényi and Newman-Watts small-world networks.","Synchronization,
Stability criteria,
Eigenvalues and eigenfunctions,
Couplings,
Circuit stability,
Numerical stability"
Using speech recognition for real-time captioning and lecture transcription in the classroom,"Speech recognition (SR) technologies were evaluated in different classroom environments to assist students to automatically convert oral lectures into text. Two distinct methods of SR-mediated lecture acquisition (SR-mLA), real-time captioning (RTC) and postlecture transcription (PLT), were evaluated in situ life and social sciences lecture courses employing typical classroom equipment. Both methods were compared according to technical feasibility and reliability of classroom implementation, instructors' experiences, word recognition accuracy, and student class performance. RTC provided near-instantaneous display of the instructor's speech for students during class. PLT employed a user-independent SR algorithm to optimally generate multimedia class notes with synchronized lecture transcripts, instructor audio, and class PowerPoint slides for students to access online after class. PLT resulted in greater word recognition accuracy than RTC. During a science course, students were more likely to take optional online quizzes and received higher quiz scores with PLT than when multimedia class notes were unavailable. Overall class grades were also higher when multimedia class notes were available. The potential benefits of SR-mLA for students who have difficulty taking notes accurately and independently were discussed, particularly for nonnative English speakers and students with disabilities. Field-tested best practices for optimizing SR accuracy for both SR-mLA methods were outlined.","Real-time systems,
Speech recognition,
Multimedia communication,
Education courses,
Electronic learning"
Adaptive traffic management for secure and efficient emergency services in smart cities,"Rapid increase in number of vehicles on the roads as well as growing size of cities have led to a plethora of challenges for road traffic management authorities such as traffic congestion, accidents and air pollution. The work presented in this paper focuses on the particular problem of traffic management for emergency services, for which a delay of few minutes may cause human lives risks as well as financial losses. The goal is to reduce the latency of emergency services for vehicles such as ambulances and police cars, with minimum unnecessary disruption to the regular traffic, and preventing potential misuses. To this end, we propose to design a framework in which the Traffic Management System (TMS) may adapt by dynamically adjusting traffic lights, changing related driving policies, recommending behavior change to drivers, and applying essential security controls. The choice of an adaptation depends on the emergency severity level announced by the emergency vehicle(s). The severity level may need to be verified by corresponding authorities to preserve security measures. We discuss the details of our proposed framework and the potential challenges in the paper.","Vehicles,
Security,
Roads,
Emergency services,
Cities and towns,
Adaptive systems,
Delays"
On-board dual-stereo-vision for autonomous quadrotor navigation,"We present a quadrotor Micro Aerial Vehicle (MAV) capable of autonomous indoor navigation. The MAV is equipped with four cameras arranged in two stereo configurations. One camera pair is facing forward and serves as input for a reduced stereo SLAM system. The other camera pair is facing downwards and is used for ground plane detection and tracking. All processing, including sparse stereo matching, is run on-board in real-time and at high processing rates. We demonstrate the capabilities of this MAV design in several flight experiments. Our MAV is able to recover from pose estimation errors and can cope with processing failures for one camera pair. We show that by using two camera pairs instead of one, we are able to significantly increase navigation accuracy and robustness.","Cameras,
Simultaneous localization and mapping,
Computers,
Sensor fusion,
Visualization,
Current measurement,
Kalman filters"
B-Planner: Night bus route planning using large-scale taxi GPS traces,"Taxi GPS traces provide us with rich information about the human mobility pattern in modern cities. Instead of designing the bus route based on inaccurate human survey regarding people's mobility pattern, we intend to address the night-bus route planning issue by leveraging taxi GPS traces. In this paper, we propose a two-phase approach based on the crowd-sourced GPS data for night-bus route planning. In the first phase, we develop a process to cluster “hot” areas with dense passenger pick-up/drop-off, and then propose effective methods to split big “hot” areas into clusters and identify a location in each cluster as a candidate bus stop. In the second phase, given the bus route origin, destination, candidate bus stops as well as bus operation time constraints, we derive several effective rules to build bus routing graph and prune the invalid stops and edges iteratively. We further develop two heuristic algorithms to automatically generate candidate bus routes, and finally we select the best route which expects the maximum number of passengers under the given conditions. To validate the effectiveness of the proposed approach, extensive empirical studies are performed on a real-world taxi GPS data set which contains more than 1.57 million passenger delivery trips, generated by 7,600 taxis for a month in Hangzhou, China.","Global Positioning System,
Cities and towns,
Routing,
Planning,
Time factors,
Buildings,
Merging"
Closed-form solutions within sparsifying transform learning,"Many applications in signal processing benefit from the sparsity of signals in a certain transform domain or dictionary. Synthesis sparsifying dictionaries that are directly adapted to data have been popular in applications such as image denoising, and medical image reconstruction. In this work, we focus specifically on the learning of orthonormal as well as well-conditioned square sparsifying transforms. The proposed algorithms alternate between a sparse coding step, and a transform update step. We derive the exact analytical solution for each of these steps. Adaptive well-conditioned transforms are shown to perform better in applications compared to adapted orthonormal ones. Moreover, the closed form solution for the transform update step achieves the global minimum in that step, and also provides speedups over iterative solutions involving conjugate gradients. We also present examples illustrating the promising performance and significant speed-ups of transform learning over synthesis K-SVD in image denoising.","Transforms,
Dictionaries,
Noise reduction,
Analytical models,
PSNR,
Closed-form solutions,
Noise measurement"
A Novel Technology for Motion Capture Using Passive UHF RFID Tags,"Although there are several existing methods for human motion capture, they all have important limitations and hence there is the need to explore fundamentally new approaches. Here, we present a method based on a radio frequency identification (RFID) system with passive ultra high frequency (UHF) tags placed on the body segments whose kinematics is to be captured. Dual polarized antennas are used to estimate the inclination of each tag based on the polarization of the tag responses. The method has been validated experimentally for the shank and thigh in the sagittal plane during treadmill walking. The reference segment angles for the validation were obtained by an optoelectronic system. Although the method is in its initial phase of development, the results of the validation are promising and show that the movement information can be extracted from the RFID response signals.","Radiofrequency identification,
Antennas,
Thigh,
Motion segmentation,
Legged locomotion,
Humans,
Joints"
GPU-Based Real-Time Volumetric Ultrasound Image Reconstruction for a Ring Array,"Synthetic phased array (SPA) beamforming with Hadamard coding and aperture weighting is an optimal option for real-time volumetric imaging with a ring array, a particularly attractive geometry in intracardiac and intravascular applications. However, the imaging frame rate of this method is limited by the immense computational load required in synthetic beamforming. For fast imaging with a ring array, we developed graphics processing unit (GPU)-based, real-time image reconstruction software that exploits massive data-level parallelism in beamforming operations. The GPU-based software reconstructs and displays three cross-sectional images at 45 frames per second (fps). This frame rate is 4.5 times higher than that for our previously-developed multi-core CPU-based software. In an alternative imaging mode, it shows one B-mode image rotating about the axis and its maximum intensity projection, processed at a rate of 104 fps . This paper describes the image reconstruction procedure on the GPU platform and presents the experimental images obtained using this software.",
Using maximum consistency context for multiple target association in wide area traffic scenes,"Tracking multiple vehicles in wide area traffic scenes is challenging due to high target density, severe similar target ambiguity, and low frame rate. In this paper, we propose a novel spatio-temporal context model, named maximum consistency context (MCC), to leverage the discriminative power and robustness in the scenario. For a candidate association, its MCC is defined as the most consistent association in its neighborhood. Such a maximum selection picks the reliable neighborhood context information while filtering out noisy distraction. We tested the proposed context modeling on multi-target tracking using three challenging wide area motion sequences. Both quantitative and qualitative results show clearly the effectiveness of MCC, in comparison with algorithms that use no context and standard spatial context respectively.",
Hybrid Feature-Based Diffeomorphic Registration for Tumor Tracking in 2-D Liver Ultrasound Images,"Real-time ultrasound image acquisition is a pivotal resource in the medical community, in spite of its limited image quality. This poses challenges to image registration methods, particularly to those driven by intensity values. We address these difficulties in a novel diffeomorphic registration technique for tumor tracking in series of 2-D liver ultrasound. Our method has two main characteristics: 1) each voxel is described by three image features: intensity, local phase, and phase congruency; 2) we compute a set of forces from either local information (Demons-type of forces), or spatial correspondences supplied by a block-matching scheme, from each image feature. A family of update deformation fields which are defined by these forces, and inform upon the local or regional contribution of each image feature are then composed to form the final transformation. The method is diffeomorphic, which ensures the invertibility of deformations. The qualitative and quantitative results yielded by both synthetic and real clinical data show the suitability of our method for the application at hand.","Tumors,
Liver,
Vectors,
Robustness,
Kernel,
Ultrasonic imaging,
Target tracking"
Mixed orthogonal frequency coded SAW RFID tags,"Orthogonal frequency coded (OFC) SAW radio-frequency identification (RFID) tags are currently being explored as a multi-sensor platform because of their passive spread-spectrum operation, low loss, and resilience in harsh environments. Ongoing research continues to search for robust device embodiments that increase the number of identifiable codes, in the presence of intersymbol interference, while maintaining reasonable device lengths. This paper presents a technique that shortens the SAW response length while preserving code diversity and bandwidth by utilizing a multi-track SAW configuration. These new devices allow the time response of multiple OFC chips to overlap and yield a mixed-frequency chip having the sum of the chip bandwidths but shorter overall time response. The theoretical development is presented and examples are discussed for these new mixed orthogonal frequency coded (MOFC) SAW devices. Experimental results for MOFC sensors, fabricated on YZ-LiNbO3, with a 7% fractional bandwidth and five chip frequencies in three cells, provide a good contrast to similar OFC designs. Experimental results are presented for the simultaneous operation of eight wireless temperature sensors-four OFC and four MOFC-in a 915-MHz wireless correlator receiver system, highlighting the ability of these devices to operate in the same system.","Time frequency analysis,
Bandwidth,
Temperature sensors,
Sensor systems,
Transducers"
JST: An automatic test generation tool for industrial Java applications with strings,"In this paper we present JST, a tool that automatically generates a high coverage test suite for industrial strength Java applications. This tool uses a numeric-string hybrid symbolic execution engine at its core which is based on the Symbolic Java PathFinder platform. However, in order to make the tool applicable to industrial applications the existing generic platform had to be enhanced in numerous ways that we describe in this paper. The JST tool consists of newly supported essential Java library components and widely used data structures; novel solving techniques for string constraints, regular expressions, and their interactions with integer and floating point numbers; and key optimizations that make the tool more efficient. We present a methodology to seamlessly integrate the features mentioned above to make the tool scalable to industrial applications that are beyond the reach of the original platform in terms of both applicability and performance. We also present extensive experimental data to illustrate the effectiveness of our tool.",
Hybrid pricing for TV white space database,"According to the recent rulings of the Federal Communications Commission (FCC), TV white spaces (TVWS) can now be accessed by secondary users (SUs) after a list of vacant TV channels is obtained via a geo-location database. Proper business models are essential for database operators to manage the cost of maintaining geo-location databases. Database access can be simultaneously priced under two different schemes: the registration scheme and the service plan scheme. In the registration scheme, the database reserves part of the TV bandwidth for registered White Space Devices (WSD) in a soft-license way. In the service plan scheme, WSDs are charged according to their queries. In this paper, we investigate the business model for the TVWS database under a hybrid pricing scheme. We consider the scenario where a database operator employs both the registration scheme and the service plan scheme to serve the SUs. The SUs' choices of different pricing schemes are modeled as a non-cooperative game and we derive distributed algorithms to achieve the Nash Equilibrium (NE). Considering the NE of the SUs, the database operator optimally determines the pricing parameters for both pricing schemes in terms of bandwidth reservation, registration fee and query plans.",
Comparative Study of Uniform Versus Supersteep Retrograde MOSFET Channel Doping and Implications for 6-T SRAM Yield,"The benefit of supersteep retrograde (SSR) channel doping for suppressing short-channel effects in planar bulk MOSFET performance is studied via technology computer-aided design simulation of devices with gate length Lg = 28 nm. It is found that drain-induced barrier lowering is reduced by more than 40%, and variation in saturation threshold voltage (σ VT,Sat), caused by random dopant fluctuation, is reduced by ~50%, with SSR channel doping. However, degraded drive current is observed for SSR channel doping due to enhanced body effect. Estimations of six-transistor static random access memory (SRAM) cell yield indicate that 33% reduction in the minimum operating voltage (VMIN,SRAM) can be achieved with SSR channel doping.",
2D Meets 4G: G-Quadruplexes in RNA Secondary Structure Prediction,"G-quadruplexes are abundant locally stable structural elements in nucleic acids. The combinatorial theory of RNA structures and the dynamic programming algorithms for RNA secondary structure prediction are extended here to incorporate G-quadruplexes using a simple but plausible energy model. With preliminary energy parameters, we find that the overwhelming majority of putative quadruplex-forming sequences in the human genome are likely to fold into canonical secondary structures instead. Stable G-quadruplexes are strongly enriched, however, in the 5Ê1UTR of protein coding mRNAs.","RNA,
Shape,
Bioinformatics,
Temperature measurement,
Computational biology,
Humans,
DNA"
Rhetorical robots: Making robots more effective speakers using linguistic cues of expertise,"Robots hold great promise as informational assistants such as museum guides, information booth attendants, concierges, shopkeepers, and more. In such positions, people will expect them to be experts on their area of specialty. Not only will robots need to be experts, but they will also need to communicate their expertise effectively in order to raise trust and compliance with the information that they provide. This paper draws upon literature in psychology and linguistics to examine cues in speech that would help robots not only to provide expert knowledge, but also to deliver this knowledge effectively. To test the effectiveness of these cues, we conducted an experiment in which participants created a plan to tour a fictional city based on suggestions by two robots. We manipulated the landmark descriptions along two dimensions of expertise: practical knowledge and rhetorical ability. We then measured which locations the participants chose to include in the tour based on their descriptions. Our results showed that participants were strongly influenced by both practical knowledge and rhetorical ability; they included more landmarks described using expert linguistic cues than those described using simple facts. Even when the overall level of practical knowledge was high, an increase in rhetorical ability resulted in significant improvements. These results have implications for the development of effective dialogue strategies for informational robots.",
Vulnerability Scrying Method for Software Vulnerability Discovery Prediction Without a Vulnerability Database,"Predicting software vulnerability discovery trends can help improve secure deployment of software applications and facilitate backup provisioning, disaster recovery, diversity planning, and maintenance scheduling. Vulnerability discovery models (VDMs) have been studied in the literature as a means to capture the underlying stochastic process. Based on the VDMs, a few vulnerability prediction schemes have been proposed. Unfortunately, all these schemes suffer from the same weaknesses: they require a large amount of historical vulnerability data from a database (hence they are not applicable to a newly released software application), their precision depends on the amount of training data, and they have significant amount of error in their estimates. In this work, we propose vulnerability scrying, a new paradigm for vulnerability discovery prediction based on code properties. Using compiler-based static analysis of a codebase, we extract code properties such as code complexity (cyclomatic complexity), and more importantly code quality (compliance with secure coding rules), from the source code of a software application. Then we propose a stochastic model which uses code properties as its parameters to predict vulnerability discovery. We have studied the impact of code properties on the vulnerability discovery trends by performing static analysis on the source code of four real-world software applications. We have used our scheme to predict vulnerability discovery in three other software applications. The results show that even though we use no historical data in our prediction, vulnerability scrying can predict vulnerability discovery with better precision and less divergence over time.","Software,
Predictive models,
Mathematical model,
Security,
Data models,
History,
Databases"
WiFi-BA: Choosing arbitration over backoff in high speed multicarrier wireless networks,"Advancements in wireless communication techniques have increased the wireless physical layer (PHY) data rates by hundreds of times in a dozen years. The high PHY data rates, however, have not been translated to commensurate throughput gains due to overheads incurred by medium access control (MAC) and PHY convergence procedure. At high PHY data rates, the time used for collision avoidance (CA) at MAC layer and the time used for PHY convergence procedure can easily exceed the time used for transmission of an actual data frame. Recent work intends to reduce the CA overhead by reducing the backoff time slot size. However, the method introduces more collisions in presence of hidden terminals because the tiny backoff slots can no longer de-synchronize hidden terminals, leading to persistent collisions among hidden terminals. As collision detection (CD) in wireless communication became feasible recently, some protocols migrate random backoff from the time domain to the frequency domain, but they fail to address the introduced high collision probability. We investigate the practical issues of CD in the frequency domain and introduce a binary mapping scheme to reduce the collision probability. Based on the binary mapping, a bitwise arbitration (BA) mechanism is devised to grant only one transmitter the permission to initiate data transmission in a contention. With the low collision probability achieved in a short bounded arbitration phase, the throughput is significantly improved by our proposed WiFi-BA. Because collisions are unlikely to happen, unfairness caused by capture effect of radios is also reduced. The bitwise arbitration mechanism can further be set to let high priority messages get through unimpeded, making WiFi-BA suitable for real time prioritized communication. We validate the effectiveness of WiFi-BA through implementation on FPGA of USRP E110. Performance evaluation demonstrates that WiFi-BA is more efficient than current Wi-Fi solutions.","Data communication,
OFDM,
Frequency-domain analysis,
Binary codes,
Wireless communication,
IEEE 802.11 Standards,
Interference"
Early termination for TZSearch in HEVC Motion Estimation,"The TZSearch algorithm was adopted in the high efficiency video coding reference software HM as a fast Motion Estimation (ME) algorithm for its excellent performance in reducing ME time and maintaining a comparable Rate Distortion (RD) performance. However, the multiple initial search point decision and the hybrid block matching search contribute a relatively high computational complexity to TZSearch. In this paper, based on the statistical analysis of the probability of median predictor to be selected as the final best point in the large Coding Units (CUs) (64×64, 32×32) and small CUs (16×16, 8×8) as well as the center-biased characteristic of the final best search point in ME process, we propose two early terminations for TZSearch. Experimental results show that the proposed early terminations can achieve 38.96% encoding time saving, while the RD performance degradation is quite acceptable.",
"GaN-Based
S
0
-Wave Sensors on Silicon for Chemical and Biological Sensing in Liquid Environments","In this paper, we successfully developed Lamb-wave sensors in a two-port delay line topology with suspending GaN thin films on silicon substrates. The liquid insusceptibility of the lowest order symmetric mode (S0) Lamb wave was experimentally investigated, and the relative frequency shift to water loading of the two-port S0-wave sensors was found to be as small as 0.12%. Our GaN-on-Si sensors, exhibiting a high mass sensitivity (272 cm2/g) and a sharp signal response at a low concentration (1 μg/mL) of anti-bovine serum albumin, were demonstrated to be suitable for chemical and biological sensing in liquid environments. In addition, the small size of the sensors and their potential to be integrated with a wide range of GaN-based devices allow for a robust, low-cost miniature sensing system to be manufactured with GaN-on-Si substrates.",
Subglottal Impedance-Based Inverse Filtering of Voiced Sounds Using Neck Surface Acceleration,"A model-based inverse filtering scheme is proposed for an accurate, non-invasive estimation of the aerodynamic source of voiced sounds at the glottis. The approach, referred to as subglottal impedance-based inverse filtering (IBIF), takes as input the signal from a lightweight accelerometer placed on the skin over the extrathoracic trachea and yields estimates of glottal airflow and its time derivative, offering important advantages over traditional methods that deal with the supraglottal vocal tract. The proposed scheme is based on mechano-acoustic impedance representations from a physiologically-based transmission line model and a lumped skin surface representation. A subject-specific calibration protocol is used to account for individual adjustments of subglottal impedance parameters and mechanical properties of the skin. Preliminary results for sustained vowels with various voice qualities show that the subglottal IBIF scheme yields comparable estimates with respect to current aerodynamics-based methods of clinical vocal assessment. A mean absolute error of less than 10% was observed for two glottal airflow measures-maximum flow declination rate and amplitude of the modulation component-that have been associated with the pathophysiology of some common voice disorders caused by faulty and/or abusive patterns of vocal behavior (i.e., vocal hyper-function). The proposed method further advances the ambulatory assessment of vocal function based on the neck acceleration signal, that previously have been limited to the estimation of phonation duration, loudness, and pitch. Subglottal IBIF is also suitable for other ambulatory applications in speech communication, in which further evaluation is underway.","Skin,
Neck,
Impedance,
Surface impedance,
Accelerometers,
Acceleration,
Atmospheric modeling"
Frequency-Multiplying Optoelectronic Oscillator With a Tunable Multiplication Factor,"A frequency-multiplying optoelectronic oscillator (OEO) with a tunable multiplication factor to generate a frequency-quadrupled, sextupled, or octupled microwave signal without using an optical filter is proposed and experimentally demonstrated, for the first time to the best of our knowledge. In the proposed OEO, a polarization modulator (PolM), a polarization controller (PC), and an optical polarizer (Pol) function jointly as a Mach-Zehnder modulator (MZM). Microwave oscillation is achieved in the OEO by feedbacking the intensity-modulated signal to the PolM after photodetection, and the oscillation frequency is determined by the center frequency of an electrical bandpass filter (EBPF) in the loop. A frequency-multiplied microwave signal is generated by a joint use of the PolM and a second modulator to generate two sidebands at the ±second, ±third, or ±fourth orders with the sidebands at other orders fully suppressed. By beating the two sidebands at a second photodetector (PD), a frequency-quadrupled, sextupled, or octupled microwave signal is generated. An experiment is performed. A fundamental microwave signal at 9.957 GHz is generated in the OEO loop, which is multiplied to generate a frequency-quadrupled, sextupled, or octupled microwave signal at 39.828, 59.742, or 79.656 GHz, respectively. The phase-noise performance of the frequency-multiplying microwave signal is also investigated.","Amplitude modulation,
Microwave oscillators,
Microwave theory and techniques,
Frequency modulation,
Optical polarization,
Optical modulation"
"Navigating Central Path with Electrical Flows: From Flows to Matchings, and Back","We present an Õ(m10/7) = Õ(m1.43)-time1 algorithm for the maximum s-t flow and the minimum s-t cut problems in directed graphs with unit capacities. This is the first improvement over the sparse-graph case of the long-standing O(m min{√m, n2/3}) running time bound due to Even and Tarjan [16]. By well-known reductions, this also establishes an Õ(m107)-time algorithm for the maximum-cardinality bipartite matching problem. That, in turn, gives an improvement over the celebrated O(m√n) running time bound of Hopcroft and Karp [25] whenever the input graph is sufficiently sparse. At a very high level, our results stem from acquiring a deeper understanding of interior-point methods - a powerful tool in convex optimization - in the context of flow problems, as well as, utilizing certain interplay between maximum flows and bipartite matchings.","Electric potential,
Vectors,
Approximation algorithms,
Context,
Erbium,
Linear systems,
Laplace equations"
Variable switching frequency PWM strategy for inverter switching loss and system noise reduction in electric/hybrid vehicle motor drives,"In order to reduce the inverter switching loss and system noise of electric vehicle (EV) and hybrid electric vehicle (HEV) motor drives operating in high output torque region, while preventing over-heating and demagnetization of the electric motor, this paper proposes variable switching frequency PWM (VSFPWM) strategies based on on-line prediction of current ripple RMS value for two typical motor drive systems of EV/HEV. First, the instantaneous output current ripple of three-phase inverter with SVPWM is analyzed in the time-domain. Then the current ripple prediction based VSFPWM strategies are proposed for both traction motor drive topologies to meet the current ripple RMS value requirement. Compared with constant switching frequency PWM (CSFPWM) method, the inverter switching loss and noise reduction capabilities of the proposed VSFPWM methods are analyzed. The effectiveness of the proposed methods is verified by both simulation and experiments.",
GKAR: A Novel Geographic K-anycast Routing for Wireless Sensor Networks,"To efficiently archive and query data in wireless sensor networks (WSNs), distributed storage systems, and multisink schemes have been proposed recently. However, such distributed access cannot be fully supported and exploited by existing routing protocols in a large-scale WSN. In this paper, we will address this challenging issue and propose a distributed geographic K-anycast routing (GKAR) protocol for WSNs, which can efficiently route data from a source sensor to any K destinations (e.g., storage nodes or sinks). To guarantee K-delivery, an iterative approach is adopted in GKAR where in each round, GKAR will determine not only the next hops at each node, but also a set of potential destinations for every next hop node to reach. Efficient algorithms are designed to determine the selection of the next hops and destination set division at each intermediate node. We analyze the complexity of GKAR in each round and we also theoretically analyze the expected number of rounds required to guarantee K-delivery. Simulation results demonstrate the superiority of the GKAP scheme in reducing the total duration and the communication overhead for finding K destinations, by comparing with the existing schemes, e.g., K 1-anycast [10].",
Measuring architecture quality by structure plus history analysis,"This case study combines known software structure and revision history analysis techniques, in known and new ways, to predict bug-related change frequency, and uncover architecture-related risks in an agile industrial software development project. We applied a suite of structure and history measures and statistically analyzed the correlations between them. We detected architecture issues by identifying outliers in the distributions of measured values and investigating the architectural significance of the associated classes. We used a clustering method to identify sets of files that often change together without being structurally close together, investigating whether architecture issues were among the root causes. The development team confirmed that the identified clusters reflected significant architectural violations, unstable key interfaces, and important undocumented assumptions shared between modules. The combined structure diagrams and history data justified a refactoring proposal that was accepted by the project manager and implemented.","Computer architecture,
Correlation,
Computer bugs,
History,
Software,
Size measurement,
Complexity theory"
"Development of a Semiempirical Compact Model for DC/AC Cell Operation of
HfO
x
-Based ReRAMs","A semiempirical model that can simulate dc and pulse (ac) characteristics of filament-type HfOx-based resistance change random access memory (ReRAM) devices has been developed. Time-dependent device characteristics, because of the dynamic change in the filament size, were emulated using a modified ion migration model. This model describes the difference between SET and RESET operations using a current crowding effect This model is a semiempirical model that can simultaneously match both dc and ac characteristics of HfOx-based ReRAM devices.","Integrated circuit modeling,
Resistance,
Hafnium compounds,
Switches,
SPICE,
Data models,
Materials"
A Printed Beam-Shifting Slab Designed Using Tensor Transmission-Line Metamaterials,"We present the design and implementation of a beam-shifting slab (a transformation electromagnetics device) using tensor transmission-line metamaterials. A beam-shifting slab is an anisotropic, homogeneous and reflectionless slab which laterally displaces the electromagnetic field transmitted through it. The experimental beam-shifting slab consists of printed metamaterial unit cells exhibiting anisotropic effective material parameters, while the surrounding medium consists of printed isotropic unit cells. The measured and simulated field patterns within the beam-shifting slab and the surrounding media are compared and show excellent agreement. Simulation and experimental results demonstrate that radiation from a cylindrical source is shifted upward by 5.28 unit cells due to the presence of the beam-shifting slab. Furthermore, the wide-band frequency response of the slab is experimentally studied. The reported experimental results verify the theory behind tensor transmission-line metamaterials and demonstrate their utility in the design of transformation electromagnetics devices at microwave frequencies.","Slabs,
Metamaterials,
Transmission lines,
Tensile stress,
Electromagnetics,
Integrated circuit modeling"
Top-k string similarity search with edit-distance constraints,"String similarity search is a fundamental operation in many areas, such as data cleaning, information retrieval, and bioinformatics. In this paper we study the problem of top-k string similarity search with edit-distance constraints, which, given a collection of strings and a query string, returns the top-k strings with the smallest edit distances to the query string. Existing methods usually try different edit-distance thresholds and select an appropriate threshold to find top-k answers. However it is rather expensive to select an appropriate threshold. To address this problem, we propose a progressive framework by improving the traditional dynamic-programming algorithm to compute edit distance. We prune unnecessary entries in the dynamic-programming matrix and only compute those pivotal entries. We extend our techniques to support top-k similarity search. We develop a range-based method by grouping the pivotal entries to avoid duplicated computations. Experimental results show that our method achieves high performance, and significantly outperforms state-of-the-art approaches on real-world datasets.","Search problems,
Indexes,
Time complexity,
Cleaning,
Bioinformatics"
Quality Metrics for High Order Meshes: Analysis of the Mechanical Simulation of the Heart Beat,"The quality of a computational mesh is an important characteristic for stable and accurate simulations. Quality depends on the regularity of the initial mesh, and in mechanical simulations it evolves in time, with deformations causing changes in volume and distortion of mesh elements. Mesh quality metrics are therefore relevant for both mesh personalization and the monitoring of the simulation process. This work evaluates the significance, in meshes with high order interpolation, of four quality metrics described in the literature, applying them to analyse the stability of the simulation of the heart beat. It also investigates how image registration and mesh warping parameters affect the quality and stability of meshes. Jacobian-based metrics outperformed or matched the results of coarse geometrical metrics of aspect ratio or orthogonality, although they are more expensive computationally. The stability of simulations of a complete heart cycle was best predicted with a specificity of 61%, sensitivity of 85%, and only nominal differences were found changing the intra-element and per-element combination of quality values. A compromise between fitting accuracy and mesh stability and quality was found. Generic geometrical quality metrics have a limited success predicting stability, and an analysis of the simulation problem may be required for an optimal definition of quality.","Measurement,
Computational modeling,
Jacobian matrices,
Accuracy,
Stability criteria,
Mathematical model"
Multisample aCGH Data Analysis via Total Variation and Spectral Regularization,"DNA copy number variation (CNV) accounts for a large proportion of genetic variation. One commonly used approach to detecting CNVs is array-based comparative genomic hybridization (aCGH). Although many methods have been proposed to analyze aCGH data, it is not clear how to combine information from multiple samples to improve CNV detection. In this paper, we propose to use a matrix to approximate the multisample aCGH data and minimize the total variation of each sample as well as the nuclear norm of the whole matrix. In this way, we can make use of the smoothness property of each sample and the correlation among multiple samples simultaneously in a convex optimization framework. We also developed an efficient and scalable algorithm to handle large-scale data. Experiments demonstrate that the proposed method outperforms the state-of-the-art techniques under a wide range of scenarios and it is capable of processing large data sets with millions of probes.","Spectral analysis,
Optimization,
Convex optimization"
Assessing Spinal Loading Using the Kinect Depth Sensor: A Feasibility Study,"We propose to use the Microsoft Kinect depth sensor for assessing spinal loading, and present an initial study on a public action database with 20 actions. It is built on the recent success on human skeleton extraction with depth sensor, which has been coded into the Kinect software development kit. This letter is an essential step toward a systematic evaluation in future.","Skeleton,
Loading,
Biomechanics,
Biomedical equipment,
Bones"
Objective Assessment of Sonographic: Quality II Acquisition Information Spectrum,"This paper describes a task-based, information-theoretic approach to the assessment of image quality in diagnostic sonography. We expand the Kullback-Leibler divergence metric J, which quantifies the diagnostic information contained within recorded radio-frequency echo signals, into a spatial-frequency integral comprised of two spectral components: one describes patient features for low-contrast diagnostic tasks and the other describes instrumentation properties. The latter quantity is the acquisition information spectrum (AIS), which measures the density of object information that an imaging system is able to transfer to the echo data at each spatial frequency. AIS is derived based on unique properties of acoustic scattering in tissues that generate object contrast. Predictions made by the J integral expression were validated through Monte Carlo studies using echo-signal data from simulated lesions. Our analysis predicts the diagnostic performance of any sonographic system at specific diagnostic tasks based on engineering properties of the instrument that constitute image quality.","Instruments,
Observers,
Noise,
Covariance matrix,
Imaging,
Lesions,
Vectors"
Intelligent Control of Ventilation System for Energy-Efficient Buildings With {\rm CO}_{2} Predictive Model,"In this paper, an intelligent control strategy for ventilation systems in energy-efficient buildings is proposed. The design goal of the intelligent controller is to determine the optimal ventilation rate efficiently and accurately by maintaining the indoor concentration in the comfort zone with a reduced amount of energy consumption. In this study, the concentration is used as the indicator of human comfort in terms of indoor air quality. In addition, a predictive model is utilized to forecast the indoor concentration based on the occupancy pattern of buildings. Due to the high non-linearity of the model, particle swarm optimization (PSO) is applied to derive the optimal ventilation rate. Fuzzy technique is used to represent the relationship between the ventilation rate and the corresponding power consumption for mechanical ventilation systems. As compared with the traditional ON/OFF or fixed ventilation control scheme, the performance of the proposed intelligent control system has demonstrated its advantage in energy savings. Three case studies are analyzed in different situations and using different input parameters. The corresponding simulation results confirm the viability of the proposed intelligent control strategy for ventilation systems.","Ventilation,
Buildings,
Intelligent control,
Predictive models,
Optimization,
Particle swarm optimization"
Distance Transform-Based Skeleton Extraction and Its Applications in Sensor Networks,"We study the problem of skeleton extraction for large-scale sensor networks with reliance purely on connectivity information. Existing efforts in this line highly depend on the boundary detection algorithms, which are used to extract accurate boundary nodes. One challenge is that in practical this could limit the applicability of the boundary detection algorithms. For instance, in low node density networks where boundary detection algorithms do not work well, the extracted boundary nodes are often incomplete. This paper brings a new view to skeleton extraction from a distance transform perspective, bridging the distance transform of the network and the incomplete boundaries. As such, we propose a distributed and scalable algorithm for skeleton extraction, called DIST, based on DIStance Transform, while incurring low communication overhead. The proposed algorithm does not require that the boundaries are complete or accurate, which makes the proposed algorithm more practical in applications. First, we compute the distance transform of the network. Specifically, the distance (hop count) of each node to the boundaries of a sensor network is estimated. The node map consisting of the distance values is considered as the distance transform (the distance map). The distance map is then used to identify skeleton nodes. Next, skeleton arcs are generated by controlled flooding within the identified skeleton nodes, thereby connecting these skeleton arcs, to extract a coarse skeleton. Finally, we refine the coarse skeleton by building shortest path trees followed by a prune phase. The obtained skeleton is robust to boundary noise or shape variations. Besides, we present two specific applications that benefit from the extracted skeleton: identifying complete boundaries and shape segmentation. First, with the extracted skeleton using DIST, we propose to identify more boundary nodes to form a meaningful boundary curve. Second, the utilization of the derived skeleton to segment the network into approximately convex pieces has been shown to be effective.","Skeleton,
Transforms,
Joining processes,
Wireless sensor networks,
Radiation detectors,
Detection algorithms,
Noise"
Fault location and isolation using multi agent systems in power distribution systems with distributed generation sources,"This paper presents a Multi Agent System (MAS) design with distributed intelligence for fault location and isolation in power distribution systems with the presence of Distributed Generation Sources (DGS). In the proposed MAS, agents all over the feeder communicate with their neighbors and use the local differential current information to locate the faulty zone and isolate the fault. Agents update their local knowledge by exchanging their voltage and current phasor data with their neighbors and monitoring the local current. The distributed generation penetration is considered to be up to 50 percent. The multi-agent models are simulated in Matlab® Simulink using user defined s-functions and the power system is modeled using the Simulink Simpower toolbox. The proposed method has been tested on a model of an existing Mon Power company circuit. Both faulted zone and fault type have been successfully identified.","Circuit faults,
Mathematical model,
Fault location,
Software packages,
Power distribution"
Balancing Performance and Fairness in P2P Live Video Systems,"Measurement studies of popular peer-to-peer (P2P) live video systems reveal that there exists extreme unfairness among peers in the swarm. Such kind of unfairness will provide disincentives to altruistic super peers and encourage free riding behavior in the system. It is essential for video service providers to take fairness into consideration when designing their systems. In this paper, we develop a simple model of P2P live video systems to understand the fairness problem from a theoretic perspective. We identify the fundamental tradeoff between fairness and performance, and propose a semidistributed algorithm based on the subgradient method to tune the P2P live video system toward optimal fairness while still maintaining the targeted universal streaming rate. We also conduct extensive trace-driven simulations to validate the effectiveness of our proposed algorithm. The simulation results show that our algorithm can guide the system toward optimal fairness quickly without degrading streaming performance at the same time.",
EEG-Based Learning System for Online Motion Sickness Level Estimation in a Dynamic Vehicle Environment,"Motion sickness is a common experience for many people. Several previous researches indicated that motion sickness has a negative effect on driving performance and sometimes leads to serious traffic accidents because of a decline in a person's ability to maintain self-control. This safety issue has motivated us to find a way to prevent vehicle accidents. Our target was to determine a set of valid motion sickness indicators that would predict the occurrence of a person's motion sickness as soon as possible. A successful method for the early detection of motion sickness will help us to construct a cognitive monitoring system. Such a monitoring system can alert people before they become sick and prevent them from being distracted by various motion sickness symptoms while driving or riding in a car. In our past researches, we investigated the physiological changes that occur during the transition of a passenger's cognitive state using electroencephalography (EEG) power spectrum analysis, and we found that the EEG power responses in the left and right motors, parietal, lateral occipital, and occipital midline brain areas were more highly correlated to subjective sickness levels than other brain areas. In this paper, we propose the use of a self-organizing neural fuzzy inference network (SONFIN) to estimate a driver's/passenger's sickness level based on EEG features that have been extracted online from five motion sickness-related brain areas, while either in real or virtual vehicle environments. The results show that our proposed learning system is capable of extracting a set of valid motion sickness indicators that originated from EEG dynamics, and through SONFIN, a neuro-fuzzy prediction model, we successfully translated the set of motion sickness indicators into motion sickness levels. The overall performance of this proposed EEG-based learning system can achieve an average prediction accuracy of ~82%.",
Design and experimentation of acceleration-level drift-free scheme aided by two recurrent neural networks,"To solve the joint-angle and joint-velocity drift problems in cyclic motion of redundant robot manipulators, an acceleration-level drift-free (ALDF) scheme subject to a linear equality constraint is proposed, of which the effectiveness is analysed and proved via the theory of second-order system. The scheme is then reformulated into a quadratic program (QP). Furthermore, two recurrent neural networks (RNNs) are developed for solving the resultant QP problem. The first RNN solver is based on Zhang et al's neural-dynamic method and called Zhang neural network (ZNN), whereas the other is based on the gradient-descent method and called gradient neural network (GNN). Comparison results based on computer simulations between the ZNN and GNN solvers with a circular-path tracking task demonstrate that the ZNN solver has faster convergence and fewer errors. In addition, the hardware experiments of tracking a straight-line path and a rhombic path based on a six degrees of freedom manipulator validate the physical realisability and efficacy of the proposed ALDF scheme and the two RNN QP-solvers. Moreover, the position, velocity and acceleration error analyses indicate the accuracy of the proposed ALDF scheme and the corresponding RNN QP-solvers.","redundant manipulators,
gradient methods,
neurocontrollers,
quadratic programming,
recurrent neural nets"
SWIFT: A Low-Power Network-On-Chip Implementing the Token Flow Control Router Architecture With Swing-Reduced Interconnects,"A 64-bit, 8 × 8 mesh network-on-chip (NoC) is presented that uses both new architectural and circuit design techniques to improve on-chip network energy-efficiency, latency, and throughput. First, we propose token flow control, which enables bypassing of flit buffering in routers, thereby reducing buffer size and their power consumption. We also incorporate reduced-swing signaling in on-chip links and crossbars to minimize datapath interconnect energy. The 64-node NoC is experimentally validated with a 2 × 2 test chip in 90 nm, 1.2 V CMOS that incorporates traffic generators to emulate the traffic of the full network. Compared with a fully synthesized baseline 8 × 8 NoC architecture designed to meet the same peak throughput, the fabricated prototype reduces network latency by 20% under uniform random traffic, when both networks are run at their maximum operating frequencies. When operated at the same frequencies, the SWIFT NoC reduces network power by 38% and 25% at saturation and low loads, respectively.",
CrisisTracker: Crowdsourced social media curation for disaster awareness,"Victims, volunteers, and relief organizations are increasingly using social media to report and act on large-scale events, as witnessed in the extensive coverage of the 2010–2012 Arab Spring uprisings and 2011 Japanese tsunami and nuclear disasters. Twitter® feeds consist of short messages, often in a nonstandard local language, requiring novel techniques to extract relevant situation awareness data. Existing approaches to mining social media are aimed at searching for specific information, or identifying aggregate trends, rather than providing narratives. We present CrisisTracker, an online system that in real time efficiently captures distributed situation awareness reports based on social media activity during large-scale events, such as natural disasters. CrisisTracker automatically tracks sets of keywords on Twitter and constructs stories by clustering related tweets on the basis of their lexical similarity. It integrates crowdsourcing techniques, enabling users to verify and analyze stories. We report our experiences from an 8-day CrisisTracker pilot deployment during 2012 focused on the Syrian civil war, which processed, on average, 446,000 tweets daily and reduced them to consumable stories through analytics and crowdsourcing. We discuss the effectiveness of CrisisTracker based on the usage and feedback from 48 domain experts and volunteer curators.",
Graph-Based IVUS Segmentation With Efficient Computer-Aided Refinement,"A new graph-based approach for segmentation of luminal and external elastic lamina (EEL) surface of coronary vessels in gated 20 MHz intravascular ultrasound (IVUS) image sequences (volumes) is presented. The approach consists of a fully automated segmentation stage (“new automated” or NA) and a user-guided computer-aided refinement (“new refinement” or NR) stage. Both approaches are based on the LOGISMOS approach for simultaneous dual-surface graph-based segmentation. This combination allows the user to efficiently combine general information about IVUS image appearance and case-specific IVUS morphology and therefore deal with frequently occurring issues like calcified plaque-causing signal shadowing-and imaging artifacts. The automated segmentation stage starts with pre-segmenting the lumen to automatically define the lumen centerline, which is used to transform the segmentation task into a LOGISMOS-family graph optimization problem. Following the automated segmentation, the user can inspect the result and correct local or regional segmentation inaccuracies by (iteratively) providing approximate clues regarding the location of the desired surface locations. This expert information is utilized to modify the previously calculated cost functions, locally re-optimizing the underlying modified graph without a need to start the new optimization from scratch. Validation of our method was performed on 41 gated 20 MHz IVUS data sets for which an expert-defined independent standard was available. Resulting from the automated stage of the approach (NA), the mean and standard deviation of the root mean square area errors for the luminal and external elastic lamina surfaces were 1.12 ± 0.67 mm2 and 2.35 ± 1.61 mm2, respectively. Following the refinement stage (NR), the root mean square area errors significantly decreased to 0.82 ± 0.44 mm2 and 1.17 ± 0.65 mm2 for the same surfaces, respectively (p <; 0.001 for both surfaces). The approach is delivering a previously unachievable speed of obtaining clinically relevant segmentations compared to the current approaches of automated segmentation followed by manual editing.","Image segmentation,
Rough surfaces,
Surface roughness,
Imaging,
Surface morphology,
Cost function,
Logic gates"
Intensity Range Based Background Subtraction for Effective Object Detection,"In this letter, we propose an intensity range based object detection scheme for videos with fixed background and static cameras. The scheme suggests two different algorithms; the first one models the background from initial few frames and the second algorithm extracts the objects based on local thresholding. The strength of the scheme lies in its simplicity and the fact that, it defines an intensity range for each pixel location in the background to accommodate illumination variation as well as motion in the background. The efficacy of the scheme is shown through comparative analysis with competitive methods. Both visual as well as quantitative measures show an improved performance and the scheme has a strong potential for applications in real time surveillance.","Videos,
Computational modeling,
Object detection,
Lighting,
Video sequences,
Adaptation models,
Signal processing algorithms"
Robust Anatomical Correspondence Detection by Hierarchical Sparse Graph Matching,"Robust anatomical correspondence detection is a key step in many medical image applications such as image registration and motion correction. In the computer vision field, graph matching techniques have emerged as a powerful approach for correspondence detection. By considering potential correspondences as graph nodes, graph edges can be used to measure the pairwise agreement between possible correspondences. In this paper, we present a novel, hierarchical graph matching method with sparsity constraint to further augment the power of conventional graph matching methods in establishing anatomical correspondences, especially for the cases of large inter-subject variations in medical applications. Specifically, we first propose to measure the pairwise agreement between potential correspondences along a sequence of intensity profiles which reduces the ambiguity in correspondence matching. We next introduce the concept of sparsity on the fuzziness of correspondences to suppress the distraction from misleading matches, which is very important for achieving the accurate, one-to-one correspondences. Finally, we integrate our graph matching method into a hierarchical correspondence matching framework, where we use multiple models to deal with the large inter-subject anatomical variations and gradually refine the correspondence matching results between the tentatively deformed model images and the underlying subject image. Evaluations on both synthetic data and public hand X-ray images indicate that the proposed hierarchical sparse graph matching method yields the best correspondence matching performance in terms of both accuracy and robustness when compared with several conventional graph matching methods.","X-ray imaging,
Robustness,
Optimization,
Vectors,
Feature extraction,
Biomedical imaging,
Deformable models"
Economic analysis of 4G network upgrade,"As the successor to the 3G standard, 4G provides much higher data rates to address cellular users' ever-increasing demands for high-speed multimedia communications. This paper analyzes the cellular operators' timing of network upgrades and models that users can switch operators and services. Being the first to upgrade 3G to 4G service, an operator increases his market share but takes more risk or upgrade cost because 4G technology matures over time. This paper first studies a 4G monopoly market with one dominant operator and some small operators, where the monopolist decides his upgrade time by trading off increased market share and upgrade cost. The paper also considers a 4G competition market and develops a game theoretic model for studying operators' interactions. The analysis shows that operators select different upgrade times to avoid severe competition. One operator takes the lead to upgrade, using the benefit of a larger market share to compensate for the larger cost of an early upgrade. This result matches well with many industry observations of asymmetric 4G upgrades. The paper further shows that the availability of 4G upgrade may decrease both operators' profits due to increased competition. Perhaps surprisingly, the profits can increase with the upgrade cost.",
Hybrid User-Assisted Incremental Model Adaptation for Activity Recognition in a Dynamic Smart-Home Environment,"Identifying on-going activities for the provision of services that are capable of matching the needs of users poses a number of daunting challenges. Most existing approaches to activity recognition require training offline activity models before being applied to the identification of activities in real time. However, the dynamic nature of actual living environments can make previously learned activity models irrelevant. This study addressed the problem of learning and recognizing daily activities in a dynamic smart-home environment, using a novel approach referred to as hybrid user-assisted incremental model adaptation. This approach involves reconfiguring previously learned activity models within a dynamic environment, while pursuing maximum efficiency by using assistance from users as well as the system to annotate new training data. Experiments that are conducted in a fully equipped smart-home lab demonstrate the efficacy of the proposed approach.",
Generalized Ray Theory for Time-Domain Electromagnetic Fields in Horizontally Layered Media,"Generalized-ray theory for time-domain electromagnetic fields in a horizontally layered medium is developed. It can be considered as the time-domain equivalent of the intensively studied Green's function formulation in frequency domain. After introducing appropriate integral transformations and source-type field representations, the solution is written out in terms of generalized ray constituents whose space-time counterparts are constructed with the aid of the Cagniard–DeHoop technique. The formulation lays the foundation to rigorously study time-domain field behavior in numerous practical topologies where a stratified multilayer is involved, such as planar antennas and circuits, but also electromagnetic compatibility (EMC) and propagation problems. Illustrative numerical results are presented.","Time domain analysis,
Green's function methods,
Equations,
Media,
Magnetic domains,
Tensile stress"
Ultra-Wideband Suppression of Power/Ground Noise in High-Speed Circuits Using a Novel Electromagnetic Bandgap Power Plane,"A power/ground plane pair is proposed using a novel planar electromagnetic bandgap (EBG) structure for isolating the power-to-ground noise (PGN) in high-speed circuits. Each unit cell of the novel EBG is designed by etching slots in a “C” shape on the power plane while maintaining the ground plane solid. Without cascading hybrid periodic structures, it shows an efficient mitigation of PGN within an ultra-wideband frequency range of 0.25-2.18 GHz. In this paper, the equivalent circuit model and cavity mode analysis for the novel EBG unit cell are given to quickly predict the lower and upper bound cutoff frequency, respectively. The dispersion diagram of the proposed EBG structure is validated by insertion loss measurements with ports at different locations of the unit cell for different modes. The result shows that there is a good consistency between the simulated and measured results.","Periodic structures,
Metamaterials,
Inductance,
Integrated circuit modeling,
Equivalent circuits,
Dispersion,
Bridge circuits"
Community-based features for identifying spammers in Online Social Networks,"The popularity of Online Social Networks (OSNs) is often faced with challenges of dealing with undesirable users and their malicious activities in the social networks. The most common form of malicious activity over OSNs is spamming wherein a bot (fake user) disseminates content, malware/viruses, etc. to the legitimate users of the social networks. The common motives behind such activity include phishing, scams, viral marketing and so on which the recipients do not indent to receive. It is thus a highly desirable task to devise techniques and methods for identifying spammers (spamming accounts) in OSNs. With an aim of exploiting social network characteristics of community formation by legitimate users, this paper presents a community-based framework to identify spammers in OSNs. The framework uses community-based features of OSN users to learn classification models for identification of spamming accounts. The preliminary experiments on a real-world dataset with simulated spammers reveal that proposed approach is promising and that using community-based node features of OSN users can improve the performance of classifying spammers and legitimate users.","Communities,
Social network services,
Feature extraction,
Unsolicited electronic mail,
Mathematical model,
Equations"
Computing Reeb Graphs as a Union of Contour Trees,"The Reeb graph of a scalar function tracks the evolution of the topology of its level sets. This paper describes a fast algorithm to compute the Reeb graph of a piecewise-linear (PL) function defined over manifolds and non-manifolds. The key idea in the proposed approach is to maximally leverage the efficient contour tree algorithm to compute the Reeb graph. The algorithm proceeds by dividing the input into a set of subvolumes that have loop-free Reeb graphs using the join tree of the scalar function and computes the Reeb graph by combining the contour trees of all the subvolumes. Since the key ingredient of this method is a series of union-find operations, the algorithm is fast in practice. Experimental results demonstrate that it outperforms current generic algorithms by a factor of up to two orders of magnitude, and has a performance on par with algorithms that are catered to restricted classes of input. The algorithm also extends to handle large data that do not fit in memory.",
Real-Time Error Recovery in Cyberphysical Digital-Microfluidic Biochips Using a Compact Dictionary,"A cyberphysical digital microfluidics system is an emerging technology that enables the integration of fluid-handling operations, reaction-outcome detection, and automated error recovery on a biochip. Cyberphysical biochip systems studied thus far suffer from a significant increase in reaction time for error recovery. We present a hardware-assisted method that can be implemented in real-time on a field-programmable gate array (FPGA). In order to store the error dictionary in the limited memory available in the FPGA, we utilize and adapt two data compaction techniques from the literature. We use four laboratorial protocols to demonstrate that, compared to software-based methods, the proposed dictionary-based error-recovery method has low response time, and requires a simple experimental setup, and only a small amount of memory.",
Design methodologies for high density domain wall memory,"Domain wall memory (DWM) has emerged as a possible candidate for embedded cache application. The fundamental advantage of DWM is its MLC (multi-level cell) capability allowing it to store multiple bits/cell in order to break the density barrier. Additionally, it provides low standby power, fast access time, good endurance and good retention. In this paper, we address design challenges associated with DWM for potential use in on-chip cache.",
Convergence of evolutionary algorithms on the n-dimensional continuous space,"Evolutionary algorithms (EAs) are random optimization methods inspired by genetics and natural selection, resembling simulated annealing. We develop a method that can be used to find a meaningful tradeoff between the difficulty of the analysis and the algorithms' efficiency. Since the case of a discrete search space has been studied extensively, we develop a new stochastic model for the continuous n-dimensional case. Our model uses renewal processes to find global convergence conditions. A second goal of the paper is the analytical estimation of the computation time of EA with uniform mutation inside the (hyper)-sphere of volume 1, minimizing a quadratic function.","stochastic processes,
evolutionary computation,
random processes,
simulated annealing"
A QoE preserving M2M-aware hybrid scheduler for LTE uplink,The 4th Generation (4G) Long Term Evolution (LTE) wireless networks are expected to be used for the majority of Machine to Machine (M2M) communication. M2M communication over 4G networks faces some challenges. The main challenge is how to accommodate the massive number of M2M devices without negatively impacting the human subscribers' Quality of Experience (QoE). This paper discusses the challenges of scheduling UEs and M2M terminals in LTE networks. The LTE scheduler plays an important role in distributing radio resources to user equipments (UEs) and M2M terminals. We present a hybrid uplink scheduler that balances the radio resources allocation to preserve human users QoE and fairly fulfills M2M terminals communication requests. The simulation results show that the proposed solution provides fair scheduling of M2M terminals without impacting the UE.,"Mobile computing,
Mobile communication,
Wireless communication,
Conferences"
Incoherent training of deep neural networks to de-correlate bottleneck features for speech recognition,"Recently, the hybrid model combining deep neural network (DNN) with context-dependent HMMs has achieved some dramatic gains over the conventional GMM/HMM method in many speech recognition tasks. In this paper, we study how to compete with the state-of-the-art DNN/HMM method under the traditional GMM/HMM framework. Instead of using DNN as acoustic model, we use DNN as a front-end bottleneck (BN) feature extraction method to decorrelate long feature vectors concatenated from several consecutive speech frames. More importantly, we have proposed two novel incoherent training methods to explicitly de-correlate BN features in learning of DNN. The first method relies on minimizing coherence of weight matrices in DNN while the second one attempts to minimize correlation coefficients of BN features calculated in each mini-batch data in DNN training. Experimental results on a 70-hr Mandarin transcription task and the 309-hr Switchboard task have shown that the traditional GMM/HMMs using BN features can yield comparable performance as DNN/HMM. The proposed incoherent training can produce 2-3% additional gain over the baseline BN features. At last, the discriminatively trained GMM/HMMs using incoherently trained BN features have consistently surpassed the state-of-the-art DNN/HMMs in all evaluated tasks.",
Throughput of Cognitive Radio Systems with Finite Blocklength Codes,"In this paper, throughput achieved in cognitive radio channels with finite blocklength codes under buffer limitations is studied. Cognitive users first determine the activity of the primary users' through channel sensing and then initiate data transmission at a power level that depends on the channel sensing decisions. It is assumed that finite blocklength codes are employed in the data transmission phase. Hence, errors can occur in reception and retransmissions can be required. Primary users' activities are modeled as a two-state Markov chain and an eight-state Markov chain is constructed in order to model the cognitive radio channel. Channel state information (CSI) is assumed to be perfectly known by either the secondary receiver only or both the secondary transmitter and receiver. In the absence of CSI at the transmitter, fixed-rate transmission is performed whereas under perfect CSI knowledge, for a given target error probability, the transmitter varies the rate according to the channel conditions. Under these assumptions, throughput in the presence of buffer constraints is determined by characterizing the maximum constant arrival rates that can be supported by the cognitive radio channel while satisfying certain limits on buffer violation probabilities. Tradeoffs between throughput, buffer constraints, coding blocklength, and sensing duration for both fixed-rate and variable-rate transmissions are analyzed numerically. The relations between average error probability, sensing threshold and sensing duration are studied in the case of variable-rate transmissions.","Sensors,
Receivers,
Radio transmitters,
Cognitive radio,
Interference,
Throughput,
Fading"
Wireless Sensor Networks and the Internet of Things: Optimal Estimation With Nonuniform Quantization and Bandwidth Allocation,"Wireless sensor networks (WSNs) are an invaluable resource for realizing the vision of the Internet of Things. This paper investigates the energy minimization problem for the joint estimation of a noise-corrupted parameter in WSNs, where the sensors send digital signals to a fusion center via orthogonal channels. In particular, each sensor chooses a quantization level, a modulation order, and a transmission bandwidth for its link to the fusion center with the goal to minimize the total energy consumption at the sensors. It is shown that this problem can be approximated as a convex optimization problem and an efficient iterative algorithm is proposed to compute the near-optimal solution. Simulation results are provided to validate the analysis.","wireless sensor networks,
bandwidth allocation,
Internet of Things,
iterative methods,
quadrature amplitude modulation"
Battling the Internet water army: Detection of hidden paid posters,"We initiate a systematic study to help distinguish a special group of online users, called hidden paid posters, or termed “Internet water army” in China, from the legitimate ones. On the Internet, the paid posters represent a new type of online job opportunities. They get paid for posting comments or articles on different online communities and Websites for hidden purposes, e.g., to influence the opinion of other people towards certain social events or business markets. While being an interesting strategy in business marketing, paid posters may create a significant negative effect on the online communities, since the information from paid posters is usually not trustworthy. When two competitive companies hire paid posters to post fake news or negative comments about each other, normal netizens may feel overwhelmed and find it difficult to put any trust in the information they acquire from the Internet. In this paper, we thoroughly investigate the behavioral pattern of online paid posters based on real-world trace data. We design and validate a new detection mechanism, using both non-semantic analysis and semantic analysis, to identify potential online paid posters. Our test results with real-world datasets show a very promising performance.","Semantics,
Internet,
Companies,
Support vector machines,
Conferences,
Social network services,
Educational institutions"
Multiple Target Localization Using Wideband Echo Chirp Signals,"Active target detection and localization is a classical signal processing problem that arises in various military and biomedical applications. A novel method for the detection and estimation of the range, velocity and direction of arrival (DOA) of multiple far-field targets using wideband chirp signals is proposed in this paper. Using the plane wave representation of the signals reflected from far-field targets, a modal preprocessing procedure is designed for the echo signals received at a concentric circular array. Following that, the parameter estimation method for the multiple targets present is developed based on (i) the fractional Fourier transform which projects a signal onto an orthonormal basis formed by chirps and (ii) the Root-MUSIC algorithm which is a high resolution DOA estimation method originally proposed for narrowband signals received at a uniform linear array. There is no limit on the number of targets detectable by the proposed method as long as the echo signals are separable in the chosen fractional Fourier domain. Simulation results show that the proposed method demonstrates good performance, with low root-mean-square errors in the parameters estimated under difficult conditions such as closely spaced targets and low signal-to-noise ratio.","target tracking,
direction-of-arrival estimation,
echo,
mean square error methods,
medical signal detection,
object detection"
Broadband methods for online grid impedance measurement,"Grid impedance is an important parameter for the operation and control of grid-connected inverters used for the integration of solar, wind, and other distributed generation resources. Since the grid impedance usually varies over time and with grid operation conditions, online measurement is required for adaptive control of grid-connected inverters. Existing online measurement methods based on impulse perturbation and Fourier analysis require large current or voltage injection that may interfere with normal operation of the inverter. This paper proposes the use of maximum-length binary sequence (MLBS) injection and averaging Fourier techniques to overcome the drawbacks of impulse injection. Experimental results based on a three-phase grid-connected inverter are presented and used to demonstrate the effectiveness of the proposed methods.","Impedance,
Voltage measurement,
Inverters,
Current measurement,
Frequency measurement,
Impedance measurement,
Noise"
Quality-Driven Energy-Neutralized Power and Relay Selection for Smart Grid Wireless Multimedia Sensor Based IoTs,"With the popularity of photovoltaic based green energy in smart grid systems, accurate information gathering becomes a critical issue in predicting microgrid power input. In this paper, we propose a new quality-optimized multimedia information gathering scheme, in the energy harvesting wireless sensor networks based Internet of things system, to provide the best-effort sky camera information accuracy for further predicting available photovoltaic power. In the proposed approach, the power control and relay node selection strategies are jointly optimized to achieve maximum sky camera image quality subject to the harvestable energy neutrality constraint. Simulation results show that the proposed scheme can improve multimedia data transmission quality by exploring adaptive transmission power and relay selection strategy.","wireless sensor networks,
energy harvesting,
environmental factors,
Internet of Things,
multimedia communication,
photovoltaic power systems,
relay networks (telecommunication),
smart power grids,
telecommunication power supplies"
Implementation of FREEDM Smart Grid distributed load balancing using IEC 61499 function blocks,"This paper presents implementation of one of the Distributed Grid Intelligence (DGI) applications: Load Balancing, using the IEC61499 architecture. This enables system level design of distributed load balancing application with a direct pathway to deployment to hardware. The use of IEC 61499 improves scalability, re-configurability and maintainability of automation software. The application was deployed to commercial programmable automation devices and embedded controller (ARM based TS-7800). The application was verified using co-simulation approach: control and power system simulated using Matlab on PC networked with the number of distributed hardware running load balance algorithm. The use of IEC 61499 facilitates deployment of hardware independent function block model to the variety of compliant hardware.","Load management,
IEC standards,
Load modeling,
Peer-to-peer computing,
Mathematical model,
MATLAB,
Computer architecture"
Assessing the Cost Effectiveness of Fault Prediction in Acceptance Testing,"Until now, various techniques for predicting fault-prone modules have been proposed and evaluated in terms of their prediction performance; however, their actual contribution to business objectives such as quality improvement and cost reduction has rarely been assessed. This paper proposes using a simulation model of software testing to assess the cost effectiveness of test effort allocation strategies based on fault prediction results. The simulation model estimates the number of discoverable faults with respect to the given test resources, the resource allocation strategy, a set of modules to be tested, and the fault prediction results. In a case study applying fault prediction of a small system to acceptance testing in the telecommunication industry, results from our simulation model showed that the best strategy was to let the test effort be proportional to ""the number of expected faults in a module × log(module size)."" By using this strategy with our best fault prediction model, the test effort could be reduced by 25 percent while still detecting as many faults as were normally discovered in testing, although the company required about 6 percent of the test effort for metrics collection, data cleansing, and modeling. The simulation results also indicate that the lower bound of acceptable prediction accuracy is around 0.78 in terms of an effort-aware measure, Norm(Popt). The results indicate that reduction of the test effort can be achieved by fault prediction only if the appropriate test strategy is employed with high enough fault prediction accuracy. Based on these preliminary results, we expect further research to assess their general validity with larger systems.","Testing,
Predictive models,
Measurement,
Software,
Resource management,
Companies,
Accuracy"
Towards MIMO-Aware 802.11n Rate Adaptation,"In this paper, we use real experiments to study multiple-input-multiple-output (MIMO) 802.11n rate adaptation (RA) on a programmable access point (AP) platform. Our case study shows that existing RA solutions offer much lower throughput than even a fixed-rate scheme. It is proven that all such algorithms are MIMO-mode oblivious; they do not differentiate spatial diversity and spatial multiplexing modes. We first design MiRA, a novel MIMO RA scheme that zigzags between intra- and inter-MIMO modes to address MIMO 802.11n dynamics. Second, we examine a window-based RA solution, which runs an independent RA in each MIMO mode in parallel and a signal-to-noise ratio (SNR)-based MIMO RA that differentiates modes using SNR measurements. Our experiments show that MIMO-mode aware designs outperform MIMO-mode oblivious RAs in various settings, with goodput gains up to 73.5% in field trials.","MIMO,
IEEE 802.11n Standard,
Signal to noise ratio,
Probes,
Algorithm design and analysis,
Radio frequency,
Gain"
Reverb: Recommending code-related web pages,"The web is an important source of development-related resources, such as code examples, tutorials, and API documentation. Yet existing development environments are largely disconnected from these resources. In this work, we explore how to provide useful web page recommendations to developers by focusing on the problem of refinding web pages that a developer has previously used. We present the results of a study about developer browsing activity in which we found that 13.7% of developers visits to code-related pages are revisits and that only a small fraction (7.4%) of these were initiated through a low-cost mechanism, such as a bookmark. To assist with code-related revisits, we introduce Reverb, a tool which recommends previously visited web pages that pertain to the code visible in the developer's editor. Through a field study, we found that, on average, Reverb can recommend a useful web page in 51% of revisitation cases.","Web pages,
History,
Browsers,
Software,
Indexing,
Google"
Investigation on cross- and multilingual MLP features under matched and mismatched acoustical conditions,"In this paper, Multi Layer Perceptron (MLP) based multilingual bottleneck features are investigated for acoustic modeling in three languages - German, French, and US English. We use a modified training algorithm to handle the multilingual training scenario without having to explicitly map the phonemes to a common phoneme set. Furthermore, the cross-lingual portability of bottleneck features between the three languages are also investigated. Single pass recognition experiments on large vocabulary SMS dictation task indicate that (1) multilingual bottleneck features yield significantly lower word error rates compared to standard MFCC features (2) multilingual bottleneck features are superior to monolingual bottleneck features trained for the target language with limited training data, and (3) multilingual bottleneck features are beneficial in training acoustic models in a low resource language where only mismatched training data is available-by exploiting the more matched training data from other languages.","Training,
Mel frequency cepstral coefficient,
Hidden Markov models,
Speech,
Feature extraction,
Training data"
Selfish Response to Epidemic Propagation,"An epidemic that spreads in a network calls for a decision on the part of the network users. They have to decide whether to protect themselves or not. Their decision depends on the tradeoff between the perceived infection and the protection cost. Aiming to help users reach an informed decision, security advisories provide periodic information about the infection level in the network. We study the best-response dynamic in a network whose users repeatedly activate or de-activate security, depending on what they learn about the infection level. Our main result is the counterintuitive fact that the equilibrium level of infection increases as the users' learning rate increases. The same is true when the users follow smooth best-response dynamics, or any other continuous response function that implies higher probability of protection when learning a higher level of infection. In both cases, we characterize the stability and the domains of attraction of the equilibrium points. Our finding also holds when the epidemic propagation is simulated on human contact traces, both when all users are of the same best-response behavior type and when they are of two distinct behavior types.","Switched systems,
Security,
Nonlinear systems,
Communication networks,
Invasive software"
Broadband Predistortion Circuit Using Zero Bias Diodes for Radio Over Fiber Systems,"A low-cost broadband analog predistortion circuit (PDC) is designed and experimentally verified in a radio over fiber (RoF) system. A miniature hybrid microwave integrated circuit technique is used to reduce the size and parasitics of PDC. Only two zero bias GaAs beam lead detector diodes and capacitors are used in the PDC. The diodes can be biased at due to zero bias characteristic so that power consumption is reduced. No broadband matching network is required because of high series resistance of the zero bias diodes. The linearization performance is evaluated using an RoF system without and with the PDC. It is shown that the PDC improves the input 1-dB compression power by 0.4-2.2 dB from 7 to 18 GHz; and spurious free dynamic ranges are improved by ~ 10 dB from 7 to 14 GHz and ~ 6 dB from 15 to 18 GHz, limited by fifth order nonlinear distortion.","Optical fibers,
Modulation,
Optical fiber communication,
Optical saturation,
Broadband amplifiers,
Optical distortion"
Turing Machines with Atoms,"We study Turing machines over sets with atoms, also known as nominal sets. Our main result is that deterministic machines are weaker than nondeterministic ones; in particular, P≠NP in sets with atoms. Our main construction is closely related to the Cai-Furer-Immerman graphs used in descriptive complexity theory.","Turing machines,
Law,
Orbits,
Magnetic heads,
Computational modeling,
Polynomials"
"CCN-WSN - A lightweight, flexible Content-Centric Networking protocol for wireless sensor networks","In future Internet research, content centric networking (CCN) is a new promising approach. CCNx has been introduced recently as an open source protocol suite for CCN and implementation base for practical research. In wireless sensor networks (WSNs) research, data or content centric approaches like in-network processing and data aggregation are important. While the principle of CCN is a suitable approach in WSNs, the CCNx protocol suite designed for PCs is not applicable to resource-constrained WSNs. Therefore, we design, implement and evaluate a lightweight variant of a CCN protocol specifically for WSNs called CCN-WSN as a lightweight alternative to implementing IP for sensor networks. Key concepts of CCNx protocol are integrated but a variety of aspects are revised to meet the memory and computational constraints of sensor nodes and communication patterns in WSNs. E.g. the message format is simplified and some fields are omitted completely. Instead, we propose a flexible naming strategy which extends the functionality of content names to add small amount of data in interest messages. For performance evaluation a challenging time-synchronization application was implemented with CCN-WSN to demonstrate the flexibility of the approach and a comparison with a reference protocol for data dissemination called AutoCast is presented.","Protocols,
Wireless sensor networks,
Synchronization,
IP networks,
Internet,
Routing,
IEEE 802.15 Standards"
A Physics-Based Green's Function for Analysis of Vertical Electric Dipole Radiation Over an Imperfect Ground Plane,"Sommerfeld integrals appear in the solution of radiation and scattering problems involving antennas in planar multi-layered media. In the conventional approach it is quite difficult to numerically integrate the tails related to Sommerfeld integrals as they are not only oscillatory but also slowly decaying. Numerous research efforts have been developed to accelerate the accurate computation of such integrals, for example, by changing the integration path in the complex plane, or by using extrapolation methods. In this paper, the physical origin of the problem of the Sommerfeld integral tails is studied. Based on the physical description of the problem, a new Green's function for the radiation of a vertical electric dipole over an imperfect ground plane is derived. The new Green's function involves what is called in this paper Schelkunoff integrals. The new formulation is compared to the conventional Sommerfeld formulation, mainly with respect to the speed of convergence when the fields are calculated near the ground plane. The characteristics of the new formulation show that if Schelkunoff integrals are used in the appropriate region, the problem of Sommerfeld integral tails, which plagued the electromagnetic community for decades, can be totally abolished.","planar antennas,
antenna radiation patterns,
dipole antennas,
electromagnetic wave scattering,
extrapolation,
Green's function methods,
integral equations"
HomePort: Middleware for heterogeneous home automation networks,"Ambient Intelligence systems use many sensors and actuators, with a diversity of networks, protocols and technologies which makes it impossible to access the devices in a common manner. This paper presents the HomePort software, which provides an open source RESTful interface to heterogeneous sensor networks, allowing a simple unified access to virtually any kind of protocol using well known standards. HomePort includes means to provide event notification, as well as a tracing mechanism. The software is implemented and we report on initial experiments and provide an evaluation that shows the feasibility and scalability of the approach.","Servers,
Computer architecture,
Sensors,
Protocols,
Access control,
Middleware"
Verifying SystemC using an intermediate verification language and symbolic simulation,"Formal verification of SystemC is challenging. Before dealing with symbolic inputs and the concurrency semantics, a front-end is required to translate the design to a formal model. The lack of such front-ends has hampered the development of efficient back-ends so far. In this paper, we propose an isolated approach by using an Intermediate Verification Language (IVL). This enables a SystemC-to-IVL translator (frond-end) and an IVL verifier (back-end) to be developed independently. We present a compact but general IVL that together with an extensive benchmark set will facilitate future research. Furthermore, we propose an efficient symbolic simulator integrating Partial Order Reduction. Experimental comparison with existing approaches has shown its potential.","Semantics,
Benchmark testing,
Kernel,
Object oriented modeling,
Process control,
Algorithm design and analysis,
Scheduling"
Joint opportunistic scheduling and network coding for bidirectional relay channel,"In this paper, we consider a two-way communication system in which two users communicate with each other through an intermediate relay over block-fading channels. We investigate the optimal opportunistic scheduling scheme in order to maximize the long-term average transmission rate in the system assuming symmetric information flow between the two users. Based on the channel state information, the scheduler decides that either one of the users transmits to the relay, or the relay transmits to a single user or broadcasts to both users a combined version of the two users' transmitted information by using linear network coding. We obtain the optimal scheduling scheme by using the Lagrangian dual problem. Furthermore, in order to characterize the gains of network coding and opportunistic scheduling, we compare the achievable rate of the system versus suboptimal schemes in which the gains of network coding and opportunistic scheduling are partially exploited.","Relays,
Network coding,
Optimal scheduling,
Uplink,
Gain,
Downlink"
Design Optimization of Multigate Bulk MOSFETs,"The design optimization of multigate bulk MOSFET structures is investigated for sub-20-nm gate lengths. Three-dimensional device simulations were used to optimize device design parameters such as the retrograde channel doping profile, as well as the length, width, and height of the gated channel region. Compared with the FinFET design, the results indicate that the tri-gate MOSFET design is promising for continued bulk-Si CMOS transistor scaling, because it can achieve similar on-state current performance and intrinsic delay [for the same channel stripe pitch (SP)] at a lower height/width aspect ratio (0.8 versus 2.17) and less aggressive retrograde channel doping gradient for improved manufacturability. Only by increasing the height of the channel region and/or reducing the channel SP can the FinFET bulk MOSFET design achieve better delay, but at the cost of reduced manufacturability.","FinFETs,
Doping,
Logic gates,
Delay,
Design optimization"
Comparison between android and iOS Operating System in terms of security,"This paper compares between android and iPhone Operating System (iOS) mobile operating systems (MOS) that available in the market which is more specific on the security issue. These issues are reportedly the concern of not only the mobile customers but also the software developers. In achieving security requirements, the MOS developers need to know how to achieve the criteria. The security requirements for MOS are Application Sandboxing, Memory Randomization, Encryption, Data Storage Format and Built-in Antivirus. Application sandboxing enforces permissions, privileges, directories, entitlements and kernel access for a mobile app. Memory randomization ensures that the memory regions of mobile application as well as system shared libraries are all randomized at device and application start-up. Encryption is performed on disk or filer/folder level and also at the interprocess communication level. It is difficult to speak in favor or against the android or the iOS operating system in terms of better security. The way of using the device plays a major role in determining the security level. In terms of storage, all data are stored in Data Storage Format. Data can be stored at internal storage or external storage. To protect the MOS from virus attacks, antivirus need to be installed for increasing security areas.","Mobile communication,
Operating systems,
Encryption,
Androids,
Humanoid robots,
Smart phones"
A Cyber Physical Test-Bed for Virtualization of RF Access Environment for Body Sensor Network,"Performance evaluation of wireless access and localization is important for body sensor networks, as any defects in the design not only cause wastage of resources, but also threaten an individual's health and safety. The typical cyber methods, however, such as software simulation, often fail to accurately simulate the influence of hardware implementation. The traditional physical methods, however, such as field testing, are not capable of creating repeatable and controllable channel conditions. To combine cyber and physical factors as well as to address the issue, we present a cyber physical test-bed for environment virtualization to facilitate the performance evaluation of wireless access and localization in body sensor networks. This test-bed creates a virtualized environment by emulating the wireless channel in a cybernetic way using a real time channel emulator. The original devices or systems under testing can be physically connected to a channel emulator to evaluate the performance in the virtualization environment. Furthermore, the cyber physical test-bed supports various scenarios from in-body data transmission to time of arrival based indoor localization. To validate the cyber physical approach, emulated outputs are compared with the empirical data obtained from actual measurements. To overcome the bandwidth limitation of traditional digital channel emulators, we have designed an analog channel emulator for UWB technologies. The preliminary verification of this analog emulator is introduced at the end of this paper.","telecommunication computing,
body sensor networks,
indoor radio,
performance evaluation"
Generalized tensor compressive sensing,"Compressive sensing (CS) has triggered enormous research activity since its first appearance. CS exploits the signal's sparseness or compressibility in a particular domain and integrates data compression and acquisition. While conventional CS theory relies on data representation in the form of vectors, many data types in various applications such as color imaging, video sequences, and multi-sensor networks, are intrinsically represented by higher-order tensors. Application of CS to higher-order data representation is typically performed by conversion of the data to very long vectors that must be measured using very large sampling matrices, thus imposing a huge computational and memory burden. In this paper, we propose Generalized Tensor Compressive Sensing (GTCS)- a unified framework for compressive sensing of higher-order tensors. GTCS offers an efficient means for representation of multidimensional data by providing simultaneous acquisition and compression from all tensor modes. In addition, we compare the performance of the proposed method with Kronecker compressive sensing (KCS). We demonstrate experimentally that GTCS outperforms KCS in terms of both accuracy and speed.","Tensile stress,
Compressed sensing,
Vectors,
Image reconstruction,
PSNR,
Sparse matrices,
Minimization"
Demand side management algorithms and modeling in smart grids A customer's behavior based study,"This paper presents algorithms and architecture models for a home energy management system. It's based on customers' behavior that is modeled by a decision-making chain, and smart appliances' use for demand side management. The proposed architecture is scalable and extensible to upper levels of smart grid as the development approach used is bottom-up. Once the model is validated for home use, we can go up and apply it for holdings, factories, and micro-grids contexts. Scalability models and strategies are also presented and discussed. Ensuring supply and demand balance at real time is the main problematic of smart grids. The proposed solution meets this objective, because it allows large scale renewable energy resources integration. Hence, it leads to global energy efficiency and demand side management optimization in smart grids.","Home appliances,
Smart grids,
Unified modeling language,
Load modeling,
Computer architecture,
Biological system modeling,
Software"
Supporting cloud deployment in the Guifi.net community network,"Community networking is an emerging model of a shared communication infrastructure in which communities of citizens build and own open networks. Community networks offer successfully IP-based networking to the user. Cloud computing infrastructures however, while common in today's Internet, hardy exist in community networks. We explain our approach to bring clouds into the Guifi.net community network. For this we have started integrating part of our cloud prototype into the Guifi.net community network management tools. A proof-of-concept cloud infrastructure is currently under deployment in the Guifi.net community network. Our long term vision is that the users of community networks will not need to consume cloud applications from the Internet, but find them within the community network.","Communities,
Cloud computing,
Virtual machining,
Prototypes,
Operating systems"
OSNAP: Faster Numerical Linear Algebra Algorithms via Sparser Subspace Embeddings,"An oblivious subspace embedding (OSE) given some parameters ε, d is a distribution D over matrices Π ∈ Rm×n such that for any linear subspace W ⊆ Rn with dim(W) = d, PΠ~D(∀x ∈ W ||Πx||2 ∈ (1 ± ε)||x||2) > 2/3. We show that a certain class of distributions, Oblivious Sparse Norm-Approximating Projections (OSNAPs), provides OSE's with m = O(d1+γ/ε2), and where every matrix Π in the support of the OSE has only s = Oγ(1/ε) non-zero entries per column, for γ > 0 any desired constant. Plugging OSNAPs into known algorithms for approximate least squares regression, ℓp regression, low rank approximation, and approximating leverage scores implies faster algorithms for all these problems. Our main result is essentially a Bai-Yin type theorem in random matrix theory and is likely to be of independent interest: we show that for any fixed U ∈ Rn×d with orthonormal columns and random sparse Π, all singular values of ΠU lie in [1 - ε, 1 + ε] with good probability. This can be seen as a generalization of the sparse Johnson-Lindenstrauss lemma, which was concerned with d = 1. Our methods also recover a slightly sharper version of a main result of [Clarkson-Woodruff, STOC 2013], with a much simpler proof. That is, we show that OSNAPs give an OSE with m = O(d2/ε2), s = 1.","Least squares approximations,
Sparse matrices,
Approximation algorithms,
Vectors,
Algorithm design and analysis"
Detection of malicious attack in MANET a behavioral approach,"Topology of MANET is dynamic in nature due to this characteristic in this network build routing mechanism more convoluted and anxious and consequently nodes are more vulnerable to compromise and are predominantly susceptible to denial of service attack (DoS) assail launched by malicious nodes or intruders [6].Reactive routing for instance AODV is more trendy than table driven routing exploit flooding to find out route. Attackers used this conception to initiate DoS attack akin to flooding; black hole and gray hole are the branded attack in MANET. In this paper we have projected a novel automatic security mechanism using SVM to defense against malicious attack occurring in AODV. Proposed method uses machine learning to categorize nodes as malicious. This system is far further resilient to the context changes general in MANET's, such as those due to malicious nodes changing their misbehavior patterns over time or quick changes in environmental factors, for instance the movement speed and communication range. This paper introduced new proposed algorithm for detection of attacks in Ad-hoc networks based on SVM behavioral routing protocols to detect MANET attacks. In this technique we have used the PMOR, PDER, and PMISR as metrics to evaluate the QoS of a link and into prediction of attacks.",
A Holistic Model for Resource Representation in Virtualized Cloud Computing Data Centers,"Management and optimization of cloud infrastructures combine multiple challenges. The optimization of data centers targets such objectives as performance, reliability, energy consumption, and security. To achieve these goals, multiple actions can be taken, for example, task and virtual machine allocation or infrastructure management. In this work we propose a model for representation of computing, memory, storage, and communication resources in cloud computing data centers. This model is relevant for the characterization of cloud applications, virtual machines, as well as physical servers. The performance evaluation and validation of the proposed model is carried out using the Green Cloud simulator. The obtained results show good agreement with the design objectives and confirm validity of the assumptions.","Computational modeling,
Servers,
Vectors,
Resource management,
Data models,
Computer architecture,
Green products"
Reduced-Complexity Noncoherent Soft-Decision-Aided DAPSK Dispensing With Channel Estimation,"Differential amplitude phase-shift keying (DAPSK), which is also known as star-shaped quadrature-amplitude modulation, has implementational advantages not only due to dispensing with channel estimation but as a benefit of its low signal detection complexity as well. It is widely recognized that separately detecting the amplitude and the phase of a received DAPSK symbol exhibits lower complexity than jointly detecting the two terms. However, since the amplitude and the phase of a DAPSK symbol are affected by correlated magnitude fading and phase rotations, detecting the two terms completely independently results in a performance loss, which is particularly significant for soft-decision-aided DAPSK detectors relying on multiple receive antennas. Therefore, in this contribution, we propose a new soft-decision-aided DAPSK detection method, which achieves optimum DAPSK detection capability at substantially reduced detection complexity. More specifically, we link each a priori soft-input bit to a specific part of the channel's output, so that only a reduced subset of the DAPSK constellation points has to be evaluated by the soft DAPSK detector. Our simulation results demonstrate that the proposed soft DAPSK detector exhibits lower detection complexity than that of independently detecting the amplitude and the phase, whereas the optimal performance of DAPSK detection is retained.",
On hardware Trojan design and implementation at register-transfer level,"There have been a number of hardware Trojan (HT) designs at register-transfer level (RTL) in the literature, which mainly describe their malicious behaviors and trigger mechanisms. Generally speaking, the stealthiness of the HTs is shown with extremely low sensitization probability of the trigger events. In practice, however, based on the fact that HTs are not sensitized with verification test cases (otherwise their malicious behaviors would have manifested themselves), designers could focus on verification corners for HT detection. Consequently, a stealthy HT not only requires to be hard to trigger, but also needs to be able to evade those hardware trust verification techniques based on “unused circuit identification (UCI)”. In this paper, we present new HT design and implementation techniques that are able to achieve the above objectives. In addition, attackers would like to be able to control their HTs easily, which is also considered in the proposed HT design methodology. Experimental results demonstrate that HTs constructed with the proposed technique are both hard to be detected and easy to be controlled when compared to existing HTs shown in the literature.","Hardware,
Design methodology,
Integrated circuit modeling,
Security,
Measurement,
Radiation detectors"
Stick-On Piezoelectromagnetic AC Current Monitoring of Circuit Breaker Panels,"We present a stick-on wireless electric current monitoring system that is designed to measure and report electricity usage from circuit breaker panels in residential and commercial settings. This monitoring system uses piezoelectromagnetic (PEM) AC current sensors to couple to the magnetic fields produced by the current-carrying conductors. The PEM sensors can be easily attached to the surfaces of common circuit breaker panels, facilitating the installation by non-technical individuals. This paper describes the sensing principles and provides an analytical model of the PEM AC sensors. It also presents the architecture for a wireless current monitoring system and describes its implementation for sub-metering a circuit breaker panel in a building at the University of California, Berkeley. The theory and experimental validation of a signal deconvolution and calibration method, essential for extracting signals from cross-coupled magnetic fields, are also included.",
Face recognition with occlusion using Dynamic Image-to-Class Warping (DICW),"A novel approach Dynamic Image-to-Class Warping (DICW) is proposed to deal with partially occluded face recognition in this work. An image is partitioned into sub-patches, which are then concatenated in the raster scan order to form a sequence. A face consists of forehead, eyes, nose, mouth and chin in a natural order and this order does not change despite occlusion or small rotation. Thus, in this work, a face is represented by the aforementioned sequence which contains the order of facial features. Taking the order information into account, DICW computes the distance between a query face and an enrolled person by finding the optimal alignment between the query sequence and all sequences of that person along both time dimension and within-class dimension. Extensive experiments on public face databases with various types of occlusion have verified the effectiveness of the proposed method. In addition, our method, which considers the inherent structure of the face, performs with greater consistency than current methods when the number of enrolled images per person is limited. Our method does not require any training process and has a low computational cost, which makes it applicable for real-world FR applications.",
Accelerated Regularized Estimation of MR Coil Sensitivities Using Augmented Lagrangian Methods,"Several magnetic resonance parallel imaging techniques require explicit estimates of the receive coil sensitivity profiles. These estimates must be accurate over both the object and its surrounding regions to avoid generating artifacts in the reconstructed images. Regularized estimation methods that involve minimizing a cost function containing both a data-fit term and a regularization term provide robust sensitivity estimates. However, these methods can be computationally expensive when dealing with large problems. In this paper, we propose an iterative algorithm based on variable splitting and the augmented Lagrangian method that estimates the coil sensitivity profile by minimizing a quadratic cost function. Our method, ADMM-Circ, reformulates the finite differencing matrix in the regularization term to enable exact alternating minimization steps. We also present a faster variant of this algorithm using intermediate updating of the associated Lagrange multipliers. Numerical experiments with simulated and real data sets indicate that our proposed method converges approximately twice as fast as the preconditioned conjugate gradient method over the entire field-of-view. These concepts may accelerate other quadratic optimization problems.","Coils,
Sensitivity,
Estimation,
Convergence,
Minimization,
Cost function,
Materials"
Improving genetic programming based symbolic regression using deterministic machine learning,"Symbolic regression (SR) is a well studied method in genetic programming (GP) for discovering free-form mathematical models from observed data. However, it has not been widely accepted as a standard data science tool. The reluctance is in part due to the hard to analyze random nature of GP and scalability issues. On the other hand, most popular deterministic regression algorithms were designed to generate linear models and therefore lack the flexibility of GP based SR (GP-SR). Our hypothesis is that hybridizing these two techniques will create a synergy between the GP-SR and deterministic approaches to machine learning, which might help bring the GP based techniques closer to the realm of big learning. In this paper, we show that a hybrid deterministic/GP-SR algorithm outperforms GP-SR alone and the state-of-the-art deterministic regression technique alone on a set of multivariate polynomial symbolic regression tasks as the system to be modeled becomes more multivariate.",
Clock gating based energy efficient ALU design and implementation on FPGA,"In this paper, latch free clock gating techniques is applied in ALU to reduce clock power and dynamic power consumption of ALU. Clock power is 50%, 41.46%, 51.30%, 55.15% and 55.78% of total dynamic power when device operating frequency is 100MHz, 1GHz, 10GHz, 100GHz and 1 THz. After implementation of clock gating techniques in ALU, Clock power reduces to 17.85%, 23.39%, 26.49% and 27.19% of total dynamic power, when device operating frequency is 1GHz, 10GHz, 100GHz and 1 THz. On 1 THz operating frequency, when we use clock gating, there are 72.77% reduction in clock power, 38.88% reduction in IOs power and 44% reduction in dynamic power in compare to power consumption without using clock gating techniques. Target device is 90-nm Spartan-3. There is 14.57% reduction in junction temperature on 10GHz operating frequency in compare to temperature without using clock gating techniques. Clock gating saves power but increases over all area. There is 32.35%, 37.84%, 43.31% and 44% reduction in dynamic current when we use clock gate on 1GHz, 10GHz, 100GHz and 1THz operating frequency respectively.","Clocks,
Logic gates,
Power demand,
Field programmable gate arrays,
Conferences,
Junctions,
Registers"
Addressing the EU Sovereign Ratings Using an Ordinal Regression Approach,"The current European debt crisis has drawn considerable attention to credit-rating agencies' news about sovereign ratings. From a technical point of view, credit rating constitutes a typical ordinal regression problem because credit-rating agencies generally present a scale of risk composed of several categories. This fact motivated the use of an ordinal regression approach to address the problem of sovereign credit rating in this paper. Therefore, the ranking of different classes will be taken into account for the design of the classifier. To do so, a novel model is introduced in order to replicate sovereign rating, based on the negative correlation learning framework. The methodology is fully described in this paper and applied to the classification of the 27 European countries' sovereign rating during the 2007-2010 period based on Standard and Poor's reports. The proposed technique seems to be competitive and robust enough to classify the sovereign ratings reported by this agency when compared with other existing well-known ordinal and nominal methods.",
"Independent Set, Induced Matching, and Pricing: Connections and Tight (Subexponential Time) Approximation Hardnesses","We present a series of almost settled inapproximability results for three fundamental problems. The first in our series is the subexponential-time inapproximability of the independent set problem, a question studied in the area of parameterized complexity. The second is the hardness of approximating the bipartite induced matching problem on bounded-degree bipartite graphs. The last in our series is the tight hardness of approximating the k-hypergraph pricing problem, a fundamental problem arising from the area of algorithmic game theory. In particular, assuming the Exponential Time Hypothesis, our two main results are: For any r larger than some constant, any r-approximation algorithm for the independent set problem must run in at least 2n1-ε/r1+ε time. This nearly matches the upper bound of 2n/r [23]. It also improves some hardness results in the domain of parameterized complexity (e.g., [26], [19]). For any k larger than some constant, there is no polynomial time min{k1-ε, n1/2-ε} time min -approximation algorithm for the k-hypergraph pricing problem , where n is the number of vertices in an input graph. This almost matches the upper bound of min{O(k), Õ(√n) } min (by Balcan and Blum [3] and an algorithm in this paper). We note an interesting fact that, in contrast to n1/2-ε hardness for polynomial-time algorithms, the k-hypergraph pricing problem admits nδ approximation for any δ > 0 in quasi-polynomial time. This puts this problem in a rare approximability class in which approximability thresholds can be improved significantly by allowing algorithms to run in quasi-polynomial time. The proofs of our hardness results rely on unexpectedly tight connections between the three problems. First, we establish a connection between the first and second problems by proving a new graph-theoretic property related to an induced matching number of dispersers. Then, we show that the n1/2-ε hardness of the last problem follows from nearly tight subexponential time inapproximability of the first problem, illustrating a rare application of the second type of inapproximability result to the first one. Finally, to prove the subexponential-time inapproximability of the first problem, we construct a new PCP with several properties; it is sparse and has nearly-linear size, large degree, and small free-bit complexity. Our PCP requires no ground-breaking ideas but rather a very careful assembly of the existing ingredients in the PCP literature.","Approximation methods,
Pricing,
Approximation algorithms,
Complexity theory,
Polynomials,
Bipartite graph,
Upper bound"
Multi-Hop Collaborative Relay Networks with Consideration of Contention Overhead of Relay Nodes in IEEE 802.11 DCF,"In a WLAN setting, the system throughput may be heavily affected by a small number of low data rate clients due to the packet-fairness property provided by IEEE 802.11 DCF. This is regarded as the performance anomaly problem. Client relay is a technology widely adopted to solve this problem. An important issue of client relay is to decide when a client's traffic should be relayed and who relays it. However, the existing protocols fail to consider the overhead introduced by DCF contentions, resulting in an inaccurate performance analysis and lead to wrong decisions for client relay. In this paper, we focus on the performance analysis for multi-hop relay networks with consideration of contention overhead of relay nodes in IEEE 802.11 DCF protocols. The main work of this paper includes: we consider the contention overhead in the performance analytical model of collaborative relay networks. This model is more accurate than the existing models. We present a throughput analytical model that considers different traffic demands of clients for the traffic pattern of relay networks. Extensive simulations have been done in NS-2. The simulation results show that our algorithm is more accurate and achieves higher relay performance, compared with existing methods.","Relays,
Throughput,
IEEE 802.11 Standards,
Analytical models,
Protocols,
Downlink,
Bandwidth"
The Convergence of Machine and Biological Intelligence,"To explore the exciting new domain of brain informatics, we invited several well-known experts to discuss the state of the art, the challenges, the opportunities, and the trends. In ""Creating Human-Level AI by Educating a Child Machine,"" Raj Reddy proposes an architecture for a ""child machine"" that can learn and is teachable. In ""Cyborg Intelligence,"" Zhaohui Wu, Gang Pan, and Nenggan Zheng describe a biological-machine system consisting of both an organic and a computing part. In ""Formal Minds and Biological Brains II: From the Mirage of Intelligence to a Science and Engineering of Consciousness,"" Paul F.M.J. Verschure discusses human-like cognitive architectures and describes the Distributed Adaptive Control (DAC) architecture for perception, cognition, and action. In ""The Challenges of Closed-Loop Invasive Brain-Machine Interfaces,"" Qiaosheng Zhang and Xiaoxiang Zheng discuss the challenges and trends in closed-loop brain-machine interfaces. In ""Neural Signal Processing in Brain-Machine Interfaces,"" Jose C. Principe takes a critical look at the challenges and opportunities of performing computation with pulses, as neurons do. In ""Neuroprosthesis Control via a Noninvasive Hybrid Brain-Computer Interface,"" Alex Kreilinger, Martin Rohm, Vera Kaiser, Robert Leeb, Rüdiger Rupp, and Gernot R. Müller-Putz describe an example of the convergence of biological intelligence and machine intelligence in a hand-elbow neuroprosthesis control unit.","Biology,
Artificial intelligence,
Computer architecture,
Cognition,
Educational institutions,
Market research,
Speech recognition"
In-Network-Processing: Distributed Consensus-Based Linear Estimation,"In a cooperative broadcast scenario, a group of nodes in a network aims to reconstruct a common message. In this paper, we present a new algorithm for distributed consensus-based estimation in such scenarios. Possible applications comprise mobile communication systems and sensor networks. Starting with a least squares estimation problem, the algorithm is developed using techniques from optimization theory. The required communication effort for parallel implementation in a resource-constrained network is estimated and compared to existing approaches. We show that the proposed algorithm requires fewer iterations and a reduced communication overhead per iteration while keeping the estimation accuracy. A modification of the algorithm based on an approximation is presented, which reduces the communication effort even further. All results are corroborated by computer simulations considering different system parameters.","Approximation algorithms,
Estimation,
Least squares approximation,
Algorithm design and analysis,
Mathematical model,
Equations"
Comparing Four Approaches to Generalized Redirected Walking: Simulation and Live User Data,"Redirected walking algorithms imperceptibly rotate a virtual scene and scale movements to guide users of immersive virtual environment systems away from tracking area boundaries. These distortions ideally permit users to explore large and potentially unbounded virtual worlds while walking naturally through a physically limited space. Estimates of the physical space required to perform effective redirected walking have been based largely on the ability of humans to perceive the distortions introduced by redirected walking and have not examined the impact the overall steering strategy used. This work compares four generalized redirected walking algorithms, including Steer-to-Center, Steer-to-Orbit, Steer-to-Multiple-Targets and Steer-to-Multiple+Center. Two experiments are presented based on simulated navigation as well as live-user navigation carried out in a large immersive virtual environment facility. Simulations were conducted with both synthetic paths and previously-logged user data. Primary comparison metrics include mean and maximum distances from the tracking area center for each algorithm, number of wall contacts, and mean rates of redirection. Results indicated that Steer-to-Center out-performed all other algorithms relative to these metrics. Steer-to-Orbit also performed well in some circumstances.","Legged locomotion,
Orbits,
Navigation,
Algorithm design and analysis,
Space vehicles,
Visualization,
Tracking"
"Teaching agile software development at university level: Values, management, and craftsmanship","Agile methodologies have come a long way over the last decade. Several recent surveys show that agile methodologies like Scrum, Extreme Programming and, more recently, Kanban have been successfully adopted by many companies to develop their software. However, the same surveys show that only few of the agile practices are used and even fewer are applied consequently and thoroughly. This is to a great extent due to the lack of skilled personnel. Although teaching agile software development has drawn some attention in recent research and has been discussed in several papers, we do not yet seem to be able to “deliver” the appropriately skilled personnel. What is the reason for this, and more importantly, how can we improve the situation? In this paper we propose a more holistic approach for teaching agile software development, in which the required agile practices and values are not only integrated theoretically into our courses but also practically applied and repeated until they become a habit to our graduates. The proposed concept was realized in a new Software Engineering course held at Zurich University of Applied Sciences during 2012. The evaluation shows very encouraging results, but also leaves some challenges and problems to be solved.","Software,
Documentation,
Programming,
Companies,
Educational institutions,
Software engineering"
Petri Net Representation of Switched Fuzzy Systems,"Switched fuzzy systems can be used to describe the hybrid systems with fuzziness. However, the languages to describe the switching logic and the fuzzy subsystems are, in general, different, and this difference makes the system analysis and implementation hard. In this paper, we use differential Petri net (DPN) as a unified model to represent both the discrete logic and fuzzy dynamic processes. To exam the rationality of the representation, we prove the correctness of the representation for the discrete part and estimate the approximation accuracy of the representation for the dynamic part. Our work provides a way to analyze the switched fuzzy systems by checking the PN and to use the PN model for further system implementation. We demonstrate the benefits of our work via a case study.","Switches,
Fuzzy systems,
Mathematical model,
Analytical models,
Petri nets,
Equations,
Differential equations"
Load Balanced Resampling for Real-Time Particle Filtering on Graphics Processing Units,"The application of particle filters to real-time systems is often limited because of their computational complexity, and hence the use of graphics processing units (GPUs) that contain hundreds of processing elements on a chip is very promising. However, parallel implementations of particle filters with state-of-the-art systematic resampling on a GPU suffer from a severe workload imbalance problem, which results in fluctuation of the computation speed and hinders their application to real-time systems. We analyze the computational load imbalance of the systematic resampling method in conventional implementations, and show that the workload imbalance is proportional to the variance of weights in particle filters. Then, we propose a load balanced particle replication (LBPR) algorithm for systematic resampling, which shows almost constant execution speed and outperforms the conventional algorithm in terms of the worst-case computation time. The proposed algorithm has been implemented on an NVIDIA GTX580 GPU.","Message systems,
Graphics processing unit,
Systematics,
Real-time systems,
Indexes,
Computer architecture,
Computational complexity"
Complete Real Time Solution of the General Nonlinear Filtering Problem Without Memory,"It is well known that the nonlinear filtering problem has important applications in both military and civil industries. The central problem of nonlinear filtering is to solve the Duncan-Mortensen-Zakai (DMZ) equation in real time and in a memoryless manner. In this paper, we shall extend the algorithm developed previously by S.-T. Yau and the second author to the most general setting of nonlinear filterings, where the explicit time-dependence is in the drift term, observation term, and the variance of the noises could be a matrix of functions of both time and the states. To preserve the off-line virtue of the algorithm, necessary modifications are illustrated clearly. Moreover, it is shown rigorously that the approximated solution obtained by the algorithm converges to the real solution in the L1 sense. And the precise error has been estimated. Finally, the numerical simulation support the feasibility and efficiency of our algorithm.","Equations,
Mathematical model,
Real-time systems,
Approximation algorithms,
Algorithm design and analysis,
Approximation methods,
Noise"
Supervised Spatio-Temporal Neighborhood Topology Learning for Action Recognition,"Supervised manifold learning has been successfully applied to action recognition, in which class label information could improve the recognition performance. However, the learned manifold may not be able to well preserve both the local structure and global constraint of temporal labels in action sequences. To overcome this problem, this paper proposes a new supervised manifold learning algorithm called supervised spatio-temporal neighborhood topology learning (SSTNTL) for action recognition. By analyzing the topological characteristics in the context of action recognition, we propose to construct the neighborhood topology using both supervised spatial and temporal pose correspondence information. Employing the property in locality preserving projection (LPP), SSTNTL solves the generalized eigenvalue problem to obtain the best projections that not only separates data points from different classes, but also preserves local structures and temporal pose correspondence of sequences from the same class. Experimental results demonstrate that SSTNTL outperforms the manifold embedding methods with other topologies or local discriminant information. Moreover, compared with state-of-the-art action recognition algorithms, SSTNTL gives convincing performance for both human and gesture action recognition.",
Designing Two-Dimensional Spectrum Auctions for Mobile Secondary Users,"Dynamic spectrum access by non-licensed users has emerged as a promising solution to address the bandwidth scarcity challenge. In a secondary spectrum market, primary users lease chunks of unused spectrum to secondary users. Auctions perform as one of the natural mechanisms for allocating the spectrum, generating an economic incentive for the licensed user to relinquish channels. Existing spectrum auction designs, while taking externality introduced by interference into account, fail to consider the potential mobility of secondary users, which leads to another dimension of externality: mobile communication motivates a secondary user to exclusively occupy a channel, i.e., forbidding channel reuse in its mobility region. In this work, we design two expressive auctions for mobility support, by introducing two-dimensional bids that reject a secondary user's willingness to pay for exclusive and non-exclusive channel usage, for the single-channel and multiple-channel scenarios, respectively. In the outcome of our 2D auctions, a channel is either monopolized or simultaneously reused without interference, whereas a secondary user can be mobile or is regulated to be static. We prove the existence of desirable equilibria in both auctions, where 1/10 and c/7(1+c) of optimal social welfare are guaranteed to be recoverable, respectively (c is the number of channels).","Cost accounting,
Mobile communication,
Interference,
Resource management,
Channel allocation,
Vectors,
Wireless communication"
An integrated model-based diagnosis and repair architecture for ROS-based robot systems,"Autonomous robots are artifacts that comprise a significant number of heterogeneous hardware and software components and interact with dynamic environments. Therefore, there is always a chance of faults at run-time that negatively affect the reliability of the system. In this paper we present a novel diagnosis and repair architecture for ROS-based robot systems. It is an extension to the existing ROS diagnostics stack and follows a model-based diagnosis and repair approach. In the paper we discuss the integrated diagnosis and repair architecture in detail. Moreover, we show its application to an example robot system and report first experimental results. The presented work provides three major contributions: a combination of diagnosis and repair, the integration of hardware and software, and the integration into ROS.",
Single Relay Selection Schemes for Broadcast Networks,"Achieving the goal of reliably delivering data to all nodes in broadcast wireless networks is very challenging since wireless channels may experience severe variations in signal strength and channel impairments. To mitigate this problem, one or several relays can be used as collaborators to forward the broadcasted signal to other nodes. In this paper, we propose and investigate several single relay selection schemes in broadcast wireless networks using either selective digital relaying or selective analog relaying. The key idea is to classify the nodes in the considered broadcast network into two sets. A set of ""reliable"" nodes, whose source-node signal-to-noise ratio exceeds a threshold value and a set of ""unreliable"" nodes gathering the remaining ones. Then, one node among ""reliable"" nodes is activated as a relay. We derive closed form expressions of the end-to-end bit error probabilities of some proposed single relay selection schemes for selective digital relaying. The data rate loss due to the cooperation is also studied. Analytical results along with simulations prove that compared to the direct transmission, the single relay selection schemes improve significantly the bit error probability performance of the broadcast network.","wireless channels,
broadcasting,
probability,
relay networks (telecommunication)"
Novel Fractal Feature-Based Multiclass Glaucoma Detection and Progression Prediction,"We investigate the use of fractal analysis (FA) as the basis of a system for multiclass prediction of the progression of glaucoma. FA is applied to pseudo 2-D images converted from 1-D retinal nerve fiber layer data obtained from the eyes of normal subjects, and from subjects with progressive and nonprogressive glaucoma. FA features are obtained using a box-counting method and a multifractional Brownian motion method that incorporates texture and multiresolution analyses. Both features are used for Gaussian kernel-based multiclass classification. Sensitivity, specificity, and area under receiver operating characteristic curve (AUROC) are computed for the FA features and for metrics obtained using wavelet-Fourier analysis (WFA) and fast-Fourier analysis (FFA). The AUROCs that predict progressors from nonprogressors based on classifiers trained using a dataset comprised of nonprogressors and ocular normal subjects are 0.70, 0.71, and 0.82 for WFA, FFA, and FA, respectively. The correct multiclass classification rates among progressors, nonprogressors, and ocular normal subjects are 0.82, 0.86, and 0.88 for WFA, FFA, and FA, respectively. Simultaneous multiclass classification among progressors, nonprogressors, and ocular normal subjects has not been previously described. The novel FA-based features achieve better performance with fewer features and less computational complexity than WFA and FFA.","Kernel,
Support vector machines,
Training,
Retina,
Testing,
Fractals,
Educational institutions"
Neither more nor less: Optimizing thread-level parallelism for GPGPUs,"General-purpose graphics processing units (GPG-PUs) are at their best in accelerating computation by exploiting abundant thread-level parallelism (TLP) offered by many classes of HPC applications. To facilitate such high TLP, emerging programming models like CUDA and OpenCL allow programmers to create work abstractions in terms of smaller work units, called cooperative thread arrays (CTAs). CTAs are groups of threads and can be executed in any order, thereby providing ample opportunities for TLP. The state-of-the-art GPGPU schedulers allocate maximum possible CTAs per-core (limited by available on-chip resources) to enhance performance by exploiting TLP. However, we demonstrate in this paper that executing the maximum possible number of CTAs on a core is not always the optimal choice from the performance perspective. High number of concurrently executing threads might cause more memory requests to be issued, and create contention in the caches, network and memory, leading to long stalls at the cores. To reduce resource contention, we propose a dynamic CTA scheduling mechanism, called DYNCTA, which modulates the TLP by allocating optimal number of CTAs, based on application characteristics. To minimize resource contention, DYNCTA allocates fewer CTAs for applications suffering from high contention in the memory subsystem, compared to applications demonstrating high throughput. Simulation results on a 30-core GPGPU platform with 31 applications show that the proposed CTA scheduler provides 28% average improvement in performance compared to the existing CTA scheduler.","Instruction sets,
Parallel processing,
Kernel,
Graphics processing units,
Pipelines,
Transform coding,
Measurement"
Adaptive Retransmission Scheme for Video Streaming over Content-Centric Wireless Networks,"This paper presents an adaptive retransmission scheme to overcome video packet losses in content-centric wireless networks. Because of in-network caching, the round-trip time (RTT) may fluctuate significantly. A new timeout estimation algorithm is proposed to quickly adjust the timeout value. The sequential hypothesis testing methodology is suggested to provide theoretical bounds on the probabilities of false-positive and false-negative detection rates. By considering the reasons for packet losses, the scheme adaptively controls its retransmission window size. Experimental results demonstrate that the proposed scheme efficiently recovers packet losses under various network conditions.","Streaming media,
Packet loss,
Wireless communication,
Probes,
Estimation,
Protocols"
I-Detectability of Discrete-Event Systems,"State estimation has always been important in discrete-event systems. There are two types of state estimation problems in discrete-event systems: one is to determine the initial state of the system and the other is to determine the current state of the system. In this paper, we investigate the initial state estimation problem. We formulate initial state estimation problem as I-detectability. A discrete-event system is strongly I-detectable if we can determine the initial state of the system after a finite number of event observations for all trajectories of the system. It is weakly I-detectable if we can determine the initial state of the system for some trajectories of the system. We construct I-observer to analyze strong and weak I-detectability and construct I-detector to check strong I-detectability. For some applications, strong I-detectability is required but not satisfied; hence we investigated how to control a system to achieve strong I-detectability if needed. If there exists a controllable, observable, and strongly I-detectable sublanguage, then we say the system is closed-loop strongly I-detectable. We derive an effective algorithm to check whether a system is closed-loop strongly I-detectable. The algorithm can also calculate a controllable, observable, and strongly I-detectable sublanguage if the system is closed-loop strongly I-detectable.","Discrete event systems,
Observability,
State estimation,
Closed loop systems,
Controllability"
Learning environmental knowledge from task-based human-robot dialog,"This paper presents an approach for learning environmental knowledge from task-based human-robot dialog. Previous approaches to dialog use domain knowledge to constrain the types of language people are likely to use. In contrast, by introducing a joint probabilistic model over speech, the resulting semantic parse and the mapping from each element of the parse to a physical entity in the building (e.g., grounding), our approach is flexible to the ways that untrained people interact with robots, is robust to speech to text errors and is able to learn referring expressions for physical locations in a map (e.g., to create a semantic map). Our approach has been evaluated by having untrained people interact with a service robot. Starting with an empty semantic map, our approach is able ask 50% fewer questions than a baseline approach, thereby enabling more effective and intuitive human robot dialog.","Robots,
Knowledge based systems,
Grounding,
Speech,
Speech recognition,
Semantics,
Natural languages"
Comparing different LTE scheduling schemes,"Long Term Evolution (LTE) is a cellular technology developed to support diversity of data traffic at potentially high rates. 3GPP's LTE is defined by the standardization body's Release 8 and 9. A key mechanism in the LTE traffic handling is the packet scheduler, which is in charge of allocating resources to active flows in both the frequency and time dimension. The scheduling scheme used largely impacts the throughput of individual users as well as throughput of the cell. It is worthwhile to evaluate the throughput and fairness conditions for different scheduling schemes before the actual deployment of LTE scheduler. Our main contribution in this study is to evaluate and compare the performance of six scheduling schemes designed for LTE network in terms of user's throughput and fairness. The findings from our performance evaluation presented to draw conclusions on the performance of the six schedulers, and point out the strengths and weakness that are common to schedulers under study. This would help design the scheme of the scheduler at the eNodeB appropriately.","Throughput,
Signal to noise ratio,
Long Term Evolution,
Scheduling,
Radio frequency,
OFDM,
Scheduling algorithms"
Automatic Distortion Correction of Endoscopic Images Captured With Wide-Angle Zoom Lens,"Operation in minimally invasive surgery is more difficult since the surgeons perform operations without haptic feedback or depth perception. Moreover, the field of view perceived by the surgeons through endoscopy is usually quite limited. The goal of this paper is to allow surgeons to see wide-angle images from endoscopy without the drawback of lens distortion. The proposed distortion correction process consists of lens calibration and real-time image warping. The calibration step is to estimate the parameters in the lens distortion model. We propose a fully automatic Hough-entropy-based calibration algorithm, which provides calibration results comparable to the previous manual calibration method. To achieve real-time correction, we use graphics processing unit to warp the image in parallel. In addition, surgeons may adjust the focal length of a lens during the operation. Real-time distortion correction of a zoomable lens is impossible by using traditional calibration methods because the tedious calibration process has to repeat again if focal length is changed. We derive a formula to describe the relationship between the distortion parameter, focal length, and image boundary. Hence, we can estimate the focal length for a zoomable lens from endoscopic images online and achieve real-time lens distortion correction.",
Objective Assessment of Sonographic Quality I: Task Information,"In this paper, we explore relationships between the performance of the ideal observer and information-based measures of class separability in the context of sonographic breast-lesion diagnosis. This investigation was motivated by a finding that, since the test statistic of the ideal observer in sonography is a quadratic function of the echo data, it is not generally normally distributed. We found for some types of boundary discrimination tasks often required for sonographic lesion diagnosis, the deviation of the test statistic from a normal distribution can be significant. Hence the usual relationships between performance and information metrics become uncertain. Using Monte Carlo studies involving five common sonographic lesion-discrimination tasks, we found in each case that the detectability index dA2 from receiver operating characteristic analysis was well approximated by the Kullback-Leibler divergence J, a measure of clinical task information available from the recorded radio-frequency echo data. However, the lesion signal-to-noise ratio, SNRI2, calculated from moments of the ideal observer test statistic, consistently underestimates dA2 for high-contrast boundary discrimination tasks. Thus, in a companion paper, we established a relationship between image-quality properties of the imaging system and J in order to predict ideal performance. These relationships provide a rigorous basis for sonographic instrument evaluation and design.","Observers,
Lesions,
Measurement,
Radio frequency,
Imaging,
Vectors,
Noise"
An empirical study based on a fuzzy logic system to assess the QoS/QoE correlation for layered video streaming,"A model that can predict an end user satisfaction or QoE (Quality of Experience) directly from the network QoS (Quality of Service) is still illusive in the field of image processing and is completely absent in multi-layered video. This motivates the derivation of a meaningful QoS to QoE mapping function to allow one to be predicted in the absence of the other. This paper presents an affine fuzzy logic based system that can map the QoS to QoE and can be extended to layered video streaming. The proposed methodology employs a learning system which optimizes the coded layered video for best QoE. Four QoS parameters are chosen as the inputs of the designed model, while the output is the Peak Signal-to-Noise Ratio (PSNR). The designed membership functions and the fuzzy rules extracted from the input and the output enable the proposed model to identify and learn the video QoE.","Decision support systems,
Hafnium"
A dataset from change history to support evaluation of software maintenance tasks,"Approaches that support software maintenance need to be evaluated and compared against existing ones, in order to demonstrate their usefulness in practice. However, oftentimes the lack of well-established sets of benchmarks leads to situations where these approaches are evaluated using different datasets, which results in biased comparisons. In this data paper we describe and make publicly available a set of benchmarks from six Java applications, which can be used in the evaluation of various software engineering (SE) tasks, such as feature location and impact analysis. These datasets consist of textual description of change requests, the locations in the source code where they were implemented, and execution traces. Four of the benchmarks were already used in several SE research papers, and two of them are new. In addition, we describe in detail the methodology used for generating these benchmarks and provide a suite of tools in order to encourage other researchers to validate our datasets and generate new benchmarks for other subject software systems. Our online appendix: http://www.cs.wm.edu/semeru/data/msr13/.","Gold,
Java,
Software systems,
Benchmark testing,
Software maintenance,
Large scale integration"
Large-Eddy Simulations of Turbulent Incompressible Flows on GPU Clusters,"A dual-level parallel incompressible flow solver accelerates turbulent flow computations on GPU clusters. This approach solves the pressure Poisson equation with a full-depth, amalgamated parallel geometric multigrid method, and implements a Lagrangian dynamic model for subgrid-scale turbulence modeling.","Mathematical model,
Graphics processing unit,
Computational modeling,
Numerical models,
Jacobian matrices,
Computational fluid dynamics,
Fluidics"
Decentralized control for maintenance of strong connectivity for directed graphs,"In order to accomplish cooperative tasks, decentralized systems are required to communicate among each other. Thus, maintaining the connectivity of the communication graph is a fundamental issue. Connectivity maintenance has been extensively studied in the last few years, but generally considering undirected communication graphs. In this paper we introduce a decentralized control and estimation strategy to maintain the strong connectivity property of directed communication graphs. The control strategy is initially developed for balanced digraphs, and is then extended to generic strongly connected digraphs, introducing a decentralized balancing algorithm. The control strategy is validated by means of analytical proofs and simulation results.","Maintenance engineering,
Laplace equations,
Estimation,
Robots,
Protocols,
Computer architecture,
Decentralized control"
Dummy Gate-Assisted n-MOSFET Layout for a Radiation-Tolerant Integrated Circuit,"A dummy gate-assisted n-type metal oxide semiconductor field effect transistor (DGA n-MOSFET) layout was evaluated to demonstrate its effectiveness at mitigating radiation-induced leakage currents in a conventional n-MOSFET. In the proposed DGA n-MOSFET layout, radiation-induced leakage currents are settled by isolating both the source and drain from the sidewall oxides using a p+ layer and dummy gates. Moreover, the dummy gates and dummy Metal-1 layers are expected to suppress the charge trapping in the sidewall oxides. The inherent structure of the DGA n-MOSFET supplements the drawbacks of the enclosed layout transistor, which is also proposed in order to improve radiation tolerance characteristics. The Vg-Id simulation results of the DGA n-MOSFET layout demonstrated the effectiveness of eliminating such radiation-induced leakage current paths. Furthermore, the radiation exposure experimental results obtained with the fabricated DGA n-MOSFET layout also exhibited good performance with regard to the total ionizing dose tolerance.",
Efficient Software Reliability Analysis With Correlated Component Failures,"Correlated component failures (COCOF) may impact the reliability of a software application, and hence these types of failures must be explicitly incorporated into reliability analysis. The influence of COCOF on application reliability must be analyzed within the context of the application architecture. Contemporary reliability analysis approaches that incorporate COCOF, however, cannot scale to even moderate-sized software applications. This paper presents an efficient, scalable approach to analyze the reliability of a component-based software system, considering COCOF within the context of its architecture. The effectiveness of the approach is illustrated through two experimental studies. The results indicate that the approach is simple and efficient, and hence can be applied to large systems to identify correlations that impede system reliability.","Correlation,
Software reliability,
Computer architecture,
Software systems,
Encoding"
Integrating Reservations and Queuing in Remote Laboratory Scheduling,"Remote laboratories (RLs) have become increasingly seen as a useful tool in supporting flexible shared access to scarce laboratory resources. An important element in supporting shared access is coordinating the scheduling of the laboratory usage. Optimized scheduling can significantly decrease access waiting times and improve the utilization level of RL resources, with associated reductions in per-use costs. Current RL systems have typically supported scheduling based on either reservations or queuing, though rarely both. In this paper, we investigate issues that arise when a single RL resource (or pool of resources) supports both modes for gaining access, and how these two approaches can be effectively integrated. This research analyzes the scheduling algorithm utilized by the Sahara RL system to investigate any limitations that affect the system utilization. We identify a number of current issues and propose specific modifications to address them. The proposed modifications will lead to increased utilization and improved student experiences.","Remote laboratories,
Scheduling,
Computer aided instruction,
Computer architecture,
Scheduling algorithms,
Resource management,
Electronic learning,
Education"
Homogenization of Maxwell's Equations in Lossy Biperiodic Metamaterials,A novel homogenization technique is proposed for computing the quasi-static effective parameters of the lossy bi-periodic artificial structure materials. This technique is based on the Floquet's Theorem which allows reducing the studied domain to the elementary cell with pseudo-periodic conditions on the lateral sides. The studied domain is extended by adding a vacuum layer in order to impose correctly the Silver-Müler absorbing boundary condition. This homogenization technique is a numerical method using the Finite Element Method and based on the evaluation of the macroscopic fields by averaging the local fields on the elementary cell. The effective constitutive parameters are obtained from the macroscopic fields and inductions. The numerical validation of this approach is presented in 2D and 3D by computing the effective conductivities for square cylinders and cubes suspended in a host isotropic medium. The obtained results are compared to our previous approach based on Unfolding Method and Finite Element Method (UFEM). On the one hand this technique can be applied to homogenize any bi-periodic metamaterial with elementary cells having inclusions of arbitrary geometry and on the other hand it takes into account the effect of the inclusions shape on the effective parameters.,"Conductivity,
Finite element analysis,
Boundary conditions,
Electromagnetics,
Maxwell equations,
Metamaterials"
Transmit-Only Ultra Wide Band Body Sensors and Collision Analysis,"Ultra wide band (UWB) stands out from other wireless technologies used for wireless physiological signal monitoring due to its low power transmitter, immunity from interference, small sized antenna, and high data rate. Although a UWB transmitter has low power consumption, the UWB receiver is generally complex and consumes more power. This paper investigates the use of a transmit-only mechanism for data transfer in wireless body area network (WBAN) applications. A transmit-only medium access control mechanism that can be used in low-power WBANs is developed. Detailed attention is given to the simulation-based analysis of collisions between data which occur in such a scheme. A performance enhancement scheme is suggested to achieve optimum data transmission. Results are validated using a hardware implementation of the proposed system.","Receivers,
Logic gates,
Sensor systems,
Power demand,
Hardware,
Bit error rate"
Scalable Digital CMOS Comparator Using a Parallel Prefix Tree,"We present a new comparator design featuring wide-range and high-speed operation using only conventional digital CMOS cells. Our comparator exploits a novel scalable parallel prefix structure that leverages the comparison outcome of the most significant bit, proceeding bitwise toward the least significant bit only when the compared bits are equal. This method reduces dynamic power dissipation by eliminating unnecessary transitions in a parallel prefix structure that generates the N-bit comparison result after (log4 N)+(log16N)+4 CMOS gate delays. Our comparator is composed of locally interconnected CMOS gates with a maximum fan-in and fan-out of five and four, respectively, independent of the comparator bitwidth. The main advantages of our design are high speed and power efficiency, maintained over a wide range. Additionally, our design uses a regular reconfigurable VLSI topology, which allows analytical derivation of the input-output delay as a function of bitwidth. HSPICE simulation for a 64-b comparator shows a worst case input-output delay of 0.86 ns and a maximum power dissipation of 7.7 mW using 0.15- μm TSMC technology at 1 GHz.",
Gamification-based assessment of group work,"The importance and benefit of group work is nowadays widely recognized and acknowledged in education. Group work can be supported by online shared workspaces that allow group collaboration. However, the e-assessment of group work remains an issue. Most of the existing strategies rely on intra-group peer assessment to evaluate individual contribution to group work. We propose an alternative by introducing some gamification components. The assessment of students' individual involvement and performance is then shifted to the engagement of students to contribute and participate into a learning community. The goal is to create an enabling environment to stimulate learning by peer sharing and formative feedback. This paper describes the approach, the online learning platform and some of the latest results.","Collaboration,
Educational institutions,
Seminars,
Communities,
Collaborative work,
Standards"
Further results on optimal signaling over secure MIMO channels,"Optimal signalling over the wire-tap MIMO Gaussian channel is studied under the total transmit power constraint. The recent results are extended in several directions, including a rank-deficient solution for the optimal covariance, lower and upper capacity bounds for the general case, and characterization of optimality of the isotropic signaling. An isotropic eavesdropper model is studied, which provides (tight) upper and lower capacity bounds for the non-isotropic case and also serves as the worst-case scenario. The optimal signaling for this model is obtained in an explicit form and its properties are studied, including the high and low-SNR behavior, the conditions for the eavesdropper to be negligible and the capacity saturation effect.","Signal to noise ratio,
MIMO,
Eigenvalues and eigenfunctions,
Resource management,
Transmitters,
Information theory,
Educational institutions"
Removing Ballistocardiogram Artifact From EEG Using Short- and Long-Term Linear Predictor,"In this paper, a novel source extraction method is proposed for removing ballistocardiogram (BCG) artifact from EEG. BCG appears in EEG signals recorded simultaneously with functional magnetic resonance imaging. The proposed method is a semiblind source extraction algorithm based on linear prediction technique. We define a cost function according to a joint short- and long-term prediction strategy to extract the BCG sources. We call this method SLTP-BSE standing for short- and long-term prediction blind source extraction. The objective of this work is to 1) model the temporal structure of the sources using short-term prediction and 2) impose the prior information about the BCG sources using long-term prediction. These two procedures are simultaneously implemented to optimize the system. The performance of the proposed method is evaluated using both synthetic and real EEG data. The obtained results show that the proposed technique is able to remove the BCG artifact while preserving the task-related parts of the signal. The results of SLTP-BSE are compared with those of well-known BCG removal techniques confirming the superiority of the proposed method.",
Transmural Imaging of Ventricular Action Potentials and Post-Infarction Scars in Swine Hearts,"The problem of using surface data to reconstruct transmural electrophysiological (EP) signals is intrinsically ill-posed without a unique solution in its unconstrained form. Incorporating physiological spatiotemporal priors through probabilistic integration of dynamic EP models, we have previously developed a Bayesian approach to transmural electrophysiological imaging (TEPI) using body-surface electrocardiograms. In this study, we generalize TEPI to using electrical signals collected from heart surfaces, and we test its feasibility on two pre-clinical swine models provided through the STACOM 2011 EP simulation Challenge. Since this new application of TEPI does not require whole-body imaging, there may be more immediate potential in EP laboratories where it could utilize catheter mapping data and produce transmural information for therapy guidance. Another focus of this study is to investigate the consistency among three modalities in delineating scar after myocardial infarction: TEPI, electroanatomical voltage mapping (EAVM), and magnetic resonance imaging (MRI). Our preliminary data demonstrate that, compared to the low-voltage scar area in EAVM, the 3-D electrical scar volume detected by TEPI is more consistent with anatomical scar volume delineated in MRI. Furthermore, TEPI could complement anatomical imaging by providing EP functional features related to both scar and healthy tissue.","Mathematical model,
Equations,
Heart,
Myocardium,
Solid modeling,
Magnetic resonance imaging,
Computational modeling"
Novel Biobjective Clustering (BiGC) Based on Cooperative Game Theory,"We propose a new approach to clustering. Our idea is to map cluster formation to coalition formation in cooperative games, and to use the Shapley value of the patterns to identify clusters and cluster representatives. We show that the underlying game is convex and this leads to an efficient biobjective clustering algorithm that we call BiGC. The algorithm yields high-quality clustering with respect to average point-to-center distance (potential) as well as average intracluster point-to-point distance (scatter). We demonstrate the superiority of BiGC over state-of-the-art clustering algorithms (including the center based and the multiobjective techniques) through a detailed experimentation using standard cluster validity criteria on several benchmark data sets. We also show that BiGC satisfies key clustering properties such as order independence, scale invariance, and richness.","Games,
Clustering algorithms,
Resource management,
Data models,
Analytical models,
Heuristic algorithms,
Game theory"
Data Scientists Aren't Domain Experts,It will take a lot of conversation to make data science work. Data scientists can't do it on their own. Success in data science requires a multiskilled project team with data scientists and domain experts working closely together.,"Information science,
Knowledge management,
Information analysis,
Business"
Profit-Optimal and Stability-Aware Load Curtailment in Smart Grids,"A key feature of future smart grids is demand response. With the integration of a two-way communication infrastructure, a smart grid allows its operator to monitor the production and usage of power in real time. Upon detection of significant events, the operator may send requests to intelligent loads to curtail their power usage. The operator can use load curtailments reactively for adaptation to the loss of generation capacity (e.g., with unpredictable renewable energy sources), or proactively for profit maximization by avoiding the use of expensive energy sources during peak hours. In this paper, we optimize operator profits for the different cases of load curtailment, under various practical constraints including the physical properties of the power system, and different cost and valuation functions for heterogeneous generation units and loads, respectively. We also investigate the requirements imposed by different cases of the load curtailment on the cyber infrastructure. In particular, we evaluate how the delay of cyber control impacts the frequency stability of the power grid during the load curtailment phase.","Cost accounting,
Power system stability,
Pricing,
Smart grids,
Stability analysis,
Load modeling,
Cost function"
Wildfire Smoke Detection Using Computational Intelligence Techniques Enhanced With Synthetic Smoke Plume Generation,"An early wildfire detection is essential in order to assess an effective response to emergencies and damages. In this paper, we propose a low-cost approach based on image processing and computational intelligence techniques, capable to adapt and identify wildfire smoke from heterogeneous sequences taken from a long distance. Since the collection of frame sequences can be difficult and expensive, we propose a virtual environment, based on a cellular model, for the computation of synthetic wildfire smoke sequences. The proposed detection method is tested on both real and simulated frame sequences. The results show that the proposed approach obtains accurate results.","Feature extraction,
Mathematical model,
Computational modeling,
Equations,
Computational intelligence,
Algorithm design and analysis,
Image color analysis"
Analysis of the reputation system and user contributions on a question answering website: StackOverflow,"Question answering (Q&A) communities have been gaining popularity in the past few years. The success of such sites depends mainly on the contribution of a small number of expert users who provide a significant portion of the helpful answers, and so identifying users that have the potential of becoming strong contributers is an important task for owners of such communities. We present a study of the popular Q&A website StackOverflow (SO), in which users ask and answer questions about software development, algorithms, math and other technical topics. The dataset includes information on 3.5 million questions and 6.9 million answers created by 1.3 million users in the years 2008-2012. Participation in activities on the site (such as asking and answering questions) earns users reputation, which is an indicator of the value of that user to the site. We describe an analysis of the SO reputation system, and the participation patterns of high and low reputation users. The contributions of very high reputation users to the site indicate that they are the primary source of answers, and especially of high quality answers. Interestingly, we find that while the majority of questions on the site are asked by low reputation users, on average a high reputation user asks more questions than a user with low reputation. We consider a number of graph analysis methods for detecting influential and anomalous users in the underlying user interaction network, and find they are effective in detecting extreme behaviors such as those of spam users. Lastly, we show an application of our analysis: by considering user contributions over first months of activity on the site, we predict who will become influential long-term contributors.","Communities,
Social network services,
Knowledge engineering,
Blogs,
Conferences,
Electronic mail,
Computer science"
Throughput and Stability for Relay-Assisted Wireless Broadcast with Network Coding,"The throughput and stability properties of wireless network coding are evaluated for an arbitrary number of terminals exchanging broadcast traffic with the aid of a relay. First, coding and scheduling schemes are derived that minimize the number of transmissions needed for each node to broadcast one packet. For stochastically varying traffic, the stable throughput is then compared under both digital and analog network coding schemes. The initial analysis focuses on a network with a single relay. Extensions to arbitrary terminal-relay configurations are then outlined for a general multihop network. Backpressure-like algorithms for jointly achieving throughput optimal scheduling and network coding are given for each network coding scheme.",
The effect of client buffer and MBR consideration on DASH Adaptation Logic,"DASH is new ISO/IEC MPEG and 3GPP standard for HTTP multimedia streaming that begins to be widely accepted in the industry. DASH is design to be flexible and support various multimedia formats. DASH unify the proprietary adaptive streaming solutions and suggests differing between them by using different behavioral approaches, each one best suited for the specific streaming application. Each behavior is determined by Adaptation Logic (AL), which decides according to the estimation of the network conditions and buffer state what is the best suitable segment to be requested from the streaming server. This work presents the drawback of current DASH standard and its vulnerability to variable bit rate stream encoding. We have found that the advertised bit rate for each quality layer that was dictated by the Media Presentation Description (MPD) isn't accurate for VBR streaming. Moreover, we suggest an Adaptive Buffer Moving Median (ABMM) buffer sensitive adaptation logic that will support its bandwidth estimation decisions based on the client buffer redundancy. The new method was found to be suitable for mobile network traffic which is characterized with large fluctuations with network bandwidth. Our proposed solution showed more than 20 percent better average PSNR improvement compared to the original VLC plug-in rate adaptation logic.","Bit rate,
Bandwidth,
Estimation,
Streaming media,
Servers,
Standards,
Multimedia communication"
Spectral defragmentation in elastic optical path networks using independent sets,Spectral fragmentation in elastic optical networks decreases the spectral efficiency and increases the request blocking. We propose a novel auxiliary graph model and spectral defragmentation technique using independent sets to efficiently consolidate the spectrum allocation.,
A new framework to integrate wireless sensor networks with cloud computing,"Wireless sensors networks have several applications of their own. These applications can further enhanced by integrating a local wireless sensor network to internet, which can be used in real time applications where the results of sensors are stored on the cloud. We propose an architecture that integrates a wireless sensor network to the internet using cloud technology. The resultant system is proved to be reliable, available and extensible. In this paper a new framework is proposed for WSN integration with Cloud computing model, existing WSN will be connected to the proposed framework. Three deployment layer are used to serve user request (IaaS, PaaS, SaaS) either from the library which is made from data collected from data centric DC by WSN periodically. The integration controller unit of the proposed framework integrates the sensor network and cloud computing technology which offers reliability, availability and extensibility.","Wireless sensor networks,
Military computing,
Mobile communication,
Airports,
Software as a service,
Oceans"
Application of Microfluidic Device for Lactic Biosensor,"In this paper, the RuO2 sensing film is fabricated by the sputtering system, and the miniature reference electrode is fabricated by the screen printed technique for integrating the RuO2 thin film in the array flexible sensor. Furthermore, the computer numerical control technique is used to fabricate the stainless model of the fluidic channel, and polydimethylsiloxane is used as the material of the fluidic channel. Finally, the array flexible sensor is integrated fluidic channel to form the potentiometric biosensor of the fluidic. The property of the fluidic channel is analyzed by differential pressure meter to measure the pressure drop and discuss the effect of related factors. In this paper, the RuO2 based pH sensor can obtain a higher sensing value at 61.3 mV/pH with super-Nernstian response. Besides, due to silver's excellent stability and conductivity, the miniature reference electrode is fabricated by screen printed technique to fix silver at the polyethylene terephthalate substrate. The sensitivities of the sensor of 61.31, 59.65, and 56.45 mV/pH with flow rates of 10, 20, and 30 ml/min, respectively, are obtained. The experimental result demonstrates that the potentiometric biosensor can be applied to detect the fluidic concentration.","Electrodes,
Sensitivity,
Biosensors,
Films,
Positron emission tomography,
Microfluidics"
An automatic 3D expression recognition framework based on sparse representation of conformal images,"We propose a general and fully automatic framework for 3D facial expression recognition by modeling sparse representation of conformal images. According to Riemann Geometry theory, a 3D facial surface S embedded in ℝ3, which is a topological disk, can be conformally mapped to a 2D unit disk D through the discrete surface Ricci Flow algorithm. Such a conformal mapping induces a unique and intrinsic surface conformal representation denoted by a pair of functions defined on D, called conformal factor image (CFI) and mean curvature image (MCI). As facial expression features, CFI captures the local area distortion of S induced by the conformal mapping; MCI characterizes the geometry information of S. To model sparse representation of conformal images for expression classification, both CFI and MCI are further normalized by a Mobius transformation. This transformation is defined by the three main facial landmarks (i.e. nose tip, left and right inner eye corners) which can be detected automatically and precisely. Expression recognition is carried out by the minimal sparse expression-class-dependent reconstruction error over the conformal image based expression dictionary. Extensive experimental results on the BU-3DFER dataset demonstrate the effectiveness and generalization of the proposed framework.",
The Elimination of Spatial-Temporal Uncertainty in Underwater Sensor Networks,"Since data in underwater sensor networks (UWSNs) is transmitted by acoustic signals, the characteristics of a UWSN are different from those of a terrestrial sensor network. Specifically, due to the high propagation delay of acoustic signals in UWSNs, referred as spatial-temporal uncertainty, current terrestrial MAC schemes do not work well in UWSNs. Hence, we consider spatial-temporal uncertainty in the design of an energy-efficient TDMA-based MAC protocol for UWSNs. We first translate the TDMA-based scheduling problem in UWSNs into a special vertex-coloring problem in the context of a spatial-temporal conflict graph (ST-CG) that describes explicitly the conflict delays among transmission links. With the help of the ST-CG, we propose two novel heuristic approaches: 1) the traffic-based one-step trial approach (TOTA) to solve the coloring problem in a centralized fashion; and for scalability, 2) the distributed traffic-based one-step trial approach (DTOTA) to assign the data schedule for tree-based routing structures in a distributed manner. In addition, a mixed integer linear programming (MILP) model is derived to obtain a theoretical bound for the TDMA-based scheduling problem in UWSNs. Finally, a comprehensive performance study is presented, showing that both TOTA and DTOTA guarantee collision-free transmission. They thus outperform existing MAC schemes such as S-MAC, ECDiG, and T-Lohi in terms of network throughput and energy consumption.","Propagation delay,
Schedules,
Delay,
Routing,
Uncertainty,
Acoustics,
Topology"
A syllable-based framework for unit selection synthesis in 13 Indian languages,"In this paper, we discuss a consortium effort on building text to speech (TTS) systems for 13 Indian languages. There are about 1652 Indian languages. A unified framework is therefore attempted required for building TTSes for Indian languages. As Indian languages are syllable-timed, a syllable-based framework is developed. As quality of speech synthesis is of paramount interest, unit-selection synthesizers are built. Building TTS systems for low-resource languages requires that the data be carefully collected an annotated as the database has to be built from the scratch. Various criteria have to addressed while building the database, namely, speaker selection, pronunciation variation, optimal text selection, handling of out of vocabulary words and so on. The various characteristics of the voice that affect speech synthesis quality are first analysed. Next the design of the corpus of each of the Indian languages is tabulated. The collected data is labeled at the syllable level using a semiautomatic labeling tool. Text to speech synthesizers are built for all the 13 languages, namely, Hindi, Tamil, Marathi, Bengali, Malayalam, Telugu, Kannada, Gujarati, Rajasthani, Assamese, Manipuri, Odia and Bodo using the same common framework. The TTS systems are evaluated using degradation Mean Opinion Score (DMOS) and Word Error Rate (WER). An average DMOS score of ≈3.0 and an average WER of about 20 % is observed across all the languages.","Speech,
Buildings,
Speech synthesis,
Dictionaries,
Labeling,
Synthesizers,
Optimization"
Using Game-Based Cooperative Learning to Improve Learning Motivation: A Study of Online Game Use in an Operating Systems Course,"Many researchers have studied the use of game-based learning. Game-based learning takes many forms, including virtual reality, role playing, and performing tasks. For students to learn specific course content, it is important that the selected game be suited to the course. Thus far, no studies have investigated the use of game-based cooperative learning in an operating systems course. For this study, an online game was developed to enable students to learn cooperatively. The findings indicate that students' desire to win the game motivates them to learn from online course materials before they play, which in turn can enable them to achieve better learning outcomes.","Virtual reality,
Human computer interaction,
Operating systems,
Computer aided instruction,
Computer science education"
Image Super-Resolution Via Analysis Sparse Prior,"In this letter, we present a new algorithm for a single image super-resolution using the analysis sparse prior in the lαβ color space. Experimental results show that our algorithm outperforms other existing state-of-the-art methods. In addition, due to the high scalability of our algorithm, key modules of the proposed algorithm can be integrated with other super resolution algorithms.","Analytical models,
Algorithm design and analysis,
Image resolution,
Image color analysis,
Image reconstruction,
Dictionaries,
Electronic mail"
The Infinite-Message Limit of Two-Terminal Interactive Source Coding,"A two-terminal interactive function computation problem with alternating messages is studied within the framework of distributed block source coding theory. For any finite number of messages, a single-letter characterization of the sum-rate-distortion function was established in previous works using standard information-theoretic techniques. This, however, does not provide a satisfactory characterization of the infinite-message limit, which is a new, unexplored dimension for asymptotic analysis in distributed block source coding involving potentially an infinite number of infinitesimal-rate messages. In this paper, the infinite-message sum-rate-distortion function, viewed as a functional of the joint source distribution and the distortion levels, is characterized as the least element of a partially ordered family of functionals having certain convex-geometric properties. The new characterization does not involve evaluating the infinite-message limit of a finite-message sum-rate-distortion expression. This characterization leads to a family of lower bounds for the infinite-message sum-rate-distortion expression and a simple criterion to test the optimality of any achievable infinite-message sum-rate-distortion expression. The new convex-geometric characterization is used to develop an iterative algorithm for evaluating any finite-message sum-rate-distortion function. It is also used to construct the first examples which demonstrate that for lossy source reproduction, two messages can strictly improve the one-message Wyner-Ziv rate-distortion function settling an unresolved question from a 1985 paper. It is shown that a single backward message of arbitrarily small rate can lead to an arbitrarily large gain in the sum-rate.","Joints,
Random variables,
Source coding,
Rate-distortion,
Optimization,
Iterative methods"
An Efficient Optimization Framework for Multi-Region Segmentation Based on Lagrangian Duality,"We introduce a multi-region model for simultaneous segmentation of medical images. In contrast to many other models, geometric constraints such as inclusion and exclusion between the regions are enforced, which makes it possible to correctly segment different regions even if the intensity distributions are identical. We efficiently optimize the model using a combination of graph cuts and Lagrangian duality which is faster and more memory efficient than current state of the art. As the method is based on global optimization techniques, the resulting segmentations are independent of initialization. We apply our framework to the segmentation of the left and right ventricles, myocardium and the left ventricular papillary muscles in magnetic resonance imaging and to lung segmentation in full-body X-ray computed tomography. We evaluate our approach on a publicly available benchmark with competitive results.","Image segmentation,
Optimization,
Muscles,
Biomedical imaging,
Heart,
Computational modeling,
Labeling"
I-LEACH: An efficient routing algorithm to improve performance & to reduce energy consumption in Wireless Sensor Networks,"A large amount of energy in nodes of a Wireless Sensor Network (WSN) is consumed due to the inner-network communications. In this paper, an energy efficient routing algorithm is proposed which saves a significant portion of inner-network communications energy. To do this, the proposed routing algorithm selects sensor nodes with higher residual energy, more neighbors, and lower distance from the Base Station (BS) as Cluster Head (CH) nodes. Then, it manages sensor nodes appropriately and constructs clusters such a way to maximize WSN lifetime and minimize average energy dissipation per each sensor node. To evaluate the proposed routing algorithm, various simulations have been carried out by using of MATLAB simulator. The proposed routing algorithm is compared to the previous proposed algorithms e.g., LEACH, DBS, and LEACH-C algorithms. Results of the simulations show that the proposed routing algorithm has been improved the WSN performance at least 65%, reduces the energy consumption of the WSN up to 62%, and improves the successfully delivered packet ratio by at least 56% as compared to the previous routing algorithms.",
Impact of Supply Voltage and Frequency on the Soft Error Rate of Logic Circuits,"Alpha particle irradiations of 28-nm combinational logic and flip-flop circuits under different supply voltage and frequency operating conditions are investigated. Results indicate that while the supply voltage has a strong impact on the alpha particle soft error rate of flip-flops, the combinational logic error rate is relatively unaffected by supply voltage variation. Simulations are used to explain the results and highlight the differences between low-LET alpha particle irradiation and heavy-ion irradiation as far as voltage dependence of the logic soft error rate is concerned. Moreover, frequency has a much stronger impact on the logic soft error rate as compared to the flip-flop soft error rate. As a result, the frequency at which soft errors from combinational logic circuits will exceed errors from flip-flops decreases as the voltage increases. The impact of these observations is discussed in the context of soft-error mitigation strategies.","Flip-flops,
Alpha particles,
Transient analysis,
Error analysis,
Inverters,
Combinational circuits,
Logic gates"
An MDE Approach for Automatic Code Generation from UML/MARTE to OpenCL,"To reduce the design complexity of OpenCL programming, the approach proposed here generates application code automatically, based on model-driven engineering (MDE) and modeling and analysis of real-time and embedded (MARTE) systems. The aim is to provide application-development resources for nonspecialists in parallel programming, exploiting concepts such as reuse and platform independence.","Unified modeling language,
Computational modeling,
Computer architecture,
Software engineering,
Resource management,
Parallel programming,
Scientific computing"
Improved Phase-Shift PWM Converter for Larger Sized PDP Slim Sustain Power Module,"New phase-shift pulse width modulation (PWM) converters with a wide zero voltage switching (ZVS) range for the slim sustain power module of over 63-in plasma display panel (PDP) are proposed in this paper. Each proposed converter is composed of two symmetric half-bridge converters (TSHBCs) that are placed in parallel on the primary side and are driven in a phase shifting manner. Two power transformers are connected in series on the secondary side. All the switches in the proposed converters can be turned on with ZVS under all load conditions, while the conduction loss caused by the assistant current source extending the ZVS range can be minimized. Moreover, because the turns ratio of the transformers can be designed to be better than that of the counterparts, the voltage stress across the secondary rectifier diode and the primary conduction loss can be reduced. A low-profile design is also achieved due to the use of the two small-sized transformers, which results in a slim power supply. In this paper, the circuit configurations, operation principle, relevant analysis results, and design example of the proposed converters are presented. Experimental results demonstrate that the proposed converters can achieve a significant improvement in the efficiency for a prototype converter realized with the specification of 80-in PDP sustain power module (320-385 Vdc input, 205 Vdc/5 A output).","Zero voltage switching,
Inductors,
Partial discharges,
Power transformers,
Stress,
Multichip modules,
Power supplies"
Cortical Graph Smoothing: A Novel Method for Exploiting DWI-Derived Anatomical Brain Connectivity to Improve EEG Source Estimation,"The electroencephalography source estimation problem consists of inferring cortical activation from measurements of electrical potential taken on the scalp surface. This inverse problem is intrinsically ill-posed. In particular the dimensionality of cortical sources greatly exceeds the number of electrode measurements, and source estimation requires regularization to obtain a unique solution. In this work, we introduce a novel regularization function called cortical graph smoothing, which exploits knowledge of anatomical connectivity available from diffusion-weighted imaging. Given a weighted graph description of the anatomical connectivity of the brain, cortical graph smoothing penalizes the weighted sum of squares of differences of cortical activity across the graph edges, thus encouraging solutions with consistent activation across anatomically connected regions. We explore the performance of the cortical graph smoothing source estimates for analysis of the event related potential for simple motor tasks, and compare against the commonly used minimum norm, weighted minimum norm, LORETA and sLORETA source estimation methods. Evaluated over a series of 18 subjects, the proposed cortical graph smoothing method shows superior localization accuracy compared to the minimum norm method, and greater relative peak intensity than the other comparison methods.","Electroencephalography,
Estimation,
Smoothing methods,
Tensile stress,
Brain modeling,
Head,
Magnetic heads"
AlGaN/GaN-Based Lateral-Type Schottky Barrier Diode With Very Low Reverse Recovery Charge at High Temperature,"We have demonstrated the lateral multifinger-type Schottky barrier diode (SBD) with bonding pad over active structure fabricated on the AlGaN/GaN heterostructure prepared on sapphire substrate. The fabricated GaN-SBD with size of 9 mm2 exhibited excellent device characteristics such as forward current of 4.5 A at 1.5 V, leakage current of 6 μA at 600 V, and high breakdown voltage of 747 V. The temperature variations of GaN-SBD for the reverse recovery characteristics are negligible and the value of reverse-recovery charge (Q)rr of GaN-SBD is one twentieth of Si-diode at 175°C.","Aluminum gallium nitride,
Gallium nitride,
Leakage currents,
Temperature measurement,
Current measurement,
Temperature,
Silicon"
Standalone First Level Event Selection Package for the CBM Experiment,"The main focus of the CBM experiment (FAIR, Germany) is the measurement of very rare probes at interaction rates of up to 10 MHz. The experiment will operate with a data flow of up to 1 TB/s and requires full online event reconstruction and selection. This is a task of the First Level Event Selection (FLES). A standalone FLES package has been developed for the CBM experiment. It contains modules for all reconstruction stages: track finding, track fitting, short-lived particle finding and selection. Reconstruction of about 50 types of particle decay channels is currently implemented. The algorithms are local with respect to data and their implementation is both vectorized (SIMD) and parallelized between CPU cores. For the track reconstruction the Cellular Automaton (CA) and the Kalman filter (KF) algorithms are used, that allows to achieve a high track reconstruction efficiency of up to 97% and a track parameters quality with 1% momentum resolution. The KF particle finder has a high efficiency with an optimal signal to background ratio. The FLES package shows a strong scalability on many-core systems and a processing speed of 1700 events per second on an Intel based computer with 80 cores. The investigation was done based on simulated minimum bias Au-Au UrQMD collisions at 25 AGeV with a realistic detector response.","Vectors,
Kalman filters,
Detectors,
Approximation methods,
Registers,
Graphics processing units"
Milieu: Lightweight and Configurable Big Data Provenance for Science,"The volume and complexity of data produced and analyzed in scientific collaborations is growing exponentially. It is important to track scientific data-intensive analysis workflows to provide context and reproducibility as data is transformed in these collaborations. Provenance addresses this need and aids scientists by providing the lineage or history of how data is generated, used and modified. Provenance has traditionally been collected at the workflow level often making it hard to capture relevant information about resource characteristics and is difficult for users to easily incorporate in existing workflows. In this paper, we describe Milieu, a framework focused on the collection of provenance for scientific experiments in High Performance Computing systems. Our approach collects provenance in a minimally intrusive way without significantly impacting the performance of the execution of scientific workflows. We also provide fidelity to our provenance collection by allowing users to specify three levels of provenance collection. We evaluate our framework on systems at the National Energy Research Scientific Computing Center (NERSC) and show that the overhead is less than the variation already experienced by these applications in these shared environments.","Instruments,
Data models,
Computer architecture,
Database languages,
Lattices,
Collaboration,
Context"
Cultural Preferences to Color Quality of Illumination of Different Artwork Objects Revealed by a Color Rendition Engine,"The preferences to color quality of illumination were investigated for American and Chinese subjects using a solid-state source of white light with the continuously tunable color saturation ability and correlated color temperature of quadrichromatic blends. Subjects were asked to identify both “most natural” and preferred blends. For very familiar objects, cultural differences did not affect the average of the selected blends. For less familiar objects (various paintings), cultural differences in the average selected blends depended on the level of the familiarity of the content. An unfamiliar painting also showed preferences to color temperature being dependent on the cultural background. In all cases, the American subjects exhibited noticeably wider distributions of selection rates.","Color,
Image color analysis,
Lighting,
Engines,
Cultural differences,
Painting,
Light emitting diodes"
Selective Flexibility: Creating Domain-Specific Reconfigurable Arrays,"Historically, hardware acceleration technologies have either been application-specific, therefore lacking in flexibility, or fully programmable, thereby suffering from notable inefficiencies on an application-by-application basis. To address the growing need for domain-specific acceleration technologies, this paper describes a design methodology (i) to automatically generate a domain-specific coarse-grained array from a set of representative applications and (ii) to introduce limited forms of architectural generality to increase the likelihood that additional applications can be successfully mapped onto it. In particular, coarse-grained arrays generated using our approach are intended to be integrated into customizable processors that use application-specific instruction set extensions to accelerate performance and reduce energy; rather than implementing these extensions using application-specific integrated circuit (ASIC) logic, which lacks flexibility, they can be synthesized onto our reconfigurable array instead, allowing the processor to be used for a variety of applications in related domains. Results show that our array is around 2× slower and 15× larger than an ultimately efficient ASIC implementation, and thus far more efficient than fieldprogrammable gate arrays (FPGAs), which are known to be 3-4× slower and 20-40× larger. Additionally, we estimate that our array is usually around 2× larger and 2× slower than an accelerator synthesized using traditional datapath merging, which has, if any, very limited flexibility beyond the design set of DFGs.","Routing,
Field programmable gate arrays,
Merging,
Acceleration,
Heuristic algorithms,
Binary trees,
Application specific integrated circuits"
Bridged-Grain Polycrystalline Silicon Thin-Film Transistors,"We introduce a new structure for low-temperature polycrystalline silicon thin-film transistors (TFTs). This bridged-grain structure can reduce the threshold voltage and the subthreshold swing, increase the on-off ratio, and suppress leakage current and kink effect of TFTs significantly. This technique can be applied to all polycrystalline silicon TFTs, including those made by solid-phase crystallization, metal-induced crystallization, metal-induced lateral crystallization, and excimer laser annealing.",
Calculating Complete and Exact Pareto Front for Multiobjective Optimization: A New Deterministic Approach for Discrete Problems,"Searching the Pareto front for multiobjective optimization problems usually involves the use of a population-based search algorithm or of a deterministic method with a set of different single aggregate objective functions. The results are, in fact, only approximations of the real Pareto front. In this paper, we propose a new deterministic approach capable of fully determining the real Pareto front for those discrete problems for which it is possible to construct optimization algorithms to find the k best solutions to each of the single-objective problems. To this end, two theoretical conditions are given to guarantee the finding of the actual Pareto front rather than its approximation. Then, a general methodology for designing a deterministic search procedure is proposed. A case study is conducted, where by following the general methodology, a ripple-spreading algorithm is designed to calculate the complete exact Pareto front for multiobjective route optimization. When compared with traditional Pareto front search methods, the obvious advantage of the proposed approach is its unique capability of finding the complete Pareto front. This is illustrated by the simulation results in terms of both solution quality and computational efficiency.",
Designing scratchpad memory architecture with emerging STT-RAM memory technologies,"Scratchpad memories (SPMs) have been widely used in embedded systems to achieve comparable performance with better energy efficiency when compared to caches. Spin-transfer torque RAM (STT-RAM) is an emerging nonvolatile memory technology that has low-power and high-density advantages over SRAM. In this study we explore and evaluate a series of scratchpad memory architectures consisting of STT-RAM. The experimental results reveal that with optimized design, STT-RAM is an effective alternative to SRAM for scratchpad memory in low-power embedded systems.","Resource management,
Phase change random access memory,
Computer architecture,
Embedded systems,
Optimized production technology,
Energy consumption"
Using machine learning to blend human and robot controls for assisted wheelchair navigation,"This work presents an algorithm for collaborative control of an assistive semi-autonomous wheelchair. Our approach is based on a statistical machine learning technique to learn task variability from demonstration examples. The algorithm has been developed in the context of shared-control powered wheelchairs that provide assistance to individuals with impairments that affect their control in challenging driving scenarios, like doorway navigation. We validate our algorithm within a simulation environment, and find that with relatively few demonstrations, our approach allows for safe traversal of the doorway while maintaining a high level of user control.","Robot sensing systems,
Wheelchairs,
Navigation,
Mobile robots,
Mathematical model,
Aerospace electronics"
Efficient sampling-based motion planning with asymptotic near-optimality guarantees for systems with dynamics,"Recent motion planners, such as RRT*, that achieve asymptotic optimality require a local planner, which connects two states with a trajectory. For systems with dynamics, the local planner corresponds to a two-point boundary value problem (BVP) solver, which is not always available. Furthermore, asymptotically optimal solutions tend to increase computational costs relative to alternatives, such as RRT, that focus on feasibility. This paper describes a sampling-based solution with the following desirable properties: a) it does not require a BVP solver but only uses a forward propagation model, b) it employs a single propagation per iteration similar to RRT, making it very efficient, c) it is asymptotically near-optimal, and d) provides a sparse data structure for answering path queries, which further improves computational performance. Simulations on prototypical dynamical systems show the method is able to improve the quality of feasible solutions over time and that it is computationally efficient.","Trajectory,
Heuristic algorithms,
Measurement,
Aerospace electronics,
Planning,
Data structures,
Cost function"
Fuzzy integrals of crowd-sourced intervals using a measure of generalized accord,"Fuzzy integrals are non-linear combinations of a hypothesis support function and the (possibly subjective) worth of subsets of sources of information, realized by a fuzzy measure. They are used in many applications, with data fusion being the most well-known. In most applications, the fuzzy measure is built by some external knowledge about the worth of subsets of the information sources, whether by a subjective expert or objective sensor property, such as signal-to-noise ratio. In this paper, we investigate fuzzy measures for interval-valued evidence that have no intrinsic known worth; hence, the fuzzy measure cannot or should not be built in the conventional ways. Instead, the fuzzy measure is built directly from the data. We examine the previously proposed fuzzy measure of agreement, which builds the fuzzy measure by a computation of the agreement of combinations of sources (sources from which the contributed evidence has a high degree of agreement with evidence from other sources have a high worth). We also propose a new fuzzy measure of generalized accord that addresses a theoretical weakness in the agreement measure. We compare the two fuzzy measures by performing aggregation experiments with the fuzzy Choquet integral. Tests on both synthetic and real data are performed. We also compare the two measures against the aggregation results obtained by a survey of several example data sets.","Frequency modulation,
Observers,
Density measurement,
Educational institutions,
Aggregates,
Equations,
Boundary conditions"
Multiple Feature-Enhanced SAR Imaging Using Sparsity in Combined Dictionaries,"Nonquadratic regularization-based image formation is a recently proposed framework for feature-enhanced radar imaging. Specific image formation techniques in this framework have so far focused on enhancing one type of feature, such as strong point scatterers, or smooth regions. However, many scenes contain a number of such feature types. We develop an image formation technique that simultaneously enhances multiple types of features by posing the problem as one of sparse representation based on combined dictionaries. This method is developed based on the sparse representation of the magnitude of the scattered complex-valued field, composed of appropriate dictionaries associated with different types of features. The multiple feature-enhanced reconstructed image is then obtained through a joint optimization problem over the combined representation of the magnitude and the phase of the underlying field reflectivities.","Dictionaries,
Synthetic aperture radar,
Image reconstruction,
Radar polarimetry,
Image resolution,
Measurement,
Radar imaging"
Analysis of Reusability of Secure Sketches and Fuzzy Extractors,"Secure sketches and fuzzy extractors enable the use of biometric data in cryptographic applications by correcting errors in noisy biometric readings and producing cryptographic materials suitable for authentication, encryption, and other purposes. Such constructions work by producing a public sketch, which is later used to reproduce the original biometric and all derived information exactly from a noisy biometric reading. It has been previously shown that release of multiple sketches associated with a single biometric presents security problems for certain constructions. We continue the analysis to demonstrate that all other constructions are also prone to similar problems and cannot be safely reused even in the presence of very weak adversaries.","Security,
Entropy,
Polynomials,
Noise measurement,
Random variables,
Bioinformatics"
Dual-microphone noise reduction for mobile phone application,"This paper addresses the dual-microphone noise reduction problem in mobile phone application. We propose to use the inter-microphone Posteriori SNR Difference (PSNRD) for Speech Presence Probability (SPP) estimation, which is more robust than the Power Level Difference (PLD) that is often used previously. Additionally, we use the recently reported multichannel minimum variance distortionless response (MVDR) filter for noise reduction. We divide the noises into quasi-stationary and transient components, and propose an SPP-based noise correlation matrix estimator. Analysis and experiments on data recorded in real environments verify the robustness of the PSNRD. The SPP-based estimator is more appropriate for the MVDR filter in tracking transient noise, and the proposed MVDR filter can lead to high noise reduction and small speech distortion.","Speech,
Microphones,
Noise reduction,
Correlation,
Signal to noise ratio,
Mobile handsets"
Simulation of intelligent Unmanned Aerial Vehicle (UAV) For military surveillance,"Nowadays, Unmanned Aerial Vehicle (UAV) is an important technology for military and security application. Various missions can be done using UAV such as surveillance in unknown areas, forestry conservation, and spying enemy territory. Application which is developed in this research has a purpose to simulate condition in war zone for spying the enemy. Platform used in the experiment is Parrot AR. Drone ver.2.0, an mini quadrotor which was developed by Parrot SA. This quadrotor controlled by Robot Operating System (ROS) framework. The quadrotor will search and recognize some objects and locate their location. Many algorithms were used to do the mission. To recognize object Adaboost Classifier and Pinhole Algorithm were used. The result shows that average error for all scenario is only 0.24 meters.",
RubiX: Combining Spatial Resolutions for Bayesian Inference of Crossing Fibers in Diffusion MRI,"The trade-off between signal-to-noise ratio (SNR) and spatial specificity governs the choice of spatial resolution in magnetic resonance imaging (MRI); diffusion-weighted (DW) MRI is no exception. Images of lower resolution have higher signal to noise ratio, but also more partial volume artifacts. We present a data-fusion approach for tackling this trade-off by combining DW MRI data acquired both at high and low spatial resolution. We combine all data into a single Bayesian model to estimate the underlying fiber patterns and diffusion parameters. The proposed model, therefore, combines the benefits of each acquisition. We show that fiber crossings at the highest spatial resolution can be inferred more robustly and accurately using such a model compared to a simpler model that operates only on high-resolution data, when both approaches are matched for acquisition time.","Spatial resolution,
Signal to noise ratio,
Magnetic resonance imaging,
Data models,
Signal resolution,
Solid modeling"
Dynamic cooperative spectrum sharing in elastic networks,"Spectrum expansion, contraction, and re-allocation policies are proposed for flexible networks. Reductions in blocking probability can be achieved by introducing “neighbor avoidance” mechanisms. Trade-offs between blocking probability and the number of re-allocated connections are quantified.","Optical fiber networks,
Resource management,
Educational institutions,
Optical fibers,
Telecommunication traffic,
Optical receivers,
Probability"
Multistructure Large Deformation Diffeomorphic Brain Registration,"Whole brain MRI registration has many useful applications in group analysis and morphometry, yet accurate registration across different neuropathological groups remains challenging. Structure-specific information, or anatomical guidance, can be used to initialize and constrain registration to improve accuracy and robustness. We describe here a multistructure diffeomorphic registration approach that uses concurrent subcortical and cortical shape matching to guide the overall registration. Validation experiments carried out on openly available datasets demonstrate comparable or improved alignment of subcortical and cortical brain structures over leading brain registration algorithms. We also demonstrate that a group-wise average atlas built with multistructure registration accounts for greater intersubject variability and provides more sensitive tensor-based morphometry measurements.","Image segmentation,
Magnetic resonance imaging,
Brain,
Smoothing methods,
Manuals,
Subspace constraints,
Educational institutions"
Photonic Crystal Waveguide Electro-Optic Modulator With a Wide Bandwidth,"Future optical systems will require electro-optic (EO) modulators with bandwidths of 100 GHz. For high-speed modulation, a photonic crystal (PhC) waveguide modulator using a ferroelectric thin film has been proposed. Here we report on the design, fabrication and properties of optical intensity modulator and its microwave frequency dependence. The 1.5 mm long BaTiO3 PhC modulator has a figure-of-merit of 2.1 V·cm drive voltage-length product, >50 GHz 3 dB bandwidth at an operating wavelength of 1560 nm.","Electrooptical waveguides,
Electrooptic modulators,
Bandwidth,
Voltage measurement,
Frequency measurement"
Matching Pursuit and Source Deflation for Sparse EEG/MEG Dipole Moment Estimation,"In this paper, we propose novel matching pursuit (MP)-based algorithms for EEG/MEG dipole source localization and parameter estimation for multiple measurement vectors with constant sparsity. The algorithms combine the ideas of MP for sparse signal recovery and source deflation, as employed in estimation via alternating projections. The source-deflated matching pursuit (SDMP) approach mitigates the problem of residual interference inherent in sequential MP-based methods or recursively applied (RAP)-MUSIC. Furthermore, unlike prior methods based on alternating projection, SDMP allows one to efficiently estimate the dipole orientation in addition to its location. Simulations show that the proposed algorithms outperform existing techniques under various conditions, including those with highly correlated sources. Results using real EEG data from auditory experiments are also presented to illustrate the performance of these algorithms.","Matching pursuit algorithms,
Brain models,
Vectors,
Electroencephalography,
Indexes"
The cognitive power meter: Looking beyond the smart meter,"The smart meter is often heralded as the key component supporting energy displays that can notify home occupants of their energy usage. But, a smart meter is only a digital power meter with enhanced communications capabilities - it is not actually smart. We need to look beyond the smart meter and define what intelligence is needed to actually make a meter smart. One area with promise is load disaggregation. Load disaggregation can be used to determine what loads contributing to the consumption reading at the smart meter. A smart meter incorporating load disaggregation intelligence can be seen as going beyond the traditional smart meter - what we call a cognitive power meter (c-meter). However, using load disaggregation, in its current form, is not feasible. We critically review the requirements for a c-meter and provide insights as to how load disaggregation research needs to change to make the c-meters a reality.","Home appliances,
Monitoring,
Accuracy,
Power measurement,
Training,
Clustering algorithms,
Hidden Markov models"
A time-predictable stack cache,"Real-time systems need time-predictable architectures to support static worst-case execution time (WCET) analysis. One architectural feature, the data cache, is hard to analyze when different data areas (e.g., heap allocated and stack allocated data) share the same cache. This sharing leads to less precise results of the cache analysis part of the WCET analysis. Splitting the data cache for different data areas enables composable data cache analysis. The WCET analysis tool can analyze the accesses to these different data areas independently. In this paper we present the design and implementation of a cache for stack allocated data. Our port of the LLVM C++ compiler supports the management of the stack cache. The combination of stack cache instructions and the hardware implementation of the stack cache is a further step towards time-predictable architectures.",
On the Feedback Capacity of the Fully Connected K-User Interference Channel,"The symmetric K-user interference channel with fully connected topology is considered, in which 1) each receiver suffers interference from all other (K-1) transmitters, and 2) each transmitter has causal and noiseless feedback from its respective receiver. The number of generalized degrees of freedom (\ssr GDoF) is characterized in terms of α, where the interference-to-noise ratio (\ssr INR) is given by \ssr INR = \ssr SNRα. It is shown that the per-user \ssr GDoF of this network is the same as that of the two-user interference channel with feedback, except for α = 1, for which existence of feedback does not help in terms of \ssr GDoF. The coding scheme proposed for this network, termed cooperative interference alignment, is based on two key ingredients, namely, interference alignment and interference decoding. Moreover, an approximate characterization is provided for the symmetric feedback capacity of the network, when the \ssr SNR and \ssr INR are far apart from each other.","Signal to noise ratio,
Interference channels,
Receivers,
Transmitters,
Encoding,
Decoding"
A Doubly Fed Induction Generator Controlled in Single-Sided Grid Connection for Wind Turbines,"This paper proposes a configuration of wind turbine using a doubly fed induction generator (DFIG) in single-sided grid connection. The stator of the machine is connected with a direct power grid, and the rotor is controlled by an inverter without any external power source. This is called a single external feeding of DFIG (SEF-DFIG). The conventional DFIG uses an additional grid power converter to regulate the rotor power; but in SEF-DFIG, the external source of a grid power is only connected to the stator windings. Due to this feature, the rotor-side inverter can be integrated on the rotor without any slip ring. In this paper, for applying the proposed scheme to the wind turbine, the performances of the generating operation are analyzed. The experimental results of a 2.4-kW DFIM system are presented to prove the feasibility of the proposed system and method.","wind turbines,
asynchronous generators,
machine control,
power convertors,
power generation control,
power grids,
rotors,
stators"
A Popov stability condition for uncertain linear quantum systems,"This paper considers a Popov type approach to the problem of robust stability for a class of uncertain linear quantum systems subject to unknown perturbations in the system Hamiltonian. A general stability result is given for a general class of perturbations to the system Hamiltonian. Then, the special case of a nominal linear quantum system is considered with quadratic perturbations to the system Hamiltonian. In this case, a robust stability condition is given in terms of a frequency domain condition which is of the same form as the standard Popov stability condition.",
Outsourcing privacy-preserving social networks to a cloud,"In the real world, companies would publish social networks to a third party, e.g., a cloud service provider, for marketing reasons. Preserving privacy when publishing social network data becomes an important issue. In this paper, we identify a novel type of privacy attack, termed 1*-neighborhood attack. We assume that an attacker has knowledge about the degrees of a target's one-hop neighbors, in addition to the target's 1-neighborhood graph, which consists of the one-hop neighbors of the target and the relationships among these neighbors. With this information, an attacker may re-identify the target from a k-anonymity social network with a probability higher than 1/k, where any node's 1-neighborhood graph is isomorphic with k - 1 other nodes' graphs. To resist the 1*-neighborhood attack, we define a key privacy property, probability indistinguishability, for an outsourced social network, and propose a heuristic indistinguishable group anonymization (HIGA) scheme to generate an anonymized social network with this privacy property. The empirical study indicates that the anonymized social networks can still be used to answer aggregate queries with high accuracy.","Social network services,
Privacy,
Measurement,
Probabilistic logic,
Outsourcing,
Educational institutions,
Aggregates"
Multi-scale superquadric fitting for efficient shape and pose recovery of unknown objects,"Rapidly acquiring the shape and pose information of unknown objects is an essential characteristic of modern robotic systems in order to perform efficient manipulation tasks. In this work, we present a framework for 3D geometric shape recovery and pose estimation from unorganized point cloud data. We propose a low latency multi-scale voxelization strategy that rapidly fits superquadrics to single view 3D point clouds. As a result, we are able to quickly and accurately estimate the shape and pose parameters of relevant objects in a scene. We evaluate our approach on two datasets of common household objects collected using Microsoft's Kinect sensor. We also compare our work to the state of the art and achieve comparable results in less computational time. Our experimental results demonstrate the efficacy of our approach.","Robot sensing systems,
Fitting,
Standards"
System-Level Modeling and Analysis of Thermal Effects in Optical Networks-on-Chip,"The performance of multiprocessor systems, such as chip multiprocessors (CMPs), is determined not only by individual processor performance, but also by how efficiently the processors collaborate with one another. It is the communication architecture that determines the collaboration efficiency on the hardware side. Optical networks-on-chip (ONoCs) are emerging communication architectures that can potentially offer ultra-high communication bandwidth and low latency to multiprocessor systems. Thermal sensitivity is an intrinsic characteristic of photonic devices used by ONoCs as well as a potential issue. This paper systematically modeled and quantitatively analyzed the thermal effects in ONoCs. We used an 8 × 8 mesh-based ONoC as a case study and evaluated the impacts of thermal effects in the average power efficiency for real MPSoC applications. We revealed three important factors regarding ONoC power efficiency under temperature variations, and proposed several techniques to reduce the temperature sensitivity of ONoCs. These techniques include the optimal initial setting of microresonator resonant wavelength, increasing the 3-dB bandwidth of optical switching elements by parallel coupling multiple microresonators, and the use of passive-routing optical router Crux to minimize the number of switching stages in mesh-based ONoCs. We gave a mathematical analysis of periodically parallel coupling of multiple microresonators and show that the 3-dB bandwidth of optical switching elements can be widened nearly linearly with the ring number. Evaluation results for different real MPSoC applications show that, on the basis of thermal tuning, the optimal device setting improves the average power efficiency by 54% to 1.2 pJ/bit when chip temperature reaches 85 °C. The findings in this paper can help support the further development of this emerging technology.",
Cloud computing models and their application in LTE based cellular systems,"As cloud computing emerges as the next novel concept in computer science, it becomes clear that the model applied in large data storage systems used to resolve issues coming forth from an increasing demand, could also be used to resolve the very high bandwidth requirements on access network, core network equipment and long communication paths between users and servers in the today's cellular networks. The cloud computing model can be used to avoid bottlenecks, better utilize available resources, and minimize delay. This paper analyses how three deployed major cloud computing platforms, i.e., OpenStack, Eucalyptus and OpenNebula could support this. The analysis showed that none of the studied currently deployed cloud computing platforms can satisfy the derived requirements without enhancing and extending the functions and modules supported by each platform.","Cloud computing,
Computational modeling,
Servers,
Virtual machining,
Mobile communication,
Virtual machine monitors"
Social risk and depression: Evidence from manual and automatic facial expression analysis,"Investigated the relationship between change over time in severity of depression symptoms and facial expression. Depressed participants were followed over the course of treatment and video recorded during a series of clinical interviews. Facial expressions were analyzed from the video using both manual and automatic systems. Automatic and manual coding were highly consistent for FACS action units, and showed similar effects for change over time in depression severity. For both systems, when symptom severity was high, participants made more facial expressions associated with contempt, smiled less, and those smiles that occurred were more likely to be accompanied by facial actions associated with contempt. These results are consistent with the “social risk hypothesis” of depression. According to this hypothesis, when symptoms are severe, depressed participants withdraw from other people in order to protect themselves from anticipated rejection, scorn, and social exclusion. As their symptoms fade, participants send more signals indicating a willingness to affiliate. The finding that automatic facial expression analysis was both consistent with manual coding and produced the same pattern of depression effects suggests that automatic facial expression analysis may be ready for use in behavioral and clinical science.","Gold,
Interviews,
Attenuation,
Manuals,
Encoding,
Context,
Reliability"
Maximizing Quality of Information From Multiple Sensor Devices: The Exploration vs Exploitation Tradeoff,"This paper investigates Quality of Information (QoI) aware adaptive sampling in a system where two sensor devices report information to an end user. The system carries out a sequence of tasks, where each task relates to a random event that must be observed. The accumulated information obtained from the sensor devices is reported once per task to a higher layer application at the end user. The utility of each report depends on the timeliness of the report and also on the quality of the observations. Quality can be improved by accumulating more observations for the same task, at the expense of delay. We assume new tasks arrive randomly, and the qualities of each new observation are also random. The goal is to maximize time average quality of information subject to cost constraints. We solve the problem by leveraging dynamic programming and Lyapunov optimization. Our algorithms involve solving a 2-dimensional optimal stopping problem, and result in a 2-dimensional threshold rule. When task arrivals are i.i.d., the optimal solution to the stopping problem can be closely approximated with a small number of simplified value iterations. When task arrivals are periodic, we derive a structured form approximately optimal stopping policy. We also introduce hybrid policies applied over the proposed adaptive sampling algorithms to further improve the performance. Numerical results demonstrate that our policies perform near optimal. Overall, this work provides new insights into network operation based on QoI attributes.","Signal processing algorithms,
Random variables,
Educational institutions,
Approximation algorithms,
Heuristic algorithms,
Sensors,
Equations"
Polar Codes for the Two-User Multiple-Access Channel,"Arikan's polar coding method is extended to two-user multiple-access channels. It is shown that if the two users of the channel use Arikan's construction, the resulting channels will polarize to one of five possible extremals, on each of which uncoded transmission is optimal. The sum rate achieved by this coding technique is the one that corresponds to uniform input distributions. The encoding and decoding complexities and the error performance of these codes are as in the single-user case: O(nlogn) for encoding and decoding, and o(2-n1/2-ε) for the block error probability, where n is the blocklength.","Encoding,
Decoding,
Error probability,
Receivers,
Face,
Mutual information,
Computers"
A spectrum-sharing rewarding framework for co-channel hybrid access femtocell networks,"With the explosive growth of mobile data traffic, the femtocell technology is one of the proper solutions to enhance mobile service quality and system capacity for cellular networks. However, one of the key problems for femtocell deployment is to find appropriate access control in which mobile operators and users are willing to be involved. Among all kinds of access control modes, the hybrid access mode is considered as the most promising one, which allows femtocells to provide preferential access to femtocell owners and subscribers while other public users can access femtocells with certain restriction. Since all femtocell owners are selfish, how to provide enough incentives to the owners for sharing their femtocell resources is challenging. In this paper, we construct an economic framework for mobile operator and femtocell users by a game theoretical analysis and introduce the concept of profit sharing to provide a positive cycle to sustain the femtocell service. In this framework, a femtocell game is formulated, where the femtocell owners determine the proportion of femtocell resources shared with public users while the operator can maximize its own benefit by determining the ratio of revenue distribution to femtocell owners. The existence of the Nash equilibrium of the game is analyzed. Extensive simulations are conducted to show that the profit of the operator can be maximized while the service requirements of users can be maintained by the proposed framework.",
A decentralized algorithm for balancing a strongly connected weighted digraph,"In this work we propose a decentralized algorithm for balancing a strongly connected weighted digraph. This algorithm relies on the decentralized estimation of the left eigenvector associated to the zero structural eigenvalue of the Laplacian matrix. The estimation is performed through the distributed computation of the powers of the Laplacian matrix itself. This information can be locally used by each agent to modify the weights of its incoming edges so that their sum is equal to the sum of the weights outgoing this agent, i.e., the weighted digraph is balanced. Simulation results are proposed to corroborate the theoretical results.","Laplace equations,
Estimation,
Eigenvalues and eigenfunctions,
Multi-agent systems,
Robots,
Vectors,
Conferences"
Optimization of a z-source DC circuit breaker,"DC faults may cause severe disruptions in continuity of service to vital loads in a shipboard integrated power system, hence detection, isolation, and protection against such faults must be incorporated in both medium-voltage DC (MVDC) and low-voltage DC (LVDC) systems. Here we consider the effectiveness of existing z-source breakers and propose several new designs more appropriate for fault detection in MVDC and LVDC systems. In particular, we perform an optimization study that aims to minimize dissipation and weight and we identify the key parameters for use in MVDC and LVDC systems. Preliminary verification and validation studies are also included.","Circuit faults,
Thyristors,
Switches,
Circuit breakers,
Capacitors,
Fault currents,
Optimization"
Emotion classification via utterance-level dynamics: A pattern-based approach to characterizing affective expressions,"Human emotion changes continuously and sequentially. This results in dynamics intrinsic to affective communication. One of the goals of automatic emotion recognition research is to computationally represent and analyze these dynamic patterns. In this work, we focus on the global utterance-level dynamics. We are motivated by the hypothesis that global dynamics have emotion-specific variations that can be used to differentiate between emotion classes. Consequently, classification systems that focus on these patterns will be able to make accurate emotional assessments. We quantitatively represent emotion flow within an utterance by estimating short-time affective characteristics. We compare time-series estimates of these characteristics using Dynamic Time Warping, a time-series similarity measure. We demonstrate that this similarity can effectively recognize the affective label of the utterance. The similarity-based pattern modeling outperforms both a feature-based baseline and static modeling. It also provides insight into typical high-level patterns of emotion. We visualize these dynamic patterns and the similarities between the patterns to gain insight into the nature of emotion expression.","Hidden Markov models,
Accuracy,
Trajectory,
Emotion recognition,
Speech,
Mathematical model,
Speech recognition"
Imitation learning for natural language direction following through unknown environments,"The use of spoken instructions in human-robot teams holds the promise of enabling untrained users to effectively control complex robotic systems in a natural and intuitive way. Providing robots with the capability to understand natural language directions would enable effortless coordination in human robot teams that operate in non-specialized unknown environments. However, natural language direction following through unknown environments requires understanding the meaning of language, using a partial semantic world model to generate actions in the world, and reasoning about the environment and landmarks that have not yet been detected. We address the problem of robots following natural language directions through complex unknown environments. By exploiting the structure of spatial language, we can frame direction following as a problem of sequential decision making under uncertainty. We learn a policy which predicts a sequence of actions that follow the directions by exploring the environment and discovering landmarks, backtracking when necessary, and explicitly declaring when it has reached the destination. We use imitation learning to train the policy, using demonstrations of people following directions. By training explicitly in unknown environments, we can generalize to situations that have not been encountered previously.","Natural languages,
Semantics,
Robot kinematics,
Training,
Elevators,
Equations"
"On Scalability, Generalization, and Hybridization of Coevolutionary Learning: A Case Study for Othello","This study investigates different methods of learning to play the game of Othello. The main questions posed concern scalability of algorithms with respect to the search space size and their capability to generalize and produce players that fare well against various opponents. The considered algorithms represent strategies as n-tuple networks, and employ self-play temporal difference learning (TDL), evolutionary learning (EL) and coevolutionary learning (CEL), and hybrids thereof. To assess the performance, three different measures are used: score against an a priori given opponent (a fixed heuristic strategy), against opponents trained by other methods (round-robin tournament), and against the top-ranked players from the online Othello League. We demonstrate that although evolutionary-based methods yield players that fare best against a fixed heuristic player, it is the coevolutionary temporal difference learning (CTDL), a hybrid of coevolution and TDL, that generalizes better and proves superior when confronted with a pool of previously unseen opponents. Moreover, CTDL scales well with the size of representation, attaining better results for larger n-tuple networks. By showing that a strategy learned in this way wins against the top entries from the Othello League, we conclude that it is one of the best 1-ply Othello players obtained to date without explicit use of human knowledge.",
Manipulation-based active search for occluded objects,"Object search is an integral part of daily life, and in the quest for competent mobile manipulation robots it is an unavoidable problem. Previous approaches focus on cases where objects are in unknown rooms but lying out in the open, which transforms object search into active visual search. However, in real life, objects may be in the back of cupboards occluded by other objects, instead of conveniently on a table by themselves. Extending search to occluded objects requires a more precise model and tighter integration with manipulation. We present a novel generative model for representing container contents by using object co-occurrence information and spatial constraints. Given a target object, a planner uses the model to guide an agent to explore containers where the target is likely, potentially needing to move occluding objects to enable further perception. We demonstrate the model on simulated domains and a detailed simulation involving a PR2 robot.",
PROMETHEUS: A Proactive Method for Thermal Management of Heterogeneous MPSoCs,"In this paper, we propose PROMETHEUS, a framework for proactive temperature aware scheduling of embedded workloads on single instruction set architecture heterogeneous multiprocessor systems-on-chip. It systematically combines temperature aware task assignment, task migration, and dynamic voltage and frequency scaling. PROMETHEUS is based on our novel low overhead temperature prediction technique, Tempo. In contrast to previous work, Tempo allows accurate estimation of potential thermal effects of future scheduling decisions without requiring any runtime adaptation. It reduces the maximum prediction error by up to an order of magnitude. Using Tempo, PROMETHEUS framework provides two temperature aware scheduling techniques that proactively avoid power states leading to future thermal emergencies while matching the performance needs to the workload requirements. The first technique, TempoMP, integrates Tempo with an online multiparametric optimization method to guide decisions on task assignment, migration, and setting core power states in a temperature aware fashion. Our second scheduling technique, TemPrompt uses Tempo in a heuristic algorithm that provides comparable efficiency at lower overhead. On average, these two techniques reduce the lateness of the tasks by 2.5× and energy-lateness product (ELP) by 5× compared to the previous work.",
Asynchronous Capacity per Unit Cost,"The capacity per unit cost, or, equivalently, the minimum cost to transmit one bit, is a well-studied quantity under the assumption of full synchrony between the transmitter and the receiver. In many applications, such as sensor networks, transmissions are very bursty, with amounts of bits arriving infrequently at random times. In such scenarios, the cost of acquiring synchronization is significant and one is interested in the fundamental limits on communication without assuming a priori synchronization. In this paper, the minimum cost to transmit B bits of information asynchronously is shown to be equal to (B +H̅) ksync, where ksync is the synchronous minimum cost per bit and H̅ is a measure of timing uncertainty equal to the entropy for most reasonable arrival time distributions. This result holds when the transmitter can stay idle at no cost and is a particular case of a general result which holds for arbitrary cost functions.","Delay,
Receivers,
Transmitters,
Decoding,
Synchronization,
Uncertainty"
A Peak Power Efficient Cooperative Diversity using Star-QAM with Coherent/Noncoherent Detection,"In this paper, we propose a new simple relaying strategy based on bit-interleaved convolutionally coded star-quadrature amplitude modulation (QAM) along with coherent/noncoherent detection. Star-QAM is composed of multiple concentric circles of phase-shift keying (PSK). Exploiting this property, a hard limiter is used to enhance power amplifier (PA) efficiency at the relay. Moreover, we show that the proposed approach retains differential detectability, which results in a significant reduction of receiver complexity with robustness against phase ambiguity. By analyzing our proposed cooperation with coherent/noncoherent detection in terms of asymptotic pairwise error probability (PEP), we show that the full diversity order can be achieved on the condition that the minimum free distance of the convolutional codes is larger than the predetermined value specified by the number of available relays. Furthermore, the effectiveness of the proposed scheme in terms of PA efficiency is confirmed by comparing the statistical distributions of the corresponding instantaneous signal powers. All the theoretical results agree with those obtained by computer simulations.","radio receivers,
communication complexity,
convolutional codes,
cooperative communication,
diversity reception,
error statistics,
phase shift keying,
power amplifiers,
quadrature amplitude modulation"
Path Selection under Budget Constraints in Multihop Cognitive Radio Networks,"Cognitive radio (CR) technology opens the licensed spectrum bands for opportunistic usage and initiates spectrum trading to improve the spectrum utilization. In this paper, we investigate the path selection problem in multihop cognitive radio networks (CRNs) under constraints on flow routing, link scheduling and CR source's budget. We extend the per-user-based spectrum trading in prior work to CR session-based spectrum trading, and effectively develop the spectrum trading mechanisms based on the cross-layer optimization in multihop CRNs. We introduce a new service provider, called secondary service provider (SSP), to help CR sessions to select the paths for packet delivery. Considering the price of bands and the potential returning of primary services at different CR links, the SSP purchases the licensed spectrum and jointly conducts flow routing and link scheduling under the budget constraints. We also propose a 4D conflict graph to characterize the conflict relationship among CR links and mathematically formulate the path selection problem under multiple constraints into an optimization problem with the objective of maximizing the end-to-end throughput. Due to the NP-hardness of the problem, we have also developed a heuristic algorithm to find the approximate solution.","Routing,
Throughput,
Interference,
Optimization,
Heuristic algorithms,
Availability,
Spread spectrum communication"
Improved Harris Feature Point Set for Orientation-Sensitive Urban-Area Detection in Aerial Images,"This letter addresses the automatic detection of urban area in remotely sensed images. As manual administration is time consuming and unfeasible, researchers have to focus on automated processing techniques, which can handle various image characteristics and huge amount of data. The applied method extracts feature points in the first step, which is followed by the construction of a voting map to represent urban areas. Finally, an adaptive decision making is performed to find urban areas. This letter presents methodological contributions in two key issues to the algorithm: 1) An automatically extracted Harris-based feature point set is introduced for the first step, which is able to represent urban areas more precisely. 2) An improved orientation-sensitive voting technique is proposed, exploiting the orientation information calculated in the local neighborhood of points. Evaluation results show that the proposed contributions increase the detection accuracy of urban areas.",
Evolutionary composition using music theory and charts,"With the development of human science and technology, applications of computer are more and more comprehensive. Using artificial intelligence (AI) to drawing, thinking, and problem solving becomes a significant topic. Recently, research on automatic composition using AI technology and especially evolutionary algorithms is blooming and has received promising results. A common issue at the current evolutionary composition systems is their requirement for subjective feedback of human sensation as evaluation criterion, which is vulnerable to the fatigue and decreased sensitivity after long-time listening. This paper proposes using music theory with the information from music charts in the evaluation criterion to address this issue. Specifically, we generate the weighted rules based on music theory for the fitness function. The weights are determined according to the download numbers from music charts. These weights obtained can interpret the music style and render an objective measure of compositions. Experimental results show that the proposed method can effectively achieve satisfactory compositions.","Genetic algorithms,
Biological cells,
Bars,
Sociology,
Statistics,
Rhythm"
Time-lag method for detecting following and leadership behavior of pedestrians from mobile sensing data,"The vast availability of mobile phones with built-in movement and location sensors enable the collection of detailed information about human movement even indoors. As mobility is a key element of many processes and activities, an interesting class of information to extract is movement patterns that quantify how humans move, interact and group. In this paper we propose methods for detecting two common pedestrian movement patterns, namely individual following relations and group leadership. The proposed methods for identifying following patterns employ machine learning on features derived using similarity analysis on time lagged sequences of WiFi measurements containing either raw signal strength values or derived locations. To detect leadership we combine the individual following relations into directed graphs and detect leadership within groups by graph link analysis. Methods for detecting these movement patterns open up new possibilities in - amongst others - computational social science, reality mining, marketing research and location-based gaming. We provide evaluation results that show error rates down to 7%, improving over state of the art methods with up to eleven percentage points for following patterns and up to twenty percentage points for leadership patterns. Our method is, contrary to state of the art, also applicable in challenging indoor environments, e.g., multi-story buildings. This implies that even quite small samples allow us to detect information such as how events and campaigns in multistory shopping malls may trigger following in small groups, or which group members typically take the lead when triggered by e.g. commercials, or how rescue or police forces act during training exercises.","Lead,
Vectors,
Feature extraction,
Time measurement,
Sensors,
IEEE 802.11 Standards"
Modeling Information Dissemination in Generalized Social Networks,"Information dissemination dynamics is an important performance index for characterizing the speed and scope of information dissemination in a network. Several analytical models have been proposed to estimate the information dissemination dynamics for social networks adopting a susceptible-infected information propagation model and having a constant informed rate. This letter extends existing model to analyze the social networks adopting either a susceptible-infected or an independent-cascade information propagation model and having a time-varying informed rate. Validated by simulations, our model demonstrates its flexibility and applicability to approximate the complicated propagation behaviors of advertisement-like or malware-like information.",
A Resource Allocation Algorithm of Multi-cloud Resources Based on Markov Decision Process,"Cloud technologies can nowadays be considered as commodities. The possibility of getting access to storage, computing and networking virtual resources empowers any business that needs dynamic IT capabilities. The Cloud Management Broker (CMB) plays a crucial role to handle heterogeneous virtualized cloud resources in order to offer a unique set of interfaces to the cloud users. Moreover, the CMB is in charge of optimizing the usage of the cloud resources, satisfying the requirements declared by the users. This paper proposes a novel multi-cloud resource allocation algorithm, based on a Markov Decision Process (MDP), capable of dynamically assigning the resources requests to a set of IT resources (storage or computing resources), with the aim of maximizing the expected CMB revenue. Simulation results show the feasibility and the higher performances obtained by the proposed algorithm, compared to a greedy approach.","Resource management,
Cloud computing,
Markov processes,
Heuristic algorithms,
Computer architecture,
Optimization"
Image based fog detection and visibility estimation for driving assistance systems,"An advanced driving assistance system (ADAS) must also take into account the weather conditions. One of the most dangerous weather conditions for driving scenarios is the presence of fog. So an important task for a driving assistance system is to detect the presence of fog, estimate the fog's density and determine the visibility distance of the driver. Our method is based on a single in-vehicle camera and is actually an improvement over existing fog detection solutions, in terms of speed and accuracy. We are able to detect day time fog in a wide range of scenarios, including urban scenarios. After detecting the presence of fog in the image and based on the fog's density we are able to compute the visibility distance and inform the driver about the environment's weather conditions.",
Sentiment analysis of Movie reviews and Blog posts,"This paper presents our experimental work on performance evaluation of the SentiWordNet approach for document-level sentiment classification of Movie reviews and Blog posts. We have implemented SentiWordNet approach with different variations of linguistic features, scoring schemes and aggregation thresholds. We used two pre-existing large datasets of Movie Reviews and two Blog post datasets on revolutionary changes in Libya and Tunisia. We have computed sentiment polarity and also its strength for both movie reviews and blog posts. The paper also presents an evaluative account of performance of the SentiWordNet approach with two popular machine learning approaches: Naïve Bayes and SVM for sentiment classification. The comparative performance of the approaches for both movie reviews and blog posts is illustrated through standard performance evaluation metrics of Accuracy, F-measure and Entropy.",
Variable mesh optimization for the 2013 CEC Special Session Niching Methods for Multimodal Optimization,"Many real-world problems have several optima, and the aim of niching optimisation algorithms is to obtain the different global optima, and not only the best solution. One common technique to create niches is the clearing method that removes solutions too close to better ones. Unfortunately, clearing is very sensitive to the niche radius, and its right value depends on the problem (in real-world problems the minimum distance between optima is unknown). In this work we propose a niching algorithm that uses clearing with an adaptive niche radius, that decreases during the run. The proposal uses an external memory that stores current global optima to avoid losing found optima during the clearing process, allowing a non-elitist search. This algorithm applies this clearing method to a mesh of solutions, expanded by the generation of nodes using combination methods between the nodes, their best neighbour, and their nearest current global optima in the population (current global optima are nodes with fitness very similar to current best fitness). The proposal is tested on the competition benchmark proposed in the Special Session Niching Methods for Multimodal Optimization, and compared with other algorithms. The proposal obtains very good results detecting global optima. In comparisons with other algorithm, this proposal obtains the best results, proving to be a very competitive niching algorithm.","Sociology,
Statistics,
Optimization,
Equations,
Proposals,
Benchmark testing,
Euclidean distance"
Toward VIP-PIX: A Low Noise Readout ASIC for Pixelated CdTe Gamma-Ray Detectors for Use in the Next Generation of PET Scanners,"VIP-PIX will be a low noise and low power pixel readout electronics with digital output for pixelated Cadmium Telluride (CdTe) detectors. The proposed pixel will be part of a 2D pixel-array detector for various types of nuclear medicine imaging devices such as positron-emission tomography (PET) scanners, Compton gamma cameras, and positron-emission mammography (PEM) scanners. Each pixel will include a SAR ADC that provides the energy deposited with 10-bit resolution. Simultaneously, the self-triggered pixel which will be connected to a global time-to-digital converter (TDC) with 1 ns resolution will provide the event's time stamp. The analog part of the readout chain and the ADC have been fabricated with TSMC 0.25 μm mixed-signal CMOS technology and characterized with an external test pulse. The power consumption of these parts is 200 μW from a 2.5 V supply. It offers 4 switchable gains from ± 10 mV/fC to ± 40 mV/fC and an input charge dynamic range of up to ± 70 fC for the minimum gain for both polarities. Based on noise measurements, the expected equivalent noise charge (ENC) is 65 e- RMS at room temperature.",
Group explosion strategy for searching multiple targets using swarm robotic,"In this paper, a group explosion strategy (GES) is proposed for searching multiple targets in obstructive environments using a swarm of simple robots. Considering the limited abilities of on-board sensors, fitness values detected by the robots are discrete in the problem. The strategy introduces schemes from the explosion phenomenon in nature and the whole swarm is self-adaptively divided into small groups which search for targets independently. GES takes the advantages of quick convergence from intra-group cooperation as well as searching multiple targets in parallel from inter-group cooperation. The simulation results demonstrate that GES has great efficiency in energy consumption and targets collecting benefitted from cooperation among robots. GES also shows great stability in obstructive environments.","Robot sensing systems,
Explosions,
Robot kinematics,
History,
Search problems"
Transcranial Thermoacoustic Tomography: A Comparison of Two Imaging Algorithms,"Thermoacoustic tomography (TAT) is a novel, non-invasive medical imaging technique but has encountered obstacles in imaging through the cranium. In this paper we present two methods for transcranial TAT: Kirchhoff migration (KM) and reverse-time migration (RTM). The two methods' imaging qualities are verified and compared based on both synthetic and experimental data. RTM proves to have better velocity variance and imaging quality, and little noise with spatial aliasing. RTM is a promising approach for achieving transcranial TAT in further studies.","Brain modeling,
Imaging,
Acoustic waves,
Needles,
Finite difference methods,
Time domain analysis"
Modeling of Electrostatic QCA Wires,"This paper presents a yield analysis of molecular scale electrostatic QCA wires in the presence of a variety of manufacturing defects. Within this analysis, we compare wires of varying lengths and widths as thicker wires are frequently projected to be more tolerant to manufacturing defects. Additionally, we compare the simulation results of long wires to the yield rates predicted via probabilistic transfer matrix (PTM) modeling. This comparison demonstrates that PTM modeling is best used when the short wire segments used to estimate the yields of long wires have high yields.","quantum wires,
cellular automata,
molecular electronics,
quantum dots"
Performance analysis of encryption algorithms for Information Security,"Information Security has become an important issue in data communication. Encryption algorithms have come up as a solution and play an important role in information security system. On other side, those algorithms consume a significant amount of computing resources such as CPU time, memory and battery power. Therefore it is essential to measure the performance of encryption algorithms. In this work, three encryption algorithms namely DES, AES and Blowfish are analyzed by considering certain performance metrics such as execution time, memory required for implementation and throughput. Based on the experiments, it has been concluded that the Blowfish is the best performing algorithm among the algorithms chosen for implementation.","Cryptography,
Educational institutions,
Memory management,
Random access memory,
Atmospheric measurements,
Particle measurements"
Schedule Communication for Decentralized State Estimation,"This paper considers decentralized state estimation subject to communication constraints. A group of agents measure the state of a process and obtain their state estimates by exchanging data with each other. Due to the communication constraint, only a few communication channels are available. The main objective of this paper is to allocate these channels among the agents so as to minimize their average estimation errors. We provide optimal allocation strategies for agents having the homogeneous and heterogeneous sensing capabilities, respectively.","Resource management,
Estimation error,
Tin,
Channel allocation,
Temperature sensors,
Optimal scheduling"
Steady-State and Dynamic Performance of Front-End Diode Rectifier Loads as Predicted by Dynamic Average-Value Models,"The detailed switch-level models of front-end diode rectifier loads can be readily implemented using a number of transient simulation programs, such as PSCAD/EMTDC, and the toolboxes in Matlab/Simulink. To improve the simulation efficiency for the system-level studies, the so-called dynamic average models have been widely used by researchers and engineers. Recently, several average-value modeling methodologies for the conventional three-phase (six-pulse) front-end rectifier loads have been discussed, and the dynamic performance of several developed models has been demonstrated in discontinuous and continuous modes. In this paper, the effects of topological variations of the ac-side filters on the system performance are investigated. Also, the steady-state and dynamic impedances predicted by the average models under balanced and unbalanced operation are compared. The studies and analyses presented here extend and complement those set forth in the preceding companion publication.",
"Characterization and Cytotoxicity of Nanostructured Lipid Carriers Formulated With Olive Oil, Hydrogenated Palm Oil, and Polysorbate 80","Nanostructured lipid carriers (NLC) composed of solid and liquid lipids, and surfactants are potentially good colloidal drug carriers. Before NLC can be used as drug carriers, the cytotoxicity of their components must be ascertained. The cytotoxicity of solid lipids (trilaurin, palmitin, docosanoid acid, and hydrogenated palm oil [HPO]) and surfactants (Polysorbate 20, 80, and 85) were determined on BALB/c 3T3 cells. The HPO and Polysorbate 80 were least cytotoxic and used with olive oil in the formulation of NLC. The particle size, polydispersity index, zeta potential, specific surface area, and crystallinity index of the NLC were 61.14 nm, 0.461, -25.4 mV, and 49.07 m2 and 27.12% respectively, while the melting point was 4.3°C lower than of HPO. Unlike in serum-free, NLC incubated in fetal bovine serum-supplemented medium did not show particle growth, suggesting that serum proteins in medium inhibit nanoparticles aggregation. The study also showed that NLC was less toxic to BALB/c 3T3 cells than Polysorbate 80. Thus, NLC with olive oil, HPO, and Polysorbate 80 as components are potentially good drug carriers with minimal cytotoxicity on normal cells.","Lipidomics,
Drugs,
Solids,
Nanoparticles,
Nanobioscience,
Chemicals,
Media"
Low cost power failure protection for MLC NAND flash storage systems with PRAM/DRAM hybrid buffer,"In the latest PRAM/DRAM hybrid MLC NAND flash storage systems (NFSS), DRAM is used to temporarily store file system data for system response time reduction. To ensure data integrity, super-capacitors are deployed to supply the backup power for moving the data from DRAM to NAND flash during power failures. However, the capacitance degradation of super-capacitor severely impairs system robustness. In this work, we proposed a low cost power failure protection scheme to reduce the energy consumption of power failure protection and increase the robustness of the NFSS with PRAM/DRAM hybrid buffer. Our scheme enables the adoption of the more reliable regular capacitor to replace the super capacitor as the backup power. The experimental result shows that our scheme can substantially reduce the capacitance budget of power failure protection circuitry by 75.1% with very marginal performance and energy overheads.","Phase change random access memory,
Registers,
Bandwidth,
Robustness,
Timing,
Flash memories"
Toward Efficient Filter Privacy-Aware Content-Based Pub/Sub Systems,"In recent years, the content-based publish/subscribe [12], [22] has become a popular paradigm to decouple information producers and consumers with the help of brokers. Unfortunately, when users register their personal interests to the brokers, the privacy pertaining to filters defined by honest subscribers could be easily exposed by untrusted brokers, and this situation is further aggravated by the collusion attack between untrusted brokers and compromised subscribers. To protect the filter privacy, we introduce an anonymizer engine to separate the roles of brokers into two parts, and adapt the k-anonymity and `-diversity models to the contentbased pub/sub. When the anonymization model is applied to protect the filter privacy, there is an inherent tradeoff between the anonymization level and the publication redundancy. By leveraging partial-order-based generalization of filters to track filters satisfying k-anonymity and ℓ-diversity, we design algorithms to minimize the publication redundancy. Our experiments show the proposed scheme, when compared with studied counterparts, has smaller forwarding cost while achieving comparable attack resilience.","Engines,
Privacy,
Cryptography,
Redundancy,
Adaptation models,
Registers,
Subscriptions"
Enhanced feature selection for biomarker discovery in LC-MS data using GP,Biomarker detection in LC-MS data depends mainly on feature selection algorithms as the number of features is extremely high while the number of samples is very small. This makes classification of these data sets extremely challenging. In this paper we propose the use of genetic programming (GP) for subset feature selection in LC-MS data which works by maximizing the signal to noise ratio of the selected features by GP. The proposed method was applied to eight LC-MS data sets with different sample sizes and different levels of concentration of the spiked biomarkers. We evaluated the accuracy of selection from the list of biomarkers and also using the classification accuracy of the selected features via the support vector machines (SVMs) and Naive Bayes (NB) classifiers. Features selected by the proposed GP method managed to achieve perfect classification accuracy for most of the data sets. The results show that the proposed method strikes a reasonable compromise between the detection rate of the biomarkers and the classification accuracy for all data sets. The method was also compared to linear Support Vector Machine-Recursive Features Elimination (SVM-RFE) and t-test for feature selection and the results show that the biomarker detection rate of the proposed approach is higher.,
IQ-ASyMTRe: Forming Executable Coalitions for Tightly Coupled Multirobot Tasks,"While most previous research on forming coalitions mainly concentrates on loosely coupled multirobot tasks, a more challenging problem is to address tightly coupled multirobot tasks that involve close robot coordinations, which often require capability sharing. General methods for autonomous capability sharing have been shown to greatly improve the flexibility of distributed systems. However, in addition to the interaction constraints between the robots and the environment as required by the tasks, these methods may introduce additional interaction constraints between the robots based on how the capabilities are shared. The satisfiability of these constraints in the current situation determines the feasibility of the potential coalitions. To achieve system autonomy, the ability to identify the potential coalitions that are feasible for task execution is critical. In this paper, we demonstrate a general approach that incorporates this capability based on the ASyMTRe architecture. The extended architecture, which is called IQ-ASyMTRe, is able to find coalitions in which these required constraints are satisfied. When used to form coalitions, IQ-ASyMTRe sets up only feasible coalitions, thus enabling tasks to be executed autonomously. We formally present the new architecture and prove that it is sound and complete, given certain assumptions. Simulations and experimental results are provided for different applications in which the robots are able to flexibly form coalitions that are ready to execute.","Robot sensing systems,
Robot kinematics,
Cognition,
Computer architecture,
Semantics"
Performance Analysis of PTP Components for IEC 61850 Process Bus Applications,"New substation automation applications, such as sampled value (SV) process buses and synchrophasors, require a sampling accuracy of 1 μs or better. The Precision Time Protocol (PTP), IEEE Std. 1588, achieves this level of performance and integrates well into Ethernet-based substation networks. This paper takes a systematic approach to the performance evaluation of commercially available PTP devices (grandmaster, slave, transparent, and boundary clocks) from a variety of manufacturers. The “error budget” is set by the performance requirements of each application. The “expenditure” of this error budget by each component is valuable information for a system designer. The component information is used to design a synchronization system that meets the overall functional requirements. The quantitative performance data presented show that this testing is effective and informative. Results from testing PTP performance in the presence of SV process bus traffic demonstrate the benefit of a “bottom-up” component testing approach combined with “top-down” system verification tests. A test method that uses a precision Ethernet capture card, rather than dedicated PTP test sets, to determine the correction field error of transparent clocks is presented. This test is particularly relevant for highly loaded Ethernet networks with stringent timing requirements. The methods presented can be used for development purposes by manufacturers or by system integrators for acceptance testing. An SV process bus was used as the test application for the systematic approach described in this paper. The test approach was applied, components were selected, and the system performance was verified to meet the application's requirements. Systematic testing, as presented in this paper, is applicable to a range of industries that use, rather than develop, PTP for time transfer.","Clocks,
Synchronization,
Delay,
Performance evaluation,
Substations,
Testing,
IEC standards"
A scalable distributed RRT for motion planning,"Rapidly-exploring Random Tree (RRT), like other sampling-based motion planning methods, has been very successful in solving motion planning problems. Even so, sampling-based planners cannot solve all problems of interest efficiently, so attention is increasingly turning to parallelizing them. However, one challenge in parallelizing RRT is the global computation and communication overhead of nearest neighbor search, a key operation in RRTs. This is a critical issue as it limits the scalability of previous algorithms. We present two parallel algorithms to address this problem. The first algorithm extends existing work by introducing a parameter that adjusts how much local computation is done before a global update. The second algorithm radially subdivides the configuration space into regions, constructs a portion of the tree in each region in parallel, and connects the subtrees,i removing cycles if they exist. By subdividing the space, we increase computation locality enabling a scalable result. We show that our approaches are scalable. We present results demonstrating almost linear scaling to hundreds of processors on a Linux cluster and a Cray XE6 machine.",
Temperature-Dependent Power Flow,"In conventional power flow, the system branch resistances are assumed to be constant despite the fact that they are sensitive to temperature, and therefore to branch loading and losses. When the accurate calculation of losses is important, temperature correction of branch resistance can improve the accuracy of the power flow calculation. This paper introduces a temperature-dependent power flow algorithm: a novel approach which integrates an estimate of branch temperatures and resistances with the conventional power flow equations. This methodology relies on the creation of a set of coupled temperature and power flow equations which are solved using the Newton-Raphson solution method for nonlinear equations. The core methodology is developed first, then extended via several decoupling techniques.","Mathematical model,
Equations,
Conductors,
Jacobian matrices,
Oil insulation,
Thermal resistance"
Distributed Multiple-Component Turbo Codes for Cooperative Hybrid ARQ,"We design distributed multiple-component turbo-codes (MCTCs) for cooperative automatic repeat request (CARQ) aided systems, which are capable of attaining both a similar performance and throughput as the conventional twin-component turbo code (TCTC) aided system, while imposing a significantly lower decoding complexity. The reduction in the decoding complexity of the MCTC-CARQ scheme is a direct benefit of using low-memory MCTC component encoders, combined with the novel principle of deferred iteration (DI), where the decoding process is only initiated when sufficient information has been accumulated at the receiver so that an open tunnel exists in the Extrinsic information transfer (EXIT) charts. In the presence of multiple collaborating relay nodes (RNs), the specific RN which succeeds in decoding the source message, and additionally, has the highest signal-to-noise ratio at the destination node is selected as the retransmission node. Our numerical results demonstrate that the proposed MCTC-CARQ protocol is capable of reducing the decoding complexity by up to 40% compared to its TCTC-CARQ counterpart, while achieving the same throughput and reliability.",
A reinforcement learning approach towards autonomous suspended load manipulation using aerial robots,"In this paper, we present a problem where a suspended load, carried by a rotorcraft aerial robot, performs trajectory tracking. We want to accomplish this by specifying the reference trajectory for the suspended load only. The aerial robot needs to discover/learn its own trajectory which ensures that the suspended load tracks the reference trajectory. As a solution, we propose a method based on least-square policy iteration (LSPI) which is a type of reinforcement learning algorithm. The proposed method is verified through simulation and experiments.",
A Survey on Biologically Inspired Algorithms for Computer Networking,"Biologically Inspired Algorithms (BIAs), processes that mimic how organisms solve problems, offer a number of attributes well suited to addressing challenges presented by future computer networking scenarios. Such future networks will require more scalable, adaptive and robust designs to address the dynamic changes and potential failures caused by high heterogeneity and large scale networks. A variety of biological algorithms demonstrate characteristics desirable to network design, and significant effort has been placed on analyzing and developing the corresponding BIAs and applying them to computer networking applications. This paper provides a comprehensive survey of BIAs for the computer networking field, in which different BIAs are organized and explored based on their: (1) biological source; (2) mathematical model; (3) major application; (4) advantages to corresponding ""classic"" approach; (5) limitations and border conditions; and (6) potential directions for future applications. The paper also compares performance amongst each type of BIA, and compares BIAs that are inspired by different biological sources but are applicable to similar networking applications. The paper concludes by offering a framework for understanding the application of BIAs to problems in the computer networking space.","Biological system modeling,
Computer security,
Routing,
Algorithm design and analysis"
Exploring venue popularity in Foursquare,"In this paper, we provide a detailed analysis on the venue popularity in Foursquare, a leading location-based social network. By collecting 2.4 million venues from 14 geographic regions all over the world, we study the common characteristics of popular venues, and make the following observations. First, venues with more complete profile information are more likely to be popular. Second, venues in the Food category attract the most (43%) public tips (comments) by users, and the Travel & Transport category is the most popular category with the highest per venue check-ins, i.e., each venue in this category attracts on average 376 check-ins. Moreover, the stickiness of users checking in venues in the residence, office, and school categories is higher than in other categories. Last but not least, in general, old venues created at the early stage of Foursquare are more popular than new venues. Our results help to understand the factors that cause venues to become popular, and have applications in venue recommendations and advertisement in location based social networks.","Educational institutions,
Cities and towns,
Social network services,
Art,
Conferences,
Communication networks,
Data collection"
Fast place recognition with plane-based maps,"This paper presents a new method for recognizing places in indoor environments based on the extraction of planar regions from range data provided by a hand-held RGB-D sensor. We propose to build a plane-based map (PbMap) consisting of a set of 3D planar patches described by simple geometric features (normal vector, centroid, area, etc.). This world representation is organized as a graph where the nodes represent the planar patches and the edges connect planes that are close by. This map structure permits to efficiently select subgraphs representing the local neighborhood of observed planes, that will be compared with other subgraphs corresponding to local neighborhoods of planes acquired previously. To find a candidate match between two subgraphs we employ an interpretation tree that permits working with partially observed and missing planes. The candidates from the interpretation tree are further checked out by a rigid registration test, which also gives us the relative pose between the matched places. The experimental results indicate that the proposed approach is an efficient way to solve this problem, working satisfactorily even when there are substantial changes in the scene (lifelong maps).","Vectors,
Three-dimensional displays,
Visualization,
Feature extraction,
Trajectory,
Simultaneous localization and mapping"
Learning to Segment and Track in RGBD,"We consider the problem of segmenting and tracking deformable objects in color video with depth (RGBD) data available from commodity sensors such as the Asus Xtion Pro Live or Microsoft Kinect. We frame this problem with very few assumptions-no prior object model, no stationary sensor, and no prior 3-D map-thus making a solution potentially useful for a large number of applications, including semi-supervised learning, 3-D model capture, and object recognition. Our approach makes use of a rich feature set, including local image appearance, depth discontinuities, optical flow, and surface normals to inform the segmentation decision in a conditional random field model. In contrast to previous work in this field, the proposed method learns how to best make use of these features from ground-truth segmented sequences. We provide qualitative and quantitative analyses which demonstrate substantial improvement over the state of the art. This paper is an extended version of our previous work. Building on our previous work, we show that it is possible to achieve an order of magnitude speedup and thus real-time performance ( ~ 20 FPS) on a laptop computer by applying simple algorithmic optimizations to the original work. This speedup comes at only a minor cost in overall accuracy and thus makes this approach applicable to a broader range of tasks. We demonstrate one such task: real-time, online, interactive segmentation to efficiently collect training data for an off-the-shelf object detector.",
Planning optimal paths for multiple robots on graphs,"In this paper, we study the problem of optimal multi-robot path planning (MPP) on graphs. We propose two multiflow based integer linear programming (ILP) models that compute minimum last arrival time and minimum total distance solutions for our MPP formulation, respectively. The resulting algorithms from these ILP models are complete and guaranteed to yield true optimal solutions. In addition, our flexible framework can easily accommodate other variants of the MPP problem. Focusing on the time optimal algorithm, we evaluate its performance, both as a stand alone algorithm and as a generic heuristic for quickly solving large problem instances. Computational results confirm the effectiveness of our method.","Robots,
Collision avoidance,
Path planning,
Computational modeling,
Planning,
Radio access networks,
Integer linear programming"
Understanding Incentives: Mechanism Design Becomes Algorithm Design,"We provide a computationally efficient black-box reduction from mechanism design to algorithm design in very general settings. Specifically, we give an approximation-preserving reduction from truthfully maximizing any objective under arbitrary feasibility constraints with arbitrary bidder types to (not necessarily truthfully) maximizing the same objective plus virtual welfare (under the same feasibility constraints). Our reduction is based on a fundamentally new approach: we describe a mechanism's behavior indirectly only in terms of the expected value it awards bidders for certain behavior, and never directly access the allocation rule at all. Applying our new approach to revenue, we exhibit settings where our reduction holds both ways. That is, we also provide an approximation-sensitive reduction from (non-truthfully) maximizing virtual welfare to (truthfully) maximizing revenue, and therefore the two problems are computationally equivalent. With this equivalence in hand, we show that both problems are NP-hard to approximate within any polynomial factor, even for a single monotone sub modular bidder. We further demonstrate the applicability of our reduction by providing a truthful mechanism maximizing fractional max-min fairness.",
Optimizing routability in large-scale mixed-size placement,"One of the necessary requirements for the placement process is that it should be capable of generating routable solutions. This paper describes a simple but effective method leading to the reduction of the routing congestion and the final routed wirelength for large-scale mixed-size designs. In order to reduce routing congestion and improve routability, we propose blocking narrow regions on the chip. We also propose dummy-cell insertion inside regions characterized by reduced fixed-macro density. Our placer consists of three major components: (i) narrow channel reduction by performing neighbor-based fixed-macro inflation; (ii) dummy-cell insertion inside large regions with reduced fixed-macro density; and (iii) pre-placement inflation by detecting tangled logic structures in the netlist and minimizing the maximum pin density. We evaluated the quality of our placer using the newly released DAC 2012 routability-driven placement contest designs and we compared our results to the top four teams that participated in the placement contest. The experimental results reveal that our placer improves the routability of the DAC 2012 placement contest designs and effectively reduces the routing congestion.","Routing,
Runtime,
Design automation,
Measurement,
Conferences,
Educational institutions,
Very large scale integration"
Face Illumination Manipulation Using a Single Reference Image by Adaptive Layer Decomposition,"This paper proposes a novel image-based framework to manipulate the illumination of human face through adaptive layer decomposition. According to our framework, only a single reference image, without any knowledge of the 3D geometry or material information of the input face, is needed. To transfer the illumination effects of a reference face image to a normal lighting face, we first decompose the lightness layers of the reference and the input images into large-scale and detail layers through weighted least squares (WLS) filter with adaptive smoothing parameters according to the gradient values of the face images. The large-scale layer of the reference image is filtered with the guidance of the input image by guided filter with adaptive smoothing parameters according to the face structures. The relit result is obtained by replacing the largescale layer of the input image with that of the reference image. To normalize the illumination effects of a non-normal lighting face (i.e., face delighting), we introduce similar reflectance prior to the layer decomposition stage by WLS filter, which make the normalized result less affected by the high contrast light and shadow effects of the input face. Through these two procedures, we can change the illumination effects of a non-normal lighting face by first normalizing the illumination and then transferring the illumination of another reference face to it. We acquire convincing relit results of both face relighting and delighting on numerous input and reference face images with various illumination effects and genders. Comparisons with previous papers show that our framework is less affected by geometry differences and can preserve better the identification structure and skin color of the input face.",
Formal Verification of Architectural Power Intent,"This paper presents a verification framework that attempts to bridge the disconnect between high-level properties capturing the architectural power management strategy and the implementation of the power management control logic using low-level per-domain control signals. The novelty of the proposed framework is in demonstrating that the architectural power intent properties developed using high-level artifacts can be automatically translated into properties over low-level control sequences gleaned from UPF specifications of power domains, and that the resulting properties can be used to formally verify the global on-chip power management logic. The proposed translation uses a considerable amount of domain knowledge and is also not purely syntactic, because it requires formal extraction of timing information for the low-level control sequences. We present a tool, called POWER-TRUCTOR which enables the proposed framework, and several test cases of significant complexity to demonstrate the feasibility of the proposed framework.","Transient analysis,
Timing,
Power control,
Bridge circuits,
System-on-a-chip,
Registers,
Data mining"
Sentiment analysis of Facebook statuses using Naive Bayes classifier for language learning,"The growing expansion of contents, placed on the Web, provides a huge collection of textual resources. People share their experiences, opinions or simply talk just about whatever concerns them online. The large amount of available data attracts system developers, studying on automatic mining and analysis. In this paper, the primary and underlying idea is that the fact of knowing how people feel about certain topics can be considered as a classification task. People's feelings can be positive, negative or neutral. A sentiment is often represented in subtle or complex ways in a text. An online user can use a diverse range of other techniques to express his or her emotions. Apart from that, s/he may mix objective and subjective information about a certain topic. On top of that, data gathered from the World Wide Web often contain a lot of noise. Indeed, the task of automatic sentiment recognition in online text becomes more difficult for all the aforementioned reasons. Hence, we present how sentiment analysis can assist language learning, by stimulating the educational process and experimental results on the Naive Bayes Classifier.","Facebook,
Support vector machines,
Twitter,
Testing,
Accuracy,
Educational institutions"
Automatic Extraction and Analysis of Ice Layering in Radar Sounder Data,"Nowadays, the interest on the development of orbiting radar sounders for the observation of Earth polar areas is increasing. In this context, the analysis of the structure of the ice stratigraphy is of primary importance for the study of the past history and for the prediction of the evPolution of icy environments. However, as proven by planetary missions, orbiting radar sounders provide a huge amount of data. Thus, the development of automatic techniques for the analysis of these data is of fundamental importance for proper data exploitation. In this paper, we propose a novel method for the automatic detection of subsurface linear features from radar sounder data acquired in icy regions showing extended layering. The proposed method allows the estimation of the position of the linear features with subpixel accuracy. Moreover, each detected linear interface is treated as a single object which is completely described by the position of its points, the estimated local width, and the contrast. This allows the direct measurement of geometrical and radiometric parameters (e.g., slope angle and intensity) without the need of further postprocessing steps. This paper also proposes some measurements for deriving from the output of the proposed technique important variables that can characterize quantitatively the properties of the detected linear features (e.g., mean depth and mean intensity) and their distribution (e.g., number and density of layers). The effectiveness of the proposed method is confirmed by the results obtained on several radargrams acquired by the Shallow Radar on the North Pole of Mars.","Feature extraction,
Spaceborne radar,
Ice,
Instruments,
Radar detection,
Mars"
Outage Exponent: A Unified Performance Metric for Parallel Fading Channels,"The parallel fading channel, which consists of finite number of subchannels, is very important, because it can be used to formulate many practical communication systems. The outage probability, on the other hand, is widely used to analyze the relationship among the communication efficiency, reliability, signal-to-noise ratio (SNR), and channel fading. To the best of our knowledge, the previous works only studied the asymptotic outage performance of the parallel fading channels which are only valid for a large number of subchannels or high SNRs. In this paper, a unified performance metric, which we shall refer to as the outage exponent, will be proposed. Our approach is mainly based on the large deviations theory and Meijer's G-function. It is shown that the proposed outage exponent is not only an accurate estimation of the outage probability for any number of subchannels, any SNR, and any target transmission rate, but also provides an easy way to compute the outage capacity, finite-SNR diversity-multiplexing tradeoff, and SNR gain. The asymptotic performance metrics, such as the delay-limited capacity, ergodic capacity, and diversity-multiplexing tradeoff can be directly obtained by letting the number of subchannels or SNR tend to infinity. Similar to Gallager's error exponent, a reliable function for parallel fading channels, which illustrates a fundamental relationship between the transmission reliability and efficiency, can also be defined from the outage exponent. Therefore, the proposed outage exponent provides a complete and comprehensive performance measure for parallel fading channels.","Fading,
Signal to noise ratio,
Reliability,
Capacity planning,
Measurement,
Encoding,
Multiplexing"
Analysis of Non-Local Euclidean Medians and Its Improvement,"Non-Local Euclidean Medians (NLEM) has recently been proposed and shows more effective than Non-Local Means (NLM) in removing heavy noise. In this letter, we find the inconsistency between the two dissimilarity measures in NLEM can affect its robustness, thus develop an improved version (INLEM) to compensate such an inconsistency. Further, we provide a concise convergence proof for the iterative algorithm used in both NLEM and INLEM. Finally, our experiments on synthetic and natural images show that INLEM achieves encouraging results.",
Practical Camera Calibration From Moving Objects for Traffic Scene Surveillance,"We address the problem of camera calibration for traffic scene surveillance, which supplies a connection between 2-D image features and 3-D measurement. It is helpful to deal with appearance distortion related to view angles, establish multiview correspondences, and make use of 3-D object models as prior information to enhance surveillance performance. A convenient and practical camera calibration method is proposed in this paper. With the camera height H measured as the only user input, we can recover both intrinsic and extrinsic parameters of the camera based on redundant information supplied by moving objects in monocular videos. All cases of traffic scene layouts are considered and corresponding solutions are given to make our method applicable to almost all kinds of traffic scenes in reality. Numerous experiments are conducted in different scenes, and experimental results demonstrate the accuracy and practicability of our approach. It is shown that our approach can be effectively adopted in all kinds of traffic scene surveillance applications.",
Behavior recognition based on machine learning algorithms for a wireless canine machine interface,"Training and handling working dogs is a costly process and requires specialized skills and techniques. Less subjective and lower-cost training techniques would not only improve our partnership with these dogs but also enable us to benefit from their skills more efficiently. To facilitate this, we are developing a canine body-area-network (cBAN) to combine sensing technologies and computational modeling to provide handlers with a more accurate interpretation for dog training. As the first step of this, we used inertial measurement units (IMU) to remotely detect the behavioral activity of canines. Decision tree classifiers and Hidden Markov Models were used to detect static postures (sitting, standing, lying down, standing on two legs and eating off the ground) and dynamic activities (walking, climbing stairs and walking down a ramp) based on the heuristic features of the accelerometer and gyroscope data provided by the wireless sensing system deployed on a canine vest. Data was collected from 6 Labrador Retrievers and a Kai Ken. The analysis of IMU location and orientation helped to achieve high classification accuracies for static and dynamic activity recognition.",
Library treasures in a virtual world,"In this paper, we present a three-dimensional virtual system which visualizes some interesting rooms of the University of Debrecen and makes the most cherished and carefully guarded treasures of the Collection of Rare and Early Printed Books of the University and National Library of the University of Debrecen virtually available. Our system is based on the Virtual Collaboration Arena (VirCA) developed by the Cognitive Informatics Research Group of the Computer and Automation Research Institute of the Hungarian Academy of Sciences.","Libraries,
Educational institutions,
Europe,
Conferences,
Collaboration,
History,
Cultural differences"
Distributed coverage optimization for small cell clusters using game theory,"Small cell cluster is a new paradigm to extend the usage of small cells from residential environment to large indoor or outdoor areas. However, coverage optimization is a challenge due to the ad-hoc deployment and plug-and-play feature of small cells. This paper considers decentralized self-optimization network (SON) architecture of small cell cluster and proposes distributed coverage optimization algorithm using game theory (DGT). A non-cooperate game is modeled to tune the Tx power of each small cell with a net utility function considering both gain of throughput and punishment of interference. Nash Equilibrium (NE) is proved to be existed in the game and a power update scheme is proposed which converges to the NE. Simulation results show that DGT can significantly improve throughput as well as coverage ratio with only several iterations. Compared with centralized algorithm such as modified particle swarm optimization (MPSO) and simulated annealing (SA), DGT algorithm reaches higher network throughput, uses less iteration and keeps considerable coverage ratio.","Throughput,
Scattering,
Computer architecture,
Microprocessors,
Optimization,
Interference,
Games"
Fast dynamic execution offloading for efficient mobile cloud computing,"In order to meet the increasing demand for high performance in smartphones, recent studies suggested mobile cloud computing techniques that aim to connect the phones to adjacent powerful cloud servers to throw their computational burden to the servers. These techniques often employ execution offloading schemes that migrate a process between machines during its execution. In execution offloading, code regions to be executed on the server are decided statically or dynamically based on the complex analysis on execution time and process state transfer time of every region. Expectedly, the transfer time is a deciding factor for the success of execution offloading. According to our analysis, it is dominated by the total size of heap objects transferred over the network. But previous work did not try hard to minimize this size. Thus in this paper, we introduce novel techniques based on compiler code analysis that effectively reduce the transferred data size by transferring only the essential heap objects. The experiments exhibit that the reduced size positively influences not only the transfer time itself but also the overall effectiveness of execution offloading, and ultimately, improves the performance of our mobile cloud computing significantly in terms of execution time and power consumption.",
Diffused Sensing for Sharp Directive Beamforming,"We generalized our previously proposed diffused sensing for a microphone array design to achieve sharp directive beamforming to enable various filter design methods to be applied. In the conventional microphone array, various filter design methods have been studied to narrow the directivity beam width. However, it is difficult to minimize the power of interference sources in the beamforming output (output interference power) over a broad frequency range since the cross-correlation between transfer functions from sound sources to microphones increases in some frequencies. With the diffused sensing, the cross-correlation is minimized by physically varying the transfer functions. We investigated how a microphone array should be designed in order to minimize the cross-correlation between transfer functions and found that placing the array in a diffuse acoustic field produces optimum results. Because the transfer functions are known a priori, this finding makes it possible to narrow the directivity beam width over a broad frequency range. This observation can be practically achieved by placing microphones inside a reflective enclosure, part of which is open to let sound waves enter. We conducted experiments using 24 microphones and confirmed that the output interference power was reduced over a broad frequency range and the beam width was narrowed by using the diffused sensing.",
Control-Point Representation and Differential Coding Affine-Motion Compensation,"The affine-motion model is able to capture rotation, zooming, and the deformation of moving objects, thereby providing a better motion-compensated prediction. However, it is not widely used due to difficulty in both estimation and efficient coding of its motion parameters. To alleviate this problem, a new control-point representation that favors differential coding is proposed for efficient compression of affine parameters. By exploiting the spatial correlation between adjacent coding blocks, motion vectors at control points can be predicted and thus efficiently coded, leading to overall improved performance. To evaluate the proposed method, four new affine prediction modes are designed and embedded into the high-efficiency video coding test model HM1.0. The encoder adaptively chooses whether to use the new affine mode in an operational rate-distortion optimization. Bitrate savings up to 33.82% in low-delay and 23.90% in random-access test conditions are obtained for low-complexity encoder settings. For high-efficiency settings, bitrate savings up to 14.26% and 4.89% for these two modes are observed.","video coding,
correlation methods,
motion compensation,
optimisation,
prediction theory,
rate distortion theory"
A disturb-alleviation scheme for 3D flash memory,"Even though 3D flash memory presents a grand opportunity for huge-capacity non-volatile memory, it suffers from serious program disturb problems. Different from the past efforts in error correction codes or the work in trading the space utilization with reliability, we propose a disturb-alleviation scheme that can alleviate the negative effects caused by program disturb, especially inside a block, without introducing extra overheads on encoding or storing of extra redundant data. In particular, a methodology is proposed to reduce the data error rate by distributing unavoidable disturb errors over the flash-memory space of invalid data, with the considerations of the physical organization of 3D flash memory. A series of experiments was conducted based on real multi-layer 3D flash chips, and it showed that the proposed scheme could significantly enhance the reliability of 3D flash memory.",
"Constrained Search for a Class of Good Bijective
S
-Boxes With Improved DPA Resistivity","The transparency order is proposed as a parameter for the robustness of S-boxes to differential power analysis (DPA): lower transparency order implying more resistance. However, most cryptographically strong S-boxes have been found to have high transparency order. In this paper, we characterize transparency order for various classes of S-boxes by computing the upper and lower bounds of transparency order for both even and odd numbers of variables. We find high transparency order values in the class of S-boxes whose sum of autocorrelation spectra of the coordinate functions has zero value for a large number of vectors a. Also instead of propagation characteristics, autocorrelation spectra of the S-box function F are found to be stronger in deciding the transparency order. With this characterization, we performed a constrained random generation and search of a class of balanced 8 × 8 S-boxes with transparency order upper bounded by 7.8. The nonlinearity and absolute indicator values of global avalanche characteristics of the coordinate functions of the S-boxes are in the range (98, 110) and (48, 88), respectively. A correlation analysis DPA on table look-up implementation of AES Rijndael S-box revealed the last round key in 700 power traces, while it took at least 1500 power traces with S-boxes from our proposed class.",
A Novel Fault Diagnostics and Prediction Scheme Using a Nonlinear Observer With Artificial Immune System as an Online Approximator,"In this paper, an observer-based fault diagnostics and prediction (FDP) scheme for a class of nonlinear discrete-time systems via output measurements is introduced by using artificial immune system (AIS) and a robust adaptive term. Traditionally, AIS was considered as an offline tool for system identification and pattern recognition whereas here AIS is utilized as an online approximator in discrete-time (OLAD) in a fault detection (FD) observer. A fault is detected when the output residual exceeds a predefined threshold. Upon detection, the OLAD is initiated to learn the unknown fault dynamics online while the robust adaptive term ensure asymptotic convergence of the output residual for a state fault whereas a bounded result for an output fault. Additionally, a mathematical equation is introduced to estimate the time-to-failure (TTF) by using the output residual and the estimated fault parameters. Finally, the performance of the proposed FDP scheme is demonstrated on an axial piston pump hardware test-bed.","Observers,
Vectors,
Robustness,
Fault detection,
Immune system,
Fault diagnosis,
Uncertainty"
Calibration of a network of Kinect sensors for robotic inspection over a large workspace,"This paper presents an approach for calibrating a network of Kinect devices used to guide robotic arms with rapidly acquired 3D models. The method takes advantage of the rapid 3D measurement technology embedded in the Kinect sensor and provides registration accuracy within the range of the depth measurements accuracy provided by this technology. The internal calibration of the sensor in between the color and depth measurement is also presented. The resulting system is developed to inspect large objects, such as vehicles, positioned within an enlarged field of view created by the network of RGB-D sensors.",
Twitter news classification using SVM,"With the development of web blogs, Social Networks, many news providers used to share their news headlines in various web sites and web blogs. Now-a-days in Sri Lanka, there are many news groups whom share their news headlines in micro blogging services such as Twitter. These data may carry out much valuable information which will relevant to many social research areas. Thus, the purpose of this research is to classify news into different groups so that the user could identify the most popular news group in a given country for a given time. The short messages were extracted from Twitter micro blog. Several active news groups were chosen to extract the short messages. Each short message was classified manually into 12 groups. These classified data were used to train the machine learning techniques. Words of each short message was considered as features and a feature vector was created using bag-of-words approach in order to create the instances. The data were trained using SVM (Support Vector Machine) machine learning techniques. The main reason of using SVM for the current study is, SVM supports high dimensional data. Current research is a high dimensional problem as a large number of features will be collected using short messages. Cross validation was done in order to avoid the biasness of data. The performance of the system will be the effectiveness of the system. Thus precision and recall values are calculated to measure the performance of the system. Fβ was calculated to obtain a single value measurement. The results show that the system provides high performance for most groups. However, the group development-government does not show much performance using SVM.","Support vector machines,
Accidents,
Education,
Computers,
Blogs,
Vectors"
Do external feedback loops improve the design of self-adaptive systems? A controlled experiment,"Providing high-quality software in the face of uncertainties, such as dealing with new user needs, changing availability of resources, and faults that are difficult to predict, raises fundamental challenges to software engineers. These challenges have motivated the need for self-adaptive systems. One of the primary claimed benefits of self-adaptation is that a design with external feedback loops provide a more effective engineering solution for self-adaptation compared to a design with internal mechanisms. While many efforts indicate the validity of this claim, to the best of our knowledge, no controlled experiments have been performed that provide scientifically founded evidence for it. Such experiments are crucial for researchers and engineers to underpin their claims and improve research. In this paper, we report the results of a controlled experiment performed with 24 final-year students of a Master in Software Engineering program in which designs based on external feedback loops are compared with designs based on internal mechanisms. The results show that applying external feedback loops can reduce control flow complexity and fault density, and improve productivity. We found no evidence for a reduction of activity complexity.","Cameras,
Complexity theory,
Monitoring,
Software,
Productivity,
Feedback loop,
Robustness"
A Surface Plasmon Resonance Biochip That Operates Both in the Angular and Wavelength Interrogation Modes,"This paper presents a surface plasmon resonance system based on a polymer prism chip. The device allows operation in both the angular and wavelength interrogation modes. The biochip design is discussed emphasizing the effect of the ambient temperature over the optical behavior. Birefringence effect, biochip polishing, and responsivity are also reported. The basic mathematical formulation for both operating modes is discussed, and morphological parameters are considered in the data analysis. Experimental sensorgrams obtained at both interrogation modes with the same polymer prism chip are presented and compared. The experimental sensorgrams obtained with assays providing reversible (phosphate buffered saline and hypochlorite solutions) and irreversible (neutravindin solution) bindings demonstrate the feasibility of the proposed design.","Optical sensors,
Biomedical optical imaging,
Optical refraction,
Optical variables control,
Plasmons,
Face"
Characterizing privacy leakage of public WiFi networks for users on travel,"Deployment of public wireless access points (also known as public hotspots) and the prevalence of portable computing devices has made it more convenient for people on travel to access the Internet. On the other hand, it also generates large privacy concerns due to the open environment. However, most users are neglecting the privacy threats because currently there is no way for them to know to what extent their privacy is revealed. In this paper, we examine the privacy leakage in public hotspots from activities such as domain name querying, web browsing, search engine querying and online advertising. We discover that, from these activities multiple categories of user privacy can be leaked, such as identity privacy, location privacy, financial privacy, social privacy and personal privacy. We have collected real data from 20 airport datasets in four countries and discover that the privacy leakage can be up to 68%, which means two thirds of users on travel leak their private information while accessing the Internet at airports. Our results indicate that users are not fully aware of the privacy leakage they can encounter in the wireless environment, especially in public WiFi networks. This fact can urge network service providers and website designers to improve their service by developing better privacy preserving mechanisms.",
A distributed fault-tolerant clustering algorithm for wireless sensor networks,"Energy is the main constraint of wireless sensor networks (WSNs) due to irreplaceable and limited power sources of the sensor nodes. Clustering is the most popular topology control method to reduce energy consumption and improve scalability of WSNs. However, in a cluster based WSN, cluster heads (CHs) consume more energy due to extra work load owing to data collection, data aggregation and their communication to the base station. Therefore, efficient cluster formation is very challenging by considering the energy consumption of the CHs. This is also complimented with the fault tolerant issue of WSNs as the sensor nodes are prone to failure. In this paper, we propose a distributed fault-tolerant clustering algorithm called DFCA which uses a cost function of the CHs for the formation of cluster. We also present a distributed run time recovery of the sensor nodes from the faulty cluster due to sudden failure of the CH. The experimental results demonstrate the strength of the proposed algorithm.","Logic gates,
Clustering algorithms,
Silicon,
Wireless sensor networks,
Fault tolerance,
Fault tolerant systems,
Relays"
Prefix Tag Clouds,"Tag clouds are a popular way to visually represent word frequencies. However, one major limitation is that they do not relate different word forms but treat every form as an individual tag. This results not only in a non-efficient use of screen space but, in particular, leaves the viewer with no indication whether there are other forms of a word or not. To overcome this limitation, we introduce prefix tag clouds: a visualization technique that uses a prefix tree to group different word forms and visualizes the sub trees as tag cloud. The grouping is emphasized by color, while the relative frequencies of the word forms are indicated by font size. A circular tag cloud layout supports the quick identification of the most frequent words and word forms. We show the usefulness of the approach for a large dataset of paper titles from the computer science bibliography DBLP.","trees (mathematics),
data visualisation,
tree data structures"
Free-Viewpoint Video of Human Actors Using Multiple Handheld Kinects,"We present an algorithm for creating free-viewpoint video of interacting humans using three handheld Kinect cameras. Our method reconstructs deforming surface geometry and temporal varying texture of humans through estimation of human poses and camera poses for every time step of the RGBZ video. Skeletal configurations and camera poses are found by solving a joint energy minimization problem, which optimizes the alignment of RGBZ data from all cameras, as well as the alignment of human shape templates to the Kinect data. The energy function is based on a combination of geometric correspondence finding, implicit scene segmentation, and correspondence finding using image features. Finally, texture recovery is achieved through jointly optimization on spatio-temporal RGB data using matrix completion. As opposed to previous methods, our algorithm succeeds on free-viewpoint video of human actors under general uncontrolled indoor scenes with potentially dynamic background, and it succeeds even if the cameras are moving.","Cameras,
Geometry,
Skeleton,
Image reconstruction,
Image color analysis,
Surface reconstruction,
Surface texture"
Similarity based applications for data-driven concept and word models based on type-1 and type-2 fuzzy sets,"In this paper we explore the practical application of the previously introduced approach [1] to generate fuzzy sets from interval-valued data. We demonstrate two specific example applications where we 1) generate type-1 fuzzy sets from interval-valued survey data for both words (e.g., neutral, excellent) and concepts (e.g., ambience, food) and 2) generate zSlices based general type-2 fuzzy set valued data from multiple iterations of a survey. We highlight the need for the simultaneous rating of both concepts and words in order to maintain context (including timeliness) of the resulting models. Further, in both example applications, we demonstrate using the Jaccard similarity measure how similarity measures can be employed to both relate and attribute word models to concept models (e.g., excellent food) and compare different concepts directly for different contexts (e.g., ambience in venue A vs. ambience in venue B). We provide interpretations for the resulting word/concept models and similarity values and highlight their utility, for example, for the data-driven generation of linguistic descriptions of venues. Finally, we highlight remaining questions and challenges both in technical terms and in application terms.","Frequency selective surfaces,
Context,
Data models,
Computational modeling,
Biological system modeling,
Fuzzy sets,
Uncertainty"
Reliability-Aware Synthesis of Combinational Logic With Minimal Performance Penalty,"Strategies to mitigate soft errors in combinational logic have resulted in large performance penalties and increases in design time. This study alleviates these issues by using standard cells to selectively harden vulnerable nodes in combinational logic. Results indicate that replacing two-input gates with four-input equivalents reduces pulse widths by 5%-20% with less than 1% power overhead. Additionally, this paper demonstrates reliability gains that can be made at the synthesis level under tight performance constraints.","MOSFETs,
Integrated circuit reliability,
Capacitance,
Transient analysis,
Delay"
Providing privacy-aware incentives for mobile sensing,"Mobile sensing exploits data contributed by mobile users (e.g., via their smart phones) to make sophisticated inferences about people and their surrounding and thus can be applied to environmental monitoring, traffic monitoring and healthcare. However, the large-scale deployment of mobile sensing applications is hindered by the lack of incentives for users to participate and the concerns on possible privacy leakage. Although incentive and privacy have been addressed separately in mobile sensing, it is still an open problem to address them simultaneously. In this paper, we propose two privacy-aware incentive schemes for mobile sensing to promote user participation. These schemes allow each mobile user to earn credits by contributing data without leaking which data it has contributed, and at the same time ensure that dishonest users cannot abuse the system to earn unlimited amount of credits. The first scheme considers scenarios where a trusted third party (TTP) is available. It relies on the TTP to protect user privacy, and thus has very low computation and storage cost at each mobile user. The second scheme removes the assumption of TTP and applies blind signature and commitment techniques to protect user privacy.","Manganese,
Sensors,
Mobile communication,
Privacy,
Incentive schemes,
Timing,
Smart phones"
Data Transfer From RZ-OOK to RZ-BPSK by Polarization-Insensitive XPM in a Passive Birefringent Nonlinear AlGaAs Waveguide,"The polarization-insensitive data transfer of 10-Gb/s return-to-zero ON-OFF keying (RZ-OOK) to RZ-binary phase-shift keying (RZ-BPSK) has been successfully carried out for the first time, in a passive birefringent nonlinear Al0.18Ga0.82As waveguide, utilizing polarization-insensitive cross-phase-modulation (PI-XPM). A 10-9 bit-error-rate (BER) pre-amplified receiver sensitivity penalty of ≈2.2 dB relative to baseline RZ-BPSK was measured for PI-XPM, when the RZ-OOK pump was polarization-scrambled and the RZ-probe was launched at 40°. The probe's optimal launch angle for PI-XPM was significantly influenced by the anisotropy of the Al0.18Ga0.82As waveguide.",
Novel Z-Domain Precoding Method for Blind Separation of Spatially Correlated Signals,"In this paper, we address the problem of blind separation of spatially correlated signals, which is encountered in some emerging applications, e.g., distributed wireless sensor networks and wireless surveillance systems. We preprocess the source signals in transmitters prior to transmission. Specifically, the source signals are first filtered by a set of properly designed precoders and then the coded signals are transmitted. On the receiving side, the Z-domain features of the precoders are exploited to separate the coded signals, from which the source signals are recovered. Based on the proposed precoders, a closed-form algorithm is derived to estimate the coded signals and the source signals. Unlike traditional blind source separation approaches, the proposed method does not require the source signals to be uncorrelated, sparse, or nonnegative. Compared with the existing precoder-based approach, the new method uses precoders with much lower order, which reduces the delay in data transmission and is easier to implement in practice.",
HACC: Extreme scaling and performance across diverse architectures,"Supercomputing is evolving towards hybrid and accelerator-based architectures with millions of cores. The HACC (Hardware/Hybrid Accelerated Cosmology Code) framework exploits this diverse landscape at the largest scales of problem size, obtaining high scalability and sustained performance. Developed to satisfy the science requirements of cosmological surveys, HACC melds particle and grid methods using a novel algorithmic structure that flexibly maps across architectures, including CPU/GPU, multi/many-core, and Blue Gene systems. We demonstrate the success of HACC on two very different machines, the CPU/GPU system Titan and the BG/Q systems Sequoia and Mira, attaining unprecedented levels of scalable performance. We demonstrate strong and weak scaling on Titan, obtaining up to 99.2% parallel efficiency, evolving 1.1 trillion particles. On Sequoia, we reach 13.94 PFlops (69.2% of peak) and 90% parallel efficiency on 1,572,864 cores, with 3.6 trillion particles, the largest cosmological benchmark yet performed. HACC design concepts are applicable to several other supercomputer applications.","Force,
Graphics processing units,
Computer architecture,
Slabs,
Accuracy,
Adaptation models,
Laboratories"
Communicating affect via flight path Exploring use of the Laban Effort System for designing affective locomotion paths,"People and animals use various kinds of motion in a multitude of ways to communicate their ideas and affective state, such as their moods or emotions. Further, people attribute affect and personalities to movements of even non-life like entities based solely on the style of their motions, e.g., the locomotion style of a geometric shape (how it moves about) can be interpreted as being shy, aggressive, etc. We investigate how robots can leverage this locomotion-style communication channel for communication with people. Specifically, our work deals with designing stylistic flying-robot locomotion paths for communicating affective state. To author and unpack the parameters of affect-oriented flying-robot locomotion styles we employ the Laban Effort System, a standard method for interpreting human motion commonly used in the performing arts. This paper describes our adaption of the Laban Effort System to author motions for flying robots, and the results of a formal experiment that investigated how various Laban Effort System parameters influence people's perception of the resulting robotic motions. We summarize with a set of guidelines for aiding designers in using the Laban Effort System to author flying robot motions to elicit desired affective responses.","Robot motion,
Shape,
Standards,
Psychology,
Adaptation models,
Educational institutions"
An intelligent approach for virtual machine and QoS provisioning in cloud computing,"Cloud Computing has become the most popular distributed computing environment because it does not require any user level management and controlling on the low-level implementation of the system. However, efficient resource provisioning is a key challenge for cloud computing and resolving such kind of problem can reduce under or over utilization of resources, increase user satisfaction by serving more users during peak hours, reduce implementation cost for providers and service cost for users. Existing works on cloud computing focuses to accurate estimation of the capacity needs, static or dynamic VM (Virtual Machine) creation and scheduling. But significant amount of time is required to create and destroy VMs which could be used to serve more user requests. In this paper, an adaptive QoS (Quality of Service) aware VM provisioning mechanism is developed that ensures efficient utilization of the system resources. The VM for similar type of requests has been recycled so that the VM creation time can be minimized and used to serve more user requests. In the proposed model, QoS is ensured by serving all the tasks within the requirements described in SLA. Tasks are separated using multilevel queue and the most urgent task is given high priority. The simulation-based experimental results shows that a great number of tasks can be served compared to others which will help to satisfy customers during the peak hour.",
Through-Silicon Via Fault-Tolerant Clock Networks for 3-D ICs,"Clock network synthesis is one of the most important and challenging problems in 3-D ICs. The clock signals have to be delivered by through-silicon vias (TSVs) to different tiers with minimum skew. While there are a few related works in literature, none consider the reliability of TSVs in a clock tree. Accordingly, the failure of any TSV in the clock tree yields a bad chip. The naive solution using double-TSV can alleviate the problem, but the significant area overhead renders it less practical for large designs. In this paper, we propose a novel TSV fault-tolerant unit (TFU) to provide tolerance against TSV failures. The TFU makes use of the existing 2-D redundant trees designed for prebond testing, and thus has minimum area overhead. In addition, the number of TSVs in a TFU is also adjustable to allow flexibility during clock network synthesis. Compared with the conventional double TSV technique, the 3-D clock network constructed by TFUs can achieve 58% area overhead reduction with similar yield rate on an industrial case. To the best of the authors' knowledge, this is the first work in the literature that considers the fault tolerance of a 3-D clock network. It can be easily integrated with any bottom-up clock network synthesis algorithm.","Clocks,
Through-silicon vias,
Fault tolerance,
Fault tolerant systems,
Logic gates,
Testing,
Circuit faults"
Capacity Management of Seed Servers in Peer-to-Peer Streaming Systems With Scalable Video Streams,"To improve rendered video quality and serve more receivers, peer-to-peer (P2P) video-on-demand streaming systems usually deploy seed servers. These servers complement the limited upload capacity offered by peers. In this paper, we are interested in optimally managing the capacity of seed servers, especially when scalable video streams are served to peers. Scalable video streams are encoded in multiple layers to support heterogeneous receivers. We show that the problem of optimally allocating the seeding capacity to serve scalable streams to peers is NP-complete. We then propose an approximation algorithm to solve it. Using the proposed allocation algorithm, we develop an analytical model to study the performance of P2P video-on-demand streaming systems and to manage their resources. The analysis also provides an upper bound on the maximum number of peers that can be admitted to the system in flash crowd scenarios. We validate our analysis by comparing its results to those obtained from simulations. Our analytical model can be used by administrators of P2P streaming systems to estimate the performance and video quality rendered to users under various network, peer, and video characteristics.",
A Sub-Wavelength RF Source Tracking System for GPS-Denied Environments,"A sub-wavelength source tracking system utilizing highly miniaturized antennas in the HF range for applications in GPS-denied environments including indoor and urban scenarios is proposed. A technique that combines a high resolution direction finding and radio triangulation utilizing a compact transmit (Tx) and receive (Rx) antenna system is pursued. Numerical models are used to investigate wave propagation and scattering in complex indoor scenarios as a function of frequency. We choose HF band to minimize attenuation through walls and multipath in indoor environments. In order to achieve a compact system, a low-profile and highly miniaturized antenna ( \lambda /300 height and \lambda /100 lateral dimensions at 20 MHz) having omnidirectional, vertically polarized field is designed. At such low frequencies, accurate measurement of the phase difference between the signals at the Rx antennas having very small baseline is challenging. To address this issue, a biomimetic circuit that mimics the hearing mechanism of a fly (Ormia Ochracea) is utilized. With this circuit, very small phase differences are amplified to measurable values. The numerical simulations are used to analyze direction of arrival retrieval and source localization in highly cluttered environments. A compact system prototype is also realized and source tracking in complex indoor scenarios is successfully demonstrated.","Arrays,
Receiving antennas,
Antenna arrays,
Dielectrics,
Buildings"
A truthful auction based incentive framework for femtocell access,"As cellular operators are suffering from a data explosion problem, and users are consequently experiencing poor data services, the introduction of femtocells offers a cost-effective way to mitigate this problem. Femtocells enable larger network capacity by increasing spatial reuse of the spectrum and shortening the distance to the users. Existing work has shown that open access femtocells, which allow unregistered macro users to connect, are efficient in reducing inter-cell interference and offloading traffic. However, a major obstacle constraining the potential capability of femtocells and open access is the lack of incentives for privately-owned femtocells to serve unregistered users. Hence in this paper, we propose a Vickrey-Clarke-Groves (VCG) auction based incentive framework for accessing such selfish femtocells. We consider two scenarios: One scenario involves a single macro user and another scenario has multiple macro users. We design auction schemes for both scenarios and show analytically that our schemes are truthful and have low computational complexity. Extensive simulations validate these properties and show huge performance improvement to the macro users.","Vectors,
Cost accounting,
Nickel,
Pricing,
Computational complexity,
Base stations,
Resource management"
Grouping of RFID Tags via Strongly Selective Families,"This letter proposes a novel scheme for grouping of radio-frequency identification (RFID) tags, based on strongly selective families (SSFs). Grouping of RFID tags allows verifying the integrity of groups of objects without external systems such as databases or verifiers, and can be extended to identify missing objects. The existing scheme is based on Gallager's low-density parity-check (LDPC) codes and, as such, it cannot easily achieve designated decoding guarantees due to its pseudo-random nature. Motivated by the strongly selective property of SSFs, this study proposes grouping of RFID tags via SSFs, such that designated decoding guarantees are more easily achieved. Simulation and theoretical results are presented, demonstrating that the proposed scheme can greatly improve the performance of the existing one.","RFID tags,
Error analysis,
Decoding,
Parity check codes,
Encoding,
Arrays"
Charge selection algorithms for maximizing sensor network life with UAV-based limited wireless recharging,"Monitoring bridges with wireless sensor networks aids in detecting failures early, but faces power challenges in ensuring reasonable network lifetimes. Recharging select nodes with Unmanned Aerial Vehicles (UAVs) provides a solution that currently can recharge a single node. However, questions arise on the effectiveness of a limited recharging system, the appropriate node to recharge, and the best sink selection algorithm for improving network lifetime given a limited recharging system. This paper simulates such a network in order to answer those questions. It explores five different sink positioning algorithms to find which provides the longest network lifetime with the added capability of limited recharging. For a range of network sizes, our results show that network lifetime improves by over 350% when recharging a single node in the network, the best node to recharge is the one with the lowest power level, and that either the Greedy Heuristic or LP sink selection algorithms perform equally well.","Heuristic algorithms,
Bridges,
Routing,
Wireless sensor networks,
Batteries,
Mathematical model,
Monitoring"
Large-Scale Simulation of Electromagnetic Wave Propagation Using Meshless Time Domain Method With Parallel Processing,"The large-scale simulation of the electromagnetic wave propagation using meshless time domain method (MTDM) is numerically investigated. Moreover, compute unified device architecture (CUDA) and OpenMP is adopted for parallelization technique to reduce the computation time. The results of computation show that the execution time of the time evolution calculation on GPU is 8.8 time faster than that of CPU. In addition, the execution time of the shape function generation procedure can be speedup about 7842 times by proposed scheme and OpenMP.","OpenMP,
Finite difference time domain (FDTD),
graphics processing unit (GPU),
meshless"
A Compositional Semantics for the Reversible p-Calculus,"We introduce a labelled transition semantics for the reversible π-calculus. It is the first account of a compositional definition of a reversible calculus, that has both concurrency primitives and name mobility. The notion of reversibility is strictly linked to the notion of causality. We discuss the notion of causality induced by our calculus, and we compare it with the existing notions in the literature, in particular for what concerns the syntactic feature of scope extrusion, typical of the π-calculus.","Semantics,
Synchronization,
Calculus,
Context,
Concurrent computing,
Syntactics,
Concrete"
Mobile jammers for secrecy rate maximization in cooperative networks,"We consider a source (Alice) trying to communicate with a destination (Bob), in a way that an unauthorized node (Eve) cannot infer, based on her observations, the information that is being transmitted. The communication is assisted by multiple multi-antenna cooperating nodes (helpers) who have the ability to move. While Alice transmits, the helpers transmit noise that is designed to affect the entire space except Bob. We consider the problem of selecting the helper weights and positions that maximize the system secrecy rate. It turns out that this optimization problem can be efficiently solved, leading to a novel decentralized helper motion control scheme. Simulations indicate that introducing helper mobility leads to considerable savings in terms of helper transmit power, as well as total number of helpers required for secrecy communications.","Noise,
Jamming,
Antennas,
Mobile communication,
Wireless communication,
Relays,
Ad hoc networks"
Brief paper - Consensus of fractional-order heterogeneous multi-agent systems,"This study is devoted to the consensus protocols design for a set of fractional-order heterogeneous agents, which is composed of two kinds of agents differed by their dynamics and the fractional-order α satisfies 0 <; α <; 2. Distributed state feedback consensus protocols are constructed for the two kinds of agents, respectively. Based on the Kronecker product technique and the fractional-order stability theory, sufficient conditions are derived to ensure the consensus of heterogeneous multi-agent systems in terms of linear matrix inequalities (LMIs). These can be solved numerically by LMI toolbox in Matlab. Finally, a simulation example is employed to validate the effectiveness of the theoretical results.","state feedback,
linear matrix inequalities,
multi-agent systems,
stability"
Impact of image preprocessing methods on polyp localization in colonoscopy frames,"In this paper we present our image preprocessing methods as a key part of our automatic polyp localization scheme. These methods are used to assess the impact of different endoluminal scene elements when characterizing polyps. More precisely we tackle the influence of specular highlights, blood vessels and black mask surrounding the scene. Experimental results prove that the appropriate handling of these elements leads to a great improvement in polyp localization results.","Biomedical imaging,
Blood vessels,
Colonoscopy,
Videos,
Cancer,
Shape,
Image color analysis"
A Decentralized Privacy Preserving Reputation Protocol for the Malicious Adversarial Model,"Users hesitate to submit negative feedback in reputation systems due to the fear of retaliation from the recipient user. A privacy preserving reputation protocol protects users by hiding their individual feedback and revealing only the reputation score. We present a privacy preserving reputation protocol for the malicious adversarial model. The malicious users in this model actively attempt to learn the private feedback values of honest users as well as to disrupt the protocol. Our protocol does not require centralized entities, trusted third parties, or specialized platforms, such as anonymous networks and trusted hardware. Moreover, our protocol is efficient. It requires an exchange of messages, where and are the number of users in the protocol and the environment, respectively.",
An Improved Differential Space-Time Block Coding Scheme Based on Viterbi Algorithm,"This letter proposes a novel improved differential space-time block code (DSTBC) scheme. By introducing a specific redundancy mechanism, the proposed DSTBC encoder behaves as a second-order discrete Markov process that we model by a multilevel trellis diagram. At the receiver side, the well-known Viterbi algorithm is applied without channel state information (CSI). The new scheme completely compensates for the 3-dB penalty, over wide SNR range, noticed in conventional DSTBC scheme and shows a closer performance to coherent STBC.",
Decision Fusion for Multimodal Active Authentication,"The authors apply a decision fusion architecture on a collection of behavioral biometric sensors using keystroke dynamics, mouse movement, stylometry, and Web browsing behavior. They test this active authentication approach on a dataset collected from 19 individuals in an office environment.","Authentication,
Biometrics (access control),
Detectors,
Pragmatics,
Support vector machines,
Keystrokes"
DIRECT Mode Early Decision Optimization Based on Rate Distortion Cost Property and Inter-view Correlation,"In this paper, an Efficient DIRECT Mode Early Decision (EDMED) algorithm is proposed for low complexity multiview video coding. Two phases are included in the proposed EDMED: 1) early decision of DIRECT mode is made before doing time-consuming motion estimation/disparity estimation, where adaptive rate-distortion (RD) cost threshold, inter-view DIRECT mode correlation and coded block pattern are jointly utilized; and 2) false rejected DIRECT mode macroblocks of the first phase are then successfully terminated based on weighted RD cost comparison between 16 16 and DIRECT modes for further complexity reduction. Experimental results show that the proposed EDMED algorithm achieves 11.76% more complexity reduction than that achieved by the state-of-the-art SDMET for the temporal views. Also, it achieves a reduction of 50.98% to 81.13% (69.15% on average) in encoding time for inter-view, which is 29.31% and 15.03% more than the encoding time reduction achieved by the state-of-the-art schemes. Meanwhile, the average Peak Signal-to-Noise Ratio (PSNR) degrades 0.05 dB and average bit rate increases by , which is negligible.","Correlation,
Video coding,
Complexity theory,
Encoding,
Degradation,
Vectors,
Probability"
Mesh Adaptation for Improving Elasticity Reconstruction Using the FEM Inverse Problem,"The finite element method is commonly used to model tissue deformation in order to solve for unknown parameters in the inverse problem of viscoelasticity. Typically, a (regular-grid) structured mesh is used since the internal geometry of the domain to be identified is not known a priori. In this work, the generation of problem-specific meshes is studied and such meshes are shown to significantly improve inverse-problem elastic parameter reconstruction. Improved meshes are generated from axial strain images, which provide an approximation to the underlying structure, using an optimization-based mesh adaptation approach. Such strain-based adapted meshes fit the underlying geometry even at coarse mesh resolutions, therefore improving the effective resolution of the reconstruction at a given mesh size/complexity. Elasticity reconstructions are then performed iteratively using the reflective trust-region method for optimizing the fit between estimated and observed displacements. This approach is studied for Young's modulus reconstruction at various mesh resolutions through simulations, yielding 40%-72% decrease in root-mean-square reconstruction error and 4-52 times improvement in contrast-to-noise ratio in simulations of a numerical phantom with a circular inclusion. A noise study indicates that conventional structured meshes with no noise perform considerably worse than the proposed adapted meshes with noise levels up to 20% of the compression amplitude. A phantom study and preliminary in vivo results from a breast tumor case confirm the benefit of the proposed technique. Not only conventional axial strain images but also other elasticity approximations can be used to adapt meshes. This is demonstrated on images generated by combining axial strain and axial-shear strain, which enhances lateral image contrast in particular settings, consequently further improving mesh-adapted reconstructions.","Image reconstruction,
Finite element methods,
Elasticity,
Strain,
IP networks,
Adaptation models,
Approximation methods"
Development of Large-Area Switchable Plasma Device for X-Band Applications,"This paper demonstrates a large-area, lightweight, conformal plasma device that interacts with propagating X-band microwave energy. The active elements are rugged plasma-shells - hollow ceramic shells encapsulating a controlled-pressure gas that can be ionized to controlled plasma parameters. Plasma-shells are electrically excited by frequency selective surfaces that are transparent to the frequency band of interest. The result is equivalent to large-area free-space plasma confined in a discrete plasma slab. A novel structure is designed with the aid of full-wave simulation and fabricated as a 76.2-mm square array, and transmission performance is tested across different drive voltages and angles of incidence. Switchable attenuation of 7 dB is measured across the passband when driven with 1400 Vpp at 1 MHz. Plasma parameters are estimated from theory and full-wave simulation, with electron density estimated to be 3.6×1012 cm-3. The proposed structure has potential for use on mobile platforms.","Plasma measurements,
Frequency selective surfaces,
Switches,
Arrays,
Frequency measurement,
Plasma devices"
Validation of the MR Simulation Approach for Evaluating the Effects of Immersion on Visual Analysis of Volume Data,"In our research agenda to study the effects of immersion (level of fidelity) on various tasks in virtual reality (VR) systems, we have found that the most generalizable findings come not from direct comparisons of different technologies, but from controlled simulations of those technologies. We call this the mixed reality (MR) simulation approach. However, the validity of MR simulation, especially when different simulator platforms are used, can be questioned. In this paper, we report the results of an experiment examining the effects of field of regard (FOR) and head tracking on the analysis of volume visualized micro-CT datasets, and compare them with those from a previous study. The original study used a CAVE-like display as the MR simulator platform, while the present study used a high-end head-mounted display (HMD). Out of the 24 combinations of system characteristics and tasks tested on the two platforms, we found that the results produced by the two different MR simulators were similar in 20 cases. However, only one of the significant effects found in the original experiment for quantitative tasks was reproduced in the present study. Our observations provide evidence both for and against the validity of MR simulation, and give insight into the differences caused by different MR simulator platforms. The present experiment also examined new conditions not present in the original study, and produced new significant results, which confirm and extend previous existing knowledge on the effects of FOR and head tracking. We provide design guidelines for choosing display systems that can improve the effectiveness of volume visualization applications.","Virtual reality,
Visualization,
Mice,
Solid modeling,
Head,
Training,
Computational modeling"
Analytical Model and Fringing-Field Parasitics of Carrier-Depletion Silicon-on-Insulator Optical Modulation Diodes,"We derive an analytical model for the depletion capacitance of silicon-on-insulator (SOI) optical modulation diodes. This model accurately describes the parasitic fringe capacitances due to a lateral pn junction and can be extended to other geometries, such as vertical and interdigitated junctions. The model is used to identify the waveguide slab to rib height ratio as a key geometric scaling parameter for the modulation efficiency and bandwidth for lateral diodes. The fringe capacitance is a parasitic effect that leads to a decrease of about 20% in the modulation bandwidth of typical SOI diodes without a corresponding increase in the modulation efficiency. From the scaling relations, the most effective way to increase the modulation bandwidth is to reduce the series resistance of the diode.",
On Feature Motion Decorrelation in Ultrasound Speckle Tracking,"Speckle tracking methods refer to motion tracking methods based on speckle patterns in ultrasound images. They are commonly used in ultrasound based elasticity imaging techniques to reveal mechanical properties of tissues for clinical diagnosis. In speckle tracking, feature motion decorrelation exists when speckle patterns are not identical before and after tissue motion and deformation. Feature motion decorrelation violates the underlying assumption of most speckle tracking methods. Consequently, the estimation accuracy of current methods is greatly limited. In this paper, two types of speckle pattern variations, the geometric transformation and the intensity change of speckle patterns, are studied. We show that a coupled filtering method is able to compensate for both types of variations. It provides accurate strain estimations even when tissue deformation or rotation is extremely large. We also show that in most cases, an affine warping method that only compensates for the geometric transformation is able to achieve a similar performance as the coupled filtering method. Feature motion decorrelation in B-mode images is also studied. Finally, we show that in typical elastography studies, speckle tracking methods without modeling local shearing or rotation will fail when tissue deformation is large.","Speckle,
Ultrasonic imaging,
Decorrelation,
Equations,
Correlation,
Tracking,
Mathematical model"
Using genetic programming to evolve heuristics for a Monte Carlo Tree Search Ms Pac-Man agent,"Ms Pac-Man is one of the most challenging test beds in game artificial intelligence (AI). Genetic programming and Monte Carlo Tree Search (MCTS) have already been successful applied to several games including Pac-Man. In this paper, we use Monte Carlo Tree Search to create a Ms Pac-Man playing agent before using genetic programming to enhance its performance by evolving a new default policy to replace the random agent used in the simulations. The new agent with the evolved default policy was able to achieve an 18% increase on its average score over the agent with random default policy.",
Towards the Development of the Future Internet Based Enterprise in the Context of Cyber-Physical Systems,The constantly increasing dynamics of the world economy and the shift of business values in accordance with the new values of the current society has lead to the development of new Internet oriented Enterprise Systems. This paper is concerned with the transformation of such systems in regard to the new paradigms of Future Internet and Cyber - Physical Systems. A Distributed Semantic Middleware is proposed as an Enabler for the development of Cyber Enterprise Systems.,
Runtime power estimation of mobile AMOLED displays,"Modeling and estimating power consumption of OLED displays are necessary to understand the energy behavior of emerging mobile devices. Although previous study exists to model and estimate the power consumption of stationary display images, to the best of our knowledge, no prior work is found to deal with runtime power behavior of OLED display running real applications. This paper proposes a runtime power estimation scheme for OLED displays that involves monitoring kernel activities that capture the screen change events of running applications. The experiment results show that the proposed scheme estimates the display energy consumption of running applications with reasonable accuracy.",
Identifying Leaders and Followers in Online Social Networks,"Identifying leaders and followers in online social networks is important for various applications in many domains such as advertisement, community health campaigns, administrative science, and even politics. In this paper, we study the problem of identifying leaders and followers in online social networks using user interaction information. We propose a new model, called the Longitudinal User Centered Influence (LUCI) model, that takes as input user interaction information and clusters users into four categories: introvert leaders, extrovert leaders, followers, and neutrals. To validate our model, we first apply it to a data set collected from an online social network called Everything2. Our experimental results show that our LUCI model achieves an average classification accuracy of up to 90.3% in classifying users as leaders and followers, where the ground truth is based on the labeled roles of users. Second, we apply our LUCI model on a data set collected from Facebook consisting of interactions among more than 3 million users over the duration of one year. However, we do not have ground truth data for Facebook users. Therefore, we analyze several important topological properties of the friendship graph for different user categories. Our experimental results show that different user categories exhibit different topological characteristics in the friendship graph and these observed characteristics are in accordance with the expected ones based on the general definition of the four roles.","Mathematical model,
Equations,
Data models,
Facebook,
Blogs,
Communities"
Efficient mining of frequent itemsets in social network data based on MapReduce framework,"Social Networks promote information sharing between people everywhere and at all times. Mining data produced in this data-rich environment can be extremely useful. Frequent itemset mining plays an important role in mining associations, correlations, sequential patterns, causality, episodes, multidimensional patterns, max-patterns, partial periodicity, emerging patterns, and many other significant data mining tasks in social networks. With the exponential growth of social network data towards a terabyte or more, most of the traditional frequent itemset mining algorithms become ineffective due to either huge resource requirements or large communications overhead. Cloud computing has proved that processing very large datasets over commodity clusters can be done by providing the right programming model. As a parallel programming model, MapReduce, one of most important techniques for cloud computing, has emerged in the mining of datasets of terabyte scale or larger on clusters of computers. In this paper, we propose an efficient frequent itemset mining algorithm, called IMRApriori, based on MapReduce framework which deals with Hadoop cloud, a parallel store and computing platform. The paper demonstrates experimental results to corroborate the theoretical claims.","Itemsets,
Data mining,
Algorithm design and analysis,
Social network services,
Clustering algorithms,
Computational modeling"
Robust Head Tracking Based on Multiple Cues Fusion in the Kernel-Bayesian Framework,"This paper presents a robust head tracking algorithm based on multiple cues fusion in a kernel-Bayesian framework. In this algorithm, the object to be tracked is characterized using a spatial-constraint mixture of the Gaussians-based appearance model and a multichannel chamfer matching-based shape model. These two models complement each other and their combination is discriminative in distinguishing the object from the background. A selective updating technique for the appearance model is employed to accommodate appearance and illumination changes. Meantime, the kernel method-mean shift algorithm is embedded into the Bayesian framework to give a heuristic prediction in the hypotheses generation process. This alleviates the great computational load suffered by conventional Bayesian trackers. Experimental results demonstrate that the proposed algorithm is effective.",
A Study of XSS Worm Propagation and Detection Mechanisms in Online Social Networks,"We present analytical models and simulation results that characterize the impacts of the following factors on the propagation of cross-site scripting (XSS) worms in online social networks (OSNs): 1) user behaviors, namely, the probability of visiting a friend's profile versus a stranger's; 2) the highly clustered structure of communities; and 3) community sizes. Our analyses and simulation results show that the clustered structure of a community and users' tendency to visit their friends more often than strangers help slow down the propagation of XSS worms in OSNs. We then present a study of selective monitoring schemes that are more resource efficient than the exhaustive checking approach used by the Facebook detection system which monitors every possible read and write operation of every user in the network. The studied selective monitoring schemes take advantage of the characteristics of OSNs such as the highly clustered structure and short average distance to select only a subset of strategically placed users to monitor, thus minimizing resource usage while maximizing the monitoring coverage. We present simulation results to show the effectiveness of the studied selective monitoring schemes for XSS worm detection.","Computer worms,
Malware,
Modeling,
Social network services"
On Minimizing Data-Read and Download for Storage-Node Recovery,"We consider the problem of efficient recovery of the data stored in any individual node of a distributed storage system, from the rest of the nodes. Applications include handling failures and degraded reads. We measure efficiency in terms of the amount of data-read and the download required. To minimize the download, we focus on the minimum bandwidth setting of the 'regenerating codes' model for distributed storage. Under this model, the system has a total of n nodes, and the data stored in any node must be (efficiently) recoverable from any d of the other (n-1) nodes. Lower bounds on the two metrics under this model were derived previously; it has also been shown that these bounds are achievable for the amount of data-read and download when d=n-1, and for the amount of download alone when d≠ n-1. In this paper, we complete the picture by proving the converse result, that when d≠ n-1, these lower bounds are strictly loose with respect to the amount of read required. The proof is information-theoretic, and hence applies to non-linear codes as well. We also show that under two (practical) relaxations of the problem setting, these lower bounds can be met for both read and download simultaneously.",
Low Leakage TCAM for IP Lookup Using Two-Side Self-Gating,"Ternary content-addressable memory (TCAM) is a popular hardware device for fast routing lookup and an attractive solution for applications such as packet forwarding and classification. However, the high cost and power consumption are limiting its popularity and versatility. In this paper, a low leakage power TCAM architecture which uses two-side self power gating technique is proposed to reduce the leakage power dissipation of the mask SRAM cells. The TCAM mask cells are divided into several segments, and the mask bits of one segment are the same except for the boundary segment. In this design, the boundary segment is activated and the others are disabled so that the leakage power can be reduced. The experimental results show that average 26% leakage power can be reduced by using UMC 90 nm CMOS process with 1.0 V supply voltage when compared with the traditional TCAM architecture.","Computer aided manufacturing,
Power demand,
Random access memory,
Computer architecture,
Transistors,
IP networks,
Logic gates"
New Techniques for Upper-Bounding the ML Decoding Performance of Binary Linear Codes,"In this paper, new techniques are presented to either simplify or improve most existing upper bounds on the maximum-likelihood (ML) decoding performance of the binary linear codes over additive white Gaussian noise (AWGN) channels. Firstly, the recently proposed union bound using truncated weight spectrum by Ma et al. is re-derived in a detailed way based on Gallager's first bounding technique (GFBT), where the ""good region"" is specified by a sub-optimal list decoding algorithm. The error probability caused by the bad region can be upper-bounded by the tail-probability of a binomial distribution, while the error probability caused by the good region can be upper-bounded by most existing techniques. Secondly, we propose two techniques to tighten the union bound on the error probability caused by the good region. The first technique is based on pair-wise error probabilities. The second technique is based on triplet-wise error probabilities, which can be upper-bounded by the fact that any three bipolar vectors form a non-obtuse triangle. The proposed bounds improve the conventional union bounds but have a similar complexity since they involve only the Q-function. The proposed bounds can also be adapted to bit-error probabilities.","Vectors,
Upper bound,
Error probability,
Maximum likelihood decoding,
Algorithm design and analysis,
Pairwise error probability"
PSR: Practical synchronous rendezvous in low-duty-cycle wireless networks,"Low-duty-cycle radio operations have been proposed for wireless networks facing severe energy constraints. Despite energy savings, duty-cycling the radio creates transient-available wireless links, making communication rendezvous a challenging task under the practical issue of clock drift. To overcome limitations of prior work, this paper presents PSR, a practical design for synchronous rendezvous in low-duty-cycle wireless networks. The key idea behind PSR is to extract timing information naturally embedded in the pattern of radio duty-cycling, so that normal traffic in the network can be utilized as a “free” input for drift detection, which helps reduce (or even eliminate) the overhead of traditional time-stamp exchange with dedicated packets or bits. To prevent an overuse of such free information, leading to energy waste, an energy-driven adaptive mechanism is developed for clock calibration to balance between energy efficiency and rendezvous accuracy. PSR is evaluated with both test-bed experiments and extensive simulations, by augmenting and comparing with four different MAC protocols. Results show that PSR is practical and effective under different levels of traffic load, and can be fused with those MAC protocols to improve their energy efficiency without major change of the original designs.","Synchronization,
Calibration,
Clocks,
Schedules,
Wireless networks,
Estimation,
Media Access Protocol"
Image co-saliency detection by propagating superpixel affinities,"Image co-saliency detection is a valuable technique to highlight perceptually salient regions in image pairs. In this paper, we propose a self-contained co-saliency detection algorithm based on superpixel affinity matrix. We first compute both intra and inter similarities of superpixels of image pairs. Bipartite graph matching is applied to determine most reliable inter similarities. To update the similarity score between every two superpixels, we next employ a GPU-based all-pair SimRank algorithm to do propagation on the affinity matrix. Based on the inter superpixel affinities we derive a co-saliency measure that evaluates the foreground cohesiveness and locality compactness of superpixels within one image. The effectiveness of our method is demonstrated in experimental evaluation.","Image color analysis,
Matrix decomposition,
Bipartite graph,
Educational institutions,
Sparse matrices,
Vectors,
Reliability"
Speed and direction based fuzzy handover system,"Handover is a very common event in Cellular Mobile network; however QoS could be severely affected by the handover performance. More handover cause more signaling traffic. Therefore, it is desired that handover should be done only when it is necessary. Besides, handover decision should be precise by taking account all possible options and considering the best one. For moving Mobile Station (MS) handover takes place more frequently. Some fuzzy logic based methodologies have already been proposed in literature to provide handover decision. In this paper, a method has been proposed to calculate speed and direction of MS relative to base station as a single metric using measurement data. Accordingly, a fuzzy logic based handover algorithm is implemented to avoid ping pong effect. By taking relative speed and direction, traffic load, signal strength and distance, the fuzzy inference system determines the best candidate neighbor based on the measurement reports from MS. Simulation has been carried out in Matlab environment and a comparison of different approaches has been performed. Simulation results demonstrate that proposed algorithm provides prediction based handover decision more accurately and avoid unnecessary handover and ping pong effect.","Handover,
Current measurement,
Fuzzy logic,
Timing,
Mobile communication"
Finite-Sample Linear Filter Optimization in Wireless Communications and Financial Systems,"We study the problem of linear filter optimization with finite sample size, which has wide applications such as beamformer design in wireless communications and portfolio optimization in finance. Traditional methods in both fields are not robust against the imprecise channel vector and the noise covariance matrix (or the mean return and the covariance of assets in finance) due to finite sample size. We consider estimation errors both in the channel vector and the noise covariance matrix (or the mean return and the covariance) simultaneously. We resort to high-dimensional asymptotics to account for the fact that the observation dimension is of the same order of magnitude as the number of samples, and use the diagonal loading method (or the shrinkage estimator) to improve the robustness. The channel vector (or mean return) and the noise covariance matrix are estimated from the training data, and then corrected under several widely-used criteria. In an asymptotic setting where the number of samples is comparable to the observation dimension, we obtain linear filters that are as good as the optimal filters with a shrinkage structure and a perfect channel vector (or mean return) under different criteria. Monte Carlo simulations show the advantage of our linear filters in the finite sample size regime.","Covariance matrices,
Vectors,
Wireless communication,
Portfolios,
Noise,
Robustness,
Loading"
On the performance of 1-level LDPC lattices,"The low-density parity-check (LDPC) lattices perform very well in high dimensions under generalized min-sum iterative decoding algorithm. In this work, we focus on 1-level LDPC lattices. We show that these lattices are the same as lattices constructed based on Construction A and low-density lattice-code (LDLC) lattices. In spite of having slightly lower coding gain, 1level regular LDPC lattices have remarkable performances. The lower complexity nature of the decoding algorithm for these type of lattices allows us to run it for higher dimensions easily. Our simulation results show that a 1-level LDPC lattice of size 10000 can work as close as 1.1 dB at normalized error probability (NEP) of 10-5.This can also be reported as 0.6 dB at symbol error rate (SER) of 10-5 with sum-product algorithm.","Lattices,
Parity check codes,
Vectors,
Decoding,
Encoding,
AWGN channels,
Sparse matrices"
Adaptive data collection approach for periodic sensor networks,"Data collection from unreachable terrain and then transmit the information to the sink is a fundamental task in periodic sensor networks. Energy is a major constraint for this network as the only source of energy is a battery with limited lifetime. Therefore, in order to keep the networks operating for long time, adaptive sampling approach to periodic data collection constitutes a fundamental mechanism for energy optimization. The key idea behind this approach is to allow each sensor node to adapt its sampling rates to the physical changing dynamics. In this way, over-sampling can be minimised and power efficiency of the overall network system can be further improved. In this paper, we present an efficient adaptive sampling approach based on the dependence of conditional variance on measurements varies over time. Then, we propose a multiple levels activity model that uses behavior functions modeled by modified Bezier curves to define application classes and allow for sampling adaptive rate. The proposed method was successfully tested in a real sensor data set.",
Autonomic performance and power control for co-located Web applications on virtualized servers,"In a data center, various components of Web applications co-located on virtualized servers exhibit complex time-varying interactions and interference. It has a significant impact on the user perceived performance and power consumption of the underlying system. We propose and develop APPLEware, an autonomic middleware for joint performance and power control of co-located Web applications. It features a distributed control structure that provides performance assurance and energy efficiency for large complex systems. It applies machine learning based self-adaptive modeling to capture the complex and time-varying relationship between the application performance and allocation of resources to various application components, in the presence of highly dynamic and bursty workloads and inter-application performance interference. The distributed controllers perform coordinated resource allocation to meet the service level agreements of applications in an agile and energy-efficient manner. Experimental results based on a testbed implementation with benchmark applications demonstrate APPLEware's effectiveness and energy efficiency.","Servers,
Resource management,
Power demand,
Vectors,
Interference,
Adaptation models,
Computational modeling"
Smart user interface for mobile consumer devices using model-based eye-gaze estimation,"A smart user-interface for mobile consumer devices was developed using a robust eye-gaze system without any hand motion. Using one camera and one display already available in popular mobile devices, the eye-gaze system estimates the visual angle, which shows the area of interest on the display to indicate the position of the cursor. Three novel techniques were developed to make the system robust, userindependent, and head/device motion invariant. First, by carefully investigating the geometric relation between the device and the user's cornea, a new algorithm was developed to estimate the cornea center position, which is directly related to the optical axis of the eye. Unlike previous algorithms, it does not utilize the user-dependent cornea radius. Second, to make the system robust for practical application, an algorithm was developed to compensate for imaging position errors due to the finite camera resolution. Third, a binocular algorithm was developed to estimate the user-dependent angular offsets between the optical and visual axes with only single point calibration. The proposed system was demonstrated to be accurate enough for many practical mobile user interfaces.","Cornea,
Cameras,
Light sources,
Estimation,
Visualization,
Adaptive optics,
Mobile handsets"
Heterogeneous Integrated Beam-Switching/ Retrodirective Array Using Synthesized Transmission Lines,"By utilizing synthesized transmission lines, in this paper a four-element heterogeneous integrated beam-switching/ retrodirective phased array is proposed and demonstrated. Without using active devices, the innovative array can switch its feeding network in two operational modes, making it identical to a beam-switching Butler matrix array in one frequency band, but become a reflection-type retrodirective array in the other band. The key building blocks of the unique feeding network are the dual-mode crossover and dual-mode delay lines, realized by synthesized transmission lines consisting of quasi-lumped meander-line inductors and series LC tanks in microstrip form. The operational principles, including the architecture and phase compensation scheme, are first discussed, followed by the design considerations and experimental results of the core components. The circuit responses of the feeding network and the radiation characteristics of the heterogeneous integrated array are validated through experiments. Discussion is given at the end of this paper.","Arrays,
Butler matrices,
Microstrip,
Ports (Computers),
Layout,
Delay lines,
Joining processes"
Vector Modulator Card for MTCA-Based LLRF Control System for Linear Accelerators,"Modern low-level radio frequency (LLRF) control systems of linear accelerators are designed to achieve extremely precise field amplitude and phase regulation inside superconducting cavities. One of the crucial components of the feedback loop is a vector modulator used to drive the high-power RF chain supplying the accelerating cavities. The LLRF control systems for the Free Electron Laser in Hamburg (FLASH) and European X-ray Free Electron Laser (XFEL) are based on the emerging Micro-Telecommunications Computing Architecture (MTCA.4) platform offering numerous advantages for high-performance control systems. This paper describes the concept, design, and performance of the first vector modulator (uVM) module dedicated for RF controls compliant with the MTCA.4 specification developed by PCI Industrial Computer Manufacturers Group (PICMG). The uVM module has been built as a double-width, mid-size rear transition module (RTM) that is accessed by an advanced mezzanine card (AMC). The uVM module incorporates digital, analog, and diagnostic subsystems. The digital part is based on Xilinx Spartan 6 family field-programmable gate array (FPGA), with several fast gigalink connections to a control module. The uVM module is equipped with an intelligent platform management interface (IPMI) circuit required by the MTCA.4 standard. The FPGA controls the analog part, which includes fast, high-precision digital-to-analog converters (DACs), In-phase and quadrature modulator chips, programmable attenuators, power amplifiers, and fast RF gates for an external interlock system. The RF chain can be adopted to different carrier frequencies covering a frequency range from 50 MHz to 6 GHz. The design has been carefully optimized for high linearity and low-output signal phase noise. The diagnostic system of the RF chain allows monitoring of input and output power levels and failure detection in the RF circuits. A low-noise and high-performance clocking system makes the uVM a universal device, extending the scope of applications beyond the LLRF control systems. Extensive tests of the board were performed, and the measurement results are presented and discussed in this paper.","Modulation,
Radio frequency,
Vectors,
Control systems,
Standards,
Field programmable gate arrays,
Clocks"
A platform for teaching applied distributed software development: The ongoing journey of the Helsinki software factory,"Teaching distributed software development (DSD) in project courses where student teams are geographically distributed promises several benefits. One main benefit is that in contrast to traditional classroom courses, students can experience the effects of distribution and the mechanisms for coping with distribution by themselves, therefore understanding their relevance for software development. They can thus learn to take more care of distribution challenges and risks when starting to develop software in industry. However, providing a sustainable environment for such project courses is difficult. A development environment is needed that can connect to different distributed teams and an ongoing routine to conduct such courses needs to be established. This article sketches a picture of the Software Factory, a platform that supports teaching distributed student projects and that has now been operational for more than three years. We describe the basic steps of conducting Software Factory projects, and portray experiences from past factory projects. In addition, we provide a short overview of related approaches and future activities.","Software,
Production facilities,
Educational institutions,
Software engineering,
Collaboration,
Proposals"
A Robust Inclinometer System With Accurate Calibration of Tilt and Azimuth Angles,"This paper proposes a robust inclinometer system using three monaxial microelectromechanical systems accelerometers and three monaxial fluxgate sensors. By formulating a basic three sensitive axes sensor model, we calibrate tilt and azimuth directly through a simple and effective linear model. To improve the accuracy of the proposed model, we present two different optimal solutions to minimize the systematic error, and adopt the interior-reflective Newton method and the sequential quadratic programming method to solve the problems, respectively. Experimental results demonstrate that our system performs excellently with the maximum error of tilt angle 0.09° in our applied measurement range (0°-120 °), and the maximum error of azimuth angle 0.4 ° in the measurement range (0° -360°).","Sensors,
Azimuth,
Accelerometers,
Vectors,
Calibration,
Micromechanical devices,
Acceleration"
Motivation and Data Quality in a Citizen Science Game: A Design Science Evaluation,"Citizen science is a form of social computation where members of the public are recruited to contribute to scientific investigations. Citizen-science projects often use web-based systems to support collaborative scientific activities. However, finding ways to attract participants and ensure the accuracy of the data they produce are key issues in making such systems successful. In this paper we describe the design and preliminary evaluation of a simple game that addresses these two concerns for the task of species identification.",
A mutation analysis based benchmarking framework for clone detectors,"In recent years, an abundant number of clone detectors have been proposed in literature. However, most of the tool papers have lacked a solid performance evaluation of the subject tools. This is due both to the lack of an available and reliable benchmark, and the manual efforts required to hand check a large number of candidate clones. In this tool demonstration paper we show how a mutation analysis based benchmarking framework can be used by developers and researchers to evaluate clone detection tools at a fine granularity with minimal effort.","Cloning,
Benchmark testing,
Detectors,
Educational institutions,
Manuals,
Taxonomy,
Databases"
The MORPH concept and its application in marine research,"The MORPH project (FP 7, 2012-2016) aims at the development of efficient methods and tools to map the underwater environment in situations that defy existing technology. Namely, missions that involve underwater surveying and marine habitat mapping of rugged terrain and structures with full 3D complexity, including near-vertical cliffs. Potential applications include the study of cold water coral reefs or ecosystems in underwater canyons. For mapping purposes, the project advances the novel concept of an underwater robotic sensor carrier consisting of a number of spatially separated mobile robotic modules, each of them carrying complementary sensors. The modules are connected virtually via wireless communication links. Free from the constraints of rigid links, the modules can reconfigure themselves spatially and position their sensors optimally as a function of the shape of the terrain, which may include walls with a negative slope. In the scope of the project, a final demonstration on a vertical cliff will validate the efficacy of the methods developed.","Vehicles,
Robot sensing systems,
Navigation,
Communities,
Sea measurements,
Three-dimensional displays"
A fast overcurrent protection scheme for IGBT modules through dynamic fault current evaluation,"This paper presents a new active overcurrent protection scheme for IGBT modules based on the evaluation of fault current level by measuring the induced voltage across the stray inductance between the Kelvin emitter and power emitter of IGBT modules. Compared with the commonly used desaturation protection, it provides a fast and reliable detection of fault current without any blanking time. Once a short circuit is detected, a current limiting and clamping function is activated to dynamically suppress the transient peak current, thus reducing the considerable energetic and thermal stresses induced upon the power device. Subsequently, a soft turn-off mechanism is employed aiming to reduce surge voltages induced by stray inductance under high current falling rate. Moreover, the proposed method provides flexible protection modes, which overcome the interruption of converter operation in the event of momentary short circuits. The feasibility and effectiveness of the proposed approach have been validated by simulation results with real component models in Saber. A Double Pulse Tester (DPT) based experimental test setup further verifies the proposed protection scheme.","Logic gates,
Circuit faults,
Insulated gate bipolar transistors,
Fault currents,
Voltage measurement,
Inductance,
Current measurement"
Distributed Dynamic Frequency Allocation in Fractional Frequency Reused Relay Based Cellular Networks,"To increase frequency efficiency in cellular communication networks, this paper describes a cell coloring based distributed frequency allocation approach (C-DFA) for all kinds of cellular networks. C-DFA has high computational efficiency and is simpler to realize than other distributed approaches. Building on C-DFA, a distributed dynamic fractional frequency allocation (DDFFA) algorithm is designed for IEEE 802.16j supported Relay Based Cellular Networks (RBCN). It is shown that: a) C-DFA can better realize frequency efficiency and network resilience compared to centralized traditional distributed frequency allocation approach. b) DDFFA can significantly increase frequency efficiency to provide high capacity and throughput to the RBCN though at the cost of extra computation and BS-BS communication. The evaluations and analysis are based on moderate and high user congestion RBCN scenarios.","Radio spectrum management,
Heuristic algorithms,
Interference,
Color,
Antennas,
Dynamic scheduling,
Relays"
A gyroscopic data based pedometer algorithm,"Accuracy of step counting is one of the main problems that exist in current Pedometers, especially when walking slowly on flat lands and performing different activities, such as climbing up and down stairs and walking on inclined planes. Although accelerometer based pedometers provide a reasonable accuracy when walking at higher speeds, the accuracy of them are not sufficient at slow walking speeds and performing different activities. This paper proposes a novel algorithm to detect steps using single-point gyroscopic sensors embedded in mobile devices. Preliminary analysis of data collected in different environments with the involvement of male and female volunteers indicated that gyroscope alone provides sufficient information necessary for accurate step detection. Algorithm was developed based on the gyroscopic data in conjunction with zero crossing and threshold detection techniques. The results proved that gyroscope based step detection algorithm provide a high accuracy when performing different activities and at slow paced walking.","Legged locomotion,
Navigation,
Computers,
Accuracy,
Micromechanical devices,
Magnetometers,
Gyroscopes"
A Statistical Model of Uplink Inter-Cell Interference with Slow and Fast Power Control Mechanisms,"Uplink power control is in essence an interference mitigation technique that aims at minimizing the inter-cell interference (ICI) in cellular networks by reducing the transmit power levels of the mobile users while maintaining their target received signal quality levels at base stations. Power control mechanisms directly impact the interference dynamics and, thus, affect the overall achievable capacity and consumed power in cellular networks. Due to the stochastic nature of wireless channels and mobile users' locations, it is important to derive theoretical models for ICI that can capture the impact of design alternatives related to power control mechanisms. To this end, we derive and verify a novel statistical model for uplink ICI in Generalized-K composite fading environments as a function of various slow and fast power control mechanisms. The derived expressions are then utilized to quantify numerically key network performance metrics that include average resource fairness, average reduction in power consumption, and ergodic capacity. The accuracy of the derived expressions is validated via Monte-Carlo simulations. Results are generated for multiple network scenarios, and insights are extracted to assess various power control mechanisms as a function of system parameters.",
Weighted Sum Rate Maximization for Multiuser Multirelay MIMO Systems,"In this paper, we study a filter design that maximizes the weighted sum rate (WSR) in multiuser multirelay systems equipped with multiple antennas at each node. Since this problem is generally nonconvex, it is quite complicated to analytically find a solution. Hence, we transform the WSR maximization problem to an equivalent weighted sum mean-square-error (WSMSE) minimization problem, which is more amenable. Then, we identify the filters at the base station and the relays for minimizing the WSMSE with a proper weight and propose an alternating computation algorithm that guarantees a local optimum solution. Through simulations, we confirm the effectiveness of our proposed scheme.",
Classification of Complex Networks Based on Topological Properties,"Study of countless real-world systems. They have been used in very different domains such as computer science, biology, sociology, management, etc. Authors have been trying to characterize them using various measures such as degree distribution, transitivity or average distance. Their goal is to detect certain properties such as the small-world or scale-free properties. Previous works have shown some of these properties are present in many different systems, while others are characteristic of certain types of systems only. However, each one of these studies generally focuses on a very small number of topological measures and networks. In this work, we aim at using a more systematic approach. We first constitute a dataset of 152 publicly available networks, spanning over 7 different domains. We then process 14 different topological measures to characterize them in the most possible complete way. Finally, we apply standard data mining tools to analyze these data. A cluster analysis reveals it is possible to obtain two significantly distinct clusters of networks, corresponding roughly to a bisection of the domains modeled by the networks. On these data, the most discriminant measures are density, modularity, average degree and transitivity, and at a lesser extent, closeness and edge betweenness centralities.","Transportation,
Complex networks,
Communities,
Upper bound,
Standards,
Computer networks,
Clustering algorithms"
Scalable algorithms for wireless link schedulings in multi-channel multi-radio wireless networks,"For wireless link scheduling in multi-channel multi-radio wireless networks aiming at maximizing (concurrent) multi-flow, constant-approximation algorithms have recently been developed in [11]. However, the running time of those algorithms grows quickly with the number of radios per node (at least in the sixth order) and the number of channels (at least in the cubic order). Such poor scalability stems intrinsically from the exploding size of the fine-grained network representation upon which those algorithms are built. In this paper, we introduce a new structure, termed as concise conflict graph, on the node-level links directly. Such structure succinctly captures the essential advantage of multiple radios and multiple channels. By exploring and exploiting the rich structural properties of the concise conflict graphs, we are able to develop fast and scalable link scheduling algorithms for either minimizing the communication latency or maximizing the (concurrent) multi-flow. These algorithms have running time growing linearly in both the number of radios per node and the number of channels, while not sacrificing the approximation bounds.",
Subbandgap Asymmetric Surface Plasmon Waveguide Schottky Detectors on Silicon,"Silicon-based surface-plasmon subbandgap detectors integrated with an asymmetric metal stripe are investigated for different metals, modes, and wavelengths of operation. Low-order bound modes supported by Al and Au stripes cladded below by silicon and covered by air are studied at the infrared wavelengths of 1310 and 1550 nm. Input optical power is end-fire coupled into the modes supported by the stripe, resulting in the total absorption of coupled power over a short length. The absorbed power creates excited carriers in the metal throughout the modal absorption volume, which can cross the Schottky barrier and become collected as photocurrent (internal photoemission). Measurements obtained for Au on n-type Si support predicted trends. The device has promise for applications in short-reach high-speed optical interconnects and silicon-based nanophotonics.","Gold,
Silicon,
Detectors,
Couplings,
Schottky barriers,
Photodetectors"
Brief Paper - Distributed consensus filtering for jump Markov linear systems,This article studies the problem of distributed filtering for jump Markov linear systems in a not fully connected sensor network. A distributed consensus filter is developed by applying an improved interacting multiple model approach in which the mode-conditioned estimates are derived by the Kalman consensus filter and the mode probabilities are obtained in the sense of linear minimum variance. A numerical example is provided to demonstrate the effectiveness of the proposed algorithm for tracking a manoeuvring target in a sensor work with eight nodes.,
Optimal Training and Data Power Allocation in Distributed Detection With Inhomogeneous Sensors,"We consider a binary distributed detection problem in a wireless sensor network with inhomogeneous sensors, in which sensors send their binary phase shift keying (BPSK) modulated decisions to the fusion center (FC) over orthogonal channels that are subject to pathloss, Rayleigh fading, and Gaussian noise. Assuming training based channel estimation, we consider a linear fusion rule which employs imperfect channel state information (CSI) to form the global decision at the FC. Under the constraint that the total transmit power of training and decision symbols at each sensor is fixed, we analytically derive the optimal power allocation between training and data at each sensor such that the deflection coefficient at the FC is maximized. Our analysis shows that the proposed optimal power allocation scheme is a function of signal-to-noise (SNR) and local detection indices, and at high SNR regime, the proposed scheme outperforms the uniform power allocation.",
Enhancing human action recognition through spatio-temporal feature learning and semantic rules,"In this paper, we present a two-stage framework that deal with the problem of automatically extract human activities from videos. First, for action recognition we employ an unsupervised state-of-the-art learning algorithm based on Independent Subspace Analysis (ISA). This learning algorithm extracts spatio-temporal features directly from video data and it is computationally more efficient and robust than other unsupervised methods. Nevertheless, when applying this one-stage state-of-the-art action recognition technique on the observations of human everyday activities, it can only reach an accuracy rate of approximately 25%. Hence, we propose to enhance this process with a second stage, which define a new method to automatically generate semantic rules that can reason about human activities. The obtained semantic rules enhance the human activity recognition by reducing the complexity of the perception system and they allow the possibility of domain change, which can great improve the synthesis of robot behaviors. The proposed method was evaluated under two complex and challenging scenarios: making a pancake and making a sandwich. The difficulty of these scenarios is that they contain finer and more complex activities than the well known data sets (Hollywood2, KTH, etc). The results show benefits of two stages method, the accuracy of action recognition was significantly improved compared to a single-stage method (above 87% compared to human expert). This indicates the improvement of the framework using the reasoning engine for the automatic extraction of human activities from observations, thus, providing a rich mechanism for transferring a wide range of human skills to humanoid robots.",
Hypothesis testing framework for active object detection,"One of the central problems in computer vision is the detection of semantically important objects and the estimation of their pose. Most of the work in object detection has been based on single image processing and its performance is limited by occlusions and ambiguity in appearance and geometry. This paper proposes an active approach to object detection by controlling the point of view of a mobile depth camera. When an initial static detection phase identifies an object of interest, several hypotheses are made about its class and orientation. The sensor then plans a sequence of viewpoints, which balances the amount of energy used to move with the chance of identifying the correct hypothesis. We formulate an active M-ary hypothesis testing problem, which includes sensor mobility, and solve it using a point-based approximate POMDP algorithm. The validity of our approach is verified through simulation and experiments with real scenes captured by a kinect sensor. The results suggest a significant improvement over static object detection.",
Adaptive non-local means for multiview image denoising: Searching for the right patches via a statistical approach,"We present an adaptive non-local means (NLM) denoising method for a sequence of images captured by a multiview imaging system, where direct extensions of existing single image NLM methods are incapable of producing good results. Our proposed method consists of three major components: (1) a robust joint-view distance metric to measure the similarity of patches; (2) an adaptive procedure derived from statistical properties of the estimates to determine the optimal number of patches to be used; (3) a new NLM algorithm to denoise using only a set of similar patches. Experimental results show that the proposed method is robust to disparity estimation error, out-performs existing algorithms in multiview settings, and performs competitively in video settings.","Noise reduction,
Image denoising,
Conferences,
Optical imaging,
Computer vision,
Robustness,
Measurement"
