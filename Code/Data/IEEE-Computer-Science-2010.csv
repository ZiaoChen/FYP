Title,Abstract,Keywords
Recent Advances and Industrial Applications of Multilevel Converters,"Multilevel converters have been under research and development for more than three decades and have found successful industrial application. However, this is still a technology under development, and many new contributions and new commercial topologies have been reported in the last few years. The aim of this paper is to group and review these recent contributions, in order to establish the current state of the art and trends of the technology, to provide readers with a comprehensive and insightful review of where multilevel converter technology stands and is heading. This paper first presents a brief overview of well-established multilevel converters strongly oriented to their current state in industrial applications to then center the discussion on the new converters that have made their way into the industry. In addition, new promising topologies are discussed. Recent advances made in modulation and control of multilevel converters are also addressed. A great part of this paper is devoted to show nontraditional applications powered by multilevel converters and how multilevel converters are becoming an enabling technology in many industrial sectors. Finally, some future trends and challenges in the further development of this technology are discussed to motivate future contributions that address open problems and explore new possibilities.",
A Survey on Transfer Learning,"A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.",
Creating the CIPRES Science Gateway for inference of large phylogenetic trees,"Understanding the evolutionary history of living organisms is a central problem in biology. Until recently the ability to infer evolutionary relationships was limited by the amount of DNA sequence data available, but new DNA sequencing technologies have largely removed this limitation. As a result, DNA sequence data are readily available or obtainable for a wide spectrum of organisms, thus creating an unprecedented opportunity to explore evolutionary relationships broadly and deeply across the Tree of Life. Unfortunately, the algorithms used to infer evolutionary relationships are NP-hard, so the dramatic increase in available DNA sequence data has created a commensurate increase in the need for access to powerful computational resources. Local laptop or desktop machines are no longer viable for analysis of the larger data sets available today, and progress in the field relies upon access to large, scalable high-performance computing resources. This paper describes development of the CIPRES Science Gateway, a web portal designed to provide researchers with transparent access to the fastest available community codes for inference of phylogenetic relationships, and implementation of these codes on scalable computational resources. Meeting the needs of the community has included developing infrastructure to provide access, working with the community to improve existing community codes, developing infrastructure to insure the portal is scalable to the entire systematics community, and adopting strategies that make the project sustainable by the community. The CIPRES Science Gateway has allowed more than 1800 unique users to run jobs that required 2.5 million Service Units since its release in December 2009. (A Service Unit is a CPU-hour at unit priority).","Portals,
Logic gates,
Communities,
Phylogeny,
Computer architecture,
DNA,
XML"
elastix: A Toolbox for Intensity-Based Medical Image Registration,"Medical image registration is an important task in medical image processing. It refers to the process of aligning data sets, possibly from different modalities (e.g., magnetic resonance and computed tomography), different time points (e.g., follow-up scans), and/or different subjects (in case of population studies). A large number of methods for image registration are described in the literature. Unfortunately, there is not one method that works for all applications. We have therefore developed elastix, a publicly available computer program for intensity-based medical image registration. The software consists of a collection of algorithms that are commonly used to solve medical image registration problems. The modular design of elastix allows the user to quickly configure, test, and compare different registration methods for a specific application. The command-line interface enables automated processing of large numbers of data sets, by means of scripting. The usage of elastix for comparing different registration methods is illustrated with three example experiments, in which individual components of the registration method are varied.","MONOS devices,
Biomedical imaging,
Image registration,
Cost function,
Application software,
Optimization methods,
Spatial resolution,
Open source software,
Image processing,
Image segmentation"
Semidefinite Relaxation of Quadratic Optimization Problems,"In this article, we have provided general, comprehensive coverage of the SDR technique, from its practical deployments and scope of applicability to key theoretical results. We have also showcased several representative applications, namely MIMO detection, B¿ shimming in MRI, and sensor network localization. Another important application, namely downlink transmit beamforming, is described in [1]. Due to space limitations, we are unable to cover many other beautiful applications of the SDR technique, although we have done our best to illustrate the key intuitive ideas that resulted in those applications. We hope that this introductory article will serve as a good starting point for readers who would like to apply the SDR technique to their applications, and to locate specific references either in applications or theory.","Array signal processing,
Signal processing,
MIMO,
Downlink,
Ellipsoids,
Radar applications,
Robustness,
Parameter estimation,
Speech recognition,
Magnetic resonance imaging"
Enhanced Local Texture Feature Sets for Face Recognition Under Difficult Lighting Conditions,"Making recognition more reliable under uncontrolled lighting conditions is one of the most important challenges for practical face recognition systems. We tackle this by combining the strengths of robust illumination normalization, local texture-based face representations, distance transform based matching, kernel-based feature extraction and multiple feature fusion. Specifically, we make three main contributions: 1) we present a simple and efficient preprocessing chain that eliminates most of the effects of changing illumination while still preserving the essential appearance details that are needed for recognition; 2) we introduce local ternary patterns (LTP), a generalization of the local binary pattern (LBP) local texture descriptor that is more discriminant and less sensitive to noise in uniform regions, and we show that replacing comparisons based on local spatial histograms with a distance transform based similarity metric further improves the performance of LBP/LTP based face recognition; and 3) we further improve robustness by adding Kernel principal component analysis (PCA) feature extraction and incorporating rich local appearance cues from two complementary sources-Gabor wavelets and LBP-showing that the combination is considerably more accurate than either feature set alone. The resulting method provides state-of-the-art performance on three data sets that are widely used for testing recognition under difficult illumination conditions: Extended Yale-B, CAS-PEAL-R1, and Face Recognition Grand Challenge version 2 experiment 4 (FRGC-204). For example, on the challenging FRGC-204 data set it halves the error rate relative to previously published methods, achieving a face verification rate of 88.1% at 0.1% false accept rate. Further experiments show that our preprocessing method outperforms several existing preprocessors for a range of feature sets, data sets and lighting conditions.","Face recognition,
Lighting,
Feature extraction,
Principal component analysis,
Pattern recognition,
Histograms,
Wavelet transforms,
Noise robustness,
Kernel,
Wavelet analysis"
Improving Wireless Physical Layer Security via Cooperating Relays,"Physical (PHY) layer security approaches for wireless communications can prevent eavesdropping without upper layer data encryption. However, they are hampered by wireless channel conditions: absent feedback, they are typically feasible only when the source-destination channel is better than the source-eavesdropper channel. Node cooperation is a means to overcome this challenge and improve the performance of secure wireless communications. This paper addresses secure communications of one source-destination pair with the help of multiple cooperating relays in the presence of one or more eavesdroppers. Three cooperative schemes are considered: decode-and-forward (DF), amplify-and-forward (AF), and cooperative jamming (CJ). For these schemes, the relays transmit a weighted version of a reencoded noise-free message signal (for DF), a received noisy source signal (for AF), or a common jamming signal (for CJ). Novel system designs are proposed, consisting of the determination of relay weights and the allocation of transmit power, that maximize the achievable secrecy rate subject to a transmit power constraint, or, minimize the transmit power subject to a secrecy rate constraint. For DF in the presence of one eavesdropper, closed-form optimal solutions are derived for the relay weights. For other problems, since the optimal relay weights are difficult to obtain, several criteria are considered leading to suboptimal but simple solutions, i.e., the complete nulling of the message signals at all eavesdroppers (for DF and AF), or the complete nulling of jamming signal at the destination (for CJ). Based on the designed relay weights, for DF in the presence of multiple eavesdroppers, and for CJ in the presence of one eavesdropper, the optimal power allocation is obtained in closed-form; in all other cases the optimal power allocation is obtained via iterative algorithms. Numerical evaluation of the obtained secrecy rate and transmit power results show that the proposed design can significantly improve the performance of secure wireless communications.","Communication system security,
Physical layer,
Relays,
Wireless communication,
Jamming,
Data security,
Power system relaying,
Cryptography,
Feedback,
Decoding"
Network Coding for Distributed Storage Systems,"Distributed storage systems provide reliable access to data through redundancy spread over individually unreliable nodes. Application scenarios include data centers, peer-to-peer storage systems, and storage in wireless networks. Storing data using an erasure code, in fragments spread across nodes, requires less redundancy than simple replication for the same level of reliability. However, since fragments must be periodically replaced as nodes fail, a key question is how to generate encoded fragments in a distributed way while transferring as little data as possible across the network. For an erasure coded system, a common practice to repair from a single node failure is for a new node to reconstruct the whole encoded data object to generate just one encoded block. We show that this procedure is sub-optimal. We introduce the notion of regenerating codes, which allow a new node to communicate functions of the stored data from the surviving nodes. We show that regenerating codes can significantly reduce the repair bandwidth. Further, we show that there is a fundamental tradeoff between storage and repair bandwidth which we theoretically characterize using flow arguments on an appropriately constructed graph. By invoking constructive results in network coding, we introduce regenerating codes that can achieve any point in this optimal tradeoff.","Network coding,
Peer to peer computing,
Redundancy,
Bandwidth,
Telecommunication network reliability,
Wireless networks,
Communication system control,
Computer science,
Statistics"
Point Set Registration: Coherent Point Drift,"Point set registration is a key component in many computer vision tasks. The goal of point set registration is to assign correspondences between two sets of points and to recover the transformation that maps one point set to the other. Multiple factors, including an unknown nonrigid spatial transformation, large dimensionality of point set, noise, and outliers, make the point set registration a challenging problem. We introduce a probabilistic method, called the Coherent Point Drift (CPD) algorithm, for both rigid and nonrigid point set registration. We consider the alignment of two point sets as a probability density estimation problem. We fit the Gaussian mixture model (GMM) centroids (representing the first point set) to the data (the second point set) by maximizing the likelihood. We force the GMM centroids to move coherently as a group to preserve the topological structure of the point sets. In the rigid case, we impose the coherence constraint by reparameterization of GMM centroid locations with rigid parameters and derive a closed form solution of the maximization step of the EM algorithm in arbitrary dimensions. In the nonrigid case, we impose the coherence constraint by regularizing the displacement field and using the variational calculus to derive the optimal transformation. We also introduce a fast algorithm that reduces the method computation complexity to linear. We test the CPD algorithm for both rigid and nonrigid transformations in the presence of noise, outliers, and missing points, where CPD shows accurate results and outperforms current state-of-the-art methods.","Stereo vision,
Computational complexity,
Computer vision,
Coherence,
Image registration,
Shape,
Image recognition,
Feature extraction,
Degradation,
Biomedical imaging"
Distance Regularized Level Set Evolution and Its Application to Image Segmentation,"Level set methods have been widely used in image processing and computer vision. In conventional level set formulations, the level set function typically develops irregularities during its evolution, which may cause numerical errors and eventually destroy the stability of the evolution. Therefore, a numerical remedy, called reinitialization, is typically applied to periodically replace the degraded level set function with a signed distance function. However, the practice of reinitialization not only raises serious problems as when and how it should be performed, but also affects numerical accuracy in an undesirable way. This paper proposes a new variational level set formulation in which the regularity of the level set function is intrinsically maintained during the level set evolution. The level set evolution is derived as the gradient flow that minimizes an energy functional with a distance regularization term and an external energy that drives the motion of the zero level set toward desired locations. The distance regularization term is defined with a potential function such that the derived level set evolution has a unique forward-and-backward (FAB) diffusion effect, which is able to maintain a desired shape of the level set function, particularly a signed distance profile near the zero level set. This yields a new type of level set evolution called distance regularized level set evolution (DRLSE). The distance regularization effect eliminates the need for reinitialization and thereby avoids its induced numerical errors. In contrast to complicated implementations of conventional level set formulations, a simpler and more efficient finite difference scheme can be used to implement the DRLSE formulation. DRLSE also allows the use of more general and efficient initialization of the level set function. In its numerical implementation, relatively large time steps can be used in the finite difference scheme to reduce the number of iterations, while ensuring sufficient numerical accuracy. To demonstrate the effectiveness of the DRLSE formulation, we apply it to an edge-based active contour model for image segmentation, and provide a simple narrowband implementation to greatly reduce computational cost.",
Dictionaries for Sparse Representation Modeling,"Sparse and redundant representation modeling of data assumes an ability to describe signals as linear combinations of a few atoms from a pre-specified dictionary. As such, the choice of the dictionary that sparsifies the signals is crucial for the success of this model. In general, the choice of a proper dictionary can be done using one of two ways: i) building a sparsifying dictionary based on a mathematical model of the data, or ii) learning a dictionary to perform best on a training set. In this paper we describe the evolution of these two paradigms. As manifestations of the first approach, we cover topics such as wavelets, wavelet packets, contourlets, and curvelets, all aiming to exploit 1-D and 2-D mathematical models for constructing effective dictionaries for signals and images. Dictionary learning takes a different route, attaching the dictionary to a set of examples it is supposed to serve. From the seminal work of Field and Olshausen, through the MOD, the K-SVD, the Generalized PCA and others, this paper surveys the various options such training has to offer, up to the most recent contributions and structures.",
Secure Transmission With Multiple Antennas I: The MISOME Wiretap Channel,"The role of multiple antennas for secure communication is investigated within the framework of Wyner's wiretap channel. We characterize the secrecy capacity in terms of generalized eigenvalues when the sender and eavesdropper have multiple antennas, the intended receiver has a single antenna, and the channel matrices are fixed and known to all the terminals, and show that a beamforming strategy is capacity-achieving. In addition, we study a masked beamforming scheme that radiates power isotropically in all directions and show that it attains near-optimal performance in the high SNR regime. Insights into the scaling behavior of the capacity in the large antenna regime as well as extensions to ergodic fading channels are also provided.","Transmitting antennas,
Receiving antennas,
Array signal processing,
Wireless communication,
Eigenvalues and eigenfunctions,
Broadcasting,
Antenna arrays,
Communication system security,
Physical layer,
Protection"
Constrained Consensus and Optimization in Multi-Agent Networks,"We present distributed algorithms that can be used by multiple agents to align their estimates with a particular value over a network with time-varying connectivity. Our framework is general in that this value can represent a consensus value among multiple agents or an optimal solution of an optimization problem, where the global objective function is a combination of local agent objective functions. Our main focus is on constrained problems where the estimates of each agent are restricted to lie in different convex sets. To highlight the effects of constraints, we first consider a constrained consensus problem and present a distributed ""projected consensus algorithm"" in which agents combine their local averaging operation with projection on their individual constraint sets. This algorithm can be viewed as a version of an alternating projection method with weights that are varying over time and across agents. We establish convergence and convergence rate results for the projected consensus algorithm. We next study a constrained optimization problem for optimizing the sum of local objective functions of the agents subject to the intersection of their local constraint sets. We present a distributed ""projected subgradient algorithm"" which involves each agent performing a local averaging operation, taking a subgradient step to minimize its own objective function, and projecting on its constraint set. We show that, with an appropriately selected stepsize rule, the agent estimates generated by this algorithm converge to the same optimal solution for the cases when the weights are constant and equal, and when the weights are time-varying but all agents have the same constraint set.","Constraint optimization,
Distributed algorithms,
Convergence,
Autonomous agents,
Engineering profession,
Systems engineering and theory,
Laboratories,
Intelligent networks"
On Feasibility of Interference Alignment in MIMO Interference Networks,"We explore the feasibility of interference alignment in signal vector space-based only on beamforming-for K-user MIMO interference channels. Our main contribution is to relate the feasibility issue to the problem of determining the solvability of a multivariate polynomial system which is considered extensively in algebraic geometry. It is well known, e.g., from Bezout's theorem, that generic polynomial systems are solvable if and only if the number of equations does not exceed the number of variables. Following this intuition, we classify signal space interference alignment problems as either proper or improper based on the number of equations and variables. Rigorous connections between feasible and proper systems are made through Bernshtein's theorem for the case where each transmitter uses only one beamforming vector. The multibeam case introduces dependencies among the coefficients of a polynomial system so that the system is no longer generic in the sense required by both theorems. In this case, we show that the connection between feasible and proper systems can be further strengthened (since the equivalency between feasible and proper systems does not always hold) by including standard information theoretic outer bounds in the feasibility analysis.",
N4ITK: Improved N3 Bias Correction,"A variant of the popular nonparametric nonuniform intensity normalization (N3) algorithm is proposed for bias field correction. Given the superb performance of N3 and its public availability, it has been the subject of several evaluation studies. These studies have demonstrated the importance of certain parameters associated with the B-spline least-squares fitting. We propose the substitution of a recently developed fast and robust B-spline approximation routine and a modified hierarchical optimization scheme for improved bias field correction over the original N3 algorithm. Similar to the N3 algorithm, we also make the source code, testing, and technical documentation of our contribution, which we denote as ¿N4ITK,¿ available to the public through the Insight Toolkit of the National Institutes of Health. Performance assessment is demonstrated using simulated data from the publicly available Brainweb database, hyperpolarized 3He lung image data, and 9.4T postmortem hippocampus data.",
Computational Methods for Sparse Solution of Linear Inverse Problems,"The goal of the sparse approximation problem is to approximate a target signal using a linear combination of a few elementary signals drawn from a fixed collection. This paper surveys the major practical algorithms for sparse approximation. Specific attention is paid to computational issues, to the circumstances in which individual methods tend to perform well, and to the theoretical guarantees available. Many fundamental questions in electrical engineering, statistics, and applied mathematics can be posed as sparse approximation problems, making these algorithms versatile and relevant to a plethora of applications.","Inverse problems,
Least squares approximation,
Signal processing algorithms,
Approximation algorithms,
Signal processing,
Statistics,
Mathematics,
Matching pursuit algorithms,
Dictionaries,
Electrical engineering"
Second-Order Consensus for Multiagent Systems With Directed Topologies and Nonlinear Dynamics,"This paper considers a second-order consensus problem for multiagent systems with nonlinear dynamics and directed topologies where each agent is governed by both position and velocity consensus terms with a time-varying asymptotic velocity. To describe the system's ability for reaching consensus, a new concept about the generalized algebraic connectivity is defined for strongly connected networks and then extended to the strongly connected components of the directed network containing a spanning tree. Some sufficient conditions are derived for reaching second-order consensus in multiagent systems with nonlinear dynamics based on algebraic graph theory, matrix theory, and Lyapunov control approach. Finally, simulation examples are given to verify the theoretical analysis.","Multiagent systems,
Network topology,
Time varying systems,
Tree graphs,
Sufficient conditions,
Graph theory,
Matrices,
Nonlinear control systems,
Control systems,
Analytical models"
Smart Transmission Grid: Vision and Framework,"A modern power grid needs to become smarter in order to provide an affordable, reliable, and sustainable supply of electricity. For these reasons, considerable activity has been carried out in the United States and Europe to formulate and promote a vision for the development of future smart power grids. However, the majority of these activities emphasized only the distribution grid and demand side leaving the big picture of the transmission grid in the context of smart grids unclear. This paper presents a unique vision for the future of smart transmission grids in which their major features are identified. In this vision, each smart transmission grid is regarded as an integrated system that functionally consists of three interactive, smart components, i.e., smart control centers, smart transmission networks, and smart substations. The features and functions of each of the three functional components, as well as the enabling technologies to achieve these features and functions, are discussed in detail in the paper.","Smart grids,
Power systems,
Energy consumption,
Sun,
Control systems,
Substations,
Voltage,
Space technology,
Communication system control,
Power grids"
Matrix Completion With Noise,"On the heels of compressed sensing, a new field has very recently emerged. This field addresses a broad range of problems of significant practical interest, namely, the recovery of a data matrix from what appears to be incomplete, and perhaps even corrupted, information. In its simplest form, the problem is to recover a matrix from a small sample of its entries. It comes up in many areas of science and engineering, including collaborative filtering, machine learning, control, remote sensing, and computer vision, to name a few. This paper surveys the novel literature on matrix completion, which shows that under some suitable conditions, one can recover an unknown low-rank matrix from a nearly minimal set of entries by solving a simple convex optimization problem, namely, nuclear-norm minimization subject to data constraints. Further, this paper introduces novel results showing that matrix completion is provably accurate even when the few observed entries are corrupted with a small amount of noise. A typical result is that one can recover an unknown matrix of low rank from just about log noisy samples with an error that is proportional to the noise level. We present numerical results that complement our quantitative analysis and show that, in practice, nuclear-norm minimization accurately fills in the many missing entries of large low-rank matrices from just a few noisy samples. Some analogies between matrix completion and compressed sensing are discussed throughout.","Motion pictures,
Compressed sensing,
Linear matrix inequalities,
Noise level,
Frequency,
Collaboration,
Filtering,
Machine learning,
Remote sensing,
Computer vision"
WLD: A Robust Local Image Descriptor,"Inspired by Weber's Law, this paper proposes a simple, yet very powerful and robust local descriptor, called the Weber Local Descriptor (WLD). It is based on the fact that human perception of a pattern depends not only on the change of a stimulus (such as sound, lighting) but also on the original intensity of the stimulus. Specifically, WLD consists of two components: differential excitation and orientation. The differential excitation component is a function of the ratio between two terms: One is the relative intensity differences of a current pixel against its neighbors, the other is the intensity of the current pixel. The orientation component is the gradient orientation of the current pixel. For a given image, we use the two components to construct a concatenated WLD histogram. Experimental results on the Brodatz and KTH-TIPS2-a texture databases show that WLD impressively outperforms the other widely used descriptors (e.g., Gabor and SIFT). In addition, experimental results on human face detection also show a promising performance comparable to the best known results on the MIT+CMU frontal face test set, the AR face data set, and the CMU profile test set.","Robustness,
Face detection,
Image edge detection,
Histograms,
Humans,
Testing,
Face recognition,
Pixel,
Image motion analysis,
Image texture analysis"
Discriminative K-SVD for dictionary learning in face recognition,"In a sparse-representation-based face recognition scheme, the desired dictionary should have good representational power (i.e., being able to span the subspace of all faces) while supporting optimal discrimination of the classes (i.e., different human subjects). We propose a method to learn an over-complete dictionary that attempts to simultaneously achieve the above two goals. The proposed method, discriminative K-SVD (D-KSVD), is based on extending the K-SVD algorithm by incorporating the classification error into the objective function, thus allowing the performance of a linear classifier and the representational power of the dictionary being considered at the same time by the same optimization procedure. The D-KSVD algorithm finds the dictionary and solves for the classifier using a procedure derived from the K-SVD algorithm, which has proven efficiency and performance. This is in contrast to most existing work that relies on iteratively solving sub-problems with the hope of achieving the global optimal through iterative approximation. We evaluate the proposed method using two commonly-used face databases, the Extended YaleB database and the AR database, with detailed comparison to 3 alternative approaches, including the leading state-of-the-art in the literature. The experiments show that the proposed method outperforms these competing methods in most of the cases. Further, using Fisher criterion and dictionary incoherence, we also show that the learned dictionary and the corresponding classifier are indeed better-posed to support sparse-representation-based recognition.",
Gossip Algorithms for Distributed Signal Processing,"Gossip algorithms are attractive for in-network processing in sensor networks because they do not require any specialized routing, there is no bottleneck or single point of failure, and they are robust to unreliable wireless network conditions. Recently, there has been a surge of activity in the computer science, control, signal processing, and information theory communities, developing faster and more robust gossip algorithms and deriving theoretical performance guarantees. This paper presents an overview of recent work in the area. We describe convergence rate results, which are related to the number of transmitted messages and thus the amount of energy consumed in the network for gossiping. We discuss issues related to gossiping over wireless links, including the effects of quantization and noise, and we illustrate the use of gossip algorithms for canonical signal processing tasks including distributed estimation, source localization, and compression.",
Near-Threshold Computing: Reclaiming Moore's Law Through Energy Efficient Integrated Circuits,"Power has become the primary design constraint for chip designers today. While Moore's law continues to provide additional transistors, power budgets have begun to prohibit those devices from actually being used. To reduce energy consumption, voltage scaling techniques have proved a popular technique with subthreshold design representing the endpoint of voltage scaling. Although it is extremely energy efficient, subthreshold design has been relegated to niche markets due to its major performance penalties. This paper defines and explores near-threshold computing (NTC), a design space where the supply voltage is approximately equal to the threshold voltage of the transistors. This region retains much of the energy savings of subthreshold operation with more favorable performance and variability characteristics. This makes it applicable to a broad range of power-constrained computing segments from sensors to high performance servers. This paper explores the barriers to the widespread adoption of NTC and describes current work aimed at overcoming these obstacles.","Moore's Law,
Energy efficiency,
CMOS technology,
Threshold voltage,
Computer architecture,
Fabrication,
Clocks,
Design optimization,
Energy consumption,
High performance computing"
OpenCL: A Parallel Programming Standard for Heterogeneous Computing Systems,"The OpenCL standard offers a common API for program execution on systems composed of different types of computational devices such as multicore CPUs, GPUs, or other accelerators.",
On the Role of Sparse and Redundant Representations in Image Processing,"Much of the progress made in image processing in the past decades can be attributed to better modeling of image content and a wise deployment of these models in relevant applications. This path of models spans from the simple l2-norm smoothness through robust, thus edge preserving, measures of smoothness (e.g. total variation), and until the very recent models that employ sparse and redundant representations. In this paper, we review the role of this recent model in image processing, its rationale, and models related to it. As it turns out, the field of image processing is one of the main beneficiaries from the recent progress made in the theory and practice of sparse and redundant representations. We discuss ways to employ these tools for various image-processing tasks and present several applications in which state-of-the-art results are obtained.",
Educational Data Mining: A Review of the State of the Art,"Educational data mining (EDM) is an emerging interdisciplinary research area that deals with the development of methods to explore data originating in an educational context. EDM uses computational approaches to analyze educational data in order to study educational questions. This paper surveys the most relevant studies carried out in this field to date. First, it introduces EDM and describes the different groups of user, types of educational environments, and the data they provide. It then goes on to list the most typical/common tasks in the educational environment that have been resolved through data-mining techniques, and finally, some of the most promising future lines of research are discussed.","Data mining,
Delta modulation,
Electronic learning,
Databases,
Psychometric testing,
Least squares approximation,
Data analysis,
Instruments,
Internet,
Gold"
Management and Control of Domestic Smart Grid Technology,"Emerging new technologies like distributed generation, distributed storage, and demand-side load management will change the way we consume and produce energy. These techniques enable the possibility to reduce the greenhouse effect and improve grid stability by optimizing energy streams. By smartly applying future energy production, consumption, and storage techniques, a more energy-efficient electricity supply chain can be achieved. In this paper a three-step control methodology is proposed to manage the cooperation between these technologies, focused on domestic energy streams. In this approach, (global) objectives like peak shaving or forming a virtual power plant can be achieved without harming the comfort of residents. As shown in this work, using good predictions, in advance planning and real-time control of domestic appliances, a better matching of demand and supply can be achieved.","Technology management,
Smart grids,
Optimized production technology,
Energy storage,
Load management,
Distributed control,
Stability,
Energy efficiency,
Energy consumption,
Supply chains"
"Parallel Control and Management for Intelligent Transportation Systems: Concepts, Architectures, and Applications","Parallel control and management have been proposed as a new mechanism for conducting operations of complex systems, especially those that involved complexity issues of both engineering and social dimensions, such as transportation systems. This paper presents an overview of the background, concepts, basic methods, major issues, and current applications of Parallel transportation Management Systems (PtMS). In essence, parallel control and management is a data-driven approach for modeling, analysis, and decision-making that considers both the engineering and social complexity in its processes. The developments and applications described here clearly indicate that PtMS is effective for use in networked complex traffic systems and is closely related to emerging technologies in cloud computing, social computing, and cyberphysical-social systems. A description of PtMS system architectures, processes, and components, including OTSt, Dyna CAS, aDAPTS, iTOP, and TransWorld is presented and discussed. Finally, the experiments and examples of real-world applications are illustrated and analyzed.","Intelligent transportation systems,
Control systems,
Engineering management,
Decision making,
Data engineering,
Communication system traffic control,
Traffic control,
Cloud computing,
Social network services,
Computer architecture"
SVM- and MRF-Based Method for Accurate Classification of Hyperspectral Images,"The high number of spectral bands acquired by hyperspectral sensors increases the capability to distinguish physical materials and objects, presenting new challenges to image analysis and classification. This letter presents a novel method for accurate spectral-spatial classification of hyperspectral images. The proposed technique consists of two steps. In the first step, a probabilistic support vector machine pixelwise classification of the hyperspectral image is applied. In the second step, spatial contextual information is used for refining the classification results obtained in the first step. This is achieved by means of a Markov random field regularization. Experimental results are presented for three hyperspectral airborne images and compared with those obtained by recently proposed advanced spectral-spatial classification techniques. The proposed method improves classification accuracies when compared to other classification approaches.","Hyperspectral imaging,
Hyperspectral sensors,
Support vector machines,
Support vector machine classification,
Markov random fields,
Image classification,
Layout,
Senior members,
Image analysis,
Pixel"
Secure Transmission With Artificial Noise Over Fading Channels: Achievable Rate and Optimal Power Allocation,"We consider the problem of secure communication with multiantenna transmission in fading channels. The transmitter simultaneously transmits an information-bearing signal to the intended receiver and artificial noise to the eavesdroppers. We obtain an analytical closed-form expression of an achievable secrecy rate and use it as the objective function to optimize the transmit power allocation between the information signal and the artificial noise. Our analytical and numerical results show that equal power allocation is a simple yet near-optimal strategy for the case of noncolluding eavesdroppers. When the number of colluding eavesdroppers increases, more power should be used to generate the artificial noise. We also provide an upper bound on the SNR, above which, the achievable secrecy rate is positive and shows that the bound is tight at low SNR. Furthermore, we consider the impact of imperfect channel state information (CSI) at both the transmitter and the receiver and find that it is wise to create more artificial noise to confuse the eavesdroppers than to increase the signal strength for the intended receiver if the CSI is not accurately obtained.",
Double Sparsity: Learning Sparse Dictionaries for Sparse Signal Approximation,"An efficient and flexible dictionary structure is proposed for sparse and redundant signal representation. The proposed sparse dictionary is based on a sparsity model of the dictionary atoms over a base dictionary, and takes the form D = ¿ A, where ¿ is a fixed base dictionary and A is sparse. The sparse dictionary provides efficient forward and adjoint operators, has a compact representation, and can be effectively trained from given example data. In this, the sparse structure bridges the gap between implicit dictionaries, which have efficient implementations yet lack adaptability, and explicit dictionaries, which are fully adaptable but non-efficient and costly to deploy. In this paper, we discuss the advantages of sparse dictionaries, and present an efficient algorithm for training them. We demonstrate the advantages of the proposed structure for 3-D image denoising.","Dictionaries,
Signal processing,
Machine learning algorithms,
Signal processing algorithms,
Principal component analysis,
Bridges,
Mathematical model,
Signal representations,
Image denoising,
Tomography"
Outlier Detection Techniques for Wireless Sensor Networks: A Survey,"In the field of wireless sensor networks, those measurements that significantly deviate from the normal pattern of sensed data are considered as outliers. The potential sources of outliers include noise and errors, events, and malicious attacks on the network. Traditional outlier detection techniques are not directly applicable to wireless sensor networks due to the nature of sensor data and specific requirements and limitations of the wireless sensor networks. This survey provides a comprehensive overview of existing outlier detection techniques specifically developed for the wireless sensor networks. Additionally, it presents a technique-based taxonomy and a comparative table to be used as a guideline to select a technique suitable for the application at hand based on characteristics such as data type, outlier type, outlier identity, and outlier degree.",
Wireless Sensor Networks for Healthcare,"Driven by the confluence between the need to collect data about people's physical, physiological, psychological, cognitive, and behavioral processes in spaces ranging from personal to urban and the recent availability of the technologies that enable this data collection, wireless sensor networks for healthcare have emerged in the recent years. In this review, we present some representative applications in the healthcare domain and describe the challenges they introduce to wireless sensor networks due to the required level of trustworthiness and the need to ensure the privacy and security of medical data. These challenges are exacerbated by the resource scarcity that is inherent with wireless sensor network platforms. We outline prototype systems spanning application domains from physiological and activity monitoring to large-scale physiological and behavioral studies and emphasize ongoing research challenges.","Wireless sensor networks,
Medical services,
Sensors,
Biomedical monitoring,
Wireless communication,
Monitoring,
Medical diagnostic imaging"
Morphological Attribute Profiles for the Analysis of Very High Resolution Images,"Morphological attribute profiles (APs) are defined as a generalization of the recently proposed morphological profiles (MPs). APs provide a multilevel characterization of an image created by the sequential application of morphological attribute filters that can be used to model different kinds of the structural information. According to the type of the attributes considered in the morphological attribute transformation, different parametric features can be modeled. The generation of APs, thanks to an efficient implementation, strongly reduces the computational load required for the computation of conventional MPs. Moreover, the characterization of the image with different attributes leads to a more complete description of the scene and to a more accurate modeling of the spatial information than with the use of conventional morphological filters based on a predefined structuring element. Here, the features extracted by the proposed operators were used for the classification of two very high resolution panchromatic images acquired by Quickbird on the city of Trento, Italy. The experimental analysis proved the usefulness of APs in modeling the spatial information present in the images. The classification maps obtained by considering different APs result in a better description of the scene (both in terms of thematic and geometric accuracy) than those obtained with an MP.","Image analysis,
Image resolution,
Information filtering,
Information filters,
Layout,
Lead,
Feature extraction,
Data mining,
Spatial resolution,
Cities and towns"
Convolutional networks and applications in vision,"Intelligent tasks, such as visual perception, auditory perception, and language understanding require the construction of good internal representations of the world (or ""features"")? which must be invariant to irrelevant variations of the input while, preserving relevant information. A major question for Machine Learning is how to learn such good features automatically. Convolutional Networks (ConvNets) are a biologically-inspired trainable architecture that can learn invariant features. Each stage in a ConvNets is composed of a filter bank, some nonlinearities, and feature pooling layers. With multiple stages, a ConvNet can learn multi-level hierarchies of features. While ConvNets have been successfully deployed in many commercial applications from OCR to video surveillance, they require large amounts of labeled training samples. We describe new unsupervised learning algorithms, and new non-linear stages that allow ConvNets to be trained with very few labeled samples. Applications to visual object recognition and vision navigation for off-road mobile robots are described.","Learning systems,
Visual perception,
Machine learning,
Filter bank,
Optical character recognition software,
Video surveillance,
Unsupervised learning,
Object recognition,
Navigation,
Mobile robots"
A Distributed Control Approach to A Robust Output Regulation Problem for Multi-Agent Linear Systems,"In this note, the robust output regulation problem of a multi-agent system is considered. An internal model based distributed control scheme is adopted to achieve the objectives of asymptotic tracking and disturbance rejection in an uncertain multi-agent system where both the reference inputs and disturbances are generated by an exosystem.",
Reversible Image Watermarking Using Interpolation Technique,"Watermarking embeds information into a digital signal like audio, image, or video. Reversible image watermarking can restore the original image without any distortion after the hidden data is extracted. In this paper, we present a novel reversible watermarking scheme using an interpolation technique, which can embed a large amount of covert data into images with imperceptible modification. Different from previous watermarking schemes, we utilize the interpolation-error, the difference between interpolation value and corresponding pixel value, to embed bit ¿1¿ or ¿0¿ by expanding it additively or leaving it unchanged. Due to the slight modification of pixels, high image quality is preserved. Experimental results also demonstrate that the proposed scheme can provide greater payload capacity and higher image fidelity compared with other state-of-the-art schemes.",
Convex Optimization-Based Beamforming,"In this article, an overview of advanced convex optimization approaches to multisensor beamforming is presented, and connections are drawn between different types of optimization-based beamformers that apply to a broad class of receive, transmit, and network beamformer design problems. It is demonstrated that convex optimization provides an indispensable set of tools for beamforming, enabling rigorous formulation and effective solution of both long-standing and emerging design problems.","Array signal processing,
Robustness,
Design optimization,
Interference,
Downlink,
Quality of service,
MIMO,
Unicast,
Radio transmitters,
Optimization methods"
Learning a hierarchy of discriminative space-time neighborhood features for human action recognition,"Recent work shows how to use local spatio-temporal features to learn models of realistic human actions from video. However, existing methods typically rely on a predefined spatial binning of the local descriptors to impose spatial information beyond a pure “bag-of-words” model, and thus may fail to capture the most informative space-time relationships. We propose to learn the shapes of space-time feature neighborhoods that are most discriminative for a given action category. Given a set of training videos, our method first extracts local motion and appearance features, quantizes them to a visual vocabulary, and then forms candidate neighborhoods consisting of the words associated with nearby points and their orientation with respect to the central interest point. Rather than dictate a particular scaling of the spatial and temporal dimensions to determine which points are near, we show how to learn the class-specific distance functions that form the most informative configurations. Descriptors for these variable-sized neighborhoods are then recursively mapped to higher-level vocabularies, producing a hierarchy of space-time configurations at successively broader scales. Our approach yields state-of-theart performance on the UCF Sports and KTH datasets.","Humans,
Vocabulary,
Histograms,
Shape measurement,
Tracking,
Computer science,
Data mining,
Surveillance,
Motion measurement,
Anthropometry"
L1-L2 Optimization in Signal and Image Processing,"Sparse, redundant representations offer a powerful emerging model for signals. This model approximates a data source as a linear combination of few atoms from a prespecified and over-complete dictionary. Often such models are fit to data by solving mixed ¿1-¿2 convex optimization problems. Iterative-shrinkage algorithms constitute a new family of highly effective numerical methods for handling these problems, surpassing traditional optimization techniques. In this article, we give a broad view of this group of methods, derive some of them, show accelerations based on the sequential subspace optimization (SESOP), fast iterative soft-thresholding algorithm (FISTA) and the conjugate gradient (CG) method, present a comparative performance, and discuss their potential in various applications, such as compressed sensing, computed tomography, and deblurring.",
A Tutorial on Graph-Based SLAM,"Being able to build a map of the environment and to simultaneously localize within this map is an essential skill for mobile robots navigating in unknown environments in absence of external referencing systems such as GPS. This so-called simultaneous localization and mapping (SLAM) problem has been one of the most popular research topics in mobile robotics for the last two decades and efficient approaches for solving this task have been proposed. One intuitive way of formulating SLAM is to use a graph whose nodes correspond to the poses of the robot at different points in time and whose edges represent constraints between the poses. The latter are obtained from observations of the environment or from movement actions carried out by the robot. Once such a graph is constructed, the map can be computed by finding the spatial configuration of the nodes that is mostly consistent with the measurements modeled by the edges. In this paper, we provide an introductory description to the graph-based SLAM problem. Furthermore, we discuss a state-of-the-art solution that is based on least-squares error minimization and exploits the structure of the SLAM problems during optimization. The goal of this tutorial is to enable the reader to implement the proposed methods from scratch.",
Adaptive Neural Control for Output Feedback Nonlinear Systems Using a Barrier Lyapunov Function,"In this brief, adaptive neural control is presented for a class of output feedback nonlinear systems in the presence of unknown functions. The unknown functions are handled via on-line neural network (NN) control using only output measurements. A barrier Lyapunov function (BLF) is introduced to address two open and challenging problems in the neuro-control area: 1) for any initial compact set, how to determine a priori the compact superset, on which NN approximation is valid; and 2) how to ensure that the arguments of the unknown functions remain within the specified compact superset. By ensuring boundedness of the BLF, we actively constrain the argument of the unknown functions to remain within a compact superset such that the NN approximation conditions hold. The semiglobal boundedness of all closed-loop signals is ensured, and the tracking error converges to a neighborhood of zero. Simulation results demonstrate the effectiveness of the proposed approach.","Programmable control,
Adaptive control,
Nonlinear control systems,
Control systems,
Output feedback,
Nonlinear systems,
Lyapunov method,
Neural networks,
Sliding mode control,
Stability"
New features and insights for pedestrian detection,"Despite impressive progress in people detection the performance on challenging datasets like Caltech Pedestrians or TUD-Brussels is still unsatisfactory. In this work we show that motion features derived from optic flow yield substantial improvements on image sequences, if implemented correctly — even in the case of low-quality video and consequently degraded flow fields. Furthermore, we introduce a new feature, self-similarity on color channels, which consistently improves detection performance both for static images and for video sequences, across different datasets. In combination with HOG, these two features outperform the state-of-the-art by up to 20%. Finally, we report two insights concerning detector evaluations, which apply to classifier-based object detection in general. First, we show that a commonly under-estimated detail of training, the number of bootstrapping rounds, has a drastic influence on the relative (and absolute) performance of different feature/classifier combinations. Second, we discuss important intricacies of detector evaluation and show that current benchmarking protocols lack crucial details, which can distort evaluations.","Image motion analysis,
Detectors,
Object detection,
Image sequences,
Optical saturation,
Humans,
Histograms,
Cascading style sheets,
Feature extraction,
Optical sensors"
A Generative Model for Image Segmentation Based on Label Fusion,"We propose a nonparametric, probabilistic model for the automatic segmentation of medical images, given a training set of images and corresponding label maps. The resulting inference algorithms rely on pairwise registrations between the test image and individual training images. The training labels are then transferred to the test image and fused to compute the final segmentation of the test subject. Such label fusion methods have been shown to yield accurate segmentation, since the use of multiple registrations captures greater inter-subject anatomical variability and improves robustness against occasional registration failures. To the best of our knowledge, this manuscript presents the first comprehensive probabilistic framework that rigorously motivates label fusion as a segmentation approach. The proposed framework allows us to compare different label fusion algorithms theoretically and practically. In particular, recent label fusion or multiatlas segmentation algorithms are interpreted as special cases of our framework. We conduct two sets of experiments to validate the proposed methods. In the first set of experiments, we use 39 brain MRI scans - with manually segmented white matter, cerebral cortex, ventricles and subcortical structures - to compare different label fusion algorithms and the widely-used FreeSurfer whole-brain segmentation tool. Our results indicate that the proposed framework yields more accurate segmentation than FreeSurfer and previous label fusion algorithms. In a second experiment, we use brain MRI scans of 282 subjects to demonstrate that the proposed segmentation tool is sufficiently sensitive to robustly detect hippocampal volume changes in a study of aging and Alzheimer's Disease.","Fusion power generation,
Image generation,
Image segmentation,
Testing,
Robustness,
Magnetic resonance imaging,
Biomedical imaging,
Inference algorithms,
Cerebral cortex,
Aging"
FRVT 2006 and ICE 2006 Large-Scale Experimental Results,"This paper describes the large-scale experimental results from the Face Recognition Vendor Test (FRVT) 2006 and the Iris Challenge Evaluation (ICE) 2006. The FRVT 2006 looked at recognition from high-resolution still frontal face images and 3D face images, and measured performance for still frontal face images taken under controlled and uncontrolled illumination. The ICE 2006 evaluation reported verification performance for both left and right irises. The images in the ICE 2006 intentionally represent a broader range of quality than the ICE 2006 sensor would normally acquire. This includes images that did not pass the quality control software embedded in the sensor. The FRVT 2006 results from controlled still and 3D images document at least an order-of-magnitude improvement in recognition performance over the FRVT 2002. The FRVT 2006 and the ICE 2006 compared recognition performance from high-resolution still frontal face images, 3D face images, and the single-iris images. On the FRVT 2006 and the ICE 2006 data sets, recognition performance was comparable for high-resolution frontal face, 3D face, and the iris images. In an experiment comparing human and algorithms on matching face identity across changes in illumination on frontal face images, the best performing algorithms were more accurate than humans on unfamiliar faces.","Ice,
Large-scale systems,
Face recognition,
Image recognition,
Iris,
Lighting,
Image sensors,
Humans,
Testing,
Waveguide discontinuities"
Retinal Imaging and Image Analysis,"Many important eye diseases as well as systemic diseases manifest themselves in the retina. While a number of other anatomical structures contribute to the process of vision, this review focuses on retinal imaging and image analysis. Following a brief overview of the most prevalent causes of blindness in the industrialized world that includes age-related macular degeneration, diabetic retinopathy, and glaucoma, the review is devoted to retinal imaging and image analysis methods and their clinical implications. Methods for 2-D fundus imaging and techniques for 3-D optical coherence tomography (OCT) imaging are reviewed. Special attention is given to quantitative techniques for analysis of fundus photographs with a focus on clinically relevant assessment of retinal vasculature, identification of retinal lesions, assessment of optic nerve head (ONH) shape, building retinal atlases, and to automated methods for population screening for retinal diseases. A separate section is devoted to 3-D analysis of OCT images, describing methods for segmentation and analysis of retinal layers, retinal vasculature, and 2-D/3-D detection of symptomatic exudate-associated derangements, as well as to OCT-based analysis of ONH morphology and shape. Throughout the paper, aspects of image acquisition, image analysis, and clinical relevance are treated together considering their mutually interlinked relationships.",
Cyber-physical systems: The next computing revolution,"Cyber-physical systems (CPS) are physical and engineered systems whose operations are monitored, coordinated, controlled and integrated by a computing and communication core. Just as the internet transformed how humans interact with one another, cyber-physical systems will transform how we interact with the physical world around us. Many grand challenges await in the economically vital domains of transportation, health-care, manufacturing, agriculture, energy, defense, aerospace and buildings. The design, construction and verification of cyber-physical systems pose a multitude of technical challenges that must be addressed by a cross-disciplinary community of researchers and educators.","Systems engineering and theory,
Monitoring,
Communication system control,
Control systems,
Physics computing,
Internet,
Humans,
Power generation economics,
Transportation,
Manufacturing"
Robust Global Exponential Synchronization of Uncertain Chaotic Delayed Neural Networks via Dual-Stage Impulsive Control,"This paper is concerned with the robust exponential synchronization problem of a class of chaotic delayed neural networks with different parametric uncertainties. A novel impulsive control scheme (so-called dual-stage impulsive control) is proposed. Based on the theory of impulsive functional differential equations, a global exponential synchronization error bound together with some new sufficient conditions expressed in the form of linear matrix inequalities (LMIs) is derived in order to guarantee that the synchronization error dynamics can converge to a predetermined level. Furthermore, to estimate the stable region, a novel optimization control algorithm is established, which can deal with the minimum problem with two nonlinear terms coexisting in LMIs effectively. The idea and approach developed in this paper can provide a more practical framework for the synchronization of multiperturbation delayed chaotic systems. Simulation results finally demonstrate the effectiveness of the proposed method.",
Digital Image Watermarking Using Discrete Wavelet Transform and Singular Value Decomposition,"The main objective of developing an image-watermarking technique is to satisfy both imperceptibility and robustness requirements. To achieve this objective, a hybrid image-watermarking scheme based on discrete wavelet transform (DWT) and singular value decomposition (SVD) is proposed in this paper. In our approach, the watermark is not embedded directly on the wavelet coefficients but rather than on the elements of singular values of the cover image's DWT subbands. Experimental results are provided to illustrate that the proposed approach is able to withstand a variety of image-processing attacks.",
Distributed Generation: Toward a New Energy Paradigm,"This paper discusses distributed generation which is emerging as a new paradigm to produce on-site highly reliable and good quality electrical power. Thus, the DG systems are presented as a suitable form to offer highly reliable electrical power supply. The concept is particularly interesting when different kinds of energy resources are available, such as photovoltaic (PV) panels, fuel cells (FCs), or wind turbines.",
Toward General Type-2 Fuzzy Logic Systems Based on zSlices,"Higher order fuzzy logic systems (FLSs), such as interval type-2 FLSs, have been shown to be very well suited to deal with the high levels of uncertainties present in the majority of real-world applications. General type-2 FLSs are expected to further extend this capability. However, the immense computational complexities associated with general type-2 FLSs have, until recently, prevented their application to real-world control problems. This paper aims to address this problem by the introduction of a complete representation framework, which is referred to as zSlices-based general type-2 fuzzy systems. The proposed approach will lead to a significant reduction in both the complexity and the computational requirements for general type-2 FLSs, while it offers the capability to represent complex general type-2 fuzzy sets. As a proof-of-concept application, we have implemented a zSlices-based general type-2 FLS for a two-wheeled mobile robot, which operates in a real-world outdoor environment. We have evaluated the computational performance of the zSlices-based general type-2 FLS, which is suitable for multiprocessor execution. Finally, we have compared the performance of the zSlices-based general type-2 FLS against type-1 and interval type-2 FLSs, and a series of results is presented which is related to the different levels of uncertainty handled by the different types of FLSs.","Fuzzy logic,
Fuzzy sets,
Uncertainty,
Fuzzy systems,
Computer science,
Computational complexity,
Mobile robots,
Logic design,
Design methodology,
Robustness"
A Survey on the Application of Genetic Programming to Classification,"Classification is one of the most researched questions in machine learning and data mining. A wide range of real problems have been stated as classification problems, for example credit scoring, bankruptcy prediction, medical diagnosis, pattern recognition, text categorization, software quality assessment, and many more. The use of evolutionary algorithms for training classifiers has been studied in the past few decades. Genetic programming (GP) is a flexible and powerful evolutionary technique with some features that can be very valuable and suitable for the evolution of classifiers. This paper surveys existing literature about the application of genetic programming to classification, to show the different ways in which this evolutionary algorithm can help in the construction of accurate and reliable classifiers.","Genetic programming,
Unsupervised learning,
Supervised learning,
Machine learning,
Data mining,
Evolutionary computation,
Decision trees,
Classification tree analysis,
Computer science,
Medical diagnosis"
A Distributed CSMA Algorithm for Throughput and Utility Maximization in Wireless Networks,"In multihop wireless networks, designing distributed scheduling algorithms to achieve the maximal throughput is a challenging problem because of the complex interference constraints among different links. Traditional maximal-weight scheduling (MWS), although throughput-optimal, is difficult to implement in distributed networks. On the other hand, a distributed greedy protocol similar to IEEE 802.11 does not guarantee the maximal throughput. In this paper, we introduce an adaptive carrier sense multiple access (CSMA) scheduling algorithm that can achieve the maximal throughput distributively. Some of the major advantages of the algorithm are that it applies to a very general interference model and that it is simple, distributed, and asynchronous. Furthermore, the algorithm is combined with congestion control to achieve the optimal utility and fairness of competing flows. Simulations verify the effectiveness of the algorithm. Also, the adaptive CSMA scheduling is a modular MAC-layer algorithm that can be combined with various protocols in the transport layer and network layer. Finally, the paper explores some implementation issues in the setting of 802.11 networks.","Multiaccess communication,
Throughput,
Wireless networks,
Scheduling algorithm,
Spread spectrum communication,
Algorithm design and analysis,
Interference constraints,
Access protocols,
Optimal control,
Adaptive scheduling"
Performance Analysis of High Performance Computing Applications on the Amazon Web Services Cloud,"Cloud computing has seen tremendous growth, particularly for commercial web applications. The on-demand, pay-as-you-go model creates a flexible and cost-effective means to access compute resources. For these reasons, the scientific computing community has shown increasing interest in exploring cloud computing. However, the underlying implementation and performance of clouds are very different from those at traditional supercomputing centers. It is therefore critical to evaluate the performance of HPC applications in today’s cloud environments to understand the tradeoffs inherent in migrating to the cloud. This work represents the most comprehensive evaluation to date comparing conventional HPC platforms to Amazon EC2, using real applications representative of the workload at a typical supercomputing center. Overall results indicate that EC2 is six times slower than a typical mid-range Linux cluster, and twenty times slower than a modern HPC system. The interconnect on the EC2 cloud platform severely limits performance and causes significant variability.","Benchmark testing,
Program processors,
Bandwidth,
Cloud computing,
Stress,
Communities,
Computer aided manufacturing"
A Particle Swarm Optimization-Based Heuristic for Scheduling Workflow Applications in Cloud Computing Environments,"Cloud computing environments facilitate applications by providing virtualized resources that can be provisioned dynamically. However, users are charged on a pay-per-use basis. User applications may incur large data retrieval and execution costs when they are scheduled taking into account only the ‘execution time’. In addition to optimizing execution time, the cost arising from data transfers between resources as well as execution costs must also be taken into account. In this paper, we present a particle swarm optimization (PSO) based heuristic to schedule applications to cloud resources that takes into account both computation cost and data transmission cost. We experiment with a workflow application by varying its computation and communication costs. We compare the cost savings when using PSO and existing ‘Best Resource Selection’ (BRS) algorithm. Our results show that PSO can achieve: a) as much as 3 times cost savings as compared to BRS, and b) good distribution of workload onto resources.",
Co-Optimization of Generation Unit Commitment and Transmission Switching With N-1 Reliability,"Currently, there is a national push for a smarter electric grid, one that is more controllable and flexible. The full control of transmission assets are not currently built into electric network optimization models. Optimal transmission switching is a straightforward way to leverage grid controllability: to make better use of the existing system and meet growing demand with existing infrastructure. Previous papers have shown that optimizing the network topology improves the dispatch of electrical networks. Such optimal topology dispatch can be categorized as a smart grid application where there is a co-optimization of both generators and transmission topology. In this paper we present a co-optimization formulation of the generation unit commitment and transmission switching problem while ensuring N-1 reliability. We show that the optimal topology of the network can vary from hour to hour. We also show that optimizing the topology can change the optimal unit commitment schedule. This problem is large and computationally complex even for medium sized systems. We present decomposition and computational approaches to solving this problem. Results are presented for the IEEE RTS 96 test case.",
Outside the Closed World: On Using Machine Learning for Network Intrusion Detection,"In network intrusion detection research, one popular strategy for finding attacks is monitoring a network's activity for anomalies: deviations from profiles of normality previously learned from benign traffic, typically identified using tools borrowed from the machine learning community. However, despite extensive academic research one finds a striking gap in terms of actual deployments of such systems: compared with other intrusion detection approaches, machine learning is rarely employed in operational ""real world"" settings. We examine the differences between the network intrusion detection problem and other areas where machine learning regularly finds much more success. Our main claim is that the task of finding attacks is fundamentally different from these other applications, making it significantly harder for the intrusion detection community to employ machine learning effectively. We support this claim by identifying challenges particular to network intrusion detection, and provide a set of guidelines meant to strengthen future research on anomaly detection.","Machine learning,
Intrusion detection,
Computer science,
Telecommunication traffic,
Guidelines,
Computer security,
National security,
Privacy,
Laboratories,
Computerized monitoring"
Image Inpainting by Patch Propagation Using Patch Sparsity,"This paper introduces a novel examplar-based inpainting algorithm through investigating the sparsity of natural image patches. Two novel concepts of sparsity at the patch level are proposed for modeling the patch priority and patch representation, which are two crucial steps for patch propagation in the examplar-based inpainting approach. First, patch structure sparsity is designed to measure the confidence of a patch located at the image structure (e.g., the edge or corner) by the sparseness of its nonzero similarities to the neighboring patches. The patch with larger structure sparsity will be assigned higher priority for further inpainting. Second, it is assumed that the patch to be filled can be represented by the sparse linear combination of candidate patches under the local patch consistency constraint in a framework of sparse representation. Compared with the traditional examplar-based inpainting approach, structure sparsity enables better discrimination of structure and texture, and the patch sparse representation forces the newly inpainted regions to be sharp and consistent with the surrounding textures. Experiments on synthetic and natural images show the advantages of the proposed approach.",
Modeling mutual context of object and human pose in human-object interaction activities,"Detecting objects in cluttered scenes and estimating articulated human body parts are two challenging problems in computer vision. The difficulty is particularly pronounced in activities involving human-object interactions (e.g. playing tennis), where the relevant object tends to be small or only partially visible, and the human body parts are often self-occluded. We observe, however, that objects and human poses can serve as mutual context to each other – recognizing one facilitates the recognition of the other. In this paper we propose a new random field model to encode the mutual context of objects and human poses in human-object interaction activities. We then cast the model learning task as a structure learning problem, of which the structural connectivity between the object, the overall human pose, and different body parts are estimated through a structure search approach, and the parameters of the model are estimated by a new max-margin algorithm. On a sports data set of six classes of human-object interactions [12], we show that our mutual context model significantly outperforms state-of-the-art in detecting very difficult objects and human poses.","Context modeling,
Humans"
Fusing Local Patterns of Gabor Magnitude and Phase for Face Recognition,"Gabor features have been known to be effective for face recognition. However, only a few approaches utilize phase feature and they usually perform worse than those using magnitude feature. To investigate the potential of Gabor phase and its fusion with magnitude for face recognition, in this paper, we first propose local Gabor XOR patterns (LGXP), which encodes the Gabor phase by using the local XOR pattern (LXP) operator. Then, we introduce block-based Fisher's linear discriminant (BFLD) to reduce the dimensionality of the proposed descriptor and at the same time enhance its discriminative power. Finally, by using BFLD, we fuse local patterns of Gabor magnitude and phase for face recognition. We evaluate our approach on FERET and FRGC 2.0 databases. In particular, we perform comparative experimental studies of different local Gabor patterns. We also make a detailed comparison of their combinations with BFLD, as well as the fusion of different descriptors by using BFLD. Extensive experimental results verify the effectiveness of our LGXP descriptor and also show that our fusion approach outperforms most of the state-of-the-art approaches.",
Multiview Spectral Embedding,"In computer vision and multimedia search, it is common to use multiple features from different views to represent an object. For example, to well characterize a natural scene image, it is essential to find a set of visual features to represent its color, texture, and shape information and encode each feature into a vector. Therefore, we have a set of vectors in different spaces to represent the image. Conventional spectral-embedding algorithms cannot deal with such datum directly, so we have to concatenate these vectors together as a new vector. This concatenation is not physically meaningful because each feature has a specific statistical property. Therefore, we develop a new spectral-embedding algorithm, namely, multiview spectral embedding (MSE), which can encode different features in different ways, to achieve a physically meaningful embedding. In particular, MSE finds a low-dimensional embedding wherein the distribution of each view is sufficiently smooth, and MSE explores the complementary property of different views. Because there is no closed-form solution for MSE, we derive an alternating optimization-based iterative algorithm to obtain the low-dimensional embedding. Empirical evaluations based on the applications of image retrieval, video annotation, and document clustering demonstrate the effectiveness of the proposed approach.",
The Approximate Capacity of the Many-to-One and One-to-Many Gaussian Interference Channels,"Recently, Etkin, Tse, and Wang found the capacity region of the two-user Gaussian interference channel to within 1 bit/s/Hz. A natural goal is to apply this approach to the Gaussian interference channel with an arbitrary number of users. We make progress towards this goal by finding the capacity region of the many-to-one and one-to-many Gaussian interference channels to within a constant number of bits. The result makes use of a deterministic model to provide insight into the Gaussian channel. The deterministic model makes explicit the dimension of signal level. A central theme emerges: the use of lattice codes for alignment of interfering signals on the signal level.","Interference channels,
Gaussian channels,
Lattices,
Multiuser channels,
Radio spectrum management,
Recycling,
Communication system control,
Aggregates,
MIMO"
Adaptive Spatial Intercell Interference Cancellation in Multicell Wireless Networks,"Downlink spatial intercell interference cancellation (ICIC) is considered for mitigating other-cell interference using multiple transmit antennas. A principle question we explore is whether it is better to do ICIC or simply standard single-cell beamforming. We explore this question analytically and show that beamforming is preferred for all users when the edge SNR (signal-to-noise ratio) is low (<;0 dB), and ICIC is preferred when the edge SNR is high (>10 dB), for example in an urban setting. At medium SNR, a proposed adaptive strategy, where multiple base stations jointly select transmission strategies based on the user location, outperforms both while requiring a lower feedback rate than the pure ICIC approach. The employed metric is sum rate, which is normally a dubious metric for cellular systems, but surprisingly we show that even with this reward function the adaptive strategy also improves fairness. When the channel information is provided by limited feedback, the impact of the induced quantization error is also investigated. The analysis provides insights on the feedback design, and it is shown that ICIC with well-designed feedback strategies still provides significant throughput gain.",
Neural-Network-Based Adaptive Leader-Following Control for Multiagent Systems With Uncertainties,"A neural-network-based adaptive approach is proposed for the leader-following control of multiagent systems. The neural network is used to approximate the agent's uncertain dynamics, and the approximation error and external disturbances are counteracted by employing the robust signal. When there is no control input constraint, it can be proved that all the following agents can track the leader's time-varying state with the tracking error as small as desired. Compared with the related work in the literature, the uncertainty in the agent's dynamics is taken into account; the leader's state could be time-varying; and the proposed algorithm for each following agent is only dependent on the information of its neighbor agents. Finally, the satisfactory performance of the proposed method is illustrated by simulation examples.","Programmable control,
Adaptive control,
Control systems,
Multiagent systems,
Uncertainty,
Communication system control,
Neural networks,
Approximation error,
Robustness,
Research and development"
Constrained parametric min-cuts for automatic object segmentation,"We present a novel framework for generating and ranking plausible objects hypotheses in an image using bottom-up processes and mid-level cues. The object hypotheses are represented as figure-ground segmentations, and are extracted automatically, without prior knowledge about properties of individual object classes, by solving a sequence of constrained parametric min-cut problems (CPMC) on a regular image grid. We then learn to rank the object hypotheses by training a continuous model to predict how plausible the segments are, given their mid-level region properties. We show that this algorithm significantly outperforms the state of the art for low-level segmentation in the VOC09 segmentation dataset. It achieves the same average best segmentation covering as the best performing technique to date [2], 0.61 when using just the top 7 ranked segments, instead of the full hierarchy in [2]. Our method achieves 0.78 average best covering using 154 segments. In a companion paper [18], we also show that the algorithm achieves state-of-the art results when used in a segmentation-based recognition pipeline.","Object segmentation,
Image segmentation,
Machine learning,
Art,
Humans,
Machine learning algorithms,
Computer vision,
Numerical simulation,
Mathematics,
Predictive models"
Retinopathy Online Challenge: Automatic Detection of Microaneurysms in Digital Color Fundus Photographs,"The detection of microaneurysms in digital color fundus photographs is a critical first step in automated screening for diabetic retinopathy (DR), a common complication of diabetes. To accomplish this detection numerous methods have been published in the past but none of these was compared with each other on the same data. In this work we present the results of the first international microaneurysm detection competition, organized in the context of the Retinopathy Online Challenge (ROC), a multiyear online competition for various aspects of DR detection. For this competition, we compare the results of five different methods, produced by five different teams of researchers on the same set of data. The evaluation was performed in a uniform manner using an algorithm presented in this work. The set of data used for the competition consisted of 50 training images with available reference standard and 50 test images where the reference standard was withheld by the organizers (M. Niemeijer, B. van Ginneken, and M. D. AbrA¿moff). The results obtained on the test data was submitted through a website after which standardized evaluation software was used to determine the performance of each of the methods. A human expert detected microaneurysms in the test set to allow comparison with the performance of the automatic methods. The overall results show that microaneurysm detection is a challenging task for both the automatic methods as well as the human expert. There is room for improvement as the best performing system does not reach the performance of the human expert. The data associated with the ROC microaneurysm detection competition will remain publicly available and the website will continue accepting submissions.","Retinopathy,
Cities and towns,
Biomedical engineering,
Diabetes,
Telecommunications,
USA Councils,
Blindness,
Biomedical imaging,
Systems engineering and theory,
Statistics"
Auto-Context and Its Application to High-Level Vision Tasks and 3D Brain Image Segmentation,"The notion of using context information for solving high-level vision and medical image segmentation problems has been increasingly realized in the field. However, how to learn an effective and efficient context model, together with an image appearance model, remains mostly unknown. The current literature using Markov Random Fields (MRFs) and Conditional Random Fields (CRFs) often involves specific algorithm design in which the modeling and computing stages are studied in isolation. In this paper, we propose a learning algorithm, auto-context. Given a set of training images and their corresponding label maps, we first learn a classifier on local image patches. The discriminative probability (or classification confidence) maps created by the learned classifier are then used as context information, in addition to the original image patches, to train a new classifier. The algorithm then iterates until convergence. Auto-context integrates low-level and context information by fusing a large number of low-level appearance features with context and implicit shape information. The resulting discriminative algorithm is general and easy to implement. Under nearly the same parameter settings in training, we apply the algorithm to three challenging vision applications: foreground/background segregation, human body configuration estimation, and scene region labeling. Moreover, context also plays a very important role in medical/brain images where the anatomical structures are mostly constrained to relatively fixed positions. With only some slight changes resulting from using 3D instead of 2D features, the auto-context algorithm applied to brain MRI image segmentation is shown to outperform state-of-the-art algorithms specifically designed for this domain. Furthermore, the scope of the proposed algorithm goes beyond image analysis and it has the potential to be used for a wide variety of problems for structured prediction problems.","Brain,
Image segmentation,
Biomedical imaging,
Context modeling,
Algorithm design and analysis,
Markov random fields,
Convergence,
Shape,
Humans,
Layout"
Chattering Analysis,"A formal mathematical definition of chattering is proposed. Chattering phenomena are classified into three types. In particular, the first type is harmless and cannot be avoided. Chattering properties of various control approaches are considered. The dangerous second and third types of chattering phenomena are proved to be removable by proper use of high-order sliding-modes (HOSM). Fast stable actuators and sensors only generate the first type of chattering in HOSM systems and practically never affect the sliding motion. Computer simulation confirms the theoretical results.","Sliding mode control,
Actuators,
Sensor systems,
Control systems,
Mathematical model,
Feedback,
Vibration control,
Vibration measurement,
Temperature measurement,
Sensor phenomena and characterization"
The Promise of Nanomagnetics and Spintronics for Future Logic and Universal Memory,"This paper is both a review of some recent developments in the utilization of magnetism for applications to logic and memory and a description of some new innovations in nanomagnetics and spintronics. Nanomagnetics is primarily based on the magnetic interactions, while spintronics is primarily concerned with devices that utilize spin polarized currents. With the end of complementary metal-oxide-semiconductor (CMOS) in sight, nanomagnetics can provide a new paradigm for information process using the principles of magnetic quantum cellular automata (MQCA). This paper will review and describe these principles and then introduce a new nonlithographic method of producing reconfigurable arrays of MQCAs and/or storage bits that can be configured electrically. Furthermore, this paper will provide a brief description of magnetoresistive random access memory (MRAM), the first mainstream spintronic nonvolatile random access memory and project how far its successor spin transfer torque random access memory (STT-RAM) can go to provide a truly universal memory that can in principle replace most, if not all, semiconductor memories in the near future. For completeness, a description of an all-metal logic architecture based on magnetoresistive structures (transpinnor) will be described as well as some approaches to logic using magnetic tunnel junctions (MTJs).","Logic gates,
Random access memory,
Switches,
Magnetoelectronics,
Magnetization,
Magnetoresistance,
Magnetic tunneling"
MIMO Radar Using Compressive Sampling,"A multiple-input multiple-output (MIMO) radar system is proposed for obtaining angle and Doppler information on potential targets. Transmitters and receivers are nodes of a small scale wireless network and are assumed to be randomly scattered on a disk. The transmit nodes transmit uncorrelated waveforms. Each receive node applies compressive sampling to the received signal to obtain a small number of samples, which the node subsequently forwards to a fusion center. Assuming that the targets are sparsely located in the angle-Doppler space, based on the samples forwarded by the receive nodes the fusion center formulates an l 1 -optimization problem, the solution of which yields target angle and Doppler information. The proposed approach achieves the superior resolution of MIMO radar with far fewer samples than required by other approaches. This implies power savings during the communication phase between the receive nodes and the fusion center. Performance in the presence of a jammer is analyzed for the case of slowly moving targets. Issues related to forming the basis matrix that spans the angle-Doppler space, and for selecting a grid for that space are discussed. Extensive simulation results are provided to demonstrate the performance of the proposed approach at difference jammer and noise levels.","MIMO,
Sampling methods,
Radar antennas,
Radar cross section,
Doppler radar,
Direction of arrival estimation,
Receiving antennas,
Image coding,
Sparse matrices,
Radar imaging"
A Novel Set-Based Particle Swarm Optimization Method for Discrete Optimization Problems,"Particle swarm optimization (PSO) is predominately used to find solutions for continuous optimization problems. As the operators of PSO are originally designed in an n-dimensional continuous space, the advancement of using PSO to find solutions in a discrete space is at a slow pace. In this paper, a novel set-based PSO (S-PSO) method for the solutions of some combinatorial optimization problems (COPs) in discrete space is presented. The proposed S-PSO features the following characteristics. First, it is based on using a set-based representation scheme that enables S-PSO to characterize the discrete search space of COPs. Second, the candidate solution and velocity are defined as a crisp set, and a set with possibilities, respectively. All arithmetic operators in the velocity and position updating rules used in the original PSO are replaced by the operators and procedures defined on crisp sets, and sets with possibilities in S-PSO. The S-PSO method can thus follow a similar structure to the original PSO for searching in a discrete space. Based on the proposed S-PSO method, most of the existing PSO variants, such as the global version PSO, the local version PSO with different topologies, and the comprehensive learning PSO (CLPSO), can be extended to their corresponding discrete versions. These discrete PSO versions based on S-PSO are tested on two famous COPs: the traveling salesman problem and the multidimensional knapsack problem. Experimental results show that the discrete version of the CLPSO algorithm based on S-PSO is promising.",
Wide-Area Frequency Monitoring Network (FNET) Architecture and Applications,"Recent developments in smart grid technology have spawned interest in the use of phasor measurement units to help create a reliable power system transmission and distribution infrastructure. Wide-area monitoring systems (WAMSs) utilizing synchrophasor measurements can help with understanding, forecasting, or even controlling the status of power grid stability in real-time. A power system frequency monitoring network (FNET) was first proposed in 2001 and was established in 2004. As a pioneering WAMS, it serves the entire North American power grid through advanced situational awareness techniques, such as real-time event alerts, accurate event location estimation, animated event visualization, and post event analysis. Several papers published in the past several years discussed the FNET structure and its functionality. This paper presents some of the latest implementations of FNET's applications, which add significant capacities to this system for observing power system problems.",
FPGA Design and Implementation of a Real-Time Stereo Vision System,"Stereo vision is a well-known ranging method because it resembles the basic mechanism of the human eye. However, the computational complexity and large amount of data access make real-time processing of stereo vision challenging because of the inherent instruction cycle delay within conventional computers. In order to solve this problem, the past 20 years of research have focused on the use of dedicated hardware architecture for stereo vision. This paper proposes a fully pipelined stereo vision system providing a dense disparity image with additional sub-pixel accuracy in real-time. The entire stereo vision process, such as rectification, stereo matching, and post-processing, is realized using a single field programmable gate array (FPGA) without the necessity of any external devices. The hardware implementation is more than 230 times faster when compared to a software program operating on a conventional computer, and shows stronger performance over previous hardware-related studies.",
"A Wearable Sensor for Unobtrusive, Long-Term Assessment of Electrodermal Activity","Electrodermal activity (EDA) is a sensitive index of sympathetic nervous system activity. Due to the lack of sensors that can be worn comfortably during normal daily activity and over extensive periods of time, research in this area is limited to laboratory settings or artificial clinical environments. We developed a novel, unobtrusive, nonstigmatizing, wrist-worn integrated sensor, and present, for the very first time, a demonstration of long-term, continuous assessment of EDA outside of a laboratory setting. We evaluated the performance of our device against a Food and Drug Administration (FDA) approved system for the measurement of EDA during physical, cognitive, as well as emotional stressors at both palmar and distal forearm sites, and found high correlations across all the tests. We also evaluated the choice of electrode material by comparing conductive fabric with Ag/AgCl electrodes and discuss the limitations found. An important result presented in this paper is evidence that the distal forearm is a viable alternative to the traditional palmar sites for EDA measurements. Our device offers the unprecedented ability to perform comfortable, long-term, and in situ assessment of EDA. This paper opens up opportunities for future investigations that were previously not feasible, and could have far-reaching implications for diagnosis and understanding of psychological or neurological conditions.","Wearable sensors,
Electronic design automation and methodology,
Electrodes,
Sympathetic nervous system,
Laboratories,
Drugs,
Stress measurement,
System testing,
Conducting materials,
Fabrics"
Ergodic Capacity Analysis of Amplify-and-Forward MIMO Dual-Hop Systems,"This paper presents an analytical characterization of the ergodic capacity of amplify-and-forward (AF) MIMO dual-hop relay channels, assuming that the channel state information is available at the destination terminal only. In contrast to prior results, our expressions apply for arbitrary numbers of antennas and arbitrary relay configurations. We derive an expression for the exact ergodic capacity, simplified closed-form expressions for the high SNR regime, and tight closed-form upper and lower bounds. These results are made possible by employing recent tools from finite-dimensional random matrix theory, which are used to derive new closed-form expressions for various statistical properties of the equivalent AF MIMO dual-hop relay channel, such as the distribution of an unordered eigenvalue and certain random determinant properties. Based on the analytical capacity expressions, we investigate the impact of the system and channel characteristics, such as the antenna configuration and the relay power gain. We also demonstrate a number of interesting relationships between the dual-hop AF MIMO relay channel and conventional point-to-point MIMO channels in various asymptotic regimes.","MIMO,
Relays,
Power system relaying,
Closed-form solution,
Wireless networks,
Protocols,
Mobile communication,
Information analysis,
Channel state information,
Eigenvalues and eigenfunctions"
Optical Network Design With Mixed Line Rates and Multiple Modulation Formats,"With the growth of traffic volume and the emergence of various new applications, future telecom networks are expected to be increasingly heterogeneous with respect to applications supported and underlying technologies employed. To address this heterogeneity, it may be most cost effective to set up different lightpaths at different bit rates in such a backbone telecom mesh network employing optical wavelength-division multiplexing. This approach can be cost effective because low-bit-rate services will need less grooming (i.e., less multiplexing with other low-bit-rate services onto high-capacity wavelengths), while a high-bit-rate service can be accommodated directly on a wavelength itself. Optical networks with mixed line rates (MLRs), e.g., 10/40/100 Gb/s over different wavelength channels, are a new networking paradigm. The unregenerated reach of a lightpath depends on its line rate. So, the assignment of a line rate to a lightpath is a tradeoff between its capacity and transparent reach. Thus, based on their signal-quality constraints (threshold bit error rate), intelligent assignment of line rates to lightpaths can minimize the need for signal regeneration. This constraint on the transparent reach based on threshold signal quality can be relaxed by employing more advanced modulation formats, but with more investment. We propose a design method for MLR optical networks with transceivers employing different modulation formats. Our results demonstrate the tradeoff between a transceiver's cost and its optical reach in overall network design.","Optical fiber networks,
Optical design,
Modulation,
Costs,
Telecommunication traffic,
Bit rate,
Spine,
Mesh networks,
Wavelength division multiplexing,
WDM networks"
Routing in Socially Selfish Delay Tolerant Networks,"Existing routing algorithms for Delay Tolerant Networks(DTNs) assume that nodes are willing to forward packets for others. In the real world, however, most people are socially selfish; i.e., they are willing to forward packets for nodes with whom they have social ties but not others, and such willingness varies with the strength of the social tie. Following the philosophy of design for user, we propose a Social Selfishness Aware Routing (SSAR) algorithm to allow user selfishness and provide better routing performance in an efficient way. To select a forwarding node, SSAR considers both users' willingness to forward and their contact opportunity, resulting in a better forwarding strategy than purely contact-based approaches. Moreover, SSAR formulates the data forwarding process as a Multiple Knapsack Problem with Assignment Restrictions (MKPAR) to satisfy user demands for selfishness and performance. Trace-driven simulations show that SSAR allows users to maintain selfishness and achieves better routing performance with low transmission cost.","Routing,
Disruption tolerant networking,
Peer to peer computing,
Algorithm design and analysis,
Relays,
Communications Society,
Computer science,
Costs,
Wireless networks,
Packet switching"
Earthquake Damage Assessment of Buildings Using VHR Optical and SAR Imagery,"Rapid damage assessment after natural disasters (e.g., earthquakes) and violent conflicts (e.g., war-related destruction) is crucial for initiating effective emergency response actions. Remote-sensing satellites equipped with very high spatial resolution (VHR) multispectral and synthetic aperture radar (SAR) imaging sensors can provide vital information due to their ability to map the affected areas with high geometric precision and in an uncensored manner. In this paper, we present a novel method that detects buildings destroyed in an earthquake using pre-event VHR optical and post-event detected VHR SAR imagery. The method operates at the level of individual buildings and assumes that they have a rectangular footprint and are isolated. First, the 3-D parameters of a building are estimated from the pre-event optical imagery. Second, the building information and the acquisition parameters of the VHR SAR scene are used to predict the expected signature of the building in the post-event SAR scene assuming that it is not affected by the event. Third, the similarity between the predicted image and the actual SAR image is analyzed. If the similarity is high, the building is likely to be still intact, whereas a low similarity indicates that the building is destroyed. A similarity threshold is used to classify the buildings. We demonstrate the feasibility and the effectiveness of the method for a subset of the town of Yingxiu, China, which was heavily damaged in the Sichuan earthquake of May 12, 2008. For the experiment, we use QuickBird and WorldView-1 optical imagery, and TerraSAR-X and COSMO-SkyMed SAR data.","Earthquakes,
Adaptive optics,
Optical sensors,
Radar detection,
Layout,
Remote sensing,
Satellites,
Spatial resolution,
Synthetic aperture radar,
High-resolution imaging"
Generalized { q}-Sampling Imaging,"Based on the Fourier transform relation between diffusion magnetic resonance (MR) signals and the underlying diffusion displacement, a new relation is derived to estimate the spin distribution function (SDF) directly from diffusion MR signals. This relation leads to an imaging method called generalized q-sampling imaging (GQI), which can obtain the SDF from the shell sampling scheme used in q-ball imaging (QBI) or the grid sampling scheme used in diffusion spectrum imaging (DSI). The accuracy of GQI was evaluated by a simulation study and an in vivo experiment in comparison with QBI and DSI. The simulation results showed that the accuracy of GQI was comparable to that of QBI and DSI. The simulation study of GQI also showed that an anisotropy index, named quantitative anisotropy, was correlated with the volume fraction of the resolved fiber component. The in vivo images of GQI demonstrated that SDF patterns were similar to the ODFs reconstructed by QBI or DSI. The tractography generated from GQI was also similar to those generated from QBI and DSI. In conclusion, the proposed GQI method can be applied to grid or shell sampling schemes and can provide directional and quantitative information about the crossing fibers.",
Distributed Collaborative Control for Industrial Automation With Wireless Sensor and Actuator Networks,"Wireless sensor and actuator networks (WSANs) bring many benefits to industrial automation systems. When a control system is integrated by a WSAN, and particularly if the network scale is large, distributed communication and control methods are quite necessary. However, unreliable wireless and multihop communications among sensors and actuators cause challenges in designing such systems. This paper proposes and evaluates a new distributed estimation and collaborative control scheme for industrial control systems with WSANs. Extensive results show that the proposed method effectively achieves control objectives and maintains robust against inaccurate system parameters. We also discuss how to dynamically extend the scale of a WSAN with only local adjustments of sensors and actuators.",
A Wearable Smartphone-Based Platform for Real-Time Cardiovascular Disease Detection Via Electrocardiogram Processing,"Cardiovascular disease (CVD) is the single leading cause of global mortality and is projected to remain so. Cardiac arrhythmia is a very common type of CVD and may indicate an increased risk of stroke or sudden cardiac death. The ECG is the most widely adopted clinical tool to diagnose and assess the risk of arrhythmia. ECGs measure and display the electrical activity of the heart from the body surface. During patients' hospital visits, however, arrhythmias may not be detected on standard resting ECG machines, since the condition may not be present at that moment in time. While Holter-based portable monitoring solutions offer 24-48 h ECG recording, they lack the capability of providing any real-time feedback for the thousands of heart beats they record, which must be tediously analyzed offline. In this paper, we seek to unite the portability of Holter monitors and the real-time processing capability of state-of-the-art resting ECG machines to provide an assistive diagnosis solution using smartphones. Specifically, we developed two smartphone-based wearable CVD-detection platforms capable of performing real-time ECG acquisition and display, feature extraction, and beat classification. Furthermore, the same statistical summaries available on resting ECG machines are provided.","Cardiovascular diseases,
Electrocardiography,
Biomedical monitoring,
Electric variables measurement,
Hospitals,
Patient monitoring,
Feedback,
Heart beat,
Computer displays,
Smart phones"
Control Methods of Inverter-Interfaced Distributed Generators in a Microgrid System,"Microgrids are a new concept for future energy distribution systems that enable renewable energy integration and improved energy management capability. Microgrids consist of multiple distributed generators (DGs) that are usually integrated via power electronic inverters. In order to enhance power quality and power distribution reliability, microgrids need to operate in both grid-connected and island modes. Consequently, microgrids can suffer performance degradation as the operating conditions vary due to abrupt mode changes and variations in bus voltages and system frequency. This paper presents controller design and optimization methods to stably coordinate multiple inverter-interfaced DGs and to robustly control individual interface inverters against voltage and frequency disturbances. Droop-control concepts are used as system-level multiple DG coordination controllers, and control theory is applied to device-level inverter controllers. Optimal control parameters are obtained by particle-swarm-optimization algorithms, and the control performance is verified via simulation studies.",
Real time motion capture using a single time-of-flight camera,"Markerless tracking of human pose is a hard yet relevant problem. In this paper, we derive an efficient filtering algorithm for tracking human pose using a stream of monocular depth images. The key idea is to combine an accurate generative model — which is achievable in this setting using programmable graphics hardware — with a discriminative model that provides data-driven evidence about body part locations. In each filter iteration, we apply a form of local model-based search that exploits the nature of the kinematic chain. As fast movements and occlusion can disrupt the local search, we utilize a set of discriminatively trained patch classifiers to detect body parts. We describe a novel algorithm for propagating this noisy evidence about body part locations up the kinematic chain using the un-scented transform. The resulting distribution of body configurations allows us to reinitialize the model-based search. We provide extensive experimental results on 28 real-world sequences using automatic ground-truth annotations from a commercial motion capture system.",
Mobile Sensor Network Control Using Mutual Information Methods and Particle Filters,"This paper develops a set of methods enabling an information-theoretic distributed control architecture to facilitate search by a mobile sensor network. Given a particular configuration of sensors, this technique exploits the structure of the probability distributions of the target state and of the sensor measurements to control the mobile sensors such that future observations minimize the expected future uncertainty of the target state. The mutual information between the sensors and the target state is computed using a particle filter representation of the posterior probability distribution, making it possible to directly use nonlinear and non-Gaussian target state and sensor models. To make the approach scalable to increasing network sizes, single-node and pairwise-node approximations to the mutual information are derived for general probability density models, with analytically bounded error. The pairwise-node approximation is proven to be a more accurate objective function than the single-node approximation. The mobile sensors are cooperatively controlled using a distributed optimization, yielding coordinated motion of the network. These methods are explored for various sensing modalities, including bearings-only sensing, range-only sensing, and magnetic field sensing, all with potential for search and rescue applications. For each sensing modality, the behavior of this non-parametric method is compared and contrasted with the results of linearized methods, and simulations are performed of a target search using the dynamics of actual vehicles. Monte Carlo results demonstrate that as network size increases, the sensors more quickly localize the target, and the pairwise-node approximation provides superior performance to the single-node approximation. The proposed methods are shown to produce similar results to linearized methods in particular scenarios, yet they capture effects in more general scenarios that are not possible with linearized methods.",
Compliant Control of Multicontact and Center-of-Mass Behaviors in Humanoid Robots,"This paper presents a new methodology for the analysis and control of internal forces and center-of-mass (CoM) behavior, which are produced during multicontact interactions between humanoid robots and the environment. The approach leverages the virtual-linkage model that provides a physical representation of the internal and CoM resultant forces with respect to reaction forces on the supporting surfaces. A grasp/contact matrix describing the complex interactions between contact forces and CoM behavior is developed. Based on this model, a new torque-based approach for the control of internal forces is suggested and illustrated on the Asimo humanoid robot. The new controller is integrated into the framework for whole-body-prioritized multitasking, thus enabling the unified control of CoM maneuvers, operational tasks, and internal-force behavior. The grasp/contact matrix is also proposed to analyze and plan internal force and CoM control policies that comply with frictional properties of the links in contact.",
"Detecting the Optic Disc Boundary in Digital Fundus Images Using Morphological, Edge Detection, and Feature Extraction Techniques","Optic disc (OD) detection is an important step in developing systems for automated diagnosis of various serious ophthalmic pathologies. This paper presents a new template-based methodology for segmenting the OD from digital retinal images. This methodology uses morphological and edge detection techniques followed by the Circular Hough Transform to obtain a circular OD boundary approximation. It requires a pixel located within the OD as initial information. For this purpose, a location methodology based on a voting-type algorithm is also proposed. The algorithms were evaluated on the 1200 images of the publicly available MESSIDOR database. The location procedure succeeded in 99% of cases, taking an average computational time of 1.67 s. with a standard deviation of 0.14 s. On the other hand, the segmentation algorithm rendered an average common area overlapping between automated segmentations and true OD regions of 86%. The average computational time was 5.69 s with a standard deviation of 0.54 s. Moreover, a discussion on advantages and disadvantages of the models more generally used for OD segmentation is also presented in this paper.",
Flexible Manifold Embedding: A Framework for Semi-Supervised and Unsupervised Dimension Reduction,"We propose a unified manifold learning framework for semi-supervised and unsupervised dimension reduction by employing a simple but effective linear regression function to map the new data points. For semi-supervised dimension reduction, we aim to find the optimal prediction labels F for all the training samples X, the linear regression function h(X) and the regression residue F0 = F - h(X) simultaneously. Our new objective function integrates two terms related to label fitness and manifold smoothness as well as a flexible penalty term defined on the residue F0. Our Semi-Supervised learning framework, referred to as flexible manifold embedding (FME), can effectively utilize label information from labeled data as well as a manifold structure from both labeled and unlabeled data. By modeling the mismatch between h(X) and F, we show that FME relaxes the hard linear constraint F = h(X) in manifold regularization (MR), making it better cope with the data sampled from a nonlinear manifold. In addition, we propose a simplified version (referred to as FME/U) for unsupervised dimension reduction. We also show that our proposed framework provides a unified view to explain and understand many semi-supervised, supervised and unsupervised dimension reduction techniques. Comprehensive experiments on several benchmark databases demonstrate the significant improvement over existing dimension reduction algorithms.","Principal component analysis,
Laboratories,
Linear discriminant analysis,
Linear regression,
Semisupervised learning,
Face recognition,
Intelligent systems,
Information science,
Automation,
Scattering"
An Overview of IP Flow-Based Intrusion Detection,"Intrusion detection is an important area of research. Traditionally, the approach taken to find attacks is to inspect the contents of every packet. However, packet inspection cannot easily be performed at high-speeds. Therefore, researchers and operators started investigating alternative approaches, such as flow-based intrusion detection. In that approach the flow of data through the network is analyzed, instead of the contents of each individual packet. The goal of this paper is to provide a survey of current research in the area of flow-based intrusion detection. The survey starts with a motivation why flow-based intrusion detection is needed. The concept of flows is explained, and relevant standards are identified. The paper provides a classification of attacks and defense techniques and shows how flow-based techniques can be used to detect scans, worms, Botnets and (DoS) attacks.","Intrusion detection,
Inspection,
Computer worms,
Computer crime,
Computer hacking,
Internet,
Viruses (medical),
Invasive software,
Payloads,
Telematics"
Partially Coupled Stochastic Gradient Identification Methods for Non-Uniformly Sampled Systems,"This technical note addresses identification problems of non-uniformly sampled systems. For the input-output representation of non-uniform discrete-time systems, a partially coupled stochastic gradient (C-SG) algorithm is proposed to estimate the model parameters with high computational efficiency compared with the standard stochastic gradient (SG) algorithm. The analysis indicates that the partially C-SG algorithm can give more accurate parameter estimates than the SG algorithm. The parameter estimates obtained using the partially C-SG algorithm converge to their true values as the data length approaches infinity.","Stochastic systems,
Parameter estimation,
Sampling methods,
Control systems,
Chemical sensors,
Sensor systems,
Process control,
Predictive control,
State estimation,
State-space methods"
Decentralized Fault Diagnosis of Large-Scale Processes Using Multiblock Kernel Partial Least Squares,"In this paper, a decentralized fault diagnosis approach of complex processes is proposed based on multiblock kernel partial least squares (MBKPLS). To solve the problem posed by nonlinear characteristics, kernel partial least squares (KPLS) approaches have been proposed. In this paper, MBKPLS algorithm is first proposed and applied to monitor large-scale processes. The advantages of MBKPLS are: 1) MBKPLS can capture more useful information between and within blocks compared to partial least squares (PLS); 2) MBKPLS gives nonlinear interpretation compared to MBPLS; 3) Fault diagnosis becomes possible if number of sub-blocks is equal to the number of the variables compared to KPLS. The proposed methods are applied to process monitoring of a continuous annealing process. Application results indicate that the proposed decentralized monitoring scheme effectively captures the complex relations in the process and improves the diagnosis ability tremendously.","Fault diagnosis,
Large-scale systems,
Kernel,
Least squares methods,
Principal component analysis,
Monitoring,
Covariance matrix,
Artificial neural networks,
Chemical industry,
Neural networks"
Scale-invariant heat kernel signatures for non-rigid shape recognition,"One of the biggest challenges in non-rigid shape retrieval and comparison is the design of a shape descriptor that would maintain invariance under a wide class of transformations the shape can undergo. Recently, heat kernel signature was introduced as an intrinsic local shape descriptor based on diffusion scale-space analysis. In this paper, we develop a scale-invariant version of the heat kernel descriptor. Our construction is based on a logarithmically sampled scale-space in which shape scaling corresponds, up to a multiplicative constant, to a translation. This translation is undone using the magnitude of the Fourier transform. The proposed scale-invariant local descriptors can be used in the bag-of-features framework for shape retrieval in the presence of transformations such as isometric deformations, missing data, topological noise, and global and local scaling. We get significant performance improvement over state-of-the-art algorithms on recently established non-rigid shape retrieval benchmarks.","Kernel,
Shape,
Information retrieval,
Image analysis,
Internet,
Extraterrestrial measurements,
Geometry,
Image retrieval,
Image sampling,
Computer vision"
Region Duplication Detection Using Image Feature Matching,"Region duplication is a simple and effective operation to create digital image forgeries, where a continuous portion of pixels in an image, after possible geometrical and illumination adjustments, are copied and pasted to a different location in the same image. Most existing region duplication detection methods are based on directly matching blocks of image pixels or transform coefficients, and are not effective when the duplicated regions have geometrical or illumination distortions. In this work, we describe a new region duplication detection method that is robust to distortions of the duplicated regions. Our method starts by estimating the transform between matched scale invariant feature transform (SIFT) keypoints, which are insensitive to geometrical and illumination distortions, and then finds all pixels within the duplicated regions after discounting the estimated transforms. The proposed method shows effective detection on an automatically synthesized forgery image database with duplicated and distorted regions. We further demonstrate its practical performance with several challenging forgery images created with state-of-the-art tools.",
Coherent and Differential Space-Time Shift Keying: A Dispersion Matrix Approach,"Motivated by the recent concept of Spatial Modulation (SM), we propose a novel Space-Time Shift Keying (STSK) modulation scheme for Multiple-Input Multiple-Output (MIMO) communication systems, where the concept of SM is extended to include both the space and time dimensions, in order to provide a general shift-keying framework. More specifically, in the proposed STSK scheme one out of Q dispersion matrices is activated during each transmitted block, which enables us to strike a flexible diversity and multiplexing tradeoff. This is achieved by optimizing both the space-time block duration as well as the number of the dispersion matrices in addition to the number of transmit and receive antennas. We will demonstrate that the resultant equivalent system model does not impose any Inter-Channel Interference (ICI), and hence the employment of single-stream Maximum Likelihood (ML) detection becomes realistic at a low-complexity. Furthermore, we propose a Differential STSK (DSTSK) scheme, assisted by the Cayley unitary transform, which does not require any Channel State Information (CSI) at the receiver. Here, the usual error-doubling, caused by the differential decoding, gives rise to 3-dB performance penalty in comparison to Coherent STSK (CSTSK). Additionally, we introduce an enhanced CSTSK scheme, which avoids the requirement of Inter-Antenna Synchronization (IAS) between the RF chains associated with the transmit Antenna Elements (AEs) by imposing a certain constraint on the dispersion matrix design, where each column of the dispersion matrices includes only a single non-zero component. Moreover, according to the turbo-coding principle, the proposed CSTSK and DSTSK schemes are combined with multiple serially concatenated codes and an iterative bit-to-symbol soft-demapper. More specifically, the associated STSK parameters are optimized with the aid of Extrinsic Information Transfer (EXIT) charts, for the sake of achieving a near-capacity performance.",
Intensity-Based Image Registration by Minimizing Residual Complexity,"Accurate definition of the similarity measure is a key component in image registration. Most commonly used intensity-based similarity measures rely on the assumptions of independence and stationarity of the intensities from pixel to pixel. Such measures cannot capture the complex interactions among the pixel intensities, and often result in less satisfactory registration performances, especially in the presence of spatially-varying intensity distortions. We propose a novel similarity measure that accounts for intensity nonstationarities and complex spatially-varying intensity distortions in mono-modal settings. We derive the similarity measure by analytically solving for the intensity correction field and its adaptive regularization. The final measure can be interpreted as one that favors a registration with minimum compression complexity of the residual image between the two registered images. One of the key advantages of the new similarity measure is its simplicity in terms of both computational complexity and implementation. This measure produces accurate registration results on both artificial and real-world problems that we have tested, and outperforms other state-of-the-art similarity measures in these cases.","Image registration,
Distortion measurement,
Biomedical measurements,
Pixel,
Biological materials,
Biomedical materials,
Permission,
Performance evaluation,
Image coding,
Computational complexity"
Joint Detection and Estimation of Multiple Objects From Image Observations,"The problem of jointly detecting multiple objects and estimating their states from image observations is formulated in a Bayesian framework by modeling the collection of states as a random finite set. Analytic characterizations of the posterior distribution of this random finite set are derived for various prior distributions under the assumption that the regions of the observation influenced by individual objects do not overlap. These results provide tractable means to jointly estimate the number of states and their values from image observations. As an application, we develop a multi-object filter suitable for image observations with low signal-to-noise ratio (SNR). A particle implementation of the multi-object filter is proposed and demonstrated via simulations.","Object detection,
Electrical capacitance tomography,
State estimation,
Radio access networks,
Radar applications,
Radar imaging,
Filters,
Permission,
Australia Council,
Sonar applications"
Monocular 3D pose estimation and tracking by detection,"Automatic recovery of 3D human pose from monocular image sequences is a challenging and important research topic with numerous applications. Although current methods are able to recover 3D pose for a single person in controlled environments, they are severely challenged by real-world scenarios, such as crowded street scenes. To address this problem, we propose a three-stage process building on a number of recent advances. The first stage obtains an initial estimate of the 2D articulation and viewpoint of the person from single frames. The second stage allows early data association across frames based on tracking-by-detection. These two stages successfully accumulate the available 2D image evidence into robust estimates of 2D limb positions over short image sequences (= tracklets). The third and final stage uses those tracklet-based estimates as robust image observations to reliably recover 3D pose. We demonstrate state-of-the-art performance on the HumanEva II benchmark, and also show the applicability of our approach to articulated 3D tracking in realistic street conditions.",
A Clustering Particle Swarm Optimizer for Locating and Tracking Multiple Optima in Dynamic Environments,"In the real world, many optimization problems are dynamic. This requires an optimization algorithm to not only find the global optimal solution under a specific environment but also to track the trajectory of the changing optima over dynamic environments. To address this requirement, this paper investigates a clustering particle swarm optimizer (PSO) for dynamic optimization problems. This algorithm employs a hierarchical clustering method to locate and track multiple peaks. A fast local search method is also introduced to search optimal solutions in a promising subregion found by the clustering method. Experimental study is conducted based on the moving peaks benchmark to test the performance of the clustering PSO in comparison with several state-of-the-art algorithms from the literature. The experimental results show the efficiency of the clustering PSO for locating and tracking multiple optima in dynamic environments in comparison with other particle swarm optimization models based on the multiswarm method.","Clustering algorithms,
Heuristic algorithms,
Clustering methods,
Algorithm design and analysis,
Particle swarm optimization,
Optimization,
Convergence"
Current and Future Challenges in Radiation Effects on CMOS Electronics,"Advances in microelectronics performance and density continue to be fueled by the engine of Moore's law. Although lately this engine appears to be running out of steam, recent developments in advanced technologies have brought about a number of challenges and opportunities for their use in radiation environments. For example, while many advanced CMOS technologies have generally shown improving total dose tolerance, single-event effects continue to be a serious concern for highly scaled technologies. In this paper, we examine the impact of recent developments and the challenges they present to the radiation effects community. Topics covered include the impact of technology scaling on radiation response and technology challenges for both total dose and single-event effects. We include challenges for hardening and mitigation techniques at the nanometer scale. Recent developments leading to hardness assurance challenges are covered. Finally, we discuss future radiation effects challenges as the electronics industry looks beyond Moore's law to alternatives to traditional CMOS technologies.",
"Long-reach optical access networks: A survey of research challenges, demonstrations, and bandwidth assignment mechanisms","Long-Reach optical access is a promising proposal for future access networks. This technology can enable broadband access for a large number of customers in the access/metro area, while decreasing capital and operational expenditures for the network operator. First, the paper reviews the evolutionary path of access networks and shows the drivers from technology and business perspectives for high bandwidth and low cost. A variety of research challenges in this field is reviewed, from optical components in the physical layer to the control and management issues in the upper layers. We discuss the requisites for optical sources, optical amplifiers, and optical receivers when used in networks with high transmission rate (10 Gbps) and large power attenuation (due to large split, transmission over 100 km and beyond, and propagation), and the key topological structures that allow to guarantee physical protection (tree-and-branch, ring-and-spur). Then, some relevant demonstrations of Long-Reach Optical Access Networks developed worldwide by different research institutes are presented. Finally, Dynamic Bandwidth Allocation (DBA) algorithms that allow to mitigate the effect of the increased control-plane delay in an extended-reach network are investigated.",
"Model globally, match locally: Efficient and robust 3D object recognition","This paper addresses the problem of recognizing free-form 3D objects in point clouds. Compared to traditional approaches based on point descriptors, which depend on local information around points, we propose a novel method that creates a global model description based on oriented point pair features and matches that model locally using a fast voting scheme. The global model description consists of all model point pair features and represents a mapping from the point pair feature space to the model, where similar features on the model are grouped together. Such representation allows using much sparser object and scene point clouds, resulting in very fast performance. Recognition is done locally using an efficient voting scheme on a reduced two-dimensional search space. We demonstrate the efficiency of our approach and show its high recognition performance in the case of noise, clutter and partial occlusions. Compared to state of the art approaches we achieve better recognition rates, and demonstrate that with a slight or even no sacrifice of the recognition performance our method is much faster then the current state of the art approaches.","Robustness,
Object recognition,
Layout,
Clouds,
Voting,
Object detection,
Computer science,
Sensor systems,
Cameras,
Stereo vision"
Saliency detection using maximum symmetric surround,"Detection of visually salient image regions is useful for applications like object segmentation, adaptive compression, and object recognition. Recently, full-resolution salient maps that retain well-defined boundaries have attracted attention. In these maps, boundaries are preserved by retaining substantially more frequency content from the original image than older techniques. However, if the salient regions comprise more than half the pixels of the image, or if the background is complex, the background gets highlighted instead of the salient object. In this paper, we introduce a method for salient region detection that retains the advantages of such saliency maps while overcoming their shortcomings. Our method exploits features of color and luminance, is simple to implement and is computationally efficient. We compare our algorithm to six state-of-the-art salient region detection methods using publicly available ground truth. Our method outperforms the six algorithms by achieving both higher precision and better recall. We also show application of our saliency maps in an automatic salient object segmentation scheme using graph-cuts.","Pixel,
Image color analysis,
Image segmentation,
Visualization,
Biology,
Computer vision,
Conferences"
A Mobile Decision Support System for Dynamic Group Decision-Making Problems,"The aim of this paper is to present a decision support system model with two important characteristic: 1) mobile technologies are applied in the decision process and 2) the set of alternatives is not fixed over time to address dynamic decision situations in which the set of solution alternatives could change throughout the decision-making process. We implement a prototype of such mobile decision support system in which experts use mobile phones to provide their preferences anywhere and anytime. To get a general system, experts' preferences are assumed to be represented by different preference representations: 1) fuzzy preference relations; 2) orderings; 3) utility functions; and 4) multiplicative preference relations. Because this prototype incorporates both selection and consensus processes, it allows us to model group decision-making situations. The prototype incorporates a tool for managing the changes on the set of feasible alternatives that could happen throughout the decision process. This way, the prototype provides a new approach to deal with dynamic group decision-making situations to help make decisions anywhere and anytime.",
Evolutionary cooperative spectrum sensing game: how to collaborate?,"Cooperative spectrum sensing has been shown to be able to greatly improve the sensing performance in cognitive radio networks. However, if cognitive users belong to different service providers, they tend to contribute less in sensing in order to increase their own throughput. In this paper, we propose an evolutionary game framework to answer the question of ""how to collaborate"" in multiuser de-centralized cooperative spectrum sensing, because evolutionary game theory provides an excellent means to address the strategic uncertainty that a user/player may face by exploring different actions, adaptively learning during the strategic interactions, and approaching the best response strategy under changing conditions and environments using replicator dynamics. We derive the behavior dynamics and the evolutionarily stable strategy (ESS) of the secondary users. We then prove that the dynamics converge to the ESS, which renders the possibility of a de-centralized implementation of the proposed sensing game. According to the dynamics, we further develop a distributed learning algorithm so that the secondary users approach the ESS solely based on their own payoff observations. Simulation results show that the average throughput achieved in the proposed cooperative sensing game is higher than the case where secondary users sense the primary user individually without cooperation. The proposed game is demonstrated to converge to the ESS, and achieve a higher system throughput than the fully cooperative scenario, where all users contribute to sensing in every time slot.","Collaboration,
Cognitive radio,
Throughput,
Game theory,
FCC,
Uncertainty,
Wireless sensor networks"
MIMO Gaussian Channels With Arbitrary Inputs: Optimal Precoding and Power Allocation,"In this paper, we investigate the linear precoding and power allocation policies that maximize the mutual information for general multiple-input-multiple-output (MIMO) Gaussian channels with arbitrary input distributions, by capitalizing on the relationship between mutual information and minimum mean-square error (MMSE). The optimal linear precoder satisfies a fixed-point equation as a function of the channel and the input constellation. For non-Gaussian inputs, a nondiagonal precoding matrix in general increases the information transmission rate, even for parallel noninteracting channels. Whenever precoding is precluded, the optimal power allocation policy also satisfies a fixed-point equation; we put forth a generalization of the mercury/waterfilling algorithm, previously proposed for parallel noninterfering channels, in which the mercury level accounts not only for the non-Gaussian input distributions, but also for the interference among inputs.","MIMO,
Gaussian channels,
Mutual information,
Government,
Equations,
Collaborative work,
Telecommunications,
Phase shift keying,
Quadrature amplitude modulation,
Interference"
Spherical Demons: Fast Diffeomorphic Landmark-Free Surface Registration,"We present the Spherical Demons algorithm for registering two spherical images. By exploiting spherical vector spline interpolation theory, we show that a large class of regularizors for the modified Demons objective function can be efficiently approximated on the sphere using iterative smoothing. Based on one parameter subgroups of diffeomorphisms, the resulting registration is diffeomorphic and fast. The Spherical Demons algorithm can also be modified to register a given spherical image to a probabilistic atlas. We demonstrate two variants of the algorithm corresponding to warping the atlas or warping the subject. Registration of a cortical surface mesh to an atlas mesh, both with more than 160 k nodes requires less than 5 min when warping the atlas and less than 3 min when warping the subject on a Xeon 3.2 GHz single processor machine. This is comparable to the fastest nondiffeomorphic landmark-free surface registration algorithms. Furthermore, the accuracy of our method compares favorably to the popular FreeSurfer registration algorithm. We validate the technique in two different applications that use registration to transfer segmentation labels onto a new image (1) parcellation of in vivo cortical surfaces and (2) Brodmann area localization in ex vivo cortical surfaces.",
Fractional Differential Mask: A Fractional Differential-Based Approach for Multiscale Texture Enhancement,"In this paper, we intend to implement a class of fractional differential masks with high-precision. Thanks to two commonly used definitions of fractional differential for what are known as Grumwald-Letnikov and Riemann-Liouville, we propose six fractional differential masks and present the structures and parameters of each mask respectively on the direction of negative x-coordinate, positive x-coordinate, negative y-coordinate, positive y-coordinate, left downward diagonal, left upward diagonal, right downward diagonal, and right upward diagonal. Moreover, by theoretical and experimental analyzing, we demonstrate the second is the best performance fractional differential mask of the proposed six ones. Finally, we discuss further the capability of multiscale fractional differential masks for texture enhancement. Experiments show that, for rich-grained digital image, the capability of nonlinearly enhancing complex texture details in smooth area by fractional differential-based approach appears obvious better than by traditional integral-based algorithms.",
New Passivity Analysis for Neural Networks With Discrete and Distributed Delays,"In this brief, the problem of passivity analysis is investigated for a class of uncertain neural networks (NNs) with both discrete and distributed time-varying delays. By constructing a novel Lyapunov functional and utilizing some advanced techniques, new delay-dependent passivity criteria are established to guarantee the passivity performance of NNs. Essentially different from the available results, when estimating the upper bound of the derivative of Lyapunov functionals, we consider and best utilize the additional useful terms about the distributed delays, which leads to less conservative results. These criteria are expressed in the form of convex optimization problems, which can be efficiently solved via standard numerical software. Numerical examples are provided to illustrate the effectiveness and less conservatism of the proposed results.","Delay,
Artificial neural networks,
Delay effects,
Symmetric matrices,
Stability criteria,
Linear matrix inequalities"
Macromodeling of the Memristor in SPICE,"In this paper, we present a new simulation program with integrated circuit emphasis macromodel of the recently physically implemented memristor. This macromodel could be a powerful tool for electrical engineers to design and experiment new circuits with memristors. Our simulation results show similar behavior to the already published measurements of the physical implementation. Our approach provides a solution for the modeling of boundary conditions following exactly the published mathematical model of HP Labs. The functionality of our macromodel is demonstrated with computer simulations. The source code of our macromodel is provided.",
An Online System of Multispectral Palmprint Verification,"Palmprint is a unique and reliable biometric characteristic with high usability. With the increasing demand of highly accurate and robust palmprint authentication system, multispectral imaging has been employed to acquire more discriminative information and increase the antispoof capability of palmprint. This paper presents an online multispectral palmprint system that could meet the requirement of real-time application. A data acquisition device is designed to capture the palmprint images under Blue, Green, Red, and near-infrared (NIR) illuminations in less than 1 s. A large multispectral palmprint database is then established to investigate the recognition performance of each spectral band. Our experimental results show that the red channel achieves the best result, whereas the Blue and Green channels have comparable performance but are slightly inferior to the NIR channel. After analyzing the extracted features from different bands, we propose a score level fusion scheme to integrate the multispectral information. The palmprint verification experiments demonstrated the superiority of multispectral fusion to each single spectrum, which results in both higher verification accuracy and antispoofing capability.","Biometrics,
Usability,
Robustness,
Authentication,
Multispectral imaging,
Real time systems,
Data acquisition,
Lighting,
Image databases,
Spatial databases"
Examination of a PHEV bidirectional charger system for V2G reactive power compensation,"Plug-in hybrid electric vehicles (PHEVs) potentially have the capability to fulfill the energy storage needs of the electric grid by supplying ancillary services such as reactive power compensation, voltage regulation, and peak shaving. However, in order to allow bidirectional power transfer, the PHEV battery charger should be designed to manage such capability. While many different battery chargers have been available since the inception of the first electric vehicles (EVs), on-board, conductive chargers with bidirectional power transfer capability have recently drawn attention due to their inherent advantages in charging accessibility, ease of use, and efficiency. In this paper, a reactive power compensation case study using just the inverter dc-link capacitor is evaluated when a PHEV battery is under charging operation. Finally, the impact of providing these services on the batteries is also explained.","Reactive power,
Battery powered vehicles,
Circuits,
Hybrid electric vehicles,
Energy storage,
Voltage control,
Capacitors,
Protection,
Computer science,
Laboratories"
Time-Delay Compensation by Communication Disturbance Observer for Bilateral Teleoperation Under Time-Varying Delay,"This paper presents the effectiveness of a time-delay compensation method based on the concept of network disturbance and communication disturbance observer for bilateral teleoperation systems under time-varying delay. The most efficient feature of the compensation method is that it works without time-delay models (model-based time-delay compensation approaches like Smith predictor usually need time-delay models). Therefore, the method is expected to be widely applied to network-based control systems, in which time delay is usually unknown and time varying. In this paper, the validity of the time-delay compensation method in the cases of both constant delay and time-varying delay is verified by experimental results compared with Smith predictor.","Delay effects,
Control systems,
Predictive models,
Communication system control,
Time varying systems,
Delay systems,
Internet,
IP networks,
Predictive control,
Neodymium"
Learning Context-Sensitive Shape Similarity by Graph Transduction,"Shape similarity and shape retrieval are very important topics in computer vision. The recent progress in this domain has been mostly driven by designing smart shape descriptors for providing better similarity measure between pairs of shapes. In this paper, we provide a new perspective to this problem by considering the existing shapes as a group, and study their similarity measures to the query shape in a graph structure. Our method is general and can be built on top of any existing shape similarity measure. For a given similarity measure, a new similarity is learned through graph transduction. The new similarity is learned iteratively so that the neighbors of a given shape influence its final similarity to the query. The basic idea here is related to PageRank ranking, which forms a foundation of Google Web search. The presented experimental results demonstrate that the proposed approach yields significant improvements over the state-of-art shape matching algorithms. We obtained a retrieval rate of 91.61 percent on the MPEG-7 data set, which is the highest ever reported in the literature. Moreover, the learned similarity by the proposed method also achieves promising improvements on both shape classification and shape clustering.","Shape measurement,
Distortion measurement,
Databases,
Computer vision,
Web search,
Clustering algorithms,
Iterative algorithms,
Information retrieval,
MPEG 7 Standard,
Machine vision"
Design of Cognitive Radio Systems Under Temperature-Interference Constraints: A Variational Inequality Approach,"The concept of cognitive radio (CR) has recently received great attention from the research community as a promising paradigm to achieve efficient use of the frequency resource by allowing the coexistence of licensed (primary) and unlicensed (secondary) users in the same bandwidth. In this paper, we propose a novel Nash equilibrium (NE) problem to model concurrent communications of cognitive secondary users who compete against each other to maximize their information rate. The formulation contains constraints on the transmit power (and possibly spectral masks) as well as aggregate interference tolerable at the primary users' receivers. The coupling among the strategies of the players due to the interference constraints presents a new challenge for the analysis of this class of Nash games that cannot be addressed using the game theoretical models proposed in the literature. For this purpose, we need the framework given by the more advanced theory of finite-dimensional variational inequalities (VI). This provides us with all the mathematical tools necessary to analyze the proposed NE problem (e.g., existence and uniqueness of the solution) and to devise alternative distributed algorithms along with their convergence properties.","Cognitive radio,
Interference constraints,
Game theory,
Chromium,
Frequency,
Bandwidth,
Nash equilibrium,
Information rates,
Aggregates,
Algorithm design and analysis"
GreenTE: Power-aware traffic engineering,"Current network infrastructures exhibit poor power efficiency, running network devices at full capacity all the time regardless of the traffic demand and distribution over the network. Most research on router power management are at component level or link level, treating routers as isolated devices. A complementary approach is to facilitate power management at network level by routing traffic through different paths to adjust the workload on individual routers or links. Given the high path redundancy and low link utilization in today's large networks, this approach can potentially allow more network devices or components to go into power saving mode. This paper proposes an intra-domain traffic engineering mechanism, GreenTE, which maximizes the number of links that can be put into sleep under given performance constraints such as link utilization and packet delay. Using network topologies and traffic data from several wide-area networks, our evaluation shows that GreenTE can reduce line-cards' power consumption by 27% to 42% under constraints that the maximum link utilization is below 50% and the network diameter remains the same as in shortest path routing.",
Power-Sharing Method of Multiple Distributed Generators Considering Control Modes and Configurations of a Microgrid,"This paper describes the active power and frequency-control principles of multiple distributed generators (DGs) in a microgrid. Microgrids have two operating modes: 1) a grid-connected mode and 2) an islanded mode. During islanded operation, one DG unit should share output generation power with other units in exact accordance with the load. Two different options for controlling the active power of DGs are introduced and analyzed: 1) unit output-power control (UPC) and 2) feeder flow control (FFC). Taking into account the control mode and the configuration of the DGs, we investigate power-sharing principles among multiple DGs under various system conditions: 1) load variation during grid-connected operation, 2) load variation during islanded operation, and 3) loss of mains (disconnected from the main grid). Based on the analysis, the FFC mode is advantageous to the main grid and the microgrid itself under load variation conditions. However, when the microgrid is islanded, the FFC control mode is limited by the existing droop controller. Therefore, we propose an algorithm to modify the droop constant of the FFC-mode DGs to ensure proper power sharing among DGs. The principles and the proposed algorithm are verified by PSCAD simulation.","Distributed power generation,
Power generation,
Distributed control,
PSCAD,
Power system reliability,
Frequency,
Control systems,
Load management,
Photovoltaic systems,
Power system faults"
Accurate Telemonitoring of Parkinson's Disease Progression by Noninvasive Speech Tests,"Tracking Parkinson's disease (PD) symptom progression often uses the unified Parkinson's disease rating scale (UPDRS) that requires the patient's presence in clinic, and time-consuming physical examinations by trained medical staff. Thus, symptom monitoring is costly and logistically inconvenient for patient and clinical staff alike, also hindering recruitment for future large-scale clinical trials. Here, for the first time, we demonstrate rapid, remote replication of UPDRS assessment with clinically useful accuracy (about 7.5 UPDRS points difference from the clinicians' estimates), using only simple, self-administered, and noninvasive speech tests. We characterize speech with signal processing algorithms, extracting clinically useful features of average PD progression. Subsequently, we select the most parsimonious model with a robust feature selection algorithm, and statistically map the selected subset of features to UPDRS using linear and nonlinear regression techniques that include classical least squares and nonparametric classification and regression trees. We verify our findings on the largest database of PD speech in existence (~6000 recordings from 42 PD patients, recruited to a six-month, multicenter trial). These findings support the feasibility of frequent, remote, and accurate UPDRS tracking. This technology could play a key part in telemonitoring frameworks that enable large-scale clinical trials into novel PD treatments.",
Towards a Relevant and Diverse Search of Social Images,"Recent years have witnessed the great success of social media websites. Tag-based image search is an important approach to accessing the image content on these websites. However, the existing ranking methods for tag-based image search frequently return results that are irrelevant or not diverse. This paper proposes a diverse relevance ranking scheme that is able to take relevance and diversity into account by exploring the content of images and their associated tags. First, it estimates the relevance scores of images with respect to the query term based on both the visual information of images and the semantic information of associated tags. Then, we estimate the semantic similarities of social images based on their tags. Based on the relevance scores and the similarities, the ranking list is generated by a greedy ordering algorithm which optimizes average diverse precision, a novel measure that is extended from the conventional average precision. Comprehensive experiments and user studies demonstrate the effectiveness of the approach. We also apply the scheme for web image search reranking, and it is shown that the diversity of search results can be enhanced while maintaining a comparable level of relevance.","Cultural differences,
Permission,
Asia,
Time measurement,
Content based retrieval,
Automation,
Materials science and technology,
Internet,
Explosions,
YouTube"
Local Barrier Coverage in Wireless Sensor Networks,"Global barrier coverage, which requires much fewer sensors than full coverage, is known to be an appropriate model of coverage for movement detection applications such as intrusion detection. However, it has been proved that given a sensor deployment, sensors can not locally determine whether the deployment provides global barrier coverage, making it impossible to develop localized algorithms, thus limiting its use in practice. In this paper, we introduce the concept of local barrier coverage to address this limitation. Motivated by the observation that movements are likely to follow a shorter path in crossing a belt region, local barrier coverage guarantees the detection of all movements whose trajectory is confined to a slice of the belt region of deployment. We prove that it is possible for individual sensors to locally determine the existence of local barrier coverage, even when the region of deployment is arbitrarily curved. Although local barrier coverage does not deterministically guarantee global barrier coverage, we show that for thin belt regions, local barrier coverage almost always provides global barrier coverage. To demonstrate that local barrier coverage can be used to design localized algorithms, we develop a novel sleep-wakeup algorithm for maximizing the network lifetime, called localized barrier coverage protocol (LBCP). We prove that LBCP guarantees local barrier coverage and show that LBCP provides close to optimal enhancement in the network lifetime, while providing global barrier coverage most of the time. They outperform an existing algorithm called randomized independent sleeping (RIS) by up to six times.","Wireless sensor networks,
Intrusion detection,
Belts,
Chemical sensors,
Gas detectors,
Algorithm design and analysis,
Protocols,
Network topology,
Production facilities,
Pipelines"
Polar Codes are Optimal for Lossy Source Coding,"We consider lossy source compression of a binary symmetric source using polar codes and a low-complexity successive encoding algorithm. It was recently shown by Arikan that polar codes achieve the capacity of arbitrary symmetric binary-input discrete memoryless channels under a successive decoding strategy. We show the equivalent result for lossy source compression, i.e., we show that this combination achieves the rate-distortion bound for a binary symmetric source. We further show the optimality of polar codes for various multiterminal problems including the binary Wyner-Ziv and the binary Gelfand-Pinsker problems. Our results extend to general versions of these problems.","Source coding,
Rate-distortion,
Parity check codes,
Decoding,
Channel coding,
Belief propagation,
Memoryless systems,
Polarization,
Information theory,
Rate distortion theory"
Label Fusion in Atlas-Based Segmentation Using a Selective and Iterative Method for Performance Level Estimation (SIMPLE),"In a multi-atlas based segmentation procedure, propagated atlas segmentations must be combined in a label fusion process. Some current methods deal with this problem by using atlas selection to construct an atlas set either prior to or after registration. Other methods estimate the performance of propagated segmentations and use this performance as a weight in the label fusion process. This paper proposes a selective and iterative method for performance level estimation (SIMPLE), which combines both strategies in an iterative procedure. In subsequent iterations the method refines both the estimated performance and the set of selected atlases. For a dataset of 100 MR images of prostate cancer patients, we show that the results of SIMPLE are significantly better than those of several existing methods, including the STAPLE method and variants of weighted majority voting.","Iterative methods,
Image segmentation,
Biomedical imaging,
Permission,
Prostate cancer,
Voting,
Medical treatment,
Process planning,
Humans,
Robustness"
Application and Evaluation of a Measured Spatially Variant System Model for PET Image Reconstruction,"Accurate system modeling in tomographic image reconstruction has been shown to reduce the spatial variance of resolution and improve quantitative accuracy. System modeling can be improved through analytic calculations, Monte Carlo simulations, and physical measurements. The purpose of this work is to improve clinical fully-3-D reconstruction without substantially increasing computation time. We present a practical method for measuring the detector blurring component of a whole-body positron emission tomography (PET) system to form an approximate system model for use with fully-3-D reconstruction. We employ Monte Carlo simulations to show that a non-collimated point source is acceptable for modeling the radial blurring present in a PET tomograph and we justify the use of a Na22 point source for collecting these measurements. We measure the system response on a whole-body scanner, simplify it to a 2-D function, and incorporate a parameterized version of this response into a modified fully-3-D OSEM algorithm. Empirical testing of the signal versus noise benefits reveal roughly a 15% improvement in spatial resolution and 10% improvement in contrast at matched image noise levels. Convergence analysis demonstrates improved resolution and contrast versus noise properties can be achieved with the proposed method with similar computation time as the conventional approach. Comparison of the measured spatially variant and invariant reconstruction revealed similar performance with conventional image metrics. Edge artifacts, which are a common artifact of resolution-modeled reconstruction methods, were less apparent in the spatially variant method than in the invariant method. With the proposed and other resolution-modeled reconstruction methods, edge artifacts need to be studied in more detail to determine the optimal tradeoff of resolution/contrast enhancement and edge fidelity.",
"The X-Space Formulation of the Magnetic Particle Imaging Process: 1-D Signal, Resolution, Bandwidth, SNR, SAR, and Magnetostimulation","The magnetic particle imaging (MPI) imaging process is a new method of medical imaging with great promise. In this paper we derive the 1-D MPI signal, resolution, bandwidth requirements, signal-to-noise ratio (SNR), specific absorption rate, and slew rate limitations. We conclude with experimental data measuring the point spread function for commercially available SPIO nanoparticles and a demonstration of the principles behind 1-D imaging using a static offset field. Despite arising from the nonlinear temporal response of a magnetic nanoparticle to a changing magnetic field, the imaging process is linear in the magnetization distribution and can be described as a convolution. Reconstruction in one dimension is exact and has a well-behaved quasi-Lorentzian point spread function. The spatial resolution improves cubically with increasing diameter of the SPIO domain, inverse to absolute temperature, linearly with saturation magnetization, and inversely with gradient. The bandwidth requirements approach a megahertz for reasonable imaging parameters and millimeter scale resolutions, and the SNR increases with the scanning rate. The limit to SNR as we scale MPI to human sizes will be patient heating. SAR and magnetostimulation limits give us surprising relations between optimal scanning speeds and scanning frequency for different types of scanners.","Magnetic particles,
Signal processing,
Image resolution,
Signal resolution,
Bandwidth,
Saturation magnetization,
Magnetic field measurement,
Nanoparticles,
Spatial resolution,
Biomedical imaging"
Analysis and Design of High-Frequency Isolated Dual-Bridge Series Resonant DC/DC Converter,"Bidirectional dual-bridge dc/dc converter with high frequency isolation is gaining more attentions in renewable energy system due to small size and high-power density. In this paper, a dual-bridge series resonant dc/dc converter is analyzed with two simple modified ac equivalent circuit analysis methods for both voltage source load and resistive load. In both methods, only fundamental components of voltages and currents are considered. All the switches may work in either zero-voltage-switching or zero-current-switching for a wide variation of voltage gain, which is important in renewable energy generation. It is also shown in the second method that the load side circuit could be represented with an equivalent impedance. The polarity of cosine value of this equivalent impedance angle reveals the power flow direction. The analysis is verified with computer simulation results. Experimental data based on a 200 W prototype circuit is included for validation purpose.",
"Low-Temperature Sintering of Nanoscale Silver Paste for Attaching Large-Area
(>100 
mm
2
)
Chips","A low-temperature sintering technique enabled by a nanoscale silver paste has been developed for attaching large-area (>100 mm2) semiconductor chips. This development addresses the need of power device or module manufacturers who face the challenge of replacing lead-based or lead-free solders for high-temperature applications. The solder-reflow technique for attaching large chips in power electronics poses serious concern on reliability at higher junction temperatures above 125°C. Unlike the soldering process that relies on melting and solidification of solder alloys, the low-temperature sintering technique forms the joints by solid-state atomic diffusion at processing temperatures below 275°C with the sintered joints having the melting temperature of silver at 961°C. Recently, we showed that a nanoscale silver paste could be used to bond small chips at temperatures similar to soldering temperatures without any externally applied pressure. In this paper, we extend the use of the nanomaterial to attach large chips by introducing a low pressure up to 5 MPa during the densification stage. Attachment of large chips to substrates with silver, gold, and copper metallization is demonstrated. Analyses of the sintered joints by scanning acoustic imaging and electron microscopy showed that the attachment layer had a uniform microstructure with micrometer-sized porosity with the potential for high reliability under high-temperature applications.",
Received Signal Strength-Based Wireless Localization via Semidefinite Programming: Noncooperative and Cooperative Schemes,"The received signal strength (RSS)-based approach to wireless localization offers the advantage of low cost and easy implementability. To circumvent the nonconvexity of the conventional maximum likelihood (ML) estimator, in this paper, we propose convex estimators specifically for the RSS-based localization problems. Both noncooperative and cooperative schemes are considered. We start with the noncooperative RSS-based localization problem and derive a nonconvex estimator that approximates the ML estimator but has no logarithm in the residual. Next, we apply the semidefinite relaxation technique to the derived nonconvex estimator and develop a convex estimator. To further improve the estimation performance, we append the ML estimator to the convex estimator with the result by the convex estimator as the initial point. We then extend these techniques to the cooperative localization problem. The corresponding Cramer-Rao lower bounds (CRLB) are derived as performance benchmarks. Our proposed convex estimators comply well with the RSS measurement model, and simulation results clearly demonstrate their superior performance for RSS-based wireless localization.",
Deconvolutional networks,"Building robust low and mid-level image representations, beyond edge primitives, is a long-standing goal in vision. Many existing feature detectors spatially pool edge information which destroys cues such as edge intersections, parallelism and symmetry. We present a learning framework where features that capture these mid-level cues spontaneously emerge from image data. Our approach is based on the convolutional decomposition of images under a spar-sity constraint and is totally unsupervised. By building a hierarchy of such decompositions we can learn rich feature sets that are a robust image representation for both the analysis and synthesis of images.",
Effects of variable solar irradiance on the reactive power compensation for large solar farm,"Dish-Stirling systems are a form of concentrating solar power (CSP) emerging as an efficient and reliable source of renewable energy. Various technical hurdles are involved in the grid interconnection of dish-Stirling systems, particularly with issues related to power factor correction, low voltage ride-through capability, and reactive power planning. While there are no grid-interconnection requirements specific to dish-Stirling technology, the requirements currently established for wind farms are used as a starting point due to the similar design and operating characteristics between wind farms and dish-Stirling solar farms. A dish-Stirling solar farm requires external reactive power compensation to meet the power factor requirements presently set for wind farms. The following paper provides a brief overview of dish-Stirling technology, along with an analysis of methods for meeting power factor grid interconnection requirements and maintaining necessary voltage levels under varying irradiance conditions due to cloud cover. Simulation results for voltage and power factor of the solar farm are provided for both steady state and cloud transient conditions within a 12-bus network.",
Quantitative Analysis of Pulmonary Emphysema Using Local Binary Patterns,"We aim at improving quantitative measures of emphysema in computed tomography (CT) images of the lungs. Current standard measures, such as the relative area of emphysema (RA), rely on a single intensity threshold on individual pixels, thus ignoring any interrelations between pixels. Texture analysis allows for a much richer representation that also takes the local structure around pixels into account. This paper presents a texture classification-based system for emphysema quantification in CT images. Measures of emphysema severity are obtained by fusing pixel posterior probabilities output by a classifier. Local binary patterns (LBP) are used as texture features, and joint LBP and intensity histograms are used for characterizing regions of interest (ROIs). Classification is then performed using a k nearest neighbor classifier with a histogram dissimilarity measure as distance. A 95.2% classification accuracy was achieved on a set of 168 manually annotated ROIs, comprising the three classes: normal tissue, centrilobular emphysema, and paraseptal emphysema. The measured emphysema severity was in good agreement with a pulmonary function test (PFT) achieving correlation coefficients of up to |r| = 0.79 in 39 subjects. The results were compared to RA and to a Gaussian filter bank, and the texture-based measures correlated significantly better with PFT than did RA.","Pattern analysis,
Computed tomography,
Histograms,
Lungs,
Measurement standards,
Area measurement,
Current measurement,
Image texture analysis,
Performance evaluation,
Nearest neighbor searches"
A Survey of Artificial Intelligence for Cognitive Radios,"Cognitive radio (CR) is an enabling technology for numerous new capabilities such as dynamic spectrum access, spectrum markets, and self-organizing networks. To realize this diverse set of applications, CR researchers leverage a variety of artificial intelligence (AI) techniques. To help researchers better understand the practical implications of AI to their CR designs, this paper reviews several CR implementations that used the following AI techniques: artificial neural networks (ANNs), metaheuristic algorithms, hidden Markov models (HMMs), rule-based systems, ontology-based systems (OBSs), and case-based systems (CBSs). Factors that influence the choice of AI techniques, such as responsiveness, complexity, security, robustness, and stability, are discussed. To provide readers with a more concrete understanding, these factors are illustrated in an extended discussion of two CR designs.",
Coherence-Based Performance Guarantees for Estimating a Sparse Vector Under Random Noise,"We consider the problem of estimating a deterministic sparse vector x0 from underdetermined measurements A x0 + w, where w represents white Gaussian noise and A is a given deterministic dictionary. We provide theoretical performance guarantees for three sparse estimation algorithms: basis pursuit denoising (BPDN), orthogonal matching pursuit (OMP), and thresholding. The performance of these techniques is quantified as the l2 distance between the estimate and the true value of x0. We demonstrate that, with high probability, the analyzed algorithms come close to the behavior of the oracle estimator, which knows the locations of the nonzero elements in x0. Our results are non-asymptotic and are based only on the coherence of A, so that they are applicable to arbitrary dictionaries. This provides insight on the advantages and drawbacks of l1 relaxation techniques such as BPDN and the Dantzig selector, as opposed to greedy approaches such as OMP and thresholding.","Matching pursuit algorithms,
Gaussian noise,
Noise measurement,
Dictionaries,
Noise reduction,
Pursuit algorithms,
Permission,
Algorithm design and analysis,
Signal processing algorithms,
Computer science"
Expensive Multiobjective Optimization by MOEA/D With Gaussian Process Model,"In some expensive multiobjective optimization problems (MOPs), several function evaluations can be carried out in a batch way. Therefore, it is very desirable to develop methods which can generate multipler test points simultaneously. This paper proposes such a method, called MOEA/D-EGO, for dealing with expensive multiobjective optimization. MOEA/D-EGO decomposes an MOP in question into a number of single-objective optimization subproblems. A predictive model is built for each subproblem based on the points evaluated so far. Effort has been made to reduce the overhead for modeling and to improve the prediction quality. At each generation, MOEA/D is used for maximizing the expected improvement metric values of all the subproblems, and then several test points are selected for evaluation. Extensive experimental studies have been carried out to investigate the ability of the proposed algorithm.","Gaussian processes,
Stochastic processes,
Pareto optimization,
Optimization methods,
Predictive models,
Acoustic testing,
Physics computing,
Computer simulation,
Computational efficiency,
Design optimization"
Handling Sideband Radiations in Time-Modulated Arrays Through Particle Swarm Optimization,"The minimization of the power losses in time-modulated arrays is addressed by means of a suitable strategy based on particle swarm optimization. By properly modifying the modulation sequence, the method is aimed at reducing the amount of wasted power, analytically computed through a very effective closed-form relationship, while constraining the radiation pattern at the carrier frequency below a fixed sidelobe level. Representative results are reported and compared with previously published solutions to assess the effectiveness of the proposed approach.","Particle swarm optimization,
Frequency,
Pattern analysis,
Switches,
Phased arrays,
Power system harmonics,
Optical arrays,
Prototypes,
Power generation,
Stochastic processes"
Biomechanical Properties of In Vivo Human Skin From Dynamic Optical Coherence Elastography,"Dynamic optical coherence elastography is used to determine in vivo skin biomechanical properties based on mechanical surface wave propagation. Quantitative Young's moduli are measured on human skin from different sites, orientations, and frequencies. Skin thicknesses, including measurements from different layers, are also measured simultaneously. Experimental results show significant differences among measurements from different skin sites, between directions parallel and orthogonal to Langer's lines, and under different skin hydration states. Results also suggest surface waves with different driving frequencies represent skin biomechanical properties from different layers in depth. With features such as micrometer-scale resolution, noninvasive imaging, and real-time processing from the optical coherence tomography technology, this optical measurement technique has great potential for measuring skin biomechanical properties in dermatology.",
Source Camera Identification Using Enhanced Sensor Pattern Noise,"Sensor pattern noises (SPNs), extracted from digital images to serve as the fingerprints of imaging devices, have been proved as an effective way for digital device identification. However, as we demonstrate in this work, the limitation of the current method of extracting SPNs is that the SPNs extracted from images can be severely contaminated by details from scenes, and as a result, the identification rate is unsatisfactory unless images of a large size are used. In this work, we propose a novel approach for attenuating the influence of details from scenes on SPNs so as to improve the device identification rate of the identifier. The hypothesis underlying our SPN enhancement method is that the stronger a signal component in an SPN is, the less trustworthy the component should be, and thus should be attenuated. This hypothesis suggests that an enhanced SPN can be obtained by assigning weighting factors inversely proportional to the magnitude of the SPN components.",
Geodesic star convexity for interactive image segmentation,"In this paper we introduce a new shape constraint for interactive image segmentation. It is an extension of Veksler's [25] star-convexity prior, in two ways: from a single star to multiple stars and from Euclidean rays to Geodesic paths. Global minima of the energy function are obtained subject to these new constraints. We also introduce Geodesic Forests, which exploit the structure of shortest paths in implementing the extended constraints. The star-convexity prior is used here in an interactive setting and this is demonstrated in a practical system. The system is evaluated by means of a “robot user” to measure the amount of interaction required in a precise way. We also introduce a new and harder dataset which augments the existing Grabcut dataset [1] with images and ground truth taken from the PASCAL VOC segmentation challenge [7].","Image segmentation,
Shape,
Robots,
Level measurement,
Humans,
Focusing,
Object recognition,
Brushes,
Joining processes"
Distributed Recovery from Network Partitioning in Movable Sensor/Actor Networks via Controlled Mobility,"Mobility has been introduced to sensor networks through the deployment of movable nodes. In movable wireless networks, network connectivity among the nodes is a crucial factor in order to relay data to the sink node, exchange data for collaboration, and perform data aggregation. However, such connectivity can be lost due to a failure of one or more nodes. Even a single node failure may partition the network, and thus, eventually reduce the quality and efficiency of the network operation. To handle this connectivity problem, we present PADRA to detect possible partitions, and then, restore the network connectivity through controlled relocation of movable nodes. The idea is to identify whether or not the failure of a node will cause partitioning in advance in a distributed manner. If a partitioning is to occur, PADRA designates a failure handler to initiate the connectivity restoration process. The overall goal in this process is to localize the scope of the recovery and minimize the overhead imposed on the nodes. We further extend PADRA to handle multiple node failures. The approach, namely, MDAPRA strives to provide a mutual exclusion mechanism in repositioning the nodes to restore connectivity. The effectiveness of the proposed approaches is validated through simulation experiments.",
Quality of Trilateration: Confidence-Based Iterative Localization,"The proliferation of wireless and mobile devices has fostered the demand for context-aware applications, in which location is one of the most significant contexts. Multilateration, as a basic building block of localization, however, has not yet overcome the challenges of 1) poor ranging measurements; 2) dynamic and noisy environments; and 3) fluctuations in wireless communications. Hence, multilateration-based approaches often suffer from poor accuracy and can hardly be employed in practical applications. In this study, we propose Quality of Trilateration (QoT) that quantifies the geometric relationship of objects and ranging noises. Based on QoT, we design a confidence-based iterative localization scheme, in which nodes dynamically select trilaterations with the highest quality for location computation. To validate this design, a prototype network based on wireless sensor motes is deployed and the results show that QoT well represents trilateration accuracy, and the proposed scheme significantly improves localization accuracy.",
Discriminative Semi-Supervised Feature Selection Via Manifold Regularization,"Feature selection has attracted a huge amount of interest in both research and application communities of data mining. We consider the problem of semi-supervised feature selection, where we are given a small amount of labeled examples and a large amount of unlabeled examples. Since a small number of labeled samples are usually insufficient for identifying the relevant features, the critical problem arising from semi-supervised feature selection is how to take advantage of the information underneath the unlabeled data. To address this problem, we propose a novel discriminative semi-supervised feature selection method based on the idea of manifold regularization. The proposed approach selects features through maximizing the classification margin between different classes and simultaneously exploiting the geometry of the probability distribution that generates both labeled and unlabeled data. In comparison with previous semi-supervised feature selection algorithms, our proposed semi-supervised feature selection method is an embedded feature selection method and is able to find more discriminative features. We formulate the proposed feature selection method into a convex-concave optimization problem, where the saddle point corresponds to the optimal solution. To find the optimal solution, the level method, a fairly recent optimization method, is employed. We also present a theoretic proof of the convergence rate for the application of the level method to our problem. Empirical evaluation on several benchmark data sets demonstrates the effectiveness of the proposed semi-supervised feature selection method.","Biosensors,
Data mining,
Optimization methods,
Computer science,
Bioinformatics,
Sensor systems,
Training data,
Communities,
Information geometry,
Probability distribution"
Nonrigid Image Registration Using Conditional Mutual Information,"Maximization of mutual information (MMI) is a popular similarity measure for medical image registration. Although its accuracy and robustness has been demonstrated for rigid body image registration, extending MMI to nonrigid image registration is not trivial and an active field of research. We propose conditional mutual information (cMI) as a new similarity measure for nonrigid image registration. cMI starts from a 3-D joint histogram incorporating, besides the intensity dimensions, also a spatial dimension expressing the location of the joint intensity pair. cMI is calculated as the expected value of the cMI between the image intensities given the spatial distribution. The cMI measure was incorporated in a tensor-product B-spline nonrigid registration method, using either a Parzen window or generalized partial volume kernel for histogram construction. cMI was compared to the classical global mutual information (gMI) approach in theoretical, phantom, and clinical settings. We show that cMI significantly outperforms gMI for all applications.","Image registration,
Mutual information,
Biomedical imaging,
Biomedical measurements,
Histograms,
Computed tomography,
Robustness,
Spline,
Probability,
Speech processing"
Utility-based asynchronous flow control algorithm for wireless sensor networks,"In this paper, we formulate a flow control optimization problem for wireless sensor networks with lifetime constraint and link interference in an asynchronous setting. Our formulation is based on the network utility maximization framework, in which a general utility function is used to characterize the network performance such as throughput. To solve the problem, we propose a fully asynchronous distributed algorithm based on dual decomposition, and theoretically prove its convergence. The proposed algorithm can achieve the maximum utility. Extensive simulations are conducted to demonstrate the efficiency of our algorithm and validate the analytical results.","Wireless sensor networks,
Interference,
Algorithm design and analysis,
Optimization,
Convergence,
Wireless communication,
Resource management"
Single image depth estimation from predicted semantic labels,"We consider the problem of estimating the depth of each pixel in a scene from a single monocular image. Unlike traditional approaches [18, 19], which attempt to map from appearance features to depth directly, we first perform a semantic segmentation of the scene and use the semantic labels to guide the 3D reconstruction. This approach provides several advantages: By knowing the semantic class of a pixel or region, depth and geometry constraints can be easily enforced (e.g., “sky” is far away and “ground” is horizontal). In addition, depth can be more readily predicted by measuring the difference in appearance with respect to a given semantic class. For example, a tree will have more uniform appearance in the distance than it does close up. Finally, the incorporation of semantic features allows us to achieve state-of-the-art results with a significantly simpler model than previous works.","Layout,
Image reconstruction,
Geometry,
Computer science,
Pixel,
Predictive models,
Computer vision,
Roads,
Image segmentation,
Application software"
A Survey of Game Theory as Applied to Network Security,"Network security is a complex and challenging problem. The area of network defense mechanism design is receiving immense attention from the research community for more than two decades. However, the network security problem is far from completely solved. Researchers have been exploring the applicability of game theoretic approaches to address the network security issues and some of these approaches look promising. This paper surveys the existing game theoretic solutions which are designed to enhance network security and presents a taxonomy for classifying the proposed solutions. This taxonomy should provide the reader with a better understanding of game theoretic solutions to a variety of cyber security problems.","Game theory,
Taxonomy,
Intrusion detection,
Computer security,
Government,
Data security,
IP networks,
Computer science,
Pressing,
Protection"
"Polar Codes: Characterization of Exponent, Bounds, and Constructions","Polar codes were recently introduced by Arikan. They achieve the symmetric capacity of arbitrary binary-input discrete memoryless channels under a low complexity successive cancellation decoding scheme. The original polar code construction is closely related to the recursive construction of Reed-Muller codes and is based on the 2 × 2 matrix [1 0 : 1 1]. It was shown by Arikan Telatar that this construction achieves an error exponent of 1/2, i.e., that for sufficiently large blocklengths the error probability decays exponentially in the square root of the blocklength. It was already mentioned by Arikan that in principle larger matrices can be used to construct polar codes. In this paper, it is first shown that any ℓ × ℓ matrix none of whose column permutations is upper triangular polarizes binary-input memoryless channels. The exponent of a given square matrix is characterized, upper and lower bounds on achievable exponents are given. Using these bounds it is shown that there are no matrices of size smaller than 15×15 with exponents exceeding 1/2. Further, a general construction based on BCH codes which for large I achieves exponents arbitrarily close to 1 is given. At size 16 × 16, this construction yields an exponent greater than 1/2.","Memoryless systems,
Complexity theory,
Error probability,
Symmetric matrices,
Polarization"
Image Clustering Using Local Discriminant Models and Global Integration,"In this paper, we propose a new image clustering algorithm, referred to as clustering using local discriminant models and global integration (LDMGI). To deal with the data points sampled from a nonlinear manifold, for each data point, we construct a local clique comprising this data point and its neighboring data points. Inspired by the Fisher criterion, we use a local discriminant model for each local clique to evaluate the clustering performance of samples within the local clique. To obtain the clustering result, we further propose a unified objective function to globally integrate the local models of all the local cliques. With the unified objective function, spectral relaxation and spectral rotation are used to obtain the binary cluster indicator matrix for all the samples. We show that LDMGI shares a similar objective function with the spectral clustering (SC) algorithms, e.g., normalized cut (NCut). In contrast to NCut in which the Laplacian matrix is directly calculated based upon a Gaussian function, a new Laplacian matrix is learnt in LDMGI by exploiting both manifold structure and local discriminant information. We also prove that K-means and discriminative K-means (DisKmeans) are both special cases of LDMGI. Extensive experiments on several benchmark image datasets demonstrate the effectiveness of LDMGI. We observe in the experiments that LDMGI is more robust to algorithmic parameter, when compared with NCut. Thus, LDMGI is more appealing for the real image clustering applications in which the ground truth is generally not available for tuning algorithmic parameters.","Clustering algorithms,
Clustering methods,
Principal component analysis,
Laplace equations,
Indexing,
Linear discriminant analysis,
Educational institutions,
Computer science,
Manifolds,
Robustness"
Adaptive Neural Network Control of a Self-Balancing Two-Wheeled Scooter,"This paper presents an adaptive control using radial-basis-function neural networks (RBFNNs) for a two-wheeled self-balancing scooter. A mechatronic system structure of the scooter driven by two dc motors is briefly described, and its mathematical modeling incorporating two frictions between the wheels and the motion surface is derived. By decomposing the overall system into two subsystems (yaw motion and mobile inverted pendulum), one proposes two adaptive controllers using RBFNN to achieve self-balancing and yaw control. The performance and merit of the proposed adaptive controllers are exemplified by conducting several simulations and experiments on a two-wheeled self-balancing scooter.","Adaptive systems,
Programmable control,
Adaptive control,
Neural networks,
Motorcycles,
Motion control,
Control systems,
Mechatronics,
DC motors,
Mathematical model"
PRESS: PRedictive Elastic ReSource Scaling for cloud systems,"Cloud systems require elastic resource allocation to minimize resource provisioning costs while meeting service level objectives (SLOs). In this paper, we present a novel PRedictive Elastic reSource Scaling (PRESS) scheme for cloud systems. PRESS unobtrusively extracts fine-grained dynamic patterns in application resource demands and adjust their resource allocations automatically. Our approach leverages light-weight signal processing and statistical learning algorithms to achieve online predictions of dynamic application resource requirements. We have implemented the PRESS system on Xen and tested it using RUBiS and an application load trace from Google. Our experiments show that we can achieve good resource prediction accuracy with less than 5% over-estimation error and near zero under-estimation error, and elastic resource scaling can both significantly reduce resource waste and SLO violations.","Presses,
Prediction algorithms,
Resource management,
Time series analysis,
Markov processes,
Predictive models,
Measurement"
Grouplet: A structured image representation for recognizing human and object interactions,"Psychologists have proposed that many human-object interaction activities form unique classes of scenes. Recognizing these scenes is important for many social functions. To enable a computer to do this is however a challenging task. Take people-playing-musical-instrument (PPMI) as an example; to distinguish a person playing violin from a person just holding a violin requires subtle distinction of characteristic image features and feature arrangements that differentiate these two scenes. Most of the existing image representation methods are either too coarse (e.g. BoW) or too sparse (e.g. constellation models) for performing this task. In this paper, we propose a new image feature representation called “grouplet”. The grouplet captures the structured information of an image by encoding a number of discriminative visual features and their spatial configurations. Using a dataset of 7 different PPMI activities, we show that grouplets are more effective in classifying and detecting human-object interactions than other state-of-the-art methods. In particular, our method can make a robust distinction between humans playing the instruments and humans co-occurring with the instruments without playing.","Image representation,
Image recognition,
Humans,
Layout,
Instruments,
Object detection,
Psychology,
Computer science,
Image coding,
Robustness"
A Model for Reducing Power Consumption in Peer-to-Peer Systems,"Information systems based on the cloud computing model and peer-to-peer (P2P) model are now getting popular. In the cloud computing model, a cloud of servers support thin clients with various types of service like Web pages and databases. On the other hand, every computer is peer and there is no centralized coordinator in the P2P model. It is getting more significant to discuss how to reduce the total electric power consumption of computers in information systems to realize eco-society. In this paper, we consider a Web type of application on P2P overlay networks. First, we discuss a model for showing how much each server peer consumes electric power to perform Web requests from client peers. Then, we discuss algorithms for a client peer to select a server peer in a collection of server peers so that the total power consumption can be reduced while some constraint like deadline one is satisfied. Lastly, we evaluate the algorithms in terms of the total power consumption and throughput compared with traditional round robin algorithms.","Power system modeling,
Energy consumption,
Peer to peer computing,
Round robin,
Network servers,
Information systems,
Cloud computing,
Web pages,
Databases,
Application software"
An Efficient Pseudonymous Authentication Scheme With Strong Privacy Preservation for Vehicular Communications,"In this paper, we propose an efficient pseudonymous authentication scheme with strong privacy preservation (PASS), for vehicular communications. Unlike traditional pseudonymous authentication schemes, the size of the certificate revocation list (CRL) in PASS is linear with the number of revoked vehicles and unrelated to how many pseudonymous certificates are held by the revoked vehicles. PASS supports the roadside unit (RSU)-aided distributed certificate service that allows the vehicles to update certificates on road, but the service overhead is almost unrelated to the number of updated certificates. Furthermore, PASS provides strong privacy preservation to the vehicles so that the adversaries cannot trace any vehicle, even though all RSUs have been compromised. Extensive simulations demonstrate that PASS outperforms previously reported schemes in terms of the revocation cost and the certificate updating overhead.",
Synchronization of Interconnected Systems With Applications to Biochemical Networks: An Input-Output Approach,"This paper provides synchronization conditions for networks of nonlinear systems. The components of the network (referred to as “compartments” in this paper) are made up of an identical interconnection of subsystems, each represented as an operator in an extended L2 space and referred to as a “species.” The compartments are, in turn, coupled through a diffusion-like term among the respective species. The synchronization conditions are provided by combining the input-output properties of the subsystems with information about the structure of the network. The paper also explores results for state-space models, as well as biochemical applications. The work is motivated by cellular networks where signaling occurs both internally, through interactions of species, and externally, through intercellular signaling. The theory is illustrated by providing synchronization conditions for networks of Goodwin oscillators.",
A Sub-\mu W Embedded CMOS Temperature Sensor for RFID Food Monitoring Application,"An ultra-low power embedded CMOS temperature sensor based on serially connected subthreshold MOS operation is implemented in a 0.18 μm CMOS process for passive RFID food monitoring applications. Employing serially connected subthreshold MOS as sensing element enables reduced minimum supply voltage for further power reduction, which is of utmost importance in passive RFID applications. Both proportional-to-absolute-temperature (PTAT) and complimentary-to-absolute-temperature (CTAT) signals can be obtained through proper transistor sizing. With the sensor core working under 0.5 V and digital interfacing under 1 V, the sensor dissipates a measured total power of 119 nW at 333 samples/s and achieves an inaccuracy of + 1/-0.8°C from - 10°C to 30°C after calibration. The sensor is embedded inside the fabricated passive UHF RFID tag. Measurement of the sensor performance at the system level is also carried out, illustrating proper sensing operation for passive RFID applications.","Passive RFID tags,
Radiofrequency identification,
CMOS process,
UHF measurements,
CMOS image sensors,
Temperature sensors,
Monitoring,
Voltage,
Power measurement,
Calibration"
Robust Super-Resolution Volume Reconstruction From Slice Acquisitions: Application to Fetal Brain MRI,"Fast magnetic resonance imaging slice acquisition techniques such as single shot fast spin echo are routinely used in the presence of uncontrollable motion. These techniques are widely used for fetal magnetic resonance imaging (MRI) and MRI of moving subjects and organs. Although high-quality slices are frequently acquired by these techniques, inter-slice motion leads to severe motion artifacts that are apparent in out-of-plane views. Slice sequential acquisitions do not enable 3-D volume representation. In this study, we have developed a novel technique based on a slice acquisition model, which enables the reconstruction of a volumetric image from multiple-scan slice acquisitions. The super-resolution volume reconstruction is formulated as an inverse problem of finding the underlying structure generating the acquired slices. We have developed a robust M-estimation solution which minimizes a robust error norm function between the model-generated slices and the acquired slices. The accuracy and robustness of this novel technique has been quantitatively assessed through simulations with digital brain phantom images as well as high-resolution newborn images. We also report here successful application of our new technique for the reconstruction of volumetric fetal brain MRI from clinically acquired data.","Robustness,
Magnetic resonance imaging,
Image reconstruction,
Fetus,
Pediatrics,
Permission,
Image resolution,
Inverse problems,
Brain modeling,
Imaging phantoms"
Modeling pixel process with scale invariant local patterns for background subtraction in complex scenes,"Background modeling plays an important role in video surveillance, yet in complex scenes it is still a challenging problem. Among many difficulties, problems caused by illumination variations and dynamic backgrounds are the key aspects. In this work, we develop an efficient background subtraction framework to tackle these problems. First, we propose a scale invariant local ternary pattern operator, and show that it is effective for handling illumination variations, especially for moving soft shadows. Second, we propose a pattern kernel density estimation technique to effectively model the probability distribution of local patterns in the pixel process, which utilizes only one single LBP-like pattern instead of histogram as feature. Third, we develop multimodal background models with the above techniques and a multiscale fusion scheme for handling complex dynamic backgrounds. Exhaustive experimental evaluations on complex scenes show that the proposed method is fast and effective, achieving more than 10% improvement in accuracy compared over existing state-of-the-art algorithms.","Layout,
Lighting,
Encoding,
Background noise,
Noise figure,
Kernel,
Probability distribution,
Histograms,
Biometrics,
National security"
Multistability of Recurrent Neural Networks With Time-varying Delays and the Piecewise Linear Activation Function,"In this brief, stability of multiple equilibria of recurrent neural networks with time-varying delays and the piecewise linear activation function is studied. A sufficient condition is obtained to ensure that n-neuron recurrent neural networks can have (4k-1)n equilibrium points and (2k)n of them are locally exponentially stable. This condition improves and extends the existing stability results in the literature. Simulation results are also discussed in one illustrative example.","Recurrent neural networks,
Piecewise linear techniques,
Biological neural networks,
Educational institutions,
Stability,
Sufficient conditions,
Brain modeling,
Associative memory,
Orbits,
Control engineering education"
Malicious User Detection in a Cognitive Radio Cooperative Sensing System,"Reliable detection of primary users (PUs) is an important task for cognitive radio (CR) systems. Cooperation among a few spectrum sensors has been shown to offer significant gain in the performance of the CR spectrum-sensing system by countering the shadow-fading effects. We consider a parallel fusion network in which the sensors send their sensing information to an access point which makes the final decision regarding presence or absence of the PU signal. It has been shown in the literature that the presence of malicious users sending false sensing data can severely degrade the performance of such a cooperative sensing system. In this paper, we investigate schemes to identify the malicious users based on outlier detection techniques for a cooperative sensing system employing energy detection at the sensors. We take into consideration constraints imposed by the CR scenario such as the lack of information about the primary signal propagation environment and the small size of the sensing data samples. Considering partial information of the PU activity, we propose a novel method to identify the malicious users. We further propose malicious user detection schemes that take into consideration the spatial information of the CR sensors. The performance of the proposed schemes are studied using simulations.","Cognitive radio,
Chromium,
Propagation losses,
Sensor systems,
Sensor fusion,
Performance gain,
Degradation,
FCC,
Radio frequency,
Power system reliability"
Quantitative Comparison of Spot Detection Methods in Fluorescence Microscopy,"Quantitative analysis of biological image data generally involves the detection of many subresolution spots. Especially in live cell imaging, for which fluorescence microscopy is often used, the signal-to-noise ratio (SNR) can be extremely low, making automated spot detection a very challenging task. In the past, many methods have been proposed to perform this task, but a thorough quantitative evaluation and comparison of these methods is lacking in the literature. In this paper, we evaluate the performance of the most frequently used detection methods for this purpose. These include seven unsupervised and two supervised methods. We perform experiments on synthetic images of three different types, for which the ground truth was available, as well as on real image data sets acquired for two different biological studies, for which we obtained expert manual annotations to compare with. The results from both types of experiments suggest that for very low SNRs ( ¿ 2), the supervised (machine learning) methods perform best overall. Of the unsupervised methods, the detectors based on the so-called h -dome transform from mathematical morphology or the multiscale variance-stabilizing transform perform comparably, and have the advantage that they do not require a cumbersome learning stage. At high SNRs ( > 5), the difference in performance of all considered detectors becomes negligible.","Fluorescence,
Image analysis,
Object detection,
Optical microscopy,
Biomedical imaging,
Optical imaging,
Signal to noise ratio,
Machine learning,
Detectors,
Proteins"
Semisupervised One-Class Support Vector Machines for Classification of Remote Sensing Data,"This paper presents two semisupervised one-class support vector machine (OC-SVM) classifiers for remote sensing applications. In one-class image classification, one tries to detect pixels belonging to one of the classes in the image and reject the others. When few labeled pixels of only one class are available, obtaining a reliable classifier is a difficult task. In the particular case of SVM-based classifiers, this task is even harder because the free parameters of the model need to be finely adjusted, but no clear criterion can be adopted. In order to improve the OC-SVM classifier accuracy and alleviate the problem of free-parameter selection, the information provided by unlabeled samples present in the scene can be used. In this paper, we present two state-of-the-art algorithms for semisupervised one-class classification for remote sensing classification problems. The first proposed algorithm is based on modifying the OC-SVM kernel by modeling the data marginal distribution with the graph Laplacian built with both labeled and unlabeled samples. The second one is based on a simple modification of the standard SVM cost function which penalizes more the errors made when classifying samples of the target class. The good performance of the proposed methods is illustrated in four challenging remote sensing image classification scenarios where the goal is to detect one of the classes present on the scene. In particular, we present results for multisource urban monitoring, hyperspectral crop detection, multispectral cloud screening, and change-detection problems. Experimental results show the suitability of the proposed techniques, particularly in cases with few or poorly representative labeled samples.",
Building a Green Wireless-Optical Broadband Access Network (WOBAN),"Access networks consume a significant portion of overall Internet energy consumption. With the increase of bit-rate requirements in access networks, future-proof access technologies should be energy efficient. In this paper, we show how we can build a very high-throughput “green” hybrid wireless-optical broadband access network (WOBAN). We devise novel energy-saving techniques for WOBAN to improve its energy efficiency and network utilization. We present a mixed integer linear program (MILP) model, which acts as a benchmark for evaluating our techniques. We analyze the impact of energy-aware design and protocols on the performance of WOBAN over dynamic traffic profiles. Illustrative numerical examples show that, with suitable design parameters, we can efficiently reduce energy consumption in WOBAN without significantly impacting the network performance.","Energy consumption,
IP networks,
Energy efficiency,
Telecommunication traffic,
Business,
Land mobile radio cellular systems,
Performance analysis,
Access protocols,
Traffic control,
Communications technology"
Robust 3D Face Recognition by Local Shape Difference Boosting,"This paper proposes a new 3D face recognition approach, Collective Shape Difference Classifier (CSDC), to meet practical application requirements, i.e., high recognition performance, high computational efficiency, and easy implementation. We first present a fast posture alignment method which is self-dependent and avoids the registration between an input face against every face in the gallery. Then, a Signed Shape Difference Map (SSDM) is computed between two aligned 3D faces as a mediate representation for the shape comparison. Based on the SSDMs, three kinds of features are used to encode both the local similarity and the change characteristics between facial shapes. The most discriminative local features are selected optimally by boosting and trained as weak classifiers for assembling three collective strong classifiers, namely, CSDCs with respect to the three kinds of features. Different schemes are designed for verification and identification to pursue high performance in both recognition and computation. The experiments, carried out on FRGC v2 with the standard protocol, yield three verification rates all better than 97.9 percent with the FAR of 0.1 percent and rank-1 recognition rates above 98 percent. Each recognition against a gallery with 1,000 faces only takes about 3.6 seconds. These experimental results demonstrate that our algorithm is not only effective but also time efficient.",
Understanding Transit Scenes: A Survey on Human Behavior-Recognition Algorithms,"Visual surveillance is an active research topic in image processing. Transit systems are actively seeking new or improved ways to use technology to deter and respond to accidents, crime, suspicious activities, terrorism, and vandalism. Human behavior-recognition algorithms can be used proactively for prevention of incidents or reactively for investigation after the fact. This paper describes the current state-of-the-art image-processing methods for automatic-behavior-recognition techniques, with focus on the surveillance of human activities in the context of transit applications. The main goal of this survey is to provide researchers in the field with a summary of progress achieved to date and to help identify areas where further research is needed. This paper provides a thorough description of the research on relevant human behavior-recognition methods for transit surveillance. Recognition methods include single person (e.g., loitering), multiple-person interactions (e.g., fighting and personal attacks), person-vehicle interactions (e.g., vehicle vandalism), and person-facility/location interactions (e.g., object left behind and trespassing). A list of relevant behavior-recognition papers is presented, including behaviors, data sets, implementation details, and results. In addition, algorithm's weaknesses, potential research directions, and contrast with commercial capabilities as advertised by manufacturers are discussed. This paper also provides a summary of literature surveys and developments of the core technologies (i.e., low-level processing techniques) used in visual surveillance systems, including motion detection, classification of moving objects, and tracking.","Layout,
Humans,
Surveillance,
Image processing,
Accidents,
Terrorism,
Vehicles,
Manufacturing,
Motion detection,
Tracking"
Shrinkage Algorithms for MMSE Covariance Estimation,"We address covariance estimation in the sense of minimum mean-squared error (MMSE) when the samples are Gaussian distributed. Specifically, we consider shrinkage methods which are suitable for high dimensional problems with a small number of samples (large p small n). First, we improve on the Ledoit-Wolf (LW) method by conditioning on a sufficient statistic. By the Rao-Blackwell theorem, this yields a new estimator called RBLW, whose mean-squared error dominates that of LW for Gaussian variables. Second, to further reduce the estimation error, we propose an iterative approach which approximates the clairvoyant shrinkage estimator. Convergence of this iterative method is established and a closed form expression for the limit is determined, which is referred to as the oracle approximating shrinkage (OAS) estimator. Both RBLW and OAS estimators have simple expressions and are easily implemented. Although the two methods are developed from different perspectives, their structure is identical up to specified constants. The RBLW estimator provably dominates the LW method for Gaussian samples. Numerical simulations demonstrate that the OAS approach can perform even better than RBLW, especially when n is much less than p . We also demonstrate the performance of these techniques in the context of adaptive beamforming.","Array signal processing,
Covariance matrix,
Ambient intelligence,
Iterative methods,
Permission,
Computer science,
Iron,
Statistics,
Yield estimation,
Estimation error"
Accurate localization of RFID tags using phase difference,"Due to their light weight, low power, and practically unlimited identification capacity, radio frequency identification (RFID) tags and associated devices offer distinctive advantages and are widely recognized for their promising potential in context-aware computing; by tagging objects with RFID tags, the environment can be sensed in a cost- and energy-efficient means. However, a prerequisite to fully realizing the potential is accurate localization of RFID tags, which will enable and enhance a wide range of applications. In this paper we show how to exploit the phase difference between two or more receiving antennas to compute accurate localization. Phase difference based localization has better accuracy, robustness and sensitivity when integrated with other measurements compared to the currently popular technique of localization using received signal strength. Using a software-defined radio setup, we show experimental results that support accurate localization of RFID tags and activity recognition based on phase difference.","RFID tags,
Radiofrequency identification,
Context-aware services,
Tagging,
Energy efficiency,
Receiving antennas,
Robustness,
Antenna measurements,
Current measurement,
Phase measurement"
Sparse Recovery Using Sparse Matrices,"In this paper, we survey algorithms for sparse recovery problems that are based on sparse random matrices. Such matrices has several attractive properties: they support algorithms with low computational complexity, and make it easy to perform incremental updates to signals. We discuss applications to several areas, including compressive sensing, data stream computing, and group testing.","Sparse matrices,
Signal processing algorithms,
Hardware,
Testing,
Signal processing,
Image coding,
Vectors,
Mathematics,
Encoding,
Computational complexity"
Monte Carlo Simulation of Single Event Effects,"In this paper, we describe a Monte Carlo approach for estimating the frequency and character of single event effects based on a combination of physical modeling of discrete radiation events, device simulations to estimate charge transport and collection, and circuit simulations to determine the effect of the collected charge. A mathematical analysis of the procedure reveals it to be closely related to the rectangular parallelepiped (RPP) rate prediction method. The results of these simulations show that event-to-event variation may have a significant impact when predicting the single-event rate in advanced spacecraft electronics. Specific criteria for supplementing established RPP-based single event analysis with Monte Carlo computations are discussed.",
Replication Routing in DTNs: A Resource Allocation Approach,"Routing protocols for disruption-tolerant networks (DTNs) use a variety of mechanisms, including discovering the meeting probabilities among nodes, packet replication, and network coding. The primary focus of these mechanisms is to increase the likelihood of finding a path with limited information, and so these approaches have only an incidental effect on such routing metrics as maximum or average delivery delay. In this paper, we present rapid, an intentional DTN routing protocol that can optimize a specific routing metric such as the worst-case delivery delay or the fraction of packets that are delivered within a deadline. The key insight is to treat DTN routing as a resource allocation problem that translates the routing metric into per-packet utilities that determine how packets should be replicated in the system. We evaluate rapid rigorously through a prototype deployed over a vehicular DTN testbed of 40 buses and simulations based on real traces. To our knowledge, this is the first paper to report on a routing protocol deployed on a real outdoor DTN. Our results suggest that rapid significantly outperforms existing routing protocols for several metrics. We also show empirically that for small loads, RAPID is within 10% of the optimal performance.","Disruption tolerant networking,
Resource management,
Routing protocols,
Network coding,
Delay effects,
Bandwidth,
Virtual prototyping,
Testing,
Large-scale systems,
Monitoring"
A New Method for Robust Damping and Tracking Control of Scanning Probe Microscope Positioning Stages,"This paper demonstrates a simple second-order controller that eliminates scan-induced oscillation and provides integral tracking action. The controller can be retrofitted to any scanning probe microscope with position sensors by implementing a simple digital controller or operational amplifier circuit. The controller is demonstrated to improve the tracking bandwidth of an NT-MDT scanning probe microscope from 15 Hz (with an integral controller) to 490 Hz while simultaneously improving gain-margin from 2 to 7 dB. The penalty on sensor induced positioning noise is minimal. A unique benefit of the proposed control scheme is the performance and stability robustness with respect to variations in resonance frequency. This is demonstrated experimentally by a change in resonance frequency from 934 to 140 Hz. This change does not compromise stability or significantly degrade performance. For the scanning probe microscope considered in this paper, the noise is marginally increased from 0.30 to 0.39 nm rms. Open and closed-loop experimental images of a calibration standard are reported at speeds of 1, 10, and 31 lines per second (with a scanner resonance frequency of 290 Hz). Compared with traditional integral controllers, the proposed controller provides a bandwidth improvement of greater than 10 times. This allows faster imaging and less tracking lag at low speeds.",
Cloud auto-scaling with deadline and budget constraints,"Clouds have become an attractive computing platform which offers on-demand computing power and storage capacity. Its dynamic scalability enables users to quickly scale up and scale down underlying infrastructure in response to business volume, performance desire and other dynamic behaviors. However, challenges arise when considering computing instance non-deterministic acquisition time, multiple VM instance types, unique cloud billing models and user budget constraints. Planning enough computing resources for user desired performance with less cost, which can also automatically adapt to workload changes, is not a trivial problem. In this paper, we present a cloud auto-scaling mechanism to automatically scale computing instances based on workload information and performance desire. Our mechanism schedules VM instance startup and shut-down activities. It enables cloud applications to finish submitted jobs within the deadline by controlling underlying instance numbers and reduces user cost by choosing appropriate instance types. We have implemented our mechanism in Windows Azure platform, and evaluated it using both simulations and a real scientific cloud application. Results show that our cloud auto-scaling mechanism can meet user specified performance goal with less cost.","Computational modeling,
Monitoring,
Delay,
Scalability,
Computer architecture,
Time factors"
Super resolution using edge prior and single image detail synthesis,"Edge-directed image super resolution (SR) focuses on ways to remove edge artifacts in upsampled images. Under large magnification, however, textured regions become blurred and appear homogenous, resulting in a super-resolution image that looks unnatural. Alternatively, learning-based SR approaches use a large database of exemplar images for “hallucinating” detail. The quality of the upsampled image, especially about edges, is dependent on the suitability of the training images. This paper aims to combine the benefits of edge-directed SR with those of learning-based SR. In particular, we propose an approach to extend edge-directed super-resolution to include detail from an image/texture example provided by the user (e.g., from the Internet). A significant benefit of our approach is that only a single exemplar image is required to supply the missing detail – strong edges are obtained in the SR image even if they are not present in the example image due to the combination of the edge-directed approach. In addition, we can achieve quality results at very large magnification, which is often problematic for both edge-directed and learning-based approaches.",
Nanopositioning System With Force Feedback for High-Performance Tracking and Vibration Control,"In this study, the actuator load force of a nanopositioning stage is utilized as a feedback variable to achieve both tracking and damping. The transfer function from the applied actuator voltage to the measured load force exhibits a zero-pole ordering that greatly simplifies the design and implementation of a tracking and damping controller. Exceptional tracking and damping performance can be achieved with a simple integral controller. Other outstanding characteristics include guaranteed stability and insensitivity to changes in resonance frequency. Experimental results on a high-speed nanopositioner demonstrate an increase in the closed-loop bandwidth from 210 Hz (with an integral controller) to 2.07 kHz (with a force-feedback control). Gain margin is simultaneously improved from 5 dB to infinity.",
Building-Environment Control With Wireless Sensor and Actuator Networks: Centralized Versus Distributed,"This paper considers joint problems of control and communication in wireless sensor and actuator networks (WSANs) for building-environment control systems. In traditional control systems, centralized control (CC) and distributed control (DC) are two major approaches. However, little work has been done in comparing the two approaches in joint problems of control and communication, particularly in WSANs serving as components of control loops. In this paper, we develop a CC scheme in which control decisions are made based on global information and a DC scheme which enables distributed actuators to make control decisions locally. We also develop methods that enable wireless communications among system devices compatible with the control strategies, and propose a method for reducing packet-loss rate. We compare the two schemes using simulations in many aspects. Simulation results show that the DC can achieve a comparable control performance of the CC, while the DC is more robust against packet loss and has lower computational complexity than the CC. Furthermore, the DC has shorter actuation latency than the CC under certain conditions.",
Multi-cue pedestrian classification with partial occlusion handling,"This paper presents a novel mixture-of-experts framework for pedestrian classification with partial occlusion handling. The framework involves a set of component-based expert classifiers trained on features derived from intensity, depth and motion. To handle partial occlusion, we compute expert weights that are related to the degree of visibility of the associated component. This degree of visibility is determined by examining occlusion boundaries, i.e. discontinuities in depth and motion. Occlusion-dependent component weights allow to focus the combined decision of the mixture-of-experts classifier on the unoccluded body parts. In experiments on extensive real-world data sets, with both partially occluded and non-occluded pedestrians, we obtain significant performance boosts over state-of-the-art approaches by up to a factor of four in reduction of false positives at constant detection rates. The dataset is made public for benchmarking purposes.","Focusing,
Image segmentation,
Image motion analysis,
Cameras,
Pattern analysis,
Computer science,
Informatics,
Intelligent systems,
Surveillance,
Intelligent vehicles"
A Digital PLL Scheme for Three-Phase System Using Modified Synchronous Reference Frame,"This paper proposes a novel phase-locked loop (PLL) control strategy to synthesize unit vector using the modified synchronous reference frame (MSRF) instead of the traditional synchronous reference frame. The unit vector is used for vector rotation or inverse rotation in vector-controlled three-phase grid-connected converting equipment. The developed MSRF-PLL is fast in transient response compared to standard PLL technique. The performance is robust against disturbances on the grid, voltage wave with harmonic distortion, and noise. The proposed algorithm has been analyzed in detail and was fully implemented digitally using digital signal processor TMS320F2812. The experimental evaluation of the MSRF-PLL in a shunt active power filter confirms its fast dynamic response, noise immunity, and applicability.","Phase locked loops,
Control system synthesis,
Virtual reality,
Transient response,
Standards development,
Noise robustness,
Voltage,
Harmonic distortion,
Algorithm design and analysis,
Digital signal processing"
Pi: A practical incentive protocol for delay tolerant networks,"Delay Tolerant Networks (DTNs) are a class of networks characterized by lack of guaranteed connectivity, typically low frequency of encounters between DTN nodes and long propagation delays within the network. As a result, the message propagation process in DTNs follows a store-carryand- forward manner, and the in-transit bundle messages can be opportunistically routed towards the destinations through intermittent connections under the hypothesis that each individual DTN node is willing to help with forwarding. Unfortunately, there may exist some selfish nodes, especially in a cooperative network like DTN, and the presence of selfish DTN nodes could cause catastrophic damage to any well designed opportunistic routing scheme and jeopardize the whole network. In this paper, to address the selfishness problem in DTNs, we propose a practical incentive protocol, called Pi, such that when a source node sends a bundle message, it also attaches some incentive on the bundle, which is not only attractive but also fair to all participating DTN nodes. With the fair incentive, the selfish DTN nodes could be stimulated to help with forwarding bundles to achieve better packet delivery performance. In addition, the proposed Pi protocol can also thwart various attacks, which could be launched by selfish DTN nodes, such as free ride attack, layer removing and adding attacks. Extensive simulation results demonstrate the effectiveness of the proposed Pi protocol in terms of high delivery ratio and lower average delay.",
Instabilities in Amorphous Oxide Semiconductor Thin-Film Transistors,"Thin-film transistors (TFTs) fabricated using amorphous oxide semiconductors (AOS) exhibit good electron mobility (5 to >; 50 cm2/V · s), they are transparent, and they can be processed at low temperatures. These new materials show a great promise for high-performance large-area electronics applications such as flexible electronics, transparent electronics, and analog current drivers for organic light-emitting diode displays. Before any of these applications can be commercialized, however, a strong understanding of the stability and reliability of AOS TFTs is needed. The purpose of this paper is to provide a comprehensive review and summary of the recently emerging work on the stability and reliability of AOS TFTs with respect to illumination, bias stress, ambient effects, surface passivation, mechanical stress, and defects, as well as to point out areas for future work. An overview of the TFT operation and expected reliability concerns as well as a brief summary of the instabilities in the well-known Si3N4/a-Si:H system is also included.","Logic gates,
Dielectrics,
Thin film transistors,
Lighting,
Stress control,
Radio frequency"
The Multiscenario Multienvironment BioSecure Multimodal Database (BMDB),"A new multimodal biometric database designed and acquired within the framework of the European BioSecure Network of Excellence is presented. It is comprised of more than 600 individuals acquired simultaneously in three scenarios: 1 over the Internet, 2 in an office environment with desktop PC, and 3 in indoor/outdoor environments with mobile portable hardware. The three scenarios include a common part of audio/video data. Also, signature and fingerprint data have been acquired both with desktop PC and mobile portable hardware. Additionally, hand and iris data were acquired in the second scenario using desktop PC. Acquisition has been conducted by 11 European institutions. Additional features of the BioSecure Multimodal Database (BMDB) are: two acquisition sessions, several sensors in certain modalities, balanced gender and age distributions, multimodal realistic scenarios with simple and quick tasks per modality, cross-European diversity, availability of demographic data, and compatibility with other multimodal databases. The novel acquisition conditions of the BMDB allow us to perform new challenging research and evaluation of either monomodal or multimodal biometric systems, as in the recent BioSecure Multimodal Evaluation campaign. A description of this campaign including baseline results of individual modalities from the new database is also given. The database is expected to be available for research purposes through the BioSecure Association during 2008.","Biometrics,
Hardware,
Spatial databases,
Internet,
Fingerprint recognition,
Iris,
Biosensors,
Sensor phenomena and characterization,
Multimodal sensors,
Availability"
HUBzero: A Platform for Dissemination and Collaboration in Computational Science and Engineering,"The HUBzero cyberinfrastructure lets scientific researchers work together online to develop simulation and modeling tools. Other researchers can then access the resulting tools using an ordinary Web browser and launch simulation runs on the national Grid infrastructure, without having to download or compile any code.","Collaboration,
Containers,
Middleware,
Computational modeling,
Computer networks,
Collaborative tools,
Videos,
Nanotechnology,
Pharmaceuticals,
Heat engines"
"Generalized Degrees of Freedom of the Symmetric Gaussian
K
User Interference Channel","We characterize the generalized degrees of freedom of the K user symmetric Gaussian interference channel where all desired links have the same signal-to-noise ratio (SNR) and all undesired links carrying interference have the same interference-to-noise ratio, INR = SNRα. We find that the number of generalized degrees of freedom per user, d(α), does not depend on the number of users, so that the characterization is identical to the 2 user interference channel with the exception of a singularity at α = 1 where d(1) = 1/K. The achievable schemes use multilevel coding with a nested lattice structure that opens the possibility that the sum of interfering signals can be decoded at a receiver even though the messages carried by the interfering signals are not decodable.",
MARTe: A Multiplatform Real-Time Framework,"Development of real-time applications is usually associated with nonportable code targeted at specific real-time operating systems. The boundary between hardware drivers, system services, and user code is commonly not well defined, making the development in the target host significantly difficult. The Multithreaded Application Real-Time executor (MARTe) is a framework built over a multiplatform library that allows the execution of the same code in different operating systems. The framework provides the high-level interfaces with hardware, external configuration programs, and user interfaces, assuring at the same time hard real-time performances. End-users of the framework are required to define and implement algorithms inside a well-defined block of software, named Generic Application Module (GAM), that is executed by the real-time scheduler. Each GAM is reconfigurable with a set of predefined configuration meta-parameters and interchanges information using a set of data pipes that are provided as inputs and required as output. Using these connections, different GAMs can be chained either in series or parallel. GAMs can be developed and debugged in a non-real-time system and, only once the robustness of the code and correctness of the algorithm are verified, deployed to the real-time system. The software also supplies a large set of utilities that greatly ease the interaction and debugging of a running system. Among the most useful are a highly efficient real-time logger, HTTP introspection of real-time objects, and HTTP remote configuration. MARTe is currently being used to successfully drive the plasma vertical stabilization controller on the largest magnetic confinement fusion device in the world, with a control loop cycle of 50 ?s and a jitter under 1 ?s. In this particular project, MARTe is used with the Real-Time Application Interface (RTAI)/Linux operating system exploiting the new ?86 multicore processors technology.","Real time systems,
Operating systems,
Hardware,
Libraries,
User interfaces,
Software algorithms,
Scheduling algorithm,
Application software,
Robustness,
Software debugging"
Intrinsically Motivated Reinforcement Learning: An Evolutionary Perspective,"There is great interest in building intrinsic motivation into artificial systems using the reinforcement learning framework. Yet, what intrinsic motivation may mean computationally, and how it may differ from extrinsic motivation, remains a murky and controversial subject. In this paper, we adopt an evolutionary perspective and define a new optimal reward framework that captures the pressure to design good primary reward functions that lead to evolutionary success across environments. The results of two computational experiments show that optimal primary reward signals may yield both emergent intrinsic and extrinsic motivation. The evolutionary perspective and the associated optimal reward framework thus lead to the conclusion that there are no hard and fast features distinguishing intrinsic and extrinsic reward computationally. Rather, the directness of the relationship between rewarding behavior and evolutionary success varies along a continuum.","Learning,
Computer science,
Psychology,
Humans,
Cognitive science,
History,
Signal resolution,
Genetic algorithms,
System performance"
Kalman Filtering Over a Packet-Dropping Network: A Probabilistic Perspective,"We consider the problem of state estimation of a discrete time process over a packet-dropping network. Previous work on Kalman filtering with intermittent observations is concerned with the asymptotic behavior of E[Pk], i.e., the expected value of the error covariance, for a given packet arrival rate. We consider a different performance metric, Pr[Pk ¿ M], i.e., the probability that Pk is bounded by a given M. We consider two scenarios in the paper. In the first scenario, when the sensor sends its measurement data to the remote estimator via a packet-dropping network, we derive lower and upper bounds on Pr[Pk ¿ M]. In the second scenario, when the sensor preprocesses the measurement data and sends its local state estimate to the estimator, we show that the previously derived lower and upper bounds are equal to each other, hence we are able to provide a closed form expression for Pr[Pk ¿ M]. We also recover the results in the literature when using Pr[Pk ¿ M] as a metric for scalar systems. Examples are provided to illustrate the theory developed in the paper.","Kalman filters,
Filtering,
State estimation,
Networked control systems,
Control systems,
Upper bound,
Communication system control,
Communication networks,
Stability,
Measurement"
Fast Registration Based on Noisy Planes With Unknown Correspondences for 3-D Mapping,"We present a robot-pose-registration algorithm, which is entirely based on large planar-surface patches extracted from point clouds sampled from a three-dimensional (3-D) sensor. This approach offers an alternative to the traditional point-to-point iterative-closest-point (ICP) algorithm, its point-to-plane variant, as well as newer grid-based algorithms, such as the 3-D normal distribution transform (NDT). The simpler case of known plane correspondences is tackled first by deriving expressions for least-squares pose estimation considering plane-parameter uncertainty computed during plane extraction. Closed-form expressions for covariances are also derived. To round-off the solution, we present a new algorithm, which is called minimally uncertain maximal consensus (MUMC), to determine the unknown plane correspondences by maximizing geometric consistency by minimizing the uncertainty volume in configuration space. Experimental results from three 3-D sensors, viz., Swiss-Ranger, University of South Florida Odetics Laser Detection and Ranging, and an actuated SICK S300, are given. The first two have low fields of view (FOV) and moderate ranges, while the third has a much bigger FOV and range. Experimental results show that this approach is not only more robust than point- or grid-based approaches in plane-rich environments, but it is also faster, requires significantly less memory, and offers a less-cluttered planar-patches-based visualization.","Iterative algorithms,
Uncertainty,
Robot sensing systems,
Clouds,
Iterative closest point algorithm,
Gaussian distribution,
Closed-form solution,
Laser modes,
Robustness,
Visualization"
Nonlinear Regularization for Per Voxel Estimation of Magnetic Susceptibility Distributions From MRI Field Maps,"Magnetic susceptibility is an important physical property of tissues, and can be used as a contrast mechanism in magnetic resonance imaging (MRI). Recently, targeting contrast agents by conjugation with signaling molecules and labeling stem cells with contrast agents have become feasible. These contrast agents are strongly paramagnetic, and the ability to quantify magnetic susceptibility could allow accurate measurement of signaling and cell localization. Presented here is a technique to estimate arbitrary magnetic susceptibility distributions by solving an ill-posed inversion problem from field maps obtained in an MRI scanner. Two regularization strategies are considered: conventional Tikhonov regularization and a sparsity promoting nonlinear regularization using the l 1 norm. Proof of concept is demonstrated using numerical simulations, phantoms, and in a stroke model in a rat. Initial experience indicates that the nonlinear regularization better suppresses noise and streaking artifacts common in susceptibility estimation.","Magnetic susceptibility,
Magnetic resonance imaging,
Magnetic properties,
Mechanical factors,
Labeling,
Stem cells,
Paramagnetic materials,
Magnetic field measurement,
Numerical simulation,
Imaging phantoms"
"Processing Dense Stereo Data Using Elevation Maps: Road Surface, Traffic Isle, and Obstacle Detection","A new approach for the detection of the road surface and obstacles is presented. The high accuracy of the method allows the detection of traffic isles as a distinct class. The 3-D data inferred from dense stereo are transformed into a rectangular digital elevation map (DEM). Two classifiers are proposed, namely, density based and road surface based. The density-based obstacle classifier marks DEM cells as road or obstacles, using the density of 3-D points as a criterion. A quadratic road surface model is initially fitted by a random sample consensus (RANSAC) approach to the region in front of the ego vehicle. A region growing-like process refines this primary solution, driven by the 3-D uncertainty model of the stereo sensor. A robust global solution for the road surface is obtained. The road surface is used for discrimination between road, traffic isle, and obstacle points. Fusion and error filtering is performed on the results of the two classifiers. The proposed real-time algorithm was evaluated in an urban scenario and can be used in complex applications from collision avoidance to path planning.","Robustness,
Filtering,
Path planning,
Image reconstruction,
Surface reconstruction,
Layout,
Road vehicles,
Uncertainty,
Traffic control,
Collision avoidance"
Robust Tensor Analysis With L1-Norm,"Tensor analysis plays an important role in modern image and vision computing problems. Most of the existing tensor analysis approaches are based on the Frobenius norm, which makes them sensitive to outliers. In this paper, we propose L1-norm-based tensor analysis (TPCA-L1), which is robust to outliers. Experimental results upon face and other datasets demonstrate the advantages of the proposed approach.","Robustness,
Tensile stress,
Algorithm design and analysis,
Image analysis,
Computer vision,
Principal component analysis,
Linear discriminant analysis,
Machine learning algorithms,
Machine learning,
Optical sensors"
Elastic Site: Using Clouds to Elastically Extend Site Resources,"Infrastructure-as-a-Service (IaaS) cloud computing offers new possibilities to scientific communities. One of the most significant is the ability to elastically provision and relinquish new resources in response to changes in demand. In our work, we develop a model of an “elastic site” that efficiently adapts services provided within a site, such as batch schedulers, storage archives, or Web services to take advantage of elastically provisioned resources. We describe the system architecture along with the issues involved with elastic provisioning, such as security, privacy, and various logistical considerations. To avoid over- or under-provisioning the resources we propose three different policies to efficiently schedule resource deployment based on demand. We have implemented a resource manager, built on the Nimbus toolkit to dynamically and securely extend existing physical clusters into the cloud. Our elastic site manager interfaces directly with local resource managers, such as Torque. We have developed and evaluated policies for resource provisioning on a Nimbus-based cloud at the University of Chicago, another at Indiana University, and Amazon EC2. We demonstrate a dynamic and responsive elastic cluster, capable of responding effectively to a variety of job submission patterns. We also demonstrate that we can process 10 times faster by expanding our cluster up to 150 EC2 nodes.","Grid computing,
Cloud computing,
Resource management,
Application software,
Computer networks,
USA Councils,
Computer science,
Laboratories,
Communities,
Processor scheduling"
Passive Diagnosis for Wireless Sensor Networks,"Network diagnosis, an essential research topic for traditional networking systems, has not received much attention for wireless sensor networks (WSNs). Existing sensor debugging tools like sympathy or EmStar rely heavily on an add-in protocol that generates and reports a large amount of status information from individual sensor nodes, introducing network overhead to the resource constrained and usually traffic-sensitive sensor network. We report our initial attempt at providing a lightweight network diagnosis mechanism for sensor networks. We further propose PAD, a probabilistic diagnosis approach for inferring the root causes of abnormal phenomena. PAD employs a packet marking scheme for efficiently constructing and dynamically maintaining the inference model. Our approach does not incur additional traffic overhead for collecting desired information. Instead, we introduce a probabilistic inference model that encodes internal dependencies among different network elements for online diagnosis of an operational sensor network system. Such a model is capable of additively reasoning root causes based on passively observed symptoms. We implement the PAD prototype in our sea monitoring sensor network test-bed. We also examine the efficiency and scalability of this design through extensive trace-driven simulations.",
Model-Based Predictive Direct Power Control of Doubly Fed Induction Generators,"This paper presents a predictive direct power control strategy for doubly fed induction generators (DFIGs). The method predicts the DFIG's stator active and reactive power variations within a fixed sampling period, which is used to directly calculate the required rotor voltage to eliminate the power errors at the end of the following sampling period. Space vector modulation is then used to generate the required switching pulses within the fixed sampling period that results in a constant switching frequency. The impact of sampling delay on the accuracy of the sampled active and reactive powers is analyzed, and detailed compensation methods are proposed to improve the power control accuracy and system stability. Experimental results for a 1.5-kW DFIG system demonstrate the effectiveness and robustness of the proposed control strategy during power steps, and variations of rotating speed and machine parameters. System performance for tracking varying stator power references further illustrates the dynamic performance of the proposed method.","Predictive models,
Power control,
Induction generators,
Sampling methods,
Stators,
Pulse modulation,
Reactive power,
Rotors,
Voltage,
Pulse generation"
An extensive comparison of bug prediction approaches,"Reliably predicting software defects is one of software engineering's holy grails. Researchers have devised and implemented a plethora of bug prediction approaches varying in terms of accuracy, complexity and the input data they require. However, the absence of an established benchmark makes it hard, if not impossible, to compare approaches.","Computer bugs,
Entropy,
Software systems,
Predictive models,
Open source software,
Informatics,
Computer science,
Software engineering,
Stability,
Power system modeling"
A Natural Visible and Infrared Facial Expression Database for Expression Recognition and Emotion Inference,"To date, most facial expression analysis has been based on visible and posed expression databases. Visible images, however, are easily affected by illumination variations, while posed expressions differ in appearance and timing from natural ones. In this paper, we propose and establish a natural visible and infrared facial expression database, which contains both spontaneous and posed expressions of more than 100 subjects, recorded simultaneously by a visible and an infrared thermal camera, with illumination provided from three different directions. The posed database includes the apex expressional images with and without glasses. As an elementary assessment of the usability of our spontaneous database for expression recognition and emotion inference, we conduct visible facial expression recognition using four typical methods, including the eigenface approach [principle component analysis (PCA)], the fisherface approach [PCA + linear discriminant analysis (LDA)], the Active Appearance Model (AAM), and the AAM-based + LDA. We also use PCA and PCA+LDA to recognize expressions from infrared thermal images. In addition, we analyze the relationship between facial temperature and emotion through statistical analysis. Our database is available for research purposes.","Emotion recognition,
Face recognition,
Image databases,
Principal component analysis,
Linear discriminant analysis,
Lighting,
Active appearance model,
Timing,
Cameras,
Image sequences"
HermesD: A High-Rate Long-Range Wireless Transmission System for Simultaneous Multichannel Neural Recording Applications,"HermesD is a high-rate, low-power wireless transmission system to aid research in neural prosthetic systems for motor disabilities and basic motor neuroscience. It is the third generation of our ""Hermes systems"" aimed at recording and transmitting neural activity from brain-implanted electrode arrays. This system supports the simultaneous transmission of 32 channels of broadband data sampled at 30 ks/s, 12 b/sample, using frequency-shift keying modulation on a carrier frequency adjustable from 3.7 to 4.1 GHz, with a link range extending over 20 m. The channel rate is 24 Mb/s and the bit stream includes synchronization and error detection mechanisms. The power consumption, approximately 142 mW, is low enough to allow the system to operate continuously for 33 h, using two 3.6-V/1200-mAh Li-SOCl2 batteries. The transmitter was designed using off-the-shelf components and is assembled in a stack of three 28 mm ? 28-mm boards that fit in a 38 mm ? 38 mm ? 51-mm aluminum enclosure, a significant size reduction over the initial version of HermesD. A 7-dBi circularly polarized patch antenna is used as the transmitter antenna, while on the receiver side, a 13-dBi circular horn antenna is employed. The advantages of using circularly polarized waves are analyzed and confirmed by indoor measurements. The receiver is a stand-alone device composed of several submodules and is interfaced to a computer for data acquisition and processing. It is based on the superheterodyne architecture and includes automatic frequency control that keeps it optimally tuned to the transmitter frequency. The HermesD communications performance is shown through bit-error rate measurements and eye-diagram plots. The sensitivity of the receiver is -83 dBm for a bit-error probability of 10-9. Experimental recordings from a rhesus monkey conducting multiple tasks show a signal quality comparable to commercial acquisition systems, both in the low-frequency (local field potentials) and upper-frequency bands (action potentials) of the neural signals. This system can be easily scaled up in terms of the number of channels and data rate to accommodate future generations of Hermes systems.","Transmitters,
Polarization,
Horn antennas,
Receiving antennas,
Transmitting antennas,
Prosthetics,
Neuroscience,
Electrodes,
Frequency shift keying,
Frequency modulation"
An EEG-Based BCI System for 2-D Cursor Control by Combining Mu/Beta Rhythm and P300 Potential,"Two-dimensional cursor control is an important and challenging issue in EEG-based brain-computer interfaces (BCIs). To address this issue, here we propose a new approach by combining two brain signals including Mu/Beta rhythm during motor imagery and P300 potential. In particular, a motor imagery detection mechanism and a P300 potential detection mechanism are devised and integrated such that the user is able to use the two signals to control, respectively, simultaneously, and independently, the horizontal and the vertical movements of the cursor in a specially designed graphic user interface. A real-time BCI system based on this approach is implemented and evaluated through an online experiment involving six subjects performing 2-D control tasks. The results attest to the efficacy of obtaining two independent control signals by the proposed approach. Furthermore, the results show that the system has merit compared with prior systems: it allows cursor movement between arbitrary positions.","Control systems,
Rhythm,
Electroencephalography,
Communication system control,
Automatic control,
Brain computer interfaces,
Multidimensional systems,
Two dimensional displays,
Automation,
Signal design"
Face Matching and Retrieval Using Soft Biometrics,"Soft biometric traits embedded in a face (e.g., gender and facial marks) are ancillary information and are not fully distinctive by themselves in face-recognition tasks. However, this information can be explicitly combined with face matching score to improve the overall face-recognition accuracy. Moreover, in certain application domains, e.g., visual surveillance, where a face image is occluded or is captured in off-frontal pose, soft biometric traits can provide even more valuable information for face matching or retrieval. Facial marks can also be useful to differentiate identical twins whose global facial appearances are very similar. The similarities found from soft biometrics can also be useful as a source of evidence in courts of law because they are more descriptive than the numerical matching scores generated by a traditional face matcher. We propose to utilize demographic information (e.g., gender and ethnicity) and facial marks (e.g., scars, moles, and freckles) for improving face image matching and retrieval performance. An automatic facial mark detection method has been developed that uses (1) the active appearance model for locating primary facial features (e.g., eyes, nose, and mouth), (2) the Laplacian-of-Gaussian blob detection, and (3) morphological operators. Experimental results based on the FERET database (426 images of 213 subjects) and two mugshot databases from the forensic domain (1225 images of 671 subjects and 10 000 images of 10 000 subjects, respectively) show that the use of soft biometric traits is able to improve the face-recognition performance of a state-of-the-art commercial matcher.","Biometrics,
Face detection,
Information retrieval,
Image retrieval,
Image databases,
Spatial databases,
Surveillance,
Demography,
Image matching,
Facial features"
Robust Downlink Beamforming in Multiuser MISO Cognitive Radio Networks With Imperfect Channel-State Information,"This paper studies the problem of robust downlink beamforming design in a multiuser multiple-input-single-output (MISO) cognitive radio network (CR-Net) in which multiple secondary users (SUs) coexist with multiple primary users (PUs) of a single-cell primary radio network (PR-Net). It is assumed that the channel-state information (CSI) for all relevant channels is imperfectly known, and the imperfectness of the CSI is modeled using a Euclidean ball-shaped uncertainty set. Our design objective is to minimize the transmit power of the SU-Transmitter (SU-Tx) while simultaneously achieving a lower bound on the received signal-to-interference-plus-noise ratio (SINR) for the SUs and imposing an upper limit on the interference power (IP) at the PUs. The design parameters at the SU-Tx are the beamforming weights, and the proposed methodology to solve the problem is based on the worst-case design scenario through which the performance metrics of the design are immune to variations in the channels. The original problem is a separable homogeneous quadratically constrained quadratic problem (QCQP), which is an NP-hard problem, even for uncertain CSI. We reformulate our original design problem to a relaxed semidefinite program (SDP) and then investigate three different approaches based on convex programming. Finally, simulation results are provided to validate the robustness of the proposed methods.",
Using Heterogeneous Wireless Sensor Networks in a Telemonitoring System for Healthcare,"Ambient intelligence has acquired great importance in recent years and requires the development of new innovative solutions. This paper presents a distributed telemonitoring system, aimed at improving healthcare and assistance to dependent people at their homes. The system implements a service-oriented architecture based platform, which allows heterogeneous wireless sensor networks to communicate in a distributed way independent of time and location restrictions. This approach provides the system with a higher ability to recover from errors and a better flexibility to change their behavior at execution time. Preliminary results are presented in this paper.","Wireless sensor networks,
Medical services,
Ambient intelligence,
Intelligent sensors,
Service oriented architecture,
Intelligent networks,
Senior citizens,
Intelligent systems,
Educational technology,
Laboratories"
Decentralized charging control for large populations of plug-in electric vehicles,"The paper develops a novel decentralized charging control strategy for large populations of plug-in electric vehicles (PEVs). We consider the situation where PEV agents are rational and weakly coupled via their operation costs. At an established Nash equilibrium, each of the PEV agents reacts optimally with respect to the average charging strategy of all the PEV agents. Each of the average charging strategies can be approximated by an infinite population limit which is the solution of a fixed point problem. The control objective is to minimize electricity generation costs by establishing a PEV charging schedule that fills the overnight demand valley. The paper shows that under certain mild conditions, there exists a unique Nash equilibrium that almost satisfies that goal. Moreover, the paper establishes a sufficient condition under which the system converges to the unique Nash equilibrium. The theoretical results are illustrated through various numerical examples.",
Data fusion through cross-modality metric learning using similarity-sensitive hashing,"Visual understanding is often based on measuring similarity between observations. Learning similarities specific to a certain perception task from a set of examples has been shown advantageous in various computer vision and pattern recognition problems. In many important applications, the data that one needs to compare come from different representations or modalities, and the similarity between such data operates on objects that may have different and often incommensurable structure and dimensionality. In this paper, we propose a framework for supervised similarity learning based on embedding the input data from two arbitrary spaces into the Hamming space. The mapping is expressed as a binary classification problem with positive and negative examples, and can be efficiently learned using boosting algorithms. The utility and efficiency of such a generic approach is demonstrated on several challenging applications including cross-representation shape retrieval and alignment of multi-modal medical images.","Image retrieval,
Shape,
Biomedical imaging,
Content based retrieval,
Computer vision,
Vocabulary,
Pattern recognition,
Application software,
Boosting,
Support vector machines"
Human Tracking Using Convolutional Neural Networks,"In this paper, we treat tracking as a learning problem of estimating the location and the scale of an object given its previous location, scale, as well as current and previous image frames. Given a set of examples, we train convolutional neural networks (CNNs) to perform the above estimation task. Different from other learning methods, the CNNs learn both spatial and temporal features jointly from image pairs of two adjacent frames. We introduce multiple path ways in CNN to better fuse local and global information. A creative shift-variant CNN architecture is designed so as to alleviate the drift problem when the distracting objects are similar to the target in cluttered environment. Furthermore, we employ CNNs to estimate the scale through the accurate localization of some key points. These techniques are object-independent so that the proposed method can be applied to track other types of object. The capability of the tracker of handling complex situations is demonstrated in many testing sequences.",
Normally Off GaN MOSFET Based on AlGaN/GaN Heterostructure With Extremely High 2DEG Density Grown on Silicon Substrate,"A normally off GaN MOSFET was proposed by utilizing an extremely high 2-D electron-gas density (> 1014 / cm2) at an AlGaN/GaN heterostructure as source and drain, which can be obtained by controlling the tensile stress accompanied with the growth of GaN on silicon substrate. The fabricated MOSFET with an Al2O3 gate insulator exhibited excellent device performance, such as a threshold voltage of 2 V, drain current of 353 mA/mm, extrinsic transconductance of 98 mS/mm, and field-effect mobility of 225 cm2/V·s.","Gallium nitride,
MOSFET circuits,
Aluminum gallium nitride,
Silicon,
Stress control,
Threshold voltage,
Transconductance,
Electrons,
Switching circuits,
Tensile stress"
"Generalized Assorted Pixel Camera: Postcapture Control of Resolution, Dynamic Range, and Spectrum","We propose the concept of a generalized assorted pixel (GAP) camera, which enables the user to capture a single image of a scene and, after the fact, control the tradeoff between spatial resolution, dynamic range and spectral detail. The GAP camera uses a complex array (or mosaic) of color filters. A major problem with using such an array is that the captured image is severely under-sampled for at least some of the filter types. This leads to reconstructed images with strong aliasing. We make four contributions in this paper: 1) we present a comprehensive optimization method to arrive at the spatial and spectral layout of the color filter array of a GAP camera. 2) We develop a novel algorithm for reconstructing the under-sampled channels of the image while minimizing aliasing artifacts. 3) We demonstrate how the user can capture a single image and then control the tradeoff of spatial resolution to generate a variety of images, including monochrome, high dynamic range (HDR) monochrome, RGB, HDR RGB, and multispectral images. 4) Finally, the performance of our GAP camera has been verified using extensive simulations that use multispectral images of real world scenes. A large database of these multispectral images has been made available at http://wwwl.cs.columbia.edu/ CAVE/projects/gap_camera/ for use by the research community.",
Theoretical and Empirical Results for Recovery From Multiple Measurements,"The joint-sparse recovery problem aims to recover, from sets of compressed measurements, unknown sparse matrices with nonzero entries restricted to a subset of rows. This is an extension of the single-measurement-vector (SMV) problem widely studied in compressed sensing. We study the recovery properties of two algorithms for problems with noiseless data and exact-sparse representation. First, we show that recovery using sum-of-norm minimization cannot exceed the uniform-recovery rate of sequential SMV using l 1 minimization, and that there are problems that can be solved with one approach, but not the other. Second, we study the performance of the ReMBo algorithm (M. Mishali and Y. Eldar, ¿Reduce and boost: Recovering arbitrary sets of jointly sparse vectors,¿ IEEE Trans. Signal Process., vol. 56, no. 10, 4692-4702, Oct. 2008) in combination with l 1 minimization, and show how recovery improves as more measurements are taken. From this analysis, it follows that having more measurements than the number of linearly independent nonzero rows does not improve the potential theoretical recovery rate.","Signal processing algorithms,
Sparse matrices,
Signal processing,
Compressed sensing,
Councils,
Computer science"
A new hybrid PSOGSA algorithm for function optimization,"In this paper, a new hybrid population-based algorithm (PSOGSA) is proposed with the combination of Particle Swarm Optimization (PSO) and Gravitational Search Algorithm (GSA). The main idea is to integrate the ability of exploitation in PSO with the ability of exploration in GSA to synthesize both algorithms' strength. Some benchmark test functions are used to compare the hybrid algorithm with both the standard PSO and GSA algorithms in evolving best solution. The results show the hybrid algorithm possesses a better capability to escape from local optimums with faster convergence than the standard PSO and GSA.",
A Permanent-Magnet Tubular Linear Generator for Ocean Wave Energy Conversion,"This paper presents a novel permanent-magnet tubular linear generator (PMTLG) buoy system designed to convert the linear motion of ocean waves into electrical energy. The design incorporates no working seals and a saltwater air-gap bearing surface integration between the PMTLG buoy components. The internal generator design will be discussed, in addition to the system integration with the buoy structure. The simulation and hardware results of the generator are presented.",
Self-Calibrating View-Invariant Gait Biometrics,"We present a new method for viewpoint independent gait biometrics. The system relies on a single camera, does not require camera calibration, and works with a wide range of camera views. This is achieved by a formulation where the gait is self-calibrating. These properties make the proposed method particularly suitable for identification by gait, where the advantages of completely unobtrusiveness, remoteness, and covertness of the biometric system preclude the availability of camera information and specific walking directions. The approach has been assessed for feature extraction and recognition capabilities on the SOTON gait database and then evaluated on a multiview database to establish recognition capability with respect to view invariance. Moreover, tests on the multiview CASIA-B database, composed of more than 2270 video sequences with 65 different subjects walking freely along different walking directions, have been performed. The obtained results show that human identification by gait can be achieved without any knowledge of internal or external camera parameters with a mean correct classification rate of 73.6% across all views using purely dynamic gait features. The performance of the proposed method is particularly encouraging for application in surveillance scenarios.","Biometrics,
Cameras,
Legged locomotion,
Spatial databases,
Calibration,
Feature extraction,
Testing,
Video sequences,
Performance evaluation,
Humans"
Optimal Experimental Design for Diffusion Kurtosis Imaging,"Diffusion kurtosis imaging (DKI) is a new magnetic resonance imaging (MRI) model that describes the non-Gaussian diffusion behavior in tissues. It has recently been shown that DKI parameters, such as the radial or axial kurtosis, are more sensitive to brain physiology changes than the well-known diffusion tensor imaging (DTI) parameters in several white and gray matter structures. In order to estimate either DTI or DKI parameters with maximum precision, the diffusion weighting gradient settings that are applied during the acquisition need to be optimized. Indeed, it has been shown previously that optimizing the set of diffusion weighting gradient settings can have a significant effect on the precision with which DTI parameters can be estimated. In this paper, we focus on the optimization of DKI gradients settings. Commonly, DKI data are acquired using a standard set of diffusion weighting gradients with fixed directions and with regularly spaced gradient strengths. In this paper, we show that such gradient settings are suboptimal with respect to the precision with which DKI parameters can be estimated. Furthermore, the gradient directions and the strengths of the diffusion-weighted MR images are optimized by minimizing the Crame¿r-Rao lower bound of DKI parameters. The impact of the optimized gradient settings is evaluated, both on simulated as well as experimentally recorded datasets. It is shown that the precision with which the kurtosis parameters can be estimated, increases substantially by optimizing the gradient settings.","Design for experiments,
Magnetic resonance imaging,
Diffusion tensor imaging,
Parameter estimation,
Physiology,
Design optimization,
Magnetic properties,
Technological innovation,
Control systems,
Hospitals"
Continuous-Wave Operation of a Frequency-Tunable 460-GHz Second-Harmonic Gyrotron for Enhanced Nuclear Magnetic Resonance,"The design, operation, and characterization of a continuous-wave (CW) tunable second-harmonic 460-GHz gyrotron are reported. The gyrotron is intended to be used as a submillimeter-wave source for 700-MHz nuclear magnetic resonance experiments with sensitivity enhanced by dynamic nuclear polarization. The gyrotron operates in the whispering-gallery mode TE11, 2 and has generated 16 W of output power with a 13-kV 100-mA electron beam. The start oscillation current measured over a range of magnetic field values is in good agreement with theoretical start currents obtained from linear theory for successive high-order axial modes TE11, 2,q. The minimum start current is 27 mA. Power and frequency tuning measurements as a function of the electron cyclotron frequency have also been carried out. A smooth frequency tuning range of 1 GHz was obtained for the operating second-harmonic mode either by magnetic field tuning or beam voltage tuning. Long-term CW operation was evaluated during an uninterrupted period of 48 h, where the gyrotron output power and frequency were kept stable to within ±0.7% and ± 6 ppm, respectively, by a computerized control system. Proper operation of an internal quasi-optical mode converter implemented to transform the operating whispering-gallery mode to a Gaussian-like beam was also verified. Based on the images of the gyrotron output beam taken with a pyroelectric camera, the Gaussian-like mode content of the output beam was computed to be 92% with an ellipticity of 12%.",
General Retinal Vessel Segmentation Using Regularization-Based Multiconcavity Modeling,"Detecting blood vessels in retinal images with the presence of bright and dark lesions is a challenging unsolved problem. In this paper, a novel multiconcavity modeling approach is proposed to handle both healthy and unhealthy retinas simultaneously. The differentiable concavity measure is proposed to handle bright lesions in a perceptive space. The line-shape concavity measure is proposed to remove dark lesions which have an intensity structure different from the line-shaped vessels in a retina. The locally normalized concavity measure is designed to deal with unevenly distributed noise due to the spherical intensity variation in a retinal image. These concavity measures are combined together according to their statistical distributions to detect vessels in general retinal images. Very encouraging experimental results demonstrate that the proposed method consistently yields the best performance over existing state-of-the-art methods on the abnormal retinas and its accuracy outperforms the human observer, which has not been achieved by any of the state-of-the-art benchmark methods. Most importantly, unlike existing methods, the proposed method shows very attractive performances not only on healthy retinas but also on a mixture of healthy and pathological retinas.","Retinal vessels,
Retina,
Lesions,
Image segmentation,
Blood vessels,
Biomedical imaging,
Extraterrestrial measurements,
Noise measurement,
Statistical distributions,
Humans"
Geometric Distortion Insensitive Image Watermarking in Affine Covariant Regions,"Feature-based image watermarking schemes, which aim to survive various geometric distortions, have attracted great attention in recent years. Existing schemes have shown robustness against rotation, scaling, and translation, but few are resistant to cropping, nonisotropic scaling, random bending attacks (RBAs), and affine transformations. Seo and Yoo present a geometrically invariant image watermarking based on affine covariant regions (ACRs) that provide a certain degree of robustness. To further enhance the robustness, we propose a new image watermarking scheme on the basis of Seo's work, which is insensitive to geometric distortions as well as common image processing operations. Our scheme is mainly composed of three components: 1) feature selection procedure based on graph theoretical clustering algorithm is applied to obtain a set of stable and nonoverlapped ACRs; 2) for each chosen ACR, local normalization, and orientation alignment are performed to generate a geometrically invariant region, which can obviously improve the robustness of the proposed watermarking scheme; and 3) in order to prevent the degradation in image quality caused by the normalization and inverse normalization, indirect inverse normalization is adopted to achieve a good compromise between the imperceptibility and robustness. Experiments are carried out on an image set of 100 images collected from Internet, and the preliminary results demonstrate that the developed method improves the performance over some representative image watermarking approaches in terms of robustness.","Watermarking,
Robustness,
Image processing,
Videos,
Optical distortion,
Optical filters,
Clustering algorithms,
Degradation,
Image quality,
Internet"
Non-uniform deblurring for shaken images,"Blur from camera shake is mostly due to the 3D rotation of the camera, resulting in a blur kernel that can be significantly non-uniform across the image. However, most current deblurring methods model the observed image as a convolution of a sharp image with a uniform blur kernel. We propose a new parametrized geometric model of the blurring process in terms of the rotational velocity of the camera during exposure. We apply this model to two different algorithms for camera shake removal: the first one uses a single blurry image (blind deblurring), while the second one uses both a blurry image and a sharp but noisy image of the same scene. We show that our approach makes it possible to model and remove a wider class of blurs than previous approaches, including uniform blur as a special case, and demonstrate its effectiveness with experiments on real images.",
Constrained Relay Node Placement in Wireless Sensor Networks: Formulation and Approximations,"One approach to prolong the lifetime of a wireless sensor network (WSN) is to deploy some relay nodes to communicate with the sensor nodes, other relay nodes, and the base stations. The relay node placement problem for wireless sensor networks is concerned with placing a minimum number of relay nodes into a wireless sensor network to meet certain connectivity or survivability requirements. Previous studies have concentrated on the unconstrained version of the problem in the sense that relay nodes can be placed anywhere. In practice, there may be some physical constraints on the placement of relay nodes. To address this issue, we study constrained versions of the relay node placement problem, where relay nodes can only be placed at a set of candidate locations. In the connected relay node placement problem, we want to place a minimum number of relay nodes to ensure that each sensor node is connected with a base station through a bidirectional path. In the survivable relay node placement problem, we want to place a minimum number of relay nodes to ensure that each sensor node is connected with two base stations (or the only base station in case there is only one base station) through two node-disjoint bidirectional paths. For each of the two problems, we discuss its computational complexity and present a framework of polynomial time O(1) -approximation algorithms with small approximation ratios. Extensive numerical results show that our approximation algorithms can produce solutions very close to optimal solutions.",
Comparison of AdaBoost and Support Vector Machines for Detecting Alzheimer's Disease Through Automated Hippocampal Segmentation,"We compared four automated methods for hippocampal segmentation using different machine learning algorithms: 1) hierarchical AdaBoost, 2) support vector machines (SVM) with manual feature selection, 3) hierarchical SVM with automated feature selection (Ada-SVM), and 4) a publicly available brain segmentation package (FreeSurfer). We trained our approaches using T1-weighted brain MRIs from 30 subjects [10 normal elderly, 10 mild cognitive impairment (MCI), and 10 Alzheimer's disease (AD)], and tested on an independent set of 40 subjects (20 normal, 20 AD). Manually segmented gold standard hippocampal tracings were available for all subjects (training and testing). We assessed each approach's accuracy relative to manual segmentations, and its power to map AD effects. We then converted the segmentations into parametric surfaces to map disease effects on anatomy. After surface reconstruction, we computed significance maps, and overall corrected p-values, for the 3-D profile of shape differences between AD and normal subjects. Our AdaBoost and Ada-SVM segmentations compared favorably with the manual segmentations and detected disease effects as well as FreeSurfer on the data tested. Cumulative p-value plots, in conjunction with the false discovery rate method, were used to examine the power of each method to detect correlations with diagnosis and cognitive scores. We also evaluated how segmentation accuracy depended on the size of the training set, providing practical information for future users of this technique.",
An Efficient 10GBASE-T Ethernet LDPC Decoder Design With Low Error Floors,"A grouped-parallel low-density parity-check (LDPC) decoder is designed for the (2048,1723) Reed-Solomon-based LDPC (RS-LDPC) suitable for 10GBASE-T Ethernet. A two-step decoding scheme reduces the wordlength to 4 bits while lowering the error floor to below 10-14 BER. The proposed post-processor is conveniently integrated with the decoder, adding minimal area and power. The decoder architecture is optimized by groupings so as to localize irregular interconnects and regularize global interconnects and the overall wiring overhead is minimized. The 5.35 mm2, 65 nm CMOS chip achieves a decoding throughput of 47.7 Gb/s. With scaled frequency and voltage, the chip delivers a 6.67 Gb/s throughput necessary for 10GBASE-T while dissipating 144 mW of power.","Ethernet networks,
Parity check codes,
Iterative decoding,
Integrated circuit interconnections,
Wiring,
Digital video broadcasting,
Routing,
Throughput,
WiMAX,
Silicon"
Increasing PCM main memory lifetime,"The introduction of Phase-Change Memory (PCM) as a main memory technology has great potential to achieve a large energy reduction. PCM has desirable energy and scalability properties, but its use for main memory also poses challenges such as limited write endurance with at most 107 writes per bit cell before failure. This paper describes techniques to enhance the lifetime of PCM when used for main memory. Our techniques are (a) writeback minimization with new cache replacement policies, (b) avoidance of unnecessary writes, which write only the bit cells that are actually changed, and (c) endurance management with a novel PCM-aware swap algorithm for wear-leveling. A failure detection algorithm is also incorporated to improve the reliability of PCM. With these approaches, the lifetime of a PCM main memory is increased from just a few days to over 8 years.","Phase change materials,
Random access memory,
Phase change memory,
Energy consumption,
Computer science,
Scalability,
Minimization methods,
Detection algorithms,
Degradation,
Costs"
Random Subspace Ensembles for fMRI Classification,"Classification of brain images obtained through functional magnetic resonance imaging (fMRI) poses a serious challenge to pattern recognition and machine learning due to the extremely large feature-to-instance ratio. This calls for revision and adaptation of the current state-of-the-art classification methods. We investigate the suitability of the random subspace (RS) ensemble method for fMRI classification. RS samples from the original feature set and builds one (base) classifier on each subset. The ensemble assigns a class label by either majority voting or averaging of output probabilities. Looking for guidelines for setting the two parameters of the method-ensemble size and feature sample size-we introduce three criteria calculated through these parameters: usability of the selected feature sets, coverage of the set of ¿important¿ features, and feature set diversity. Optimized together, these criteria work toward producing accurate and diverse individual classifiers. RS was tested on three fMRI datasets from single-subject experiments: the Haxby data (Haxby, 2001.) and two datasets collected in-house. We found that RS with support vector machines (SVM) as the base classifier outperformed single classifiers as well as some of the most widely used classifier ensembles such as bagging, AdaBoost, random forest, and rotation forest. The closest rivals were the single SVM and bagging of SVM classifiers. We use kappa-error diagrams to understand the success of RS.",
Efficient additive kernels via explicit feature maps,"Maji and Berg [13] have recently introduced an explicit feature map approximating the intersection kernel. This enables efficient learning methods for linear kernels to be applied to the non-linear intersection kernel, expanding the applicability of this model to much larger problems. In this paper we generalize this idea, and analyse a large family of additive kernels, called homogeneous, in a unified framework. The family includes the intersection, Hellinger's, and χ2 kernels commonly employed in computer vision. Using the framework we are able to: (i) provide explicit feature maps for all homogeneous additive kernels along with closed form expression for all common kernels; (ii) derive corresponding approximate finite-dimensional feature maps based on the Fourier sampling theorem; and (iii) quantify the extent of the approximation. We demonstrate that the approximations have indistinguishable performance from the full kernel on a number of standard datasets, yet greatly reduce the train/test times of SVM implementations. We show that the χ2 kernel, which has been found to yield the best performance in most applications, also has the most compact feature representation. Given these train/test advantages we are able to obtain a significant performance improvement over current state of the art results based on the intersection kernel.","Kernel,
Testing,
Support vector machines,
Learning systems,
Computer vision,
Probability distribution,
Histograms,
Sampling methods,
Large-scale systems,
Machine learning"
Population-Based Algorithm Portfolios for Numerical Optimization,"In this paper, we consider the scenario that a population-based algorithm is applied to a numerical optimization problem and a solution needs to be presented within a given time budget. Although a wide range of population-based algorithms, such as evolutionary algorithms, particle swarm optimizers, and differential evolution, have been developed and studied under this scenario, the performance of an algorithm may vary significantly from problem to problem. This implies that there is an inherent risk associated with the selection of algorithms. We propose that, instead of choosing an existing algorithm and investing the entire time budget in it, it would be less risky to distribute the time among multiple different algorithms. A new approach named population-based algorithm portfolio (PAP), which takes multiple algorithms as its constituent algorithms, is proposed based upon this idea. PAP runs each constituent algorithm with a part of the given time budget and encourages interaction among the constituent algorithms with a migration scheme. As a general framework rather than a specific algorithm, PAP is easy to implement and can accommodate any existing population-based search algorithms. In addition, a metric is also proposed to compare the risks of any two algorithms on a problem set. We have comprehensively evaluated PAP via investigating 11 instantiations of it on 27 benchmark functions. Empirical results have shown that PAP outperforms its constituent algorithms in terms of solution quality, risk, and probability of finding the global optimum. Further analyses have revealed that the advantages of PAP are mostly credited to the synergy between constituent algorithms, which should complement each other either over a set of problems, or during different stages of an optimization process.",
Short-term breakdown and long-term failure in nanodielectrics: a review,"Nanodielectrics, which are concentrated in polymer matrix incorporating nanofillers, have received considerable attention due to their potential benefits as dielectrics. In this paper, short-term breakdown and long-term failure properties of nanodielectrics have been reviewed. The characteristics of polymer matrix, types of nanoparticle and its content, and waveforms of the applied voltage are fully evaluated. In order to effectively comment on the published experimental data, a ratio k has been proposed to compare the electric properties of the nanodielectrics with the matrix and assess the effect for nanoparticles doping. There is evidence that the short-term breakdown properties of nanodielectrics show a strong dependence on the applied voltage waveforms. The polarity and the cohesive energy density (CED) of polymer matrix have a dramatic influence on the properties of nanodielectrics. Nanoparticle doped composites show a positive effect on the long-term failure properties, such as ageing resistance and partial discharge (PD) properties of nanocomposites are superior than microcomposites and the matrix. The larger the dielectric constant and CED of the matrix become, the more significant improvements in long-term performance appear. Based on the reported experimental results, we also present our understandings and propose some suggestions for further work.",
3D Forward and Back-Projection for X-Ray CT Using Separable Footprints,"Iterative methods for 3D image reconstruction have the potential to improve image quality over conventional filtered back projection (FBP) in X-ray computed tomography (CT). However, the computation burden of 3D cone-beam forward and back-projectors is one of the greatest challenges facing practical adoption of iterative methods for X-ray CT. Moreover, projector accuracy is also important for iterative methods. This paper describes two new separable footprint (SF) projector methods that approximate the voxel footprint functions as 2D separable functions. Because of the separability of these footprint functions, calculating their integrals over a detector cell is greatly simplified and can be implemented efficiently. The SF-TR projector uses trapezoid functions in the transaxial direction and rectangular functions in the axial direction, whereas the SF-TT projector uses trapezoid functions in both directions. Simulations and experiments showed that both SF projector methods are more accurate than the distance-driven (DD) projector, which is a current state-of-the-art method in the field. The SF-TT projector is more accurate than the SF-TR projector for rays associated with large cone angles. The SF-TR projector has similar computation speed with the DD projector and the SF-TT projector is about two times slower.",
Anti-jamming broadcast communication using uncoordinated spread spectrum techniques,"Jamming-resistant communication is crucial for safety-critical applications such as emergency alert broadcasts or the dissemination of navigation signals in adversarial settings. In such applications, mission-critical messages are broadcast to a large and unknown number of (potentially untrusted) receivers that rely on the availability, integrity, and authenticity of the messages; here, availability primarily refers to the ability to communicate in the presence of jamming. Common techniques to counter jamming-based denial-of-service attacks such as Frequency Hopping (FH) and Direct Sequence Spread Spectrum (DSSS) cannot be applied in such settings because they depend on secret pairwise or group keys shared between the sender and the receivers before the communication. This dependency entails serious or unsolvable scalability and keysetup problems or weak jamming-resistance (a single malicious receiver can compromise the whole system). As a solution, in this work, we propose uncoordinated spread spectrum techniques that enable anti-jamming broadcast communication without shared secrets. Uncoordinated spread spectrum techniques can handle an unlimited amount of (malicious) receivers. We present two instances (Uncoordinated FH and Uncoordinated DSSS) and analyze differences in their performance as well as their combination. We further discuss the applications of these techniques to anti-jamming navigation broadcast, bootstrapping of coordinated spread spectrum communication, and anti-jamming emergency alerts.","Broadcasting,
Spread spectrum communication,
Navigation,
Jamming,
Random sequences,
Frequency,
Scalability,
Communication system security,
Base stations,
Mission critical systems"
On-Chip Clocking for Nanomagnet Logic Devices,"We report local control of nanomagnets that can be arranged to perform computation in a cellular automata-like architecture. This letter represents the first demonstration of deterministically placed quantum-dot cellular automata (QCA) devices (of any implementation), where devices are controlled by on-chip local fields.",
Cloth grasp point detection based on multiple-view geometric cues with application to robotic towel folding,"We present a novel vision-based grasp point detection algorithm that can reliably detect the corners of a piece of cloth, using only geometric cues that are robust to variation in texture. Furthermore, we demonstrate the effectiveness of our algorithm in the context of folding a towel using a general-purpose two-armed mobile robotic platform without the use of specialized end-effectors or tools. The robot begins by picking up a randomly dropped towel from a table, goes through a sequence of vision-based re-grasps and manipulations—partially in the air, partially on the table—and finally stacks the folded towel in a target location. The reliability and robustness of our algorithm enables for the first time a robot with general purpose manipulators to reliably and fully-autonomously fold previously unseen towels, demonstrating success on all 50 out of 50 single-towel trials as well as on a pile of 5 towels.","Robotics and automation,
Robot vision systems,
Clothing,
Collaborative work,
Robustness,
Manipulators,
Machine learning algorithms,
USA Councils,
Detection algorithms,
Mobile robots"
Piecewise planar and non-planar stereo for urban scene reconstruction,"Piecewise planar models for stereo have recently become popular for modeling indoor and urban outdoor scenes. The strong planarity assumption overcomes the challenges presented by poorly textured surfaces, and results in low complexity 3D models for rendering, storage, and transmission. However, such a model performs poorly in the presence of non-planar objects, for example, bushes, trees, and other clutter present in many scenes. We present a stereo method capable of handling more general scenes containing both planar and non-planar regions. Our proposed technique segments an image into piecewise planar regions as well as regions labeled as non-planar. The non-planar regions are modeled by the results of a standard multi-view stereo algorithm. The segmentation is driven by multi-view photoconsistency as well as the result of a color-and texture-based classifier, learned from hand-labeled planar and non-planar image regions. Additionally our method links and fuses plane hypotheses across multiple overlapping views, ensuring a consistent 3D reconstruction over an arbitrary number of images. Using our system, we have reconstructed thousands of frames of street-level video. Results show our method successfully recovers piecewise planar surfaces alongside general 3D surfaces in challenging scenes containing large buildings as well as residential houses.","Layout,
Image reconstruction,
Semiconductor device modeling,
Image segmentation,
Stereo vision,
Surface reconstruction,
Surface texture,
Surface fitting,
Stereo image processing,
Rendering (computer graphics)"
Soft Biometric Traits for Continuous User Authentication,"Most existing computer and network systems authenticate a user only at the initial login session. This could be a critical security weakness, especially for high-security systems because it enables an impostor to access the system resources until the initial user logs out. This situation is encountered when the logged in user takes a short break without logging out or an impostor coerces the valid user to allow access to the system. To address this security flaw, we propose a continuous authentication scheme that continuously monitors and authenticates the logged in user. Previous methods for continuous authentication primarily used hard biometric traits, specifically fingerprint and face to continuously authenticate the initial logged in user. However, the use of these biometric traits is not only inconvenient to the user, but is also not always feasible due to the user's posture in front of the sensor. To mitigate this problem, we propose a new framework for continuous user authentication that primarily uses soft biometric traits (e.g., color of user's clothing and facial skin). The proposed framework automatically registers (enrolls) soft biometric traits every time the user logs in and fuses soft biometric matching with the conventional authentication schemes, namely password and face biometric. The proposed scheme has high tolerance to the user's posture in front of the computer system. Experimental results show the effectiveness of the proposed method for continuous user authentication.","Authentication,
Biometrics,
Histograms,
Image color analysis,
Face recognition"
"Computing With Words Is an Implementable Paradigm: Fuzzy Queries, Linguistic Data Summaries, and Natural-Language Generation","We point out some relevant issues that are related to the computing-with-words (CWW) paradigm and argue for an urgent need for a new, nontraditional look at the area, since the traditional approach has resulted in very valuable theoretical research results. However, there is no proper exposure and recognition in other areas to which CWW belongs and can really contribute, notably natural-language processing (NLP), in general, and natural-language understanding (NLU) and natural-language generation (NLG), in particular. First, we present crucial elements of CWW, in particular Zadeh's protoforms, and indicate their power and stress a need to develop new tools to handle more modalities. We argue that CWW also has a high implementation potential and present our approach to linguistic data(base) summaries, which is a very intuitive and human-consistent natural-language-based knowledge-discovery tool. Special emphasis is on the use of Zadeh's protoform (prototypical form) as a general form of a linguistic data summary. We present an extension of our interactive approach, which is based on fuzzy logic and fuzzy database queries, to implement such linguistic summaries. In the main part of the paper, we discuss a close relation between linguistic summarization in the sense considered and some basic ideas and solutions in NLG, thus analyzing possible common elements and an opportunity to use developed tools, as well as some inherent differences and difficulties. Notably, we indicate a close relation of linguistic summaries that are considered to be some type of an extended template-based, and even a simple phrase-based, NLG system and emphasize a possibility to use software that is available in these areas. An important conclusion is also an urgent need to develop new protoforms, thus going beyond the classical ones of Zadeh. For illustration, we present an implementation for a sales database in a computer retailer, thereby showing the power of linguistic summaries, as well as an urgent need for new types of protoforms. Although we use linguistic summaries throughout, our discussion is also valid for CWW in general. We hope that this paper-which presents our personal view and perspective that result from our long-time involvement in both theoretical work in broadly perceived CWW and real-world implementations-will trigger a discussion and research efforts to help find a way out of a strange situation in which, on one hand, one can clearly see that CWW is related to words (language) and computing and, hence, should be part of broadly perceived mainstream computational linguistics, which lack tools to handle imprecision. These tools can be provided by CWW. Yet, CWW is practically unknown to these communities and is not mentioned or cited, and---reciprocally---even the top people in CWW do not refer to the results that are obtained in these areas. We hope that our paper, for the benefit of both the areas, will help bridge this gap that results from a wrong and dangerous fragmentation of break science.",
Multiscale AM-FM Methods for Diabetic Retinopathy Lesion Detection,"In this paper, we propose the use of multiscale amplitude-modulation-frequency-modulation (AM-FM) methods for discriminating between normal and pathological retinal images. The method presented in this paper is tested using standard images from the early treatment diabetic retinopathy study. We use 120 regions of 40 × 40 pixels containing four types of lesions commonly associated with diabetic retinopathy (DR) and two types of normal retinal regions that were manually selected by a trained analyst. The region types included microaneurysms, exudates, neovascularization on the retina, hemorrhages, normal retinal background, and normal vessels patterns. The cumulative distribution functions of the instantaneous amplitude, the instantaneous frequency magnitude, and the relative instantaneous frequency angle from multiple scales are used as texture feature vectors. We use distance metrics between the extracted feature vectors to measure interstructure similarity. Our results demonstrate a statistical differentiation of normal retinal structures and pathological lesions based on AM-FM features. We further demonstrate our AM-FM methodology by applying it to classification of retinal images from the MESSIDOR database. Overall, the proposed methodology shows significant capability for use in automatic DR screening.","Diabetes,
Retinopathy,
Lesions,
Retina,
Pathology,
Frequency,
Testing,
Hemorrhaging,
Distribution functions,
Feature extraction"
A simple optimal power flow model with energy storage,"The integration of renewable energy generation, such as wind power, into the electric grid is difficult because of the source intermittency and the large distance between generation sites and users. This difficulty can be overcome through a transmission network with large-scale storage that not only transports power, but also mitigates against fluctuations in generation and supply. We formulate an optimal power flow problem with storage as a finite-horizon optimal control problem. We prove, for the special case with a single generator and a single load, that the optimal generation schedule will cross the time-varying demand profile at most once, from above. This means that the optimal policy will generate more than demand initially in order to charge up the battery, and then generate less than the demand and use the battery to supplement generation in final stages. This is a consequence of the fact that the marginal storage cost-to-go decreases in time.","Batteries,
Schedules,
Discharges,
Generators,
Optimization,
Energy states,
Renewable energy resources"
Personal Navigation via High-Resolution Gait-Corrected Inertial Measurement Units,"In this paper, a personal micronavigation system that uses high-resolution gait-corrected inertial measurement units is presented. The goal of this paper is to develop a navigation system that uses secondary inertial variables, such as velocity, to enable long-term precise navigation in the absence of Global Positioning System (GPS) and beacon signals. In this scheme, measured zero-velocity duration from the ground reaction sensors is used to reset the accumulated integration errors from accelerometers and gyroscopes in position calculation. With the described system, an average position error of 4 m is achieved at the end of half-hour walks.",
Clustering Algorithms in Biomedical Research: A Review,"Applications of clustering algorithms in biomedical research are ubiquitous, with typical examples including gene expression data analysis, genomic sequence analysis, biomedical document mining, and MRI image analysis. However, due to the diversity of cluster analysis, the differing terminologies, goals, and assumptions underlying different clustering algorithms can be daunting. Thus, determining the right match between clustering algorithms and biomedical applications has become particularly important. This paper is presented to provide biomedical researchers with an overview of the status quo of clustering algorithms, to illustrate examples of biomedical applications based on cluster analysis, and to help biomedical researchers select the most suitable clustering algorithms for their own applications.","Clustering algorithms,
Algorithm design and analysis,
Data analysis,
Gene expression,
Magnetic resonance imaging,
Text analysis"
A Survey of Medical Image Registration on Multicore and the GPU,"In this article, we look at early, recent, and state-of-the-art methods for registration of medical images using a range of high-performance computing (HPC) architectures including symmetric multiprocessing (SMP), massively multiprocessing (MMP), and architectures with distributed memory (DM), and nonuniform memory access (NUMA). The article is designed to be self-sufficient. We will take the time to define and describe concepts of interest, albeit briefly, in the context of image registration and HPC. We provide an overview of the registration problem and its main components in the section ""Registration."" Our main focus will be HPC-related aspects, and we will highlight relevant issues as we explore the problem domain. This approach presents a fresh angle on the subject than previously investigated by the more general and classic reviews in the literature [1]-[3]. The sections ""Multi-CPU Implementations"" and ""Accelerator Implementations"" are organized from the perspective of high-performance and parallel- computing with the registration problem embodied. This is meant to equip the reader with the knowledge to map a registration problem to a given computing architecture.","Biomedical imaging,
Image registration,
Multicore processing,
Surges,
Computer architecture,
Cancer,
Ultrasonic imaging,
Computed tomography,
Pancreas,
Laparoscopes"
Real-Time Noncoherent UWB Positioning Radar With Millimeter Range Accuracy: Theory and Experiment,"In this paper, we propose a novel architecture for ultra-wideband (UWB) positioning systems, which combines the architectures of carrier-based UWB systems and traditional energy detection-based UWB systems. By implementing the novel architecture, we have successfully developed a standalone noncoherent system for positioning both static and dynamic targets in an indoor environment with approximately 2 and 5 mm of 3-D accuracy, respectively. The results are considered a great milestone in developing such technology. 1-D and 3-D experiments have been carried out and validated using an optical reference system, which provides better than 0.3-mm 3-D accuracy. This type of indoor high-accuracy wireless localization system has many unique applications including robot control, surgical navigation, sensitive material monitoring, and asset tracking.",
"Progress Review of Electromagnetic Compatibility Analysis Technologies for Packages, Printed Circuit Boards, and Novel Interconnects","The ever-increasing demands of digital computing and wireless communication have been driving the semiconductor technology to change with each passing day. Modern electronic systems integrate more complex components and devices, which results in a very complex electromagnetic (EM) field environment. EM compatibility has become one of the major issues in ICs redesign, mainly due to the lack of efficient and accurate simulation tools and expertise on noise reduction and immunity improvement. This paper reviews the state of the arts of IC, electronic package, and printed circuit board simulation and modeling technologies. It summarizes the modeling technologies for both available structures [multilayered power-ground planes and macromodeling of interconnect (INC)] and novel structures (nano-INCs and 3-D ICs based on through-silicon via technology). It also illustrates the trends of simulation and modeling technologies in EM compatibility, signal integrity, and power integrity.","Integrated circuit modeling,
Computational modeling,
Impedance,
Capacitance,
Analytical models,
Book reviews,
Shape"
In Vivo Impedance Imaging With Total Variation Regularization,"We show that electrical impedance tomography (EIT) image reconstruction algorithms with regularization based on the total variation (TV) functional are suitable for in vivo imaging of physiological data. This reconstruction approach helps to preserve discontinuities in reconstructed profiles, such as step changes in electrical properties at interorgan boundaries, which are typically smoothed by traditional reconstruction algorithms. The use of the TV functional for regularization leads to the minimization of a nondifferentiable objective function in the inverse formulation. This cannot be efficiently solved with traditional optimization techniques such as the Newton method. We explore two implementations methods for regularization with the TV functional: the lagged diffusivity method and the primal dual-interior point method (PD-IPM). First we clarify the implementation details of these algorithms for EIT reconstruction. Next, we analyze the performance of these algorithms on noisy simulated data. Finally, we show reconstructed EIT images of in vivo data for ventilation and gastric emptying studies. In comparison to traditional quadratic regularization, TV regulariza tion shows improved ability to reconstruct sharp contrasts.","In vivo,
Image reconstruction,
Tomography,
TV,
Impedance,
Reconstruction algorithms,
Optimization methods,
Newton method,
Performance analysis,
Algorithm design and analysis"
4-D Cardiac MR Image Analysis: Left and Right Ventricular Morphology and Function,"In this study, a combination of active shape model (ASM) and active appearance model (AAM) was used to segment the left and right ventricles of normal and Tetralogy of Fallot (TOF) hearts on 4-D (3-D+time) MR images. For each ventricle, a 4-D model was first used to achieve robust preliminary segmentation on all cardiac phases simultaneously and a 3-D model was then applied to each phase to improve local accuracy while maintaining the overall robustness of the 4-D segmentation. On 25 normal and 25 TOF hearts, in comparison to the expert traced independent standard, our comprehensive performance assessment showed subvoxel segmentation accuracy, high overlap ratios, good ventricular volume correlations, and small percent volume differences. Following 4-D segmentation, novel quantitative shape and motion features were extracted using shape information, volume-time and dV/dt curves, analyzed and used for disease status classification. Automated discrimination between normal/TOF subjects achieved 90%-100% sensitivity and specificity. The features obtained from TOF hearts show higher variability compared to normal subjects, suggesting their potential use as disease progression indicators. The abnormal shape and motion variations of the TOF hearts were accurately captured by both the segmentation and feature characterization.",
Multilevel Optimal Predictive Dynamic Voltage Restorer,"This paper presents an optimal predictive controller for a multilevel converter-based dynamic voltage restorer (DVR), which is able to improve the voltage quality of sensitive loads connected to the electrical power network. The optimal predictive controlled multilevel DVR can restore sags and short interruptions while reducing the total harmonic distortion (THD) of the ac line voltages to values lower than 1%. The DVR is based on a three-phase neutral point clamped converter to dynamically inject a compensation voltage vector in series with the line voltage, through series-connected transformer secondary windings. To assure high-quality voltages for sensitive loads, we devise optimal predictive control laws for the injected compensation ac voltages. A suitable quadratic weighed cost functional is used to choose the voltage vector, minimizing both the ac voltage errors through current injection and the dc side capacitor voltage unbalancing. The performance of the proposed predictive controller is compared to classical proportional integral (PI): synchronous frame and stationary frame (P+resonant) controllers. The line-side filter capacitor topology is compared to the regular converter-side filter capacitor. Obtained experimental results show that the ac voltages are almost sinusoidal in steady-state operation when facing balanced and unbalanced sags and short interruptions with unbalanced loads. Voltage THD is reduced to values lower than 1%; the DVR is behaving also as a series active power filter for the ac voltages.","Capacitors,
Active filters,
Optimal control,
Voltage control,
Pi control,
Proportional control,
Total harmonic distortion,
Predictive control,
Cost function,
Resonance"
A Mobile GPRS-Sensors Array for Air Pollution Monitoring,"An online GPRS-Sensors Array for air pollution monitoring has been designed, implemented, and tested. The proposed system consists of a Mobile Data-Acquisition Unit (Mobile-DAQ) and a fixed Internet-Enabled Pollution Monitoring Server (Pollution-Server). The Mobile-DAQ unit integrates a single-chip microcontroller, air pollution sensors array, a General Packet Radio Service Modem (GPRS-Modem), and a Global Positioning System Module (GPS-Module). The Pollution-Server is a high-end personal computer application server with Internet connectivity. The Mobile-DAQ unit gathers air pollutants levels (CO, NO2, and SO2), and packs them in a frame with the GPS physical location, time, and date. The frame is subsequently uploaded to the GPRS-Modem and transmitted to the Pollution-Server via the public mobile network. A database server is attached to the Pollution-Server for storing the pollutants level for further usage by various clients such as environment protection agencies, vehicles registration authorities, and tourist and insurance companies. The Pollution-Server is interfaced to Google Maps to display real-time pollutants levels and locations in large metropolitan areas. The system was successfully tested in the city of Sharjah, UAE. The system reports real-time pollutants level and their location on a 24-h/7-day basis.","Air pollution,
Web server,
Sensor arrays,
Internet,
Global Positioning System,
Network servers,
Testing,
Computerized monitoring,
Microcontrollers,
Sensor systems"
Niching Without Niching Parameters: Particle Swarm Optimization Using a Ring Topology,"Niching is an important technique for multimodal optimization. Most existing niching methods require specification of certain niching parameters in order to perform well. These niching parameters, often used to inform a niching algorithm how far apart between two closest optima or the number of optima in the search space, are typically difficult to set as they are problem dependent. This paper describes a simple yet effective niching algorithm, a particle swarm optimization (PSO) algorithm using a ring neighborhood topology, which does not require any niching parameters. A PSO algorithm using the ring topology can operate as a niching algorithm by using individual particles' local memories to form a stable network retaining the best positions found so far, while these particles explore the search space more broadly. Given a reasonably large population uniformly distributed in the search space, PSO algorithms using the ring topology are able to form stable niches across different local neighborhoods, eventually locating multiple global/local optima. The complexity of these niching algorithms is only O(N), where N is the population size. Experimental results suggest that PSO algorithms using the ring topology are able to provide superior and more consistent performance over some existing PSO niching algorithms that require niching parameters.","Particle swarm optimization,
Optimization methods,
Network topology,
Space exploration,
Robustness,
Computer science,
Information technology,
Australia,
Machine learning"
Regularized Common Spatial Pattern With Aggregation for EEG Classification in Small-Sample Setting,"Common spatial pattern (CSP) is a popular algorithm for classifying electroencephalogram (EEG) signals in the context of brain-computer interfaces (BCIs). This paper presents a regularization and aggregation technique for CSP in a small-sample setting (SSS). Conventional CSP is based on a sample-based covariance-matrix estimation. Hence, its performance in EEG classification deteriorates if the number of training samples is small. To address this concern, a regularized CSP (R-CSP) algorithm is proposed, where the covariance-matrix estimation is regularized by two parameters to lower the estimation variance while reducing the estimation bias. To tackle the problem of regularization parameter determination, R-CSP with aggregation (R-CSP-A) is further proposed, where a number of R-CSPs are aggregated to give an ensemble-based solution. The proposed algorithm is evaluated on data set IVa of BCI Competition III against four other competing algorithms. Experiments show that R-CSP-A significantly outperforms the other methods in average classification performance in three sets of experiments across various testing scenarios, with particular superiority in SSS.",
Efficient Generalized Integer Transform for Reversible Watermarking,"In this letter, an efficient integer transform based reversible watermarking is proposed. We first show that Tian's difference expansion (DE) technique can be reformulated as an integer transform. Then, a generalized integer transform and a payload-dependent location map are constructed to extend the DE technique to the pixel blocks of arbitrary length. Meanwhile, the distortion can be controlled by preferentially selecting embeddable blocks that introduce less distortion. Finally, the superiority of the proposed method is experimental verified by comparing with other existing schemes.",
A Capacitor-Less CMOS Active Feedback Low-Dropout Regulator With Slew-Rate Enhancement for Portable On-Chip Application,"A low-dropout regulator for on-chip application with active feedback and a slew-rate enhancement circuit to minimize compensation capacitance and speed up transient response is presented in this brief. The idea has been modeled and experimentally verified in a standard 0.35-¿m CMOS process. The total compensation capacitance is 7 pF. From experimental results, the implemented regulator can operate from a supply voltage of 1.8-4.5 V with a minimum dropout voltage of 0.2 V at a maximum 100-mA load and I Q of 20 ¿A.","Regulators,
Voltage,
Capacitors,
Capacitance,
Power transistors,
Filtering,
Power amplifiers,
Output feedback,
Feedback circuits,
Energy management"
Perceptual issues in augmented reality revisited,"This paper provides a classification of perceptual issues in augmented reality, created with a visual processing and interpretation pipeline in mind. We organize issues into ones related to the environment, capturing, augmentation, display, and individual user differences. We also illuminate issues associated with more recent platforms such as handhelds or projector-camera systems. Throughout, we describe current approaches to addressing these problems, and suggest directions for future research.",
Trust management in mobile ad hoc networks using a scalable maturity-based model,"In this paper, we propose a human-based model which builds a trust relationship between nodes in an ad hoc network. The trust is based on previous individual experiences and on the recommendations of others. We present the Recommendation Exchange Protocol (REP) which allows nodes to exchange recommendations about their neighbors. Our proposal does not require disseminating the trust information over the entire network. Instead, nodes only need to keep and exchange trust information about nodes within the radio range. Without the need for a global trust knowledge, our proposal scales well for large networks while still reducing the number of exchanged messages and therefore the energy consumption. In addition, we mitigate the effect of colluding attacks composed of liars in the network. A key concept we introduce is the relationship maturity, which allows nodes to improve the efficiency of the proposed model for mobile scenarios. We show the correctness of our model in a single-hop network through simulations. We also extend the analysis to mobile multihop networks, showing the benefits of the maturity relationship concept. We evaluate the impact of malicious nodes that send false recommendations to degrade the efficiency of the trust model. At last, we analyze the performance of the REP protocol and show its scalability. We show that our implementation of REP can significantly reduce the number messages.",
An Electromagnetic Micro Power Generator for Low-Frequency Environmental Vibrations Based on the Frequency Upconversion Technique,"This paper presents a microelectromechanical-system-based electromagnetic vibration-to-electrical power generator that can harvest energy from low-frequency external vibrations. The efficiency of vibration-based harvesters is proportional to excitation frequency, so the proposed generator is designed to convert low-frequency environmental vibrations to a higher frequency by employing the frequency upconversion (FupC) technique. It has been shown that the generator can effectively harvest energy from environmental vibrations of 70-150 Hz and generates 0.57-mV voltage with 0.25-nW power from a single cantilever by upconverting the input vibration frequency of 95 Hz-2 kHz. The fabricated generator size is 8.5×7×2.5 mm3, and a total of 20 serially connected cantilevers have been used to multiply the generated voltage and power. The generator demonstrated in this paper is designed for the proof of concept, and the power and voltage levels can further be increased by increasing the number of cantilevers or coil turns. The performance of the generator is also compared with that of a same sized custom-made traditional magnet-coil-type generator and with that of a traditional generator from the literature to prove its effectiveness.",
Fully Integrated Graphene and Carbon Nanotube Interconnects for Gigahertz High-Speed CMOS Electronics,"Carbon-based nanomaterials such as metallic single-walled carbon nanotubes, multiwalled carbon nanotubes (MWCNTs), and graphene have been considered as some of the most promising candidates for future interconnect technology because of their high current-carrying capacity and conductivity in the nanoscale, and immunity to electromigration, which has been a great challenge for scaling down the traditional copper interconnects. Therefore, studies on the performance and optimization of carbon-based interconnects working in a realistic operational environment are needed in order to advance the technology beyond the exploratory discovery phase. In this paper, we present the first demonstration of graphene interconnects monolithically integrated with industry-standard complementary metal-oxide-semiconductor technology, as well as the first experimental results that compare the performance of high-speed on-chip graphene and MWCNT interconnects. The graphene interconnects operate up to 1.3-GHz frequency, which is a speed that is commensurate with the fastest high-speed processor chips today. A low-swing signaling technique has been applied to improve the speed of carbon interconnects up to 30%.","Integrated circuit interconnections,
CMOS integrated circuits,
Wire,
Carbon nanotubes,
Nanomaterials"
Nonparametric Detection of Signals by Information Theoretic Criteria: Performance Analysis and an Improved Estimator,"Determining the number of sources from observed data is a fundamental problem in many scientific fields. In this paper we consider the nonparametric setting, and focus on the detection performance of two popular estimators based on information theoretic criteria, the Akaike information criterion (AIC) and minimum description length (MDL). We present three contributions on this subject. First, we derive a new expression for the detection performance of the MDL estimator, which exhibits a much closer fit to simulations in comparison to previous formulas. Second, we present a random matrix theory viewpoint of the performance of the AIC estimator, including approximate analytical formulas for its overestimation probability. Finally, we show that a small increase in the penalty term of AIC leads to an estimator with a very good detection performance and a negligible overestimation probability.","Signal detection,
Performance analysis,
Sensor arrays,
Eigenvalues and eigenfunctions,
Covariance matrix,
Signal analysis,
Probability,
Array signal processing,
Computer science,
Mathematics"
Scalability of Roll-to-Roll Gravure-Printed Electrodes on Plastic Foils,"Roll-to-roll (R2R) gravure printing is considered to be a leading technology for the production of flexible and low-cost printed electronics in the near future. To enable the use of R2R gravure in printed electronics, the limits of overlay printing registration accuracy (OPRA) and the scalability of printed features with respect to the physical parameters of the gravure system, including given plastic substrates and inks, should be characterized. Important parameters of printed lines include surface roughness, thickness, line widening, and line-edge roughness. To date, there are no comprehensive reports regarding the limits of OPRA and the scalability of printed electrodes, including the control of surface roughness, thickness, line widening, and line-edge roughness using R2R gravure printing. In this paper, we examine ways of evaluating the OPRA limit of our gravure system. We find that OPRA is limited in the web moving direction to 40 μm and in the perpendicular direction to 16 μm, showing the importance of web handling on registration. Furthermore, we demonstrate the scalability of printed electrodes formed using a R2R gravure system to linewidths of 317 μm, with 440 nm thickness, 30 nm of surface roughness and edge waviness of 4 μm on PET foils, and describe optimization strategies to realize improved surface roughness, thickness, line widening, and line-edge roughness for future printed electronics applications.",
Region-Based Location-Service-Management Protocol for VANETs,"The efficiency by which a node of a vehicular ad hoc network (VANET) can route messages to destinations heavily depends on the VANET's ability to keep track of the locations of its nodes (vehicles). Current location-management schemes lack scalability and, hence, are proven unable to work in large-scale networks. Therefore, location management in VANETs remains a major challenge. In this paper, we propose a new region-based location-service-management protocol (RLSMP) that uses mobility patterns as means to synthesize node movement and, thus, can be used in large VANET applications. The protocol attempts to relax the scalability issue suffered by other protocols by employing message aggregation in location updating and in querying. Furthermore, due to the protocol's intrinsic locality awareness, it achieves minimum control overhead. To evaluate the efficiency of the protocol, we study its performance analytically and by using simulation for a 2-D random-walk model, as well as on real mobility patterns. The performance of the protocol is compared with that of other prominent location-management protocols.",
An Affine Projection Sign Algorithm Robust Against Impulsive Interferences,"A new affine projection sign algorithm (APSA) is proposed, which is robust against non-Gaussian impulsive interferences and has fast convergence. The conventional affine projection algorithm (APA) converges fast at a high cost in terms of computational complexity and it also suffers performance degradation in the presence of impulsive interferences. The family of sign algorithms (SAs) stands out due to its low complexity and robustness against impulsive noise. The proposed APSA combines the benefits of the APA and SA by updating its weight vector according to the L 1-norm optimization criterion while using multiple projections. The features of the APA and the L 1-norm minimization guarantee the APSA an excellent candidate for combatting impulsive interference and speeding up the convergence rate for colored inputs at a low computational complexity. Simulations in a system identification context show that the proposed APSA outperforms the normalized least-mean-square (NLMS) algorithm, APA, and normalized sign algorithm (NSA) in terms of convergence rate and steady-state error. The robustness of the APSA against impulsive interference is also demonstrated.",
DTRAB: Combating Against Attacks on Encrypted Protocols Through Traffic-Feature Analysis,"The unbridled growth of the Internet and the network-based applications has contributed to enormous security leaks. Even the cryptographic protocols, which are used to provide secure communication, are often targeted by diverse attacks. Intrusion detection systems (IDSs) are often employed to monitor network traffic and host activities that may lead to unauthorized accesses and attacks against vulnerable services. Most of the conventional misuse-based and anomaly-based IDSs are ineffective against attacks targeted at encrypted protocols since they heavily rely on inspecting the payload contents. To combat against attacks on encrypted protocols, we propose an anomaly-based detection system by using strategically distributed monitoring stubs (MSs). We have categorized various attacks against cryptographic protocols. The MSs, by sniffing the encrypted traffic, extract features for detecting these attacks and construct normal usage behavior profiles. Upon detecting suspicious activities due to the deviations from these normal profiles, the MSs notify the victim servers, which may then take necessary actions. In addition to detecting attacks, the MSs can also trace back the originating network of the attack. We call our unique approach DTRAB since it focuses on both Detection and TRAceBack in the MS level. The effectiveness of the proposed detection and traceback methods are verified through extensive simulations and Internet datasets.",
Two-Dimensional Intraventricular Flow Mapping by Digital Processing Conventional Color-Doppler Echocardiography Images,"Doppler echocardiography remains the most extended clinical modality for the evaluation of left ventricular (LV) function. Current Doppler ultrasound methods, however, are limited to the representation of a single flow velocity component. We thus developed a novel technique to construct 2D time-resolved (2D+t) LV velocity fields from conventional transthoracic clinical acquisitions. Combining color-Doppler velocities with LV wall positions, the cross-beam blood velocities were calculated using the continuity equation under a planar flow assumption. To validate the algorithm, 2D Doppler flow mapping and laser particle image velocimetry (PIV) measurements were carried out in an atrio-ventricular duplicator. Phase-contrast magnetic resonance (MR) acquisitions were used to measure in vivo the error due to the 2D flow assumption and to potential scan-plane misalignment. Finally, the applicability of the Doppler technique was tested in the clinical setting. In vitro experiments demonstrated that the new method yields an accurate quantitative description of the main vortex that forms during the cardiac cycle (mean error <; 25% for vortex radius, position and circulation). MR image analysis evidenced that the error due to the planar flow assumption is close to 15% and does not preclude the characterization of major vortex properties neither in the normal nor in the dilated LV. These results are yet to be confirmed by a head-to-head clinical validation study. Clinical Doppler studies showed that the method is readily applicable and that a single large anterograde vortex develops in the healthy ventricle while supplementary retrograde swirling structures may appear in the diseased heart. The proposed echocardiographic method based on the continuity equation is fast, clinically-compliant and does not require complex training. This technique will potentially enable investigators to study of additional quantitative aspects of intraventricular flow dynamics in the clinical setting by high-throughput processing conventional color-Doppler images.","Echocardiography,
Equations,
Ultrasonic imaging,
Blood,
Magnetic field measurement,
Particle measurements,
Magnetic resonance,
Phase measurement,
In vivo,
Testing"
Dominant orientation templates for real-time detection of texture-less objects,"We present a method for real-time 3D object detection that does not require a time consuming training stage, and can handle untextured objects. At its core, is a novel template representation that is designed to be robust to small image transformations. This robustness based on dominant gradient orientations lets us test only a small subset of all possible pixel locations when parsing the image, and to represent a 3D object with a limited set of templates. We show that together with a binary representation that makes evaluation very fast and a branch-and-bound approach to efficiently scan the image, it can detect untextured objects in complex situations and provide their 3D pose in real-time.","Object detection,
Computer vision,
Robustness,
Distortion measurement,
Runtime,
Histograms,
Computer science,
Laboratories,
Testing,
Pixel"
JPEG Error Analysis and Its Applications to Digital Image Forensics,"JPEG is one of the most extensively used image formats. Understanding the inherent characteristics of JPEG may play a useful role in digital image forensics. In this paper, we introduce JPEG error analysis to the study of image forensics. The main errors of JPEG include quantization, rounding, and truncation errors. Through theoretically analyzing the effects of these errors on single and double JPEG compression, we have developed three novel schemes for image forensics including identifying whether a bitmap image has previously been JPEG compressed, estimating the quantization steps of a JPEG image, and detecting the quantization table of a JPEG image. Extensive experimental results show that our new methods significantly outperform existing techniques especially for the images of small sizes. We also show that the new method can reliably detect JPEG image blocks which are as small as 8 × 8 pixels and compressed with quality factors as high as 98. This performance is important for analyzing and locating small tampered regions within a composite image.",
On the Annotation of Web Videos by Efficient Near-Duplicate Search,"With the proliferation of Web 2.0 applications, user-supplied social tags are commonly available in social media as a means to bridge the semantic gap. On the other hand, the explosive expansion of social web makes an overwhelming number of web videos available, among which there exists a large number of near-duplicate videos. In this paper, we investigate techniques which allow effective annotation of web videos from a data-driven perspective. A novel classifier-free video annotation framework is proposed by first retrieving visual duplicates and then suggesting representative tags. The significance of this paper lies in the addressing of two timely issues for annotating query videos. First, we provide a novel solution for fast near-duplicate video retrieval. Second, based on the outcome of near-duplicate search, we explore the potential that the data-driven annotation could be successful when huge volume of tagged web videos is freely accessible online. Experiments on cross sources (annotating Google videos and Yahoo! videos using YouTube videos) and cross time periods (annotating YouTube videos using historical data) show the effectiveness and efficiency of the proposed classifier-free approach for web video tag annotation.",
Opportunity-Based Topology Control in Wireless Sensor Networks,"Topology control is an effective method to improve the energy efficiency of wireless sensor networks (WSNs). Traditional approaches are based on the assumption that a pair of nodes is either ""connected"" or ""disconnected."" These approaches are called connectivity-based topology control. In real environments, however, there are many intermittently connected wireless links called lossy links. Taking a succeeded lossy link as an advantage, we are able to construct more energy-efficient topologies. Toward this end, we propose a novel opportunity-based topology control. We show that opportunity-based topology control is a problem of NP-hard. To address this problem in a practical way, we design a fully distributed algorithm called CONREAP based on reliability theory. We prove that CONREAP has a guaranteed performance. The worst running time is O(\vert E\vert ), where E is the link set of the original topology, and the space requirement for individual nodes is O(d), where d is the node degree. To evaluate the performance of CONREAP, we design and implement a prototype system consisting of 50 Berkeley Mica2 motes. We also conducted comprehensive simulations. Experimental results show that compared with the connectivity-based topology control algorithms, CONREAP can improve the energy efficiency of a network up to six times.",
A characterization of the Rodinia benchmark suite with comparison to contemporary CMP workloads,"The recently released Rodinia benchmark suite enables users to evaluate heterogeneous systems including both accelerators, such as GPUs, and multicore CPUs. As Rodinia sees higher levels of acceptance, it becomes important that researchers understand this new set of benchmarks, especially in how they differ from previous work. In this paper, we present recent extensions to Rodinia and conduct a detailed characterization of the Rodinia benchmarks (including performance results on an NVIDIA GeForce GTX480, the first product released based on the Fermi architecture). We also compare and contrast Rodinia with Parsec to gain insights into the similarities and differences of the two benchmark collections; we apply principal component analysis to analyze the application space coverage of the two suites. Our analysis shows that many of the workloads in Rodinia and Parsec are complementary, capturing different aspects of certain performance metrics.",
Unsupervised Change Detection in Multispectral Remotely Sensed Imagery With Level Set Methods,"In this paper, the unsupervised change-detection problem in remote sensing images is formulated as a segmentation issue where the discrimination between changed and unchanged classes in the difference image is achieved by defining a proper energy functional. The minimization of this functional is carried out by means of a level set method which iteratively seeks to find a global optimal contour splitting the image into two mutually exclusive regions associated with changed and unchanged classes, respectively. In order to increase the robustness of the method to noise and to the choice of the initial contour, a multiresolution implementation, which performs an analysis of the difference image at different resolution levels, is proposed. The experimental results obtained on three different multitemporal remote sensing images acquired by low- as well as high-spatial-resolution optical remote sensing sensors suggest a clear superiority of the proposed approach compared with state-of-the-art change-detection methods.",
A Registration-Based Propagation Framework for Automatic Whole Heart Segmentation of Cardiac MRI,"Magnetic resonance (MR) imaging has become a routine modality for the determination of patient cardiac morphology. The extraction of this information can be important for the development of new clinical applications as well as the planning and guidance of cardiac interventional procedures. To avoid inter- and intra-observer variability of manual delineation, it is highly desirable to develop an automatic technique for whole heart segmentation of cardiac magnetic resonance images. However, automating this process is complicated by the limited quality of acquired images and large shape variation of the heart between subjects. In this paper, we propose a fully automatic whole heart segmentation framework based on two new image registration algorithms: the locally affine registration method (LARM) and the free-form deformations with adaptive control point status (ACPS FFDs). LARM provides the correspondence of anatomical substructures such as the four chambers and great vessels of the heart, while the registration using ACPS FFDs refines the local details using a constrained optimization scheme. We validated our proposed segmentation framework on 37 cardiac MR volumes on the end-diastolic phase, displaying a wide diversity of morphology and pathology, and achieved a mean accuracy of 2.14 ± 0.63 mm (rms surface distance) and a maximal error of 4.31 mm.","Heart,
Magnetic resonance imaging,
Image segmentation,
Magnetic resonance,
Morphology,
Data mining,
Manuals,
Shape,
Image registration,
Adaptive control"
ADS-Based Guidelines for Thinned Planar Arrays,"We propose an analytical technique based on almost difference sets (ADSs) for thinning planar arrays with well controlled sidelobes. The method allows one to synthesize bidimensional arrangements with peak sidelobe levels (PSLs) predictable and deducible from the knowledge of the array aperture, the filling factor, and the autocorrelation function of the ADS at hand. The numerical validation, concerned with both small and very large apertures, points out that the expected PSL values are significantly below those of random arrays and comparable with those from different sets (DSs) although obtainable in a wider range of configurations.","Guidelines,
Planar arrays,
Apertures,
Decision support systems,
Autocorrelation,
Antenna arrays,
Filling,
Level control,
Radar tracking,
Remote sensing"
Dynamic Resource Pricing on Federated Clouds,"Current large distributed systems allow users to share and trade resources. In cloud computing, users purchase different types of resources from one or more resource providers using a fixed pricing scheme. Federated clouds, a topic of recent interest, allows different cloud providers to share resources for increased scalability and reliability. However, users and providers of cloud resources are rational and maximize their own interest when consuming and contributing shared resources. In this paper, we present a dyanmic pricing scheme suitable for rational users requests containing multiple resource types. Using simulations, we compare the efficiency of our proposed strategy-proof dynamic scheme with fixed pricing, and show that user welfare and the percentage of successful requests is increased by using dynamic pricing.",
WiFi localization and navigation for autonomous indoor mobile robots,"Building upon previous work that demonstrates the effectiveness of WiFi localization information per se, in this paper we contribute a mobile robot that autonomously navigates in indoor environments using WiFi sensory data. We model the world as a WiFi signature map with geometric constraints and introduce a continuous perceptual model of the environment generated from the discrete graph-based WiFi signal strength sampling. We contribute our WiFi localization algorithm which continuously uses the perceptual model to update the robot location in conjunction with its odometry data. We then briefly introduce a navigation approach that robustly uses the WiFi location estimates. We present the results of our exhaustive tests of the WiFi localization independently and in conjunction with the navigation of our custom-built mobile robot in extensive long autonomous runs.",
MobiCent: a Credit-Based Incentive System for Disruption Tolerant Network,"When Disruption Tolerant Network (DTN) is used in commercial environments, incentive mechanism should be employed to encourage cooperation among selfish mobile users. Key challenges in the design of an incentive scheme for DTN are that disconnections among nodes are the norm rather than exception and network topology is time varying. Thus, it is difficult to detect selfish actions that can be launched by mobile users or to pre-determine the routing path to be used. In this paper, we propose MobiCent, a credit-based incentive system for DTN. While MobiCent allows the underlying routing protocol to discover the most efficient paths, it is also incentive compatible. Therefore, using MobiCent, rational nodes will not purposely waste transfer opportunity or cheat by creating non-existing contacts to increase their rewards. MobiCent also provides different payment mechanisms to cater to client that wants to minimize either payment or data delivery delay.",
Intersection Based Motion Correction of Multislice MRI for 3-D in Utero Fetal Brain Image Formation,"In recent years, postprocessing of fast multislice magnetic resonance imaging (MRI) to correct fetal motion has provided the first true 3-D MR images of the developing human brain in utero. Early approaches have used reconstruction based algorithms, employing a two-step iterative process, where slices from the acquired data are realigned to an approximate 3-D reconstruction of the fetal brain, which is then refined further using the improved slice alignment. This two step slice-to-volume process, although powerful, is computationally expensive in needing a 3-D reconstruction, and is limited in its ability to recover subvoxel alignment. Here, we describe an alternative approach which we term slice intersection motion correction (SIMC), that seeks to directly co-align multiple slice stacks by considering the matching structure along all intersecting slice pairs in all orthogonally planned slices that are acquired in clinical imaging studies. A collective update scheme for all slices is then derived, to simultaneously drive slices into a consistent match along their lines of intersection. We then describe a 3-D reconstruction algorithm that, using the final motion corrected slice locations, suppresses through-plane partial volume effects to provide a single high isotropic resolution 3-D image. The method is tested on simulated data with known motions and is applied to retrospectively reconstruct 3-D images from a range of clinically acquired imaging studies. The quantitative evaluation of the registration accuracy for the simulated data sets demonstrated a significant improvement over previous approaches. An initial application of the technique to studying clinical pathology is included, where the proposed method recovered up to 15 mm of translation and 30? of rotation for individual slices, and produced full 3-D reconstructions containing clinically useful additional information not visible in the original 2-D slices.","Magnetic resonance imaging,
Three dimensional displays,
Image reconstruction,
Humans,
Iterative algorithms,
Iterative methods,
Image resolution,
Testing,
High-resolution imaging,
Pathology"
Particle Swarm Optimization With Composite Particles in Dynamic Environments,"In recent years, there has been a growing interest in the study of particle swarm optimization (PSO) in dynamic environments. This paper presents a new PSO model, called PSO with composite particles (PSO-CP), to address dynamic optimization problems. PSO-CP partitions the swarm into a set of composite particles based on their similarity using a “worst first” principle. Inspired by the composite particle phenomenon in physics, the elementary members in each composite particle interact via a velocity-anisotropic reflection scheme to integrate valuable information for effectively and rapidly finding the promising optima in the search space. Each composite particle maintains the diversity by a scattering operator. In addition, an integral movement strategy is introduced to promote the swarm diversity. Experiments on a typical dynamic test benchmark problem provide a guideline for setting the involved parameters and show that PSO-CP is efficient in comparison with several state-of-the-art PSO algorithms for dynamic optimization problems.","Particle swarm optimization,
Reflection,
Particle scattering,
Physics,
Extraterrestrial phenomena,
Benchmark testing,
Guidelines,
Heuristic algorithms,
Reactive power,
Evolutionary computation"
I2T: Image Parsing to Text Description,"In this paper, we present an image parsing to text description (I2T) framework that generates text descriptions of image and video content based on image understanding. The proposed I2T framework follows three steps: 1) input images (or video frames) are decomposed into their constituent visual patterns by an image parsing engine, in a spirit similar to parsing sentences in natural language; 2) the image parsing results are converted into semantic representation in the form of Web ontology language (OWL), which enables seamless integration with general knowledge bases; and 3) a text generation engine converts the results from previous steps into semantically meaningful, human readable, and query-able text reports. The centerpiece of the I2T framework is an and-or graph (AoG) visual knowledge representation, which provides a graphical representation serving as prior knowledge for representing diverse visual patterns and provides top-down hypotheses during the image parsing. The AoG embodies vocabularies of visual elements including primitives, parts, objects, scenes as well as a stochastic image grammar that specifies syntactic relations (i.e., compositional) and semantic relations (e.g., categorical, spatial, temporal, and functional) between these visual elements. Therefore, the AoG is a unified model of both categorical and symbolic representations of visual knowledge. The proposed I2T framework has two objectives. First, we use semiautomatic method to parse images from the Internet in order to build an AoG for visual knowledge representation. Our goal is to make the parsing process more and more automatic using the learned AoG model. Second, we use automatic methods to parse image/video in specific domains and generate text reports that are useful for real-world applications. In the case studies at the end of this paper, we demonstrate two automatic I2T systems: a maritime and urban scene video surveillance system and a real-time automatic driving scene understanding system.","Layout,
Search engines,
Image converters,
OWL,
Knowledge representation,
Natural languages,
Humans,
Vocabulary,
Stochastic processes,
Internet"
Miniaturized sensors for the viscosity and density of liquids-performance and issues,"This paper reviews our recent work on vibrating sensors for the physical properties of fluids, particularly viscosity and density. Several device designs and the associated properties, specifically with respect to the sensed rheological domain and the onset of non-Newtonian behavior, are discussed.","Viscosity,
Resonance,
Monitoring,
Electrodes,
Vibrations,
Liquids,
Sensor systems,
Equivalent circuits,
RLC circuits,
Mechatronics"
Dead reckoning from the pocket - An experimental study,"Modern mobile phones enable absolute positioning based on GPS or WiFi. However, incremental positioning based on dead reckoning is an interesting source of complementary information, e.g., for indoor positioning or for filling in reception gaps. In the literature however, reasonable dead reckoning accuracies have been reported for fixed and typically a priori known device placements only, e.g., on the hip. Therefore, this paper contributes an experimental study of several published as well as novel approaches for dead reckoning in a scenario with unconstrained placement of a device in the user's trouser pockets. Utilizing the movement of a sensor in a trouser pocket due to body motion, we estimate the user's walking direction and steps robustly for arbitrary placements in the pocket and without additional body-worn sensors. We evaluate these methods on a large dataset of 23 traces of 8 different persons, and compare different approaches.","Dead reckoning,
Prototypes,
Smart phones,
Computational modeling,
Road vehicles,
Radio broadcasting,
Social network services,
Access control,
Automatic control,
Communication system control"
Segmenting Clustered Nuclei Using H-minima Transform-Based Marker Extraction and Contour Parameterization,"In this letter, we present a novel watershed-based method for segmentation of cervical and breast cell images. We formulate the segmentation of clustered nuclei as an optimization problem. A hypothesis concerning the nuclei, which involves a priori knowledge with respect to the shape of nuclei, is tested to solve the optimization problem. We first apply the distance transform to the clustered nuclei. A marker extraction scheme based on the H -minima transform is introduced to obtain the optimal segmentation result from the distance map. In order to estimate the optimal h-value, a size-invariant segmentation distortion evaluation function is defined based on the fitting residuals between the segmented region boundaries and fitted models. Ellipsoidal modeling of contours is introduced to adjust nuclei contours for more effective analysis. Experiments on a variety of real microscopic cell images show that the proposed method yields more accurate segmentation results than the state-of-the-art watershed-based methods.",
Open Cirrus: A Global Cloud Computing Testbed,"Open Cirrus is a cloud computing testbed that, unlike existing alternatives, federates distributed data centers. It aims to spur innovation in systems and applications research and catalyze development of an open source service stack for the cloud.","Cloud computing,
Testing,
Technological innovation"
Differential Modulation for Bidirectional Relaying With Analog Network Coding,"In this correspondence, we propose an analog network coding scheme with differential modulation (ANC-DM) using amplify-and-forward protocol for bidirectional relay networks when neither the source nodes nor the relay knows the channel state information (CSI). The performance of the proposed ANC-DM scheme is analyzed and a simple asymptotic bit error rate (BER) expression is derived. The analytical results are verified through simulations. It is shown that the BER performance of the proposed differential scheme is about 3 dB away from that of the coherent detection scheme. To improve the system performance, the optimum power allocation between the sources and the relay is determined based on the simplified BER. Simulation results indicate that the proposed differential scheme with optimum power allocation yields 1-2 dB performance improvement over an equal power allocation scheme.",
Refinements on IEEE 802.11 Distributed Coordination Function Modeling Approaches,"With the popularity of the IEEE 802.11 standards, many analytical saturation throughput studies for the distributed coordination function (DCF) have been reported. In this paper, we outline a number of issues and criticalities raised by previously proposed models. In particular, a careful look at backoff counter decrement rules allows us to conclude that, under saturation conditions, the slot immediately following a successful transmission can be accessed only by the station (STA) that has successfully transmitted in the previous channel access. Moreover, due to the specific acknowledgment (ACK) timeout setting adopted in the standard, the slot immediately following a collision cannot be accessed by any STA. Thus, the hypothesis of uncorrelation between consecutive channel slots and statistical homogeneity is not generally true. We propose a new backoff decrement model that retains the simplicity of traditional DCF models while being able to take into account such a correlation, and we compare the accuracy of our model with that of previously proposed approaches.","Throughput,
Media Access Protocol,
Counting circuits,
Wireless sensor networks,
Ethernet networks,
Wireless application protocol,
Access protocols,
Performance analysis,
Wireless LAN,
Collision avoidance"
Decentralized charging control for large populations of plug-in electric vehicles: Application of the Nash certainty equivalence principle,"The paper develops and illustrates a novel decentralized charging control algorithm for large populations of plug-in electric vehicles (PEVs). The proposed algorithm is an application of the so-called Nash certainty equivalence principle (or mean-field games.) The control scheme seeks to achieve social optimality by establishing a PEV charging schedule that fills the overnight demand valley. The paper discusses implementation issues and computational complexity, and illustrates concepts with various numerical examples.",
Shape-Preserving Response Prediction for Microwave Design Optimization,"A shape-preserving response prediction methodology for microwave design optimization is introduced. The presented technique allows us to estimate the response of the microwave structure being optimized (fine model) using a computationally cheap representation of the structure (coarse model). The change of the coarse model response is described by the translation vectors corresponding to certain (finite) number of characteristic points of the response. These translation vectors are subsequently used to predict the response change of the fine model. The presented method has very good generalization capability and it is not based on any extractable parameters, which makes it easy to implement. Applications for microwave design optimization are discussed. The robustness of the proposed approach is demonstrated by extensive comparison with space mapping, which is one of the most efficient optimization approaches in microwave engineering so far.","Predictive models,
Solid modeling,
Optimization,
Computational modeling,
Microwave theory and techniques,
Integrated circuit modeling,
Chebyshev approximation"
Recognizing human actions from still images with latent poses,"We consider the problem of recognizing human actions from still images. We propose a novel approach that treats the pose of the person in the image as latent variables that will help with recognition. Different from other work that learns separate systems for pose estimation and action recognition, then combines them in an ad-hoc fashion, our system is trained in an integrated fashion that jointly considers poses and actions. Our learning objective is designed to directly exploit the pose information for action recognition. Our experimental results demonstrate that by inferring the latent poses, we can improve the final action recognition results.",
Active Reranking for Web Image Search,"Image search reranking methods usually fail to capture the user's intention when the query term is ambiguous. Therefore, reranking with user interactions, or active reranking, is highly demanded to effectively improve the search performance. The essential problem in active reranking is how to target the user's intention. To complete this goal, this paper presents a structural information based sample selection strategy to reduce the user's labeling efforts. Furthermore, to localize the user's intention in the visual feature space, a novel local-global discriminative dimension reduction algorithm is proposed. In this algorithm, a submanifold is learned by transferring the local geometry and the discriminative information from the labelled images to the whole (global) image database. Experiments on both synthetic datasets and a real Web image search dataset demonstrate the effectiveness of the proposed active reranking scheme, including both the structural information based active sample selection strategy and the local-global discriminative dimension reduction algorithm.","Search engines,
Animals,
Labeling,
Information geometry,
Image databases,
Uniform resource locators,
Educational technology,
Research and development,
Information science,
Asia"
Toward an Effective Risk-Conscious and Collaborative Vehicular Collision Avoidance System,"In this paper, we introduce a cooperative collision-avoidance (CCA) scheme for intelligent transport systems. Unlike contemporary strategies, the envisioned scheme avoids flooding the considered vehicular network with high volumes of emergency messages upon accidental events. We present a cluster-based organization of the target vehicles. The cluster is based upon several criteria, which define the movement of the vehicles, namely, the directional bearing and relative velocity of each vehicle, as well as the inter-vehicular distance. We also design a risk-aware medium-access control (MAC) protocol to increase the responsiveness of the proposed CCA scheme. According to the order of each vehicle in its corresponding cluster, an emergency level is associated with the vehicle that signifies the risk of encountering a potential emergency scenario. To swiftly circulate the emergency notifications to collocated vehicles to mitigate the risk of chain collisions, the medium-access delay of each vehicle is set as a function of its emergency level. Due to its twofold contributions, i.e., the cluster-based and risk-conscious approaches, our adopted strategy is referred to as the cluster-based risk-aware CCA (C-RACCA) scheme. The performance of the C-RACCA system is verified through mathematical analyses and computer simulations, whose results clearly verify its effectiveness in mitigating collision risks of the vehicles arising from accidental hazards.","Collaboration,
Collision avoidance,
Vehicles,
Delay,
Collision mitigation,
Intelligent systems,
Media Access Protocol,
Mathematical analysis,
Computer simulation,
Hazards"
Decoding 3-D Reach and Grasp Kinematics From High-Frequency Local Field Potentials in Primate Primary Motor Cortex,"Intracortical microelectrode array recordings generate a variety of neural signals with potential application as control signals in neural interface systems. Previous studies have focused on single and multiunit activity (MUA), as well as low-frequency local field potentials (LFPs), but have not explored higher frequency (>200 Hz) LFPs. In addition, the potential to decode 3-D reach and grasp kinematics based on LFPs has not been demonstrated. Here, we use mutual information and decoding analyses to probe the information content about 3-D reaching and grasping of seven different LFP frequency bands in the range of 0.3-400 Hz. LFPs were recorded via 96-microelectrode arrays in primary motor cortex (M1) of two monkeys performing free reaching to grasp moving objects. Mutual information analyses revealed that higher frequency bands (e.g., 100-200 and 200-400 Hz) carried the most information about the examined kinematics. Furthermore, Kalman filter decoding revealed that broad-band high frequency LFPs, likely reflecting MUA, provided the best decoding performance as well as substantial accuracy in reconstructing reach kinematics, grasp aperture, and aperture velocity. These results indicate that LFPs, especially high frequency bands, could be useful signals for neural interfaces controlling 3-D reach and grasp kinematics.","Decoding,
Kinematics,
Frequency,
Mutual information,
Information analysis,
Apertures,
Microelectrodes,
Signal generators,
Control systems,
Performance analysis"
Automatic Segmentation and Quantitative Analysis of the Articular Cartilages From Magnetic Resonance Images of the Knee,"In this paper, we present a segmentation scheme that automatically and accurately segments all the cartilages from magnetic resonance (MR) images of nonpathological knees. Our scheme involves the automatic segmentation of the bones using a three-dimensional active shape model, the extraction of the expected bone-cartilage interface (BCI), and cartilage segmentation from the BCI using a deformable model that utilizes localization, patient specific tissue estimation and a model of the thickness variation. The accuracy of this scheme was experimentally validated using leave one out experiments on a database of fat suppressed spoiled gradient recall MR images. The scheme was compared to three state of the art approaches, tissue classification, a modified semi-automatic watershed algorithm and nonrigid registration (B-spline based free form deformation). Our scheme obtained an average Dice similarity coefficient (DSC) of (0.83, 0.83, 0.85) for the (patellar, tibial, femoral) cartilages, while (0.82, 0.81, 0.86) was obtained with a tissue classifier and (0.73, 0.79, 0.76) was obtained with nonrigid registration. The average DSC obtained for all the cartilages using a semi-automatic watershed algorithm (0.90) was slightly higher than our approach (0.89), however unlike this approach we segment each cartilage as a separate object. The effectiveness of our approach for quantitative analysis was evaluated using volume and thickness measures with a median volume difference error of (5.92, 4.65, 5.69) and absolute Laplacian thickness difference of (0.13, 0.24, 0.12) mm.",
Power decoupling techniques for micro-inverters in PV systems-a review,"This paper reviews the power decoupling techniques of micro-inverters used in single-phase, grid-tied PV systems. The power decoupling techniques are categorized into three groups: (1) PV side decoupling; (2) DC link decoupling; and (3) AC side decoupling. Various topologies and techniques are presented, compared, and evaluated against the size of capacitance, efficiency and control complexity. Finally, potential topologies and technologies are pointed out as the best options for power decoupling implementation.",
Power Flow Characterization of a Bidirectional Galvanically Isolated High-Power DC/DC Converter Over a Wide Operating Range,"This paper studies the power flow characterization of a bidirectional galvanically isolated high-power dual active bridge DC/DC converter. In experimental tests at the University of Michigan, we have observed three phenomena, which we term as internal power transfer, phase drift, and low system efficiency, that are present under certain operating conditions. These phenomena cannot be explained by conventional power transfer analysis. The authors develop a new model, based on a detailed analysis over a short time scale, that incorporates additional parameters, including the power semiconductor voltage loss and dead time. The new power flow model may be used to explain the observed phenomena and to characterize the power flow of the converter. The model may also be used to perform accurate power flow computations over a wide operating range, thereby supporting optimal hardware design, operating range selection, and power management strategy development. Experimental results are presented to illustrate the validity of the new model.","Load flow,
Galvanizing,
DC-DC power converters,
Bridge circuits,
Topology,
Uninterruptible power systems,
Voltage,
Inductors,
Capacitors,
Energy storage"
L1-Norm-Based 2DPCA,"In this paper, we first present a simple but effective L1-norm-based two-dimensional principal component analysis (2DPCA). Traditional L2-norm-based least squares criterion is sensitive to outliers, while the newly proposed L1-norm 2DPCA is robust. Experimental results demonstrate its advantages.",
Clustering and cluster-based routing protocol for delay-tolerant mobile networks,"This research investigates distributed clustering scheme and proposes a cluster-based routing protocol for Delay-Tolerant Mobile Networks (DTMNs). The basic idea is to distributively group mobile nodes with similar mobility pattern into a cluster, which can then interchangeably share their resources (such as buffer space) for overhead reduction and load balancing, aiming to achieve efficient and scalable routing in DTMN. Due to the lack of continuous communications among mobile nodes and possible errors in the estimation of nodal contact probability, convergence and stability become major challenges in distributed clustering in DTMN. To this end, an exponentially weighted moving average (EWMA) scheme is employed for on-line updating nodal contact probability, with its mean proven to converge to the true contact probability. Based on nodal contact probabilities, a set of functions including Sync(), Leave(), and Join() are devised for cluster formation and gateway selection. Finally, the gateway nodes exchange network information and perform routing. Extensive simulations are carried out to evaluate the effectiveness and efficiency of the proposed cluster-based routing protocol. The simulation results show that it achieves higher delivery ratio and significantly lower overhead and end-to-end delay compared with its non-clustering counterpart.",
Integration of Action and Language Knowledge: A Roadmap for Developmental Robotics,"This position paper proposes that the study of embodied cognitive agents, such as humanoid robots, can advance our understanding of the cognitive development of complex sensorimotor, linguistic, and social learning skills. This in turn will benefit the design of cognitive robots capable of learning to handle and manipulate objects and tools autonomously, to cooperate and communicate with other robots and humans, and to adapt their abilities to changing internal, environmental, and social conditions. Four key areas of research challenges are discussed, specifically for the issues related to the understanding of: 1) how agents learn and represent compositional actions; 2) how agents learn and represent compositional lexica; 3) the dynamics of social interaction and learning; and 4) how compositional action and language representations are integrated to bootstrap the cognitive system. The review of specific issues and progress in these areas is then translated into a practical roadmap based on a series of milestones. These milestones provide a possible set of cognitive robotics goals and test scenarios, thus acting as a research roadmap for future work on cognitive developmental robotics.","Cognitive robotics,
Humanoid robots,
Robot sensing systems,
Paper technology,
Humans,
IEEE Transactions on Autonomous Mental Development,
Testing,
Physiology,
Computer science,
Cognitive science"
Sensitivity Versus Accuracy in Multiclass Problems Using Memetic Pareto Evolutionary Neural Networks,"This paper proposes a multiclassification algorithm using multilayer perceptron neural network models. It tries to boost two conflicting main objectives of multiclassifiers: a high correct classification rate level and a high classification rate for each class. This last objective is not usually optimized in classification, but is considered here given the need to obtain high precision in each class in real problems. To solve this machine learning problem, we use a Pareto-based multiobjective optimization methodology based on a memetic evolutionary algorithm. We consider a memetic Pareto evolutionary approach based on the NSGA2 evolutionary algorithm (MPENSGA2). Once the Pareto front is built, two strategies or automatic individual selection are used: the best model in accuracy and the best model in sensitivity (extremes in the Pareto front). These methodologies are applied to solve 17 classification benchmark problems obtained from the University of California at Irvine (UCI) repository and one complex real classification problem. The models obtained show high accuracy and a high classification rate for each class.",
Fractional repetition codes for repair in distributed storage systems,"We introduce a new class of exact Minimum-Bandwidth Regenerating (MBR) codes for distributed storage systems, characterized by a low-complexity uncoded repair process that can tolerate multiple node failures. These codes consist of the concatenation of two components: an outer MDS code followed by an inner repetition code. We refer to the inner code as a Fractional Repetition code since it consists of splitting the data of each node into several packets and storing multiple replicas of each on different nodes in the system. Our model for repair is table-based, and thus, differs from the random access model adopted in the literature. We present constructions of Fractional Repetition codes based on regular graphs and Steiner systems for a large set of system parameters. The resulting codes are guaranteed to achieve the storage capacity for random access repair. The considered model motivates a new definition of capacity for distributed storage systems, that we call Fractional Repetition capacity. We provide upper bounds on this capacity, while a precise expression remains an open problem.","Maintenance engineering,
Decision support systems,
Peer to peer computing,
Bandwidth,
Data models,
Complexity theory,
Redundancy"
Mechanical Computing Redux: Relays for Integrated Circuit Applications,"Power density has grown to be the dominant challenge for continued complementary metal-oxide-semiconductor (CMOS) technology scaling. Together with recent improvements in microrelay design and process technology, this has led to renewed interest in mechanical computing for ultralow-power integrated circuit (IC) applications. This paper provides a brief history of mechanical computing followed by an overview of the various types of micromechanical switches, with particular emphasis on electromechanical relays since they are among the most promising for IC applications. Relay reliability and process integration challenges are discussed. Demonstrations of functional relay logic circuits are then presented, and relay scaling for improved device density and performance is described. Finally, the energy efficiency benefit of a scaled relay technology versus a CMOS technology with comparable minimum dimensions is assessed.","Logic gates,
Relays,
MOSFET circuits,
CMOS integrated circuits,
Transistors,
CMOS technology,
Micromechanical devices"
LLC Resonant Converter With Adaptive Link-Voltage Variation for a High-Power-Density Adapter,"The output voltage of an adapter for a laptop computer should vary according to the load current in order to supply power to the computer. To satisfy this requirement, an LLC resonant converter with an adaptive link-voltage-variation (ALVV) scheme is proposed in this letter. The proposed ALVV scheme helps the LLC resonant converter to operate at a nearly constant resonant frequency and also allows for the optimal design of the converter. High power density and high efficiency can therefore be obtained. The proposed LLC resonant converter with the ALVV scheme is analyzed theoretically and verified experimentally.","Resonance,
Voltage,
Portable computers,
Resonant frequency,
DC-DC power converters,
Power engineering computing,
Power supplies,
Power system harmonics,
Switching frequency,
Inductors"
Automatic image annotation using group sparsity,"Automatically assigning relevant text keywords to images is an important problem. Many algorithms have been proposed in the past decade and achieved good performance. Efforts have focused upon model representations of keywords, but properties of features have not been well investigated. In most cases, a group of features is preselected, yet important feature properties are not well used to select features. In this paper, we introduce a regularization based feature selection algorithm to leverage both the sparsity and clustering properties of features, and incorporate it into the image annotation task. A novel approach is also proposed to iteratively obtain similar and dissimilar pairs from both the keyword similarity and the relevance feedback. Thus keyword similarity is modeled in the annotation framework. Numerous experiments are designed to compare the performance between features, feature combinations and regularization based feature selection methods applied on the image annotation task, which gives insight into the properties of features in the image annotation task. The experimental results demonstrate that the group sparsity based method is more accurate and stable than others.",
Complex Independent Component Analysis by Entropy Bound Minimization,"We first present a new (differential) entropy estimator for complex random variables by approximating the entropy estimate using a numerically computed maximum entropy bound. The associated maximum entropy distributions belong to the class of weighted linear combinations and elliptical distributions, and together, they provide a rich array of bivariate distributions for density matching. Next, we introduce a new complex independent component analysis (ICA) algorithm, complex ICA by entropy-bound minimization (complex ICA-EBM), using this new entropy estimator and a line search optimization procedure. We present simulation results to demonstrate the superior separation performance and computational efficiency of complex ICA-EBM in separation of complex sources that come from a wide range of bivariate distributions.","Independent component analysis,
Entropy,
Random variables,
Higher order statistics,
Minimization methods,
Signal processing,
Computational modeling,
Computational efficiency,
Neural networks,
Radar signal processing"
"Robust classification of objects, faces, and flowers using natural image statistics","Classification of images in many category datasbets has rapidly improved in recent years. However, systems that perform well on particular datasets typically have one or more limitations such as a failure to generalize across visual tasks (e.g., requiring a face detector or extensive retuning of parameters), insufficient translation invariance, inability to cope with partial views and occlusion, or significant performance degradation as the number of classes is increased. Here we attempt to overcome these challenges using a model that combines sequential visual attention using fixations with sparse coding. The model's biologically-inspired filters are acquired using unsupervised learning applied to natural image patches. Using only a single feature type, our approach achieves 78.5% accuracy on Caltech-101 and 75.2% on the 102 Flowers dataset when trained on 30 instances per class and it achieves 92.7% accuracy on the AR Face database with 1 training instance per person. The same features and parameters are used across these datasets to illustrate its robust performance.","Robustness,
Statistics,
Face detection,
Biological system modeling,
Detectors,
Degradation,
Filters,
Unsupervised learning,
Image databases,
Spatial databases"
Indicator dilution models for the quantification of microvascular blood flow with bolus administration of ultrasound contrast agents,"Indicator dilution methods have a long history in the quantification of both macro- and microvascular blood flow in many clinical applications. Various models have been employed in the past to isolate the primary pass of an indicator after an intravenous bolus injection. The use of indicator dilution techniques allows for the estimation of hemodynamic parameters of a tumor or organ and thus may lead to useful diagnostic and therapy monitoring information. In this paper, we review and discuss the properties of the lognormal function, the gamma variate function, the diffusion with drift models, and the lagged normal function, which have been used to model indicator dilution curves in different fields of medicine. We fit these models to contrast-enhanced ultrasound time-intensity curves from liver metastases and the ovine corpora lutea. We evaluate the models' performance on the image data and compare their predictions for hemodynamic-related parameters such as the area under the curve, the mean transit time, the full-width at half-maximum, the time to the peak intensity, and wash-in time. The models that best fit the experimental data are the lognormal function and the diffusion with drift.",
Patient-Specific Modeling and Quantification of the Aortic and Mitral Valves From 4-D Cardiac CT and TEE,"As decisions in cardiology increasingly rely on noninvasive methods, fast and precise image processing tools have become a crucial component of the analysis workflow. To the best of our knowledge, we propose the first automatic system for patient-specific modeling and quantification of the left heart valves, which operates on cardiac computed tomography (CT) and transesophageal echocardiogram (TEE) data. Robust algorithms, based on recent advances in discriminative learning, are used to estimate patient-specific parameters from sequences of volumes covering an entire cardiac cycle. A novel physiological model of the aortic and mitral valves is introduced, which captures complex morphologic, dynamic, and pathologic variations. This holistic representation is hierarchically defined on three abstraction levels: global location and rigid motion model, nonrigid landmark motion model, and comprehensive aortic-mitral model. First we compute the rough location and cardiac motion applying marginal space learning. The rapid and complex motion of the valves, represented by anatomical landmarks, is estimated using a novel trajectory spectrum learning algorithm. The obtained landmark model guides the fitting of the full physiological valve model, which is locally refined through learned boundary detectors. Measurements efficiently computed from the aortic-mitral representation support an effective morphological and functional clinical evaluation. Extensive experiments on a heterogeneous data set, cumulated to 1516 TEE volumes from 65 4-D TEE sequences and 690 cardiac CT volumes from 69 4-D CT sequences, demonstrated a speed of 4.8 seconds per volume and average accuracy of 1.45 mm with respect to expert defined ground-truth. Additional clinical validations prove the quantification precision to be in the range of inter-user variability. To the best of our knowledge this is the first time a patient-specific model of the aortic and mitral valves is automatically estimated from volumetric sequences.",
Novel Delay-Dependent Robust Stability Analysis for Switched Neutral-Type Neural Networks With Time-Varying Delays via SC Technique,"This paper studies a class of new neural networks referred to as switched neutral-type neural networks (SNTNNs) with time-varying delays, which combines switched systems with a class of neutral-type neural networks. The less conservative robust stability criteria for SNTNNs with time-varying delays are proposed by using a new Lyapunov-Krasovskii functional and a novel series compensation (SC) technique. Based on the new functional, SNTNNs with fast-varying neutral-type delay (the derivative of delay is more than one) is first considered. The benefit brought by employing the SC technique is that some useful negative definite elements can be included in stability criteria, which are generally ignored in the estimation of the upper bound of derivative of Lyapunov-Krasovskii functional in literature. Furthermore, the criteria proposed in this paper are also effective and less conservative in switched recurrent neural networks which can be considered as special cases of SNTNNs. The simulation results based on several numerical examples demonstrate the effectiveness of the proposed criteria.","Robust stability,
Neural networks,
Recurrent neural networks,
Delay effects,
Time varying systems,
Hopfield neural networks,
Cellular neural networks,
Delay systems,
Propagation delay,
Very large scale integration"
Design and development of Generation-I silicon based Solid State Transformer,"The Solid State Transformer (SST) is one of the key elements proposed in the National Science Foundation (NSF) Generation-III Engineering Research Center (ERC) “Future Renewable Electric Energy Delivery and Management” (FREEDM) Systems Center. The SST is used to enable active management of distributed renewable energy resources, energy storage devices and loads. In this paper, the Generation-I SST single-phase 20kVA, based on 6.5kV Si-IGBT is proposed for interface with 12kV distribution system voltage. The SST system design parameters, overall system efficiency, high frequency transformer design, dual active bridge converter, auxiliary power supply and gate drives are investigated. Design considerations and experimental results of the prototype SST are reported.","Silicon,
Solid state circuits,
Energy management,
Power engineering and energy,
Engineering management,
Resource management,
Renewable energy resources,
Energy storage,
Frequency conversion,
Bridge circuits"
Dense linear algebra solvers for multicore with GPU accelerators,"Solving dense linear systems of equations is a fundamental problem in scientific computing. Numerical simulations involving complex systems represented in terms of unknown variables and relations between them often lead to linear systems of equations that must be solved as fast as possible. We describe current efforts toward the development of these critical solvers in the area of dense linear algebra (DLA) for multicore with GPU accelerators. We describe how to code/develop solvers to effectively use the high computing power available in these new and emerging hybrid architectures. The approach taken is based on hybridization techniques in the context of Cholesky, LU, and QR factorizations. We use a high-level parallel programming model and leverage existing software infrastructure, e.g. optimized BLAS for CPU and GPU, and LAPACK for sequential CPU processing. Included also are architecture and algorithm-specific optimizations for standard solvers as well as mixed-precision iterative refinement solvers. The new algorithms, depending on the hardware configuration and routine parameters, can lead to orders of magnitude acceleration when compared to the same algorithms on standard multicore architectures that do not contain GPU accelerators. The newly developed DLA solvers are integrated and freely available through the MAGMA library.","Linear algebra,
Multicore processing,
Acceleration,
Iterative algorithms,
Linear accelerators,
Linear systems,
Equations,
Computer architecture,
Scientific computing,
Numerical simulation"
Three-Dimensional Analysis of Retinal Layer Texture: Identification of Fluid-Filled Regions in SD-OCT of the Macula,"Optical coherence tomography (OCT) is becoming one of the most important modalities for the noninvasive assessment of retinal eye diseases. As the number of acquired OCT volumes increases, automating the OCT image analysis is becoming increasingly relevant. In this paper, a method for automated characterization of the normal macular appearance in spectral domain OCT (SD-OCT) volumes is reported together with a general approach for local retinal abnormality detection. Ten intraretinal layers are first automatically segmented and the 3-D image dataset flattened to remove motion-based artifacts. From the flattened OCT data, 23 features are extracted in each layer locally to characterize texture and thickness properties across the macula. The normal ranges of layer-specific feature variations have been derived from 13 SD-OCT volumes depicting normal retinas. Abnormalities are then detected by classifying the local differences between the normal appearance and the retinal measures in question. This approach was applied to determine footprints of fluid-filled regions-SEADs (Symptomatic Exudate-Associated Derangements)-in 78 SD-OCT volumes from 23 repeatedly imaged patients with choroidal neovascularization (CNV), intra-, and sub-retinal fluid and pigment epithelial detachment. The automated SEAD footprint detection method was validated against an independent standard obtained using an interactive 3-D SEAD segmentation approach. An area under the receiver-operating characteristic curve of 0.961 ? 0.012 was obtained for the classification of vertical, cross-layer, macular columns. A study performed on 12 pairs of OCT volumes obtained from the same eye on the same day shows that the repeatability of the automated method is comparable to that of the human experts. This work demonstrates that useful 3-D textural information can be extracted from SD-OCT scans and-together with an anatomical atlas of normal retinas-can be used for clinically important applications.",
Hardware accelerated convolutional neural networks for synthetic vision systems,"In this paper we present a scalable hardware architecture to implement large-scale convolutional neural networks and state-of-the-art multi-layered artificial vision systems. This system is fully digital and is a modular vision engine with the goal of performing real-time detection, recognition and segmentation of mega-pixel images. We present a performance comparison between a software, FPGA and ASIC implementation that shows a speed up in custom hardware implementations.","Neural network hardware,
Acceleration,
Neural networks,
Machine vision,
Artificial neural networks,
Computer architecture,
Large-scale systems,
Multi-layer neural network,
Engines,
Real time systems"
"Unfreezing the robot: Navigation in dense, interacting crowds","In this paper, we study the safe navigation of a mobile robot through crowds of dynamic agents with uncertain trajectories. Existing algorithms suffer from the “freezing robot” problem: once the environment surpasses a certain level of complexity, the planner decides that all forward paths are unsafe, and the robot freezes in place (or performs unnecessary maneuvers) to avoid collisions. Since a feasible path typically exists, this behavior is suboptimal. Existing approaches have focused on reducing the predictive uncertainty for individual agents by employing more informed models or heuristically limiting the predictive covariance to prevent this overcautious behavior. In this work, we demonstrate that both the individual prediction and the predictive uncertainty have little to do with the frozen robot problem. Our key insight is that dynamic agents solve the frozen robot problem by engaging in “joint collision avoidance”: They cooperatively make room to create feasible trajectories. We develop IGP, a nonparametric statistical model based on dependent output Gaussian processes that can estimate crowd interaction from data. Our model naturally captures the non-Markov nature of agent trajectories, as well as their goal-driven navigation. We then show how planning in this model can be efficiently implemented using particle based inference. Lastly, we evaluate our model on a dataset of pedestrians entering and leaving a building, first comparing the model with actual pedestrians, and find that the algorithm either outperforms human pedestrians or performs very similarly to the pedestrians. We also present an experiment where a covariance reduction method results in highly overcautious behavior, while our model performs desirably.",
Sampling-based motion planning with temporal goals,"This paper presents a geometry-based, multi-layered synergistic approach to solve motion planning problems for mobile robots involving temporal goals. The temporal goals are described over subsets of the workspace (called propositions) using temporal logic. A multi-layered synergistic framework has been proposed recently for solving planning problems involving significant discrete structure. In this framework, a high-level planner uses a discrete abstraction of the system and the exploration information to suggest feasible high-level plans. A low-level sampling-based planner uses the physical model of the system, and the suggested high-level plans, to explore the state-space for feasible solutions. In this paper, we advocate the use of geometry within the above framework to solve motion planning problems involving temporal goals. We present a technique to construct the discrete abstraction using the geometry of the obstacles and the propositions defined over the workspace. Furthermore, we show through experiments that the use of geometry results in significant computational speedups compared to previous work. Traces corresponding to trajectories of the system are defined employing the sampling interval used by the low-level algorithm. The applicability of the approach is shown for second-order nonlinear robot models in challenging workspace environments with obstacles, and for a variety of temporal logic specifications.","Motion planning,
Computational geometry,
Logic,
Vehicle dynamics,
Robotics and automation,
USA Councils,
Mobile robots,
Sampling methods,
Solid modeling,
Sun"
"Genetics-Based Machine Learning for Rule Induction: State of the Art, Taxonomy, and Comparative Study","The classification problem can be addressed by numerous techniques and algorithms which belong to different paradigms of machine learning. In this paper, we are interested in evolutionary algorithms, the so-called genetics-based machine learning algorithms. In particular, we will focus on evolutionary approaches that evolve a set of rules, i.e., evolutionary rule-based systems, applied to classification tasks, in order to provide a state of the art in this field. This paper has a double aim: to present a taxonomy of the genetics-based machine learning approaches for rule induction, and to develop an empirical analysis both for standard classification and for classification with imbalanced data sets. We also include a comparative study of the genetics-based machine learning (GBML) methods with some classical non-evolutionary algorithms, in order to observe the suitability and high potential of the search performed by evolutionary algorithms and the behavior of the GBML algorithms in contrast to the classical approaches, in terms of classification accuracy.","Machine learning,
Taxonomy,
Machine learning algorithms,
Evolutionary computation,
Knowledge based systems,
Computer science,
Artificial intelligence,
Classification tree analysis,
Knowledge representation,
Standards development"
Year,,
Feedback Linearization Control of Three-Phase UPS Inverter Systems,"In this paper, a feedback linearization technique is proposed to control the output voltage control of three-phase uninterruptible power supply systems. First, a nonlinear model including the output LC filters is derived from the power balance condition between the inverter output terminal and the load side. Then, input-output feedback linearization is applied to the nonlinear model to make it linear. The controller of the linearized model is designed by linear control theory. The tracking control law is obtained with a pole placement technique. It is shown experimentally that the proposed control scheme gives high dynamic responses in response to load variation as well as a zero steady-state error.",
Semantics-Preserving Bag-of-Words Models and Applications,"The Bag-of-Words (BoW) model is a promising image representation technique for image categorization and annotation tasks. One critical limitation of existing BoW models is that much semantic information is lost during the codebook generation process, an important step of BoW. This is because the codebook generated by BoW is often obtained via building the codebook simply by clustering visual features in Euclidian space. However, visual features related to the same semantics may not distribute in clusters in the Euclidian space, which is primarily due to the semantic gap between low-level features and high-level semantics. In this paper, we propose a novel scheme to learn optimized BoW models, which aims to map semantically related features to the same visual words. In particular, we consider the distance between semantically identical features as a measurement of the semantic gap, and attempt to learn an optimized codebook by minimizing this gap, aiming to achieve the minimal loss of the semantics. We refer to such kind of novel codebook as semantics-preserving codebook (SPC) and the corresponding model as the Semantics-Preserving Bag-of-Words (SPBoW) model. Extensive experiments on image annotation and object detection tasks with public testbeds from MIT's Labelme and PASCAL VOC challenge databases show that the proposed SPC learning scheme is effective for optimizing the codebook generation process, and the SPBoW model is able to greatly enhance the performance of the existing BoW model.","Image retrieval,
Research and development,
Image storage,
Image segmentation,
Image representation,
Loss measurement,
Particle measurements,
Object detection,
Testing,
Image databases"
Unobtrusive and Ubiquitous In-Home Monitoring: A Methodology for Continuous Assessment of Gait Velocity in Elders,"Gait velocity has been shown to quantitatively estimate risk of future hospitalization, a predictor of disability, and has been shown to slow prior to cognitive decline. In this paper, we describe a system for continuous and unobtrusive in-home assessment of gait velocity, a critical metric of function. This system is based on estimating walking speed from noisy time and location data collected by a ¿sensor line¿ of restricted view passive infrared motion detectors. We demonstrate the validity of our system by comparing with measurements from the commercially available GAITRite walkway system gait mat. We present the data from 882 walks from 27 subjects walking at three different subject-paced speeds (encouraged to walk slowly, normal speed, or fast) in two directions through a sensor line. The experimental results show that the uncalibrated system accuracy (average error) of estimated velocity was 7.1 cm/s (SD = 11.3 cm/s), which improved to 1.1 cm/s (SD = 9.1 cm/s) after a simple calibration procedure. Based on the average measured walking speed of 102 cm/s, our system had an average error of less than 7% without calibration and 1.1% with calibration.",
Upsampling range data in dynamic environments,"We present a flexible method for fusing information from optical and range sensors based on an accelerated high-dimensional filtering approach. Our system takes as input a sequence of monocular camera images as well as a stream of sparse range measurements as obtained from a laser or other sensor system. In contrast with existing approaches, we do not assume that the depth and color data streams have the same data rates or that the observed scene is fully static. Our method produces a dense, high-resolution depth map of the scene, automatically generating confidence values for every interpolated depth point. We describe how to integrate priors on object motion and appearance and how to achieve an efficient implementation using parallel processing hardware such as GPUs.",
Multi-View Video Summarization,"Previous video summarization studies focused on monocular videos, and the results would not be good if they were applied to multi-view videos directly, due to problems such as the redundancy in multiple views. In this paper, we present a method for summarizing multi-view videos. We construct a spatio-temporal shot graph and formulate the summarization problem as a graph labeling task. The spatio-temporal shot graph is derived from a hypergraph, which encodes the correlations with different attributes among multi-view video shots in hyperedges. We then partition the shot graph and identify clusters of event-centered shots with similar contents via random walks. The summarization result is generated through solving a multi-objective optimization problem based on shot importance evaluated using a Gaussian entropy fusion scheme. Different summarization objectives, such as minimum summary length and maximum information coverage, can be accomplished in the framework. Moreover, multi-level summarization can be achieved easily by configuring the optimization parameters. We also propose the multi-view storyboard and event board for presenting multi-view summaries. The storyboard naturally reflects correlations among multi-view summarized shots that describe the same important event. The event-board serially assembles event-centered multi-view shots in temporal order. Single video summary which facilitates quick browsing of the summarized multi-view video can be easily generated based on the event board representation.",
Crowd-sourced sensing and collaboration using twitter,"Despite the availability of the sensor and smart-phone devices to fulfill the ubiquitous computing vision, the-state-of-the-art falls short of this vision. We argue that the reason for this gap is the lack of an infrastructure to task/utilize these devices for collaboration. We propose that microblogging services like Twitter can provide an ""open"" publish-subscribe infrastructure for sensors and smartphones, and pave the way for ubiquitous crowd-sourced sensing and collaboration applications. We design and implement a crowd-sourced sensing and collaboration system over Twitter, and showcase our system in the context of two applications: a crowd-sourced weather radar, and a participatory noise-mapping application. Our results from real-world Twitter experiments give insights into the feasibility of this approach and outline the research challenges in sensor/smartphone integration to Twitter.",
Exponential Stabilization of Neural Networks With Various Activation Functions and Mixed Time-Varying Delays,"This paper presents some results on the global exponential stabilization for neural networks with various activation functions and time-varying continuously distributed delays. Based on augmented time-varying Lyapunov-Krasovskii functionals, new delay-dependent conditions for the global exponential stabilization are obtained in terms of linear matrix inequalities. A numerical example is given to illustrate the feasibility of our results.",
Completely stale transmitter channel state information is still very useful,"Transmitter channel state information (CSIT) is crucial for the multiplexing gains offered by advanced interference management techniques such as multiuser MIMO and interference alignment. Such CSIT is usually obtained by feedback from the receivers, but the feedback is subject to delays. The usual approach is to use the fed back information to predict the current channel state and then apply a scheme designed assuming perfect CSIT. When the feedback delay is large compared to the channel coherence time, such a prediction approach completely fails to achieve any multiplexing gain. In this paper, we show that even in this case, the completely stale CSI is still very useful. More concretely, we showed that in a MIMO broadcast channel with K transmit antennas and K receivers each with 1 receive antenna, equation (> 1) degrees of freedom is achievable even when the fed back channel state is completely independent of the current channel state. Moreover, we establish that if all receivers have identically distributed channels, then this is the optimal number of degrees of freedom achievable. In the optimal scheme, the transmitter uses the fed back CSI to learn the side information that the receivers receive from previous transmissions rather than to predict the current channel state. Our result can be viewed as the first example of feedback providing a degree-of-freedom gain in memoryless channels.","Equations,
Receiving antennas,
Delay,
Multiplexing,
Transmitting antennas"
TODA: Truthful Online Double Auction for Spectrum Allocation in Wireless Networks,"The spectrum usage by a secondary user often happens in a certain geographical region and in a certain time interval, and the requests often come in an online fashion. Considering the selfish behaviors of primary users and secondary users, it is imperative to design online double spectrum auction methods. The most significant challenge is how to make the online double auction economic-robust (truthful in particular). Unfortunately, existing designs either do not consider the online requests or become untruthful when applied to scenarios when both primary users and secondary users could be selfish. In this paper, we address this problem by proposing TODA, a general framework for truthful online double auction for spectrum allocation. We assume that there is a central auctioneer, and the arrivals of secondary users' requests follow Poisson distribution. Upon receiving online spectrum requests, the central auctioneer will decide immediately which secondary and primary users will win the auction, and match winning primary users and secondary users, as well as decide how much secondary users should pay and primary users should get. To preempt existing spectrum usage is not allowed. We study the case in which the conflict graph of secondary users is a complete graph, which occurs in the urban area where the distribution of the secondary users is very dense. In this case, we design strategyproof (truthful) mechanisms for both the primary users and secondary users. To the best of our knowledge, we are the first to design truthful online double auction mechanisms for spectrum allocation. Our simulation results show that the expected social efficiency ratio of our mechanism is always above 80% compared with the off-line VCG mechanism and the spectrum utilization ratio is around 70% when the system is highly loaded.","Wireless networks,
Radio spectrum management,
FCC,
Paper technology,
Computer science,
USA Councils,
White spaces,
Communications Society,
Computer applications,
Urban areas"
Linear and Nonlinear Projective Nonnegative Matrix Factorization,"A variant of nonnegative matrix factorization (NMF) which was proposed earlier is analyzed here. It is called projective nonnegative matrix factorization (PNMF). The new method approximately factorizes a projection matrix, minimizing the reconstruction error, into a positive low-rank matrix and its transpose. The dissimilarity between the original data matrix and its approximation can be measured by the Frobenius matrix norm or the modified Kullback-Leibler divergence. Both measures are minimized by multiplicative update rules, whose convergence is proven for the first time. Enforcing orthonormality to the basic objective is shown to lead to an even more efficient update rule, which is also readily extended to nonlinear cases. The formulation of the PNMF objective is shown to be connected to a variety of existing NMF methods and clustering approaches. In addition, the derivation using Lagrangian multipliers reveals the relation between reconstruction and sparseness. For kernel principal component analysis (PCA) with the binary constraint, useful in graph partitioning problems, the nonlinear kernel PNMF provides a good approximation which outperforms an existing discretization approach. Empirical study on three real-world databases shows that PNMF can achieve the best or close to the best in clustering. The proposed algorithm runs more efficiently than the compared NMF methods, especially for high-dimensional data. Moreover, contrary to the basic NMF, the trained projection matrix can be readily used for newly coming samples and demonstrates good generalization.","Principal component analysis,
Kernel,
Clustering algorithms,
Convergence,
Feature extraction,
Time measurement,
Lagrangian functions,
Databases,
Partitioning algorithms,
Signal processing algorithms"
Internet Economics: The Use of Shapley Value for ISP Settlement,"Within the current Internet, autonomous ISPs implement bilateral agreements, with each ISP establishing agreements that suit its own local objective to maximize its profit. Peering agreements based on local views and bilateral settlements, while expedient, encourage selfish routing strategies and discriminatory interconnections. From a more global perspective, such settlements reduce aggregate profits, limit the stability of routes, and discourage potentially useful peering/connectivity arrangements, thereby unnecessarily balkanizing the Internet. We show that if the distribution of profits is enforced at a global level, then there exist profit-sharing mechanisms derived from the coalition games concept of Shapley value and its extensions that will encourage these selfish ISPs who seek to maximize their own profits to converge to a Nash equilibrium. We show that these profit-sharing schemes exhibit several fairness properties that support the argument that this distribution of profits is desirable. In addition, at the Nash equilibrium point, the routing and connecting/peering strategies maximize aggregate network profits and encourage ISP connectivity so as to limit balkanization.","Internet,
Routing,
Aggregates,
Nash equilibrium,
Joining processes,
Telecommunication traffic,
Computer science,
Stability,
IP networks"
Plastic Surgery: A New Dimension to Face Recognition,"Advancement and affordability is leading to the popularity of plastic surgery procedures. Facial plastic surgery can be reconstructive to correct facial feature anomalies or cosmetic to improve the appearance. Both corrective as well as cosmetic surgeries alter the original facial information to a large extent thereby posing a great challenge for face recognition algorithms. The contribution of this research is 1) preparing a face database of 900 individuals for plastic surgery, and 2) providing an analytical and experimental underpinning of the effect of plastic surgery on face recognition algorithms. The results on the plastic surgery database suggest that it is an arduous research challenge and the current state-of-art face recognition algorithms are unable to provide acceptable levels of identification performance. Therefore, it is imperative to initiate a research effort so that future face recognition systems will be able to address this important problem.",
Performance Analysis of IEEE 802.15.4 Beacon-Enabled Mode,"In this paper, a mathematical model for the beacon-enabled mode of the IEEE 802.15.4 medium-access control (MAC) protocol is provided. A personal area network (PAN) composed of multiple nodes, which transmit data to a PAN coordinator through direct links or multiple hops, is considered. The application is query based: Upon reception of the beacon transmitted by the PAN coordinator, each node tries to transmit its packet using the superframe structure defined by the IEEE 802.15.4 protocol. Those nodes that do not succeed in accessing the channel discard the packet; at the next superframe, a new packet is generated. The aim of the paper is to develop a flexible mathematical tool able to study beacon-enabled 802.15.4 networks organized in different topologies. Both the contention access period (CAP) and the contention-free period defined by the standard are considered. The slotted carrier-sense multiple access with collision avoidance (CSMA/CA) algorithm used in the CAP portion of the superframe is analytically modeled. The model describes the probability of packet successful reception and access delay statistics. Moreover, both star and tree-based topologies are dealt with; a suitable comparison between these topologies is provided. The model is a useful tool for the design of MAC parameters and to select the better topology. The mathematical model is validated through simulation results. The model differs from those previously published by other authors in the literature as it precisely follows the MAC procedure defined by the standard in the context of the application scenario described.",
Cell phone-based biometric identification,"Mobile devices are becoming increasingly sophisticated and now incorporate many diverse and powerful sensors. The latest generation of smart phones is especially laden with sensors, including GPS sensors, vision sensors (cameras), audio sensors (microphones), light sensors, temperature sensors, direction sensors (compasses), and acceleration sensors. In this paper we describe and evaluate a system that uses phone-based acceleration sensors, called accelerometers, to identify and authenticate cell phone users. This form of behavioral biométrie identification is possible because a person's movements form a unique signature and this is reflected in the accelerometer data that they generate. To implement our system we collected accelerometer data from thirty-six users as they performed normal daily activities such as walking, jogging, and climbing stairs, aggregated this time series data into examples, and then applied standard classification algorithms to the resulting data to generate predictive models. These models either predict the identity of the individual from the set of thirty-six users, a task we call user identification, or predict whether (or not) the user is a specific user, a task we call user authentication. This work is notable because it enables identification and authentication to occur unobtrusively, without the users taking any extra actions-all they need to do is carry their cell phones. There are many uses for this work. For example, in environments where sharing may take place, our work can be used to automatically customize a mobile device to a user. It can also be used to provide device security by enabling usage for only specific users and can provide an extra level of identity verification.","Authentication,
Accelerometers,
Accuracy,
Aggregates,
Intelligent sensors,
Temperature sensors"
A Nonparametric Feature Extraction and Its Application to Nearest Neighbor Classification for Hyperspectral Image Data,"Feature extraction plays an essential role in hyperspectral image classification. Nonparametric feature extraction algorithms have more advantages than parametric ones and are well suited for nonnormally distributed data along with being able to extract more features than the classic linear discriminant analysis. In this paper, a novel nonparametric feature extraction method, namely, cosine-based nonparametric feature extraction (CNFE), is proposed, in which the weight function embedded in the within-class and between-class scatter matrices is developed based on cosine distance. Moreover, a powerful K-nearest neighbor (KNN) classification algorithm based on the distance metric formed by CNFE features is also developed, which is called the CNFE-based KNN (CKNN) classifier. The effectiveness of the proposed CNFE and CKNN is evaluated by two hyperspectral real data sets. The experimental results demonstrate that both the proposed CNFE and CKNN achieve remarkable performances on various types of training sample sizes, including the small-sample-size cases.","Feature extraction,
Nearest neighbor searches,
Hyperspectral imaging,
Neural networks,
Data mining,
Linear discriminant analysis,
Computer science,
Image classification,
Scattering,
Classification algorithms"
A Type-2 Fuzzy Ontology and Its Application to Personal Diabetic-Diet Recommendation,"It has been widely pointed out that classical ontology is not sufficient to deal with imprecise and vague knowledge for some real-world applications like personal diabetic-diet recommendation. On the other hand, fuzzy ontology can effectively help to handle and process uncertain data and knowledge. This paper proposes a novel ontology model, which is based on interval type-2 fuzzy sets (T2FSs), called type-2 fuzzy ontology (T2FO), with applications to knowledge representation in the field of personal diabetic-diet recommendation. The T2FO is composed of 1) a type-2 fuzzy personal profile ontology ( type-2 FPPO); 2) a type-2 fuzzy food ontology ( type-2 FFO); and 3) a type-2 fuzzy-personal food ontology (type-2 FPFO). In addition, the paper also presents a T2FS-based intelligent diet-recommendation agent ( IDRA), including 1) T2FS construction; 2) a T2FS-based personal ontology filter; 3) a T2FS-based fuzzy inference mechanism; 4) a T2FS-based diet-planning mechanism; 5) a T2FS-based menu-recommendation mechanism; and 6) a T2FS-based semantic-description mechanism. In the proposed approach, first, the domain experts plan the diet goal for the involved diabetes and create the nutrition facts of common Taiwanese food. Second, the involved diabetics are requested to routinely input eaten items. Third, the ontology-creating mechanism constructs a T2FO, including a type-2 FPPO, a type-2 FFO, and a set of type-2 FPFOs. Finally, the T2FS-based IDRA retrieves the built T2FO to recommend a personal diabetic meal plan. The experimental results show that the proposed approach can work effectively and that the menu can be provided as a reference for the involved diabetes after diet validation by domain experts.","Ontologies,
Diabetes,
Fuzzy sets,
Intelligent agent,
Sugar,
Insulin,
Knowledge representation,
Computer science,
Delta modulation,
Fluids and secretions"
An Energy-Efficient Subthreshold Level Converter in 130-nm CMOS,"This brief presents a fast energy-efficient level converter capable of converting an input signal from subthreshold voltages up to the nominal supply voltage. Measured results from a 130-nm test chip show robust conversion from 188 mV to 1.2 V with no intermediate supplies required. A combination of circuit methods makes the converter robust to the large variations in the current characteristics of subthreshold circuits. To support dynamic voltage scaling, the level converter can upconvert an input at any voltage within this range to 1.2 V.","Energy efficiency,
Dynamic voltage scaling,
MOS devices,
Robustness,
Threshold voltage,
Circuit topology,
Voltage measurement,
Semiconductor device measurement,
Circuit testing,
Monitoring"
Linear Programming Algorithms for Sparse Filter Design,"In designing discrete-time filters, the length of the impulse response is often used as an indication of computational cost. In systems where the complexity is dominated by arithmetic operations, the number of nonzero coefficients in the impulse response may be a more appropriate metric to consider instead, and computational savings are realized by omitting arithmetic operations associated with zero-valued coefficients. This metric is particularly relevant to the design of sensor arrays, where a set of array weights with many zero-valued entries allows for the elimination of physical array elements, resulting in a reduction of data acquisition and communication costs. However, designing a filter with the fewest number of nonzero coefficients subject to a set of frequency-domain constraints is a computationally difficult optimization problem. This paper describes several approximate polynomial-time algorithms that use linear programming to design filters having a small number of nonzero coefficients, i.e., filters that are sparse. Specifically, we present two approaches that have different computational complexities in terms of the number of required linear programs. The first technique iteratively thins the impulse response of a non-sparse filter until frequency-domain constraints are violated. The second minimizes the 1-norm of the impulse response of the filter, using the resulting design to determine the coefficients that are constrained to zero in a subsequent re-optimization stage. The algorithms are evaluated within the contexts of array design and acoustic equalization.","Linear programming,
Nonlinear filters,
Algorithm design and analysis,
Sensor arrays,
Arithmetic,
Iterative algorithms,
Computational efficiency,
Data acquisition,
Costs,
Constraint optimization"
A Robust Object Segmentation System Using a Probability-Based Background Extraction Algorithm,"A video-based monitoring system must be capable of continuous operation under various weather and illumination conditions. Moreover, background subtraction is a very important part of surveillance applications for successful segmentation of objects from video sequences, and the accuracy, computational complexity, and memory requirements of the initial background extraction are crucial in any background subtraction method. This paper proposes an algorithm to extract initial color backgrounds from surveillance videos using a probability-based background extraction algorithm. With the proposed algorithm, the initial background can be extracted accurately and quickly, while using relatively little memory. The intrusive objects can then be segmented quickly and correctly by a robust object segmentation algorithm. The segmentation algorithm analyzes the threshold values of the background subtraction from the prior frame to obtain good quality while minimizing execution time and maximizing detection accuracy. The color background images can be extracted efficiently and quickly from color image sequences and updated in real time to overcome any variation in illumination conditions. Experimental results for various environmental sequences and a quantitative evaluation are provided to demonstrate the robustness, accuracy, effectiveness, and memory economy of the proposed algorithm.","Robustness,
Object segmentation,
Lighting,
Surveillance,
Image segmentation,
Condition monitoring,
Video sequences,
Computational complexity,
Algorithm design and analysis,
Color"
An Adaptive Multiagent Approach to Protection Relay Coordination With Distributed Generators in Industrial Power Distribution System,"This paper presents new explorations into the use of agent technology applied to the protection coordination of power systems. The impact of distributed generators on protection coordination is first discussed. Then, a coordination multiagent system is proposed with the functions of the agents described. In the proposed system, communication will play an important role to provide more information for the relay coordination besides the relay settings. Communication simulation has been carried out on the Java Agent Development Framework platform. The information communication process shows that adaptive coordination can be achieved.","Power system protection,
Power system relaying,
Protective relaying,
Distributed power generation,
Power generation,
Power distribution,
Power system simulation,
Industrial power systems,
Multiagent systems,
Java"
"Adaptive Voltage Control With Distributed Energy Resources: Algorithm, Theoretical Analysis, Simulation, and Field Test Verification","Distributed energy resources (DE) or distributed generators (DG) with power electronics interfaces and logic control using local measurements are capable of providing reactive power related ancillary system services. In particular, local voltage regulation has drawn much attention in regards to power system reliability and voltage stability, especially from past major cascading outages. This paper addresses the challenges of controlling DEs to regulate local voltage in distribution systems. An adaptive voltage control method has been proposed to dynamically modify control parameters to respond to system changes. Theoretical analysis shows that there exists a corresponding formulation of the dynamic control parameters; hence the adaptive control method is theoretically solid. Both simulation and field experiment test results at the Distributed Energy Communications and Controls (DECC) Laboratory confirm that this method is capable of satisfying the fast response requirement for operational use without causing oscillation, inefficiency, or system equipment interference. Since this method has a high tolerance to real-time data shortage and is widely adaptive to variable power system operational situations, it is quite suitable for broad utility application.",
Centered Hyperspherical and Hyperellipsoidal One-Class Support Vector Machines for Anomaly Detection in Sensor Networks,"Anomaly detection in wireless sensor networks is an important challenge for tasks such as intrusion detection and monitoring applications. This paper proposes two approaches to detecting anomalies from measurements from sensor networks. The first approach is a linear programming-based hyperellipsoidal formulation, which is called a centered hyperellipsoidal support vector machine (CESVM). While this CESVM approach has advantages in terms of its flexibility in the selection of parameters and the computational complexity, it has limited scope for distributed implementation in sensor networks. In our second approach, we propose a distributed anomaly detection algorithm for sensor networks using a one-class quarter-sphere support vector machine (QSSVM). Here a hypersphere is found that captures normal data vectors in a higher dimensional space for each sensor node. Then summary information about the hyperspheres is communicated among the nodes to arrive at a global hypersphere, which is used by the sensors to identify any anomalies in their measurements. We show that the CESVM and QSSVM formulations can both achieve high detection accuracies on a variety of real and synthetic data sets. Our evaluation of the distributed algorithm using QSSVM reveals that it detects anomalies with comparable accuracy and less communication overhead than a centralized approach.","Support vector machines,
Intrusion detection,
Wireless sensor networks,
Permission,
Fault diagnosis,
Condition monitoring,
Linear programming,
Computer networks,
Detection algorithms,
Computer science"
Emergency Services in Future Intelligent Transportation Systems Based on Vehicular Communication Networks,"Over the years, we have harnessed the power of computing to improve the speed of operations and increase in productivity. Also, we have witnessed the merging of computing and telecommunications. This excellent combination of two important fields has propelled our capability even further, allowing us to communicate anytime and anywhere, improving our work flow and increasing our quality of life tremendously. The next wave of evolution we foresee is the convergence of telecommunication, computing, wireless, and transportation technologies. Once this happens, our roads and highways will be both our communications and transportation platforms, which will completely revolutionize when and how we access services and entertainment, how we communicate, commute, navigate, etc., in the coming future. This paper presents an overview of the current state-of-the-art, discusses current projects, their goals, and finally highlights how emergency services and road safety will evolve with the blending of vehicular communication networks with road transportation.","Vehicles,
Safety,
Road safety,
Driver circuits,
Europe"
A 60-GHz OOK Receiver With an On-Chip Antenna in 90 nm CMOS,"A low power 60-GHz on-off-keying (OOK) receiver has been implemented in a commercial 90 nm RF CMOS process. By employing a novel on-chip antenna together with architecture optimization, the receiver achieves a sensitivity of -47 dBm at a bit-error rate (BER) of less than 10-3. Using a commercial transmitter with transmit power of 1.5 dBm, a transmission distance of 5 cm can be achieved at 1.2 Gbps data rate. In this design, the on-chip antenna minimizes the packaging loss, while energy detection at RF allows architecture simplification. Both techniques contribute to the receiver's low power consumption of 51 mW, excluding test buffers. This leads to a bit energy efficiency of 28 pj/bit at 1.8 Gbps. The total die area is 3.8 mm2 with the on-chip antenna occupying almost half of it.","Detectors,
Receivers,
System-on-a-chip,
Transistors,
Antennas,
Integrated circuit modeling,
CMOS integrated circuits"
Cooperative Recovery of Distributed Storage Systems from Multiple Losses with Network Coding,"This paper studies the recovery from multiple node failures in distributed storage systems. We design a mutually cooperative recovery (MCR) mechanism for multiple node failures. Via a cut-based analysis of the information flow graph, we obtain a lower bound of maintenance bandwidth based on MCR. For MCR, we also propose a transmission scheme and design a linear network coding scheme based on (¿, ¿) strong-MDS code, which is a generalization of (¿, ¿) MDS code. We prove that the maintenance bandwidth based on our transmission and coding schemes matches the lower bound, so the lower bound is tight and the transmission scheme and coding scheme for MCR are optimal. We also give numerical comparisons of MCR with other redundancy recovery mechanisms in storage cost and maintenance bandwidth to show the advantage of MCR.",
Validation of in-water 3D radiative transfer using DIRSIG,"Sensor reaching radiance in coastal ocean-water environments contains contributions from the air-water interface, in-water objects, and the participating volume itself. If rendered by a forward-modeling synthetic image generation program, the imagery must account for several interesting phenomenon, including, but not limited to; volumetric scattering, shadows, skyfraction, background reflections, and capillary and gravity wave glints and caustics. DIRSIG models the radiative transfer process in this complex environment using a combination of sophisticated raytracing and photon mapping techniques. This research illustrates a subset of our validation efforts associated with the forward radiometric modeling process used by DIRSIG when rendering coastal environments with significant contributions from in-water objects. The results exemplify DIRSIG's ability to render spectrally independent (elastic) and radiometrically accurate hyperspectral imagery of participating media.","Photonics,
Sea measurements,
Scattering,
Surface waves,
Predictive models,
Computational modeling,
Rendering (computer graphics)"
Decentralized Sparse Signal Recovery for Compressive Sleeping Wireless Sensor Networks,"This paper develops an optimal decentralized algorithm for sparse signal recovery and demonstrates its application in monitoring localized phenomena using energy-constrained large-scale wireless sensor networks. Capitalizing on the spatial sparsity of localized phenomena, compressive data collection is enforced by turning off a fraction of sensors using a simple random node sleeping strategy, which conserves sensing energy and prolongs network lifetime. In the absence of a fusion center, sparse signal recovery via decentralized in-network processing is developed, based on a consensus optimization formulation and the alternating direction method of multipliers. In the proposed algorithm, each active sensor monitors and recovers its local region only, collaborates with its neighboring active sensors through low-power one-hop communication, and iteratively improves the local estimates until reaching the global optimum. Because each sensor monitors the local region rather than the entire large field, the iterative algorithm converges fast, in addition to being scalable in terms of transmission and computation costs. Further, through collaboration, the sensing performance is globally optimal and attains a high spatial resolution commensurate with the node density of the original network containing both active and inactive sensors. Simulations demonstrate the performance of the proposed approach.","Wireless sensor networks,
Iterative algorithms,
Monitoring,
Large-scale systems,
Turning,
Sensor phenomena and characterization,
Signal processing,
Optimization methods,
International collaboration,
Computational efficiency"
People tracking with human motion predictions from social forces,"For many tasks in populated environments, robots need to keep track of current and future motion states of people. Most approaches to people tracking make weak assumptions on human motion such as constant velocity or acceleration. But even over a short period, human behavior is more complex and influenced by factors such as the intended goal, other people, objects in the environment, and social rules. This motivates the use of more sophisticated motion models for people tracking especially since humans frequently undergo lengthy occlusion events. In this paper, we consider computational models developed in the cognitive and social science communities that describe individual and collective pedestrian dynamics for tasks such as crowd behavior analysis. In particular, we integrate a model based on a social force concept into a multi-hypothesis target tracker. We show how the refined motion predictions translate into more informed probability distributions over hypotheses and finally into a more robust tracking behavior and better occlusion handling. In experiments in indoor and outdoor environments with data from a laser range finder, the social force model leads to more accurate tracking with up to two times fewer data association errors.",
Sequential Compressed Sensing,"Compressed sensing allows perfect recovery of sparse signals (or signals sparse in some basis) using only a small number of random measurements. Existing results in compressed sensing literature have focused on characterizing the achievable performance by bounding the number of samples required for a given level of signal sparsity. However, using these bounds to minimize the number of samples requires a priori knowledge of the sparsity of the unknown signal, or the decay structure for near-sparse signals. Furthermore, there are some popular recovery methods for which no such bounds are known. In this paper, we investigate an alternative scenario where observations are available in sequence. For any recovery method, this means that there is now a sequence of candidate reconstructions. We propose a method to estimate the reconstruction error directly from the samples themselves, for every candidate in this sequence. This estimate is universal in the sense that it is based only on the measurement ensemble, and not on the recovery method or any assumed level of sparsity of the unknown signal. With these estimates, one can now stop observations as soon as there is reasonable certainty of either exact or sufficiently accurate reconstruction. They also provide a way to obtain ¿run-time¿ guarantees for recovery methods that otherwise lack a priori performance bounds. We investigate both continuous (e.g., Gaussian) and discrete (e.g., Bernoulli) random measurement ensembles, both for exactly sparse and general near-sparse signals, and with both noisy and noiseless measurements.","Compressed sensing,
Image reconstruction,
Noise measurement,
Gaussian noise,
Magnetic resonance imaging,
Signal processing,
Runtime,
Military computing,
Costs,
Reconstruction algorithms"
A 64 Channel Programmable Closed-Loop Neurostimulator With 8 Channel Neural Amplifier and Logarithmic ADC,"This paper describes a neurostimulation IC for use in advanced closed-loop neurostimulation applications, such as deep brain stimulation (DBS) for treatment and research of neurological disorders including Parkinson's disease. This system senses and filters neural activity with eight pre-amplifiers, a 200 kS/s 8-bit log ADC and digital filters and incorporates 64 programmable current-stimulation channels. The entire device, implemented in 0.18 μm CMOS, occupies 2.7 mm2 and consumes 89 μW in normal operation mode and 271 μW in configuration mode from a 1.8 V supply.",
Characterization of Metamorphic GaAsP/Si Materials and Devices for Photovoltaic Applications,"GaAsyP1-y anion-sublattice compositionally graded buffers and device structures were grown directly on Si(100) substrates by way of a high-quality GaP integration layer, yielding GaAsP target layers having band gaps of photovoltaic interest (1.65-1.8 eV), free of antiphase domains/borders, stacking faults, and microtwins. GaAsyP1-y growths on both Si and GaP substrates were compared via high-resolution X-ray diffractometry of the metamorphic buffers and deep-level transient spectroscopy (DLTS) of p+-n diodes that are lattice matched to the final buffer layer. Structural analysis indicates highly efficient epitaxial relaxation throughout the entire growth structure for both types of samples and suggests no significant difference in physical behavior between the two types of samples. DLTS measurements performed on GaAsP diodes fabricated on both Si and GaP substrates reveal the existence of identical sets of traps residing in the n-type GaAsP layers in both types of samples: a single majority carrier (electron) trap, which is located at EC - 0.18&nbsp;eV, and a single minority carrier (hole) trap, which is located at EV + 0.71&nbsp;eV. Prototype 1.75-eV GaAsP solar cell test devices grown on GaAsyP1-y/Si buffers show good preliminary performance characteristics and offer great promise for future high-efficiency III-V photovoltaics integrated with Si substrates and devices.","Silicon,
Substrates,
Lattices,
Photovoltaic cells,
Gallium arsenide,
Monolithic integrated circuits,
Epitaxial growth"
How Wireless Power Charging Technology Affects Sensor Network Deployment and Routing,"As wireless power charging technology emerges, some basic principles in sensor network design are changed accordingly. Existing sensor node deployment and data routing strategies cannot exploit wireless charging technology to minimize overall energy consumption. Hence, in this paper, we (a) investigate the impact of wireless charging technology on sensor network deployment and routing arrangement, (b) formalize the deployment and routing problem, (c) prove it as NP-complete, (d) develop heuristic algorithms to solve the problem, and (e) evaluate the performance of the solutions through extensive simulations. To the best of our knowledge, this is the first effort on adapting sensor network design to leverage wireless charging technology.","Wireless sensor networks,
Routing,
Energy consumption,
Monitoring,
Costs,
Acoustic sensors,
Photovoltaic cells,
Sensor systems,
Computer science,
Receiving antennas"
A Review of Active Appearance Models,"Active appearance model (AAM) is a powerful generative method for modeling deformable objects. The model decouples the shape and the texture variations of objects, which is followed by an efficient gradient-based model fitting method. Due to the flexible and simple framework, AAM has been widely applied in the fields of computer vision. However, difficulties are met when it is applied to various practical issues, which lead to a lot of prominent improvements to the model. Nevertheless, these difficulties and improvements have not been studied systematically. This motivates us to review the recent advances of AAM. This paper focuses on the improvements in the literature in turns of the problems suffered by AAM in practical applications. Therefore, these algorithms are summarized from three aspects, i.e., efficiency, discrimination, and robustness. Additionally, some applications and implementations of AAM are also enumerated. The main purpose of this paper is to serve as a guide for further research.","Active appearance model,
Deformable models,
Principal component analysis,
Active shape model,
Biomedical optical imaging,
Image analysis,
Image segmentation,
Real time systems,
Power generation,
Computer vision"
"A Printed, Broadband Luneburg Lens Antenna","The design of a 2D broadband, Luneburg lens antenna implemented using printed circuit board techniques is detailed. The refractive index of the lens is controlled through a combination of meandering crossed microstrip lines and varying their widths. The 12.4λ° diameter lens is designed to operate in the transverse electromagnetic (TEM) mode at 13 GHz. The lens antenna was designed, fabricated, and measured. The measured half power beamwidth of the experimental antenna is 4.34°.",
Mapping Displacement and Deformation of the Heart With Local Sine-Wave Modeling,"The new SinMod method extracts motion from magnetic resonance imaging (MRI)-tagged (MRIT) image sequences. Image intensity in the environment of each pixel is modeled as a moving sine wavefront. Displacement is estimated at subpixel accuracy. Performance is compared with the harmonic-phase analysis (HARP) method, which is currently the most common method used to detect motion in MRIT images. SinMod can handle line tags, as well as speckle patterns. In artificial images (tag distance six pixels), SinMod detects displacements accurately (error < pixels). Effects of noise are suppressed effectively. Sharp transitions in motion at the boundary of an object are smeared out over a width of 0.6 tag distance. For MRIT images of the heart, SinMod appears less sensitive to artifacts, especially later in the cardiac cycle when image quality deteriorates. For each pixel, the quality of the sine-wave model in describing local image intensity is quantified objectively. If local quality is low, artifacts are avoided by averaging motion over a larger environment. Summarizing, SinMod is just as fast as HARP, but it performs better with respect to accuracy of displacement detection, noise reduction, and avoidance of artifacts.","Heart,
Deformable models,
Pixel,
Magnetic resonance imaging,
Image sequences,
Harmonic analysis,
Image analysis,
Image motion analysis,
Magnetic analysis,
Performance analysis"
A Compositional and Dynamic Model for Face Aging,"In this paper, we present a compositional and dynamic model for face aging. The compositional model represents faces in each age group by a hierarchical And-or graph, in which And nodes decompose a face into parts to describe details (e.g., hair, wrinkles, etc.) crucial for age perception and Or nodes represent large diversity of faces by alternative selections. Then a face instance is a transverse of the And-or graph-parse graph. Face aging is modeled as a Markov process on the parse graph representation. We learn the parameters of the dynamic model from a large annotated face data set and the stochasticity of face aging is modeled in the dynamics explicitly. Based on this model, we propose a face aging simulation and prediction algorithm. Inversely, an automatic age estimation algorithm is also developed under this representation. We study two criteria to evaluate the aging results using human perception experiments: (1) the accuracy of simulation: whether the aged faces are perceived of the intended age group, and (2) preservation of identity: whether the aged faces are perceived as the same person. Quantitative statistical analysis validates the performance of our aging model and age estimation algorithm.",
Voronoi coverage of non-convex environments with a group of networked robots,This paper presents a solution to decentralized Voronoi coverage in non-convex polygonal environments. We show that complications arise when existing approaches to Voronoi coverage are applied for deploying a group of robots in non-convex environments. We present an algorithm that is guaranteed to converge to a local optimum. Our algorithm combines classical Voronoi coverage with the Lloyd algorithm and the local path planning algorithm TangentBug to compute the motion of the robots around obstacles and corners. We present the algorithm and prove convergence and optimality. We also discuss experimental results from an implementation with five robots.,"Robot kinematics,
Robot sensing systems,
Laboratories,
Robotics and automation,
Convergence,
Multirobot systems,
Distributed computing,
USA Councils,
Path planning,
Monitoring"
Energy Efficient State Estimation With Wireless Sensors Through the Use of Predictive Power Control and Coding,"We study state estimation via wireless sensors over fading channels. Packet loss probabilities depend upon time-varying channel gains, packet lengths and transmission power levels of the sensors. Measurements are coded into packets by using either independent coding or distributed zero-error coding. At the gateway, a time-varying Kalman filter uses the received packets to provide the state estimates. To trade sensor energy expenditure for state estimation accuracy, we develop a predictive control algorithm which, in an online fashion, determines the transmission power levels and codebooks to be used by the sensors. To further conserve sensor energy, the controller is located at the gateway and sends coarsely quantized power increment commands, only whenever deemed necessary. Simulations based on real channel measurements illustrate that the proposed method gives excellent results.","Energy efficiency,
State estimation,
Wireless sensor networks,
Power control,
Fading,
Propagation losses,
Time-varying channels,
Actuators,
Sockets,
Capacitive sensors"
Face Verification Across Age Progression Using Discriminative Methods,"Face verification in the presence of age progression is an important problem that has not been widely addressed. In this paper, we study the problem by designing and evaluating discriminative approaches. These directly tackle verification tasks without explicit age modeling, which is a hard problem by itself. First, we find that the gradient orientation, after discarding magnitude information, provides a simple but effective representation for this problem. This representation is further improved when hierarchical information is used, which results in the use of the gradient orientation pyramid (GOP). When combined with a support vector machine GOP demonstrates excellent performance in all our experiments, in comparison with seven different approaches including two commercial systems. Our experiments are conducted on the FGnet dataset and two large passport datasets, one of them being the largest ever reported for recognition tasks. Second, taking advantage of these datasets, we empirically study how age gaps and related issues (including image quality, spectacles, and facial hair) affect recognition algorithms. We found surprisingly that the added difficulty of verification produced by age gaps becomes saturated after the gap is larger than four years, for gaps of up to ten years. In addition, we find that image quality and eyewear present more of a challenge than facial hair.",
Cooperative Co-evolution for large scale optimization through more frequent random grouping,"In this paper we propose three techniques to improve the performance of one of the major algorithms for large scale continuous global function optimization. Multilevel Cooperative Co-evolution (MLCC) is based on a Cooperative Co-evolutionary framework and employs a technique called random grouping in order to group interacting variables in one subcomponent. It also uses another technique called adaptive weighting for co-adaptation of subcomponents. We prove that the probability of grouping interacting variables in one subcomponent using random grouping drops significantly as the number of interacting variables increases. This calls for more frequent random grouping of variables. We show how to increase the frequency of random grouping without increasing the number of fitness evaluations. We also show that adaptive weighting is ineffective and in most cases fails to improve the quality of found solution, and hence wastes considerable amount of CPU time by extra evaluations of objective function. Finally we propose a new technique for self-adaptation of the subcomponent sizes in CC. We demonstrate how a substantial improvement can be gained by applying these three techniques.",
Statistics-driven workload modeling for the Cloud,"A recent trend for data-intensive computations is to use pay-as-you-go execution environments that scale transparently to the user. However, providers of such environments must tackle the challenge of configuring their system to provide maximal performance while minimizing the cost of resources used. In this paper, we use statistical models to predict resource requirements for Cloud computing applications. Such a prediction framework can guide system design and deployment decisions such as scale, scheduling, and capacity. In addition, we present initial design of a workload generator that can be used to evaluate alternative configurations without the overhead of reproducing a real workload. This paper focuses on statistical modeling and its application to data-intensive workloads.","Cloud computing,
Job shop scheduling,
Databases,
Predictive models,
Processor scheduling,
Large-scale systems,
Resource management,
Computer science,
Costs,
Computer industry"
Tunnel Field Effect Transistor With Raised Germanium Source,"The performance of a tunnel field effect transistor (TFET) with a raised germanium (Ge) source region is investigated via 2-D device simulation with a tunneling model calibrated to experimental data. The comparison of various Ge-source TFET designs shows that a fully elevated Ge-source design provides for the steepest subthreshold swing and, therefore, the largest on-state drive current for low-voltage operation. Mixed-mode (dc and ac) simulations are used to assess the energy-delay performance. In comparison with a MOSFET, an optimized Ge-source TFET is projected to provide for a lower energy per operation for throughput in the frequency range of up to ~1 GHz for sub-0.5-V operation.",
Miniature Internal Penta-Band Monopole Antenna for Mobile Phones,"A compact T-slit monopole antenna with slotted ground plane in the mobile phone for penta-band operation is proposed. In this configuration, the antenna comprises a T-slit monopole printed on the top ungrounded portion of an FR4 substrate of small size of 47 × 5.4 mm2 and a slotted ground plane etched on the back side of the substrate of size of 47 × 10 mm2. In addition, an inverted-L copper strip is soldered to the end edge of the monopole for extending the electrical length of the antenna for GSM band; that is, the proposed antenna occupies a small volume of 47 × 10 × 5 mm3 inside the mobile phone and is suitable to operate as an internal antenna. By controlling the related parameters, the proposed antenna can resonates at different operating bands to cover GSM850/900 and DCS/PCS/UMTS operations independently.","Mobile antennas,
Mobile handsets,
Slot antennas,
Mobile communication,
Etching,
Copper,
GSM,
Resonance,
Printed circuits,
Distributed control"
A Novel Anti-Collision Algorithm in RFID Systems for Identifying Passive Tags,"Radio frequency identification has been developed and used in many applications in the real world. Due to the shared wireless channel between tags and the reader during communication, the tag collision arbitration is a significant issue for reducing the communication overhead. This paper presents a novel anti-collision algorithm named New Enhanced Anti-Collision Algorithm (NEAA) using counters and stack to reduce the probability of collision efficiently and to make it possible to identify multiple passive tags in a timeslot. The upper bound of total timeslots for identifying N passive tags is first derived in this paper; suppose the length of a tag ID is n, the upper bound of total timeslots for identifying N (N= 2n) passive tags is derived to be 2n-1 - n + 4, when n > 2. This bound is quite tight. Compared to the existing methods proposed by other researchers, the performance evaluation shows that the proposed scheme in this paper consumes fewer timeslots and has better performance for identifying tags.","Radiofrequency identification,
Computer science,
RFID tags,
Frequency,
Upper bound,
Computational intelligence,
Prototypes,
Broadcasting,
Counting circuits,
Wireless communication"
Learning to navigate through crowded environments,"The goal of this research is to enable mobile robots to navigate through crowded environments such as indoor shopping malls, airports, or downtown side walks. The key research question addressed in this paper is how to learn planners that generate human-like motion behavior. Our approach uses inverse reinforcement learning (IRL) to learn human-like navigation behavior based on example paths. Since robots have only limited sensing, we extend existing IRL methods to the case of partially observable environments. We demonstrate the capabilities of our approach using a realistic crowd flow simulator in which we modeled multiple scenarios in crowded environments. We show that our planner learned to guide the robot along the flow of people when the environment is crowded, and along the shortest path if no people are around.","Navigation,
Learning,
Cost function,
Mobile robots,
Airports,
Robot sensing systems,
Gaussian processes,
Robotics and automation,
USA Councils,
Computer science"
"Moving From Federated to Integrated Architectures in Automotive: The Role of Standards, Methods and Tools","Cost pressure, flexibility, extensibility and the need for coping with increased functional complexity are changing the fundamental paradigms for the definition of automotive and aeronautics architectures. Traditional designs are based on the concept of a Federated Architecture in which integrated hardware/software components [Electronic Control Units (ECUs)] realize mostly independent or loosely interconnected functions. These components are connected by bus and cooperate by exchanging messages. This paradigm is now being replaced by the Integrated Architecture, - the concept comes from Integrated Modular Avionics (IMA) introduced by the avionics community (see C. B. Watkins and R. Walter, ?Transitioning from federated avionics architectures to integrated modular avionics?, in Proc. 26th Digital Avionics Syst. Conf., Oct. 2007) but it is certainly general and applicable to other fields and in particular, automotive - in which software components can be supplied from multiple sources, integrated on the same hardware platform or physically distributed and possibly moved from one CPU to another without loss of functional and time correctness and providing a guaranteed level of reliability. This shift will decouple software design from the hardware platform design and provide opportunities for the optimization of the architecture configuration, increased extensibility, flexibility and modularity. However, the integration of software components in a distributed system realizing a complex functional behavior and characterized by safety, time and reliability constraints requires a much tighter control on the component model and its semantics, new methods and tools for analyzing the results of the composition, whether by simulation or formal methods, and methods for exploring the architecture solution space and optimizing the configuration. We provide a general overview of existing challenges and possible solutions to the design and analysis problem, with special focus on the automotive domain. The development of such methods and tools must necessarily consider compatibility with existing modeling languages and standards, including UML, AUTOSAR and synchronous reactive models, on which the widely used commercial products Simulink and SCADE are based.","Automotive engineering,
Aerospace electronics,
Computer architecture,
Hardware,
Software safety,
Cost function,
Software design,
Design optimization,
Software tools,
Time factors"
Authenticated Group Key Transfer Protocol Based on Secret Sharing,"Key transfer protocols rely on a mutually trusted key generation center (KGC) to select session keys and transport session keys to all communication entities secretly. Most often, KGC encrypts session keys under another secret key shared with each entity during registration. In this paper, we propose an authenticated key transfer protocol based on secret sharing scheme that KGC can broadcast group key information to all group members at once and only authorized group members can recover the group key; but unauthorized users cannot recover the group key. The confidentiality of this transformation is information theoretically secure. We also provide authentication for transporting this group key. Goals and security threats of our proposed group key transfer protocol will be analyzed in detail.","Protocols,
Cryptography,
Authentication,
DH-HEMTs,
Polynomials,
Servers"
Cognitive infocommunications: CogInfoCom,"In recent years, considerable amount of research has been dedicated to the integration of artificial cognitive functionalities into informatics. With the immense growth in volume of cognitive content handled by both artificial and natural cognitive systems, the scientific treatment of new and efficient communication forms between such cognitive systems is inevitable. In this paper, we provide the first definition of cognitive infocommunications, a multidisciplinary field which aims to expand the information space between communicating cognitive systems (artificial or otherwise). Following this definition, we specify the modes and types of communication which make up cognitive infocommunications. Through a number of examples, we describe what is expected from this new discipline in further detail.","Robot sensing systems,
Humans,
Media,
Cognitive informatics,
Teleoperators"
PCE: Piecewise Convex Endmember Detection,"A new hyperspectral endmember detection method that represents endmembers as distributions, autonomously partitions the input data set into several convex regions, and simultaneously determines endmember distributions (EDs) and proportion values for each convex region is presented. Spectral unmixing methods that treat endmembers as distributions or hyperspectral images as piecewise convex data sets have not been previously developed. Piecewise convex endmember (PCE) detection can be viewed in two parts. The first part, the ED detection algorithm, estimates a distribution for each endmember rather than estimating a single spectrum. By using EDs, PCE can incorporate an endmember's inherent spectral variation and the variation due to changing environmental conditions. ED uses a new sparsity-promoting polynomial prior while estimating abundance values. The second part of PCE partitions the input hyperspectral data set into convex regions and estimates EDs and proportions for each of these regions. The number of convex regions is determined autonomously using the Dirichlet process. PCE is effective at handling highly mixed hyperspectral images where all of the pixels in the scene contain mixtures of multiple endmembers. Furthermore, each convex region found by PCE conforms to the convex geometry model for hyperspectral imagery. This model requires that the proportions associated with a pixel be nonnegative and sum to one. Algorithm results on hyperspectral data indicate that PCE produces endmembers that represent the true ground-truth classes of the input data set. The algorithm can also effectively represent endmembers as distributions, thus incorporating an endmember's spectral variability.","Hyperspectral imaging,
Solid modeling,
Pixel,
Layout,
Geometry,
Detection algorithms,
Government,
Lakes,
Polynomials,
Military computing"
"Fundamentals of Large Sensor Networks: Connectivity, Capacity, Clocks, and Computation","Sensor networks potentially feature large numbers of nodes. The nodes can monitor and sense their environment over time, communicate with each other over a wireless network, and process information that they exchange with each other. They differ from data networks in that the network as a whole may be designed for a specific application. We study the theoretical foundations of such large-scale sensor networks. We address four fundamental organizational and operational issues related to large sensor networks: connectivity, capacity, clocks, and function computation. To begin with, a sensor network must be connected so that information can indeed be exchanged between nodes. The connectivity graph of an ad hoc network is modeled as a random graph and the critical range for asymptotic connectivity is determined, as well as the critical number of neighbors that a node needs to connect to. Next, given connectivity, we address the issue of how much data can be transported over the sensor network. We present fundamental bounds on capacity under several models, as well as architectural implications for how wireless communication should be organized. Temporal information is important both for the applications of sensor networks as well as their operation. We present fundamental bounds on the synchronizability of clocks in networks, and also present and analyze algorithms for clock synchronization. Finally, we turn to the issue of gathering relevant information, which sensor networks are designed to do. One needs to study optimal strategies for in-network aggregation of data, in order to reliably compute a composite function of sensor measurements, as well as the complexity of doing so. We address the issue of how such computation can be performed efficiently in a sensor network and the algorithms for doing so, for some classes of functions.","Wireless sensor networks,
Wireless networks,
Interference,
Clocks,
Ad hoc networks,
Synchronization"
Future internet: The Internet of Things,"Nowadays, the main communication form on the Internet is human-human. But it is foreseeable that in a near soon that any object will have a unique way of identification and can be addressed so that every object can be connected. The Internet will become to the Internet of Things. The communicate forms will expand from human-human to human-human, human-thing and thing-thing (also called M2M).This will bring a new ubiquitous computing and communication era and change people's life extremely. Radio Frequency Identification techniques (RFID) and related identification technologies will be the cornerstones of the upcoming Internet of Things (IOT).This paper aims to show a skeleton of the Internet of Things and we try to address some essential issues of the Internet of Things like its architecture and the interoperability, etc. At the beginning we describe an overview of the Internet of Things. Then we give our architecture design proposal of the Internet of Things and then we design a specific the Internet of Things application model which can apply to automatic facilities management in the smart campus. At last, we discuss some open questions about the Internet of Things.","Logic gates,
Artificial intelligence,
Computer architecture,
Geology,
Educational institutions,
IEEE 802.11 Standards"
Harmony potentials for joint classification and segmentation,"Hierarchical conditional random fields have been successfully applied to object segmentation. One reason is their ability to incorporate contextual information at different scales. However, these models do not allow multiple labels to be assigned to a single node. At higher scales in the image, this yields an oversimplified model, since multiple classes can be reasonable expected to appear within one region. This simplified model especially limits the impact that observations at larger scales may have on the CRF model. Neglecting the information at larger scales is undesirable since class-label estimates based on these scales are more reliable than at smaller, noisier scales. To address this problem, we propose a new potential, called harmony potential, which can encode any possible combination of class labels. We propose an effective sampling strategy that renders tractable the underlying optimization problem. Results show that our approach obtains state-of-the-art results on two challenging datasets: Pascal VOC 2009 and MSRC-21.","Image classification,
Image segmentation,
Pixel,
Computer science,
Object segmentation,
Image sampling,
Rendering (computer graphics),
Histograms,
Image representation,
Acoustic noise"
IPv6 in Low-Power Wireless Networks,"With deeply embedded wireless sensors, a new tier of the Internet is emerging that will extend into the physical world. These wireless sensor nodes are expected to vastly outnumber conventional computer hosts as we see them today, but their strict resource constraints are unlike other technologies already common to the Internet. As wireless sensor network research took off, many in the field eschewed the use of IP as inadequate and in contradiction to the needs of wireless sensor networking. Since then, the field has matured and IP has evolved. In this paper, we show that the convergence of Internet Protocol Version 6 (IPv6) and low-power multihop wireless networking is possible, pragmatic, and efficient-especially in regard to the metrics that matter most for embedded applications, low memory footprint, high reliability, and low energy usage. Using real commercial deployments, we show that it is possible to simultaneously achieve an average duty cycle of <; 0.4%, average message delivery rate of > 99.9%, and average per-hop latency of <; 125 ms over 12 months in different environments.","IP networks,
Internet,
Routing protocols,
Wireless sensor networks,
Ad hoc networks,
Ethernet networks"
ECG Signal Compression and Classification Algorithm With Quad Level Vector for ECG Holter System,"An ECG signal processing method with quad level vector (QLV) is proposed for the ECG holter system. The ECG processing consists of the compression flow and the classification flow, and the QLV is proposed for both flows to achieve better performance with low-computation complexity. The compression algorithm is performed by using ECG skeleton and the Huffman coding. Unit block size optimization, adaptive threshold adjustment, and 4-bit-wise Huffman coding methods are applied to reduce the processing cost while maintaining the signal quality. The heartbeat segmentation and the R-peak detection methods are employed for the classification algorithm. The performance is evaluated by using the Massachusetts Institute of Technology-Boston's Beth Israel Hospital Arrhythmia Database, and the noise robust test is also performed for the reliability of the algorithm. Its average compression ratio is 16.9:1 with 0.641% percentage root mean square difference value and the encoding rate is 6.4 kbps. The accuracy performance of the R-peak detection is 100% without noise and 95.63% at the worst case with -10-dB SNR noise. The overall processing cost is reduced by 45.3% with the proposed compression techniques.",
The Emergence of Intelligent Enterprises: From CPS to CPSS,"When IEEE Intelligent Systems solicited ideas for a new department, cyberphysical systems(CPS) received overwhelming support.Cyber-Physical-Social Systems is the new name for CPS. CPSS is the enabling platform technology that will lead us to an era of intelligent enterprises and industries. Internet use and cyberspace activities have created an overwhelming demand for the rapid development and application of CPSS. CPSS must be conducted with a multidisciplinary approach involving the physical, social, and cognitive sciences and that Al-based intelligent systems will be key to any successful construction and deployment.",
Controller for Urban Intersections Based on Wireless Communications and Fuzzy Logic,"A major research topic in intelligent transportation systems (ITSs) is the development of systems that will be capable of controlling the flow of vehicular traffic through crossroads, particularly in urban environments. This could significantly reduce traffic jams, since autonomous vehicles would be capable of calculating the optimal speed to maximize the number of cars driving through the intersection. We describe the use of vehicle-to-vehicle (V2V) communications to determine the position and speed of the vehicles in an environment around a crossroad. These data are used to estimate the intersection point, and a fuzzy controller then modifies the speed of the cars without right of way according to the speed of the car with right of way. Experimental tests conducted with two mass-produced cars on a real circuit at the facilities of the Instituto de Automa¿tica Industrial, Consejo Superior de Investigaciones Cienti¿ficas, Madrid, Spain, gave excellent results.","Communication system control,
Wireless communication,
Fuzzy logic,
Communication system traffic control,
Intelligent transportation systems,
Remotely operated vehicles,
Circuit testing,
Intelligent vehicles,
Control systems,
Vehicle driving"
Evolutionary Trajectory Planner for Multiple UAVs in Realistic Scenarios,"This paper presents a path planner for multiple unmanned aerial vehicles (UAVs) based on evolutionary algorithms (EAs) for realistic scenarios. The paths returned by the algorithm fulfill and optimize multiple criteria that 1) are calculated based on the properties of real UAVs, terrains, radars, and missiles and 2) are structured in different levels of priority according to the selected mission. The paths of all the UAVs are obtained with the multiple coordinated agents coevolution EA (MCACEA), which is a general framework that uses an EA per agent (i.e., UAV) that share their optimal solutions to coordinate the evolutions of the EAs populations using cooperation objectives. This planner works offline and online by means of recalculating parts of the original path to avoid unexpected risks while the UAV is flying. Its search space and computation time have been reduced using some special operators in the EAs. The successful results of the paths obtained in multiple scenarios, which are statistically analyzed in the paper, and tested against a simulator that incorporates complex models of the UAVs, radars, and missiles, make us believe that this planner could be used for real-flight missions.","Unmanned aerial vehicles,
Evolutionary computation,
Mobile robots,
Radar,
Missiles,
Path planning,
Remotely operated vehicles,
Constraint optimization,
Testing,
Computational modeling"
Networked Synchronization Control of Coupled Dynamic Networks With Time-Varying Delay,"This paper is concerned with the networked synchronization control problem of coupled dynamic networks (CDNs) with time-varying delay. First, both the data packet dropouts and network-induced delays are taken into account in the synchronization controller design. A Markovian jump process is induced to describe the packet dropouts. The network-induced delays are interval time varying and depend on the Markovian jump modes. A new closed-loop coupled dynamic error system (CDES) with Markovian jump parameters and interval time-varying delays is constructed. Second, using the Kronecker product technique and the stochastic Lyapunov method, a delay-dependent sufficient criterion of stochastic stability is obtained for the closed-loop CDES, which also guarantees that the CDNs are stochastically synchronized. Finally, a simulation example is given to demonstrate the effectiveness of the proposed result.","Communication system control,
Stochastic processes,
Neural networks,
Control systems,
Sufficient conditions,
Linear matrix inequalities,
Information science,
Networked control systems,
Delay effects,
Time varying systems"
GPGPU-Aided Ensemble Empirical-Mode Decomposition for EEG Analysis During Anesthesia,"Ensemble empirical-mode decomposition (EEMD) is a novel adaptive time-frequency analysis method, which is particularly suitable for extracting useful information from noisy nonlinear or nonstationary data. Unfortunately, since the EEMD is highly compute-intensive, the method does not apply in real-time applications on top of commercial-off-the-shelf computers. Aiming at this problem, a parallelized EEMD method has been developed using general-purpose computing on the graphics processing unit (GPGPU), namely, G-EEMD. A spectral entropy facilitated by G-EEMD was, therefore, proposed to analyze the EEG data for estimating the depth of anesthesia (DoA) in a real-time manner. In terms of EEG data analysis, G-EEMD has dramatically improved the run-time performance by more than 140 times compared to the original serial EEMD implementation. G-EEMD also performs far better than another parallelized implementation of EEMD bases on conventional CPU-based distributed computing technology despite the latter utilizes 16 high-end computing nodes for the same computing task. Furthermore, the results obtained from a pharmacokinetics/pharmacodynamic (PK/PD) model analysis indicate that the EEMD method is slightly more effective than its precedent alternative method (EMD) in estimating DoA, the coefficient of determination R2 by EEMD is significantly higher than that by EMD (p <; 0.05, paired Mest) and the prediction probability Pk by EEMD is also slighter higher than that by EMD (p <; 0.2, paired t-test).","Electroencephalography,
Entropy,
Instruction sets,
Graphics processing unit,
Distributed computing,
Anesthesia"
Experimental study on the impact of vehicular obstructions in VANETs,"Channel models for vehicular networks typically disregard the effect of vehicles as physical obstructions for the wireless signal. We aim to clarify the validity of this simplification by quantifying the impact of obstructions through a series of wireless experiments. Using two cars equipped with Dedicated Short Range Communications (DSRC) hardware designed for vehicular use, we perform experimental measurements in order to collect received signal power and packet delivery ratio information in a multitude of relevant scenarios: parking lot, highway, suburban and urban canyon. Upon separating the data into line of sight (LOS) and non-line of sight (NLOS) categories, our results show that obstructing vehicles cause significant impact on the channel quality. A single obstacle can cause a drop of over 20 dB in received signal strength when two cars communicate at a distance of 10 m. At longer distances, NLOS conditions affect the usable communication range, effectively halving the distance at which communication can be achieved with 90% chance of success. The presented results motivate the inclusion of vehicles in the radio propagation models used for VANET simulation in order to increase the level of realism.","Vehicles,
Roads,
Antennas,
Ad hoc networks,
Power measurement,
Hardware"
SADV: Static-Node-Assisted Adaptive Data Dissemination in Vehicular Networks,"Vehicular networks have recently attracted great interest in the research community, and multihop data dissemination has become an important issue. To improve data-delivery performance, we propose deploying static nodes at road intersections to help relay data. In this paper, we present SADV, which is a static-node assisted adaptive data-dissemination protocol for vehicular networks. With the assistance of static nodes at intersections, a packet is forwarded to the static node when there are no vehicles available to deliver the packets along the optimal path. The static node is able to store the packet and transmit it when the optimal delivery path becomes available. In addition, we let adjacent static nodes measure the delay of forwarding data between each other in real time so that the routing decision that is made at static nodes can adapt to the changing vehicle densities. Moreover, a multipath routing mechanism is also adopted in SADV, which is effective in reducing the data-delivery delay. Our simulation results show that SADV outperforms other multihop data dissemination protocols, particularly under median or low vehicle density where the network is frequently partitioned. In this paper, we also present some heuristic deployment strategies to maximize SADV performance under partial deployment of static nodes and analyze them by simulations.","Vehicles,
Spread spectrum communication,
Protocols,
Delay effects,
Routing,
Roads,
Relays,
Density measurement,
Performance analysis,
Analytical models"
Detecting the Number of Clusters in n-Way Probabilistic Clustering,"Recently, there has been a growing interest in multiway probabilistic clustering. Some efficient algorithms have been developed for this problem. However, not much attention has been paid on how to detect the number of clusters for the general n-way clustering (n ≥ 2). To fill this gap, this problem is investigated based on n-way algebraic theory in this paper. A simple, yet efficient, detection method is proposed by eigenvalue decomposition (EVD), which is easy to implement. We justify this method. In addition, its effectiveness is demonstrated by the experiments on both simulated and real-world data sets.","Tensile stress,
Eigenvalues and eigenfunctions,
Clustering methods,
Clustering algorithms,
Array signal processing,
Signal processing,
Brain,
Laboratories,
Data processing"
Multi-task warped Gaussian process for personalized age estimation,"Automatic age estimation from facial images has aroused research interests in recent years due to its promising potential for some computer vision applications. Among the methods proposed to date, personalized age estimation methods generally outperform global age estimation methods by learning a separate age estimator for each person in the training data set. However, since typical age databases only contain very limited training data for each person, training a separate age estimator using only training data for that person runs a high risk of overfitting the data and hence the prediction performance is limited. In this paper, we propose a novel approach to age estimation by formulating the problem as a multi-task learning problem. Based on a variant of the Gaussian process (GP) called warped Gaussian process (WGP), we propose a multi-task extension called multi-task warped Gaussian process (MTWGP). Age estimation is formulated as a multi-task regression problem in which each learning task refers to estimation of the age function for each person. While MTWGP models common features shared by different tasks (persons), it also allows task-specific (person-specific) features to be learned automatically. Moreover, unlike previous age estimation methods which need to specify the form of the regression functions or determine many parameters in the functions using inefficient methods such as cross validation, the form of the regression functions in MTWGP is implicitly defined by the kernel function and all its model parameters can be learned from data automatically. We have conducted experiments on two publicly available age databases, FG-NET and MORPH. The experimental results are very promising in showing that MTWGP compares favorably with state-of-the-art age estimation methods.","Gaussian processes,
Aging,
Training data,
Face detection,
Face recognition,
Feature extraction,
Databases,
Kernel,
State estimation,
Pediatrics"
A Probabilistic Approach for Vision-Based Fire Detection in Videos,"Automated fire detection is an active research topic in computer vision. In this paper, we propose and analyze a new method for identifying fire in videos. Computer vision-based fire detection algorithms are usually applied in closed-circuit television surveillance scenarios with controlled background. In contrast, the proposed method can be applied not only to surveillance but also to automatic video classification for retrieval of fire catastrophes in databases of newscast content. In the latter case, there are large variations in fire and background characteristics depending on the video instance. The proposed method analyzes the frame-to-frame changes of specific low-level features describing potential fire regions. These features are color, area size, surface coarseness, boundary roughness, and skewness within estimated fire regions. Because of flickering and random characteristics of fire, these features are powerful discriminants. The behavioral change of each one of these features is evaluated, and the results are then combined according to the Bayes classifier for robust fire recognition. In addition, a priori knowledge of fire events captured in videos is used to significantly improve the classification results. For edited newscast videos, the fire region is usually located in the center of the frames. This fact is used to model the probability of occurrence of fire as a function of the position. Experiments illustrated the applicability of the method.","Fires,
Videos,
Computer vision,
Surveillance,
Detection algorithms,
TV,
Automatic control,
Information retrieval,
Content based retrieval,
Spatial databases"
Building Height Retrieval From VHR SAR Imagery Based on an Iterative Simulation and Matching Technique,"Experimental airborne synthetic aperture radar (SAR) systems achieve spatial resolutions of approximately 10 cm, whereas the new spaceborne very high spatial resolution (VHR) SAR sensors onboard the TerraSAR-X and COSMO-SkyMed satellites achieve spatial resolutions down to 1 m. In VHR SAR data, features from individual urban structures (i.e., buildings) can be identified by their characteristic settings in urban settlement patterns. In this paper, we present a novel concept for the height estimation of generic man-made structures from single detected SAR data. The proposed approach is based on the definition of a hypothesis on the height of the building and on the simulation of a SAR image for testing that hypothesis. A matching procedure is applied between the estimated and the actual SAR image in order to test the height hypothesis. The process is iterated for different height assumptions until the matching function is optimized, and thus, the building height is estimated. The efficiency of the proposed method is demonstrated on a set of 40 flat- and gable-roof buildings using two submeter VHR airborne and two 1-m resolution TerraSAR-X SAR scenes all acquired from the same residential area in Dorsten, Germany. The results show that, in the absence of string disturbing effects, the method is able to estimate the height of flat- and gable-roof buildings in the submeter data to the order of a meter, while the accuracy for the meter resolution spaceborne data is lower but still sufficient to estimate the number of floors of a building.",
Estimating arterial traffic conditions using sparse probe data,"Estimating and predicting traffic conditions in arterial networks using probe data has proven to be a substantial challenge. In the United States, sparse probe data represents the vast majority of the data available on arterial roads in most major urban environments. This article proposes a probabilistic modeling framework for estimating and predicting arterial travel time distributions using sparsely observed probe vehicles. We evaluate our model using data from a fleet of 500 taxis in San Francisco, CA, which send GPS data to our server every minute. The sampling rate does not provide detailed information about where vehicles encountered delay or the reason for any delay (i.e. signal delay, congestion delay, etc.). Our model provides an increase in estimation accuracy of 35% when compared to a baseline approach for processing probe vehicle data.",
Novel Stability Analysis for Recurrent Neural Networks With Multiple Delays via Line Integral-Type L-K Functional,"This paper studies the stability problem of a class of recurrent neural networks (RNNs) with multiple delays. By using an augmented matrix-vector transformation for delays and a novel line integral-type Lyapunov-Krasovskii functional, a less conservative delay-dependent global asymptotical stability criterion is first proposed for RNNs with multiple delays. The obtained stability result is easy to check and improve upon the existing ones. Then, two numerical examples are given to verify the effectiveness of the proposed criterion.","Delay,
Stability criteria,
Asymptotic stability,
Numerical stability,
Recurrent neural networks,
Linear matrix inequalities"
Synthesizing Near-Optimal Malware Specifications from Suspicious Behaviors,"Fueled by an emerging underground economy, malware authors are exploiting vulnerabilities at an alarming rate. To make matters worse, obfuscation tools are commonly available, and much of the malware is open source, leading to a huge number of variants. Behavior-based detection techniques are a promising solution to this growing problem. However, these detectors require precise specifications of malicious behavior that do not result in an excessive number of false alarms. In this paper, we present an automatic technique for extracting optimally discriminative specifications, which uniquely identify a class of programs. Such a discriminative specification can be used by a behavior-based malware detector. Our technique, based on graph mining and concept analysis, scales to large classes of programs due to probabilistic sampling of the specification space. Our implementation, called Holmes, can synthesize discriminative specifications that accurately distinguish between programs, sustaining an 86% detection rate on new, unknown malware, with 0 false positives, in contrast with 55% for commercial signature-based antivirus (AV) and 62-64% for behavior-based AV (commercial or research).","Detectors,
Computer hacking,
Humans,
Computer security,
Privacy,
Computer science,
Sampling methods,
Credit cards,
Internet,
Art"
Building 3-D Statistical Shape Models by Direct Optimization,"Statistical shape models are powerful tools for image interpretation and shape analysis. A simple, yet effective, way of building such models is to capture the statistics of sampled point coordinates over a training set of example shapes. However, a major drawback of this approach is the need to establish a correspondence across the training set. In 2-D, a correspondence is often defined using a set of manually placed ¿landmarks¿ and linear interpolation to sample the shape in between. Such annotation is, however, time-consuming and subjective, particularly when extended to 3-D. In this paper, we show that it is possible to establish a dense correspondence across the whole training set automatically by treating correspondence as an optimization problem. The objective function we use for the optimization is based on the minimum description length principle, which we argue is a criterion that leads to models with good compactness, specificity, and generalization ability. We manipulate correspondence by reparameterizing each training shape. We describe an explicit representation of reparameterization for surfaces in 3-D that makes it impossible to generate an illegal (i.e., not one-to-one) correspondence. We also describe several large-scale optimization strategies for model building, and perform a detailed analysis of each approach. Finally, we derive quantitative measures of model quality, allowing meaningful comparison between models built using different methods. Results are given for several different training sets of 3-D shapes, which show that the minimum description length models perform significantly better than other approaches.","Shape,
Biomedical imaging,
Biomedical engineering,
Councils,
Image analysis,
Statistics,
Interpolation,
Large-scale systems,
Performance analysis,
Biomedical measurements"
Compressed Sensing Performance Bounds Under Poisson Noise,"This paper describes performance bounds for compressed sensing (CS) where the underlying sparse or compressible (sparsely approximable) signal is a vector of nonnegative intensities whose measurements are corrupted by Poisson noise. In this setting, standard CS techniques cannot be applied directly for several reasons. First, the usual signal-independent and/or bounded noise models do not apply to Poisson noise, which is nonadditive and signal-dependent. Second, the CS matrices typically considered are not feasible in real optical systems because they do not adhere to important constraints, such as nonnegativity and photon flux preservation. Third, the typical l2 - l1 minimization leads to overfitting in the high-intensity regions and oversmoothing in the low-intensity areas. In this paper, we describe how a feasible positivity- and flux-preserving sensing matrix can be constructed, and then analyze the performance of a CS reconstruction approach for Poisson data that minimizes an objective function consisting of a negative Poisson log likelihood term and a penalty term which measures signal sparsity. We show that, as the overall intensity of the underlying signal increases, an upper bound on the reconstruction error decays at an appropriate rate (depending on the compressibility of the signal), but that for a fixed signal intensity, the error bound actually grows with the number of measurements or sensors. This surprising fact is both proved theoretically and justified based on physical intuition.","Compressed sensing,
Optical noise,
Image reconstruction,
Optical imaging,
Optical sensors,
Optical computing,
Optical arrays,
Noise measurement,
Signal analysis,
Performance analysis"
Filtered Multitensor Tractography,"We describe a technique that uses tractography to drive the local fiber model estimation. Existing techniques use independent estimation at each voxel so there is no running knowledge of confidence in the estimated model fit. We formulate fiber tracking as recursive estimation: at each step of tracing the fiber, the current estimate is guided by those previous. To do this we perform tractography within a filter framework and use a discrete mixture of Gaussian tensors to model the signal. Starting from a seed point, each fiber is traced to its termination using an unscented Kalman filter to simultaneously fit the local model to the signal and propagate in the most consistent direction. Despite the presence of noise and uncertainty, this provides a causal estimate of the local structure at each point along the fiber. Using two- and three-fiber models we demonstrate in synthetic experiments that this approach significantly improves the angular resolution at crossings and branchings. In vivo experiments confirm the ability to trace through regions known to contain such crossing and branching while providing inherent path regularization.","Magnetic resonance imaging,
Image analysis,
Neuro imaging"
Data-Driven Service Composition in Enterprise SOA Solutions: A Petri Net Approach,"Under Service Oriented Architecture (SOA), service composition is used to integrate service components together to meet new business needs. In this paper, we propose a novel data-driven method to provide service composition guidance to implement given requirements. Based on the relations between business domain data and service domain data, we generate additional data mediations according to three composition rules. With these data relations and composition rules, we propose a Petri-net based approach to the composition of services. In our approach, all the in/output messages of the service operations are modeled as colored places, and service operations themselves are modeled as transitions with input/output places. We first generate a Service Net (SN) that contains all operations in a given service portfolio, and then use Petri-net decomposition techniques to derive a subnet of SN, and this subnet meets the need of the business requirement. Our work can be seen as an effort to bridge the gap between business and service domains.",
Correcting Charge-Constrained Errors in the Rank-Modulation Scheme,"We investigate error-correcting codes for a the rank-modulation scheme with an application to flash memory devices. In this scheme, a set of n cells stores information in the permutation induced by the different charge levels of the individual cells. The resulting scheme eliminates the need for discrete cell levels, overcomes overshoot errors when programming cells (a serious problem that reduces the writing speed), and mitigates the problem of asymmetric errors. In this paper, we study the properties of error-correcting codes for charge-constrained errors in the rank-modulation scheme. In this error model the number of errors corresponds to the minimal number of adjacent transpositions required to change a given stored permutation to another erroneous one-a distance measure known as Kendall's ¿ -distance. We show bounds on the size of such codes, and use metric-embedding techniques to give constructions which translate a wealth of knowledge of codes in the Lee metric to codes over permutations in Kendall's ¿-metric. Specifically, the one-error-correcting codes we construct are at least half the ball-packing upper bound.","Error correction,
Flash memory,
Error correction codes,
Nonvolatile memory,
Programming profession,
Upper bound,
Modulation coding,
Electron traps,
Robustness,
Engineering profession"
Hybrid Genetic Algorithm Using a Forward Encoding Scheme for Lifetime Maximization of Wireless Sensor Networks,"Maximizing the lifetime of a sensor network by scheduling operations of sensors is an effective way to construct energy efficient wireless sensor networks. After the random deployment of sensors in the target area, the problem of finding the largest number of disjoint sets of sensors, with every set being able to completely cover the target area, is nondeterministic polynomial-complete. This paper proposes a hybrid approach of combining a genetic algorithm with schedule transition operations, termed STHGA, to address this problem. Different from other methods in the literature, STHGA adopts a forward encoding scheme for chromosomes in the population and uses some effective genetic and sensor schedule transition operations. The novelty of the forward encoding scheme is that the maximum gene value of each chromosome is increased consistently with the solution quality, which relates to the number of disjoint complete cover sets. By exerting the restriction on chromosomes, the forward encoding scheme reflects the structural features of feasible schedules of sensors and provides guidance for further advancement. Complying with the encoding requirements, genetic operations and schedule transition operations in STHGA cooperate to change the incomplete cover set into a complete one, while the other sets still maintain complete coverage through the schedule of redundant sensors in the sets. Applications for sensing a number of target points, termed point-coverage, and for the whole area, termed area-coverage, have been used for evaluating the effectiveness of STHGA. Besides the number of sensors and sensors' sensing ranges, the influence of sensors' redundancy on the performance of STHGA has also been analyzed. Results show that the proposed algorithm is promising and outperforms the other existing approaches by both optimization speed and solution quality.","Genetic algorithms,
Encoding,
Wireless sensor networks,
Biological cells,
Sun,
Sensor phenomena and characterization,
Computer science education,
Surveillance,
Energy efficiency,
Polynomials"
Maximum a Posteriori Video Super-Resolution Using a New Multichannel Image Prior,"Super-resolution (SR) is the term used to define the process of estimating a high-resolution (HR) image or a set of HR images from a set of low-resolution (LR) observations. In this paper we propose a class of SR algorithms based on the maximum a posteriori (MAP) framework. These algorithms utilize a new multichannel image prior model, along with the state-of-the-art single channel image prior and observation models. A hierarchical (two-level) Gaussian nonstationary version of the multichannel prior is also defined and utilized within the same framework. Numerical experiments comparing the proposed algorithms among themselves and with other algorithms in the literature, demonstrate the advantages of the adopted multichannel approach.",
Switching Bilateral Filter With a Texture/Noise Detector for Universal Noise Removal,"In this paper, we propose a switching bilateral filter (SBF) with a texture and noise detector for universal noise removal. Operation was carried out in two stages: detection followed by filtering. For detection, we propose the sorted quadrant median vector (SQMV) scheme, which includes important features such as edge or texture information. This information is utilized to allocate a reference median from SQMV, which is in turn compared with a current pixel to classify it as impulse noise, Gaussian noise, or noise-free. The SBF removes both Gaussian and impulse noise without adding another weighting function. The range filter inside the bilateral filter switches between the Gaussian and impulse modes depending upon the noise classification result. Simulation results show that our noise detector has a high noise detection rate as well as a high classification rate for salt-and-pepper, uniform impulse noise and mixed impulse noise. Unlike most other impulse noise filters, the proposed SBF achieves high peak signal-to-noise ratio and great image quality by efficiently removing both types of mixed noise, salt-and-pepper with uniform noise and salt-and-pepper with Gaussian noise. In addition, the computational complexity of SBF is significantly less than that of other mixed noise filters.","Detectors,
Nonlinear filters,
Gaussian noise,
Additive noise,
PSNR,
Filtering,
Switches,
Image processing,
Computer science,
Pixel"
Semi-Supervised Classification via Local Spline Regression,"This paper presents local spline regression for semi-supervised classification. The core idea in our approach is to introduce splines developed in Sobolev space to map the data points directly to be class labels. The spline is composed of polynomials and Green's functions. It is smooth, nonlinear, and able to interpolate the scattered data points with high accuracy. Specifically, in each neighborhood, an optimal spline is estimated via regularized least squares regression. With this spline, each of the neighboring data points is mapped to be a class label. Then, the regularized loss is evaluated and further formulated in terms of class label vector. Finally, all of the losses evaluated in local neighborhoods are accumulated together to measure the global consistency on the labeled and unlabeled data. To achieve the goal of semi-supervised classification, an objective function is constructed by combining together the global loss of the local spline regressions and the squared errors of the class labels of the labeled data. In this way, a transductive classification algorithm is developed in which a globally optimal classification can be finally obtained. In the semi-supervised learning setting, the proposed algorithm is analyzed and addressed into the Laplacian regularization framework. Comparative classification experiments on many public data sets and applications to interactive image segmentation and image matting illustrate the validity of our method.","Spline,
Semisupervised learning,
Machine learning algorithms,
Iterative algorithms,
Laplace equations,
Image segmentation,
Machine learning,
Labeling,
Web pages,
Polynomials"
Area- and Power-Efficient Monolithic Buck Converters With Pseudo-Type III Compensation,"Monolithic PWM voltage-mode buck converters with a novel Pseudo-Type III (PT3) compensation are presented. The proposed compensation maintains the fast load transient response of the conventional Type III compensator; while the Type III compensator response is synthesized by adding a high-gain low-frequency path (via error amplifier) with a moderate-gain high-frequency path (via bandpass filter) at the inputs of PWM comparator. As such, smaller passive components and low-power active circuits can be used to generate two zeros required in a Type III compensator. Constant Gm/C biasing technique can also be adopted by PT3 to reduce the process variation of passive components, which is not possible in a conventional Type III design. Two prototype chips are fabricated in a 0.35-μm CMOS process with constant Gm/C biasing technique being applied to one of the designs. Measurement result shows that converter output is settled within 7 μs for a load current step of 500 mA. Peak efficiency of 97% is obtained at 360 mW output power, and high efficiency of 86% is measured for output power as low as 60 mW. The area and power consumption of proposed compensator is reduced by > 75 % in both designs, compared to an equivalent conventional Type III compensator.","Buck converters,
Pulse width modulation,
Power generation,
Pulse width modulation converters,
Voltage,
Transient response,
Circuit synthesis,
Band pass filters,
Active circuits,
Filtering theory"
Partial discharge source discrimination using a support vector machine,"Partial discharge (PD) measurements are an important tool for assessing the health of power equipment. Different sources of PD have different effects on the insulation performance of power apparatus. Therefore, discrimination between PD sources is of great interest to both system utilities and equipment manufacturers. This paper investigates the use of a wide bandwidth PD on-line measurement system consisting of a radio frequency current transducer (RFCT) sensor, a digital storage oscilloscope and a high performance personal computer to facilitate automatic PD source identification. Three artificial PD models were used to simulate typical PD sources which may exist within power system apparatus. Wavelet analysis was applied to pre-process measurement data obtained from the wide bandwidth PD sensor. This data was then processed using correlation analysis to cluster the discharges into different groups. A machine learning technique, namely the support vector machine (SVM) was then used to identify between the different PD sources. The SVM is trained to differentiate between the inherent features of each discharge source signal. Laboratory experiments where the trained SVM was tested using measurement data from the RFCT as opposed to conventional measurement data indicate that this approach has a robust performance and has great potential for use with field measurement data.","Partial discharges,
Support vector machines,
Bandwidth,
Power system modeling,
Power system simulation,
Fault location,
Partial discharge measurement,
Power measurement,
Insulation,
Manufacturing"
Bridging the Semantic Gap Between Image Contents and Tags,"With the exponential growth of Web 2.0 applications, tags have been used extensively to describe the image contents on the Web. Due to the noisy and sparse nature in the human generated tags, how to understand and utilize these tags for image retrieval tasks has become an emerging research direction. As the low-level visual features can provide fruitful information, they are employed to improve the image retrieval results. However, it is challenging to bridge the semantic gap between image contents and tags. To attack this critical problem, we propose a unified framework in this paper which stems from a two-level data fusions between the image contents and tags: 1) A unified graph is built to fuse the visual feature-based image similarity graph with the image-tag bipartite graph; 2) A novel random walk model is then proposed, which utilizes a fusion parameter to balance the influences between the image contents and tags. Furthermore, the presented framework not only can naturally incorporate the pseudo relevance feedback process, but also it can be directly applied to applications such as content-based image retrieval, text-based image retrieval, and image annotation. Experimental analysis on a large Flickr dataset shows the effectiveness and efficiency of our proposed framework.",
The Impact of Temperature on Outdoor Industrial Sensornet Applications,"Wireless sensor networks are being considered for use in industrial process and control environments. Unlike traditional deployment scenarios for sensor networks, in which energy preservation is the main design principle, industrial environments stress worker safety and uninterrupted production. To fulfill these requirements, sensor networks must be able to provide performance guarantees for radio communication. In this paper, we consider as a case study the deployment of a sensornet in an oil refinery in Portugal, where sensor nodes are deployed outdoors and might experience high temperature fluctuations. We investigate how the variations of ambient temperature influence data delivery performance and link quality in low-power radio communications. We also study the impact that specific implementation requirements, such as the ATEX fire-safety regulations, can have on the design of the overall network. Our experiments show that temperature directly affects the communication between sensor nodes, and that significantly less transmission power is required at low temperatures. We further illustrate that it is possible to save up to 16% energy during nights and cold periods of the year, while still ensuring reliable communication among sensor nodes. In view of these experimental results, we elaborate on how the temperature influences both the design and the deployment of wireless sensor networks in industrial environments.","Temperature sensors,
Sensor phenomena and characterization,
Industrial control,
Protocols,
Radio communication,
Fluctuations,
Wireless sensor networks,
Process control,
Communication system control,
Oil refineries"
Towards computational models of kinship verification,"We tackle the challenge of kinship verification using novel feature extraction and selection methods, automatically classifying pairs of face images as “related” or “unrelated” (in terms of kinship). First, we conducted a controlled online search to collect frontal face images of 150 pairs of public figures and celebrities, along with images of their parents or children. Next, we propose and evaluate a set of low-level image features for this classification problem. After selecting the most discriminative inherited facial features, we demonstrate a classification accuracy of 70.67% on a test set of image pairs using K-Nearest-Neighbors. Finally, we present an evaluation of human performance on this problem.","Face,
Feature extraction,
Facial features,
Humans,
Accuracy,
Support vector machine classification,
Image color analysis"
Cooperative Communications in Multi-hop Wireless Networks: Joint Flow Routing and Relay Node Assignment,"It has been shown that cooperative communications (CC) have the potential to significantly increase the capacity of wireless networks. However, most of the existing results are limited to single-hop wireless networks. To illustrate the benefits of CC in multi-hop wireless networks, we solve a joint optimization problem of relay node assignment and flow routing for concurrent sessions. We study this problem via mathematical modeling and solve it using a solution procedure based on the branch-and-cut framework. We design several novel components to speed-up the computation time of branch-and-cut. Via numerical results, we show the significant rate gains that can be achieved by incorporating CC in multi-hop networks.","Spread spectrum communication,
Wireless networks,
Routing,
Relays,
Peer to peer computing,
USA Councils,
MIMO,
Communications Society,
Computer science,
Communication industry"
Automatic Fuzzy Clustering Using Modified Differential Evolution for Image Classification,"The problem of classifying an image into different homogeneous regions is viewed as the task of clustering the pixels in the intensity space. In particular, satellite images contain landcover types, some of which cover significantly large areas while some (e.g., bridges and roads) occupy relatively much smaller regions. Automatically detecting regions or clusters of such widely varying sizes is a challenging task. In this paper, a new real-coded modified differential evolution based automatic fuzzy clustering algorithm is proposed which automatically evolves the number of clusters as well as the proper partitioning from a data set. Here, the assignment of points to different clusters is done based on a Xie-Beni index where the Euclidean distance is taken into consideration. The effectiveness of the proposed technique is first demonstrated for two numeric remote sensing data described in terms of feature vectors and then in identifying different landcover regions in remote sensing imagery. The superiority of the new method is demonstrated by comparing it with other existing techniques like automatic clustering using improved differential evolution, classical differential evolution based automatic fuzzy clustering, variable length genetic algorithm based fuzzy clustering, and well known fuzzy C-means algorithm both qualitatively and quantitatively.","Image classification,
Clustering algorithms,
Remote sensing,
Pixel,
Satellites,
Bridges,
Roads,
Fuzzy sets,
Partitioning algorithms,
Euclidean distance"
Efficient Recovery Control Channel Design in Cognitive Radio Ad Hoc Networks,"A constantly available control channel facilitates control message exchange and spectrum coordination in cognitive radio (CR) ad hoc networks. When a dedicated control channel is unavailable, a control channel must be dynamically allocated in licensed channels and vacated for the presence of primary users (PUs). As a result, the establishment of such a control channel is a challenge. In this paper, an efficient recovery control channel (ERCC) design is proposed to address this challenge. This heuristic and distributed design approach is essentially based on the observed spectrum homogeneity in a neighborhood. By adaptively updating a list of channels commonly available to neighbors, each secondary user is able to efficiently establish new control channels among neighbors in response to PU activity changes. Therefore, a virtually “always on” control channel robust to PU activity can be realized by the proposed method. The contributions are summarized as follows: 1) The proposed method efficiently recovers control channels from PU activity changes and maintains network connectivity. 2) It extends the control channel coverage to facilitate broadcast and reduce control overhead and delay. 3) It minimizes the interference with PUs. Simulation results show that the proposed solution outperforms the classic group- and sequence-based solutions in the responsiveness to rapidly changing PU activity and the maintenance of connectivity. Furthermore, the increase in control channel coverage and the allocation of the highest quality channels to control channels can be well balanced with reliability and scalability in various network scenarios.",
Clustering of Vehicle Trajectories,"We present a method that is suitable for clustering of vehicle trajectories obtained by an automated vision system. We combine ideas from two spectral clustering methods and propose a trajectory-similarity measure based on the Hausdorff distance, with modifications to improve its robustness and account for the fact that trajectories are ordered collections of points. We compare the proposed method with two well-known trajectory-clustering methods on a few real-world data sets.","Vehicles,
Transportation,
Computer science,
Principal component analysis,
Robustness,
Layout,
Euclidean distance,
Machine vision,
Clustering methods,
Unsupervised learning"
Antennas and Propagation of Implanted RFIDs for Pervasive Healthcare Applications,"Radio-frequency identification (RFID) is a growing technology, with the potential for reducing medical errors and improving the quality of healthcare in hospitals. The benefits include more secure and safe access in the healthcare environment (with the possibility, for example, to track patients, personnel, and equipment), as well as providing the means to easily identify patients and their medications with low risk of error. In this paper, we present an overview of the challenges faced in antenna design, electromagnetic modeling and wave propagation for RFID implants. The performance of ultra-high-frequency (UHF) subcutaneous tag antennas was investigated numerically and validated with measurements. Furthermore, the wave propagation between an off-body reader and an implanted tag was analyzed, in both free space and a scattered indoor environment. Results demonstrated that a passive tag solution allows a very limited communication range, due to the body losses, the electrically small size of the antenna, and nulls in the radiation pattern. In comparison, a maximum communication range of 10 m was predicted as achievable for an active tag operating indoors with a limited power (-20 dBm).",
Joint Elevation and Azimuth Direction Finding Using L-Shaped Array,"For two-dimensional (2-D) directions-of-arrival (DOA) estimation problem, the L-shaped array seems to have higher accuracy than other structured arrays [see ¿An L-shaped array for estimating 2-D directions of wave arrival¿ by Hua for details], and has received much attention. To estimate elevation and azimuth angles, two correctly matched electric angles (functions of elevation and azimuth angles) are estimated in advance, so that elevation and azimuth angles are obtained from the two correctly matched electric angles. However, the failure in pairing will cause severe performance degradation. In this communication, a novel algorithm, which doesn't require match procedure, is proposed to estimate 2-D DOA in the L-shaped array geometry. The key points of this communication are: i) by introducing a novel electric angle, the steering vector is separated into two parts; ii) the two parts can be obtained in turn by generalized ESPRIT approach and eigenvalue decomposition (EVD) of one particular matrix, respectively; iii) elevation and azimuth angles can be obtained from the recovered steering vector. The resultant algorithm avoids match operation, and requires one-dimensional search once. Simulation results are presented to validate the performance of the proposed method.",
Node-Depth Encoding and Multiobjective Evolutionary Algorithm Applied to Large-Scale Distribution System Reconfiguration,"The power loss reduction in distribution systems (DSs) is a nonlinear and multiobjective problem. Service restoration in DSs is even computationally hard since it additionally requires a solution in real-time. Both DS problems are computationally complex. For large-scale networks, the usual problem formulation has thousands of constraint equations. The node-depth encoding (NDE) enables a modeling of DSs problems that eliminates several constraint equations from the usual formulation, making the problem solution simpler. On the other hand, a multiobjective evolutionary algorithm (EA) based on subpopulation tables adequately models several objectives and constraints, enabling a better exploration of the search space. The combination of the multiobjective EA with NDE (MEAN) results in the proposed approach for solving DSs problems for large-scale networks. Simulation results have shown the MEAN is able to find adequate restoration plans for a real DS with 3860 buses and 632 switches in a running time of 0.68 s. Moreover, the MEAN has shown a sublinear running time in function of the system size. Tests with networks ranging from 632 to 5166 switches indicate that the MEAN can find network configurations corresponding to a power loss reduction of 27.64% for very large networks requiring relatively low running time.",
Detecting Double JPEG Compression With the Same Quantization Matrix,"Detection of double joint photographic experts group (JPEG) compression is of great significance in the field of digital forensics. Some successful approaches have been presented for detecting double JPEG compression when the primary compression and the secondary compression have different quantization matrixes. However, when the primary compression and the secondary compression have the same quantization matrix, no detection method has been reported yet. In this paper, we present a method which can detect double JPEG compression with the same quantization matrix. Our algorithm is based on the observation that in the process of recompressing a JPEG image with the same quantization matrix over and over again, the number of different JPEG coefficients, i.e., the quantized discrete cosine transform coefficients between the sequential two versions will monotonically decrease in general. For example, the number of different JPEG coefficients between the singly and doubly compressed images is generally larger than the number of different JPEG coefficients between the corresponding doubly and triply compressed images. Via a novel random perturbation strategy implemented on the JPEG coefficients of the recompressed test image, we can find a “proper” randomly perturbed ratio. For different images, this universal “proper” ratio will generate a dynamically changed threshold, which can be utilized to discriminate the singly compressed image and doubly compressed image. Furthermore, our method has the potential to detect triple JPEG compression, four times JPEG compression, etc.","Image coding,
Transform coding,
Quantization,
Discrete cosine transforms,
Image reconstruction,
Decoding"
Variational Bayesian Image Restoration With a Product of Spatially Weighted Total Variation Image Priors,"In this paper, a new image prior is introduced and used in image restoration. This prior is based on products of spatially weighted total variations (TV). These spatial weights provide this prior with the flexibility to better capture local image features than previous TV based priors. Bayesian inference is used for image restoration with this prior via the variational approximation. The proposed restoration algorithm is fully automatic in the sense that all necessary parameters are estimated from the data and is faster than previous similar algorithms. Numerical experiments are shown which demonstrate that image restoration based on this prior compares favorably with previous state-of-the-art restoration algorithms.",
Pulsed Eddy-Current Based Giant Magnetoresistive System for the Inspection of Aircraft Structures,"Research in nondestructive evaluation is constantly increasing the sensitivity of detection of small cracks embedded deep in layered aircraft structures. Pulsed eddy-current (PEC) techniques using coil probes have shown considerable promise in detection and characterization of buried cracks in multilayered structures. In this paper, we describe the design and development of a nondestructive inspection system that uses pulse excitation of a planar multiline coil to generate a transient field that is detected via a giant magnetoresistive (GMR) field sensor. An analysis algorithm using features in time and frequency domain processes the experimentally measured signals for automatic detection of small cracks under fasteners in multilayered structures at a depth of up to 10 mm.","Giant magnetoresistance,
Inspection,
Aircraft,
Coils,
Probes,
Pulse generation,
Magnetic sensors,
Sensor phenomena and characterization,
Sensor systems,
Signal analysis"
Information-Theoretic Limits on Sparse Signal Recovery: Dense versus Sparse Measurement Matrices,"We study the information-theoretic limits of exactly recovering the support set of a sparse signal, using noisy projections defined by various classes of measurement matrices. Our analysis is high-dimensional in nature, in which the number of observations n, the ambient signal dimension p, and the signal sparsity k are all allowed to tend to infinity in a general manner. This paper makes two novel contributions. First, we provide sharper necessary conditions for exact support recovery using general (including non-Gaussian) dense measurement matrices. Combined with previously known sufficient conditions, this result yields sharp characterizations of when the optimal decoder can recover a signal for various scalings of the signal sparsity k and sample size n, including the important special case of linear sparsity (k = ¿(p)) using a linear scaling of observations (n = ¿(p)). Our second contribution is to prove necessary conditions on the number of observations n required for asymptotically reliable recovery using a class of ¿-sparsified measurement matrices, where the measurement sparsity parameter ¿(n, p, k) ¿ (0,1] corresponds to the fraction of nonzero entries per row. Our analysis allows general scaling of the quadruplet (n, p, k, ¿) , and reveals three different regimes, corresponding to whether measurement sparsity has no asymptotic effect, a minor effect, or a dramatic effect on the information-theoretic limits of the subset recovery problem.","Sparse matrices,
Signal analysis,
Decoding,
Information analysis,
Statistics,
Computational complexity,
H infinity control,
Sufficient conditions,
Compressed sensing,
Vectors"
Adding Attributes to Role-Based Access Control,Merging the best features of RBAC and attribute-based systems can provide effective access control for distributed and rapidly changing applications.,
An Intrinsic Circuit Model for Multiple Vias in an Irregular Plate Pair Through Rigorous Electromagnetic Analysis,"An irregular plate pair with multiple vias is analyzed by the segmentation method that divides the plate pair into a plate domain and via domains. In the via domains, all the parallel-plate modes are considered, while in the plate domain, only the propagating modes are included to account for the coupling among vias and the reflection from plate edges. Boundary conditions at both vias and plate edges are enforced and all parasitic components of via circuit are expressed analytically in terms of parallel-plate modes. The work presented in this paper indicates that a previous physics-based via circuit model from intuition is a low-frequency approximation. Analytical and numerical simulations, as well as measurements, have been used to validate the intrinsic via circuit model.","Circuits,
Electromagnetic modeling,
Electromagnetic analysis,
Electromagnetic scattering,
Reflection,
Boundary conditions,
Nonhomogeneous media,
Packaging,
Crosstalk,
Power systems"
Estimating Divergence Functionals and the Likelihood Ratio by Convex Risk Minimization,"We develop and analyze M-estimation methods for divergence functionals and the likelihood ratios of two probability distributions. Our method is based on a nonasymptotic variational characterization of f -divergences, which allows the problem of estimating divergences to be tackled via convex empirical risk optimization. The resulting estimators are simple to implement, requiring only the solution of standard convex programs. We present an analysis of consistency and convergence for these estimators. Given conditions only on the ratios of densities, we show that our estimators can achieve optimal minimax rates for the likelihood ratio and the divergence functionals in certain regimes. We derive an efficient optimization algorithm for computing our estimates, and illustrate their convergence behavior and practical viability by simulations.",
Constructions of Cryptographically Significant Boolean Functions Using Primitive Polynomials,"It is known that Boolean functions used in stream and block ciphers should have good cryptographic properties to resist algebraic attacks. Up until now, there have been several constructions of Boolean functions achieving optimum algebraic immunity. However, most of their nonlinearities are very low. Carlet and Feng studied a class of Boolean functions with optimum algebraic immunity and deduced the lower bound of its nonlinearity, which is good, but not very high. Moreover, the main practical problem with this construction is that it cannot be implemented efficiently. In this paper, we put forward a new method to construct cryptographically significant Boolean functions by using primitive polynomials, and construct three infinite classes of Boolean functions with good cryptographic properties: balancedness, optimum algebraic degree, optimum algebraic immunity, and a high nonlinearity.","Cryptography,
Boolean functions,
Polynomials,
Electrical resistance measurement,
Hamming weight,
Resists,
Information processing,
Computer science,
Mathematics,
Table lookup"
Frequency Estimation of Three-Phase Power System Using Weighted-Least-Square Algorithm and Adaptive FIR Filtering,"A new technique for estimation of the instantaneous frequency based on simultaneous sampling of three-phase voltage signals is presented. The structure consists of two decoupled modules: the first is for adaptive filtering of input signals, and the second is for frequency estimation. A suitable and robust algorithm for frequency estimation is obtained. This technique provides better performance, compared with the technique based on a single-phase signal in relation to waveforms with noise. The technique is particularly important when asymmetric sags generate zero voltage in one of the three phases. In addition, it allows the measurement of the instantaneous frequency value of real signals for single- or three-phase systems. To demonstrate the performance of the developed algorithm, computer-simulated data records and calibrator-generated signals are processed. The proposed algorithm has been put to test with distorted three-phase voltage signals.","Finite impulse response filter,
Frequency estimation,
Power systems,
Filtering algorithms,
Adaptive filters,
Voltage fluctuations,
Sampling methods,
Noise robustness,
Distortion measurement,
Frequency measurement"
Transmission completion time minimization in an energy harvesting system,"We consider the transmission completion time minimization problem in a single-user energy harvesting wireless communication system. In this system, both the data packets and the harvested energy are modelled to arrive at the source node randomly. Our goal is to adaptively change the transmission rate according to the traffic load and available energy, such that the transmission completion time is minimized. Under a deterministic system setting, we assume that the energy harvesting times and harvested energy amounts are known before the transmission starts. For the data traffic arrivals, we consider two different scenarios. In the first scenario, we assume that all bits have arrived and are ready at the transmitter before the transmission starts. In the second scenario we consider, packets arrive during the transmissions with known arriving times and sizes. We develop optimal off-line scheduling policies which minimize the overall transmission completion time under causality constraints on both data and energy arrivals.","Delay,
Scheduling algorithm,
Minimization methods,
Educational institutions,
Wireless communication,
Telecommunication traffic,
Transmitters,
Time factors,
Photovoltaic cells,
Absorption"
Automatic Liver Segmentation Using a Statistical Shape Model With Optimal Surface Detection,"In this letter, we present an approach for automatic liver segmentation from computed tomography (CT) scans that is based on a statistical shape model (SSM) integrated with an optimal-surface-detection strategy. The proposed method is a hybrid method that combines three steps. First, we use localization of the average liver shape model in a test CT volume via 3-D generalized Hough transform. Second, we use subspace initialization of the SSM through intensity and gradient profile. Third, we deform the shape model to adapt to liver contour through an optimal-surface-detection approach based on graph theory. The proposed method is evaluated on MICCAI 2007 liver-segmentation challenge datasets. The experiment results demonstrate availability of the proposed method.",
X-Ray Luminescence Computed Tomography via Selective Excitation: A Feasibility Study,"X-ray luminescence computed tomography (XLCT) is proposed as a new molecular imaging modality based on the selective excitation and optical detection of X-ray-excitable phosphor nanoparticles. These nano-sized particles can be fabricated to emit near-infrared (NIR) light when excited with X-rays, and, because because both X-rays and NIR photons propagate long distances in tissue, they are particularly well suited for in vivo biomedical imaging. In XLCT, tomographic images are generated by irradiating the subject using a sequence of programmed X-ray beams, while sensitive photo-detectors measure the light diffusing out of the subject. By restricting the X-ray excitation to a single, narrow beam of radiation, the origin of the optical photons can be inferred regardless of where these photons were detected, and how many times they scattered in tissue. This study presents computer simulations exploring the feasibility of imaging small objects with XLCT, such as research animals. The accumulation of 50 nm phosphor nanoparticles in a 2-mm-diameter target can be detected and quantified with subpicomolar sensitivity using less than 1 cGy of radiation dose. Provided sufficient signal-to-noise ratio, the spatial resolution of the system can be made as high as needed by narrowing the beam aperture. In particular, 1 mm spatial resolution was achieved for a 1-mm-wide X-ray beam. By including an X-ray detector in the system, anatomical imaging is performed simultaneously with molecular imaging via standard X-ray computed tomography (CT). The molecular and anatomical images are spatially and temporally co-registered, and, if a single-pixel X-ray detector is used, they have matching spatial resolution.","Luminescence,
Computed tomography,
X-ray imaging,
X-ray detectors,
Biomedical optical imaging,
Optical scattering,
Spatial resolution,
Molecular imaging,
Optical sensors,
X-ray detection"
Random Access Game and Medium Access Control Design,"Motivated partially by a control-theoretic viewpoint, we propose a game-theoretic model, called random access game, for contention control. We characterize Nash equilibria of random access games, study their dynamics, and propose distributed algorithms (strategy evolutions) to achieve Nash equilibria. This provides a general analytical framework that is capable of modeling a large class of system-wide quality-of-service (QoS) models via the specification of per-node utility functions, in which system-wide fairness or service differentiation can be achieved in a distributed manner as long as each node executes a contention resolution algorithm that is designed to achieve the Nash equilibrium. We thus propose a novel medium access method derived from carrier sense multiple access/collision avoidance (CSMA/CA) according to distributed strategy update mechanism achieving the Nash equilibrium of random access game. We present a concrete medium access method that adapts to a continuous contention measure called conditional collision probability, stabilizes the network into a steady state that achieves optimal throughput with targeted fairness (or service differentiation), and can decouple contention control from handling failed transmissions. In addition to guiding medium access control design, the random access game model also provides an analytical framework to understand equilibrium and dynamic properties of different medium access protocols.",
Fuzzy Multiple Criteria Hierarchical Group Decision-Making Based on Interval Type-2 Fuzzy Sets,"In this paper, we present a new method for handling fuzzy multiple criteria hierarchical group decision-making problems based on arithmetic operations and fuzzy preference relations of interval type-2 fuzzy sets. Because the time complexity of the proposed method is O(nk), where n is the number of criteria and k is the number of decision-makers, it is more efficient than Wu and Mendel's method, whose time complexity is O(mnk), where m is the number of α-cuts, n is the number of criteria and k is the number of decision-makers. Moreover, the proposed method can overcome another drawback of Wu and Mendel's method, i.e., it can handle evaluating values represented by nonnormal interval type-2 fuzzy sets. The proposed method provides us with a useful way to handle fuzzy multiple criteria hierarchical group decision-making problems.","Fuzzy sets,
Decision making,
Fuzzy logic,
Arithmetic,
Fuzzy set theory,
Uncertainty,
Programming,
Councils,
Computer science,
Fuzzy systems"
Comparative Study of Energy-Efficient Sampling Approaches for Wireless Control Networks,"Wireless sensor and control networks are attractive for many embedded system applications mainly because they don't need wired connections for communication or energy supply. Therefore, energy efficiency is an elementary requirement of devices and concerns not only the hardware and communication protocols, but also the device applications. Adaptive sampling approaches promise to reduce the energy consumption of applications by adapting sampling and message transmissions. Selecting appropriate approaches and parameters is challenging as it strongly influences their performance. Therefore, this paper compares several adaptive sampling approaches in different realistic closed control loop scenarios from building automation, to develop a guideline for approach selection and parameterization.",
Temperature Insensitive All-Fiber Compact Polarization-Maintaining Photonic Crystal Fiber Based Interferometer and Its Applications in Fiber Sensors,"A novel temperature insensitive all-fiber compact polarization-maintaining photonic crystal fiber (PMPCF) based interferometer was presented. The coupling between the PMPCF and single mode fiber (SMF) was investigated experimentally and analytically. With an all-fiber compact SMF-PMPCF-SMF structure, the cladding modes propagating in the PMPCF can be effectively excited by finely core-offsetting one splice between the PMPCF and SMF. With the increase of the core-offset, the interference depth of the interference pattern enlarges accordingly. Under a suitable core-offset, the PMPCF based interferometer with high interference depth can be obtained. Moreover, it is temperature insensitive due to its ultra-low thermal characteristics. We also demonstrated its applications in strain and refractive index measurement. The sensors have the advantages of small size, simple and compact all fiber structure, high sensitivity, and temperature insensitiveness.","Temperature sensors,
Photonic crystal fibers,
Optical fiber polarization,
Optical fiber sensors,
Optoelectronic and photonic sensors,
Interference,
Physics,
Strain measurement,
Sagnac interferometers,
Sensor phenomena and characterization"
Content Centric Networking in tactical and emergency MANETs,"Reliable and secure content distribution in a disruptive environment is a critical challenge due to high mobile and lossy channels. Traditional IP networking and wireless protocols tend to perform poorly. In this paper, we propose Content Centric Networking (CCN) for emergency wireless ad hoc environments. CCN is a novel communication architecture capable to access and retrieve content by name. This new approach achieves scalability, security, and efficient network resource management in large scale disaster recovery and battlefield networks. Existing Internet CCN schemes cannot be directly applied to wireless mobile ad hoc networks due to different environments and specific limitations. Thus, we must extend the CCN architecture by introducing features and requirements especially designed for disruptive networks. We prove feasibility and performance gain of the new design via implementation and experimentation.","Ad hoc networks,
Peer to peer computing,
Mobile computing,
Logic gates,
Internet,
Mobile communication,
Routing"
Efficient Compression of Encrypted Grayscale Images,"Lossless compression of encrypted sources can be achieved through Slepian-Wolf coding. For encrypted real-world sources, such as images, the key to improve the compression efficiency is how the source dependency is exploited. Approaches in the literature that make use of Markov properties in the Slepian-Wolf decoder do not work well for grayscale images. In this correspondence, we propose a resolution progressive compression scheme which compresses an encrypted image progressively in resolution, such that the decoder can observe a low-resolution version of the image, study local statistics based on it, and use the statistics to decode the next resolution level. Good performance is observed both theoretically and experimentally.","Image coding,
Cryptography,
Gray-scale,
Image resolution,
Decoding,
Statistics,
Image reconstruction,
System performance,
Data security,
Computer security"
An Efficient Ant Colony System Based on Receding Horizon Control for the Aircraft Arrival Sequencing and Scheduling Problem,"The aircraft arrival sequencing and scheduling (ASS) problem is a salient problem in air traffic control (ATC), which proves to be nondeterministic polynomial (NP) hard. This paper formulates the ASS problem in the form of a permutation problem and proposes a new solution framework that makes the first attempt at using an ant colony system (ACS) algorithm based on the receding horizon control (RHC) to solve it. The resultant RHC-improved ACS algorithm for the ASS problem (termed the RHC-ACS-ASS algorithm) is robust, effective, and efficient, not only due to that the ACS algorithm has a strong global search ability and has been proven to be suitable for these kinds of NP-hard problems but also due to that the RHC technique can divide the problem with receding time windows to reduce the computational burden and enhance the solution's quality. The RHC-ACS-ASS algorithm is extensively tested on the cases from the literatures and the cases randomly generated. Comprehensive investigations are also made for the evaluation of the influences of ACS and RHC parameters on the performance of the algorithm. Moreover, the proposed algorithm is further enhanced by using a two-opt exchange heuristic local search. Experimental results verify that the proposed RHC-ACS-ASS algorithm generally outperforms ordinary ACS without using the RHC technique and genetic algorithms (GAs) in solving the ASS problems and offers high robustness, effectiveness, and efficiency.","Control systems,
Aircraft,
Aerospace control,
Air traffic control,
Job shop scheduling,
NP-hard problem,
Robustness,
Genetic algorithms,
Aerospace electronics,
Delay"
FACTS: A Framework for Fault-Tolerant Composition of Transactional Web Services,"Along with the standardization of Web services composition language and the widespread acceptance of composition technologies, Web services composition is becoming an efficient and cost-effective way to develop modern business applications. As Web services are inherently unreliable, how to deliver reliable Web services composition over unreliable Web services is a significant and challenging problem. In this paper, we propose FACTS, a framework for fault-tolerant composition of transactional Web services. We identify a set of high-level exception handling strategies and a new taxonomy of transactional Web services to devise a fault-tolerant mechanism that combines exception handling and transaction techniques. We also devise a specification module and a verification module to assist service designers to construct fault-handling logic conveniently and correctly. Furthermore, we design an implementation module to automatically implement fault-handling logic in WS-BPEL. A case study demonstrates the viability of our framework and experimental results show that FACTS can improve fault tolerance of composite services with acceptable overheads.","Web services,
Fault tolerance,
Fault tolerant systems,
Business,
Data mining,
Maintenance engineering,
Engines"
Distributed Random Access Algorithm: Scheduling and Congestion Control,"This paper provides proofs of the rate stability, Harris recurrence, and ε-optimality of carrier sense multiple access (CSMA) algorithms where the random access (or backoff) parameter of each node is adjusted dynamically. These algorithms require only local information and they are easy to implement. The setup is a network of wireless nodes with a fixed conflict graph that identifies pairs of nodes whose simultaneous transmissions conflict. The paper studies two algorithms. The first algorithm schedules transmissions to keep up with given arrival rates of packets. The second algorithm controls the arrivals in addition to the scheduling and attempts to maximize the sum of the utilities, in terms of the rates, of the packet flows at different nodes. For the first algorithm, the paper proves rate stability for strictly feasible arrival rates and also Harris recurrence of the queues. For the second algorithm, the paper proves the ε-optimality in terms of the utilities of the allocated rates. Both algorithms are iterative and we study two versions of each of them. In the first version, both operate with strictly local information but have relatively weaker performance guarantees; under the second version, both provide stronger performance guarantees by utilizing the additional information of the number of nodes in the network.",
Catch Me if You Can: An Abnormality Detection Approach for Collaborative Spectrum Sensing in Cognitive Radio Networks,"Collaborative spectrum sensing is subject to the attack of malicious secondary user(s), which may send false reports. Therefore, it is necessary to detect potential attacker(s) and then exclude the attacker's report for spectrum sensing. Many existing attacker-detection schemes are based on the knowledge of the attacker's strategy and thus apply the Bayesian attacker detection. However, in practical cognitive radio systems the data fusion center typically does not know the attacker's strategy. To alleviate the problem of the unknown strategy of attacker(s), an abnormality-detection approach, based on the abnormality detection in data mining, is proposed. The performance of the attacker detection in the single-attacker scenario is analyzed explicitly. For the case in which the attacker does not know the reports of honest secondary users (called independent attack), it is shown that the attacker can always be detected as the number of spectrum sensing rounds tends to infinity. For the case in which the attacker knows all the reports of other secondary users, based on which the attacker sends its report (called dependent attack), an approach for the attacker to perfectly avoid being detected is found, provided that the attacker has perfect information about the miss-detection and false-alarm probabilities. This motivates cognitive radio networks to protect the reports of secondary users. The performance of attacker detection in the general case of multiple attackers is demonstrated using numerical simulations.","Sensors,
Collaboration,
History,
Cognitive radio,
Detection algorithms,
Measurement,
Data mining"
OpenMM: A Hardware-Independent Framework for Molecular Simulations,"The wide diversity of computer architectures today requires a new approach to software development. OpenMM is an abstraction layer for molecular mechanics simulations, allowing a single program to run efficiently on a variety of hardware platforms.","Hardware,
Computer architecture,
Programming profession,
Graphics,
Computational modeling,
Radio access networks,
Multicore processing,
Power engineering computing,
Predictive models"
"Synchronization and control of complex networks via contraction, adaptation and evolution","Complex networked systems abound in Nature and Technology. They consist of a multitude of interacting agents communicating with each other over a web of complex interconnections. Flocks of birds, platoon of cooperating robots, swirling fishes in the Ocean are all examples whose intricate dynamics can be modeled in terms of three essential ingredients: (i) a mathematical description of the dynamical behavior of each of the agents in the network; (ii) an interaction (or coupling) protocol used by agents to communicate with each other and (iii) a graph describing the network of interconnections between neighboring agents. These three elements are actually mapped onto the mathematical model usually considered in the literature to describe a complex network which uses appropriate equations to describe the node dynamics, the coupling protocol and the network topology.",
"Dogfight in Spectrum: Combating Primary User Emulation Attacks in Cognitive Radio Systems, Part I: Known Channel Statistics","In cognitive radio systems, primary user emulation (PUE) attack means that an attacker sends primary-user-like signals during the spectrum sensing period such that honest secondary users leave the corresponding channels, which causes a serious threat to cognitive radio systems. A passive anti-PUE approach, similar to the random frequency hopping in traditional anti-jamming schemes, is proposed and called dogfight in spectrum. In this scheme, the defenders randomly choose channels to sense and avoid the PUE attack. It is assumed that the channel statistics like availability probabilities are known; then the PUE attack and the random hopping are modeled as a zero-sum game between the attacker and defending secondary user(s). The Nash equilibrium of the game is found. The anti-jamming efficiency is also obtained. Numerical simulations demonstrated the performances of the proposed schemes for both the single defender, multiple defender and multiple round cases.","Games,
Sensors,
Jamming,
Nash equilibrium,
Cognitive radio,
Markov processes,
Emulation"
Experimental Analysis of Accuracy in the Identification of Motor Unit Spike Trains From High-Density Surface EMG,"The aim of this study was to compare the decomposition results obtained from high-density surface electromyography (EMG) and concurrently recorded intramuscular EMG. Surface EMG signals were recorded with electrode grids from the tibialis anterior, biceps brachii, and abductor digiti minimi muscles of twelve healthy men during isometric contractions ranging between 5% and 20% of the maximal force. Bipolar intramuscular EMG signals were recorded with pairs of wire electrodes. Surface and intramuscular EMG were independently decomposed into motor unit spike trains. When averaged over all the contractions of the same contraction force, the percentage of discharge times of motor units identified by both decompositions varied in the ranges 84%-87% (tibialis anterior), 84%-86% (biceps brachii), and 87%-92% (abductor digiti minimi) across the force levels analyzed. This index of agreement between the two decompositions was linearly correlated with a self-consistency measure of motor unit discharge pattern that was based on coefficient of variation for the interspike interval (R2 = 0.68 for tibialis anterior, R2 = 0.56 for biceps brachii, and R2 = 0.38 for abductor digiti minimi). These results constitute an important contribution to the validation of the noninvasive approach for the investigation of motor unit behavior in isometric low-force tasks.",
On the Cyclostationarity of OFDM and Single Carrier Linearly Digitally Modulated Signals in Time Dispersive Channels: Theoretical Developments and Application,"Previous studies on the cyclostationarity aspect of orthogonal frequency division multiplexing (OFDM) and single carrier linearly digitally modulated (SCLD) signals assumed simplified signal and channel models or considered only second-order cyclostationarity. This paper presents new results concerning the cyclostationarity of these signals under more general conditions, including time dispersive channels, additive Gaussian noise, and carrier phase, frequency, and timing offsets. Analytical closed-form expressions are derived for time- and frequency-domain parameters of the cyclostationarity of OFDM and SCLD signals. In addition, a condition to eliminate aliasing in the cycle and spectral frequency domains is derived. Based on these results, an algorithm is developed for recognizing OFDM versus SCLD signals. This algorithm obviates the need for commonly required signal preprocessing tasks, such as signal and noise power estimation and the recovery of symbol timing and carrier information.","Digital modulation,
OFDM modulation,
Dispersion,
Timing,
Frequency domain analysis,
Chirp modulation,
Additive noise,
Gaussian noise,
Signal analysis,
Closed-form solution"
Electrical Characterization of Screen-Printed Circuits on the Fabric,"Fabrication methods of planar printed circuits on fabrics are introduced and their electrical characteristics are measured and analyzed. Wet patterning method like screen printing as well as dry process of sputtering are used to fabricate the patterned film electrodes on various types of fabrics. The minimum width of the patterns is 0.2 mm for screen printing and 0.1 mm for gold sputtering, and the typical sheet resistance is 134 m ¿/¿. Fabrication methods of capacitors of 1 pF-1 nF and inductors of 500 nH-1 ¿H at 10 MHz on the fabrics are also introduced. Bonding and packaging of silicon chip directly on the fabric circuit board are proposed and their mechanical properties are investigated. The ac impedance of the transmission line is measured as 201-215 ¿ with variation, and the time-domain reflectometry profile shows that the -3 dB frequency of the printed transmission line of 15 cm on the fabric is 80 MHz. A complete system composed of a fabric capacitor sensor input, a controller system-on-a-chip, and an LED array display is implemented on the fabric and its operation is demonstrated successfully.","Fabrics,
Sensor arrays,
Fabrication,
Printed circuits,
Printing,
Sputtering,
Capacitors,
Distributed parameter circuits,
Electric variables,
Electric variables measurement"
A Partial Intensity Invariant Feature Descriptor for Multimodal Retinal Image Registration,"Detection of vascular bifurcations is a challenging task in multimodal retinal image registration. Existing algorithms based on bifurcations usually fail in correctly aligning poor quality retinal image pairs. To solve this problem, we propose a novel highly distinctive local feature descriptor named partial intensity invariant feature descriptor (PIIFD) and describe a robust automatic retinal image registration framework named Harris-PIIFD. PIIFD is invariant to image rotation, partially invariant to image intensity, affine transformation, and viewpoint/perspective change. Our Harris-PIIFD framework consists of four steps. First, corner points are used as control point candidates instead of bifurcations since corner points are sufficient and uniformly distributed across the image domain. Second, PIIFDs are extracted for all corner points, and a bilateral matching technique is applied to identify corresponding PIIFDs matches between image pairs. Third, incorrect matches are removed and inaccurate matches are refined. Finally, an adaptive transformation is used to register the image pairs. PIIFD is so distinctive that it can be correctly identified even in nonvascular areas. When tested on 168 pairs of multimodal retinal images, the Harris-PIIFD far outperforms existing algorithms in terms of robustness, accuracy, and computational efficiency.","Retina,
Image registration,
Bifurcation,
Automation,
Biomedical engineering,
Robustness,
Content addressable storage,
Laboratories,
Degenerative diseases,
Automatic control"
Identification-free batch authentication for RFID tags,"Cardinality estimation and tag authentication are two major issues in large-scale Radio Frequency Identification (RFID) systems. While there exist both per-tag and probabilistic approaches for the cardinality estimation, the RFID-oriented authentication protocols are mainly per-tag based: the reader authenticates one tag at each time. For a batch of tags, current RFID systems have to identify them and then authenticate each tag sequentially, incurring large volume of authentication data and huge communication cost. We study the RFID batch authentication issue and propose the first probabilistic approach, termed as Single Echo based Batch Authentication (SEBA), to meet the requirement of prompt and reliable batch authentications in large scale RFID applications, e.g., the anti-counterfeiting solution. Without the need of identifying tags, SEBA provides a provable probabilistic guarantee that the percentage of potential counterfeit products is under the user-defined threshold. The experimental result demonstrates the effectiveness of SEBA in fast batch authentications and significant improvement compared to existing approaches.",
PIConGPU: A Fully Relativistic Particle-in-Cell Code for a GPU Cluster,"The particle-in-cell (PIC) algorithm is one of the most widely used algorithms in computational plasma physics. With the advent of graphical processing units (GPUs), large-scale plasma simulations on inexpensive GPU clusters are in reach. We present an implementation of a fully relativistic plasma PIC algorithm for GPUs based on the NVIDIA CUDA library. It supports a hybrid architecture consisting of single computation nodes interconnected in a standard cluster topology, with each node carrying one or more GPUs. The internode communication is realized using the message-passing interface. The simulation code PIConGPU presented in this paper is, to our knowledge, the first scalable GPU cluster implementation of the PIC algorithm in plasma physics.","Graphics processing unit,
Magnetic cores,
Computer architecture,
Clustering algorithms,
Instruction sets,
Computational modeling,
Plasmas"
Object recognition as ranking holistic figure-ground hypotheses,"We present an approach to visual object-class recognition and segmentation based on a pipeline that combines multiple, holistic figure-ground hypotheses generated in a bottom-up, object independent process. Decisions are performed based on continuous estimates of the spatial overlap between image segment hypotheses and each putative class. We differ from existing approaches not only in our seemingly unreasonable assumption that good object-level segments can be obtained in a feed-forward fashion, but also in framing recognition as a regression problem. Instead of focusing on a one-vs-all winning margin that can scramble ordering inside the non-maximum (non-winning) set, learning produces a globally consistent ranking with close ties to segment quality, hence to the extent entire object or part hypotheses spatially overlap with the ground truth. We demonstrate results beyond the current state of the art for image classification, object detection and semantic segmentation, in a number of challenging datasets including Caltech-101, ETHZ-Shape and PASCAL VOC 2009.","Object recognition,
Image segmentation,
Shape,
Machine learning,
Object detection,
Space exploration,
Computer vision,
Numerical simulation,
Mathematics,
Pipelines"
Capacity Regions and Sum-Rate Capacities of Vector Gaussian Interference Channels,"The capacity regions of vector, or multiple-input multiple-output, Gaussian interference channels are established for very strong interference and aligned strong interference. Furthermore, the sum-rate capacities are established for Z interference, noisy interference, and mixed (aligned weak/intermediate and aligned strong) interference. These results generalize known results for scalar Gaussian interference channels.",
Cooperative Communication-Aware Spectrum Leasing in Cognitive Radio Networks,"In this paper, we focus on the dynamic spectrum access of two infrastructure-based cognitive radio networks, primary network and secondary network, which are collocated with each other. To improve network performance of two networks, we propose a cooperative communication-aware spectrum leasing framework, in which, primary network leverages secondary users as cooperative relays, and decides the optimal strategy on the relay selection and the price for spectrum leasing. Based on primary network's strategy, secondary network determines the length of spectrum access time it purchases from the primary network. Finally, each network allocates the total spectrum access time of the network among its end users. The above sequential decision procedure is formulated as a Stackelberg game, with primary network acting as the leader and secondary network as the follower, and a unique Nash Equilibrium (NE) point is achieved through backward induction analysis. At this NE point, both networks maximize their utilities in terms of transmission rate and revenue/payment. Meanwhile, the optimal relay selection and spectrum resource allocation among all the users are also derived based on the Nash Equilibrium. Simulation results show that both primary and secondary networks achieve higher utility by exploiting cooperative transmission under our proposed framework, which gives both networks incentive for cooperation.",
A Hybrid Approach for Generating Secure and Discriminating Face Template,"Biometric template protection is one of the most important issues in deploying a practical biometric system. To tackle this problem, many algorithms, that do not store the template in its original form, have been reported in recent years. They can be categorized into two approaches, namely biometric cryptosystem and transform-based. However, most (if not all) algorithms in both approaches offer a trade-off between the template security and matching performance. Moreover, we believe that no single template protection method is capable of satisfying the security and performance simultaneously. In this paper, we propose a hybrid approach which takes advantage of both the biometric cryptosystem approach and the transform-based approach. A three-step hybrid algorithm is designed and developed based on random projection, discriminability-preserving (DP) transform, and fuzzy commitment scheme. The proposed algorithm not only provides good security, but also enhances the performance through the DP transform. Three publicly available face databases, namely FERET, CMU-PIE, and FRGC, are used for evaluation. The security strength of the binary templates generated from FERET, CMU-PIE, and FRGC databases are 206.3, 203.5, and 347.3 bits, respectively. Moreover, noninvertibility analysis and discussion on data leakage of the proposed hybrid algorithm are also reported. Experimental results show that, using Fisherface to construct the input facial feature vector (face template), the proposed hybrid method can improve the recognition accuracy by 4%, 11%, and 15% on the FERET, CMU-PIE, and FRGC databases, respectively. A comparison with the recently developed random multispace quantization biohashing algorithm is also reported.","Hybrid power systems,
Biometrics,
Protection,
Cryptography,
Algorithm design and analysis,
Data security,
Spatial databases,
Facial features,
Face recognition,
Quantization"
Assessing Software Service Quality and Trustworthiness at Selection Time,"The integration of external software in project development is challenging and risky, notably because the execution quality of the software and the trustworthiness of the software provider may be unknown at integration time. This is a timely problem and of increasing importance with the advent of the SaaS model of service delivery. Therefore, in choosing the SaaS service to utilize, project managers must identify and evaluate the level of risk associated with each candidate. Trust is commonly assessed through reputation systems; however, existing systems rely on ratings provided by consumers. This raises numerous issues involving the subjectivity and unfairness of the service ratings. This paper describes a framework for reputation-aware software service selection and rating. A selection algorithm is devised for service recommendation, providing SaaS consumers with the best possible choices based on quality, cost, and trust. An automated rating model, based on the expectancy-disconfirmation theory from market science, is also defined to overcome feedback subjectivity issues. The proposed rating and selection models are validated through simulations, demonstrating that the system can effectively capture service behavior and recommend the best possible choices.",
Analytical Performance of Amplify-and-Forward MIMO Relaying with Orthogonal Space-Time Block Codes,"This paper considers orthogonal space-time block coded transmission for a multiple-input multiple-output channel (MIMO) with non-coherent amplify-and-forward (AF) relaying in Rayleigh fading. We first characterize the statistical properties of the instantaneous signal-to-noise ratio (SNR) at the destination, by deriving new exact closed form expressions for the moment generating function, cumulants, and first and second moments. These results show a reciprocity relationship between the number of antennas at the relay and destination. The probability density function and cumulative distribution function of the SNR are also derived for certain system configurations, and for various asymptotic regimes. We then investigate the system performance by presenting new analytical expressions for the symbol error rate, outage probability, amount of fading, as well as the diversity order and array gain. Our results indicate that the proposed scheme can achieve the maximum diversity order of the non-coherent AF MIMO relay channel.","Performance analysis,
MIMO,
Relays,
Block codes,
Rayleigh channels,
Signal to noise ratio,
Character generation,
Signal generators,
Probability density function,
Distribution functions"
Automated Modeling of Dynamic Reliability Block Diagrams Using Colored Petri Nets,"Computer system reliability is conventionally modeled and analyzed using techniques such as fault tree analysis and reliability block diagrams (RBDs), which provide static representations of system reliability properties. A recent extension to RBDs, called dynamic RBDs (DRBD), defines a framework for modeling the dynamic reliability behavior of computer-based systems. However, analyzing a DRBD model in order to locate and identify design errors, such as a deadlock error or faulty state, is not trivial when done manually. A feasible approach to verifying it is to develop its formal model and then analyze it using programmatic methods. In this paper, we first define a reliability markup language that can be used to formally describe DRBD models. Then, we present an algorithm that automatically converts a DRBD model into a colored Petri net. We use a case study to illustrate the effectiveness of our approach and demonstrate how system properties of a DRBD model can be verified using an existing Petri net tool. Our formal modeling approach is compositional; thus, it provides a potential solution to automated verification of DRBD models.","Petri nets,
XML,
Fault trees,
US Department of Transportation,
Telecommunication control,
Computer errors,
System recovery,
Markup languages,
Reliability engineering,
Computer network reliability"
Enhanced Electromagnetic Interference Shielding Through the Use of Functionalized Carbon-Nanotube-Reactive Polymer Composites,"We report on a new principle yielding enhanced electromagnetic shielding, using as an example a composite comprised of carbon nanotubes (CNTs) integrated with a reactive ethylene terpolymer (RET). Such composites were synthesized through the chemical reaction of the functional groups on the CNT with the epoxy linkage of the RET polymer. The main advantages of these composites include good dispersion with low electrical percolation volume fractions (~0.1 volume%), yielding outstanding microwave shielding efficiency for electromagnetic interference applications. The shielding effectiveness was characterized for both single-walled and multiwalled CNT-based composites and was much enhanced in the former. The specific roles of absorption and reflection in determining the total shielding, as a function of the nanotube filling fraction, is also discussed.","Electromagnetic interference,
Carbon nanotubes,
Polymers,
Conducting materials,
Magnetic materials,
Composite materials,
Organic materials,
Conductivity,
Electromagnetic wave absorption,
Optical reflection"
Model-Based Reconstruction for Magnetic Particle Imaging,"Magnetic particle imaging (MPI) is a new imaging modality capable of imaging distributions of superparamagnetic nanoparticles with high sensitivity, high spatial resolution and, in particular, high imaging speed. The image reconstruction process requires a system function, describing the mapping between particle distribution and acquired signal. To date, the system function is acquired in a tedious calibration procedure by sequentially measuring the signal of a delta sample at the positions of a grid that covers the field of view. In this work, for the first time, the system function is calculated using a model of the signal chain. The modeled system function allows for reconstruction of the particle distribution in a 1-D MPI experiment. The approach thus enables fast generation of system functions on arbitrarily dense grids. Furthermore, reduction in memory requirements may be feasible by generating parts of the system function on the fly during reconstruction instead of keeping the complete matrix in memory.","Image reconstruction,
Magnetic particles,
High-resolution imaging,
Nanoparticles,
Spatial resolution,
Signal mapping,
Signal processing,
Calibration,
Magnetic field measurement,
Position measurement"
Reinforcement learning of motor skills in high dimensions: A path integral approach,"Reinforcement learning (RL) is one of the most general approaches to learning control. Its applicability to complex motor systems, however, has been largely impossible so far due to the computational difficulties that reinforcement learning encounters in high dimensional continuous state-action spaces. In this paper, we derive a novel approach to RL for parameterized control policies based on the framework of stochastic optimal control with path integrals. While solidly grounded in optimal control theory and estimation theory, the update equations for learning are surprisingly simple and have no danger of numerical instabilities as neither matrix inversions nor gradient learning rates are required. Empirical evaluations demonstrate significant performance improvements over gradient-based policy learning and scalability to high-dimensional control problems. Finally, a learning experiment on a robot dog illustrates the functionality of our algorithm in a real-world scenario. We believe that our new algorithm, Policy Improvement with Path Integrals (PI2), offers currently one of the most efficient, numerically robust, and easy to implement algorithms for RL in robotics.",
LCM: Lightweight Communications and Marshalling,"We describe the Lightweight Communications and Marshalling (LCM) library for message passing and data marshalling. The primary goal of LCM is to simplify the development of low-latency message passing systems, especially for real-time robotics research applications.","Bandwidth,
Java,
Message passing,
Robots,
Peer to peer computing,
Software,
Real time systems"
A Context-Sensitive Technique Robust to Registration Noise for Change Detection in VHR Multispectral Images,"This paper presents an automatic context-sensitive technique robust to registration noise (RN) for change detection (CD) in multitemporal very high geometrical resolution (VHR) remote sensing images. Exploiting the properties of RN in VHR images, the proposed technique analyzes the distribution of the spectral change vectors (SCVs) computed according to the change vector analysis (CVA) in a quantized polar domain. The method studies the SCVs falling into each quantization cell at different resolution levels (scales) to automatically identify the effects of RN in the polar domain. This information is jointly exploited with the spatial context information contained in the neighborhood of each pixel for generating the final CD map. The spatial context information is modeled through the definition of adaptive regions homogeneous both in spatial and temporal domain (parcels). Experimental results obtained on real VHR remote sensing multitemporal images confirm the effectiveness of the proposed technique.","Noise robustness,
Multispectral imaging,
Remote sensing,
Image resolution,
Image analysis,
Image sensors,
Multidimensional systems,
Spatial resolution,
Motion detection,
Biosensors"
Superquadric Glyphs for Symmetric Second-Order Tensors,"Symmetric second-order tensor fields play a central role in scientific and biomedical studies as well as in image analysis and feature-extraction methods. The utility of displaying tensor field samples has driven the development of visualization techniques that encode the tensor shape and orientation into the geometry of a tensor glyph. With some exceptions, these methods work only for positive-definite tensors (i.e. having positive eigenvalues, such as diffusion tensors). We expand the scope of tensor glyphs to all symmetric second-order tensors in two and three dimensions, gracefully and unambiguously depicting any combination of positive and negative eigenvalues. We generalize a previous method of superquadric glyphs for positive-definite tensors by drawing upon a larger portion of the superquadric shape space, supplemented with a coloring that indicates the tensor's quadratic form. We show that encoding arbitrary eigenvalue sign combinations requires design choices that differ fundamentally from those in previous work on traceless tensors (arising in the study of liquid crystals). Our method starts with a design of 2-D tensor glyphs guided by principles of symmetry and continuity, and creates 3-D glyphs that include the 2-D glyphs in their axis-aligned cross-sections. A key ingredient of our method is a novel way of mapping from the shape space of three-dimensional symmetric second-order tensors to the unit square. We apply our new glyphs to stress tensors from mechanics, geometry tensors and Hessians from image analysis, and rate-of-deformation tensors in computational fluid dynamics.",
Accurate Direct and Indirect On-Chip Temperature Sensing for Efficient Dynamic Thermal Management,"Dynamic thermal management techniques require accurate runtime temperature information in order to operate effectively and efficiently. In this paper, we propose two novel solutions for accurate sensing of on-chip temperature. Our first technique is used at design time for sensor allocation and placement to minimize the number of sensors while maintaining the desired accuracy. The experimental results show that this technique can improve the efficiency and accuracy of sensor allocation and placement compared to previous work and can reduce the number of required thermal sensors by about 16% on average. Secondly, we propose indirect temperature sensing to accurately estimate the temperature at arbitrary locations on the die based on the noisy temperature readings from a limited number of sensors which are located further away from the locations of interest. Our runtime technique for temperature estimation reduces the standard deviation and maximum value of temperature estimation errors by an order of magnitude.",
Robot pebbles: One centimeter modules for programmable matter through self-disassembly,"This paper describes the design, fabrication, and experimental results of a programmable matter system capable of 2D shape formation through subtraction. The system is composed of autonomous 1cm modules which use custom-designed electropermanent magnets to bond, communicate, and share power with their neighbors. Given an initial block composed of many of these modules latched together in a regular crystalline structure, our system is able to form shapes by detaching the unnecessary modules. Many experiments show that the modules in our system are able to distribute data at 9600bps to their neighbors with a 98.5% success rate after four retries, and the connectors are able to support over 85 times the weight of a single module.","Robots,
Shape,
Magnets,
Crystallization,
Stochastic processes,
Robotics and automation,
Bonding,
Self-assembly,
USA Councils,
Fabrication"
Design and Field Experimentation of an Energy-Efficient Architecture for DTN Throwboxes,"Disruption-tolerant networks (DTNs) rely on intermittent contacts between mobile nodes to deliver packets using a store-carry-and-forward paradigm. We earlier proposed the use of throwbox nodes, which are stationary, battery-powered nodes with storage and processing, to enhance the capacity of DTNs. However, the use of throwboxes without efficient power management is minimally effective. If the nodes are too liberal with their energy consumption, they will fail prematurely. However, if they are too conservative, they may miss important transfer opportunities, hence increasing lifetime without improving performance. In this paper, we present a hardware and software architecture for energy-efficient throwboxes in DTNs. We propose a hardware platform that uses a multitiered, multiradio, scalable, solar-powered platform. The throwbox employs an approximate heuristic for solving the NP-hard problem of meeting an average power constraint while maximizing the number of bytes forwarded by the throwbox. We built and deployed prototype throwboxes in UMass DieselNet, a bus-based DTN testbed. Through extensive trace-driven simulations and prototype deployment, we show that a single throwbox with a 270-cm2 solar panel can run perpetually while improving packet delivery by 37% and reducing message delivery latency by at least 10% in the network.","Energy efficiency,
Disruption tolerant networking,
Hardware,
Energy management,
Energy consumption,
Software architecture,
NP-hard problem,
Prototypes,
Testing,
Virtual prototyping"
Quaternion-Based Adaptive Output Feedback Attitude Control of Spacecraft Using Chebyshev Neural Networks,"This paper investigates the problem of output feedback attitude control of an uncertain spacecraft. Two robust adaptive output feedback controllers based on Chebyshev neural networks (CNN) termed adaptive neural networks (NN) controller-I and adaptive NN controller-II are proposed for the attitude tracking control of spacecraft. The four-parameter representations (quaternion) are employed to describe the spacecraft attitude for global representation without singularities. The nonlinear reduced-order observer is used to estimate the derivative of the spacecraft output, and the CNN is introduced to further improve the control performance through approximating the spacecraft attitude motion. The implementation of the basis functions of the CNN used in the proposed controllers depends only on the desired signals, and the smooth robust compensator using the hyperbolic tangent function is employed to counteract the CNN approximation errors and external disturbances. The adaptive NN controller-II can efficiently avoid the over-estimation problem (i.e., the bound of the CNNs output is much larger than that of the approximated unknown function, and hence, the control input may be very large) existing in the adaptive NN controller-I. Both adaptive output feedback controllers using CNN can guarantee that all signals in the resulting closed-loop system are uniformly ultimately bounded. For performance comparisons, the standard adaptive controller using the linear parameterization of spacecraft attitude motion is also developed. Simulation studies are presented to show the advantages of the proposed CNN-based output feedback approach over the standard adaptive output feedback approach.",
Improved Delay-Dependent Stability Condition of Discrete Recurrent Neural Networks With Time-Varying Delays,"This brief investigates the problem of global exponential stability analysis for discrete recurrent neural networks with time-varying delays. In terms of linear matrix inequality (LMI) approach, a novel delay-dependent stability criterion is established for the considered recurrent neural networks via a new Lyapunov function. The obtained condition has less conservativeness and less number of variables than the existing ones. Numerical example is given to demonstrate the effectiveness of the proposed method.","Recurrent neural networks,
Costs,
Lattices,
Function approximation,
Optimal control,
Polynomials,
Neural networks,
Stability analysis,
Testing,
Spline"
Input and Output Quantized Feedback Linear Systems,"Although there has been a lot of research on analysis and synthesis of quantized feedback control systems, most results are developed for the case of a single quantizer (either measurement quantization or control signal quantization). In this technical note, we investigate the case of feedback control systems subject to both input and output quantization. This is motivated by the fact that it is common in remotely controlled systems that measurement and control signals are shared over a single digital network. More specifically, we consider a single-input single-output linear system with memoryless logarithmic quantizers. We firstly show that the output feedback quadratic stabilization problem in this setting can be addressed with no conservatism by means of a sector bound approach. Secondly, we provide a sufficient condition for quadratic stabilization via the solution of a scaled H¿ control problem. Finally, we analyze a problem of bandwidth allocation in the communication channel for finite-level input and output quantizers.","Output feedback,
Linear systems,
Quantization,
Feedback control,
Control systems,
Signal analysis,
Control system synthesis,
Signal synthesis,
Sufficient conditions,
Communication system control"
On the Equivalence of Information Retrieval Methods for Automated Traceability Link Recovery,"We present an empirical study to statistically analyze the equivalence of several traceability recovery methods based on Information Retrieval (IR) techniques. The analysis is based on Principal Component Analysis and on the analysis of the overlap of the set of candidate links provided by each method. The studied techniques are the Jensen-Shannon (JS) method, Vector Space Model (VSM), Latent Semantic Indexing (LSI), and Latent Dirichlet Allocation (LDA). The results show that while JS, VSM, and LSI are almost equivalent, LDA is able to capture a dimension unique to the set of techniques which we considered.","Information retrieval,
Linear discriminant analysis,
Large scale integration,
Principal component analysis,
Indexing,
Documentation,
Software maintenance,
Mathematics,
Informatics,
Computer science"
Cell Nuclei and Cytoplasm Joint Segmentation Using the Sliding Band Filter,"Microscopy cell image analysis is a fundamental tool for biological research. In particular, multivariate fluorescence microscopy is used to observe different aspects of cells in cultures. It is still common practice to perform analysis tasks by visual inspection of individual cells which is time consuming, exhausting and prone to induce subjective bias. This makes automatic cell image analysis essential for large scale, objective studies of cell cultures. Traditionally the task of automatic cell analysis is approached through the use of image segmentation methods for extraction of cells' locations and shapes. Image segmentation, although fundamental, is neither an easy task in computer vision nor is it robust to image quality changes. This makes image segmentation for cell detection semi-automated requiring frequent tuning of parameters. We introduce a new approach for cell detection and shape estimation in multivariate images based on the sliding band filter (SBF). This filter's design makes it adequate to detect overall convex shapes and as such it performs well for cell detection. Furthermore, the parameters involved are intuitive as they are directly related to the expected cell size. Using the SBF filter we detect cells' nucleus and cytoplasm location and shapes. Based on the assumption that each cell has the same approximate shape center in both nuclei and cytoplasm fluorescence channels, we guide cytoplasm shape estimation by the nuclear detections improving performance and reducing errors. Then we validate cell detection by gathering evidence from nuclei and cytoplasm channels. Additionally, we include overlap correction and shape regularization steps which further improve the estimated cell shapes. The approach is evaluated using two datasets with different types of data: a 20 images benchmark set of simulated cell culture images, containing 1000 simulated cells; a 16 images Drosophila melanogaster Kc167 dataset containing 1255 cells, stained for DNA and actin. Both image datasets present a difficult problem due to the high variability of cell shapes and frequent cluster overlap between cells. On the Drosophila dataset our approach achieved a precision/recall of 95%/69% and 82%/90% for nuclei and cytoplasm detection respectively and an overall accuracy of 76%.",
Segmentation of the Left Ventricle From Cardiac MR Images Using a Subject-Specific Dynamical Model,"Statistical models have shown considerable promise as a basis for segmenting and interpreting cardiac images. While a variety of statistical models have been proposed to improve the segmentation results, most of them are either static models (SMs), which neglect the temporal dynamics of a cardiac sequence, or generic dynamical models (GDMs), which are homogeneous in time and neglect the intersubject variability in cardiac shape and deformation. In this paper, we develop a subject-specific dynamical model (SSDM) that simultaneously handles temporal dynamics (intrasubject variability) and intersubject variability. We also propose a dynamic prediction algorithm that can progressively identify the specific motion patterns of a new cardiac sequence based on the shapes observed in past frames. The incorporation of this SSDM into the segmentation framework is formulated in a recursive Bayesian framework. It starts with a manual segmentation of the first frame, and then segments each frame according to intensity information from the current frame as well as the prediction from past frames. In addition, to reduce error propagation in sequential segmentation, we take into account the periodic nature of cardiac motion and perform segmentation in both forward and backward directions. We perform ¿leave-one-out¿ test on 32 canine sequences and 22 human sequences, and compare the experimental results with those from SM, GDM, and active appearance motion model (AAMM). Quantitative analysis of the experimental results shows that SSDM outperforms SM, GDM, and AAMM by having better global and local consistencies with manual segmentation. Moreover, we compare the segmentation results from forward and forward-backward segmentation. Quantitative evaluation shows that forward-backward segmentation suppresses the propagation of segmentation errors.","Image segmentation,
Deformable models,
Shape,
Samarium,
Heuristic algorithms,
Prediction algorithms,
Bayesian methods,
Performance evaluation,
Testing,
Humans"
Bio-inspired design and dynamic maneuverability of a minimally actuated six-legged robot,"Rapidly running arthropods like cockroaches make use of passive dynamics to achieve remarkable locomotion performance with regard to stability, speed, and maneuverability. In this work, we take inspiration from these organisms to design, fabricate, and control a 10cm, 24 gram underactuated hexapedal robot capable of running at 14 body lengths per second and performing dynamic turning maneuvers. Our design relies on parallel kinematic mechanisms fabricated using the scaled smart composite microstructures (SCM) process and viscoelastic polymer legs with tunable stiffness. In addition to the novel robot design, we present experimental validation of the lateral leg spring (LLS) locomotion model's prediction that dynamic turning can be achieved by modulating leg stiffness. Finally, we present and validate a leg design for active stiffness control using shape memory alloy and demonstrate the ability of the robot to execute near-gymnastic 90° turns in the span of five strides.","Leg,
Legged locomotion,
Turning,
Kinematics,
Robot kinematics,
Couplings"
Reversible Logic-Based Concurrently Testable Latches for Molecular QCA,"Nanotechnologies, including molecular quantum dot cellular automata (QCA), are susceptible to high error rates. In this paper, we present the design of concurrently testable latches (D latch, T latch, JK latch, and SR latch), which are based on reversible conservative logic for molecular QCA. Conservative reversible circuits are a specific type of reversible circuits, in which there would be an equal number of 1's in the outputs as there would be on the inputs, in addition to one-to-one mapping. Thus, conservative logic is parity-preserving, i.e., the parity of the input vectors is equal to that of the output vectors. We analyzed the fault patterns in the conservative reversible Fredkin gate due to a single missing/additional cell defect in molecular QCA. We found that if there is a fault in the molecular QCA implementation of Fredkin gate, there is a parity mismatch between the inputs and the outputs, otherwise the inputs parity is the same as outputs parity. Any permanent or transient fault in molecular QCA can be concurrently detected if implemented with the conservative Fredkin gate. The design of QCA layouts and the verification of the latch designs using the QCADesigner and the HDLQ tool are presented.",
Limiting false data attacks on power system state estimation,"Malicious attacks against power system state estimation are considered. It has been recently observed that if an adversary is able to manipulate the measurements taken at several meters in a power system, it can sometimes change the state estimate at the control center in a way that will never be detected by classical bad data detectors. However, in cases when the adversary is not able to perform this attack, it was not clear what attacks might look like. An easily computable heuristic is developed to find bad adversarial attacks in all cases. This heuristic recovers the undetectable attacks, but it will also find the most damaging attack in all cases. In addition, a Bayesian formulation of the bad data problem is introduced, which captures the prior information that a control center has about the likely state of the power system. This formulation softens the impact of undetectable attacks. Finally, a new L∞ norm detector is introduced, and it is demonstrated that it outperforms more standard L2 norm based detectors by taking advantage of the inherent sparsity of the false data injection.","Power systems,
State estimation,
Detectors,
Power system measurements,
Power measurement,
Control systems,
Bayesian methods,
Power system control,
Power system security,
Power system reliability"
On the Classification of Emotional Biosignals Evoked While Viewing Affective Pictures: An Integrated Data-Mining-Based Approach for Healthcare Applications,"Recent neuroscience findings demonstrate the fundamental role of emotion in the maintenance of physical and mental health. In the present study, a novel architecture is proposed for the robust discrimination of emotional physiological signals evoked upon viewing pictures selected from the International Affective Picture System (IAPS). Biosignals are multichannel recordings from both the central and the autonomic nervous systems. Following the bidirectional emotion theory model, IAPS pictures are rated along two dimensions, namely, their valence and arousal. Following this model, biosignals in this paper are initially differentiated according to their valence dimension by means of a data mining approach, which is the C4.5 decision tree algorithm. Then, the valence and the gender information serve as an input to a Mahalanobis distance classifier, which dissects the data into high and low arousing. Results are described in Extensible Markup Language (XML) format, thereby accounting for platform independency, easy interconnectivity, and information exchange. The average recognition (success) rate was 77.68% for the discrimination of four emotional states, differing both in their arousal and valence dimension. It is, therefore, envisaged that the proposed approach holds promise for the efficient discrimination of negative and positive emotions, and it is hereby discussed how future developments may be steered to serve for affective healthcare applications, such as the monitoring of the elderly or chronically ill people.","Medical services,
XML,
Neuroscience,
Robustness,
Biomedical monitoring,
Autonomic nervous system,
Data mining,
Decision trees,
LAN interconnection,
Emotion recognition"
A Unified Tensor Level Set for Image Segmentation,"This paper presents a new region-based unified tensor level set model for image segmentation. This model introduces a three-order tensor to comprehensively depict features of pixels, e.g., gray value and the local geometrical features, such as orientation and gradient, and then, by defining a weighted distance, we generalized the representative region-based level set method from scalar to tensor. The proposed model has four main advantages compared with the traditional representative method as follows. First, involving the Gaussian filter bank, the model is robust against noise, particularly the salt- and pepper-type noise. Second, considering the local geometrical features, e.g., orientation and gradient, the model pays more attention to boundaries and makes the evolving curve stop more easily at the boundary location. Third, due to the unified tensor pixel representation representing the pixels, the model segments images more accurately and naturally. Fourth, based on a weighted distance definition, the model possesses the capacity to cope with data varying from scalar to vector, then to high-order tensor. We apply the proposed method to synthetic, medical, and natural images, and the result suggests that the proposed method is superior to the available representative region-based level set method.","Tensile stress,
Level set,
Image segmentation,
Active contours,
Solid modeling,
Filter bank,
Gaussian noise,
Pixel,
Partial differential equations,
Noise robustness"
Spatially Adaptive Mixture Modeling for Analysis of fMRI Time Series,"Within-subject analysis in fMRI essentially addresses two problems, the detection of brain regions eliciting evoked activity and the estimation of the underlying dynamics. In Makni et aL, 2005 and Makni et aL, 2008, a detection-estimation framework has been proposed to tackle these problems jointly, since they are connected to one another. In the Bayesian formalism, detection is achieved by modeling activating and nonactivating voxels through independent mixture models (IMM) within each region while hemodynamic response estimation is performed at a regional scale in a nonparametric way. Instead of IMMs, in this paper we take advantage of spatial mixture models (SMM) for their nonlinear spatial regularizing properties. The proposed method is unsupervised and spatially adaptive in the sense that the amount of spatial correlation is automatically tuned from the data and this setting automatically varies across brain regions. In addition, the level of regularization is specific to each experimental condition since both the signal-to-noise ratio and the activation pattern may vary across stimulus types in a given brain region. These aspects require the precise estimation of multiple partition functions of underlying Ising fields. This is addressed efficiently using first path sampling for a small subset of fields and then using a recently developed fast extrapolation technique for the large remaining set. Simulation results emphasize that detection relying on supervised SMM outperforms its IMM counterpart and that unsupervised spatial mixture models achieve similar results without any hand-tuning of the correlation parameter. On real datasets, the gain is illustrated in a localizer fMRI experiment: brain activations appear more spatially resolved using SMM in comparison with classical general linear model (GLM)-based approaches, while estimating a specific parcel-based HRF shape. Our approach therefore validates the treatment of unsmoothed fMRI data without fixed GLM definition at the subject level and makes also the classical strategy of spatial Gaussian filtering deprecated.","Time series analysis,
Brain modeling,
Bayesian methods,
Hemodynamics,
Signal to noise ratio,
Sampling methods,
Extrapolation,
Spatial resolution,
Active shape model,
Filtering"
CORNER: a realistic urban propagation model for VANET,"Recent advances in portable technologies suggest that ad hoc networks will finally move out from the research and military harbors to the commercial world. In particular, vehicular safety and entertainment applications are mature for the market. Several major manufacturer are considering vehicular communications as an opportunity to increase the profitability and marketability of their vehicles. In this phase, simulations are essential to evaluate the performance of protocols and applications large urban Ad Hoc and Vehicular networks. This paper tackles on the long overdue issue of an high fidelity propagation model for urban ad hoc networks. In particular, we propose CORNER a low computational cost yet accurate urban propagation prediction technique for ad hoc networks in urban scenarios. We also provide validation of the model through a side-to-side comparison of real experiments and simulations.","Computational modeling,
Ad hoc networks,
Military computing,
Protocols,
Computer vision,
Attenuation,
Reflection,
Computer science,
Vehicles,
Computational efficiency"
A Dynamic LVRT Solution for Doubly Fed Induction Generators,"Doubly fed induction generators have become the most common type of wind turbine generators. However, this type of generator is susceptible to grid-side low voltage and short circuits due to existence of a power electronics converter on the rotor side. When a short circuit or voltage sag happens on the grid side, the rotor current of the generator tends to rise, which could cause damage to the rotor converter. Design and implementation of a series converter on the stator side is presented in this paper to limit the current rise in the rotor. This system includes an active AC/DC inverter, three series transformers, and a DC-bus capacitor. To lower the rating of the components and make the system viable for practical solutions, an exponential decaying sinusoidal voltage, instead of a pure sinusoidal voltage, is applied by the converter during short circuit.","Induction generators,
Rotors,
Wind energy generation,
Circuits,
Mesh generation,
Voltage fluctuations,
Wind turbines,
Power generation,
Low voltage,
Power electronics"
Fast approximate energy minimization with label costs,"The α-expansion algorithm [4] has had a significant impact in computer vision due to its generality, effectiveness, and speed. Thus far it can only minimize energies that involve unary, pairwise, and specialized higher-order terms. Our main contribution is to extend α-expansion so that it can simultaneously optimize “label costs” as well. An energy with label costs can penalize a solution based on the set of labels that appear in it. The simplest special case is to penalize the number of labels in the solution. Our energy is quite general, and we prove optimality bounds for our algorithm. A natural application of label costs is multi-model fitting, and we demonstrate several such applications in vision: homography detection, motion segmentation, and unsupervised image segmentation. Our C++/MATLAB implementation is publicly available.","Computer vision,
Cost function,
Labeling,
Motion segmentation,
Minimization methods,
Computer science,
Mathematics,
Cybernetics,
Motion detection,
Image segmentation"
Learning Actions from Observations,"In the area of imitation learning, one of the important research problems is action representation. There has been a growing interest in expressing actions as a combination of meaningful subparts called action primitives. Action primitives could be thought of as elementary building blocks for action representation. In this article, we present a complete concept of learning action primitives to recognize and synthesize actions. One of the main novelties in this work is the detection of primitives in a unified framework, which takes into account objects and actions being applied to them. As the first major contribution, we propose an unsupervised learning approach for action primitives that make use of the human movements as well as object state changes. As the second major contribution, we propose using parametric hidden Markov models (PHMMs) for representing the discovered action primitives. PHMMs represent movement trajectories as a function of their desired effect on the object, and we will discuss 1) how these PHMMs can be trained in an unsupervised manner, 2) how they can be used for synthesizing movements to achieve a desired effect, and 3) how they can be used to recognize an action primitive and the effect from an observed acting human.","Humans,
Robots,
Object detection,
Unsupervised learning,
Hidden Markov models,
Speech synthesis,
Speech recognition,
Data mining,
Data structures,
Supervised learning"
Joint Reconstruction of Image and Motion in Gated Positron Emission Tomography,"We present a novel intrinsic method for joint reconstruction of both image and motion in positron emission tomography (PET). Intrinsic motion compensation methods exclusively work on the measured data, without any external motion measurements. Most of these methods separate image from motion estimation: They use deformable image registration/optical flow techniques in order to estimate the motion from individually reconstructed gates. Then, the image is estimated based on this motion information. With these methods, a main problem lies in the motion estimation step, which is based on the noisy gated frames. The more noise is present, the more inaccurate the image registration becomes. As we show both visually and quantitatively, joint reconstruction using a simple deformation field motion model can compete with state-of-the-art image registration methods which use robust multilevel B-spline motion models.","Image reconstruction,
Positron emission tomography,
Motion estimation,
Image registration,
Optical noise,
Motion measurement,
Deformable models,
Motion compensation,
Stimulated emission,
Image motion analysis"
Fundamental Limit of Sample Generalized Eigenvalue Based Detection of Signals in Noise Using Relatively Few Signal-Bearing and Noise-Only Samples,"The detection problem in statistical signal processing can be succinctly formulated: given m (possibly) signal bearing, n -dimensional signal-plus-noise snapshot vectors (samples) and N statistically independent n-dimensional noise-only snapshot vectors, can one reliably infer the presence of a signal? This problem arises in the context of applications as diverse as radar, sonar, wireless communications, bioinformatics, and machine learning and is the critical first step in the subsequent signal parameter estimation phase. The signal detection problem can be naturally posed in terms of the sample generalized eigenvalues. The sample generalized eigenvalues correspond to the eigenvalues of the matrix formed by ?whitening? the signal-plus-noise sample covariance matrix with the noise-only sample covariance matrix. In this paper, we prove a fundamental asymptotic limit of sample generalized eigenvalue-based detection of signals in arbitrarily colored noise when there are relatively few signal bearing and noise-only samples. Specifically, we show why when the (eigen) signal-to-noise ratio (SNR) is below a critical value, that is a simple function of n , m, and N, then reliable signal detection, in an asymptotic sense, is not possible. If, however, the eigen-SNR is above this critical value then a simple, new random matrix theory-based algorithm, which we present here, will reliably detect the signal even at SNRs close to the critical value. Numerical simulations highlight the accuracy of our analytical prediction, permit us to extend our heuristic definition of the effective number of identifiable signals in colored noise and display the dramatic improvement in performance relative to the classical estimator by Zhao We discuss implications of our result for the detection of weak and/or closely spaced signals in sensor array processing, abrupt change detection in sensor networks, and clustering methodologies in machine learning.","Eigenvalues and eigenfunctions,
Signal detection,
Signal processing,
Covariance matrix,
Colored noise,
Machine learning,
Signal to noise ratio,
Sensor arrays,
Biomedical signal processing,
Radar signal processing"
Compressive Sensing on a CMOS Separable-Transform Image Sensor,"This paper demonstrates a computational image sensor capable of implementing compressive sensing operations. Instead of sensing raw pixel data, this image sensor projects the image onto a separable 2-D basis set and measures the corresponding expansion coefficients. The inner products are computed in the analog domain using a computational focal plane and an analog vector-matrix multiplier (VMM). This is more than mere postprocessing, as the processing circuity is integrated as part of the sensing circuity itself. We implement compressive imaging on the sensor by using pseudorandom vectors called noiselets for the measurement basis. This choice allows us to reconstruct the image from only a small percentage of the transform coefficients. This effectively compresses the image without any digital computation and reduces the throughput of the analog-to-digital converter (ADC). The reduction in throughput has the potential to reduce power consumption and increase the frame rate. The general architecture and a detailed circuit implementation of the image sensor are discussed. We also present experimental results that demonstrate the advantages of using the sensor for compressive imaging rather than more traditional coded imaging strategies.","Image coding,
CMOS image sensors,
Image sensors,
Integrated circuit measurements,
Analog computers,
Throughput,
Pixel,
Noise measurement,
Image reconstruction,
Analog-digital conversion"
Efficient Tag Identification in Mobile RFID Systems,"In this paper we consider how to efficiently identify tags on the moving conveyor. Considering conditions like the path loss and multi-path effect in realistic settings, we first propose a probabilistic model for RFID tag identification. Based on this model, we propose efficient solutions to identify moving RFID tags, according to the fixed-path mobility on the conveyor. A dynamic program based solution and an adaptive solution are proposed to select optimized frame sizes during the query cycles. Simulation results indicate that by leveraging the probabilistic model our solutions can achieve much better performance than using parameters for the ideal propagation situations.","Radiofrequency identification,
RFID tags,
Belts,
Media Access Protocol,
Intrusion detection,
Supply chains,
Communications Society,
Mobile computing,
Laboratories,
Computer science"
DCS: An Efficient Distributed-Certificate-Service Scheme for Vehicular Networks,"In this paper, we propose an efficient distributed-certificate-service (DCS) scheme for vehicular networks. The proposed scheme offers flexible interoperability for certificate service in heterogeneous administrative authorities and an efficient way for any onboard units (OBUs) to update its certificate from the available infrastructure roadside units (RSUs) in a timely manner. In addition, the DCS scheme introduces an aggregate batch-verification technique for authenticating certificate-based signatures, which significantly decreases the verification overhead. Security analysis and performance evaluation demonstrate that the DCS scheme can reduce the complexity of certificate management and achieve excellent security and efficiency for vehicular communications.",
Output-Capacitor-Free Adaptively Biased Low-Dropout Regulator for System-on-Chips,"A high-precision low-voltage adaptively biased (AB) low-dropout regulator (LDR) with extended loop bandwidth is proposed. The multistage output-capacitor-free LDR is stabilized by Miller compensation and Q-reduction techniques to reduce the required minimum load current. Adaptive biasing is achieved by using direct current feedback from a simple current mirror. The dynamics of both the main feedback loop (MFL) and the adaptive biasing loop are thoroughly analyzed. Tradeoffs between the adaptive biasing factor and the MFL stability are discussed. The AB LDR is designed using a standard 0.35- ¿m CMOS technology ( Vtn ¿ 0.52 V and Vtp ¿ -0.72 V). The output is 1.0 V, which delivers a maximum current of 100 mA. The minimum input voltage is 1.2 V, and the minimum load current required is reduced to 50 ¿A . Extensive simulation results verify that the proposed LDR achieves high loop bandwidth, fast line and load transient responses, high power supply rejection, and low output impedance.","Regulators,
System-on-a-chip,
Bandwidth,
Magnetic flux leakage,
CMOS technology,
Mirrors,
Feedback loop,
Stability,
Voltage,
Power supplies"
Robust Detection of Premature Ventricular Contractions Using a Wave-Based Bayesian Framework,"Detection and classification of ventricular complexes from the ECG is of considerable importance in Holter and critical care patient monitoring, being essential for the timely diagnosis of dangerous heart conditions. Accurate detection of premature ventricular contractions (PVCs) is particularly important in relation to life-threatening arrhythmias. In this paper, we introduce a model-based dynamic algorithm for tracking the ECG characteristic waveforms using an extended Kalman filter. The algorithm can work on single or multiple leads. A ""polargram''-a polar representation of the signal-is introduced, which is constructed using the Bayesian estimations of the state variables. The polargram allows the specification of a polar envelope for normal rhythms. Moreover, we propose a novel measure of signal fidelity by monitoring the covariance matrix of the innovation signals throughout the filtering procedure. PVCs are detected by simultaneous tracking the signal fidelity and the polar envelope. Five databases, including 40 records from MIT-BIH arrhythmia database, are used for differentiating normal, PVC, and other beats. Performance evaluation results show that the proposed method has an average detection accuracy of 99.10%, aggregate sensitivity of 98.77%, and aggregate positive predictivity of 97.47%. Furthermore, the method is capable of 100% accuracy for records that contain only PVCs and normal sinus beats. The results illustrate that the method can contribute to, and enhance the performance of clinical PVC detection.","Robustness,
Heart rate variability,
Bayesian methods,
Electrocardiography,
Databases,
Aggregates,
Patient monitoring,
Heuristic algorithms,
State estimation,
Rhythm"
A study on continuous max-flow and min-cut approaches,"We propose and study novel max-flow models in the continuous setting, which directly map the discrete graph-based max-flow problem to its continuous optimization formulation. We show such a continuous max-flow model leads to an equivalent min-cut problem in a natural way, as the corresponding dual model. In this regard, we revisit basic conceptions used in discrete max-flow / min-cut models and give their new explanations from a variational perspective. We also propose corresponding continuous max-flow and min-cut models constrained by priori supervised information and apply them to interactive image segmentation/labeling problems. We prove that the proposed continuous max-flow and min-cut models, with or without supervised constraints, give rise to a series of global binary solutions λ*(x) ϵ {0,1}, which globally solves the original nonconvex image partitioning problems. In addition, we propose novel and reliable multiplier-based max-flow algorithms. Their convergence is guaranteed by classical optimization theories. Experiments on image segmentation, unsupervised and supervised, validate the effectiveness of the discussed continuous max-flow and min-cut models and suggested max-flow based algorithms.","Image segmentation,
Mathematics,
Partitioning algorithms,
Minimization methods,
Computer science,
Educational institutions,
Mathematical model,
Labeling,
Computer vision,
Application software"
Unequal Error Protection for Robust Streaming of Scalable Video Over Packet Lossy Networks,"Efficient bit stream adaptation and resilience to packet losses are two critical requirements in scalable video coding for transmission over packet-lossy networks. Various scalable layers have highly distinct importance, measured by their contribution to the overall video quality. This distinction is especially more significant in the scalable H.264/advanced video coding (AVC) video, due to the employed prediction hierarchy and the drift propagation when quality refinements are missing. Therefore, efficient bit stream adaptation and unequal protection of these layers are of special interest in the scalable H.264/AVC video. This paper proposes an algorithm to accurately estimate the overall distortion of decoder reconstructed frames due to enhancement layer truncation, drift/error propagation, and error concealment in the scalable H.264/AVC video. The method recursively computes the total decoder expected distortion at the picture-level for each layer in the prediction hierarchy. This ensures low computational cost since it bypasses highly complex pixel-level motion compensation operations. Simulation results show an accurate distortion estimation at various channel loss rates. The estimate is further integrated into a cross-layer optimization framework for optimized bit extraction and content-aware channel rate allocation. Experimental results demonstrate that precise distortion estimation enables our proposed transmission system to achieve a significantly higher average video peak signal-to-noise ratio compared to a conventional content independent system.","Error correction codes,
Robustness,
Streaming media,
Automatic voltage control,
Video coding,
Decoding,
Resilience,
Propagation losses,
Protection,
Computational efficiency"
Classification of Energy Consumption in Buildings With Outlier Detection,"In this paper, we propose an intelligent data-analysis method for modeling and prediction of daily electricity consumption in buildings. The objective is to enable a building-management system to be used for forecasting and detection of abnormal energy use. First, an outlier-detection method is proposed to identify abnormally high or low energy use in a building. Then a canonical variate analysis is employed to describe latent variables of daily electricity-consumption profiles, which can be used to group the data sets into different clusters. Finally, a simple classifier is used to predict the daily electricity-consumption profiles. A case study, based on a mixed-use environment, was studied. The results demonstrate that the method proposed in this paper can be used in conjunction with a building-management system to identify abnormal utility consumption and notify building operators in real time.","Energy consumption,
Load forecasting,
Predictive models,
Energy management,
Intelligent structures,
Data analysis,
Energy efficiency,
Permission,
Neural networks,
Feedforward neural networks"
A Novel Breath Analysis System Based on Electronic Olfaction,"Certain gases in the breath are known to be indicators of the presence of diseases and clinical conditions. These gases have been identified as biomarkers using equipments, such as gas chromatography and electronic nose (e-nose). GC is very accurate but is expensive, time consuming, and nonportable. E-nose has the advantages of low cost and easy operation, but is not particular for analyzing breath odor, and hence, has a limited application in diseases diagnosis. This paper proposes a novel system that is special for breath analysis. We selected chemical sensors that are sensitive to the biomarkers and compositions in human breath, developed the system, and introduced the odor signal preprocessing and classification method. To evaluate the system performance, we captured breath samples from healthy persons and patients known to be afflicted with diabetes, renal disease, and airway inflammation, respectively, and conducted experiments on medical treatment evaluation and disease identification. The results show that the system is not only able to distinguish between breath samples from subjects suffering from various diseases or conditions (diabetes, renal disease, and airway inflammation) and breath samples from healthy subjects, but in the case of renal failure is also helpful in evaluating the efficacy of hemodialysis (treatment for renal failure).","Diseases,
Gases,
Biomarkers,
Diabetes,
Gas chromatography,
Electronic noses,
Chemical sensors,
Humans,
System performance,
Medical treatment"
On Robust Stability of Stochastic Genetic Regulatory Networks With Time Delays: A Delay Fractioning Approach,"Robust stability serves as an important regulation mechanism in system biology and synthetic biology. In this paper, the robust stability analysis problem is investigated for a class of nonlinear delayed genetic regulatory networks with parameter uncertainties and stochastic perturbations. The nonlinear function describing the feedback regulation satisfies the sector condition, the time delays exist in both translation and feedback regulation processes, and the state-dependent Brownian motions are introduced to reflect the inherent intrinsic and extrinsic noise perturbations. The purpose of the addressed stability analysis problem is to establish some easy-to-verify conditions under which the dynamics of the true concentrations of the messenger ribonucleic acid (mRNA) and protein is asymptotically stable irrespective of the norm-bounded modeling errors. By utilizing a new Lyapunov functional based on the idea of ¿delay fractioning¿, we employ the linear matrix inequality (LMI) technique to derive delay-dependent sufficient conditions ensuring the robust stability of the gene regulatory networks. Note that the obtained results are formulated in terms of LMIs that can easily be solved using standard software packages. Simulation examples are exploited to illustrate the effectiveness of the proposed design procedures.","Delay effects,
Robust stability,
Stochastic processes,
Genetics,
State feedback,
Systems biology,
Synthetic biology,
Uncertain systems,
Stochastic resonance,
Stability analysis"
Measurement and Defect Detection of the Weld Bead Based on Online Vision Inspection,"Weld bead inspection is important for high-quality welding. This paper summarizes our work on weld bead profile measurement, monitoring, and defect detection using a structured light-based vision inspection system. The configuration of the sensor is described and analyzed. In this configuration, the system presented in this paper can easily be calibrated. The image processing and extraction algorithms for laser profiles and feature points are presented. The dimensional parameters of the weld bead are measured, and the weld defects are detected during multilayer welding processes. Experiments using the vision inspection system were conducted with satisfactory results for online inspection.","Welding,
Inspection,
Robotics and automation,
Machine vision,
Radiography,
Sensor systems,
Monitoring,
Manufacturing automation,
Productivity,
Service robots"
Reducing the Number of Elements in the Synthesis of Shaped-Beam Patterns by the Forward-Backward Matrix Pencil Method,"The matrix pencil method (MPM) has been used to reduce the number of elements in the linear antenna array with a pencil-beam pattern. This work extends the MPM-based synthesis method to the synthesis of shaped-beam patterns by using the forward-backward matrix pencil method (FBMPM). The FBMPM-based synthesis method places a necessary restriction on the poles which correspond to element positions, and consequently obtains more accurate synthesis results, particularly for the synthesis of asymmetric patterns. Numerical examples show the effectiveness and advantages of the proposed method in the reduction of the number of elements for shaped-beam patterns.","Linear antenna arrays,
Matrix decomposition,
Antenna arrays,
Sparse matrices,
Inverse problems,
Stochastic processes,
Iterative algorithms,
Geometry,
Scholarships,
Councils"
Robust Tracking and Vibration Suppression for a Two-Inertia System by Combining Backstepping Approach With Disturbance Observer,"In this paper, we consider the problem of designing a robust controller for a two-inertia system which contains arbitrarily large (but bounded) model uncertainties and disturbances. The research is motivated by the fact that a two-inertia system represents most of an industrial robot arm system that has a flexible joint, for which vibration suppression and robust control against model uncertainties and external disturbances are very important. The proposed controller consists of two parts: the outer-loop controller designed by the backstepping approach and the inner-loop controller by the new partial disturbance observer (DOB). The DOB is responsible for compensating the input-matched uncertainties and disturbances, while the backstepping controller is designed for dealing with the rest. The proposed controller makes tracking error and vibration of the system suppressed within an arbitrarily small bound during operation time when full states are measured. The results are verified by simulations and experiments with a Luenberger observer.","Robustness,
Backstepping,
Robust control,
Uncertainty,
Vibration control,
Vibration measurement,
Electrical equipment industry,
Industrial control,
Service robots,
Control systems"
Minimizing Delay and Maximizing Lifetime for Wireless Sensor Networks With Anycast,"In this paper, we are interested in minimizing the delay and maximizing the lifetime of event-driven wireless sensor networks for which events occur infrequently. In such systems, most of the energy is consumed when the radios are on, waiting for a packet to arrive. Sleep-wake scheduling is an effective mechanism to prolong the lifetime of these energy-constrained wireless sensor networks. However, sleep-wake scheduling could result in substantial delays because a transmitting node needs to wait for its next-hop relay node to wake up. An interesting line of work attempts to reduce these delays by developing ¿anycast¿-based packet forwarding schemes, where each node opportunistically forwards a packet to the first neighboring node that wakes up among multiple candidate nodes. In this paper, we first study how to optimize the anycast forwarding schemes for minimizing the expected packet-delivery delays from the sensor nodes to the sink. Based on this result, we then provide a solution to the joint control problem of how to optimally control the system parameters of the sleep-wake scheduling protocol and the anycast packet-forwarding protocol to maximize the network lifetime, subject to a constraint on the expected end-to-end packet-delivery delay. Our numerical results indicate that the proposed solution can outperform prior heuristic solutions in the literature, especially under practical scenarios where there are obstructions, e.g., a lake or a mountain, in the coverage area of the wireless sensor network.","Wireless sensor networks,
Control systems,
Protocols,
Energy consumption,
Communication system control,
Delay,
Optimal control,
Computer science,
Data communication,
Relays"
Motion-tolerant magnetic earring sensor and wireless earpiece for wearable photoplethysmography,"This paper addresses the design considerations and critical evaluation of a novel embodiment for wearable photoplethysmography (PPG) comprising a magnetic earring sensor and wireless earpiece. The miniaturized sensor can be worn comfortably on the earlobe and contains an embedded accelerometer to provide motion reference for adaptive noise cancellation. The compact wireless earpiece provides analog signal conditioning and acts as a data-forwarding device via a radio frequency transceiver. Using Bland-Altman and correlation analysis, we evaluated the performance of the proposed system against an FDA-approved ECG measurement device during daily activities. The mean ± standard deviation (SD) of the differences between heart rate measurements from the proposed device and ECG (expressed as percentage of the average between the two techniques) along with the 95% limits of agreement (LOA = ±1.96 SD) was 0.62% ± 4.51% (LOA = -8.23% and 9.46%), -0.49% ± 8.65% (-17.39% and 16.42%), and -0.32% ± 10.63% (-21.15% and 20.52%) during standing, walking, and running, respectively. Linear regression indicated a high correlation between the two measurements across the three evaluated conditions (r = 0.97, 0.82, and 0.76, respectively with p < 0.001). The new earring PPG system provides a platform for comfortable, robust, unobtrusive, and discreet monitoring of cardiovascular function.","Magnetic sensors,
Wearable sensors,
Wireless sensor networks,
Biomedical monitoring,
Electrocardiography,
Accelerometers,
Noise cancellation,
RF signals,
Radio frequency,
Transceivers"
Depth-aided image inpainting for novel view synthesis,"Depth Image Based Rendering (DIBR) technique has been recognized as a promising tool for supporting advanced 3D video services required in MultiView Video (MVV) systems. However, an inherent problem with DIBR is to fill newly exposed areas (holes) caused by disocclusions. This paper addresses the disocclusion problem. To deal with small disocclusions, hole-filling strategies have been designed by the state-of-the-art through pre-processing techniques of the depth video. For larger disocclusions, where depth pre-processing has some limitations, we propose an inpainting approach to retrieve missing pixels. Specifically, we propose in the texture and structure propagation process to take into account the depth information by distinguishing foreground and background parts of the scene. Experimental results illustrate the efficiency of the proposed method.","Pixel,
Three dimensional displays,
Rendering (computer graphics),
PSNR,
Painting,
Conferences,
Image coding"
Revisiting common bug prediction findings using effort-aware models,"Bug prediction models are often used to help allocate software quality assurance efforts (e.g. testing and code reviews). Mende and Koschke have recently proposed bug prediction models that are effort-aware. These models factor in the effort needed to review or test code when evaluating the effectiveness of prediction models, leading to more realistic performance evaluations. In this paper, we revisit two common findings in the bug prediction literature: 1) Process metrics (e.g., change history) outperform product metrics (e.g., LOC), 2) Package-level predictions outperform file-level predictions. Through a case study on three projects from the Eclipse Foundation, we find that the first finding holds when effort is considered, while the second finding does not hold. These findings validate the practical significance of prior findings in the bug prediction literature and encourage their adoption in practice.","Measurement,
Predictive models,
Computer bugs,
Radio frequency,
Mathematical model,
Regression tree analysis,
Computational modeling"
A Novel Technique for Subpixel Image Classification Based on Support Vector Machine,"This paper presents a novel support vector machine classifier designed for subpixel image classification (pixel/spectral unmixing). The proposed classifier generalizes the properties of SVMs to the identification and modeling of the abundances of classes in mixed pixels by using fuzzy logic. This results in the definition of a fuzzy-input fuzzy-output support vector machine (F2SVM) classifier that can: 1) process fuzzy information given as input to the classification algorithm for modeling the subpixel information in the learning phase of the classifier and 2) provide a fuzzy modeling of the classification results, allowing a relation many-to-one between classes and pixels. The presented binary F2SVM can address multicategory problems according to two strategies: the fuzzy one-against-all (FOAA) and the fuzzy one-against-one (FOAO) strategies. These strategies generalize to the fuzzy case techniques based upon ensembles of binary classifiers used for addressing multicategory problems in crisp classification problems. The effectiveness of the proposed F2SVM classifier is tested on three problems related to image classification in presence of mixed pixels having different characteristics. Experimental results confirm the validity of the proposed subpixel classification method.","Image classification,
Support vector machines,
Support vector machine classification,
Pixel,
Hyperspectral sensors,
Remote sensing,
Image analysis,
Layout,
Hyperspectral imaging,
Information analysis"
Connecting modalities: Semi-supervised segmentation and annotation of images using unaligned text corpora,"We propose a semi-supervised model which segments and annotates images using very few labeled images and a large unaligned text corpus to relate image regions to text labels. Given photos of a sports event, all that is necessary to provide a pixel-level labeling of objects and background is a set of newspaper articles about this sport and one to five labeled images. Our model is motivated by the observation that words in text corpora share certain context and feature similarities with visual objects. We describe images using visual words, a new region-based representation. The proposed model is based on kernelized canonical correlation analysis which finds a mapping between visual and textual words by projecting them into a latent meaning space. Kernels are derived from context and adjective features inside the respective visual and textual domains. We apply our method to a challenging dataset and rely on articles of the New York Times for textual features. Our model outperforms the state-of-the-art in annotation. In segmentation it compares favorably with other methods that use significantly more labeled training data.","Joining processes,
Image segmentation,
Image retrieval,
Pixel,
Labeling,
Kernel,
Humans,
Computer science,
Context modeling,
Training data"
Segmentation of building facades using procedural shape priors,"In this paper we propose a novel approach to the perceptual interpretation of building facades that combines shape grammars, supervised classification and random walks. Procedural modeling is used to model the geometric and the photometric variation of buildings. This is fused with visual classification techniques (randomized forests) that provide a crude probabilistic interpretation of the observation space in order to measure the appropriateness of a procedural generation with respect to the image. A random exploration of the grammar space is used to optimize the sequence of derivation rules towards a semantico-geometric interpretation of the observations. Experiments conducted on complex architecture facades with ground truth validate the approach.","Image segmentation,
Solid modeling,
Buildings,
Computer vision,
Level set,
Shape measurement,
Space exploration,
Computer science,
Photometry,
Computer architecture"
On Optimal Information Capture by Energy-Constrained Mobile Sensors,"A mobile sensor is used to cover a number of points of interest (PoIs), where dynamic events appear and disappear according to the given random processes. The sensor, which is of sensing range r, visits the PoIs in a cyclic schedule and gains information about any event that falls within its range. We consider the temporal dimension of the sensing as given by a utility function, which specifies how much information is gained about an event as a function of the cumulative sensing or observation time. The quality of monitoring (QoM), i.e., the fraction of information captured about all events, depends on the speed of the sensor and has been analyzed in an earlier paper for different utility functions. The prior work, however, does not consider the energy of motion, which is an important constraint for mobile sensor coverage. In this paper, we analyze the expected Information captured Per unit of Energy consumption (IPE) as a function of the event type (in terms of the utility function), the event dynamics, and the speed of the mobile sensor. Our analysis uses a realistic energy model of motion, and it allows the sensor speed to be optimized for information capture. The case of multiple sensors will also be discussed. Extensive simulation results verify and illustrate the analytical results.","Energy capture,
Chemical and biological sensors,
Biosensors,
Intelligent sensors,
Monitoring,
Information analysis,
Sun,
Industrial control,
Random processes"
A Dynamic Decision Model for the Real-Time Control of Hybrid Renewable Energy Production Systems,"The use of renewable energy sources can reduce the greenhouse gas emissions and the dependence on fossil fuels. The main problem of the installations based on renewable energy is that electricity generation cannot be fully forecasted and may not follow the trend of the actual energy demand. Hybrid systems (including different subsystems such as renewable energy plants, energy storage systems based on hydrogen or dam water reservoirs) can help in improving the economic and environmental sustainability of renewable energy plants. In addition, hybrid systems may be used to satisfy other user demands (such as water supply or hydrogen for automotive use). However, their use should be optimized in order to fulfill the user demand in terms of energy or other needs. In this paper, a model representing an integrated hybrid system based on a mix of renewable energy generation/conversion technologies (e.g., electrolyzer, hydroelectric plant, pumping stations, wind turbines, fuel cell) is presented. The model includes an optimization problem for the control of the different ways to store energy. The goal is to satisfy the hourly variable electric, hydrogen, and water demands. A specific application area in Morocco is considered and the results obtained are discussed in detail.","Reservoirs,
Fuel cells,
Wind turbines,
Wind speed,
Hydrogen storage,
Wind farms"
Energy Aware Iterative Source Localization for Wireless Sensor Networks,"In this paper, the source localization problem in wireless sensor networks is investigated where the location of the source is estimated based on the quantized measurements received from sensors in the field. An energy efficient iterative source localization scheme is proposed where the algorithm begins with a coarse location estimate obtained from measurement data from a set of anchor sensors. Based on the available data at each iteration, the posterior probability density function (pdf) of the source location is approximated using an importance sampling based Monte Carlo method and this information is utilized to activate a number of non-anchor sensors. Two sensor selection metrics namely the mutual information and the posterior Cramér-Rao lower bound (PCRLB) are employed and their performance compared. Further, the approximate posterior pdf of the source location is used to compress the quantized data of each activated sensor using distributed data compression techniques. Simulation results show that with significantly less computation, the PCRLB based iterative sensor selection method achieves similar mean squared error (MSE) performance as compared to the state-of-the-art mutual information based sensor selection method. By selecting only the most informative sensors and compressing their data prior to transmission to the fusion center, the iterative source localization method reduces the communication requirements significantly and thereby results in energy savings.","Wireless sensor networks,
Position measurement,
Mutual information,
Iterative methods,
Energy efficiency,
Iterative algorithms,
Energy measurement,
Probability density function,
Monte Carlo methods,
Data compression"
Channel Models and Detectors for Two-Dimensional Magnetic Recording,"Two-dimensional magnetic recording (TDMR) is a novel recording architecture intended to support densities beyond those of conventional recording systems. The gains from TDMR come primarily from more powerful coding and signal processing algorithms that allow the bits to be packed more tightly on the disk, and yet be retrieved with acceptable error rates. In this paper, we present some preliminary results for an advanced channel model based on micromagnetic simulations, coined the Grain Flipping Probability model. This model requires a one-time computationally complex characterization phase, but subsequently provides fast and accurate two-dimensional (2-D) readback waveforms that include effects captured from micromagnetic simulations and the statistical effects derived from the granularity of the recording medium. We also show the performance of several detectors over a pre-existing TDMR channel model directly as a function of channel density rather than the signal-to-noise ratio (SNR).","Detectors,
Magnetic recording,
Power system modeling,
Disk recording,
Micromagnetics,
Computational modeling,
Signal processing algorithms,
Error analysis,
Probability,
Two dimensional displays"
Design of a 24-GHz CMOS VCO With an Asymmetric-Width Transformer,"A K-band CMOS voltage-controlled oscillator (VCO) is implemented with a 0.18- ¿m radio frequency CMOS process. For low supply voltage operation, a transformer-feedback topology using a transformer is proposed. The analysis of the transformer-feedback VCO is presented. This shows that the inductance ratio of the transformer must be optimized, and asymmetric-width transformers allow the easy optimization and the high Q-factor. Based on this analysis, the transformer design consideration of the transformer feedback VCO is presented. The VCO operates at 24.27 GHz with the phase noise of -100.33 dBc/Hz at 1-MHz offset, and it consumes 7.8 mW from a 0.65-V supply voltage.","Voltage-controlled oscillators,
CMOS process,
K-band,
Radio frequency,
Low voltage,
Topology,
Inductance,
Q factor,
Feedback,
Phase noise"
"Wireless, Multipurpose In-Home Health Monitoring Platform: Two Case Trials","We propose a general purpose home area sensor network and monitoring platform that is intended for e-Health applications, ranging from elderly monitoring to early homecoming after a hospitalization period. Our monitoring platform is multipurpose, meaning that the system is easily configurable for various user needs and is easy to set up. The system could be temporarily rented from a service company by, for example, hospitals, elderly service providers, specialized physiological rehabilitation centers, or individuals. Our system consists of a chosen set of sensors, a wireless sensor network, a home client, and a distant server. We evaluated our concept in two initial trials: one with an elderly woman living in sheltered housing, and the other with a hip surgery patient during his rehabilitation phase. The results prove the functionality of the platform. However, efficient utilization of such platforms requires further work on the actual e-Health service concepts.","Biomedical monitoring,
Wireless sensor networks,
Senior citizens,
Biomedical engineering,
Biomedical measurements,
Network servers,
Patient monitoring,
Diseases,
Medical services,
Costs"
A Smart ECG Measurement System Based on Web-Service-Oriented Architecture for Telemedicine Applications,"The opportunity for cardiac patients to have constantly monitored their health state at home is now possible by means of telemedicine applications. In fact, today, portable and simple-to-use devices allow one to get preliminary domestic diagnoses of the heart status. In this paper, the authors present an original ECG measurement system based on web-service-oriented architecture to monitor the heart health of cardiac patients. The projected device is a smart patient-adaptive system able to provide personalized diagnoses by using personal data and clinical history of the monitored patient. In the presence of a pathology occurrence, the system is able to call the emergency service for assistance. An ECG sensor has the task to acquire, condition, and sample the heart electrical impulses, whereas a personal digital assistant (PDA) performs the diagnosis according to the measurement uncertainty and, in case of a critical situation, calls the medical staff. The system has two removable and updatable memory devices: the first memory device stores the clinical and personal data of the patient, and the second memory device stores information on the metrological status of the measurement system. This way, according to the personal data and historical information of the patient, the measurement system adapts itself by selecting the best fitted ECG model as a reference to configure the computing algorithm. Further information on the measurement uncertainty is used to qualify the reliability of the final clinical response to reduce the occurrence of a faulty diagnosis. Through the PDA graphic interface, the user can display his personal data, observe the graph of his ECG signal, and read diagnosis information with the relative reliability level. Moreover, the patient can choose to print his ECG graph through a Bluetooth printer or to send it to a specialist by a General Packet Radio Service (GPRS) modem.","Electrocardiography,
Heart,
Measurement uncertainty,
Pathology,
Reliability,
Muscles,
Monitoring"
Universal Glucose Models for Predicting Subcutaneous Glucose Concentration in Humans,"This paper tests the hypothesis that a ¿universal,¿ data-driven model can be developed based on glucose data from one diabetic subject, and subsequently applied to predict subcutaneous glucose concentrations of other subjects, even of those with different types of diabetes. We employed three separate studies, each utilizing a different continuous glucose monitoring (CGM) device, to verify the model's universality. Two out of the three studies involved subjects with type 1 diabetes and the other one with type 2 diabetes. We first filtered the subcutaneous glucose concentration data by imposing constraints on their rate of change. Then, using the filtered data, we developed data-driven autoregressive models of order 30, and used them to make short-term, 30-min-ahead glucose-concentration predictions. We used same-subject model predictions as a reference for comparisons against cross-subject and cross-study model predictions, which were evaluated using the root-mean-squared error (RMSE) and Clarke error grid analysis (EGA). We found that, for each studied subject, the average cross-subject and cross-study RMSEs of the predictions were small and indistinguishable from those obtained with the same-subject models. These observations were corroborated by EGA, where better than 99.0% of the paired sensor-predicted glucose concentrations lay in the clinically acceptable zone A. In addition, the predictive capability of the models was found not to be affected by diabetes type, subject age, CGM device, and interindividual differences. We conclude that it is feasible to develop universal glucose models that allow for clinical use of predictive algorithms and CGM devices for proactive therapy of diabetic patients.","Sugar,
Predictive models,
Humans,
Diabetes,
User-generated content,
Testing,
Monitoring,
Error analysis,
Prediction algorithms,
Medical treatment"
A Body Sensor Network With Electromyogram and Inertial Sensors: Multimodal Interpretation of Muscular Activities,"The evaluation of the postural control system (PCS) has applications in rehabilitation, sports medicine, gait analysis, fall detection, and diagnosis of many diseases associated with a reduction in balance ability. Standing involves significant muscle use to maintain balance, making standing balance a good indicator of the health of the PCS. Inertial sensor systems have been used to quantify standing balance by assessing displacement of the center of mass, resulting in several standardized measures. Electromyogram (EMG) sensors directly measure the muscle control signals. Despite strong evidence of the potential of muscle activity for balance evaluation, less study has been done on extracting unique features from EMG data that express balance abnormalities. In this paper, we present machine learning and statistical techniques to extract parameters from EMG sensors placed on the tibialis anterior and gastrocnemius muscles, which show a strong correlation to the standard parameters extracted from accelerometer data. This novel interpretation of the neuromuscular system provides a unique method of assessing human balance based on EMG signals. In order to verify the effectiveness of the introduced features in measuring postural sway, we conduct several classification tests that operate on the EMG features and predict significance of different balance measures.","Body sensor networks,
Multimodal sensors,
Electromyography,
Muscles,
Data mining,
Personal communication networks,
Medical control systems,
Control systems,
Medical diagnostic imaging,
Diseases"
Assessment of the Risk Factors of Coronary Heart Events Based on Data Mining With Decision Trees,"Coronary heart disease (CHD) is one of the major causes of disability in adults as well as one of the main causes of death in the developed countries. Although significant progress has been made in the diagnosis and treatment of CHD, further investigation is still needed. The objective of this study was to develop a data-mining system for the assessment of heart event-related risk factors targeting in the reduction of CHD events. The risk factors investigated were: 1) before the event: a) nonmodifiable-age, sex, and family history for premature CHD, b) modifiable-smoking before the event, history of hypertension, and history of diabetes; and 2) after the event: modifiable-smoking after the event, systolic blood pressure, diastolic blood pressure, total cholesterol, high-density lipoprotein, low-density lipoprotein, triglycerides, and glucose. The events investigated were: myocardial infarction (MI), percutaneous coronary intervention (PCI), and coronary artery bypass graft surgery (CABG). A total of 528 cases were collected from the Paphos district in Cyprus, most of them with more than one event. Data-mining analysis was carried out using the C4.5 decision tree algorithm for the aforementioned three events using five different splitting criteria. The most important risk factors, as extracted from the classification rules analysis were: 1) for MI, age, smoking, and history of hypertension; 2) for PCI, family history, history of hypertension, and history of diabetes; and 3) for CABG, age, history of hypertension, and smoking. Most of these risk factors were also extracted by other investigators. The highest percentages of correct classifications achieved were 66%, 75%, and 75% for the MI, PCI, and CABG models, respectively. It is anticipated that data mining could help in the identification of high and low risk subgroups of subjects, a decisive factor for the selection of therapy, i.e., medical or surgical. However, further investigation with larger datasets is still needed.","Heart,
Data mining,
Decision trees,
History,
Hypertension,
Diabetes,
Blood pressure,
Surgery,
Cardiac disease,
Sugar"
Autonomous Light Control by Wireless Sensor and Actuator Networks,"Recently, wireless sensor and actuator networks (WSANs) have been widely discussed in many applications. In this paper, we propose an autonomous light control system based on the feedback from light sensors carried by users. Our design focuses on meeting users' preferences and energy efficiency. Both whole and local lighting devices are considered. Users' preferences may depend on their activities and profiles and two requirement models are considered: binary satisfaction and continuous satisfaction models. For controlling whole lighting devices, two decision algorithms are proposed. For controlling local lighting devices, a surface-tracking scheme is proposed. Our solutions are autonomous because, as opposed to existing solutions, they can dynamically adapt to environment changes and do not need to track users' current locations. Simulations and prototyping results are presented to verify the effectiveness of our designs.","Wireless sensor networks,
Lighting control,
Actuators,
Intelligent sensors,
Wireless communication,
Control systems,
Sensor systems,
Energy efficiency,
Space technology,
Energy conservation"
"Mental Models, Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective","Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development.","Cognitive science,
Cognition,
Visualization,
Data visualization,
Computational modeling,
Brain modeling,
Humans"
Imaging Electric Properties of Biological Tissues by RF Field Mapping in MRI,"The electric properties (EPs) of biological tissue, i.e., the electric conductivity and permittivity, can provide important information in the diagnosis of various diseases. The EPs also play an important role in specific absorption rate calculation, a major concern in high-field MRI, as well as in nonmedical areas such as wireless telecommunications. The high-field MRI system is accompanied by significant wave propagation effects, and the RF radiation is dependent on the EPs of biological tissue. On the basis of the measurement of the active transverse magnetic component of the applied RF field (known as B1-mapping technique), we propose a dual-excitation algorithm, which uses two sets of measured B1 data to noninvasively reconstruct the EPs of biological tissues. The finite-element method was utilized in 3-D modeling and B1 field calculation. A series of computer simulations were conducted to evaluate the feasibility and performance of the proposed method on a 3-D head model within a TEM coil and a birdcage coil. Using a TEM coil, when noise free, the reconstructed EP distribution of tissues in the brain has relative errors of 12%-28% and correlated coefficients of greater than 0.91. Compared with other B1-mapping-based reconstruction algorithms, our approach provides superior performance without the need for iterative computations. The present simulation results suggest that good reconstruction of EPs from B1 mapping can be achieved.","Biological tissues,
Radio frequency,
Magnetic resonance imaging,
Image reconstruction,
Coils,
Magnetic field measurement,
Conductivity,
Permittivity,
Diseases,
Finite element methods"
"Camera Augmented Mobile C-Arm (CAMC): Calibration, Accuracy Study, and Clinical Applications","Mobile C-arm is an essential tool in everyday trauma and orthopedics surgery. Minimally invasive solutions, based on X-ray imaging and coregistered external navigation created a lot of interest within the surgical community and started to replace the traditional open surgery for many procedures. These solutions usually increase the accuracy and reduce the trauma. In general, they introduce new hardware into the OR and add the line of sight constraints imposed by optical tracking systems. They thus impose radical changes to the surgical setup and overall procedure. We augment a commonly used mobile C-arm with a standard video camera and a double mirror system allowing real-time fusion of optical and X-ray images. The video camera is mounted such that its optical center virtually coincides with the C-arm's X-ray source. After a one-time calibration routine, the acquired X-ray and optical images are coregistered. This paper describes the design of such a system, quantifies its technical accuracy, and provides a qualitative proof of its efficiency through cadaver studies conducted by trauma surgeons. In particular, it studies the relevance of this system for surgical navigation within pedicle screw placement, vertebroplasty, and intramedullary nail locking procedures. The image overlay provides an intuitive interface for surgical guidance with an accuracy of <;1 mm, ideally with the use of only one single X-ray image. The new system is smoothly integrated into the clinical application with no additional hardware especially for down-the-beam instrument guidance based on the anteroposterior oblique view, where the instrument axis is aligned with the X-ray source. Throughout all experiments, the camera augmented mobile C-arm system proved to be an intuitive and robust guidance solution for selected clinical routines.","Cameras,
Calibration,
X-ray imaging,
Biomedical optical imaging,
Minimally invasive surgery,
Navigation,
Hardware,
Instruments,
Orthopedic surgery,
Mirrors"
Generalized Kernel-Based Visual Tracking,"Kernel-based mean shift (MS) trackers have proven to be a promising alternative to stochastic particle filtering trackers. Despite its popularity, MS trackers have two fundamental drawbacks: 1) the template model can only be built from a single image, and 2) it is difficult to adaptively update the template model. In this paper, we generalize the plain MS trackers and attempt to overcome these two limitations. It is well known that modeling and maintaining a representation of a target object is an important component of a successful visual tracker. However, little work has been done on building a robust template model for kernel-based MS tracking. In contrast to building a template from a single frame, we train a robust object representation model from a large amount of data. Tracking is viewed as a binary classification problem, and a discriminative classification rule is learned to distinguish between the object and background. We adopt a support vector machine for training. The tracker is then implemented by maximizing the classification score. An iterative optimization scheme very similar to MS is derived for this purpose. Compared with the plain MS tracker, it is now much easier to incorporate online template adaptation to cope with inherent changes during the course of tracking. To this end, a sophisticated online support vector machine is used. We demonstrate successful localization and tracking on various data sets.","Target tracking,
Particle tracking,
Australia,
Filtering,
Robustness,
Support vector machines,
Support vector machine classification,
Deformable models,
Laboratories,
Stochastic processes"
Statistical Analysis of Gait Rhythm in Patients With Parkinson's Disease,"To assess the gait variability in patients with Parkinson's disease (PD), we first used the nonparametric Parzen-window method to estimate the probability density functions (PDFs) of stride interval and its two subphases (i.e., swing interval and stance interval). The gait rhythm standard deviation (¿) parameters computed with the PDFs indicated that the gait variability is significantly increased in PD. Signal turns count (STC) was also derived from each outlier-processed gait rhythm time series to serve as a dominant feature, which could be used to characterize the gait variability in PD. Since it was observed that the statistical parameters of swing interval or stance interval were highly correlated with those of stride interval, this article only used the stride interval parameters, i.e., ¿r and STCr , to form the feature vector in the pattern classification experiments. The results evaluated with the leave-one-out cross-validation method demonstrated that the least squares support vector machine with polynomial kernels was able to provide a classification accurate rate of 90.32% and an area (Az) of 0.952 under the receiver operating characteristic curve, both of which were better than the results obtained with the linear discriminant analysis (accuracy: 67.74%, Az: 0.917). The features and the classifiers used in the present study could be useful for monitoring of the gait in PD.","Statistical analysis,
Rhythm,
Parkinson's disease,
Probability density function,
Pattern classification,
Least squares methods,
Support vector machines,
Support vector machine classification,
Polynomials,
Kernel"
A Two-Phase Switching Hybrid Supply Modulator for RF Power Amplifiers With 9% Efficiency Improvement,"A hybrid supply modulator consisting of a parallel operation of a high-drive, low output impedance, wideband class-AB linear amplifier and a high-efficiency, wideband, low-ripple switching amplifier is presented for the application of polar transmitters. At system level, a two-phase switching is employed to lower the inductor current ripple so that both the output ripple and power loss are reduced. On-chip feed-forward bandpass filter is used to extend the tracking bandwidth of the switching amplifier, without hurting the stability of parallel control loop or the need to increase switching frequency. At circuit level, the output impedance of the linear amplifier is lowered by optimizing the design of super source-follower output stage. Inductor current sharing and two-phase ramp generator are implemented for realizing the two-phase switching scheme. Fabricated in a 0.35-μm CMOS process, the prototype chip measures 9 % static efficiency improvement over the conventional single-phase switching design in the back-off power level. Dynamic efficiency is enhanced by 8-12% by enabling the bandpass filter. Successful tracking of a 4 MHz 0.4-2.8 V full-wave rectified sine wave and a WCDMA envelope signal is demonstrated.","Switches,
Inductors,
Switching circuits,
Pulse width modulation,
Transmitters,
Power amplifiers"
Usage Patterns in an Urban WiFi Network,"While WiFi was initially designed as a local-area access network, mesh networking technologies have led to increasingly expansive deployments of WiFi networks. In urban environments, the WiFi mesh frequently supplements a number of existing access technologies, including wired broadband networks, 3G cellular, and commercial WiFi hotspots. It is an open question what role citywide WiFi deployments play in the increasingly diverse access network spectrum. We study the usage of the Google WiFi network deployed in Mountain View, CA, and find that usage naturally falls into three classes based almost entirely on client device type, which we divide into traditional laptop users, fixed-location access devices, and PDA-like smartphone devices. Moreover, each of these classes of use has significant geographic locality, following the distribution of residential, commercial, and transportation areas of the city. When comparing the network usage of each device class, we find a diverse set of mobility patterns that map well to the archetypal use cases for traditional access technologies. To help place our results in context, we also provide key performance measurements of the mesh backbone and, where possible, compare them to those of previously studied urban mesh networks.","Cities and towns,
Mesh networks,
Broadband communication,
Cellular networks,
Portable computers,
Spine,
Wireless mesh networks,
Computer science,
Transportation,
Measurement"
Cost-Effective Multiperiod Spraying for Routing in Delay-Tolerant Networks,"In this paper, we present a novel multiperiod spraying algorithm for routing in delay-tolerant networks (DTNs). The goal is to minimize the average copy count used per message until the delivery while maintaining the predefined message delivery rate by the given deadline. In each period, some number of additional copies are sprayed into the network, followed by the wait for message delivery. At any time instance, the total number of message copies distributed to the network depends on the urgency of achieving the delivery rate by the given deadline for that message. Waiting for early delivery in the initial periods with a small number of copies in existence decreases the average number of copies sprayed in the network till delivery. We first discuss two- and three-period variants of our algorithm, and then we also give an idea of how the presented approach can be extended to more periods. We present an in-depth analysis of the algorithm and validate the analytical results with simulations. The results demonstrate that our multiperiod spraying algorithm outperforms the algorithms with a single spraying period.","Spraying,
Routing,
Disruption tolerant networking,
Algorithm design and analysis,
Government,
Analytical models,
Environmental factors,
Condition monitoring,
Oceans,
Ad hoc networks"
An Ultra-Low-Power Pulse Oximeter Implemented With an Energy-Efficient Transimpedance Amplifier,"Pulse oximeters are ubiquitous in modern medicine to noninvasively measure the percentage of oxygenated hemoglobin in a patient's blood by comparing the transmission characteristics of red and infrared light-emitting diode light through the patient's finger with a photoreceptor. We present an analog single-chip pulse oximeter with 4.8-mW total power dissipation, which is an order of magnitude below our measurements on commercial implementations. The majority of this power reduction is due to the use of a novel logarithmic transimpedance amplifier with inherent contrast sensitivity, distributed amplification, unilateralization, and automatic loop gain control. The transimpedance amplifier, together with a photodiode current source, form a high-performance photoreceptor with characteristics similar to those found in nature, which allows LED power to be reduced. Therefore, our oximeter is well suited for portable medical applications, such as continuous home-care monitoring for elderly or chronic patients, emergency patient transport, remote soldier monitoring, and wireless medical sensing. Furthermore, our design obviates the need for an A-to-D and digital signal processor and leads to a small single-chip solution. We outline how extensions of our work could lead to submilliwatt oximeters.","Pulse amplifiers,
Energy efficiency,
Pulse measurements,
Light emitting diodes,
Photoreceptors,
Patient monitoring,
Biomedical monitoring,
Remote monitoring,
Blood,
Fingers"
A Security Analysis for Wireless Sensor Mesh Networks in Highly Critical Systems,"Nowadays, critical control systems are a fundamental component contributing to the overall performance of critical infrastructures in our society, most of which belong to the industrial sector. These complex systems include in their design different types of information and communication technology systems, such as wireless (mesh) sensor networks, to carry out control processes in real time. This fact has meant that several communication standards, such as Zigbee PRO, WirelessHART, and ISA100.11a, have been specified to ensure coexistence, reliability, and security in their communications. The main purpose of this paper has been to review these three standards and analyze their security. We have identified a set of threats and potential attacks in their routing protocols, and we consequently provide recommendations and countermeasures to help Industry protect its infrastructures.","Wireless sensor networks,
Communication system security,
Sensor systems,
Mesh networks,
Information security,
Communication system control,
Control systems,
Electrical equipment industry,
Industrial control,
Communications technology"
Efficiently selecting regions for scene understanding,"Recent advances in scene understanding and related tasks have highlighted the importance of using regions to reason about high-level scene structure. Typically, the regions are selected beforehand and then an energy function is defined over them. This two step process suffers from the following deficiencies: (i) the regions may not match the boundaries of the scene entities, thereby introducing errors; and (ii) as the regions are obtained without any knowledge of the energy function, they may not be suitable for the task at hand. We address these problems by designing an efficient approach for obtaining the best set of regions in terms of the energy function itself. Each iteration of our algorithm selects regions from a large dictionary by solving an accurate linear programming relaxation via dual decomposition. The dictionary of regions is constructed by merging and intersecting segments obtained from multiple bottom-up over-segmentations. To demonstrate the usefulness of our algorithm, we consider the task of scene segmentation and show significant improvements over state of the art methods.","Layout,
Image segmentation,
Dictionaries,
Merging,
Image reconstruction,
Pixel,
Computer science,
Feature extraction,
Linear programming,
Tires"
Multiple-Input Multiple-Output Gaussian Broadcast Channels With Common and Confidential Messages,This paper considers the problem of the multiple-input multiple-output (MIMO) Gaussian broadcast channel with two receivers (receivers 1 and 2) and two messages: a common message intended for both receivers and a confidential message intended only for receiver 1 but needing to be kept asymptotically perfectly secure from receiver 2. A matrix characterization of the secrecy capacity region is established via a channel enhancement argument. The enhanced channel is constructed by first splitting receiver 1 into two virtual receivers and then enhancing only the virtual receiver that decodes the confidential message. The secrecy capacity region of the enhanced channel is characterized using an extremal entropy inequality previously established for characterizing the capacity region of a degraded compound MIMO Gaussian broadcast channel.,"MIMO,
Receivers,
Covariance matrix,
Encoding,
Optimization,
Region 4,
Noise"
Compact Monopole Antenna With Band-Notched Characteristic for UWB Applications,"A compact planar monopole antenna with standard band-notched characteristic suitable for ultrawideband (UWB) applications is presented. This microstrip-fed antenna, consisting of a square slot patch with a vertical coupling strip, only occupies a small size of 15 (L) × 15 (W) × 1.6 (H) mm3. By properly designing the strip placed at the center of the patch, good frequency rejection performance of the antenna with a wide operating band from 3.05 to 11.15 GHz can be obtained. Compared to other designs, the antenna has a quite simple structure to make the band-notched property to reduce the effect caused by the frequency interference. Furthermore, fairly good omnidirectional radiation patterns and transmission responses both indicate that the proposed antenna is well suited to be integrated within various portable devices for UWB operation.","Ultra wideband antennas,
Frequency,
Microstrip antennas,
Ultra wideband technology,
Slot antennas,
Interference,
Transmitting antennas,
Costs,
Geometry,
Antennas and propagation"
Permutation Arrays Under the Chebyshev Distance,"An (n,d) permutation array (PA) is a subset of Sn with the property that the distance (under some metric) between any two permutations in the array is at least d. They became popular recently for communication over power lines. Motivated by an application to flash memories, in this paper, the metric used is the Chebyshev metric. A number of different constructions are given, as well as bounds on the size of such PA.","Chebyshev approximation,
Flash memory,
Additive white noise,
Gaussian noise,
Hamming distance,
AWGN,
Decoding,
Error correction,
Noise level,
Pulse modulation"
Dense non-rigid surface registration using high-order graph matching,"In this paper, we propose a high-order graph matching formulation to address non-rigid surface matching. The singleton terms capture the geometric and appearance similarities (e.g., curvature and texture) while the high-order terms model the intrinsic embedding energy. The novelty of this paper includes: 1) casting 3D surface registration into a graph matching problem that combines both geometric and appearance similarities and intrinsic embedding information, 2) the first implementation of high-order graph matching algorithm that solves a non-convex optimization problem, and 3) an efficient two-stage optimization approach to constrain the search space for dense surface registration. Our method is validated through a series of experiments demonstrating its accuracy and efficiency, notably in challenging cases of large and/or non-isometric deformations, or meshes that are partially occluded.","Conformal mapping,
Chaos,
Energy capture,
Solid modeling,
Constraint optimization,
Application software,
Boundary conditions,
Computer science,
Casting,
Computer vision"
Segmentation of the Optic Disc in 3-D OCT Scans of the Optic Nerve Head,"Glaucoma is the second leading ocular disease causing blindness due to gradual damage to the optic nerve and resultant visual field loss. Segmentations of the optic disc cup and neuroretinal rim can provide important parameters for detecting and tracking this disease. The purpose of this study is to describe and evaluate a method that can automatically segment the optic disc cup and rim in spectral-domain 3-D OCT (SD-OCT) volumes. Four intraretinal surfaces were segmented using a fast multiscale 3-D graph search algorithm. After surface segmentation, the retina in each 3-D OCT scan was flattened to ensure a consistent optic nerve head shape. A set of 15 features, derived from the segmented intraretinal surfaces and voxel intensities in the SD-OCT volume, were used to train a classifier that can determine which A-scans in the OCT volume belong to the background, optic disc cup and rim. Finally, prior knowledge about the shapes of the cup and rim was incorporated into the system using a convex hull-based approach. Two glaucoma experts annotated the cup and rim area using planimetry, and the annotations of the first expert were used as the reference standard. A leave-one-subject-out experiment on 27 optic nerve head-centered OCT volumes (14 right eye scans and 13 left eye scans from 14 patients) was performed. Two different types of classification methods were compared, and experimental results showed that the best performing method had an unsigned error for the optic disc cup of 2.52 ? 0.87 pixels (0.076 ? 0.026 mm) and for the neuroretinal rim of 2.04 ? 0.86 pixels (0.061 ? 0.026 mm). The interobserver variability as indicated by the unsigned border positioning difference between the second expert observer and the reference standard was 2.54 ? 1.03 pixels (0.076 ? 0.031 mm for the optic disc cup and 2.14 ? 0.80 pixels (0.064 ? 0.024 mm for the neuroretinal rim. The unsigned error of the best performing method was not significantly different (p > 0.2) from the interobserver variability.","Cities and towns,
Biomedical optical imaging,
Diseases,
Blindness,
Shape,
Optical losses,
Retina,
Oncology,
Biomedical imaging,
Head"
A Continuous Petri Net Approach for Model Predictive Control of Traffic Systems,"Traffic systems are often highly populated discrete event systems that exhibit several modes of behavior such as free flow traffic, traffic jams, stop-and-go waves, etc. An appropriate closed loop control of the congested system is crucial in order to avoid undesirable behavior. This paper proposes a macroscopic model based on continuous Petri nets as a tool for designing control laws that improve the behavior of traffic systems. The main reason to use a continuous model is to avoid the state explosion problem inherent to large discrete event systems. The obtained model captures the different operation modes of a traffic system and is highly compositional. In order to handle the variability of the traffic conditions, a model predictive control strategy is proposed and validated.","Predictive models,
Predictive control,
Traffic control,
Communication system traffic control,
Petri nets,
Explosions,
Discrete event systems,
Control systems,
Vehicles,
Firing"
Multiple output selection-LAS algorithm in large MIMO systems,"We present a low-complexity algorithm for detection in large MIMO systems based on the likelihood ascent search (LAS) algorithm. The key idea in our work is to generate multiple possible solutions or outputs from which we select the best one. We propose two possible approaches to achieve this goal and both are investigated. Computer simulations demonstrate that the proposed algorithm, Multiple Output Selection-LAS, which has the same complexity order as that of conventional LAS algorithms, is superior in bit error rate (BER) performance to LAS conventional algorithms. For example, with 20 antennas at both the transmitter and receiver, the proposed MOS-LAS algorithm needs about 4 dB less SNR to achieve a target BER of 10-4 for 4-QAM.","MIMO,
Detectors,
Bit error rate,
Maximum likelihood detection,
Receiving antennas,
Transmitting antennas,
Transmitters,
Computer simulation,
Quadrature phase shift keying,
Maximum likelihood estimation"
NMEEF-SD: Non-dominated Multiobjective Evolutionary Algorithm for Extracting Fuzzy Rules in Subgroup Discovery,"A non-dominated multiobjective evolutionary algorithm for extracting fuzzy rules in subgroup discovery (NMEEF-SD) is described and analyzed in this paper. This algorithm, which is based on the hybridization between fuzzy logic and genetic algorithms, deals with subgroup-discovery problems in order to extract novel and interpretable fuzzy rules of interest, and the evolutionary fuzzy system NMEEF-SD is based on the well-known Non-dominated Sorting Genetic Algorithm II (NSGA-II) model but is oriented toward the subgroup-discovery task using specific operators to promote the extraction of interpretable and high-quality subgroup-discovery rules. The proposal includes different mechanisms to improve diversity in the population and permits the use of different combinations of quality measures in the evolutionary process. An elaborate experimental study, which was reinforced by the use of nonparametric tests, was performed to verify the validity of the proposal, and the proposal was compared with other subgroup discovery methods. The results show that NMEEF-SD obtains the best results among several algorithms studied.","Evolutionary computation,
Fuzzy systems,
Proposals,
Data mining,
Genetic algorithms,
Testing,
Computer science,
Algorithm design and analysis,
Fuzzy logic,
Performance evaluation"
Standardization of Automated Analyses of Oculomotor Fixation and Saccadic Behaviors,"In an effort toward standardization, this paper evaluates the performance of five eye-movement classification algorithms in terms of their assessment of oculomotor fixation and saccadic behavior. The results indicate that performance of these five commonly used algorithms vary dramatically, even in the case of a simple stimulus-evoked task using a single, common threshold value. The important contributions of this paper are: evaluation and comparison of performance of five algorithms to classify specific oculomotor behavior; introduction and comparison of new standardized scores to provide more reliable classification performance; logic for a reasonable threshold-value selection for any eye-movement classification algorithm based on the standardized scores; and logic for establishing a criterion-based baseline for performance comparison between any eye-movement classification algorithms. Proposed techniques enable efficient and objective clinical applications providing means to assure meaningful automated eye-movement classification.","Standardization,
Classification algorithms,
Computer science,
Logic,
Humans,
Visual system,
Psychology,
Permission,
Brain injuries,
Alzheimer's disease"
Learning Control in Robotics,"Recent trends in robot learning are to use trajectory-based optimal control techniques and reinforcement learning to scale complex robotic systems. On the one hand, increased computational power and multiprocessing, and on the other hand, probabilistic reinforcement learning methods and function approximation, have contributed to a steadily increasing interest in robot learning. Imitation learning has helped significantly to start learning with reasonable initial behavior. However, many applications are still restricted to rather lowdimensional domains and toy applications. Future work will have to demonstrate the continual and autonomous learning abilities, which were alluded to in the introduction.","Robot control,
Control systems,
Robotics and automation,
Mobile robots,
Orbital robotics,
Humans,
Adaptive control,
Educational robots,
Error correction,
Learning systems"
Threshold saturation on BMS channels via spatial coupling,"We consider spatially coupled code ensembles. A particular instance are convolutional LDPC ensembles. It was recently shown that, for transmission over the binary erasure channel, this coupling increases the belief propagation threshold of the ensemble to the maximum a-priori threshold of the underlying component ensemble. We report on empirical evidence which suggests that the same phenomenon also occurs when transmission takes place over a general binary memoryless symmetric channel. This is confirmed both by simulations as well as by computing EBP GEXIT curves and by comparing the empirical BP thresholds of coupled ensembles to the empirically determined MAP thresholds of the underlying regular ensembles. We further consider ways of reducing the rate-loss incurred by such constructions.",
Random-Restart Reactive Tabu Search Algorithm for Detection in Large-MIMO Systems,"We present a low-complexity algorithm based on reactive tabu search (RTS) for near maximum likelihood (ML) detection in large-MIMO systems. The conventional RTS algorithm achieves near-ML performance for 4-QAM in large-MIMO systems. But its performance for higher-order QAM is far from ML performance. Here, we propose a random-restart RTS (R3TS) algorithm which achieves significantly better bit error rate (BER) performance compared to that of the conventional RTS algorithm in higher-order QAM. The key idea is to run multiple tabu searches, each search starting with a random initial vector and choosing the best among the resulting solution vectors. A criterion to limit the number of searches is also proposed. Computer simulations show that the R3TS algorithm achieves almost the ML performance in 16 × 16 V-BLAST MIMO system with 16-QAM and 64-QAM at significantly less complexities than the sphere decoder. Also, in a 32 × 32 V-BLAST MIMO system, the R3TS performs close to ML lower bound within 1.6 dB for 16-QAM (128 bps/Hz), and within 2.4 dB for 64-QAM (192 bps/Hz) at 10-3 BER.","MIMO,
Complexity theory,
Bit error rate,
Quadrature amplitude modulation,
Decoding,
Signal to noise ratio,
Approximation algorithms"
Investigation of Hybrid EMI Filters for Common-Mode EMI Suppression in a Motor Drive System,"This paper begins with an analysis of the common-mode (CM) noise in a motor drive system. Based on the developed CM noise model, two cancellation techniques, CM noise voltage cancellation and CM noise current cancellation, are discussed. The constraints and impedance requirements for these two cancellation methods are investigated. An active filter with a feedforward current cancellation technique is proposed, implemented, and tested, and techniques to improve the performance of active filters are explored. It is found that due to the limitations of speed, power loss, and gain bandwidth of active filters, active electromagnetic interference (EMI) filters are not good at suppressing high di/dt or high amplitude noise current. Hybrid filters that include a passive filter and an active filter are proposed to overcome the shortcomings of active filters. Hybrid EMI filters are investigated based on the impedance requirements and frequency responses between the passive and active filters. The experiments show that the proposed active filter can greatly reduce noise by up to 50 dB at low frequencies (LFs), and therefore, the corner frequency of the passive filter can be increased considerably; as a result, the CM inductance of the passive filter is greatly reduced. The power loss of the proposed active EMI filter can be well-controlled in the experiments.","Electromagnetic interference,
Motor drives,
Active filters,
Passive filters,
Noise cancellation,
Frequency,
Impedance,
Band pass filters,
Active noise reduction,
Voltage"
No-Reference Quality Assessment of H.264/AVC Encoded Video,"This paper proposes a no-reference quality assessment metric for digital video subject to H.264/advanced video coding encoding. The proposed metric comprises two main steps: coding error estimation and perceptual weighting of this error. Error estimates are computed in the transform domain, assuming that discrete cosine transform (DCT) coefficients are corrupted by quantization noise. The DCT coefficient distributions are modeled using Cauchy or Laplace probability density functions, whose parameterization is performed using the quantized coefficient data and quantization steps. Parameter estimation is based on a maximum-likelihood estimation method combined with linear prediction. The linear prediction scheme takes advantage of the correlation between parameter values at neighbor DCT spatial frequencies. As for the perceptual weighting module, it is based on a spatiotemporal contrast sensitivity function applied to the DCT domain that compensates image plane movement by considering the movements of the human eye, namely smooth pursuit, natural drift, and saccadic movements. The video related inputs for the perceptual model are the motion vectors and the frame rate, which are also extracted from the encoded video. Subjective video quality assessment tests have been carried out in order to validate the results of the metric. A set of 11 video sequences, spanning a wide range of content, have been encoded at different bitrates and the outcome was subject to quality evaluation. Results show that the quality scores computed by the proposed algorithm are well correlated with the mean opinion scores associated to the subjective assessment.","Discrete cosine transforms,
Measurement,
Quality assessment,
Quantization,
Maximum likelihood estimation,
PSNR,
Streaming media"
Application performance modeling in a virtualized environment,"Performance models provide the ability to predict application performance for a given set of hardware resources and are used for capacity planning and resource management. Traditional performance models assume the availability of dedicated hardware for the application. With growing application deployment on virtualized hardware, hardware resources are increasingly shared across multiple virtual machines. In this paper, we build performance models for applications in virtualized environments. We identify a key set of virtualization architecture independent parameters that influence application performance for a diverse and representative set of applications. We explore several conventional modeling techniques and evaluate their effectiveness in modeling application performance in a virtualized environment. We propose an iterative model training technique based on artificial neural networks which is found to be accurate across a range of applications. The proposed approach is implemented as a prototype in Xen-based virtual machine environments and evaluated for accuracy, sensitivity to the training process, and overhead. Median modeling error in the range 1.16-6.65% across a diverse application set and low modeling overhead suggest the suitability of our approach in production virtualized environments.","Application virtualization,
Hardware,
Virtual machining,
Predictive models,
Capacity planning,
Resource management,
Availability,
Resource virtualization,
Artificial neural networks,
Virtual prototyping"
Multiclass Relevance Vector Machines: Sparsity and Accuracy,"In this paper, we investigate the sparsity and recognition capabilities of two approximate Bayesian classification algorithms, the multiclass multi-kernel relevance vector machines (mRVMs) that have been recently proposed. We provide an insight into the behavior of the mRVM models by performing a wide experimentation on a large range of real-world datasets. Furthermore, we monitor various model fitting characteristics that identify the predictive nature of the proposed methods and compare against existing classification techniques. By introducing novel convergence measures, sample selection strategies and model improvements, it is demonstrated that mRVMs can produce state-of-the-art results on multiclass discrimination problems. In addition, this is achieved by utilizing only a very small fraction of the available observation data.","Training,
Kernel,
Convergence,
Q factor,
Estimation,
Integrated circuits,
Predictive models"
Time Reversal in Multiple-Input Multiple-Output Radar,"Time reversal explores the rich scattering in a multipath environment to achieve high target detectability. Multiple-input multiple-output (MIMO) radar is an emerging active sensing technology that uses diverse waveforms transmitted from widely spaced antennas to achieve increased target sensitivity when compared to standard phased arrays. In this paper, we combine MIMO radar with time reversal to automatically match waveforms to a scattering channel and further improve the performance of radar detection. We establish a radar target model in multipath rich environments and develop likelihood ratio tests for the proposed time-reversal MIMO radar (TR-MIMO). Numerical simulations demonstrate improved target detectability compared with the commonly used statistical MIMO strategy.","MIMO,
Radar antennas,
Radar scattering,
Radar detection,
Phased arrays,
Spaceborne radar,
Space technology,
Transmitting antennas,
Antenna arrays,
Testing"
"Fast Decision of Block Size, Prediction Mode, and Intra Block for H.264 Intra Prediction","The spatial-domain intra prediction scheme of H.264 has high computational complexity, especially for the High Profile as it incorporates the additional intra 8 × 8 prediction mode. To address this issue, we explore the hierarchy of H.264 mode decision process in this paper and adopt an approach that is in synchrony with the mode decision hierarchy. In particular, we propose a variance-based algorithm for block size decision, an improved filter-based algorithm for prediction mode decision using contextual information, and a selection algorithm for intra block decision that exploits the relation between the rate-distortion characteristic and the best coding type. Performance comparison is provided to show the improvement of the proposed algorithms over previous methods.","Video coding,
Automatic voltage control,
Rate-distortion,
Communication standards,
Computational complexity,
Information filtering,
Information filters,
Prediction algorithms,
Communications technology"
A framework for statistical wireless spectrum occupancy modeling,"In this paper, we propose a novel spectrum occupancy model designed to generate accurate temporal and frequency behavior of various wireless transmissions. Our proposed work builds upon existing concepts in open literature in order to develop a more accurate time-varying spectrum occupancy model. This model can be employed by wireless researchers for evaluating new wireless communication and networking algorithms and techniques designed to perform dynamic spectrum access (DSA). Using statistical characteristics extracted from actual radio frequency measurements, first- and second-order parameters are employed in a statistical spectrum occupancy model based on a combination of several different probability density functions (PDFs) defining various features of a specific spectrum band with several concurrent transmissions. To assess the accuracy of the model, the output characteristics of the proposed spectrum occupancy model are compared with realtime radio frequency measurements in the television and paging bands.","Frequency measurement,
Wireless communication,
Radio frequency,
Electromagnetic measurements,
Bandwidth,
Wireless sensor networks,
Computer science,
Algorithm design and analysis,
Performance evaluation,
Density measurement"
Linked sensor data,"A number of government, corporate, and academic organizations are collecting enormous amounts of data provided by environmental sensors. However, this data is too often locked within organizations and underutilized by the greater community. In this paper, we present a framework to make this sensor data openly accessible by publishing it on the Linked Open Data (LOD) Cloud. This is accomplished by converting raw sensor observations to RDF and linking with other datasets on LOD. With such a framework, organizations can make large amounts of sensor data openly accessible, thus allowing greater opportunity for utilization and analysis.","Resource description framework,
Sensor phenomena and characterization,
Hurricanes,
Clouds,
Joining processes,
Computer science,
Data engineering,
Government,
Publishing,
Standardization"
Low-Cost and High-Performance Supervision in Ratio-Enforced Automated Manufacturing Systems Using Timed Petri Nets,"In the context of automated manufacturing, this work proposes a new special class of timed Petri nets, namely, Timed ratio-enforced Augmented Marked Graph (TAMG) and its low-cost and high-performance supervisor synthesis methodology. A supervisor is composed of a set of control places (monitors), each of which is easy to be algebraically specified by a generalized mutual exclusion constraint (GMEC) to prevent certain siphons from being undermarked. In order to make a good tradeoff between the supervisor implementation cost and system performance, a mixed integer programming (MIP) approach is formulated to synthesize the monitors. An example is used to validate the effectiveness and efficiency of the proposed method. The results show that the proposed method remarkably outperforms any existing ones.","Manufacturing systems,
Petri nets,
Educational institutions,
Costs,
Control system synthesis,
Educational programs,
System recovery,
Automatic control,
Control systems,
Throughput"
Optimization of Dilution and Mixing of Biochemical Samples Using Digital Microfluidic Biochips,"The recent emergence of lab-on-a-chip (LoC) technology has led to a paradigm shift in many healthcare-related application areas, e.g., point-of-care clinical diagnostics, high-throughput sequencing, and proteomics. A promising category of LoCs is digital microfluidic (DMF)-based biochips, in which nanoliter-volume fluid droplets are manipulated on a 2-D electrode array. A key challenge in designing such chips and mapping lab-bench protocols to a LoC is to carry out the dilution process of biochemical samples efficiently. As an optimization and automation technique, we present a dilution/mixing algorithm that significantly reduces the production of waste droplets. This algorithm takes O(n) time to compute at most n sequential mix/split operations required to achieve any given target concentration with an error in concentration factor less than [1/(2n)]. To implement the algorithm, we design an architectural layout of a DMF-based LoC consisting of two O(n)-size rotary mixers and O(n) storage electrodes. Simulation results show that the proposed technique always yields nonnegative savings in the number of waste droplets and also in the total number of input droplets compared to earlier methods.","Electrodes,
System-on-a-chip,
Layout,
Algorithm design and analysis,
Arrays,
Design automation,
Optimization"
Reducing Drifts in the Inertial Measurements of Wrist and Elbow Positions,"In this paper, we present an inertial-sensor-based monitoring system for measuring the movement of human upper limbs. Two wearable inertial sensors are placed near the wrist and elbow joints, respectively. The measurement drift in segment orientation is dramatically reduced after a Kalman filter is applied to estimate inclinations using accelerations and turning rates from gyroscopes. Using premeasured lengths of the upper and lower arms, we compute the position of the wrist and elbow joints via a proposed kinematic model. Experimental results demonstrate that this new motion capture system, in comparison to an optical motion tracker, possesses an RMS position error of less than 0.009 m, with a drift of less than 0.005 ms-1 in five daily activities. In addition, the RMS angle error is less than 3°. This indicates that the proposed approach has performed well in terms of accuracy and reliability.","Position measurement,
Wrist,
Elbow,
Motion measurement,
Humans,
Biomedical monitoring,
Wearable sensors,
Acceleration,
Turning,
Gyroscopes"
PhoenixSim: A simulator for physical-layer analysis of chip-scale photonic interconnection networks,"Recent developments have shown the possibility of leveraging silicon nanophotonic technologies for chip-scale interconnection fabrics that deliver high bandwidth and power efficient communications both on- and off-chip. Since optical devices are fundamentally different from conventional electronic interconnect technologies, new design methodologies and tools are required to exploit the potential performance benefits in a manner that accurately incorporates the physically different behavior of photonics. We introduce PhoenixSim, a simulation environment for modeling computer systems that incorporates silicon nanophotonic devices as interconnection building blocks. PhoenixSim has been developed as a cross-discipline platform for studying photonic interconnects at both the physical-layer level and at the architectural and system levels. The broad scope at which modeled systems can be analyzed with PhoenixSim provides users with detailed information into the physical feasibility of the implementation, as well as the network and system performance. Here, we describe details about the implementation and methodology of the simulator, and present two case studies of silicon nanophotonic-based networks-on-chip.","Analytical models,
Multiprocessor interconnection networks,
Silicon,
Fabrics,
Bandwidth,
Optical devices,
Power system interconnection,
Design methodology,
Photonics,
Computational modeling"
Intrinsically Motivated Hierarchical Skill Learning in Structured Environments,"We present a framework for intrinsically motivated developmental learning of abstract skill hierarchies by reinforcement learning agents in structured environments. Long-term learning of skill hierarchies can drastically improve an agent's efficiency in solving ensembles of related tasks in a complex domain. In structured domains composed of many features, understanding the causal relationships between actions and their effects on different features of the environment can greatly facilitate skill learning. Using Bayesian network structure (learning techniques and structured dynamic programming algorithms), we show that reinforcement learning agents can learn incrementally and autonomously both the causal structure of their environment and a hierarchy of skills that exploit this structure. Furthermore, we present a novel active learning scheme that employs intrinsic motivation to maximize the efficiency with which this structure is learned. As new structure is acquired using an agent's current set of skills, more complex skills are learned, which in turn allow the agent to discover more structure, and so on. This bootstrapping property makes our approach a developmental learning process that results in steadily increasing domain knowledge and behavioral complexity as an agent continues to explore its environment.","Bayesian methods,
Dynamic programming,
Heuristic algorithms,
Robustness,
Machine learning,
Computer science,
Learning systems,
Context modeling,
State-space methods"
Boosting and Differential Privacy,"Boosting is a general method for improving the accuracy of learning algorithms. We use boosting to construct improved {\em privacy-preserving synopses} of an input database. These are data structures that yield, for a given set
Undefined control sequence \Q
of queries over an input database, reasonably accurate estimates of the responses to every query in~
Undefined control sequence \Q
, even when the number of queries is much larger than the number of rows in the database. Given a {\em base synopsis generator} that takes a distribution on
Undefined control sequence \Q
and produces a ``weak'' synopsis that yields ``good'' answers for a majority of the weight in
Undefined control sequence \Q
, our {\em Boosting for Queries} algorithm obtains a synopsis that is good for all of~
Undefined control sequence \Q
. We ensure privacy for the rows of the database, but the boosting is performed on the {\em queries}. We also provide the first synopsis generators for arbitrary sets of arbitrary low-sensitivity queries, {\it i.e.}, queries whose answers do not vary much under the addition or deletion of a single row. In the execution of our algorithm certain tasks, each incurring some privacy loss, are performed many times. To analyze the cumulative privacy loss, we obtain an
Undefined control sequence \eps
bound on the {\em expected} privacy loss from a single
Undefined control sequence \eps
-\dfp{} mechanism. Combining this with evolution of confidence arguments from the literature, we get stronger bounds on the expected cumulative privacy loss due to multiple mechanisms, each of which provides
Undefined control sequence \eps
-differential privacy or one of its relaxations, and each of which operates on (potentially) different, adaptively chosen, databases.","Databases,
Privacy,
Boosting,
Data privacy,
Generators,
Accuracy,
Data structures"
Multimodal Optimization by Means of a Topological Species Conservation Algorithm,"Any evolutionary technique for multimodal optimization must answer two crucial questions in order to guarantee some success on a given task: How to most unboundedly distinguish between the different attraction basins and how to most accurately safeguard the consequently discovered solutions. This paper thus aims to present a novel technique that integrates the conservation of the best successive local individuals (as in the species conserving genetic algorithm) with a topological subpopulations separation (as in the multinational genetic algorithm) instead of the common but problematic radius-triggered manner. A special treatment for offspring integration, a more rigorous control on the allowed number and uniqueness of the resulting seeds, and a more efficient fitness evaluations budget management further augment a previously suggested naïve combination of the two algorithms. Experiments have been performed on a series of benchmark test functions, including a problem from engineering design. Comparison is primarily conducted to show the significant performance difference to the naïve combination; also the related radius-dependent conserving algorithm is subsequently addressed. Additionally, three more multimodal evolutionary methods, being either conceptually close, competitive as radius-based strategies, or recent state-of-the-art are also taken into account. We detect a clear advantage of three of the six algorithms that, in the case of our method, probably comes from the proper topological separation into subpopulations according to the existing attraction basins, independent of their locations in the function landscape. Additionally, an investigation of the parameter independence of the method as compared to the radius-compelled algorithms is systematically accomplished.","Computer science,
Genetic algorithms,
Financial management,
Performance evaluation,
Benchmark testing,
Design engineering,
Mathematics,
Evolutionary computation,
Optimization methods"
Kernel Discriminant Learning for Ordinal Regression,"Ordinal regression has wide applications in many domains where the human evaluation plays a major role. Most current ordinal regression methods are based on Support Vector Machines (SVM) and suffer from the problems of ignoring the global information of the data and the high computational complexity. Linear Discriminant Analysis (LDA) and its kernel version, Kernel Discriminant Analysis (KDA), take into consideration the global information of the data together with the distribution of the classes for classification, but they have not been utilized for ordinal regression yet. In this paper, we propose a novel regression method by extending the Kernel Discriminant Learning using a rank constraint. The proposed algorithm is very efficient since the computational complexity is significantly lower than other ordinal regression methods. We demonstrate experimentally that the proposed method is capable of preserving the rank of data classes in a projected data space. In comparison to other benchmark ordinal regression methods, the proposed method is competitive in accuracy.","Kernel,
Support vector machines,
Linear discriminant analysis,
Machine learning algorithms,
Computational complexity,
Constraint optimization,
Sun,
Humans,
Support vector machine classification,
Information analysis"
Simultaneous Estimation of Chords and Musical Context From Audio,"Chord labels provide a concise description of musical harmony. In pop and jazz music, a sequence of chord labels is often the only written record of a song, and forms the basis of so-called lead sheets. We devise a fully automatic method to simultaneously estimate from an audio waveform the chord sequence including bass notes, the metric positions of chords, and the key. The core of the method is a six-layered dynamic Bayesian network, in which the four hidden source layers jointly model metric position, key, chord, and bass pitch class, while the two observed layers model low-level audio features corresponding to bass and treble tonal content. Using 109 different chords our method provides substantially more harmonic detail than previous approaches while maintaining a high level of accuracy. We show that with 71% correctly classified chords our method significantly exceeds the state of the art when tested against manually annotated ground truth transcriptions on the 176 audio tracks from the MIREX 2008 Chord Detection Task. We introduce a measure of segmentation quality and show that bass and meter modeling are especially beneficial for obtaining the correct level of granularity.","Music,
Bayesian methods,
Testing,
Multiple signal classification,
Signal processing,
Computer science,
Network topology,
Humans,
Parameter estimation"
Health-State Estimation and Prognostics in Machining Processes,"Failure mechanisms of electromechanical systems usually involve several degraded health-states. Tracking and forecasting the evolution of health-states and impending failures, in the form of remaining-useful-life (RUL), is a critical challenge and regarded as the Achilles' heel of condition-based-maintenance (CBM). This paper demonstrates how this difficult problem can be addressed through Hidden Markov models (HMMs) that are able to estimate unobservable health-states using observable sensor signals. In particular, implementation of HMM based models as dynamic Bayesian networks (DBNs) facilitates compact representation as well as additional flexibility with regard to model structure. Both regular HMM pools and hierarchical HMMs are employed here to estimate online the health-state of drill-bits as they deteriorate with use on a CNC drilling machine. Hierarchical HMM is composed of sub-HMMs in a pyramid structure, providing functionality beyond an HMM for modeling complex systems. In the case of regular HMMs, each HMM within the pool competes to represent a distinct health-state and adapts through competitive learning. In the case of hierarchical HMMs, health-states are represented as distinct nodes at the top of the hierarchy. Monte Carlo simulation, with state transition probabilities derived from a hierarchical HMM, is employed for RUL estimation. Detailed results on health-state and RUL estimation are very promising and are reported in this paper. Hierarchical HMMs seem to be particularly effective and efficient and outperform other HMM methods from literature.",
Scene understanding by statistical modeling of motion patterns,"We present a novel method for the discovery and statistical representation of motion patterns in a scene observed by a static camera. Related methods involving learning of patterns of activity rely on trajectories obtained from object detection and tracking systems, which are unreliable in complex scenes of crowded motion. We propose a mixture model representation of salient patterns of optical flow, and present an algorithm for learning these patterns from dense optical flow in a hierarchical, unsupervised fashion. Using low level cues of noisy optical flow, K-means is employed to initialize a Gaussian mixture model for temporally segmented clips of video. The components of this mixture are then filtered and instances of motion patterns are computed using a simple motion model, by linking components across space and time. Motion patterns are then initialized and membership of instances in different motion patterns is established by using KL divergence between mixture distributions of pattern instances. Finally, a pixel level representation of motion patterns is proposed by deriving conditional expectation of optical flow. Results of extensive experiments are presented for multiple surveillance sequences containing numerous patterns involving both pedestrian and vehicular traffic.","Layout,
Optical filters,
Image motion analysis,
Cameras,
Trajectory,
Object detection,
Tracking,
Gaussian noise,
Noise level,
Optical noise"
Online Signature Verification With Support Vector Machines Based on LCSS Kernel Functions,"In this paper, a new technique for online signature verification or identification is proposed. The technique integrates a longest common subsequences (LCSS) detection algorithm which measures the similarity of signature time series into a kernel function for support vector machines (SVM). LCSS offers the possibility to consider the local variability of signals such as the time series of pen-tip coordinates on a graphic tablet, forces on a pen, or inclination angles of a pen measured during a signing process. Consequently, the similarity of two signature time series can be determined in a more reliable way than with other measures. A proprietary database with signatures of 153 test persons and the SVC 2004 benchmark database are used to show the properties of the new SVM-LCSS. We investigate its parameterization and compare it to SVM with other kernel functions such as dynamic time warping (DTW). Our experiments show that SVM with the LCSS kernel authenticate persons very reliably and with a performance which is significantly better than that of the best comparing technique, SVM with DTW kernel.","Handwriting recognition,
Support vector machines,
Kernel,
Time measurement,
Databases,
Detection algorithms,
Signal processing,
Graphics,
Coordinate measuring machines,
Force measurement"
Improving MapReduce performance through data placement in heterogeneous Hadoop clusters,"MapReduce has become an important distributed processing model for large-scale data-intensive applications like data mining and web indexing. Hadoop-an open-source implementation of MapReduce is widely used for short jobs requiring low response time. The current Hadoop implementation assumes that computing nodes in a cluster are homogeneous in nature. Data locality has not been taken into account for launching speculative map tasks, because it is assumed that most maps are data-local. Unfortunately, both the homogeneity and data locality assumptions are not satisfied in virtualized data centers. We show that ignoring the data-locality issue in heterogeneous environments can noticeably reduce the MapReduce performance. In this paper, we address the problem of how to place data across nodes in a way that each node has a balanced data processing load. Given a dataintensive application running on a Hadoop MapReduce cluster, our data placement scheme adaptively balances the amount of data stored in each node to achieve improved data-processing performance. Experimental results on two real data-intensive applications show that our data placement strategy can always improve the MapReduce performance by rebalancing data across nodes before performing a data-intensive application in a heterogeneous Hadoop cluster.","Peer to peer computing,
Data processing,
Large-scale systems,
Data mining,
Indexing,
Open source software,
Facebook,
Programming profession,
Computer science,
Software engineering"
Modular Robot Systems,"We have presented a detailed retrospective on modular robots and discussed connections between modular robots and programmable matter. This field has seen a great deal of creativity and innovation at the level of designing physical systems capable of matching shape to function and algorithms that achieve this capability. The success of these projects rests on the convergence of innovation in hardware design and materials for creating the basic building blocks, information distribution for programming the interaction between the blocks, and control. Most current systems have dimensions on the order of centimeters, yet pack computation, communication, sensing, and power transfer capabilities into their form factors. Additionally, these modules operate using distributed algorithms that use a modules ability to observe its current neighborhood and local rules to decide what to do next.","Mobile robots,
Connectors,
Robot kinematics,
Lattices,
Modular construction"
Correction of Spatially Varying Image and Video Motion Blur Using a Hybrid Camera,"We describe a novel approach to reduce spatially varying motion blur in video and images using a hybrid camera system. A hybrid camera is a standard video camera that is coupled with an auxiliary low-resolution camera sharing the same optical path but capturing at a significantly higher frame rate. The auxiliary video is temporally sharper but at a lower resolution, while the lower frame-rate video has higher spatial resolution but is susceptible to motion blur. Our deblurring approach uses the data from these two video streams to reduce spatially varying motion blur in the high-resolution camera with a technique that combines both deconvolution and super-resolution. Our algorithm also incorporates a refinement of the spatially varying blur kernels to further improve results. Our approach can reduce motion blur from the high-resolution video as well as estimate new high-resolution frames at a higher frame rate. Experimental results on a variety of inputs demonstrate notable improvement over current state-of-the-art methods in image/video deblurring.","Video sharing,
Spatial resolution,
Deconvolution,
Sampling methods,
High speed optical techniques,
Digital cameras,
High-resolution imaging,
Optical imaging,
Object segmentation,
Optical coupling"
Neural Network Output Feedback Control of Robot Formations,"In this paper, a combined kinematic/torque output feedback control law is developed for leader-follower-based formation control using backstepping to accommodate the dynamics of the robots and the formation in contrast with kinematic-based formation controllers. A neural network (NN) is introduced to approximate the dynamics of the follower and its leader using online weight tuning. Furthermore, a novel NN observer is designed to estimate the linear and angular velocities of both the follower robot and its leader. It is shown, by using the Lyapunov theory, that the errors for the entire formation are uniformly ultimately bounded while relaxing the separation principle. In addition, the stability of the formation in the presence of obstacles, is examined using Lyapunov methods, and by treating other robots in the formation as obstacles, collisions within the formation are prevented. Numerical results are provided to verify the theoretical conjectures.","Neural networks,
Output feedback,
Robot control,
Robot kinematics,
Velocity control,
State feedback,
Torque control,
Stability,
Mobile robots,
PD control"
Unsupervised Segmentation of Overlapped Nuclei Using Bayesian Classification,"In a fully automatic cell extraction process, one of the main issues to overcome is the problem related to extracting overlapped nuclei since such nuclei will often affect the quantitative analysis of cell images. In this paper, we present an unsupervised Bayesian classification scheme for separating overlapped nuclei. The proposed approach first involves applying the distance transform to overlapped nuclei. The topographic surface generated by distance transform is viewed as a mixture of Gaussians in the proposed algorithm. In order to learn the distribution of the topographic surface, the parametric expectation-maximization (EM) algorithm is employed. Cluster validation is performed to determine how many nuclei are overlapped. Our segmentation approach incorporates a priori knowledge about the regular shape of clumped nuclei to yield more accurate segmentation results. Experimental results show that the proposed method yields superior segmentation performance, compared to those produced by conventional schemes.","Bayesian methods,
Image segmentation,
Image analysis,
Surface topography,
Gaussian processes,
Biomedical imaging,
Medical diagnostic imaging,
Clustering algorithms,
Pathology,
Hospitals"
Adaptive generic learning for face recognition from a single sample per person,"Real-world face recognition systems often have to face the single sample per person (SSPP) problem, that is, only a single training sample for each person is enrolled in the database. In this case, many of the popular face recognition methods fail to work well due to the inability to learn the discriminatory information specific to the persons to be identified. To address this problem, in this paper, we propose an Adaptive Generic Learning (AGL) method, which adapts a generic discriminant model to better distinguish the persons with single face sample. As a specific implementation of the AGL, a Coupled Linear Representation (CLR) algorithm is proposed to infer, based on the generic training set, the within-class scatter matrix and the class mean of each person given its single enrolled sample. Thus, the traditional Fisher's Linear Discriminant (FLD) can be applied to SSPP task. Experiments on the FERET and a challenging passport face database show that the proposed method can achieve better results compared with other common solutions to the SSPP problem.","Face recognition,
Principal component analysis,
Linear discriminant analysis,
Computer science,
Content addressable storage,
Laboratories,
Deductive databases,
Information processing,
Scattering,
Image databases"
Random Early Detection for Congestion Avoidance in Wired Networks: A Discretized Pursuit Learning-Automata-Like Solution,"In this paper, we present a learning-automata-like (LAL) mechanism for congestion avoidance in wired networks. Our algorithm, named as LAL random early detection (LALRED), is founded on the principles of the operations of existing RED congestion-avoidance mechanisms, augmented with a LAL philosophy. The primary objective of LALRED is to optimize the value of the average size of the queue used for congestion avoidance and to consequently reduce the total loss of packets at the queue. We attempt to achieve this by stationing a LAL algorithm at the gateways and by discretizing the probabilities of the corresponding actions of the congestion-avoidance algorithm. At every time instant, the LAL scheme, in turn, chooses the action that possesses the maximal ratio between the number of times the chosen action is rewarded and the number of times that it has been chosen. In LALRED, we simultaneously increase the likelihood of the scheme converging to the action, which minimizes the number of packet drops at the gateway. Our approach helps to improve the performance of congestion avoidance by adaptively minimizing the queue-loss rate and the average queue size. Simulation results obtained using NS2 establish the improved performance of LALRED over the traditional RED methods which were chosen as the benchmarks for performance comparison purposes.","Stochastic processes,
Information technology,
Computer science,
Communication system traffic control,
Traffic control,
Learning automata,
Computer network reliability,
Computer applications,
Application software,
Government"
Stabilization and Disturbance Attenuation Over a Gaussian Communication Channel,"We consider the problem of stabilizing an unstable system driven by a Gaussian disturbance using a feedback signal transmitted over a memoryless Gaussian communication channel. By applying the concept of entropy power, we show that the mean square norm of the state vector must satisfy a lower bound that holds for any causal, measurable communication and control strategies that result in signals having well defined differential entropy. In addition, we show that use of nonlinear, time varying strategies does not allow stabilization over a channel with a lower signal-to-noise ratio than that achievable with linear time invariant state feedback. Finally, we show that for scalar systems the lower bound on the mean square norm of the state is tight, and achievable using linear time invariant communication and control.","Attenuation,
Communication channels,
Communication system control,
Automatic control,
Bandwidth,
Internet,
Shape control,
Control systems,
Communication networks,
Peer to peer computing"
Performance evaluation of a Green Scheduling Algorithm for energy savings in Cloud computing,"With energy shortages and global climate change leading our concerns these days, the power consumption of datacenters has become a key issue. Obviously, a substantial reduction in energy consumption can be made by powering down servers when they are not in use. This paper aims at designing, implementing and evaluating a Green Scheduling Algorithm integrating a neural network predictor for optimizing server power consumption in Cloud computing. We employ the predictor to predict future load demand based on historical demand. According to the prediction, the algorithm turns off unused servers and restarts them to minimize the number of running servers, thus minimizing the energy use at the points of consumption to benefit all other levels. For evaluation, we perform simulations with two load traces. The results show that the PP20 mode can save up to 46.3% of power consumption with a drop rate of 0.03% on one load trace, and a drop rate of 0.12% with a power reduction rate of 46.7% on the other.","Scheduling algorithm,
Cloud computing,
Energy consumption,
Network servers,
Costs,
Neural networks,
Information science,
Algorithm design and analysis,
Design optimization,
Prediction algorithms"
Noise-optimal capture for high dynamic range photography,"Taking multiple exposures is a well-established approach both for capturing high dynamic range (HDR) scenes and for noise reduction. But what is the optimal set of photos to capture? The typical approach to HDR capture uses a set of photos with geometrically-spaced exposure times, at a fixed ISO setting (typically ISO 100 or 200). By contrast, we show that the capture sequence with optimal worst-case performance, in general, uses much higher and variable ISO settings, and spends longer capturing the dark parts of the scene. Based on a detailed model of noise, we show that optimal capture can be formulated as a mixed integer programming problem. Compared to typical HDR capture, our method lets us achieve higher worst-case SNR in the same capture time (for some cameras, up to 19 dB improvement in the darkest regions), or much faster capture for the same minimum acceptable level of SNR. Our experiments demonstrate this advantage for both real and synthetic scenes.","Dynamic range,
Photography,
Signal to noise ratio,
Cameras,
Layout,
Additive noise,
ISO standards,
Noise reduction,
Linear programming,
Computer science"
Hyperspectral Region Classification Using a Three-Dimensional Gabor Filterbank,"A 3-D spectral/spatial discrete Fourier transform can be used to represent a hyperspectral image region using a dense sampling in the frequency domain. In many cases, a more compact frequency-domain representation that preserves the 3-D structure of the data can be exploited. For this purpose, we have developed a new model for spectral/spatial information based on 3-D Gabor filters. These filters capture specific orientation, scale, and wavelength-dependent properties of hyperspectral image data and provide an efficient means of sampling a 3-D frequency-domain representation. Since 3-D Gabor filters allow for a large number of spectral/spatial features to be used to represent an image region, the performance and efficiency of algorithms that use this representation can be further improved if methods are available to reduce the size of the model. Thus, we have derived methods for selecting features that emphasize the most significant spectral/spatial differences between the various classes in a scene. We demonstrate the performance of the 3-D Gabor features for the classification of regions in Airborne Visible/Infrared Imaging Spectrometer hyperspectral data. The new features are compared against pure spectral features and multiband generalizations of gray-level co-occurrence matrix features.","Filter bank,
Hyperspectral imaging,
Gabor filters,
Image sampling,
Discrete Fourier transforms,
Frequency domain analysis,
Layout,
Infrared imaging,
Infrared spectra,
Spectroscopy"
A Genetic Programming Hyper-Heuristic Approach for Evolving 2-D Strip Packing Heuristics,"We present a genetic programming (GP) system to evolve reusable heuristics for the 2-D strip packing problem. The evolved heuristics are constructive, and decide both which piece to pack next and where to place that piece, given the current partial solution. This paper contributes to a growing research area that represents a paradigm shift in search methodologies. Instead of using evolutionary computation to search a space of solutions, we employ it to search a space of heuristics for the problem. A key motivation is to investigate methods to automate the heuristic design process. It has been stated in the literature that humans are very good at identifying good building blocks for solution methods. However, the task of intelligently searching through all of the potential combinations of these components is better suited to a computer. With such tools at their disposal, heuristic designers are then free to commit more of their time to the creative process of determining good components, while the computer takes on some of the design process by intelligently combining these components. This paper shows that a GP hyper-heuristic can be employed to automatically generate human competitive heuristics in a very-well studied problem domain.","Genetic programming,
Strips,
Humans,
Evolutionary computation,
Process design,
Computer science,
Sheet materials,
Councils,
Job shop scheduling,
Processor scheduling"
A Machine Learning Approach to TCP Throughput Prediction,"TCP throughput prediction is an important capability for networks where multiple paths exist between data senders and receivers. In this paper, we describe a new lightweight method for TCP throughput prediction. Our predictor uses Support Vector Regression (SVR); prediction is based on both prior file transfer history and measurements of simple path properties. We evaluate our predictor in a laboratory setting where ground truth can be measured with perfect accuracy. We report the performance of our predictor for oracular and practical measurements of path properties over a wide range of traffic conditions and transfer sizes. For bulk transfers in heavy traffic using oracular measurements, TCP throughput is predicted within 10% of the actual value 87% of the time, representing nearly a threefold improvement in accuracy over prior history-based methods. For practical measurements of path properties, predictions can be made within 10% of the actual value nearly 50% of the time, approximately a 60% improvement over history-based methods, and with much lower measurement traffic overhead. We implement our predictor in a tool called PathPerf, test it in the wide area, and show that PathPerf predicts TCP throughput accurately over diverse wide area paths.","Machine learning,
Throughput,
Time measurement,
Size measurement,
History,
Laboratories,
Testing,
Computer science,
Instruments"
On the stability of wholesale electricity markets under real-time pricing,"The paper proposes a mathematical model for the dynamic evolution of supply, demand, and clearing prices under a class of real-time pricing mechanisms characterized by passing on the real-time wholesale prices to the end consumers. The effects that such mechanisms could pose on the stability and efficiency of the entire system is investigated and several stability criteria are presented. It is shown that relaying the real-time wholesale electricity prices to the end consumers creates a closed loop feedback system which could be unstable or lack robustness, leading to extreme price volatility. Finally, a result is presented which characterizes the efficiency losses incurred when, in order to achieve stability, the wholesale prices are adjusted by a static pricing function before they are passed on to the retail consumers.",
Varactor-Tuned Dual-Mode Bandpass Filters,"This paper presents a new type of varactor-tuned dual-mode bandpass filter. Since the two operating modes (i.e., the odd and even modes) in a dual-mode microstrip open-loop resonator do not couple to each other, the tuning of the passband frequency becomes simple with a single dc-bias circuit while keeping nearly constant absolute bandwidth. Design equations and procedures are derived, and two two-pole tunable bandpass filters of this type are demonstrated experimentally.","Band pass filters,
Resonator filters,
Tunable circuits and devices,
Tuning,
Microwave filters,
Microstrip resonators,
Frequency,
Bandwidth,
Microstrip filters,
Coupling circuits"
Autonomic traffic engineering for network robustness,"The continuously increasing complexity of communication networks and the increasing diversity and unpredictability of traffic demand has led to a consensus view that the automation of the management process is inevitable. Currently, network and service management techniques are mostly manual, requiring human intervention, and leading to slow response times, high costs, and customer dissatisfaction. In this paper we present AutoNet, a self-organizing management system for core networks where robustness to environmental changes, namely traffic shifts, topology changes, and community of interest is viewed as critical. A framework to design robust control strategies for autonomic networks is proposed. The requirements of the network are translated to graph-theoretic metrics and the management system attempts to automatically evolve to a stable and robust control point by optimizing these metrics. The management approach is inspired by ideas from evolutionary science where a metric, network criticality, measures the survival value or robustness of a particular network configuration. In our system, network criticality is a measure of the robustness of the network to environmental changes. The control system is designed to direct the evolution of the system state in the direction of increasing robustness. As an application of our framework, we propose a traffic engineering method in which different paths are ranked based on their robustness measure, and the best path is selected to route the flow. The choice of the path is in the direction of preserving the robustness of the network to the unforeseen changes in topology and traffic demands. Furthermore, we develop a method for capacity assignment to optimize the robustness of the network.",
Diamonds in the rough: Social media visual analytics for journalistic inquiry,"Journalists increasingly turn to social media sources such as Facebook or Twitter to support their coverage of various news events. For large-scale events such as televised debates and speeches, the amount of content on social media can easily become overwhelming, yet still contain information that may aid and augment reporting via individual content items as well as via aggregate information from the crowd's response. In this work we present a visual analytic tool, Vox Civitas, designed to help journalists and media professionals extract news value from large-scale aggregations of social media content around broadcast events. We discuss the design of the tool, present the text analysis techniques used to enable the presentation, and provide details on the visual and interaction design. We provide an exploratory evaluation based on a user study in which journalists interacted with the system to explore and report on a dataset of over one hundred thousand twitter messages collected during the U.S. State of the Union presidential address in 2010.","Media,
Twitter,
Aggregates,
Context,
Classification algorithms,
Filtering,
Visual analytics"
Securing Cloud from DDOS Attacks Using Intrusion Detection System in Virtual Machine,"Innovation is necessary to ride the inevitable tide of change. The buzzword of 2009 seems to be ""cloud computing"" which is a futuristic platform to provides dynamic resource pools, virtualization, and high availability and enables the sharing, selection and aggregation of geographically distributed heterogeneous resources for solving large-scale problems in science and engineering. But with this ever developing cloud concept, problems are arising from this “golden solution” in the enterprise arena. Preventing intruders from attacking the cloud infrastructure is the only realistic thing the staff, management and planners can foresee. Regardless of company size or volume and magnitude of the cloud, this paper explains how maneuver IT virtualization strategy could be used in responding to a denial of service attack. After picking up a grossly abnormal spike in inbound traffic, targeted applications could be immediately transferred to virtual machines hosted in another data center. We’re not reinventing the wheel. We have lots of technology and standardized solutions we can already use to engineer into the stack. We are just introducing them in the way least expected.","Computer crime,
Intrusion detection,
Virtual machining,
Technological innovation,
Tides,
Cloud computing,
Resource virtualization,
Platform virtualization,
Availability,
Large-scale systems"
Estimating and Fusing Quality Factors for Iris Biometric Images,"Iris recognition, the ability to recognize and distinguish individuals by their iris pattern, is one of the most reliable biometrics in terms of recognition and identification performance. However, the performance of these systems is affected by poor-quality imaging. In this paper, we extend iris quality assessment research by analyzing the effect of various quality factors such as defocus blur, off-angle, occlusion/specular reflection, lighting, and iris resolution on the performance of a traditional iris recognition system. We further design a fully automated iris image quality evaluation block that estimates defocus blur, motion blur, off-angle, occlusion, lighting, specular reflection, and pixel counts. First, each factor is estimated individually, and then, the second step fuses the estimated factors by using a Dempster-Shafer theory approach to evidential reasoning. The designed block is evaluated on three data sets: Institute of Automation, Chinese Academy of Sciences (CASIA) 3.0 interval subset, West Virginia University (WVU) non-ideal iris, and Iris Challenge Evaluation (ICE) 1.0 dataset made available by National Institute for Standards and Technology (NIST). Considerable improvement in recognition performance is demonstrated when removing poor-quality images selected by our quality metric. The upper bound on computational complexity required to evaluate the quality of a single image is O(n2 log n).","Q factor,
Biometrics,
Iris recognition,
Pattern recognition,
Optical reflection,
Quality assessment,
Performance analysis,
Image quality,
Motion estimation,
Pixel"
Algebraic Synthesis of Timed Supervisor for Automated Manufacturing Systems Using Petri Nets,"For practical automated manufacturing systems (AMSs), the time dimension is of great significance and should be integrated in their plant models. Reasonably, many of the realistic general mutual exclusion constraints (GMECs) imposed on these discrete models should be timed rather than merely algebraic or logic. In the past, such a problem was studied on the basis of the Ramadge-Wonham supervisory control technique (SCT) and the theory of regions. It proves to be NP-hard since it necessitates the generation of reachability graphs. This paper shows that it can be solvable in polynomial time by using generalized linear constraints, which are originally proposed to increase the expressive power of the linear marking constraints. By dividing each constraint into marking, firing vector, and Parikh terms, its respective control place can be synthesized algebraically without considering the separation of dangerous states and events. Several examples are used to validate the effectiveness and efficiency of the proposed approach.",
A Novel Approach to Monitor Rehabilitation Outcomes in Stroke Survivors Using Wearable Technology,"Quantitative assessment of motor abilities in stroke survivors can provide valuable feedback to guide clinical interventions. Numerous clinical scales were developed in the past to assess levels of impairment and functional limitation in individuals after stroke. The Functional Ability Scale is one of these clinical scales. It is a 75-point scale used to evaluate the functional ability of subjects by grading movement quality during performance of 15 motor tasks. Performance of these motor tasks requires subjects to reach for objects (e.g., a pencil on a table) and manipulate them (e.g., lift the pencil). In this paper, we show that accelerometer data recorded during performance of a subset of the motor tasks pertaining to the Functional Ability Scale can be relied upon to derive accurate estimates of the scores provided by a clinician using this scale. Accelerometer-based estimates of clinical scores were obtained by segmenting the recordings into movement components (reaching, manipulation, release/return), extracting data features, selecting features that maximized the separation among classes associated with different clinical scores, feeding these features to Random Forests to estimate scores for individual motor tasks, and using a linear equation to estimate the total Functional Ability Scale score based on the sum of the clinical scores for individual motor tasks derived from the accelerometer data. Results showed that it is possible to achieve estimates of the total Functional Ability Scale score marked by a bias of only 0.04 points of the scale and a standard deviation of only 2.43 points when using as few as three sensors to collect data during performance of only six motor tasks.","Biomedical monitoring,
Accelerometers,
Patient monitoring,
Medical treatment,
Biomedical measurements,
Hospitals,
Biomedical engineering,
Fingers,
Feedback,
Data mining"
On the Use of Automated Text Summarization Techniques for Summarizing Source Code,"During maintenance developers cannot read the entire code of large systems. They need a way to get a quick understanding of source code entities (such as, classes, methods, packages, etc.), so they can efficiently identify and then focus on the ones related to their task at hand. Sometimes reading just a method header or a class name does not tell enough about its purpose and meaning, while reading the entire implementation takes too long. We study a solution which mitigates the two approaches, i.e., short and accurate textual descriptions that illustrate the software entities without having to read the details of the implementation. We create such descriptions using techniques from automatic text summarization. The paper presents a study that investigates the suitability of various such techniques for generating source code summaries. The results indicate that a combination of text summarization techniques is most appropriate for source code summarization and that developers generally agree with the summaries produced.",
High-Performance Integrated Dual-Gate AlGaN/GaN Enhancement-Mode Transistor,"In this letter, we present a new AlGaN/GaN enhancement-mode (E-mode) transistor based on a dual-gate structure. The dual gate allows the transistor to combine an E-mode behavior with low on-resistance and very high breakdown voltage. The device utilizes an integrated gate structure with a short gate controlling the threshold voltage and a long gate supporting the high-voltage drop from the drain. Using this new dual-gate technology, AlGaN/GaN E-mode transistors grown on a Si substrate have demonstrated a high threshold voltage of 2.9 V with a maximum drain current of 434 mA/mm and a specific on-resistance of 4.3 m Ω·cm2 at a breakdown voltage of 643 V.","Aluminum gallium nitride,
Gallium nitride,
MOSFETs,
HEMTs,
Threshold voltage,
Power electronics,
MODFETs,
Reliability engineering,
Power engineering and energy,
Circuit topology"
An optimal coding strategy for the binary multi-way relay channel,"We derive the capacity of the binary multi-way relay channel, in which multiple users exchange messages at a common rate through a relay. The capacity is achieved using a novel functional-decode-forward coding strategy. In the functional-decode-forward coding strategy, the relay decodes functions of the users' messages without needing to decode individual messages. The functions to be decoded by the relay are defined such that when the relay broadcasts the functions back to the users, every user is able to decode the messages of all other users.",
Threshold saturation via spatial coupling: Why convolutional LDPC ensembles perform so well over the BEC,"Convolutional LDPC ensembles, introduced by Felström and Zigangirov, have excellent thresholds and these thresholds are rapidly increasing as a function of the average degree. Several variations on the basic theme have been proposed to date, all of which share the good performance characteristics of convolutional LDPC ensembles. We describe the fundamental mechanism which explains why “convolutional-like” or “spatially coupled” codes perform so well. In essence, the spatial coupling of the individual code structure has the effect of increasing the belief-propagation (BP) threshold of the new ensemble to its maximum possible value, namely the maximum-a-posteriori (MAP) threshold of the underlying ensemble. For this reason we call this phenomenon “threshold saturation”. This gives an entirely new way of approaching capacity. One significant advantage of such a construction is that one can create capacity-approaching ensembles with an error correcting radius which is increasing in the blocklength. Our proof makes use of the area theorem of the BP-EXIT curve and the connection between the MAP and BP threshold recently pointed out by Méasson, Montanari, Richardson, and Urbanke. Although we prove the connection between the MAP and the BP threshold only for a very specific ensemble and only for the binary erasure channel, empirically the same statement holds for a wide class of ensembles and channels. More generally, we conjecture that for a large range of graphical systems a similar collapse of thresholds occurs once individual components are coupled sufficiently strongly. This might give rise to improved algorithms as well as to new techniques for analysis.","Parity check codes,
Convolutional codes,
Decoding,
Floors,
Error correction,
Algorithm design and analysis"
Online Segmentation of Time Series Based on Polynomial Least-Squares Approximations,"The paper presents SwiftSeg, a novel technique for online time series segmentation and piecewise polynomial representation. The segmentation approach is based on a least-squares approximation of time series in sliding and/or growing time windows utilizing a basis of orthogonal polynomials. This allows the definition of fast update steps for the approximating polynomial, where the computational effort depends only on the degree of the approximating polynomial and not on the length of the time window. The coefficients of the orthogonal expansion of the approximating polynomial-obtained by means of the update steps-can be interpreted as optimal (in the least-squares sense) estimators for average, slope, curvature, change of curvature, etc., of the signal in the time window considered. These coefficients, as well as the approximation error, may be used in a very intuitive way to define segmentation criteria. The properties of SwiftSeg are evaluated by means of some artificial and real benchmark time series. It is compared to three different offline and online techniques to assess its accuracy and runtime. It is shown that SwiftSeg-which is suitable for many data streaming applications-offers high accuracy at very low computational costs.","Polynomials,
Signal processing algorithms,
Computer errors,
Piecewise linear approximation,
Change detection algorithms,
Clustering algorithms,
Runtime,
Piecewise linear techniques,
Partitioning algorithms,
Approximation error"
A hybrid reservation/contention-based MAC for video streaming over wireless networks,"To reserve or not for bursty video traffic over wireless access networks has been a long-debated issue. For uplink transmissions in infrastructure-based wireless networks and peer-to-peer transmissions in mesh or ad-hoc networks, reservation can ensure the Quality-of-Service (QoS) provisioning at the cost of a lower degree of resource utilization. Contention-based Medium Access Control (MAC) protocols are more flexible and efficient in sharing resources by bursty traffic to achieve a higher multiplexing gain, but the performance may degrade severely when the network is congested and collisions occur frequently. More and more wireless standards adopt a hybrid approach, which allows the coexistence of resource reservation and contention-based MAC protocols. However, how to cost-effectively support video traffic using hybrid MAC protocols is still an open issue. In this paper, we first propose how to use hybrid MAC protocols to support video streaming over wireless networks. Then, we quantify the performance of video traffic over wireless networks with contention-only, reservation-only, and hybrid MAC protocols, respectively. Admission regions for video streams with these three approaches are obtained. Using the standard WiMedia MAC protocols as an example, extensive simulations with a commonly-used network simulator (NS-2) and real video traces are conducted to verify the analysis. The analytical and simulation results reveal the tradeoff between reservation and contention-based medium access strategies, and demonstrate the effectiveness of the hybrid approach.","Streaming media,
Wireless networks,
Media Access Protocol,
Wireless application protocol,
Analytical models,
Wireless mesh networks,
Communication system traffic control,
Access protocols,
Telecommunication traffic,
Peer to peer computing"
A Self-Adaptive RBF Neural Network Classifier for Transformer Fault Analysis,"A new hybrid self-adaptive training approach-based radial basis function (RBF) neural network for power transformer fault diagnosis is presented in this paper. The proposed method is able to generate RBF neural network models based on fuzzy c-means (FCM) and quantum-inspired particle swarm optimization (QPSO), which can automatically configure network structure and obtain model parameters. With these methods, the number of neuron, centers and radii of hidden layer activated functions, as well as output connection weights can be automatically calculated. This learning method is proved to be effective by applying the RBF neural network in the classification of five benchmark testing data sets, and power transformer fault data set. The results clearly demonstrated the improved classification accuracy compared with other alternatives and showed that it can be used as a reliable tool for power transformer fault analysis.","Neural networks,
Power transformers,
Fault diagnosis,
Oil insulation,
Power system reliability,
Power transformer insulation,
Humans,
Particle swarm optimization,
Power system stability,
Dissolved gas analysis"
Modeling pixel means and covariances using factorized third-order boltzmann machines,"Learning a generative model of natural images is a useful way of extracting features that capture interesting regularities. Previous work on learning such models has focused on methods in which the latent features are used to determine the mean and variance of each pixel independently, or on methods in which the hidden units determine the covariance matrix of a zero-mean Gaussian distribution. In this work, we propose a probabilistic model that combines these two approaches into a single framework. We represent each image using one set of binary latent features that model the image-specific covariance and a separate set that model the mean. We show that this approach provides a probabilistic framework for the widely used simple-cell complex-cell architecture, it produces very realistic samples of natural images and it extracts features that yield state-of-the-art recognition accuracy on the challenging CIFAR 10 dataset.","Pixel,
Image reconstruction,
Feature extraction,
Covariance matrix,
Object recognition,
Computer science,
Educational institutions,
Machine learning,
Gaussian distribution,
Data mining"
Active Learning From Stream Data Using Optimal Weight Classifier Ensemble,"In this paper, we propose a new research problem on active learning from data streams, where data volumes grow continuously, and labeling all data is considered expensive and impractical. The objective is to label a small portion of stream data from which a model is derived to predict future instances as accurately as possible. To tackle the technical challenges raised by the dynamic nature of the stream data, i.e., increasing data volumes and evolving decision concepts, we propose a classifier-ensemble-based active learning framework that selectively labels instances from data streams to build a classifier ensemble. We argue that a classifier ensemble's variance directly corresponds to its error rate, and reducing a classifier ensemble's variance is equivalent to improving its prediction accuracy. Because of this, one should label instances toward the minimization of the variance of the underlying classifier ensemble. Accordingly, we introduce a minimum-variance (MV) principle to guide the instance labeling process for data streams. In addition, we derive an optimal-weight calculation method to determine the weight values for the classifier ensemble. The MV principle and the optimal weighting module are combined to build an active learning framework for data streams. Experimental results on synthetic and real-world data demonstrate the performance of the proposed work in comparison with other approaches.","Labeling,
Predictive models,
Accuracy,
Data mining,
Error analysis,
Decision making,
Australia,
Computer science,
Information technology,
Information management"
Standardization and research in cognitive and dynamic spectrum access networks: IEEE SCC41 efforts and other activities,"Spectrum crowding, spectrum management, quality of service, and user support are the topics of vigorous research in the cognitive and dynamic spectrum access network communities. As research matures, standardization provides a bridge between research results, implementation, and widespread deployment of such networks. This article reports recent developments within the IEEE Standardization Coordinating Committee 41, ""Dynamic Spectrum Access Networks."" It outlines possible future standardization topics for IEEE SCC41, in the framework of other related standardization activities, and discusses open research issues that present future challenges for the standardization community.","Standardization,
Chromium,
Radio spectrum management,
IEEE activities,
Telecommunication standards,
Computer science,
Communications Society,
Standards Coordinating Committees,
Standards development,
Computer networks"
Modified Kirchhoff Migration for UWB MIMO Array-Based Radar Imaging,"In this paper, the formulation of Kirchhoff migration is modified for multiple-input-multiple-output (MIMO) array-based radar imaging in both free-space and subsurface scenarios. By applying the Kirchhoff integral to the multistatic data acquisition, the integral expression for the MIMO imaging is explicitly derived. Inclusion of the Snell's law and the Fresnel's equations into the integral formulation further expends the migration technique to subsurface imaging. A modification of the technique for strongly offset targets is proposed as well. The developed migration techniques are able to perform imaging with arbitrary MIMO configurations, which allow further exploration of the benefits of various array topologies. The proposed algorithms are compared with conventional diffraction stack migration on free-space synthetic data and experimentally validated by ground-penetrating radar experiments in subsurface scenarios. The results show that the modified Kirchhoff migration is superior over the conventional diffraction stack migration in the aspects of resolution, side-lobe level, clutter rejection ratio, and the ability to reconstruct shapes of distributed targets.","MIMO,
Radar imaging,
Integral equations,
Diffraction,
Data acquisition,
Topology,
Ground penetrating radar,
Clutter,
Image reconstruction,
Shape"
Regional Registration for Expression Resistant 3-D Face Recognition,"Biometric identification from three-dimensional (3-D) facial surface characteristics has become popular, especially in high security applications. In this paper, we propose a fully automatic expression insensitive 3-D face recognition system. Surface deformations due to facial expressions are a major problem in 3-D face recognition. The proposed approach deals with such challenging conditions in several aspects. First, we employ a fast and accurate region-based registration scheme that uses common region models. These common models make it possible to establish correspondence to all the gallery samples in a single registration pass. Second, we utilize curvature-based 3-D shape descriptors. Last, we apply statistical feature extraction methods. Since all the 3-D facial features are regionally registered to the same generic facial component, subspace construction techniques may be employed. We show that linear discriminant analysis significantly boosts the identification accuracy. We demonstrate the recognition ability of our system using the multiexpression Bosphorus and the most commonly used 3-D face database, Face Recognition Grand Challenge (FRGCv2). Our experimental results show that in both databases we obtain comparable performance to the best rank-1 correct classification rates reported in the literature so far: 98.19% for the Bosphorus and 97.51% for the FRGCv2 database. We have also carried out the standard receiver operating characteristics (ROC III) experiment for the FRGCv2 database. At an FAR of 0.1%, the verification performance was 86.09%. This shows that model-based registration is beneficial in identification scenarios where speed-up is important, whereas for verification one-to-one registration can be more beneficial.",
A Blind Watermarking Scheme Using New Nontensor Product Wavelet Filter Banks,"As an effective method for copyright protection of digital products against illegal usage, watermarking in wavelet domain has recently received considerable attention due to the desirable multiresolution property of wavelet transform. In general, images can be represented with different resolutions by the wavelet decomposition, analogous to the human visual system (HVS). Usually, human eyes are insensitive to image singularities revealed by different high frequency subbands of wavelet decomposed images. Hence, adding watermarks into these singularities will improve the imperceptibility that is a desired property of a watermarking scheme. That is, the capability for revealing singularities of images plays a key role in designing wavelet-based watermarking algorithms. Unfortunately, the existing wavelets have a limited ability in revealing singularities in different directions. This motivates us to construct new wavelet filter banks that can reveal singularities in all directions. In this paper, we utilize special symmetric matrices to construct the new nontensor product wavelet filter banks, which can capture the singularities in all directions. Empirical studies will show their advantages of revealing singularities in comparison with the existing wavelets. Based upon these new wavelet filter banks, we, therefore, propose a modified significant difference watermarking algorithm. Experimental results show its promising results.","Watermarking,
Filter bank,
Wavelet domain,
Humans,
Copyright protection,
Wavelet transforms,
Image resolution,
Visual system,
Eyes,
Frequency"
3D Scene priors for road detection,"Vision–based road detection is important in different areas of computer vision such as autonomous driving, car collision warning and pedestrian crossing detection. However, current vision–based road detection methods are usually based on low–level features and they assume structured roads, road homogeneity, and uniform lighting conditions. Therefore, in this paper, contextual 3D information is used in addition to low–level cues. Low–level photometric invariant cues are derived from the appearance of roads. Contextual cues used include horizon lines, vanishing points, 3D scene layout and 3D road stages. Moreover, temporal road cues are included. All these cues are sensitive to different imaging conditions and hence are considered as weak cues. Therefore, they are combined to improve the overall performance of the algorithm. To this end, the low-level, contextual and temporal cues are combined in a Bayesian framework to classify road sequences. Large scale experiments on road sequences show that the road detection method is robust to varying imaging conditions, road types, and scenarios (tunnels, urban and highway). Further, using the combined cues outperforms all other individual cues. Finally, the proposed method provides highest road detection accuracy when compared to state–of–the–art methods.","Layout,
Shape,
Computer vision,
Robustness,
Data mining,
Computer science,
Road accidents,
Photometry,
Bayesian methods,
Road transportation"
Non-rigid structure from locally-rigid motion,"We introduce locally-rigid motion, a general framework for solving the M-point, N-view structure-from-motion problem for unknown bodies deforming under orthography. The key idea is to first solve many local 3-point, N-view rigid problems independently, providing a “soup” of specific, plausibly rigid, 3D triangles. The main advantage here is that the extraction of 3D triangles requires only very weak assumptions: (1) deformations can be locally approximated by near-rigid motion of three points (i.e., stretching not dominant) and (2) local motions involve some generic rotation in depth. Triangles from this soup are then grouped into bodies, and their depth flips and instantaneous relative depths are determined. Results on several sequences, both our own and from related work, suggest these conditions apply in diverse settings - including very challenging ones (e.g., multiple deforming bodies). Our starting point is a novel linear solution to 3-point structure from motion, a problem for which no general algorithms currently exist.","Shape,
Layout,
Image reconstruction,
Computer science,
Mouth,
Training data,
Concrete"
A Study of k-Coverage and Measures of Connectivity in 3D Wireless Sensor Networks,"In a wireless sensor network (WSN), connectivity enables the sensors to communicate with each other, while sensing coverage reflects the quality of surveillance. Although the majority of studies on coverage and connectivity in WSNs consider 2D space, 3D settings represent more accurately the network design for real-world applications. As an example, underwater sensor networks require design in 3D rather than 2D space. In this paper, we focus on the connectivity and k-coverage issues in 3D WSNs, where each point is covered by at least k sensors (the maximum value of k is called the coverage degree). Precisely, we propose the Reuleaux tetrahedron model to characterize k-coverage of a 3D field and investigate the corresponding minimum sensor spatial density. We prove that a 3D field is guaranteed to be k-covered if any Reuleaux tetrahedron region of the field contains at least k sensors. We also compute the connectivity of 3D k-covered WSNs. Based on the concepts of conditional connectivity and forbidden faulty sensor set, which cannot include all the neighbors of a sensor, we prove that 3D k-covered WSNs can sustain a large number of sensor failures. Precisely, we prove that 3D k-covered WSNs have connectivity higher than their coverage degree k. Then, we relax some widely used assumptions in coverage and connectivity in WSNs, such as sensor homogeneity and unit sensing and communication model, so as to promote the practicality of our results in real-world scenarios. Also, we propose a placement strategy of sensors to achieve full k-coverage of a 3D field. This strategy can be used in the design of energy-efficient scheduling protocols for 3D k-covered WSNs to extend the network lifetime.","Wireless sensor networks,
Three dimensional displays,
Sensor phenomena and characterization,
Data mining,
Batteries,
Protocols"
A Model-Based Fault-Detection and Prediction Scheme for Nonlinear Multivariable Discrete-Time Systems With Asymptotic Stability Guarantees,"In this paper, a novel, unified model-based fault-detection and prediction (FDP) scheme is developed for nonlinear multiple-input-multiple-output (MIMO) discrete-time systems. The proposed scheme addresses both state and output faults by considering separate time profiles. The faults, which could be incipient or abrupt, are modeled using input and output signals of the system. The fault-detection (FD) scheme comprises online approximator in discrete time (OLAD) with a robust adaptive term. An output residual is generated by comparing the FD estimator output with that of the measured system output. A fault is detected when this output residual exceeds a predefined threshold. Upon detecting the fault, the robust adaptive terms and the OLADs are initiated wherein the OLAD approximates the unknown fault dynamics online while the robust adaptive terms help in ensuring asymptotic stability of the FD design. Using the OLAD outputs, a fault diagnosis scheme is introduced. A stable parameter update law is developed not only to tune the OLAD parameters but also to estimate the time to failure (TTF), which is considered as a first step for prognostics. The asymptotic stability of the FDP scheme enhances the detection and TTF accuracy. The effectiveness of the proposed approach is demonstrated using a fourth-order MIMO satellite system.",
Reconstruction and Finite Element Mesh Generation of Abdominal Aortic Aneurysms From Computerized Tomography Angiography Data With Minimal User Interactions,"Evaluating rupture risk of abdominal aortic aneurysms is critically important in reducing related mortality without unnecessarily increasing the rate of elective repair. According to the current clinical practice aneurysm rupture risk is (mainly) estimated from its maximum diameter and/or expansion rate; an approach motivated from statistics but known to fail often in individuals. In contrast, recent research demonstrated that patient specific biomechanical simulations can provide more reliable diagnostic parameters, however current structural model development is cumbersome and time consuming. This paper used 2D and 3D deformable models to reconstruct aneurysms from computerized tomography angiography data with minimal user interactions. In particular, formulations of frames and shells, as known from structural mechanics, were used to define deformable modes, which in turn allowed a direct mechanical interpretation of the applied set of reconstruction parameters. Likewise, a parallel finite element implementation of the models allows the segmentation of clinical cases on standard personal computers within a few minutes. The particular topology of the applied 3D deformable models supports a fast and simple hexahedral-dominated meshing of the arising generally polyhedral domain. The variability of the derived segmentations (luminal: 0.50(SD 0.19) mm; exterior 0.89(SD 0.45) mm) with respect to large variations in elastic properties of the deformable models was in the range of the differences between manual segmentations as performed by experts (luminal: 0.57(SD 0.24) mm; exterior: 0.77(SD 0.58) mm), and was particularly independent from the algorithm's initialization. The proposed interaction of deformable models and mesh generation defines finite element meshes suitable to perform accurate and efficient structural analysis of the aneurysm using mixed finite element formulations.","Finite element methods,
Mesh generation,
Abdomen,
Aneurysm,
Computed tomography,
Angiography,
Deformable models,
Statistics,
Computational modeling,
Microcomputers"
Design and Fabrication of a Magnetic Propulsion System for Self-Propelled Capsule Endoscope,"This paper investigates design, modeling, simulation, and control issues related to self-propelled endoscopic capsule navigated inside the human body through external magnetic fields. A novel magnetic propulsion system is proposed and fabricated, which has great potential of being used in the field of noninvasive gastrointestinal endoscopy. Magnetic-analysis model is established and finite-element simulations as well as orthogonal design are performed for obtaining optimized mechanical and control parameters for generating appropriate external magnetic field. Simulated intestinal tract experiments are conducted, demonstrating controllable movement of the capsule under the developed magnetic propulsion system.","Fabrication,
Propulsion,
Endoscopes,
Biological system modeling,
Magnetic fields,
Navigation,
Humans,
Gastrointestinal tract,
Magnetic analysis,
Finite element methods"
Delay-Derivative-Dependent Stability for Delayed Neural Networks With Unbound Distributed Delay,"In this brief, based on Lyapunov-Krasovskii functional approach and appropriate integral inequality, a new sufficient condition is derived to guarantee the global stability for delayed neural networks with unbounded distributed delay, in which the improved delay-partitioning technique and general convex combination are employed. The LMI-based criterion heavily depends on both the upper and lower bounds on time delay and its derivative, which is different from the existent ones and has wider application fields than some present results. Finally, three numerical examples can illustrate the efficiency of the new method based on the reduced conservatism which can be achieved by thinning the delay interval.","Stability,
Neural networks,
Chaotic communication,
Chaos,
Artificial neural networks,
Delay effects,
Sun,
Neurofeedback,
Parameter estimation,
Output feedback"
A Multiobjective Optimization Approach to Obtain Decision Thresholds for Distributed Detection in Wireless Sensor Networks,"For distributed detection in a wireless sensor network, sensors arrive at decisions about a specific event that are then sent to a central fusion center that makes global inference about the event. For such systems, the determination of the decision thresholds for local sensors is an essential task. In this paper, we study the distributed detection problem and evaluate the sensor thresholds by formulating and solving a multiobjective optimization problem, where the objectives are to minimize the probability of error and the total energy consumption of the network. The problem is investigated and solved for two types of fusion schemes: 1) parallel decision fusion and 2) serial decision fusion. The Pareto optimal solutions are obtained using two different multiobjective optimization techniques. The normal boundary intersection (NBI) method converts the multiobjective problem into a number of single objective-constrained subproblems, where each subproblem can be solved with appropriate optimization methods and nondominating sorting genetic algorithm-II (NSGA-II), which is a multiobjective evolutionary algorithm. In our simulations, NBI yielded better and evenly distributed Pareto optimal solutions in a shorter time as compared with NSGA-II. The simulation results show that, instead of only minimizing the probability of error, multiobjective optimization provides a number of design alternatives, which achieve significant energy savings at the cost of slightly increasing the best achievable decision error probability. The simulation results also show that the parallel fusion model achieves better error probability, but the serial fusion model is more efficient in terms of energy consumption.",
Speech Dereverberation Based on Variance-Normalized Delayed Linear Prediction,"This paper proposes a statistical model-based speech dereverberation approach that can cancel the late reverberation of a reverberant speech signal captured by distant microphones without prior knowledge of the room impulse responses. With this approach, the generative model of the captured signal is composed of a source process, which is assumed to be a Gaussian process with a time-varying variance, and an observation process modeled by a delayed linear prediction (DLP). The optimization objective for the dereverberation problem is derived to be the sum of the squared prediction errors normalized by the source variances; hence, this approach is referred to as variance-normalized delayed linear prediction (NDLP). Inheriting the characteristic of DLP, NDLP can robustly estimate an inverse system for late reverberation in the presence of noise without greatly distorting a direct speech signal. In addition, owing to the use of variance normalization, NDLP allows us to improve the dereverberation result especially with relatively short (of the order of a few seconds) observations. Furthermore, NDLP can be implemented in a computationally efficient manner in the time-frequency domain. Experimental results demonstrate the effectiveness and efficiency of the proposed approach in comparison with two existing approaches.","Speech,
Reverberation,
Predictive models,
Speech processing,
Optimization,
Microphones,
Correlation"
Visual Measurement and Prediction of Ball Trajectory for Table Tennis Robot,"A high-speed stereovision system with two smart cameras is presented to track a table tennis ball, which adopts a distributed parallel processing architecture based on a local area network. A set of novel algorithms with little computation and good robustness running in the smart cameras is also proposed to recognize and track the ball in the images. A computer receives the image coordinates of the ball from the cameras via the local area network and computes its 3-D positions in the working frame. Then, the flying trajectory of the ball is estimated and predicted according to the measured positions and the flying and rebound models. The main motion parameters of the ball such as the landing point and striking point are calculated from its predicted trajectory. Experimental results show that the developed image-processing algorithms are robust enough to distinguish the ball from a complex dynamic background. The predicted landing point and striking point of the ball have satisfactory precision.","Trajectory,
Smart cameras,
Local area networks,
Robustness,
Computer networks,
Robot kinematics,
Parallel processing,
Computer architecture,
Image recognition,
Position measurement"
Using Mutation to Automatically Suggest Fixes for Faulty Programs,This paper proposes a strategy for automatically fixing faults in a program by combining the processes of mutation and fault localization. Statements that are ranked in order of their suspiciousness of containing faults can then be mutated in the same order to produce possible fixes for the faulty program. The proposed strategy is evaluated against the seven benchmark programs of the Siemens suite and the Ant program. Results indicate that the strategy is effective at automatically suggesting fixes for faults without any human intervention.,"Genetic mutations,
Programming profession,
Debugging,
Software testing,
Humans,
Fault detection,
Computer science,
Benchmark testing,
Explosives,
Manuals"
Image Ratio Features for Facial Expression Recognition Application,"Video-based facial expression recognition is a challenging problem in computer vision and human-computer interaction. To target this problem, texture features have been extracted and widely used, because they can capture image intensity changes raised by skin deformation. However, existing texture features encounter problems with albedo and lighting variations. To solve both problems, we propose a new texture feature called image ratio features. Compared with previously proposed texture features, e.g., high gradient component features, image ratio features are more robust to albedo and lighting variations. In addition, to further improve facial expression recognition accuracy based on image ratio features, we combine image ratio features with facial animation parameters (FAPs), which describe the geometric motions of facial feature points. The performance evaluation is based on the Carnegie Mellon University Cohn-Kanade database, our own database, and the Japanese Female Facial Expression database. Experimental results show that the proposed image ratio feature is more robust to albedo and lighting variations, and the combination of image ratio features and FAPs outperforms each feature alone. In addition, we study asymmetric facial expressions based on our own facial expression database and demonstrate the superior performance of our combined expression recognition system.","Face recognition,
Image recognition,
Image databases,
Spatial databases,
Robustness,
Financial advantage program,
Application software,
Computer vision,
Feature extraction,
Skin"
Working towards frequency regulation with wind plants: Combined control approaches,"A pitch angle controller and a rotor speed controller are proposed for wind plant output active power adjustment. Combining the turbine inertial control with pitch angle control provides a better outlook for long-term control. The control schemes are developed for wind generators to equip them with the capability to participate in restoring grid frequency after a disturbance. With the proposed controllers, the wind plant has a higher flexibility to operate more like a synchronous generator and is able to output either larger or smaller amounts of power as required so as to contribute to grid frequency restoration. The controllers are tested on a four-bus test system for verification of the grid frequency performance under varying system dynamic conditions.","wind power plants,
angular velocity control,
power generation control,
synchronous motors"
Efficient action spotting based on a spacetime oriented structure representation,"This paper addresses action spotting, the spatiotemporal detection and localization of human actions in video. A novel compact local descriptor of video dynamics in the context of action spotting is introduced based on visual spacetime oriented energy measurements. This descriptor is efficiently computed directly from raw image intensity data and thereby forgoes the problems typically associated with flow-based features. An important aspect of the descriptor is that it allows for the comparison of the underlying dynamics of two spacetime video segments irrespective of spatial appearance, such as differences induced by clothing, and with robustness to clutter. An associated similarity measure is introduced that admits efficient exhaustive search for an action template across candidate video sequences. Empirical evaluation of the approach on a set of challenging natural videos suggests its efficacy.","Spatiotemporal phenomena,
Humans,
Robustness,
Clothing,
Distributed databases,
Legged locomotion,
Tracking,
Feature extraction,
Computer science,
Power engineering and energy"
Random-walk based approach to detect clone attacks in wireless sensor networks,"Wireless sensor networks (WSNs) deployed in hostile environments are vulnerable to clone attacks. In such attack, an adversary compromises a few nodes, replicates them, and inserts arbitrary number of replicas into the network. Consequently, the adversary can carry out many internal attacks. Previous solutions on detecting clone attacks have several drawbacks. First, some of them require a central control, which introduces several inherent limits. Second, some of them are deterministic and vulnerable to simple witness compromising attacks. Third, in some solutions the adversary can easily learn the critical witness nodes to start smart attacks and protect replicas from being detected. In this paper, we first show that in order to avoid existing drawbacks, replica-detection protocols must be non-deterministic and fully distributed (NDFD), and fulfill three security requirements on witness selection. To our knowledge, only one existing protocol, Randomized Multicast, is NDFD and fulfills the requirements, but it has very high communication overhead. Then, based on random walk, we propose two new NDFD protocols, RAndom WaLk (RAWL) and Table-assisted RAndom WaLk (TRAWL), which fulfill the requirements while having only moderate communication and memory overheads. The random walk strategy outperforms previous strategies because it distributes a core step, the witness selection, to every passed node of random walks, and then the adversary cannot easily find out the critical witness nodes. We theoretically analyze the required number of walk steps for ensuring detection. Our simulation results show that our protocols outperform an existing NDFD protocol with the lowest overheads in witness selection, and TRAWL even has lower memory overhead than that protocol. The communication overheads of our protocols are higher but are affordable considering their security benefits.","Cloning,
Wireless sensor networks,
Multicast protocols,
Application software,
Centralized control,
Protection,
Computational modeling,
Computer networks,
Computer security,
Military computing"
Monte Carlo Tree Search in Hex,"Hex, the classic board game invented by Piet Hein in 1942 and independently by John Nash in 1948, has been a domain of AI research since Claude Shannon's seminal work in the 1950s. Until the Monte Carlo Go revolution a few years ago, the best computer Hex players used knowledge-intensive alpha-beta search. Since that time, strong Monte Carlo Hex players have appeared that are on par with the best alpha-beta Hex players. In this paper, we describe MoHex, the Monte Carlo tree search Hex player that won gold at the 2009 Computer Olympiad. Our main contributions to Monte Carlo tree search include using inferior cell analysis and connection strategy computation to prune the search tree. In particular, we run our random game simulations not on the actual game position, but on a reduced equivalent board.","Games,
Simulation,
Monte Carlo methods,
Decision trees,
Computational modeling"
Scavenger: Transparent development of efficient cyber foraging applications,"Cyber foraging is a pervasive computing technique where small mobile devices offload resource intensive tasks to stronger computing machinery in the vicinity. This paper presents Scavenger-a new cyber foraging system supporting easy development of mobile cyber foraging applications, while still delivering efficient, mobile use of remote computing resources through the use of a custom built mobile code execution environment and a new dual-profiling scheduler. One of the main difficulties within cyber foraging is that it is very challenging for application programmers to develop cyber foraging enabled applications. An application using cyber foraging is working with mobile, distributed and, possibly, parallel computing; fields within computer science known to be hard for programmers to grasp. In this paper it is shown by example, how a highly distributed, parallel, cyber foraging enabled application can be developed using Scavenger. Benchmarks of the example application are presented showing that Scavenger imposes only minimal overhead when no surrogates are available, while greatly improving performance as surrogates become available.","Mobile computing,
Application software,
Smart phones,
Pervasive computing,
Central Processing Unit,
Programming profession,
Batteries,
Machinery,
Processor scheduling,
Parallel processing"
Parallel Multiscale Feature Extraction and Region Growing: Application in Retinal Blood Vessel Detection,"This paper presents a parallel implementation based on insight segmentation and registration toolkit for a multiscale feature extraction and region growing algorithm, applied to retinal blood vessels segmentation. This implementation is capable of achieving an accuracy (Ac) comparable to its serial counterpart (about 92%), but 8 to 10 times faster. In this paper, the Ac of this parallel implementation is evaluated by comparison with expert manual segmentation (obtained from public databases). On the other hand, its performance is compared with previous published serial implementations. Both these characteristics make this parallel implementation feasible for the analysis of a larger amount of high-resolution retinal images, achieving a faster and high-quality segmentation of retinal blood vessels.","Feature extraction,
Retina,
Blood vessels,
Image segmentation,
Biomedical imaging,
Image analysis,
Image databases,
Cardiovascular diseases,
Diabetes,
Iron"
Gradient-Like Observers for Invariant Dynamics on a Lie Group,"This paper proposes a design methodology for non-linear state observers for invariant kinematic systems posed on finite dimensional connected Lie groups, and studies the associated fundamental system structure. The concept of synchrony of two dynamical systems is specialized to systems on Lie groups. For invariant systems this leads to a general factorization theorem of a nonlinear observer into a synchronous (internal model) term and an innovation term. The synchronous term is fully specified by the system model. We propose a design methodology for the innovation term based on gradient-like terms derived from invariant or non-invariant cost functions. The resulting nonlinear observers have strong (almost) global convergence properties and examples are used to demonstrate the relevance of the proposed approach.",
Imaging sonar-aided navigation for autonomous underwater harbor surveillance,"In this paper we address the problem of drift-free navigation for underwater vehicles performing harbor surveillance and ship hull inspection. Maintaining accurate localization for the duration of a mission is important for a variety of tasks, such as planning the vehicle trajectory and ensuring coverage of the area to be inspected. Our approach only uses onboard sensors in a simultaneous localization and mapping setting and removes the need for any external infrastructure like acoustic beacons. We extract dense features from a forward-looking imaging sonar and apply pair-wise registration between sonar frames. The registrations are combined with onboard velocity, attitude and acceleration sensors to obtain an improved estimate of the vehicle trajectory. We show results from several experiments that demonstrate drift-free navigation in various underwater environments.","Vehicles,
Feature extraction,
Imaging,
Sonar navigation,
Sonar measurements,
Sensors"
Cooperative Network Coding With MIMO Transmission in Wireless Decode-and-Forward Relay Networks,"This paper proposes a cooperative network-coding (CNC) scheme for a dual-hop decode-and-forward (DF) multiple-input-multiple-output (MIMO) system, which consists of multiple source stations (SSs), one relay station (RS), and one base station (BS). Both the RS and the BS use multiple antennas, whereas the SS has only one antenna. Through a MIMO configuration between the RS and the BS, a cooperative network coded DF (CNC-DF) relay protocol is proposed to transmit the composite data flows from multiple SSs via the RS to the BS simultaneously to reduce delay and to provide network-coded cooperation gain. To demonstrate its effectiveness, CNC-DF is compared with time-division multiple-access (TDMA) DF and orthogonal space-time coded (OSTC) DF protocols. The ergodic capacity and outage probability for these three protocols are explicitly derived, showing that the proposed CNC-DF scheme can significantly improve the performance, which is closely related to the minimum of the numbers of SSs and the numbers of antennas used by the RS and the BS.","Network coding,
MIMO,
Decoding,
Relays,
Capacity planning,
Wireless application protocol,
Permission,
Computer numerical control,
Base stations,
Time division multiple access"
Context-Aware Adaptive Applications: Fault Patterns and Their Automated Identification,"Applications running on mobile devices are intensely context-aware and adaptive. Streams of context values continuously drive these applications, making them very powerful but, at the same time, susceptible to undesired configurations. Such configurations are not easily exposed by existing validation techniques, thereby leading to new analysis and testing challenges. In this paper, we address some of these challenges by defining and applying a new model of adaptive behavior called an Adaptation Finite-State Machine (A-FSM) to enable the detection of faults caused by both erroneous adaptation logic and asynchronous updating of context information, with the latter leading to inconsistencies between the external physical context and its internal representation within an application. We identify a number of adaptation fault patterns, each describing a class of faulty behaviors. Finally, we describe three classes of algorithms to detect such faults automatically via analysis of the A-FSM. We evaluate our approach and the trade-offs between the classes of algorithms on a set of synthetically generated Context-Aware Adaptive Applications (CAAAs) and on a simple but realistic application in which a cell phone's configuration profile changes automatically as a result of changes to the user's location, speed, and surrounding environment. Our evaluation describes the faults our algorithms are able to detect and compares the algorithms in terms of their performance and storage requirements.","Fault diagnosis,
Fault detection,
Context modeling,
Algorithm design and analysis,
Handheld computers,
Personal digital assistants,
Data structures,
Global Positioning System,
Computer science,
Lead"
Budget Feasible Mechanisms,"We study a novel class of mechanism design problems in which the outcomes are constrained by the payments. This basic class of mechanism design problems captures many common economic situations, and yet it has not been studied, to our knowledge, in the past. We focus on the case of procurement auctions in which sellers have private costs, and the auctioneer aims to maximize a utility function on subsets of items, under the constraint that the sum of the payments provided by the mechanism does not exceed a given budget. Standard mechanism design ideas such as the VCG mechanism and its variants are not applicable here. We show that, for general functions, the budget constraint can render mechanisms arbitrarily bad in terms of the utility of the buyer. However, our main result shows that for the important class of sub modular functions, a bounded approximation ratio is achievable. Better approximation results are obtained for subclasses of the sub modular functions. We explore the space of budget feasible mechanisms in other domains and give a characterization under more restricted conditions.","Resource management,
Approximation methods,
Sorting,
Frequency modulation,
Economics,
Space exploration,
Procurement"
Automated Selection and Placement of Single Cells Using Vision-Based Feedback Control,"We present a robotic manipulation system for automated selection and transfer of individual living cells to analysis locations. We begin with a commonly used cell transfer technique using glass capillary micropipettes to aspirate and release living cells suspended in liquid growth media. Using vision-based feedback and closed-loop process control, two individual three-axis robotic stages position the micropipette tip in proximity to the cell of interest. The cell is aspirated and the tip is moved to a target location where the cell is dispensed. Computer vision is used to monitor and inspect the success of the dispensing process. In our initial application, the target cell destination is a microwell etched in a fused silica substrate. The system offers a robust and flexible technology for cell selection and manipulation. Applications for this technology include embryonic stem cells transfer, blastomere biopsy, cell patterning, and cell surgery.","Feedback control,
Robotics and automation,
Application software,
Glass,
Process control,
Robot vision systems,
Computer vision,
Computerized monitoring,
Etching,
Silicon compounds"
Very low resolution face recognition problem,"This paper addresses the very low resolution (VLR) problem in face recognition in which the resolution of face image to be recognized is lower than 16×16. The VLR problem happens in many surveillance camera-based applications and existing face recognition algorithms are not able to give satisfactory performance on VLR face image. While face super-resolution (SR) methods can be employed to enhance the resolution of the images, the existing learning-based face SR methods do not perform well on such a very low resolution face image. To overcome this problem, this paper models the SR problem under VLR case as a regression problem with two constraints. First, a new data constraint is design to perform the error measurement on high resolution image space which provides more detailed and discriminative information. Second, discriminative constraint is proposed and incorporated in the training stage so that the reconstructed HR image has higher discriminability. CMU-PIE, FRGC and surveillant camera face (SCface) databases are selected for experiments. Experimental results show that the proposed method outperforms the existing methods, in terms of image quality and recognition accuracy.","Image reconstruction,
Face,
Image resolution,
Strontium,
Face recognition,
Databases,
Image recognition"
Robust dynamic average consensus of time-varying inputs,"We consider the dynamic average consensus problem in which each agent in a network has access to its own local input signal, but it must compute and track the average of all such inputs. Each agent communicates only with neighbors in the network, and local communication, computation and memory requirements should be independent of the number of the agents in the network. The Proportional-Integral (PI) estimator in [1] guarantees zero steady-state error under constant inputs for constant, connected, and balanced networks, even in the presence of estimator initialization errors. In this work, we employ the internal model principle to generalize the PI estimator so that it achieves zero steady-state error for classes of time-varying inputs, including polynomial inputs of known order and sinusoidal inputs with known frequencies. Like the PI estimator, our new estimator is robust to initialization errors.","Robustness,
Steady-state,
Noise,
Polynomials,
Noise measurement,
Stability analysis,
Transfer functions"
A resilience roadmap,"Technology scaling has an increasing impact on the resilience of CMOS circuits. This outcome is the result of (a) increasing sensitivity to various intrinsic and extrinsic noise sources as circuits shrink, and (b) a corresponding increase in parametric variability causing behavior similar to what would be expected with hard (topological) faults. This paper examines the issue of circuit resilience, then proposes and demonstrates a roadmap for evaluating fault rates starting at the 45nm and going down to the 12nm nodes. The complete infrastructure necessary to make these predictions is placed in the open source domain, with the hope that it will invigorate research in this area.",
Action classification on product manifolds,"Videos can be naturally represented as multidimensional arrays known as tensors. However, the geometry of the tensor space is often ignored. In this paper, we argue that the underlying geometry of the tensor space is an important property for action classification. We characterize a tensor as a point on a product manifold and perform classification on this space. First, we factorize a tensor relating to each order using a modified High Order Singular Value Decomposition (HOSVD). We recognize each factorized space as a Grassmann manifold. Consequently, a tensor is mapped to a point on a product manifold and the geodesic distance on a product manifold is computed for tensor classification. We assess the proposed method using two public video databases, namely Cambridge-Gesture gesture and KTH human action data sets. Experimental results reveal that the proposed method performs very well on these data sets. In addition, our method is generic in the sense that no prior training is needed.","Tensile stress,
Videos,
Geometry,
Humans,
Algebra,
Multidimensional systems,
Singular value decomposition,
Computer vision,
Training data,
Computer science"
A Data Hiding Algorithm for H.264/AVC Video Streams Without Intra-Frame Distortion Drift,"Intra-frame distortion drift is a big problem of data hiding in H.264/AVC video streams. Based on a thorough investigation of this problem, a novel readable data-hiding algorithm, which can embed data into the quantized discrete cosine transform (DCT) coefficients of I frames without bringing any intra-frame distortion drift into the H.264/advanced video coding (AVC) video host, is presented in this paper. We exploit several paired-coefficients of a 4 × 4 DCT block to accumulate the embedding induced distortion. The directions of intra-frame prediction are utilized to avert the distortion drift. It is proved analytically and shown experimentally that the proposed algorithm can achieve high embedding capacity and low visual distortion. Performance comparisons with other existing schemes are provided to demonstrate the superiority of the proposed scheme.","Discrete cosine transforms,
Watermarking,
Automatic voltage control,
Pixel,
Prediction algorithms,
Entropy,
Quantization"
Initial results in underwater single image dehazing,"As light is transmitted from subject to observer it is absorbed and scattered by the medium it passes through. In mediums with large suspended particles, such as fog or turbid water, the effect of scattering can drastically decrease the quality of images. In this paper we present an algorithm for removing the effects of light scattering, referred to as dehazing, in underwater images. Our key contribution is to propose a simple, yet effective, prior that exploits the strong difference in attenuation between the three image color channels in water to estimate the depth of the scene. We then use this estimate to reduce the spatially varying effect of haze in the image. Our method works with a single image and does not require any specialized hardware or prior knowledge of the scene. As a by-product of the dehazing process, an up-to-scale depth map of the scene is produced. We present results over multiple real underwater images and over a controlled test set where the target distance and true colors are known.","Image color analysis,
Scattering,
Pixel,
Attenuation,
Estimation,
Atmospheric modeling,
Wheels"
Handover in Mobile WiMAX Networks: The State of Art and Research Issues,"The next-generation Wireless Metropolitan Area Networks, using the Worldwide Interoperability for Microwave Access (WiMAX) as the core technology based on the IEEE 802.16 family of standards, is evolving as a Fourth-Generation (4G) technology. With the recent introduction of mobility management frameworks in the IEEE 802.16e standard, WiMAX is now in competition with the existing and forthcoming generations of wireless technologies for providing ubiquitous computing solutions. However, the success of a good mobility framework largely depends on the capability of performing fast and seamless handovers irrespective of the deployed architectural scenario. Now that the IEEE has defined the Mobile WiMAX (IEEE 802.16e) MAC-layer handover management framework, the Network Working Group (NWG) of the WiMAX Forum is working on the development of the upper layers. However, the path to commercialization of a full-fledged WiMAX mobility framework is full of research challenges. This article focuses on potential handover-related research issues in the existing and future WiMAX mobility framework. A survey of these issues in the MAC, Network and Cross-Layer scenarios is presented along with discussion of the different solutions to those challenges. A comparative study of the proposed solutions, coupled with some insights to the relevant issues, is also included.","WiMAX,
Art,
Microwave technology,
Next generation networking,
Wireless LAN,
Metropolitan area networks,
Mobile radio mobility management,
Ubiquitous computing,
Computer network management,
Commercialization"
"Information Inequalities for Joint Distributions, With Interpretations and Applications","Upper and lower bounds are obtained for the joint entropy of a collection of random variables in terms of an arbitrary collection of subset joint entropies. These inequalities generalize Shannon's chain rule for entropy as well as inequalities of Han, Fujishige, and Shearer. A duality between the upper and lower bounds for joint entropy is developed. All of these results are shown to be special cases of general, new results for submodular functions-thus, the inequalities presented constitute a richly structured class of Shannon-type inequalities. The new inequalities are applied to obtain new results in combinatorics, such as bounds on the number of independent sets in an arbitrary graph and the number of zero-error source-channel codes, as well as determinantal inequalities in matrix theory. A general inequality for relative entropies is also developed. Finally, revealing connections of the results to literature in economics, computer science, and physics are explored.","Cramer-Rao bounds,
Entropy,
Random variables,
Density measurement,
Information theory,
Upper bound,
Combinatorial mathematics,
Linear matrix inequalities,
Computer science,
Physics"
"Toward Low-Cost, High-Efficiency, and Scalable Organic Solar Cells with Transparent Metal Electrode and Improved Domain Morphology","We review our recent progress toward realizing future low-cost, high-efficiency, and scalable organic solar cells (OSCs). First, we show that the transparent electrodes based on metallic nanostructure is a strong candidate as a replacement of conventional indium tin oxide (ITO) electrode due to their superior properties, such as high optical transparency, good electrical conductivity, and mechanical flexibility, and the versatility that these properties can be adjusted independently by changing the linewidth and thickness of the metal grid structure. Furthermore, we exploited the unique optical properties due to the excitation of surface plasmon resonance by the metallic nanogratings to enhance the light absorption of organic semiconductors, and demonstrated enhanced power conversion efficiency than devices made using ITO electrode. In addition, we also investigated a new device fabrication process with a focus on the photoactive layer formation, which produces the most optimum bulk-heterojunction morphology compared with conventional annealing-based methods. Finally, we successfully demonstrated that these approaches are scalable to large-area and high-speed roll-to-roll processes. We believe that the works highlighted in this paper represent one step forward to realizing low-cost, high-efficiency, and large-area OSCs.","Photovoltaic cells,
Electrodes,
Indium tin oxide,
Mechanical factors,
High speed optical techniques,
Conductivity,
Optical devices,
Surface morphology,
Plasmons,
Resonance"
An Integrated Reusable Remote Laboratory to Complement Electronics Teaching,"The great majority of the courses on science and technology areas where lab work is a fundamental part of the apprenticeship was not until recently available to be taught at distance. This reality is changing with the dissemination of remote laboratories. Supported by resources based on new information and communication technologies, it is now possible to remotely control a wide variety of real laboratories. However, most of them are designed specifically to this purpose, are inflexible and only on its functionality they resemble the real ones. In this paper, an alternative remote lab infrastructure devoted to the study of electronics is presented. Its main characteristics are, from a teacher's perspective, reusability and simplicity of use, and from a students' point of view, an exact replication of the real lab, enabling them to complement or finish at home the work started at class. The remote laboratory is integrated in the Learning Management System in use at the school, and therefore, may be combined with other web experiments and e-learning strategies, while safeguarding security access issues.","Instruments,
Relays,
Voltage measurement,
Current measurement,
Switches,
Education,
Laboratories"
Single Event Upset and Multiple Cell Upset Modeling in Commercial Bulk 65-nm CMOS SRAMs and Flip-Flops,"A proprietary Monte-Carlo simulation code dedicated to heavy ion cross-section prediction has been developed. The code is based on diffusion-collection equations, takes into account recombination processes, uses an improved drain strike model, and includes new upset analysis algorithms for different circuit architectures. Simulated cross-sections are compared to heavy ion experimental characterizations for commercial bulk 65-nm single- and dual-port SRAMs. Simulation capabilities of much more complex circuits are demonstrated considering a 65-nm radiation-hardened-by-design (RHBD) Flip-Flop (FF).","Single event upset,
Semiconductor device modeling,
Flip-flops,
Circuit simulation,
Error correction codes,
Equations,
Computational modeling,
Analytical models,
Random access memory,
Algorithm design and analysis"
Multiple Nuclei Tracking Using Integer Programming for Quantitative Cancer Cell Cycle Analysis,"Automated cell segmentation and tracking are critical for quantitative analysis of cell cycle behavior using time-lapse fluorescence microscopy. However, the complex, dynamic cell cycle behavior poses new challenges to the existing image segmentation and tracking methods. This paper presents a fully automated tracking method for quantitative cell cycle analysis. In the proposed tracking method, we introduce a neighboring graph to characterize the spatial distribution of neighboring nuclei, and a novel dissimilarity measure is designed based on the spatial distribution, nuclei morphological appearance, migration, and intensity information. Then, we employ the integer programming and division matching strategy, together with the novel dissimilarity measure, to track cell nuclei. We applied this new tracking method for the tracking of HeLa cancer cells over several cell cycles, and the validation results showed that the high accuracy for segmentation and tracking at 99.5% and 90.0%, respectively. The tracking method has been implemented in the cell-cycle analysis software package, DCELLIQ, which is freely available.","Linear programming,
Cancer,
Drugs,
Image segmentation,
Bioinformatics,
Fluorescence,
Microscopy,
Biomedical engineering,
Radiology,
Hospitals"
FPGA PUF using programmable delay lines,"This paper proposes a novel approach for efficient implementation of a real-valued arbiter-based physical unclon-able function (PUF) on FPGA. We introduce a high resolution programmable delay logic (PDL) implemented by lookup table (LUT) internal structure. Using the PDL, we perform fine tuning to cancel out delay skews caused by asymmetries in routing and systematic variations. We devise a symmetric switch structure that can be easily implemented on FPGA. To mitigate the arbiter metastability problem, we present and analyze methods for majority voting of responses. Lastly, a method to classify and group challenges into different robustness sets is introduced, to further increase the corresponding responses' stability in the face of environmental variations. Experimental evaluations show that the responses to robust challenges have an average error rate of less than 2% under temperature variations from −10°C to 75°C.","Delay,
Tuning,
Field programmable gate arrays,
Switches,
Routing,
Table lookup,
Robustness"
Constructing Maximum-Lifetime Data-Gathering Forests in Sensor Networks,"Energy efficiency is critical for wireless sensor networks. The data-gathering process must be carefully designed to conserve energy and extend network lifetime. For applications where each sensor continuously monitors the environment and periodically reports to a base station, a tree-based topology is often used to collect data from sensor nodes. In this work, we first study the construction of a data-gathering tree when there is a single base station in the network. The objective is to maximize the network lifetime, which is defined as the time until the first node depletes its energy. The problem is shown to be NP-complete. We design an algorithm that starts from an arbitrary tree and iteratively reduces the load on bottleneck nodes (nodes likely to soon deplete their energy due to high degree or low remaining energy). We then extend our work to the case when there are multiple base stations and study the construction of a maximum-lifetime data-gathering forest. We show that both the tree and forest construction algorithms terminate in polynomial time and are provably near optimal. We then verify the efficacy of our algorithms via numerical comparisons.","Base stations,
Wireless sensor networks,
Network topology,
Iterative algorithms,
Monitoring,
Polynomials,
Computer science,
Algorithm design and analysis,
Microelectronics,
Fabrication"
Impact of frame rate and resolution on objective QoE metrics,"Video streaming applications are a major driver for the evolution of the future Internet. In this paper we introduce a framework for QoE management for video streaming systems based on the H.264/SVC codec, the scalable extension of H.264/AVC. A relevant feature is to control the user perceived quality of experience (QoE) by exploiting parameters offered by SVC. A proper design of a control mechanism requires the quantification of the main influence parameters on the QoE. For this purpose, we conducted a measurement study and quantified the influence of i) video resolution, ii) scaling method, iii) video frame rate and iv) video content types on the QoE by means of the SSIM and VQM full-reference metrics. Further, we discuss the trade-off between these different control knobs and their influence on the QoE.","Streaming media,
Static VAr compensators,
Bandwidth,
Communication system traffic control,
Internet,
Monitoring,
IP networks,
Next generation networking,
Optimal control,
Video codecs"
Perpendicular Intersection: Locating Wireless Sensors With Mobile Beacon,"Existing localization approaches are divided into two groups: 1) range based and 2) range free. The range-free schemes often suffer from poor accuracy and low scalability, whereas the range-based localization approaches heavily depend on extra hardware capabilities or on the absolute received signal strength indicator (RSSI) values, which is far from practical. In this paper, we propose a mobile-assisted localization scheme called Perpendicular Intersection (PI), setting up a delicate tradeoff between range-free and range-based approaches. Instead of directly mapping RSSI values into physical distances, by contrasting RSSI values from the mobile beacon to a sensor node, PI utilizes the geometric relationship of a perpendicular intersection to compute node positions. We have implemented the prototype of PI with 100 TelosB motes and evaluated PI in both indoor and outdoor environments. Through comprehensive experiments, we show that PI achieves high accuracy, significantly outperforming the existing range-based and the mobile-assisted localization schemes.","Wireless sensor networks,
Hardware,
Sea measurements,
Permission,
Computer science,
Attenuation,
Scalability,
Mobile computing,
Physics computing"
The 2009 Simulated Car Racing Championship,"In this paper, we overview the 2009 Simulated Car Racing Championship-an event comprising three competitions held in association with the 2009 IEEE Congress on Evolutionary Computation (CEC), the 2009 ACM Genetic and Evolutionary Computation Conference (GECCO), and the 2009 IEEE Symposium on Computational Intelligence and Games (CIG). First, we describe the competition regulations and the software framework. Then, the five best teams describe the methods of computational intelligence they used to develop their drivers and the lessons they learned from the participation in the championship. The organizers provide short summaries of the other competitors. Finally, we summarize the championship results, followed by a discussion about what the organizers learned about 1) the development of high-performing car racing controllers and 2) the organization of scientific competitions.",
Volumetric Topological Analysis: A Novel Approach for Trabecular Bone Classification on the Continuum Between Plates and Rods,"Trabecular bone (TB) is a complex quasi-random network of interconnected plates and rods. TB constantly remodels to adapt to the stresses to which it is subjected (Wolff's Law). In osteoporosis, this dynamic equilibrium between bone formation and resorption is perturbed, leading to bone loss and structural deterioration. Both bone loss and structural deterioration increase fracture risk. Bone's mechanical behavior can only be partially explained by variations in bone mineral density, which led to the notion of bone structural quality. Previously, we developed digital topological analysis (DTA) which classifies plates, rods, profiles, edges, and junctions in a TB skeletal representation. Although the method has become quite popular, a major limitation of DTA is that it provides only hard classifications of different topological entities, failing to distinguish between narrow and wide plates. Here, we present a new method called volumetric topological analysis (VTA) for regional quantification of TB topology. At each TB location, the method uniquely classifies its topology on the continuum between perfect plates and perfect rods, facilitating early detections of TB alterations from plates to rods according to the known etiology of osteoporotic bone loss. Several new ideas, including manifold distance transform, manifold scale, and feature propagation have been introduced here and combined with existing DTA and distance transform methods, leading to the new VTA technology. This method has been applied to multidetector computed tomography (CT) and micro-computed tomography (μCT) images of four cadaveric distal tibia and five distal radius specimens. Both intra- and inter-modality reproducibility of the method has been examined using repeat CT and μCT scans of distal tibia specimens. Also, the method's ability to predict experimental biomechanical properties of TB via CT imaging under in vivo conditions has been quantitatively examined and the results found are very encouraging.","Cancellous bone,
Osteoporosis,
Computed tomography,
Cities and towns,
Topology,
Stress,
Dynamic equilibrium,
Minerals,
Radiology,
Reproducibility of results"
Palacios and Kitten: New high performance operating systems for scalable virtualized and native supercomputing,"Palacios is a new open-source VMM under development at Northwestern University and the University of New Mexico that enables applications executing in a virtualized environment to achieve scalable high performance on large machines. Palacios functions as a modularized extension to Kitten, a high performance operating system being developed at Sandia National Laboratories to support large-scale supercomputing applications. Together, Palacios and Kitten provide a thin layer over the hardware to support full-featured virtualized environments alongside Kitten's lightweight native environment. Palacios supports existing, unmodified applications and operating systems by using the hardware virtualization technologies in recent AMD and Intel processors. Additionally, Palacios leverages Kitten's simple memory management scheme to enable low-overhead pass-through of native devices to a virtualized environment. We describe the design, implementation, and integration of Palacios and Kitten. Our benchmarks show that Palacios provides near native (within 5%), scalable performance for virtualized environments running important parallel applications. This new architecture provides an incremental path for applications to use supercomputers, running specialized lightweight host operating systems, that is not significantly performance-compromised.","Operating systems,
Application virtualization,
Open source software,
Laboratories,
Large-scale systems,
Hardware,
Platform virtualization,
Memory management,
Environmental management,
Supercomputers"
Optimized relay placement to federate segments in wireless sensor networks,"Federating disjoint segments may be necessary in some applications of wireless sensor networks (WSNs). The segments can be simply distinct WSNs that operate autonomously or partitions of a single WSN that has suffered a significant damage. Linking these segments is subject to varying distances among segments which may be longer than twice the communication range of a relay node. In this work, we focus on designing an effective approach for federating these segments by populating the least number of relay nodes. The deployment area is modeled as a grid with equal-sized cells. The optimization problem is then mapped to selecting the fewest count of cells to populate relay nodes such that all segments are connected. Finding the optimal number and positions of relay nodes with respect to length between segments is NP-hard and heuristics are thus pursued. We propose a distributed Cell-based Optimized Relay node Placement (CORP) algorithm and explain the beneficial aspects of the resulting topology with respect to connectivity, and traffic balance. The performance of CORP is validated through extensive simulation experiments.","Relays,
Wireless sensor networks,
Network topology,
Protective relaying,
Joining processes,
Telecommunication traffic,
Traffic control,
Protection,
Reconnaissance,
Batteries"
Scientific Computing in the Cloud,"Large, virtualized pools of computational resources raise the possibility of a new, advantageous computing paradigm for scientific research. To help achieve this, new tools make the cloud platform behave virtually like a local homogeneous computer cluster, giving users access to high-performance clusters without requiring them to purchase or maintain sophisticated hardware.","Scientific computing,
Cloud computing,
Hardware,
Ambient intelligence,
Application software,
Computer networks,
Atom optics,
Benchmark testing,
Reactive power,
Operating systems"
Improving Flash Wear-Leveling by Proactively Moving Static Data,"Motivated by the strong demand for flash memory with enhanced reliability, this work attempts to achieve improved flash-memory endurance without substantially increasing overhead and without excessively modifying popular implementation designs such as the flash translation layer protocol (FTL), NAND flash translation layer protocol (NFTL), and block-level flash translation layer protocol (BL). A wear-leveling mechanism for moving data that are not updated is proposed to distribute wear-leveling actions over the entire physical address space, so that static or rarely updated data can be proactively moved and memory-space requirements can be minimized. The properties of the mechanism are then explored with various implementation considerations. A series of experiments based on a realistic trace demonstrates the significantly improved endurance of FTL, NFTL, and BL with limited system overhead.","Ash,
Random access memory,
Flash memory,
Protocols,
Data mining,
Memory management,
Driver circuits"
Particle Swarm Optimization Aided Orthogonal Forward Regression for Unified Data Modeling,"We propose a unified data modeling approach that is equally applicable to supervised regression and classification applications, as well as to unsupervised probability density function estimation. A particle swarm optimization (PSO) aided orthogonal forward regression (OFR) algorithm based on leave-one-out (LOO) criteria is developed to construct parsimonious radial basis function (RBF) networks with tunable nodes. Each stage of the construction process determines the center vector and diagonal covariance matrix of one RBF node by minimizing the LOO statistics. For regression applications, the LOO criterion is chosen to be the LOO mean square error, while the LOO misclassification rate is adopted in two-class classification applications. By adopting the Parzen window estimate as the desired response, the unsupervised density estimation problem is transformed into a constrained regression problem. This PSO aided OFR algorithm for tunable-node RBF networks is capable of constructing very parsimonious RBF models that generalize well, and our analysis and experimental results demonstrate that the algorithm is computationally even simpler than the efficient regularization assisted orthogonal least square algorithm based on LOO criteria for selecting fixed-node RBF models. Another significant advantage of the proposed learning procedure is that it does not have learning hyperparameters that have to be tuned using costly cross validation. The effectiveness of the proposed PSO aided OFR construction procedure is illustrated using several examples taken from regression and classification, as well as density estimation applications.",
Support vector regression for multi-view gait recognition based on local motion feature selection,"Gait is a well recognized biometric feature that is used to identify a human at a distance. However, in real environment, appearance changes of individuals due to viewing angle changes cause many difficulties for gait recognition. This paper re-formulates this problem as a regression problem. A novel solution is proposed to create a View Transformation Model (VTM) from the different point of view using Support Vector Regression (SVR). To facilitate the process of regression, a new method is proposed to seek local Region of Interest (ROI) under one viewing angle for predicting the corresponding motion information under another viewing angle. Thus, the well constructed VTM is able to transfer gait information under one viewing angle into another viewing angle. This proposal can achieve view-independent gait recognition. It normalizes gait features under various viewing angles into a common viewing angle before similarity measurement is carried out. The extensive experimental results based on widely adopted benchmark dataset demonstrate that the proposed algorithm can achieve significantly better performance than the existing methods in literature.","Cameras,
Humans,
Legged locomotion,
Rendering (computer graphics),
Matrix decomposition,
Biometrics,
Image reconstruction,
Image recognition,
Linear discriminant analysis,
Computer science"
Efficient feature extraction and likelihood fusion for vehicle tracking in low frame rate airborne video,"Very large format video or wide-area motion imagery (WAMI) acquired by an airborne camera sensor array is characterized by persistent observation over a large field-of-view with high spatial resolution but low frame rates (i.e. one to ten frames per second). Current WAMI sensors have sufficient coverage and resolution to track vehicles for many hours using just a single airborne platform. We have developed an interactive low frame rate tracking system based on a derived rich set of features for vehicle detection using appearance modeling combined with saliency estimation and motion prediction. Instead of applying subspace methods to very high-dimensional feature vectors, we tested the performance of feature fusion to locate the target of interest within the prediction window. Preliminary results show that fusing the feature likelihood maps improves detection but fusing feature maps combined with saliency information actually degrades performance.","Histograms,
Vehicles,
Feature extraction,
Target tracking,
Cameras,
Arrays,
Correlation"
A Real-Time and Self-Calibrating Algorithm Based on Triaxial Accelerometer Signals for the Detection of Human Posture and Activity,"Assessment of human activity and posture with triaxial accelerometers provides insightful information about the functional ability: classification of human activities in rehabilitation and elderly surveillance contexts has been already proposed in the literature. In the meanwhile, recent technological advances allow developing miniaturized wearable devices, integrated within garments, which may extend this assessment to novel tasks, such as real-time remote surveillance of workers and emergency operators intervening in harsh environments. We present an algorithm for human posture and activity-level detection, based on the real-time processing of the signals produced by one wearable triaxial accelerometer. The algorithm is independent of the sensor orientation with respect to the body. Furthermore, it associates to its outputs a “reliability” value, representing the classification quality, in order to launch reliable alarms only when effective dangerous conditions are detected. The system was tested on a customized device to estimate the computational resources needed for real-time functioning. Results exhibit an overall 96.2% accuracy when classifying both static and dynamic activities.","Accelerometers,
Signal detection,
Humans,
Surveillance,
Senior citizens,
Clothing,
Signal processing,
Wearable sensors,
System testing,
Real time systems"
Soft Sensing and Optimal Power Control for Cognitive Radio,"We consider a cognitive radio system where the secondary transmitter varies its transmit power based on the information available from the spectrum sensor. The operation of the secondary user is governed by its peak transmit power constraint and an average interference constraint at the primary receiver. Without restricting the sensing scheme (total received energy, or correlation etc), we characterize the power adaptation strategies that maximize the secondary user's SNR and capacity. We show that, in general, the capacity optimal power adaptation requires decreasing the secondary transmit power from the peak power to zero in a continuous fashion as the probability of the primary user being present increases. In contrast, we find that that power control that maximizes the SNR is binary, i.e., if there is any transmission, it takes place only at the peak power level. Numerical results for common spectrum sensing schemes show that the SNR and capacity maximizing schemes can be very different. With an average transmit power constraint at the secondary radio, both the SNR and capacity optimal power control schemes are observed to be non-binary. Further, we find that with secondary channel knowledge at the cognitive transmitter, the optimal SNR with an average transmit power constraint is unbounded.",
A Study of Multiobjective Metaheuristics When Solving Parameter Scalable Problems,"To evaluate the search capabilities of a multiobjective algorithm, the usual approach is to choose a benchmark of known problems, to perform a fixed number of function evaluations, and to apply a set of quality indicators. However, while real problems could have hundreds or even thousands of decision variables, current benchmarks are normally adopted with relatively few decision variables (normally from 10 to 30). Furthermore, performing a constant number of evaluations does not provide information about the effort required by an algorithm to get a satisfactory set of solutions; this information would also be of interest in real scenarios, where evaluating the functions defining the problem can be computationally expensive. In this paper, we study the effect of parameter scalability in a number of state-of-the-art multiobjective metaheuristics. We adopt a benchmark of parameter-wise scalable problems (the Zitzler-Deb-Thiele test suite) and analyze the behavior of eight multiobjective metaheuristics on these test problems when using a number of decision variables that range from 8 up to 2048. By using the hypervolume indicator as a stopping condition, we also analyze the computational effort required by each algorithm in order to reach the Pareto front. We conclude that the two analyzed algorithms based on particle swarm optimization and differential evolution yield the best overall results.","Ant colony optimization,
Performance evaluation,
Scalability,
Benchmark testing,
Algorithm design and analysis,
Particle swarm optimization,
Pareto optimization,
Pareto analysis,
Technological innovation,
Contracts"
Odin II - An Open-Source Verilog HDL Synthesis Tool for CAD Research,"In this work, we present Odin II, a framework for Verilog Hardware Description Language (HDL) synthesis that allows researchers to investigate approaches/improvements to different phases of HDL elaboration that have not been previously possible. Odin II’s output can be fed into traditional back-end flows for both FPGAs and ASICs so that these improvements can be better quantified. Whereas the original Odin [1] provided an open source synthesis tool, Odin II’s synthesis framework offers significant improvements such as a unified environment for both front-end parsing and netlist flattening. Odin II also interfaces directly with VPR [2], a common academic FPGA CAD flow, allowing an architectural description of a target FPGA as an input to enable identification and mapping of design features to custom features. Furthermore, Odin II can also read the netlists from downstream CAD stages into its netlist data-structure to facilitate analysis. Odin II can be used for a wide range of experiments; in this paper, we show three specific instances of how Odin II can be used by ASIC and FPGA researchers for more than basic synthesis. Odin II is open source and released under the MIT License.","Hardware design languages,
Open source software,
Design automation,
Field programmable gate arrays,
Integrated circuit synthesis,
Application specific integrated circuits,
Design engineering,
Integrated circuit technology,
Computer science,
Automata"
Eigen-based clutter filter design for ultrasound color flow imaging: a review,"Proper suppression of tissue clutter is a prerequisite for visualizing flow accurately in ultrasound color flow imaging. Among various clutter suppression methods, the eigen- based filter has shown potential because it can theoretically adapt its stopband to the actual clutter characteristics even when tissue motion is present. This paper presents a formative review on how eigen-based filters should be designed to improve their practical efficacy in adaptively suppressing clutter without affecting the blood flow echoes. Our review is centered around a comparative assessment of two eigen-filter design considerations: 1) eigen-component estimation approach (single-ensemble vs. multi-ensemble formulations), and 2) filter order selection mechanism (eigenvalue-based vs. frequencybased algorithms). To evaluate the practical efficacy of existing eigen-filter designs, we analyzed their clutter suppression level in two in vivo scenarios with substantial tissue motion (intra-operative coronary imaging and thyroid imaging). Our analysis shows that, as compared with polynomial regression filters (with or without instantaneous clutter downmixing), eigen-filters that use a frequency-based algorithm for filter order selection generally give Doppler power images with better contrast between blood and tissue regions. Results also suggest that both multi-ensemble and single-ensemble eigen-estimation approaches have their own advantages and weaknesses in different imaging scenarios. It may be beneficial to develop an algorithmic way of defining the eigen-filter formulation so that its performance advantages can be better realized.","Ultrasonic imaging,
Frequency,
Image analysis,
Visualization,
Adaptive filters,
Blood flow,
Image motion analysis,
In vivo,
Motion analysis,
Algorithm design and analysis"
Multiparameter Receiver Operating Characteristic Analysis for Signal Detection and Classification,"Receiver operating characteristic (ROC) analysis is a widely used evaluation tool in signal processing and communications, and medical diagnosis for performance analysis. It utilizes 2-D curves plotted by detection rate (P D) against false alarm rate (P F) to assess effectiveness of a detector, sensor/device for detection. However, P D and P F are actually dependent parameters resulting from a more crucial but implicit parameter hidden in the ROC curves, threshold ¿ , which is determined by the cost of implementing a detector or sensor/device, except only the case that when the Bayes theory is used for detection, ¿ is completely determined by the Bayes cost. This paper extends the traditional ROC analysis for single-signal detection to detection and classification of multiple signals. It also explores relationships among the three parameters, P D, P F, and ¿ , and further develops a new concept of multiparameter ROC analysis, which uses 3-D ROC curves plotted by three parameters, P D, P F, and ¿, to evaluate effectiveness of detection performance based on interrelationship among P D, P F, and ¿, rather then only P D and P F used by 2-D ROC analysis. As a result of a 3-D ROC curve, three 2-D ROC curves can be also derived: the conventional 2-D ROC curve plotted by P D versus P F and two new 2-D ROC curves plotted based on P D versus ¿ and P F versus ¿. In order to demonstrate the utility of 3-D ROC analysis, four applications are considered: hyperspectral target detection, medical diagnosis, chemical/biological agent detection, and biometric recognition.","Signal analysis,
Signal detection,
Performance analysis,
Medical diagnosis,
Detectors,
Costs,
Medical signal detection,
Signal processing,
Biochemical analysis,
Object detection"
Shape and Spatially-Varying BRDFs from Photometric Stereo,"This paper describes a photometric stereo method designed for surfaces with spatially-varying BRDFs, including surfaces with both varying diffuse and specular properties. Our optimization-based method builds on the observation that most objects are composed of a small number of fundamental materials by constraining each pixel to be representable by a combination of at most two such materials. This approach recovers not only the shape but also material BRDFs and weight maps, yielding accurate rerenderings under novel lighting conditions for a wide variety of objects. We demonstrate examples of interactive editing operations made possible by our approach.","Photometry,
Image reconstruction,
Shape measurement,
Computer science,
Design methodology,
Constraint optimization,
Image analysis,
Reflectivity,
Layout,
Material properties"
Detection of Movement in Bed Using Unobtrusive Load Cell Sensors,"Quality of sleep is an important attribute of an individual's health state and its assessment is therefore a useful diagnostic feature. Changes in the patterns of motor activities during sleep can be a disease marker, or can reflect various abnormal physiological and neurological conditions. Presently, there are no convenient, unobtrusive ways to assess quality of sleep outside of a clinic. This paper describes a system for unobtrusive detection of movement in bed that uses load cells installed at the corners of a bed. The system focuses on identifying when a movement occurs based on the forces sensed by the load cells. The movement detection approach estimates the energy in each load cell signal over short segments to capture the variations caused by movement. The accuracy of the detector is evaluated using data collected in the laboratory. The detector is capable of detecting voluntary movements in bed while the subjects were awake, with an average equal error rate of 3.22% (±0.54). Its performance is invariant with respect to the individual's characteristics, e.g., weight, as well as those of the bed. The simplicity of the resulting algorithms and their relative insensitivity to the weight and height of the monitored individual make the approach practical and easily deployable in residential and clinical settings.","Sleep,
Sensor phenomena and characterization,
Detectors,
Parkinson's disease,
Biomedical monitoring,
Energy capture,
Laboratories,
Error analysis,
Mathematics"
Frequency Estimation by Phase Unwrapping,"Single frequency estimation is a long-studied problem with application domains including radar, sonar, telecommunications, astronomy and medicine. One method of estimation, called phase unwrapping, attempts to estimate the frequency by performing linear regression on the phase of the received signal. This procedure is complicated by the fact that the received phase is `wrapped' modulo and therefore must be `unwrapped' before the regression can be performed. In this paper, we propose an estimator that performs phase unwrapping in the least squares sense. The estimator is shown to be strongly consistent and its asymptotic distribution is derived. We then show that the problem of computing the least squares phase unwrapping is related to a problem in algorithmic number theory known as the nearest lattice point problem. We derive a polynomial time algorithm that computes the least squares estimator. The results of various simulations are described for different values of sample size and SNR.","Frequency estimation,
Phase estimation,
Least squares approximation,
Radar applications,
Sonar applications,
Astronomy,
Linear regression,
Least squares methods,
Lattices,
Polynomials"
Ambulatory Monitoring of Activities and Motor Symptoms in Parkinson's Disease,"Ambulatory monitoring of motor symptoms in Parkinson's disease (PD) can improve our therapeutic strategies, especially in patients with motor fluctuations. Previously published monitors usually assess only one or a few basic aspects of the cardinal motor symptoms in a laboratory setting. We developed a novel ambulatory monitoring system that provides a complete motor assessment by simultaneously analyzing current motor activity of the patient (e.g., sitting, walking, etc.) and the severity of many aspects related to tremor, bradykinesia, and hypokinesia. The monitor consists of a set of four inertial sensors. Validity of our monitor was established in seven healthy controls and six PD patients treated with deep brain stimulation (DBS) of the subthalamic nucleus. The patients were tested at three different levels of DBS treatment. Subjects were monitored while performing different tasks, including motor tests of the Unified PD Rating Scale (UPDRS). Output of the monitor was compared to simultaneously recorded videos. The monitor proved very accurate in discriminating between several motor activities. Monitor output correlated well with blinded UPDRS ratings during different DBS levels. The combined analysis of motor activity and symptom severity by our PD monitor brings true ambulatory monitoring of a wide variety of motor symptoms one step closer.","Parkinson's disease,
Patient monitoring,
Satellite broadcasting,
Medical treatment,
Testing,
Fluctuations,
Laboratories,
Legged locomotion,
PD control,
Brain stimulation"
"Fuzzy PCA-Guided Robust
k
-Means Clustering","This paper proposes a new approach to robust clustering, in which a robust k-means partition is derived by using a noise-rejection mechanism based on the noise-clustering approach. The responsibility weight of each sample for the k-means process is estimated by considering the noise degree of the sample, and cluster indicators are calculated in a fuzzy principal-component-analysis (PCA) guided manner, where fuzzy PCA-guided robust k-means is performed by considering responsibility weights of samples. Then, the proposed method achieves cluster-core estimation in a deterministic way. The validity of the derived cluster cores is visually assessed through distance-sensitive ordering, which considers responsibility weights of samples. Numerical experiments demonstrate that the proposed method is useful for capturing cluster cores by rejecting noise samples, and we can easily assess cluster validity by using cluster-crossing curves.","Robustness,
Prototypes,
Principal component analysis,
Data analysis,
Eigenvalues and eigenfunctions,
Clustering algorithms,
Iterative algorithms,
Fuzzy systems,
Clustering methods,
Phase estimation"
Image Segmentation by MAP-ML Estimations,"Image segmentation plays an important role in computer vision and image analysis. In this paper, image segmentation is formulated as a labeling problem under a probability maximization framework. To estimate the label configuration, an iterative optimization scheme is proposed to alternately carry out the maximum a posteriori (MAP) estimation and the maximum likelihood (ML) estimation. The MAP estimation problem is modeled with Markov random fields (MRFs) and a graph cut algorithm is used to find the solution to the MAP estimation. The ML estimation is achieved by computing the means of region features in a Gaussian model. Our algorithm can automatically segment an image into regions with relevant textures or colors without the need to know the number of regions in advance. Its results match image edges very well and are consistent with human perception. Comparing to six state-of-the-art algorithms, extensive experiments have shown that our algorithm performs the best.",
Facial expression recognition using Gabor motion energy filters,"Spatial Gabor energy filters (GE) are one of the most successful approaches to represent facial expressions in computer vision applications, including face recognition and expression analysis. It is well known that these filters approximate the response of complex cells in primary visual cortex. However these neurons are modulated by the temporal, not just spatial, properties of the visual signal. This suggests that spatio-temporal Gabor filters may provide useful representations for applications that involve video sequences. In this paper we explore Gabor motion energy filters (GME) as a biologically inspired representation for dynamic facial expressions. Experiments on the Cohn-Kanade expression dataset show that GME outperforms GE, particularly on difficult low intensity expression discrimination.",
Using the Amazon Mechanical Turk for transcription of spoken language,"We investigate whether Amazon's Mechanical Turk (MTurk) service can be used as a reliable method for transcription of spoken language data. Utterances with varying speaker demographics (native and non-native English, male and female) were posted on the MTurk marketplace together with standard transcription guidelines. Transcriptions were compared against transcriptions carefully prepared in-house through conventional (manual) means. We found that transcriptions from MTurk workers were generally quite accurate. Further, when transcripts for the same utterance produced by multiple workers were combined using the ROVER voting scheme, the accuracy of the combined transcript rivaled that observed for conventional transcription methods. We also found that accuracy is not particularly sensitive to payment amount, implying that high quality results can be obtained at a fraction of the cost and turnaround time of conventional methods.",
Modeling Spiking Neural Networks on SpiNNaker,"SpiNNaker is a massively parallel architecture with more than a million processing cores that can model up to 1 billion spiking neurons in biological real time. Here, we offer an overview of our research project and describe the first experiments with these test chips running spiking neurons based on Eugene Izhikevich's model. Note that we're not targeting artificial neural networks (such as perceptrons or multilayer networks) that were inspired by, but don't model, biologically plausible neural systems.","Neurons,
Biological system modeling,
Mathematical model,
Computational modeling,
Biomembranes,
Routing"
Graph-based segmentation for colored 3D laser point clouds,"We present an efficient graph-theoretic algorithm for segmenting a colored laser point cloud derived from a laser scanner and camera. Segmentation of raw sensor data is a crucial first step for many high level tasks such as object recognition, obstacle avoidance and terrain classification. Our method enables combination of color information from a wide field of view camera with a 3D LIDAR point cloud from an actuated planar laser scanner. We extend previous work on robust camera-only graph-based segmentation to the case where spatial features, such as surface normals, are available. Our combined method produces segmentation results superior to those derived from either cameras or laser-scanners alone. We verify our approach on both indoor and outdoor scenes.","Image color analysis,
Image segmentation,
Cameras,
Lasers,
Clouds,
Image edge detection,
Robot sensing systems"
An Auction Framework for Spectrum Allocation with Interference Constraint in Cognitive Radio Networks,"Extensive research in recent years has shown the benefits of \textit{cognitive radio} technologies to improve the flexibility and efficiency of spectrum utilization. This new communication paradigm, however, requires a well-designed spectrum allocation mechanism. In this paper, we propose an auction framework for cognitive radio networks to allow unlicensed secondary users (SUs) to share the available spectrum of licensed primary users (PUs) fairly and efficiently, subject to the interference temperature constraint at each PU. To study the competition among SUs, we formulate a non-cooperative multiple-PU multiple-SU auction game and study the structure of the resulting equilibrium by solving a non-continuous two-dimensional optimization problem. A distributed algorithm is developed in which each SU updates its strategy based on local information to converge to the equilibrium. We then extend the proposed auction framework to the more challenging scenario with free spectrum bands. We develop an algorithm based on the no-regret learning to reach a correlated equilibrium of the auction game. The proposed algorithm, which can be implemented distributedly based on local observation, is especially suited in decentralized adaptive learning environments as cognitive radio networks. Finally, through numerical experiments, we demonstrate the effectiveness of the proposed auction framework in achieving high efficiency and fairness in spectrum allocation.","Interference constraints,
Cognitive radio,
Resource management,
Temperature,
Distributed algorithms,
Communications Society,
Telecommunications,
Computer science,
Constraint optimization,
Command and control systems"
FleaNet: A Virtual Market Place on Vehicular Networks,"In this study, we introduce the concept of a virtual ¿flea market¿ over a vehicular ad hoc network (VANET) called FleaNet. FleaNet customers express their demands/offers to buy/sell items via radio queries. These queries are opportunistically disseminated, exploiting the mobility of other customers, until a matching customer/vendor is found. We identify the key performance metrics, namely, query resolution latency, scalability, mobility, and churning, and evaluate their impact on performance using analytic and simulation models. The results show that FleaNet can function as an effective virtual marketplace.",
Segmentation of Regions of Interest in Mammograms in a Topographic Approach,"This paper presents a novel method for the segmentation of regions of interest in mammograms. The algorithm concurrently delineates the boundaries of the breast boundary, the pectoral muscle, as well as dense regions that include candidate masses. The resulting representation constitutes an analysis of the global structure of the object in the mammogram. We propose a topographic representation called the isocontour map, in which a salient region forms a dense quasi-concentric pattern of contours. The topological and geometrical structure of the image is analyzed using an inclusion tree that is a hierarchical representation of the enclosure relationships between contours. The ¿saliency¿ of a region is measured topologically as the minimum nesting depth. Features at various scales are analyzed in multiscale isocontour maps, and we demonstrate that the multiscale scheme provides an efficient way of achieving better delineations. Experimental results demonstrate that the proposed method has potential as the basis for a prompting system in mammogram mass detection.","Breast cancer,
Mammography,
X-ray imaging,
Cancer detection,
Muscles,
Image analysis,
Metastasis,
Computer science,
Aging,
Optical imaging"
An Accurate Time-Domain Procedure for Harmonics and Interharmonics Detection,"Frequency is an important indicator for the quality of electric power. Accurate spectral decompositions rely much on the correct identification of frequencies of the measured signals. An efficient procedure that includes a high-resolution Prony-based method in conjunction with the downsampling technique for harmonics and interharmonics detection of the measured power signal is proposed in this paper. It is shown that even when two or more closely adjacent spectral lines are present, the proposed method can precisely detect the harmonic and interharmonic components. The performance of the proposed method is validated by testing the simulated and actual measured power signals. Results are compared with those obtained by fast Fourier transform with and without synchronization, IEC subgrouping method, and other commonly used linear prediction approaches adopted in the Prony's method. It shows that the proposed method is more accurate on the detection of harmonics and interharmonics with high resolution.","Time domain analysis,
Power measurement,
Frequency measurement,
Signal processing,
Power system harmonics,
Testing,
Fast Fourier transforms,
Frequency synchronization,
IEC,
Signal resolution"
Detection and classification of power quality disturbances using discrete wavelet transform and wavelet networks,"A novel approach for detection and classification of power quality (PQ) disturbances is proposed. The distorted waveforms (PQ events) are generated based on the IEEE 1159 standard, captured with a sampling rate of 20 kHz and de-noised using discrete wavelet transform (DWT) to obtain signals with higher signal-to-noise ratio. The DWT is also used to decompose the signal of PQ events and to extract its useful information. Proper feature vectors are selected and applied in training the wavelet network classifier. The effectiveness of the proposed method is tested using a wide spectrum of PQ disturbances including dc offset, harmonics, flicker, interrupt, sag, swell, notching, transient and combinations of these events. Comparison of test results with those generated by other existing methods shows enhanced performance with a classification accuracy of 98.18. The main contribution of the paper is an accurate (because of proper selection of feature vectors), fast (e.g. a new de-noising approach with proposed identification criterion) and robust (at different signal-to-noise ratios) wavelet network-based algorithm (as compared to the conventional wavelet-based algorithms) for detection/classification of individual, as well as combined PQ disturbances.","power system faults,
discrete wavelet transforms,
power supply quality"
eScience in the cloud: A MODIS satellite data reprojection and reduction pipeline in the Windows Azure platform,"The combination of low-cost sensors, low-cost commodity computing, and the Internet is enabling a new era of data-intensive science. The dramatic increase in this data availability has created a new challenge for scientists: how to process the data. Scientists today are envisioning scientific computations on large scale data but are having difficulty designing software architectures to accommodate the large volume of the often heterogeneous and inconsistent data. In this paper, we introduce a particular instance of this challenge, and present our design and implementation of a MODIS satellite data reprojection and reduction pipeline in the Windows Azure cloud computing platform. This cloud-based pipeline is designed with a goal of hiding data complexities and subsequent data processing and transformation from end u sers. This pipeline is highly flexible and extensible to accommodate different science data processing tasks, and can be dynamically scaled to fulfill scientists' various computational requirements in a cost-efficient way. Experiments show that by running a practical large-scale science data processing job in the pipeline using 150 moderately-sized Azure virtual machine instances, we were able to produce analytical results in nearly 90X less time than was possible with a high-end desktop machine. To our knowledge, this is one of the first eScience applications to use the Windows Azure platform.","MODIS,
Satellites,
Pipelines,
Data processing,
Large-scale systems,
Internet,
Software design,
Software architecture,
Cloud computing,
Virtual machining"
A Multiplicative Weights Mechanism for Privacy-Preserving Data Analysis,"We consider statistical data analysis in the interactive setting. In this setting a trusted curator maintains a database of sensitive information about individual participants, and releases privacy-preserving answers to queries as they arrive. Our primary contribution is a new differentially private multiplicative weights mechanism for answering a large number of interactive counting (or linear) queries that arrive online and may be adaptively chosen. This is the first mechanism with worst-case accuracy guarantees that can answer large numbers of interactive queries and is {\em efficient} (in terms of the runtime's dependence on the data universe size). The error is asymptotically \emph{optimal} in its dependence on the number of participants, and depends only logarithmically on the number of queries being answered. The running time is nearly {\em linear} in the size of the data universe. As a further contribution, when we relax the utility requirement and require accuracy only for databases drawn from a rich class of databases, we obtain exponential improvements in running time. Even in this relaxed setting we continue to guarantee privacy for {\em any} input database. Only the utility requirement is relaxed. Specifically, we show that when the input database is drawn from a {\em smooth} distribution — a distribution that does not place too much weight on any single data item — accuracy remains as above, and the running time becomes {\em poly-logarithmic} in the data universe size. The main technical contributions are the application of multiplicative weights techniques to the differential privacy setting, a new privacy analysis for the interactive setting, and a technique for reducing data dimensionality for databases drawn from smooth distributions.",
Coverage and Detection of a Randomized Scheduling Algorithm in Wireless Sensor Networks,"In wireless sensor networks, some sensor nodes are put in sleep mode while other sensor nodes are in active mode for sensing and communication tasks in order to reduce energy consumption and extend network lifetime. This approach is a special case (k=2) of a randomized scheduling algorithm, in which k subsets of sensors work alternatively. In this paper, we first study the randomized scheduling algorithm via both analysis and simulations in terms of network coverage intensity, detection delay, and detection probability. We further study asymptotic coverage and other properties. Finally, we analyze a problem of maximizing network lifetime under quality of service constraints such as bounded detection delay, detection probability, and network coverage intensity. We prove that the optimal solution exists, and provide conditions of the existence of the optimal solutions.","Delay,
Wireless sensor networks,
Sensors,
Computational modeling,
Electronic mail,
Quality of service,
Analytical models"
NCSLab: A Web-Based Global-Scale Control Laboratory With Rich Interactive Features,"This paper introduces the Networked Control System Laboratory (NCSLab) at http://www.ncslab.net, which provides a complete Web-based solution for users to carry out experiments on experiment devices located globally. A scalable architecture is proposed, which is composed of Web browsers, central Web server, MATLAB servers, regional experiment servers, control units, and experiment devices. Based on the architecture, many novel features, including visual algorithm designing, simulation, compilation, visual monitor configuration, and real-time monitoring and supervisory control, are designed and implemented by a combination of state-of-the-art technologies such as Web 2.0, Java 2 Enterprise Edition, and MATLAB. Users can enjoy all these rich interactive features with a simple Web browser from anywhere at any time. The issues of device safety, network security, and instability are also tackled in NCSLab.","Laboratories,
Web server,
Service oriented architecture,
MATLAB,
Algorithm design and analysis,
Monitoring,
Networked control systems,
Centralized control,
Supervisory control,
Java"
Coordinated Motion Design on Lie Groups,"The present paper proposes a unified geometric framework for coordinated motion on Lie groups. It first gives a general problem formulation and analyzes ensuing conditions for coordinated motion. Then, it introduces a precise method to design control laws in fully actuated and underactuated settings with simple integrator dynamics. It thereby shows that coordination can be studied in a systematic way once the Lie group geometry of the configuration space is well characterized. Applying the proposed general methodology to particular examples allows to retrieve control laws that have been proposed in the literature on intuitive grounds. A link with Brockett's double bracket flows is also made. The concepts are illustrated on SO(3) , SE(2) and SE(3) .","Control systems,
Manifolds,
Vehicle dynamics,
Motion control,
Oscillators,
Space vehicles,
Motion analysis,
Design methodology,
Geometry,
Distributed control"
Beyond Trilateration: On the Localizability of Wireless Ad Hoc Networks,"The proliferation of wireless and mobile devices has fostered the demand of context-aware applications, in which location is often viewed as one of the most significant contexts. Classically, trilateration is widely employed for testing network localizability; even in many cases, it wrongly recognizes a localizable graph as nonlocalizable. In this study, we analyze the limitation of trilateration-based approaches and propose a novel approach that inherits the simplicity and efficiency of trilateration and, at the same time, improves the performance by identifying more localizable nodes. We prove the correctness and optimality of this design by showing that it is able to locally recognize all one-hop localizable nodes. To validate this approach, a prototype system with 60 wireless sensors is deployed. Intensive and large-scale simulations are further conducted to evaluate the scalability and efficiency of our design.","Mobile ad hoc networks,
Peer to peer computing,
Wireless sensor networks,
Sensor phenomena and characterization,
Radiofrequency identification,
Testing,
Performance analysis,
Prototypes,
Sensor systems,
Large-scale systems"
A Bayesian Framework for Image Segmentation With Spatially Varying Mixtures,"A new Bayesian model is proposed for image segmentation based upon Gaussian mixture models (GMM) with spatial smoothness constraints. This model exploits the Dirichlet compound multinomial (DCM) probability density to model the mixing proportions (i.e., the probabilities of class labels) and a Gauss-Markov random field (MRF) on the Dirichlet parameters to impose smoothness. The main advantages of this model are two. First, it explicitly models the mixing proportions as probability vectors and simultaneously imposes spatial smoothness. Second, it results in closed form parameter updates using a maximum a posteriori (MAP) expectation-maximization (EM) algorithm. Previous efforts on this problem used models that did not model the mixing proportions explicitly as probability vectors or could not be solved exactly requiring either time consuming Markov Chain Monte Carlo (MCMC) or inexact variational approximation methods. Numerical experiments are presented that demonstrate the superiority of the proposed model for image segmentation compared to other GMM-based approaches. The model is also successfully compared to state of the art image segmentation methods in clustering both natural images and images degraded by noise.","Bayesian methods,
Image segmentation,
Clustering algorithms,
Maximum likelihood estimation,
Gaussian processes,
Monte Carlo methods,
Approximation methods,
Degradation,
Gaussian distribution,
Rate distortion theory"
Joint Routing and Sleep Scheduling for Lifetime Maximization of Wireless Sensor Networks,"The rapid proliferation of wireless sensor networks has stimulated enormous research efforts that aim to maximize the lifetime of battery-powered sensor nodes and, by extension, the overall network lifetime. Most work in this field can be divided into two equally important threads, namely (i) energy-efficient routing that balances traffic load across the network according to energy-related metrics and (ii) sleep scheduling that reduces energy cost due to idle listening by providing periodic sleep cycles for sensor nodes. To date, these two threads are pursued separately in the literature, leading to designs that optimize one component assuming the other is pre-determined. Such designs give rise to practical difficulty in determining the appropriate routing and sleep scheduling schemes in the real deployment of sensor networks, as neither component can be optimized without pre-fixing the other one. This paper endeavors to address the lack of a joint routing-and-sleep-scheduling scheme in the literature by incorporating the design of the two components into one optimization framework. Notably, joint routing-and-sleep-scheduling by itself is a non-convex optimization problem, which is difficult to solve. We tackle the problem by transforming it into an equivalent Signomial Program (SP) through relaxing the flow conservation constraints. The SP problem is then solved by an iterative Geometric Programming (IGP) method, yielding an near optimal routing-and-sleep-scheduling scheme that maximizes network lifetime. To the best of our knowledge, this is the first attempt to obtain the optimal joint routing-and-sleep-scheduling strategy for wireless sensor networks. The near optimal solution provided by this work opens up new possibilities for designing practical and heuristic schemes targeting the same problem, for now the performance of any new heuristics can be easily evaluated by using the proposed near optimal scheme as a benchmark.","Routing,
Sleep,
Wireless sensor networks,
Design optimization,
Telecommunication traffic,
Costs,
Batteries,
Energy efficiency,
Iterative methods"
"Power Engineering and Motion Control Web Laboratory: Design, Implementation, and Evaluation of Mechatronics Course","During the E-learning Distance Interactive Practical Education project, 13 partners from 11 European countries joined together to build a power engineering and motion control remote laboratory, which would offer 18 complete online courses with remote experiments and high-quality documentation, to students from the universities of all participating partners. The major benefit of this project is the possibility of sharing expensive equipment and lessening the burdens of technical and organizational problems. This paper outlines the project's goals, organization, and, as an example, realization of one of the project's modules. The described module is a mechatronics motion control course, which explains the most important aspects of motion control design, from modeling, simulations, control design, experimental validation, and comparison between various controllers. The technical solutions, educational strategy, and realization details are given for the module. The pilot testing of the module was performed to assess the module and find out what the students' personal attitude concerning e-learning and remote experiments. The results of testing are presented and discussed.","Power engineering,
Motion control,
Mechatronics,
Electronic learning,
Testing,
Control engineering education,
Power engineering education,
Remote laboratories,
Documentation,
Educational institutions"
UAV relay network to support WSN connectivity,"An important problem in Wireless Sensor Networks (WSN) is the occurrence of failures that lead to the disconnection of parts of the network, compromising the final results achieved by the WSN operation. A way to overcome such problem is to provide a reliable connection to support the connectivity via other types of nodes that communicate with the sensor nodes. This paper proposes the usage of a network composed by Unmanned Aerial Vehicles (UAVs) as a relay network to guarantee the delivery of data produced by WSN nodes on the ground to the users. Results from simulations of the proposed technique are provided and discussed.","Base stations,
Unmanned aerial vehicles,
Mobile communication,
Wireless sensor networks,
Peer to peer computing,
Mobile computing,
Relays"
Accuracy of Sine Wave Frequency Estimation by Multipoint Interpolated DFT Approach,"This paper focuses on the frequency-domain estimation of the normalized frequency of a sine wave corrupted by a stationary white noise. The weighted multipoint interpolated discrete Fourier transform method is considered, and its effect on both the spectral interference due to the image component and the additive wideband noise is taken into account. In particular, the expression of the combined standard uncertainty of the estimator is derived in the case when the H-term maximum sidelobe decay window (H ≥ 2) is used, and the number of interpolation points is 2J + 1 (J ≥ 1). Based on this expression, the number of interpolation points that minimize the estimator-combined uncertainty can be determined. The derived results are validated by means of computer simulations and applied to experimental data.","Interpolation,
Uncertainty,
Frequency estimation,
Noise,
Interference,
Discrete Fourier transforms,
Wideband"
A First Step Towards Understanding Popularity in YouTube,"Being popular in YouTube is becoming a fundamental way of promoting one's self, services or products. In this paper, we conduct an in depth study of fundamental properties of video popularity in YouTube. We collect and study arguably the largest dataset of YouTube videos, roughly 37 million, accounting for 25% of all YouTube videos. We analyze popularity in a comprehensive fashion by looking at properties and patterns in time and considering various popularity metrics. We further study the relationship of the popularity metrics and we find that four of them are highly correlated (viewcount, #comments, #ratings, #favorites) while the fifth one, the average rating, exhibits very little correlation with the other metrics. We also find a ""magic number"" in the average behavior of videos: for every 400 times a video is viewed, we have one of each of the following user actions: leaving a comment, rating the video and adding to one's favorite set.","YouTube,
Feeds,
Communications Society,
Computer science,
Pattern analysis,
Internet,
Engineering profession,
Terminology,
Watches,
Social network services"
A Scalable Limited Feedback Design for Network MIMO Using Per-Cell Product Codebook,"In network MIMO systems, channel state information is required at the transmitter side to multiplex users in the spatial domain. Since perfect channel knowledge is difficult to obtain in practice, limited feedback is a widely accepted solution. The dynamic number of cooperating BSs and heterogeneous path loss effects of network MIMO systems pose new challenges on limited feedback design. In this paper, we propose a scalable limited feedback design for network MIMO systems with multiple base stations, multiple users and multiple data streams for each user. We propose a limited feedback framework using per-cell product codebooks, along with a low-complexity feedback indices selection algorithm. We show that the proposed per-cell product codebook limited feedback design can asymptotically achieve the same performance as the joint-cell codebook approach. We also derive an asymptotic per-user throughput loss due to limited feedback with per-cell product codebooks. Based on that, we show that when the number of per-user feedback-bits Bk is {O}( NnTnR log2(ρgksum)), the system operates in the noise-limited regime in which the per-user throughput is {O} ( nR log2 (nRρgksum/NnT)). On the other hand, when the number of per-user feedback-bits Bk does not scale with the system SNR ρ, the system operates in the interference-limited regime where the per-user throughput is {O}(nRBk/(NnT)2). Numerical results show that the proposed design is very flexible to accommodate dynamic number of cooperating BSs and achieves much better performance compared with other baselines (such as the Givens rotation approach).",
USC CINAPS Builds Bridges,"More than 70% of our earth is covered by water, yet we have explored less than 5% of the aquatic environment. Aquatic robots, such as autonomous underwater vehicles (AUVs), and their supporting infrastructure play a major role in the collection of oceanographic data. To make new discoveries and improve our overall understanding of the ocean, scientists must make use of these platforms by implementing effective monitoring and sampling techniques to study ocean upwelling, tidal mixing, and other ocean processes. Effective observation and continual monitoring of a dynamic system as complex as the ocean cannot be done with one instrument in a fixed location. A more practical approach is to deploy a collection of static and mobile sensors, where the information gleaned from the acquired data is distributed across the network. Additionally, orchestrating a multisensor, long-term deployment with a high volume of distributed data involves a robust, rapid, and cost-effective communication network. Connecting all of these components, which form an aquatic robotic system, in synchronous operation can greatly assist the scientists in improving our overall understanding of the complex ocean environment.","Bridges,
Oceans,
Monitoring,
Earth,
Robots,
Underwater vehicles,
Sampling methods,
Vehicle dynamics,
Instruments,
Robustness"
Boundary Learning by Optimization with Topological Constraints,"Recent studies have shown that machine learning can improve the accuracy of detecting object boundaries in images. In the standard approach, a boundary detector is trained by minimizing its pixel-level disagreement with human boundary tracings. This naive metric is problematic because it is overly sensitive to boundary locations. This problem is solved by metrics provided with the Berkeley Segmentation Dataset, but these can be insensitive to topological differences, such as gaps in boundaries. Furthermore, the Berkeley metrics have not been useful as cost functions for supervised learning. Using concepts from digital topology, we propose a new metric called the warping error that tolerates disagreements over boundary location, penalizes topological disagreements, and can be used directly as a cost function for learning boundary detection, in a method that we call Boundary Learning by Optimization with Topological Constraints (BLOTC). We trained boundary detectors on electron microscopic images of neurons, using both BLOTC and standard training. BLOTC produced substantially better performance on a 1.2 million pixel test set, as measured by both the warping error and the Rand index evaluated on segmentations generated from the boundary labelings. We also find our approach yields significantly better segmentation performance than either gPb-OWT-UCM or multiscale normalized cut, as well as Boosted Edge Learning trained directly on our data.","Constraint optimization,
Image segmentation,
Detectors,
Cost function,
Machine learning,
Object detection,
Humans,
Supervised learning,
Topology,
Electrons"
"SMARTDIAB: A Communication and Information Technology Approach for the Intelligent Monitoring, Management and Follow-up of Type 1 Diabetes Patients","SMARTDIAB is a platform designed to support the monitoring, management, and treatment of patients with type 1 diabetes mellitus (T1DM), by combining state-of-the-art approaches in the fields of database (DB) technologies, communications, simulation algorithms, and data mining. SMARTDIAB consists mainly of two units: 1) the patient unit (PU); and 2) the patient management unit (PMU), which communicate with each other for data exchange. The PMU can be accessed by the PU through the internet using devices, such as PCs/laptops with direct internet access or mobile phones via a Wi-Fi/General Packet Radio Service access network. The PU consists of an insulin pump for subcutaneous insulin infusion to the patient and a continuous glucose measurement system. The aforementioned devices running a user-friendly application gather patient's related information and transmit it to the PMU. The PMU consists of a diabetes data management system (DDMS), a decision support system (DSS) that provides risk assessment for long-term diabetes complications, and an insulin infusion advisory system (IIAS), which reside on a Web server. The DDMS can be accessed from both medical personnel and patients, with appropriate security access rights and front-end interfaces. The DDMS, apart from being used for data storage/retrieval, provides also advanced tools for the intelligent processing of the patient's data, supporting the physician in decision making, regarding the patient's treatment. The IIAS is used to close the loop between the insulin pump and the continuous glucose monitoring system, by providing the pump with the appropriate insulin infusion rate in order to keep the patient's glucose levels within predefined limits. The pilot version of the SMARTDIAB has already been implemented, while the platform's evaluation in clinical environment is being in progress.","Information technology,
Patient monitoring,
Technology management,
Diabetes,
Insulin,
Phasor measurement units,
Sugar,
Distributed decision making,
Medical treatment,
IP networks"
Effects of haptic guidance and disturbance on motor learning: Potential advantage of haptic disturbance,"One of the primary goals of haptic guidance is to facilitate the learning of complex human motor skills by providing haptic cues that are helpful to induce desired movements. Nevertheless, a majority of previous studies have found that haptic guidance is ineffective, or sometimes even detrimental, to motor skill learning. In this paper, we propose the opposite concept, haptic disturbance, and evaluate its efficacy. In haptic disturbance, haptic cues that interfere with the movements of a learner are presented during training. We designed two methods of haptic disturbance using repulsive and noise-like forces, respectively. The effects of these methods were experimentally assessed, comparatively with the conventional methods of visual learning only and progressive haptic guidance. The motor task was to track a dot moving on a 2D plane with a haptic interface operated with one arm. We found that during training, the progressive haptic guidance showed the best tracking accuracy, but in immediate and delayed retention tests, the noise-like haptic disturbance led to the best performance. The results suggest high potentials for haptic disturbance to be a general strategy for expediting the motor learning process.",
Grasping novel objects with depth segmentation,"We consider the task of grasping novel objects and cleaning fairly cluttered tables with many novel objects. Recent successful approaches employ machine learning algorithms to identify points on the scene that the robot should grasp. In this paper, we show that the task can be significantly simplified by using segmentation, especially with depth information. A supervised localization method is employed to select graspable segments. We also propose a shape completion and grasp planner method which takes partial 3D information and plans the most stable grasping strategy. Extensive experiments on our robot demonstrate the effectiveness of our approach.","Grasping,
Three dimensional displays,
Image segmentation,
Robot sensing systems,
Shape,
Pixel"
A new texture descriptor using multifractal analysis in multi-orientation wavelet pyramid,"Based on multifractal analysis in wavelet pyramids of texture images, a new texture descriptor is proposed in this paper that implicitly combines information from both spatial and frequency domains. Beyond the traditional wavelet transform, a multi-oriented wavelet leader pyramid is used in our approach that robustly encodes the multi-scale information of texture edgels. Moreover, the resulting texture model shows empirically a strong power law relationship for nature textures, which can be characterized well by multifractal analysis. Combined with a statistics on affine invariant local patches, our proposed texture descriptor is robust to scale and rotation changes, more general geometrical transforms and illumination variations. In addition, the proposed texture descriptor is computationally efficient since it does not require many expensive processing steps, e.g., texton generation and cross-bin comparisons, which are often used by existing methods. As an application, the proposed descriptor is applied to texture classification and the experimental results on several public texture datasets verified the accuracy and efficiency of our descriptor.",
A Comprehensive Diagnosis Methodology for Complex Hybrid Systems: A Case Study on Spacecraft Power Distribution Systems,"The application of model-based diagnosis schemes to real systems introduces many significant challenges, such as building accurate system models for heterogeneous systems with complex behaviors, dealing with noisy measurements and disturbances, and producing valuable results in a timely manner with limited information and computational resources. The Advanced Diagnostics and Prognostics Testbed (ADAPT), which was deployed at the NASA Ames Research Center, is a representative spacecraft electrical power distribution system that embodies a number of these challenges. ADAPT contains a large number of interconnected components, and a set of circuit breakers and relays that enable a number of distinct power distribution configurations. The system includes electrical dc and ac loads, mechanical subsystems (such as motors), and fluid systems (such as pumps). The system components are susceptible to different types of faults, i.e., unexpected changes in parameter values, discrete faults in switching elements, and sensor faults. This paper presents Hybrid Transcend, which is a comprehensive model-based diagnosis scheme to address these challenges. The scheme uses the hybrid bond graph modeling language to systematically develop computational models and algorithms for hybrid state estimation, robust fault detection, and efficient fault isolation. The computational methods are implemented as a suite of software tools that enable diagnostic analysis and testing through simulation, diagnosability studies, and deployment on the experimental testbed. Simulation and experimental results demonstrate the effectiveness of the methodology.","Space vehicles,
Power distribution,
Circuit faults,
Computational modeling,
Power system modeling,
Software testing,
Circuit testing,
System testing,
NASA,
Integrated circuit interconnections"
On the Aggregatability of Router Forwarding Tables,"The rapid growth of global routing tables has raised concerns among many Internet Service Providers. The most immediate concern regarding routing scalability is the size of the Forwarding Information Base (FIB), which seems to be growing at a faster pace than router hardware can support. This paper focuses on one potential solution to this problem - FIB aggregation, i.e., aggregating FIB entries without affecting the forwarding paths taken by data traffic. Compared with alternative solutions to the routing scalability problem, FIB aggregation is particularly appealing because it is a purely local software optimization limited within a router, requiring no changes to routing protocols or router hardware. To understand the feasibility of using FIB aggregation to extend router lifetime, we present several FIB aggregation algorithms and evaluate their performance using routing tables and updates from tens of networks. We find that FIB aggregation can reduce the FIB table size by as much as 70% with small computational overhead. We also show that the computational overhead can be controlled through various mechanisms.","Scalability,
Costs,
Hardware,
Routing protocols,
Computer science,
Algorithm design and analysis,
Communications Society,
Web and internet services,
Energy consumption,
Telecommunication traffic"
It's Time to Eat! Using Mobile Games to Promote Healthy Eating,"It's never been more important to teach youth the importance of healthy eating habits. Time to Eat, a mobile-phone-based game, motivates children to practice healthy eating habits by letting them care for a virtual pet. Players send the pet photos of the food they consume throughout the day; the food's healthiness determines the game's outcome. An examination of the game's design provides insight into the potential of deploying health games on mobile phones.","Positron emission tomography,
Pediatrics,
Mobile handsets"
Thickness Reduction and Performance Enhancement of Steerable Square Loop Antenna Using Hybrid High Impedance Surface,"In order to reduce the thickness of a steerable beam square loop antenna, the effects of combining it with various periodic high impedance surfaces (HISs) are investigated. When a via-less HIS is used, the radiation pattern has high side lobes, which are shown to be due to surface waves propagating in the HIS lattice. Using a HIS with vias between the plates and ground removes the surface waves, but the beam is distorted due to strong coupling between the HIS's vias and the antenna element. Consequently a hybrid HIS is designed. This uses a via-less lattice beneath the loop, with vias at the edge of the HIS to suppress surface wave propagation. Consequently, a square loop antenna with four feeds on a hybrid HIS substrate is proposed for beam steering applications. This antenna has a low-profile with a total thickness of 4.69 mm for a test frequency band of 4.3 GHz to 5.0 GHz. It exhibits a gain of 8.65 dB at the test frequency (4.7 GHz). Compared to the earlier reported steerable square loop antenna, the new antenna achieves a 61% reduction in substrate thickness, a bandwidth enhancement by 150 MHz and an increase in gain by 1.95 dB.",
Efficient occupancy grid computation on the GPU with lidar and radar for road boundary detection,"Accurate maps of the static environment are essential for many advanced driver-assistance systems. A new method for the fast computation of occupancy grid maps with laser range-finders and radar sensors is proposed. The approach utilizes the Graphics Processing Unit to overcome the limitations of classical occupancy grid computation in automotive environments. It is possible to generate highly accurate grid maps in just a few milliseconds without the loss of sensor precision. Moreover, in the case of a lower resolution radar sensor it is shown that it is suitable to apply super-resolution algorithms to achieve the accuracy of a higher resolution laser-scanner. Finally, a novel histogram based approach for road boundary detection with lidar and radar sensors is presented.","Grid computing,
Laser radar,
Roads,
Radar detection,
Graphics,
Automotive engineering,
Path planning,
Target tracking,
Hardware,
Histograms"
Energy-Balanced Dispatch of Mobile Sensors in a Hybrid Wireless Sensor Network,"We consider a hybrid wireless sensor network with static and mobile nodes. Static sensors monitor the environment and report events occurring in the sensing field. Mobile sensors are then dispatched to visit these event locations to conduct more advanced analysis. A big challenge is how to schedule these mobile sensors' traveling paths in an energy-balanced way so that their overall lifetime is maximized. We formulate this problem as a multiround sensor dispatch problem and show it to be NP-complete. Then, we propose a centralized and a distributed heuristics to schedule mobile sensors' traveling paths. Our heuristics allow arbitrary numbers of mobile sensors and event locations in each round and have an energy-balanced concept in mind. The centralized heuristic tries to minimize mobile sensors' moving energy while keeping their energy consumption balanced. The distributed heuristic utilizes a grid structure for event locations to bid for mobile sensors. Through simulations, we show the effectiveness of our schemes. This paper contributes in defining a more general multiround sensor dispatch problem and proposing energy-efficient solutions to it.",
Layered object detection for multi-class segmentation,"We formulate a layered model for object detection and multi-class segmentation. Our system uses the output of a bank of object detectors in order to define shape priors for support masks and then estimates appearance, depth ordering and labeling of pixels in the image. We train our system on the PASCAL segmentation challenge dataset and show good test results with state of the art performance in several categories including segmenting humans.","Object detection,
Image segmentation,
Detectors,
Shape,
Labeling,
Pixel,
Computer science,
System testing,
Humans,
Benchmark testing"
Humanoid robot localization in complex indoor environments,"In this paper, we present a localization method for humanoid robots navigating in arbitrary complex indoor environments using only onboard sensing. Reliable and accurate localization for humanoid robots operating in such environments is a challenging task. First, humanoids typically execute motion commands rather inaccurately and odometry can be estimated only very roughly. Second, the observations of the small and lightweight sensors of most humanoids are seriously affected by noise. Third, since most humanoids walk with a swaying motion and can freely move in the environment, e.g., they are not forced to walk on flat ground only, a 6D torso pose has to be estimated. We apply Monte Carlo localization to globally determine and track a humanoid's 6D pose in a 3D world model, which may contain multiple levels connected by staircases. To achieve a robust localization while walking and climbing stairs, we intergrate 2D laser range measurements as well as attitude data and information from the joint encoders. We present simulated as well as real-word experiments with our humanoid and thoroughly evaluate our approach. As the experiments illustrate, the robot is able to globally localize itself and accurately track its 6D pose over time.","Robot sensing systems,
Variable speed drives,
Navigation,
Filtering,
Torso,
Tracking"
A Review of Noninvasive Ultrasound Image Processing Methods in the Analysis of Carotid Plaque Morphology for the Assessment of Stroke Risk,"Noninvasive ultrasound imaging of carotid plaques allows for the development of plaque-image analysis methods associated with the risk of stroke. This paper presents several plaque-image analysis methods that have been developed over the past years. The paper begins with a review of clinical methods for visual classification that have led to standardized methods for image acquisition, describes methods for image segmentation and denoizing, and provides an overview of the several texture-feature extraction and classification methods that have been applied. We provide a summary of emerging trends in 3-D imaging methods and plaque-motion analysis. Finally, we provide a discussion of the emerging trends and future directions in our concluding remarks.","Ultrasonic imaging,
Image processing,
Image analysis,
Risk analysis,
Morphology,
Image segmentation,
Computer science,
Cardiac disease,
Cardiovascular diseases,
Filtering"
Are all code smells harmful? A study of God Classes and Brain Classes in the evolution of three open source systems,"Code smells are particular patterns in object-oriented systems that are perceived to lead to difficulties in the maintenance of such systems. It is held that to improve maintainability, code smells should be eliminated by refactoring. It is claimed that classes that are involved in certain code smells are liable to be changed more frequently and have more defects than other classes in the code. We investigated the extent to which this claim is true for God Classes and Brain Classes, with and without normalizing the effects with respect to the class size. We analyzed historical data from 7 to 10 years of the development of three open-source software systems. The results show that God and Brain Classes were changed more frequently and contained more defects than other kinds of class. However, when we normalized the measured effects with respect to size, then God and Brain Classes were less subject to change and had fewer defects than other classes. Hence, under the assumption that God and Brain Classes contain on average as much functionality per line of code as other classes, the presence of God and Brain Classes is not necessarily harmful; in fact, such classes may be an efficient way of organizing code.","Data analysis,
Instruments,
FAA,
Software"
Video Analysis in Pan-Tilt-Zoom Camera Networks,"Pan-tilt-zoom (PTZ) cameras are able to dynamically modify their field of view (FOV). This functionality introduces new capabilities to camera networks such as increasing the resolution of moving targets and adapting the sensor coverage. On the other hand, PTZ functionality requires solutions to new challenges such as controlling the PTZ parameters, estimating the ego motion of the cameras, and calibrating the moving cameras.This tutorial provides an overview of the main video processing techniques and the currents trends in this active field of research. Autonomous PTZ cameras mainly aim to detect and track targets with the largest possible resolution. Autonomous PTZ operation is activated once the network detects and identifies an object as sensible target and requires accurate control of the PTZ parameters and coordination among the cameras in the network. Therefore, we present cooperative localization and tracking methods, i.e., multiagentand consensus-based approaches to jointly compute the target's properties such as ground-plane position and velocity. Stereo vision exploiting wide baselines can be used to derive three-dimensional (3-D) target localization. This tutorial further presents different techniques for controlling PTZ camera handoff, configuring the network to dynamically track targets, and optimizing the network configuration to increase coverage probability. It also discusses implementation aspects for these video processing techniques on embedded smart cameras, with a special focus on data access properties.","Cameras,
Feature extraction,
Transforms,
Target tracking,
Smart cameras,
Surveillance"
A new simple model for composite fading channels: Second order statistics and channel capacity,"In this paper, we introduce the most general composite fading distribution to model the envelope and the power of the received signal in such fading channels as millimeter wave (60 GHz or above) fading channels and free-space optical channels, which we term extended generalized-K (EGK) composite fading distribution. We obtain the second-order statistics of the received signal envelope characterized by the EGK composite fading distribution. Expressions for probability density function, cumulative distribution function, level crossing rate and average fade duration, moments, amount of fading and average capacity are derived. Numerical and computer simulation examples validate the accuracy of the presented mathematical analysis.","Shadow mapping,
Wireless communication,
Signal to noise ratio,
Rayleigh channels,
Mathematical model,
Millimeter wave propagation"
Modeling and Compensation of Ripples and Friction in Permanent-Magnet Linear Motor Using a Hysteretic Relay,"The tracking performance of a motion system based on a permanent-magnet linear motor (PMLM) is greatly affected by nonlinearities present, such as force ripples and frictions. Although various identification and compensation schemes haven been reported for the PMLM, to the authors' best knowledge, no direct and unified modeling method for force ripples and friction is available till now. This paper proposes a new method to identify various linear and nonlinear parameters in PMLM, using a hysteretic relay feedback. Dual-input describing functions are imported to leverage on the biased limit cycles generated by even nonlinearities due to force ripple. The explicit formulae, derived from the harmonic balance condition, enable direct computation of model parameters with a minimum number of relay experiments. Simulation results and real-time experiments will be presented to verify the practical appeal of proposed method in precision motion control.","Friction,
Hysteresis,
Relays,
Force feedback,
Limit-cycles,
Motion control,
Reluctance motors,
Automatic control,
Computational modeling,
Force control"
On exploiting transient contact patterns for data forwarding in Delay Tolerant Networks,"Effective data forwarding in Delay Tolerant Networks (DTNs) is challenging, due to the low node density, unpredictable node mobility and lack of global information in such networks. Most of the current data forwarding schemes choose the nodes with the best cumulative capability of contacting others as relays to carry and forward data, but these nodes may not be the best relay choices within a short time period, due to the heterogeneity of the transient node contact patterns. In this paper, we propose a novel approach to improve the performance of data forwarding in DTNs by exploiting the transient node contact patterns. We formulate the transient node contact patterns based on experimental studies of realistic DTN traces, and propose appropriate forwarding metrics based on these patterns to improve the effectiveness of data forwarding decision. When applied to various data forwarding strategies, our proposed forwarding metrics achieve much better performance compared to existing schemes with similar forwarding cost.","Transient analysis,
Measurement,
Peer to peer computing,
Relays,
Mobile communication,
Time factors,
IEEE 802.11 Standards"
Gigahertz ambipolar frequency multiplier based on CVD graphene,"Ambipolar transport in graphene offers great opportunities for novel device and circuit applications. This paper discusses the RF performance of CVD grown graphene transistors for the first time. Then, a new graphene ambipolar frequency multiplier that can operate at 1.4 GHz with extremely high output spectral purity (> 90%) is demonstrated. These GHz graphene frequency multipliers, made from wafer-scale graphene synthesis and fabrication processes, demonstrate the great potential of graphene-based ambipolar devices for RF and mixed-signal applications.","Radio frequency,
Frequency measurement,
Charge carrier processes,
Power generation,
Logic gates,
Copper,
Gain"
Physiological-Model-Constrained Noninvasive Reconstruction of Volumetric Myocardial Transmembrane Potentials,"Personalized noninvasive imaging of subject-specific cardiac electrical activity can guide and improve preventive diagnosis and treatment of cardiac arrhythmia. Compared to body surface potential (BSP) recordings and electrophysiological information reconstructed on heart surfaces, volumetric myocardial transmembrane potential (TMP) dynamics is of greater clinical importance in exhibiting arrhythmic details and arrythmogenic substrates inside the myocardium. This paper presents a physiological-model-constrained statistical framework to reconstruct volumetric TMP dynamics inside the 3-D myocardium from noninvasive BSP recordings. General knowledge of volumetric TMP activity is incorporated through the modeling of cardiac electrophysiological system, and is used to constrain TMP reconstruction. This physiological system is reformulated into a stochastic state-space representation to take into account model and data uncertainties, and nonlinear data assimilation is developed to estimate volumetric myocardial TMP dynamics from personal BSP data. Robustness of the presented framework to practical model and data errors is evaluated. Comparison of epicardial potential reconstructions with classical regularization-based approaches is performed on computational phantom regarding right bundle branch blocks. Further, phantom experiments on intramural focal activities and an initial real-data study on postmyocardial infarction demonstrate the potential of the framework in reconstructing local arrhythmic details and identifying arrhythmogenic substrates inside the myocardium.","Myocardium,
Image reconstruction,
Surface reconstruction,
Surface treatment,
Nonlinear dynamical systems,
Imaging phantoms,
Heart,
Electrophysiology,
Stochastic systems,
Uncertainty"
Real-Time Simplex Growing Algorithms for Hyperspectral Endmember Extraction,"The simplex growing algorithm (SGA) was recently developed as an alternative to the N-finder algorithm (N-FINDR) and shown to be a promising endmember extraction technique. This paper further extends the SGA to a versatile real-time (RT) processing algorithm, referred to as RT SGA, which can effectively address the following four major issues arising in the practical implementation for N-FINDR: (1) use of random initial endmembers which causes inconsistent final results; (2) high computational complexity which results from an exhaustive search for finding all endmembers simultaneously; (3) requirement of dimensionality reduction because of large data volumes; and (4) lack of RT capability. In addition to the aforementioned advantages, the proposed RT SGA can also be implemented by various criteria in endmember extraction other than the maximum simplex volume.","Hyperspectral imaging,
Data mining,
Algorithm design and analysis,
Chaos,
Computational complexity,
Least squares methods,
Error analysis,
Support vector machines,
Councils,
Remote sensing"
The Edge-Driven Dual-Bootstrap Iterative Closest Point Algorithm for Registration of Multimodal Fluorescein Angiogram Sequence,"Motivated by the need for multimodal image registration in ophthalmology, this paper introduces an algorithm which is tailored to jointly align in a common reference space all the images in a complete fluorescein angiogram (FA) sequence, which contains both red-free (RF) and FA images. Our work is inspired by Generalized Dual-Bootstrap Iterative Closest Point (GDB-ICP), which rank-orders Lowe keypoint matches and refines the transformation, going from local and low-order to global and higher-order model, computed from each keypoint match in succession. Albeit GDB-ICP has been shown to be robust in registering images taken under different lighting conditions, the performance is not satisfactory for image pairs with substantial, nonlinear intensity differences. Our algorithm, named Edge-Driven DB-ICP, targeting the least reliable component of GDB-ICP, modifies generation of keypoint matches for initialization by extracting the Lowe keypoints from the gradient magnitude image and enriching the keypoint descriptor with global-shape context using the edge points. Our dataset consists of 60 randomly-selected pathological sequences, each on average having up to two RF and 13 FA images. Edge-Driven DB-ICP successfully registered 92.4% of all pairs, and 81.1% multimodal pairs, whereas GDB-ICP registered 80.1% and 40.1%, respectively. For the joint registration of all images in a sequence, Edge-Driven DB-ICP succeeded in 59 sequences, which is a 23% improvement over GDB-ICP.","Iterative closest point algorithm,
Radio frequency,
Iterative algorithms,
Retina,
Robustness,
Pathology,
Computer science,
Retinal vessels,
Image registration,
Biomedical imaging"
E-SmallTalker: A Distributed Mobile System for Social Networking in Physical Proximity,"Small talk is an important social lubricant that helps people, especially strangers, initiate conversations and make friends with each other in physical proximity. However, due to difficulties in quickly identifying significant topics of common interest, real-world small talk tends to be superficial. The mass popularity of mobile phones can help improve the effectiveness of small talk. In this paper, we present E-SmallTalker, a distributed mobile communications system that facilitates social networking in physical proximity. It automatically discovers and suggests topics such as common interests for more significant conversations. We build on Bluetooth Service Discovery Protocol (SDP) to exchange potential topics by customizing service attributes to publish nonservice-related information without establishing a connection. We propose a novel iterative Bloom filter (IBF) protocol that encodes topics to fit in SDP attributes and achieves a low false positive rate. We have implemented the system in Java ME for ease of deployment. Our experiments on real-world phones show that it is efficient enough at the system level to facilitate social interactions among strangers in physical proximity. To the best of our knowledge, E-SmallTalker is the first distributed mobile system to achieve the same purpose.","Social network services,
Mobile handsets,
Web server,
Protocols,
Distributed computing,
Mobile computing,
Computer science,
Milling machines,
Lubricants,
Mobile communication"
"Context-Preserving, Dynamic Word Cloud Visualization","The proposed method uses context-preserving, dynamic word clouds to illustrate content evolution. It generates a sequence of word clouds in which related words are grouped together. This sequence is then coupled with a trend chart that summarizes content changes so that users can better explore large collections of documents.",
Adaptive beaconing for delay-sensitive and congestion-aware traffic information systems,"We present Adaptive Traffic Beacon (ATB), a fully-decentralized car-to-X protocol built around the central ideas of delay sensitivity and congestion awareness. From previous research findings, we see that centralized solutions, VANETs, and broadcasting based approaches each show benefits and drawbacks depending on traffic density, penetration, network utilization, and other parameters; intelligent transportation systems are therefore tuned for specific settings. In order to overcome this limitation, we developed a broadcast-based solution that has been designed to carefully use only the remaining capacity of the wireless channel. Thus, it will not influence other applications using the same radio network. ATB is adaptive in two dimensions: First, the beacon interval is adapted dynamically according to the channel quality and the importance of messages in the local knowledge base, and, secondly, the protocol can dynamically make use of available infrastructure elements. Simulation experiments demonstrate that ATB performs well in a broad range of settings. It maintains a non-congested wireless channel to prevent collisions during the data exchange.","Vehicles,
Protocols,
Wireless communication,
Measurement,
Knowledge based systems,
Roads,
Signal to noise ratio"
Multi-class object localization by combining local contextual interactions,"Recent work in object localization has shown that the use of contextual cues can greatly improve accuracy over models that use appearance features alone. Although many of these models have successfully explored different types of contextual sources, they only consider one type of contextual interaction (e.g., pixel, region or object level interactions), leaving open questions about the true potential contribution of context. Furthermore, contributions across object classes and over appearance features still remain unknown. In this work, we introduce a novel model for multi-class object localization that incorporates different levels of contextual interactions. We study contextual interactions at pixel, region and object level by using three different sources of context: semantic, boundary support and contextual neighborhoods. Our framework learns a single similarity metric from multiple kernels, combining pixel and region interactions with appearance features, and then uses a conditional random field to incorporate object level interactions. We perform experiments on two challenging image databases: MSRC and PASCAL VOC 2007. Experimental results show that our model outperforms current state-of-the-art contextual frameworks and reveals individual contributions for each contextual interaction level, as well as the importance of each type of feature in object localization.","Context modeling,
Kernel,
Layout,
Nearest neighbor searches,
Image classification,
Computer science,
Image databases,
Face detection,
Horses,
Computer vision"
A Label Field Fusion Bayesian Model and Its Penalized Maximum Rand Estimator for Image Segmentation,"This paper presents a novel segmentation approach based on a Markov random field (MRF) fusion model which aims at combining several segmentation results associated with simpler clustering models in order to achieve a more reliable and accurate segmentation result. The proposed fusion model is derived from the recently introduced probabilistic Rand measure for comparing one segmentation result to one or more manual segmentations of the same image. This non-parametric measure allows us to easily derive an appealing fusion model of label fields, easily expressed as a Gibbs distribution, or as a nonstationary MRF model defined on a complete graph. Concretely, this Gibbs energy model encodes the set of binary constraints, in terms of pairs of pixel labels, provided by each segmentation results to be fused. Combined with a prior distribution, this energy-based Gibbs model also allows for definition of an interesting penalized maximum probabilistic rand estimator with which the fusion of simple, quickly estimated, segmentation results appears as an interesting alternative to complex segmentation models existing in the literature. This fusion framework has been successfully applied on the Berkeley image database. The experiments reported in this paper demonstrate that the proposed method is efficient in terms of visual evaluation and quantitative performance measures and performs well compared to the best existing state-of-the-art segmentation methods recently proposed in the literature.",
"Automated 3D Motion Tracking Using Gabor Filter Bank, Robust Point Matching, and Deformable Models","Tagged magnetic resonance imaging (tagged MRI or tMRI) provides a means of directly and noninvasively displaying the internal motion of the myocardium. Reconstruction of the motion field is needed to quantify important clinical information, e.g., the myocardial strain, and detect regional heart functional loss. In this paper, we present a three-step method for this task. First, we use a Gabor filter bank to detect and locate tag intersections in the image frames, based on local phase analysis. Next, we use an improved version of the robust point matching (RPM) method to sparsely track the motion of the myocardium, by establishing a transformation function and a one-to-one correspondence between grid tag intersections in different image frames. In particular, the RPM helps to minimize the impact on the motion tracking result of (1) through-plane motion and (2) relatively large deformation and/or relatively small tag spacing. In the final step, a meshless deformable model is initialized using the transformation function computed by RPM. The model refines the motion tracking and generates a dense displacement map, by deforming under the influence of image information, and is constrained by the displacement magnitude to retain its geometric structure. The 2D displacement maps in short and long axis image planes can be combined to drive a 3D deformable model, using the moving least square method, constrained by the minimization of the residual error at tag intersections. The method has been tested on a numerical phantom, as well as on in vivo heart data from normal volunteers and heart disease patients. The experimental results show that the new method has a good performance on both synthetic and real data. Furthermore, the method has been used in an initial clinical study to assess the differences in myocardial strain distributions between heart disease (left ventricular hypertrophy) patients and the normal control group. The final results show that the proposed method is capable of separating patients from healthy individuals. In addition, the method detects and makes possible quantification of local abnormalities in the myocardium strain distribution, which is critical for quantitative analysis of patients' clinical conditions. This motion tracking approach can improve the throughput and reliability of quantitative strain analysis of heart disease patients, and has the potential for further clinical applications.","Tracking,
Gabor filters,
Robustness,
Deformable models,
Myocardium,
Cardiac disease,
Capacitive sensors,
Magnetic resonance imaging,
Heart,
Image reconstruction"
Full-Reference Video Quality Metric for Fully Scalable and Mobile SVC Content,"Universal Multimedia Access (UMA) aims at enabling a straightforward consumption of multimedia content in heterogeneous usage environments. These usage environments may range from mobile devices in a wireless network to high-end desktop computers with wired network connectivity. Scalable video content can be used to deal with the restrictions and capabilities of diverse usage environments. However, in order to optimally tailor scalable video content along the temporal, spatial, or perceptual quality axis, a metric is needed that reliably models subjective video quality. The major contribution of this paper is the development of a novel full-reference quality metric for scalable video bit streams that are compliant with the H.264/AVC Scalable Video Coding (SVC) standard. The scalable video bit streams are intended to be used in mobile usage environments (e.g., adaptive video streaming to mobile devices). The proposed quality metric allows modeling the temporal, spatial, and perceptual quality characteristics of SVC-compliant bit streams by taking into account several properties of the compressed bit streams. These properties include the temporal and spatial variance of the video content, the frame rate, the spatial resolution, and PSNR values. An extensive number of subjective experiments have been conducted to construct and validate our quality metric. Experimental results show that the average correlation coefficient for the video sequences tested is as high as 0.95 (compared to a value of 0.60 when only using the traditional PSNR quality metric). The proposed quality metric also shows a performance that is a uniformly high for video sequences with different temporal and spatial characteristics.",
Automatic Change Detection in Very High Resolution Images With Pulse-Coupled Neural Networks,"A novel approach based on pulse-coupled neural networks (PCNNs) for image change detection is presented. PCNNs are based on the implementation of the mechanisms underlying the visual cortex of small mammals, and, with respect to more traditional NNs architectures, such as multilayer perceptron, own interesting advantages. In particular, they are unsupervised and context sensitive. This latter property may be particularly useful when very high resolution images are considered as, in this case, an object analysis might be more suitable than a pixel-based one. The qualitative and more quantitative results are reported. The performance of the algorithm has been evaluated on a pair of QuickBird images taken over the test area of Tor Vergata University, Rome.",
Rateless Coding on Experimental Temporally Correlated FSO Channels,"We present a demonstration of two error-correction coding schemes that can successfully operate on a free-space optical (FSO) communication channel subject to atmospheric turbulence. The codes (a puntured Low-density parity-check code and a Raptor code) operate by continuously adapting the information rate to accommodate the varying channel conditions. Because these coding schemes require the use of a feedback channel, we evaluate the bandwidth cost incurred. The evaluation of the codes is performed offline and uses experimental optical signals recorded from an FSO link. We analyze the temporal characteristics of the experimental channels and compare the performance of the codes for different bit rates to asses the effect of temporal correlation and imperfect channel state information.","Optical feedback,
Communication channels,
Parity check codes,
Information rates,
Bandwidth,
Costs,
Performance evaluation,
Optical recording,
Information analysis,
Performance analysis"
Electromechanical Wave Imaging of Normal and Ischemic Hearts In Vivo,"Electromechanical wave imaging (EWI) has recently been introduced as a noninvasive, ultrasound-based imaging modality, which could map the electrical activation of the heart in various echocardiographic planes in mice, dogs, and humans in vivo. By acquiring radio-frequency (RF) frames at very high frame rates (390-520 Hz), the onset of small, localized, transient deformations resulting from the electrical activation of the heart, i.e., generating the electromechanical wave (EMW), can be mapped. The correlation between the EMW and the electrical activation speed and pacing scheme has previously been reported. In this study, we pursue the development of EWI using both displacements and strains and analysis of the EMW properties in dogs in vivo for early detection of ischemia. EWI was performed in normal and ischemic open-chest dogs during sinus rhythm. Ischemia of increasing severity was obtained by gradually obstructing the left-anterior descending (LAD) coronary artery flow. We also introduce the novel method of motion-matching that achieves the reconstruction of the full EWI cine-loop at very high frame rates even when the ECG may be irregular or unavailable. Incremental displacements were previously used by our group to map the EMW. This paper focuses on the associated incremental strains, which facilitate the interpretation of the EMW by relating it directly to contraction. Moreover, we define the onset of the EMW as the time, at which the incremental strains change sign after the onset of the QRS complex of the ECG. Based on this definition, isochronal representations of the EMW were generated using a semi-automated method. The isochronal representation of the EMW during sinus rhythm was reproducible and shown similar to electrical activation maps previously reported in the literature. After segmentation using a contour-tracking method, the two- and four-chamber views were imaged and displayed in bi-plane views, allowing a 3-D interpretation of the EMW. EWI was shown to be sensitive to the presence of intermediate ischemia. EWI localized the ischemic region when the LAD flow was obstructed at 60% and beyond and was capable of mapping the increase of the ischemic region size as the LAD occlusion level increased. In conclusion, the activation maps and wave patterns obtained with EWI were similar to the electrical equivalents previously reported in the literature. Moreover, EWI was found to be sensitive enough to detect and map intermediate ischemia. Those results indicate that EWI could be used to assess the conduction properties of the myocardium, and detect its ischemic onset and disease progression entirely noninvasively.",
A package for OpenCL based heterogeneous computing on clusters with many GPU devices,"Heterogeneous systems provide new opportunities to increase the performance of parallel applications on clusters with CPU and GPU architectures. Currently, applications that utilize GPU devices run their device-executable code on local devices in their respective hosting-nodes. This paper presents a package for running OpenMP, C++ and unmodified OpenCL applications on clusters with many GPU devices. This Many GPUs Package (MGP) includes an implementation of the OpenCL specifications and extensions of the OpenMP API that allow applications on one hosting-node to transparently utilize cluster-wide devices (CPUs and/or GPUs). MGP provides means for reducing the complexity of programming and running parallel applications on clusters, including scheduling based on task dependencies and buffer management. The paper presents MGP and the performance of its internals.","Kernel,
Graphics processing unit,
Libraries,
Context,
Performance evaluation,
Central Processing Unit,
Complexity theory"
Robust Optimization Utilizing the Second-Order Design Sensitivity Information,"This paper presents an effective methodology for robust optimization of electromagnetic devices. To achieve the goal, the method improves the robustness of the minimum of the objective function chosen as a design solution by minimizing the second-order sensitivity information, called a gradient index (GI) and defined by a function of gradients of performance functions with respect to uncertain variables. The constraint feasibility is also enhanced by adding a GI corresponding to the constraint value. The distinctive feature of the method is that it requires neither statistical information on design variables nor calculation of the performance reliability during the robust optimization process. The validity of the proposed method is tested with the TEAM Workshop Problem 22.","Robustness,
Design optimization,
Optimization methods,
Computer science,
Electromagnetic devices,
Testing,
Constraint optimization,
Sensitivity analysis,
Manufacturing,
Material properties"
Tensor Transmission-Line Metamaterials,"Transmission-line (TL) metamaterials possessing effective material parameters that are diagonal in the Cartesian basis have been previously studied. In this paper, TL metamaterials with arbitrary full tensors are introduced and analyzed. An approximate tensor analysis of the proposed metamaterials is first developed. Bloch analysis is then used to verify the approximate analysis and derive exact dispersion equations and impedance relations. Finally, simulation results are presented that validate the analysis and show the utility of this new class of metamaterials. The ability to design tensor metamaterials such as these is crucial to the practical implementation of novel devices derived through transformational optics/electromagnetics.",
Feature extraction of partial discharge signals using the wavelet packet transform and classification with a probabilistic neural network,"Partial discharge (PD) classification in power cable accessories and high voltage equipment in general is essential in evaluating the severity of the damage in the insulation. In this article, the PD classification was realised as a two-fold process. Firstly, measurements taken from a high-frequency current transformer (HFCT) sensor were represented as features by means of a transformation to the classifier and secondly, the probabilistic neural network (PNN) classifier itself was capable of effectively recognising features coming from different types of discharges. The feature that was used as a fingerprint for PD characterisation was extracted from the moments of the probability density function (PDF) of the wavelet coefficients at various scales, obtained through the wavelet packets transformation. The PNN classifier was used to classify the PDs and assess the suitability of this feature vector in PD classification. Four types of artificial PDs were created in a high voltage laboratory, namely corona discharge in air, floating discharge in oil, internal discharge in oil and surface discharge in air, at different applied voltages, and were used to train the PNN algorithm. The results obtained here (97.49, 91.9, 100 and 99.8% for the corona, the floating, the internal and the surface discharges, respectively) are very encouraging for the use of PNN in PD classification with this particular feature vector. This article suggests a feature extraction and classification algorithm for PD classification, which when combined together reduced the dimensionality of the feature space to a manageable dimension, and achieved very high levels of classification.",
Stability Analysis in Graphene Nanoribbon Interconnects,"We present a Nyquist stability criterion based on transmission line modeling for graphene nanoribbon (GNR) interconnects. This is the first instance that such an analysis has been presented for GNR, so far. In this analysis, the dependence of the degree of relative stability for multilayer GNR (MLGNR) interconnects on the geometry of each ribbon has been acquired. It is shown that, increasing the length and width, MLGNR interconnects become more stable.","Integrated circuit interconnections,
Stability criteria,
Thermal stability,
Graphene,
Integrated circuit modeling,
Circuit stability"
A CMOS Class-E Power Amplifier With Voltage Stress Relief and Enhanced Efficiency,"This paper proposes a class-E power amplifier (PA) with double-resonance circuit to reduce voltage stress on CMOS transistors. The voltage waveform applied to the CMOS transistor is shaped by harmonic control and the transistors are relieved from breakdowns. A negative capacitance is also implemented for efficiency enhancement, compensating for surplus capacitance from parasitic components on the drain node. Thus, nominal class-E operation is restored and high efficiency is achieved. We present a cascode differential class-E RF PA that is fabricated using a 0.13-¿ m CMOS technology that delivers 31.5-dBm output power with 54% drain efficiency and 51% power-added efficiency at 1.8 GHz.","Power amplifiers,
Stress,
Breakdown voltage,
Parasitic capacitance,
CMOS technology,
Circuits,
Shape control,
Voltage control,
Radio frequency,
Power generation"
A Robust Uniaxial Force Sensor for Minimally Invasive Surgery,"This paper presents a novel miniature uniaxial force sensor for use within a beating heart during mitral valve annuloplasty. The sensor measures 5.5 mm in diameter and 12 mm in length and provides a hollow core to pass instrumentation. A soft elastomer flexure design maintains a waterproof seal. Fiber optic transduction eliminates electrical circuitry within the heart, and acetal components minimize ultrasound-imaging artifacts. Calibration uses a nonlinear viscoelastic method, and in vitro tests demonstrate a 0-4-N force range with rms errors of 0.13 N (< 3.2%). In vivo tests provide the first endocardial measurements of tissue-minimally invasive surgery instrument interaction forces in a beating heart.","Minimally invasive surgery,
Robustness,
Force sensors,
Ultrasonic variables measurement,
Circuit testing,
Force measurement,
Heart valves,
Length measurement,
Instruments,
Seals"
Distributed Sensor Perception via Sparse Representation,"In this paper, sensor network scenarios are considered where the underlying signals of interest exhibit a degree of sparsity, which means that in an appropriate basis, they can be expressed in terms of a small number of nonzero coefficients. Following the emerging theory of compressive sensing (CS), an overall architecture is considered where the sensors acquire potentially noisy projections of the data, and the underlying sparsity is exploited to recover useful information about the signals of interest, which will be referred to as distributed sensor perception. First, we discuss the question of which projections of the data should be acquired, and how many of them. Then, we discuss how to take advantage of possible joint sparsity of the signals acquired by multiple sensors, and show how this can further improve the inference of the events from the sensor network. Two practical sensor applications are demonstrated, namely, distributed wearable action recognition using low-power motion sensors and distributed object recognition using high-power camera sensors. Experimental data support the utility of the CS framework in distributed sensor perception.","Wireless sensor networks,
Wearable sensors,
Intelligent sensors,
Acoustic sensors,
Cameras,
Wireless communication,
Temperature sensors,
Mobile communication,
Humans,
Surveillance"
Using a swarm of self-propelled natural microrobots in the form of flagellated bacteria to perform complex micro-assembly tasks,"Many science fiction novels have envisioned swarms of artificial microrobots capable of performing complex collective tasks. Unfortunately, today's technological constraints have prevented such powerful concept to be a reality when considering artificial microrobots. In this paper, we show that a swarm of computer-controlled flagellated Magnetotactic Bacteria (MTB) acting as natural microrobots of approximately 1 to 2 micrometers in diameter can perform many of the same complex collective tasks envisioned with these futuristic self-propelled artificial microrobots. To prove the concept, magnetotaxis-based control has been used to coordinate a swarm made of thousands of these self-propelled natural microrobots to build in a collective effort, a miniature version of an ancient Egyptian pyramid.","Microorganisms,
Propulsion,
Joining processes,
Nanoparticles,
Humans,
Micromotors,
Magnetic resonance imaging,
Microassembly,
Biomedical engineering,
Robotics and automation"
Assessing Student Learning in a Virtual Laboratory Environment,"Laboratory experience is a key factor in technical and scientific education. Virtual laboratories have been proposed to reduce cost and simplify maintenance of lab facilities while still providing students with access to real systems. It is important to determine if such virtual labs are still effective for student learning. In the assessment of a graduate computer networks course, the author quantifies the amount of learning that is observed in lectures and labs. The results not only show that learning indeed occurs during lab sessions, but almost equally as much (45.9%) as in lectures (54.1%). Also, it is observed that even students who have prior experience in networking benefit from virtual labs.","Laboratories,
Computer networks,
Education,
Hardware,
Software,
Data mining,
Probability density function"
Adaptive Multiple-Frame Image Super-Resolution Based on U-Curve,"Image super-resolution (SR) reconstruction has been a hot research topic in recent years. This technique allows the recovery of a high-resolution (HR) image from several low-resolution (LR) images that are noisy, blurred and down-sampled. Among the available reconstruction frameworks, the maximum a posteriori (MAP) model is widely used. In this model, the regularization parameter plays an important role. If the parameter is too small, the noise will not be effectively restrained; conversely, the reconstruction result will become blurry. Therefore, how to adaptively select the optimal regularization parameter has been widely discussed. In this paper, we propose an adaptive MAP reconstruction method based upon a U-curve. To determine the regularization parameter, a U-curve function is first constructed using the data fidelity term and prior term, and then the left maximum curvature point of the curve is regarded as the optimal parameter. The proposed algorithm is tested on both simulated and actual data. Experimental results show the effectiveness and robustness of this method, both in its visual effects and in quantitative terms.",
AR-REHAB: An Augmented Reality Framework for Poststroke-Patient Rehabilitation,"This paper proposes a novel approach based on augmented-reality (AR) technologies that can increase a stroke-patient's involvement in the rehabilitation process. The approach takes advantage of virtual-reality technologies and provides natural-force interaction with the daily environment by adopting a tangible-object concept. In our framework, the patient manipulates during the treatment session a tangible object that is tracked to measure her/his performance without the direct supervision of an occupational therapist. We called this framework AR-based REHABilitation. In this paper, we introduce the core architecture of the framework and its subsystems that provide more convenience to patients and therapists. We also present two exercises, a shelf exercise and a cup exercise, as examples and perform preliminary usability study. In addition, we introduce assessment measurements such as task-completion time, compactness of task, and speed of hand movement by capturing the patients' hand movements with the tangible object.",
Design of Fractional Order Digital Differentiator Using Radial Basis Function,"In this paper, the design of fractional order digital differentiator is investigated. First, the radial basis function interpolation method is described. Then, the non-integer delay sample estimation of discrete-time sequence is derived by using the radial basis function interpolation approach. Next, the Grünwald-Letnikov derivative and non-integer delay sample estimation are applied to obtain the transfer function of fractional order digital differentiator. Finally, the applications in digital image sharpening and parameter estimation of fractional noise process are studied to demonstrate the usefulness of this new design approach.","Interpolation,
Delay estimation,
Optical signal processing,
Fractional calculus,
Shape,
Fractals,
Design methodology,
Transfer functions,
Digital images,
Parameter estimation"
Optimal Sets of Frequency Hopping Sequences From Linear Cyclic Codes,"In communication systems, frequency hopping spread spectrum and direct sequence spread spectrum are two main spread coding technologies. Frequency hopping sequences are used in FH-CDMA systems. In this paper, an earlier idea of constructing optimal sets of frequency hopping sequences is further investigated. New optimal parameters of sets of frequency hopping sequences are obtained with subcodes of the Reed-Solomon codes. Optimal sets of frequency hopping sequences are constructed with a class of irreducible cyclic codes. As a byproduct, the weight distribution of a subclass of irreducible cyclic codes is determined.","Spread spectrum communication,
Communication systems,
Computer science,
Mobile communication,
Packet radio networks,
Radio transmitters,
Radio control,
Communication system control,
Frequency synchronization,
Throughput"
Field-Based Validation of a Tactile Navigation Device,"In this paper, we present three field-based evaluations of a tactile land navigation system. In Experiment 1, we transition from a laboratory setting to rugged terrain used to train US Army soldier land navigation. Navigation in this challenging terrain requires careful attention to one's surroundings. Participants navigated 3 waypoints along 600 meters through heavily wooded terrain, using 1) map and compass, 2) standard alpha-numeric handheld GPS device, and 3) the tactile GPS system, while also responding to radio requests for information. Experiment 2 used the same challenging terrain during night operations, where participants must also search for live and silhouette targets, using 1) handheld GPS device, 2) head-mounted map-based GPS, and 3) the tactile GPS system. In addition to navigating, participants searched for silhouette and live (human) targets. Experiment 3 had participants navigate with 1) a commercial GPS arrow display, 2) the tactile GPS system, and 3) both together. We conclude that tactile navigation displays can be used in strenuous outdoor environments and can outperform visual displays under conditions of high cognitive and visual workload.","Global Positioning System,
Laboratories,
Radio navigation,
Computer displays,
Aircraft navigation,
Enterprise resource planning,
Military computing,
Torso,
Humans,
Computer applications"
Integrated Fiber-Wireless (FiWi) Access Networks Supporting Inter-ONU Communications,"Integrated fiber-wireless (FiWi) access networks provide a powerful platform to improve the throughput of peer-to-peer communication by enabling traffic to be sent from the source wireless client to an ingress optical network unit (ONU), then to the egress ONU close to the destination wireless client, and finally delivered to the destination wireless client. Such wireless-optical-wireless communication mode introduced by FiWi access networks can reduce the interference in wireless subnetwork, thus improving network throughput. With the support for direct inter-ONU communication in the optical subnetwork, throughput of peer-to-peer communication in a FiWi access network can be further improved. In this paper, we propose a novel hybrid wavelength division multiplexed/time division multiplexed passive optical network (WDM/TDM PON) architecture supporting direct inter-ONU communication, a corresponding decentralized dynamic bandwidth allocation (DBA) protocol for inter-ONU communication and an algorithm to dynamically select egress ONU. The complexity of the proposed architecture is analyzed and compared with other alternatives, and the efficiency of the proposed system is validated by the simulations.","Optical fiber communication,
Optical network units,
Throughput,
Passive optical networks,
Optical fiber networks,
Peer to peer computing,
Wavelength division multiplexing,
Time division multiplexing,
Telecommunication traffic,
Interference"
A framework for the evaluation of specification miners based on finite state machines,"Software maintenance tasks, such as testing and program understanding, can benefit from formal specifications that describe how a program should use an API. Recently, there has been increasing interest in specification miners that automatically extract finite state specifications of method ordering constraints from existing software. However, comparing different mining approaches is difficult, because no common ground to evaluate the effectiveness of specification miners has been established yet. We present a framework for evaluating to which extent specification miners find valid finite state descriptions of API usage constraints. The framework helps in creating reference specifications and includes metrics to compare mined specifications to the reference specifications. The metrics are tailored for evaluating specification miners and account for imprecision and incompleteness in mined specifications. We use the framework to compare the effectiveness of three mining approaches and to show their respective benefits.","Measurement,
Data mining,
Libraries,
Instruments,
Java,
Focusing"
Automated Requirements Traceability: The Study of Human Analysts,"The requirements traceability matrix (RTM) supports many software engineering and software verification and validation (V&V) activities such as change impact analysis, reverse engineering, reuse, and regression testing. The generation of RTMs is tedious and error-prone, though, thus RTMs are often not generated or maintained. Automated techniques have been developed to generate candidate RTMs with some success. When using RTMs to support the V&V of mission-or safety-critical systems, however, a human analyst must vet the candidate RTMs. The focus thus becomes the quality of the final RTM. This paper investigate show human analysts perform when vetting candidate RTMs. Specifically, a study was undertaken at two universities and had 26 participants analyze RTMs of varying accuracy for a Java code formatter program. The study found that humans tend to move their candidate RTM toward the line that represents recall = precision. Participants who examined RTMs with low recall and low precision drastically improved both.","Humans,
Accuracy,
Training,
Information retrieval,
Computer science,
Software,
Large scale integration"
Registration of 4D Cardiac CT Sequences Under Trajectory Constraints With Multichannel Diffeomorphic Demons,"We propose a framework for the nonlinear spatiotemporal registration of 4D time-series of images based on the Diffeomorphic Demons (DD) algorithm. In this framework, the 4D spatiotemporal registration is decoupled into a 4D temporal registration, defined as mapping physiological states, and a 4D spatial registration, defined as mapping trajectories of physical points. Our contribution focuses more specifically on the 4D spatial registration that should be consistent over time as opposed to 3D registration that solely aims at mapping homologous points at a given time-point. First, we estimate in each sequence the motion displacement field, which is a dense representation of the point trajectories we want to register. Then, we perform simultaneously 3D registrations of corresponding time-points with the constraints to map the same physical points over time called the trajectory constraints. Under these constraints, we show that the 4D spatial registration can be formulated as a multichannel registration of 3D images. To solve it, we propose a novel version of the Diffeomorphic Demons (DD) algorithm extended to vector-valued 3D images, the Multichannel Diffeomorphic Demons (MDD). For evaluation, this framework is applied to the registration of 4D cardiac computed tomography (CT) sequences and compared to other standard methods with real patient data and synthetic data simulated from a physiologically realistic electromechanical cardiac model. Results show that the trajectory constraints act as a temporal regularization consistent with motion whereas the multichannel registration acts as a spatial regularization. Finally, using these trajectory constraints with multichannel registration yields the best compromise between registration accuracy, temporal and spatial smoothness, and computation times. A prospective example of application is also presented with the spatiotemporal registration of 4D cardiac CT sequences of the same patient before and after radiofrequency ablation (RFA) in case of atrial fibrillation (AF). The intersequence spatial transformations over a cardiac cycle allow to analyze and quantify the regression of left ventricular hypertrophy and its impact on the cardiac function.",
"A survey of simulators, emulators and testbeds for wireless sensor networks","Simulators, emulators and testbeds are invaluable tools for performance evaluation of algorithms and protocols in wireless sensor networks (WSNs). It is extremely difficult to choose an appropriate tool for performance testing without the horizontal and vertical analysis of existing tools. This paper presents a survey of thirty five performance evaluation tools for WSNs. Unlike most other studies, tools were selected based on their popularity, support for WSNs, active maintenance and the help available. On the horizontal dimension, prominent competitors at each stage were selected. For vertical analysis, tools for simulation, emulation and testbeds were categorized accordingly. We believe that this survey will aid researchers, application and tool developers while selecting an appropriate tool for their implementation. We have highlighted an open research issue to have an integrated tool that supports modeling, simulation, emulation and testbed implementation for algorithm validation, performance evaluation and proof-of-concept implementation in WSNs.","Wireless sensor networks,
Analytical models,
Atmospheric measurements,
Particle measurements,
Area measurement,
Humidity measurement,
Manuals"
RFID: From Supply Chains to Sensor Nets,"The next generation internet will be the internet of things (and not just of computing devices like PCs, PDAs); this is presumed to be enabled by integrating simple computing plus communications capabilities into common objects of everyday use. Radio-frequency identification (RFID) is a compelling technology for creation of such pervasive sensor networks due to its potential for ubiquitous, low-cost/low-maintenance use. However, the current drivers for RFID deployment emphasize supply chain management using passive tags, implying that RFID sensor nets require advances beyond the components and system designs aimed at supply chain applications. This work provides a glimpse of how this may be achieved.",
"Analysis and Design of a
k
-Winners-Take-All Model With a Single State Variable and the Heaviside Step Activation Function","This paper presents a k-winners-take-all (kWTA) neural network with a single state variable and a hard-limiting activation function. First, following several kWTA problem formulations, related existing kWTA networks are reviewed. Then, the kWTA model model with a single state variable and a Heaviside step activation function is described and its global stability and finite-time convergence are proven with derived upper and lower bounds. In addition, the initial state estimation and a discrete-time version of the kWTA model are discussed. Furthermore, two selected applications to parallel sorting and rank-order filtering based on the kWTA model are discussed. Finally, simulation results show the effectiveness and performance of the kWTA model.","Image analysis,
Linear programming,
Quadratic programming,
Vectors,
Neurons,
Differential equations,
Neural networks,
Piecewise linear techniques,
Recurrent neural networks"
Learning appearance in virtual scenarios for pedestrian detection,"Detecting pedestrians in images is a key functionality to avoid vehicle-to-pedestrian collisions. The most promising detectors rely on appearance-based pedestrian classifiers trained with labelled samples. This paper addresses the following question: can a pedestrian appearance model learnt in virtual scenarios work successfully for pedestrian detection in real images? (Fig. 1). Our experiments suggest a positive answer, which is a new and relevant conclusion for research in pedestrian detection. More specifically, we record training sequences in virtual scenarios and then appearance-based pedestrian classifiers are learnt using HOG and linear SVM. We test such classifiers in a publicly available dataset provided by Daimler AG for pedestrian detection benchmarking. This dataset contains real world images acquired from a moving car. The obtained result is compared with the one given by a classifier learnt using samples coming from real images. The comparison reveals that, although virtual samples were not specially selected, both virtual and real based training give rise to classifiers of similar performance.","Optical scattering,
Light scattering,
X-ray scattering,
Biomedical optical imaging,
Equations,
Skin,
Dairy products,
Biomedical imaging,
Tomography,
Optical materials"
Scene Reconstruction and Visualization From Community Photo Collections,"There are billions of photographs on the Internet, representing an extremely large, rich, and nearly comprehensive visual record of virtually every famous place on Earth. Unfortunately, these massive community photo collections are almost completely unstructured, making it very difficult to use them for applications such as the virtual exploration of our world. Over the past several years, advances in computer vision have made it possible to automatically reconstruct 3-D geometry - including camera positions and scene models - from these large, diverse photo collections. Once the geometry is known, we can recover higher level information from the spatial distribution of photos, such as the most common viewpoints and paths through the scene. This paper reviews recent progress on these challenging computer vision problems, and describes how we can use the recovered structure to turn community photo collections into immersive, interactive 3-D experiences.","Layout,
Visualization,
Computer vision,
Internet,
Earth,
Application software,
Computational geometry,
Cameras,
Solid modeling,
Information geometry"
Examining the adverse effects of limb position on pattern recognition based myoelectric control,"Pattern recognition of myoelectric signals for the control of prosthetic devices has been widely reported and debated. A large portion of the literature focuses on offline classification accuracy of pre-recorded signals. Historically, however, there has been a semantic gap between research findings and a clinically viable implementation. Recently, renewed focus on prosthetics research has pushed the field to provide more clinically relevant outcomes. One way to work towards this goal is to examine the differences between research and clinical results. The constrained nature in which offline training and test data is often collected compared to the dynamic nature of prosthetic use is just one example. In this work, we demonstrate that variations in limb position after training can have a substantial impact on the robustness of myoelectric pattern recognition.",
Deep auto-encoder neural networks in reinforcement learning,"This paper discusses the effectiveness of deep auto-encoder neural networks in visual reinforcement learning (RL) tasks. We propose a framework for combining the training of deep auto-encoders (for learning compact feature spaces) with recently-proposed batch-mode RL algorithms (for learning policies). An emphasis is put on the data-efficiency of this combination and on studying the properties of the feature spaces automatically constructed by the deep auto-encoders. These feature spaces are empirically shown to adequately resemble existing similarities and spatial relations between observations and allow to learn useful policies. We propose several methods for improving the topology of the feature spaces making use of task-dependent information. Finally, we present first results on successfully learning good control policies directly on synthesized and real images.","Training,
Approximation methods,
Noise measurement,
Visualization,
Image reconstruction,
Principal component analysis,
Feature extraction"
Deterministic rendezvous scheme in multichannel access networks,"In multichannel access networks, nodes must establish a link on a channel before data transmission begins. To find such a channel, either a centralised or a distributed approach may be employed. Presented is a distributed channel rendezvous scheme. The scheme determines the order, in which two nodes visit available channels to rendezvous within 2N+1 slots, where N is the number of channels and a slot is the minimum interval required to establish a link between any pair of nodes that are in a common channel. More notably, the scheme can be implemented without slot synchronisation which is hard to accomplish in a distributed manner.","telecommunication channels,
data communication,
radio access networks"
Microwatt embedded processor platform for medical system-on-chip applications,"A medical system-on-chip (SoC) that integrates an ARM Cortex-M3 processor is presented. Ultra-low power operation is achieved via 0.5–1.0 V operation, a 28 fW/bit fully differential subthreshold 6T SRAM, a 90%-efficient DC-DC converter, and a 100-nJ fast Fourier transform (FFT) accelerator to reduce processor workload. Using a combination of novel circuit design, system architecture, and SoC implementation, the first sub-microwatt per channel electroencephalograph (EEG) seizure detection is demonstrated.","Random access memory,
Computer architecture,
System-on-a-chip,
Converters,
Electroencephalography,
Low power electronics,
Microprocessors"
Cost-effective integration of three-dimensional (3D) ICs emphasizing testing cost analysis,"Three-dimensional (3D) ICs promise to overcome barriers in interconnect scaling by leveraging fast, dense inter-die vias, thereby offering benefits of improved performance, higher memory bandwidth, smaller form factors, and heterogeneous integration. However, when deciding to adopt this emerging technology as a mainstream design approach, designers must consider the cost of 3D integration. IC testing is a key factor that affects the final product cost, and it could be a major portion of the total IC cost. In 3D IC design, various testing strategies and different integration methods could affect the final product cost dramatically, and the interaction with other cost factors could result in various trade-offs. This paper develops a comprehensive and parameterized testing cost model for 3D IC integration, and analyzes the trade-offs associated with testing strategies and testing circuit overheads. With the proposed testing cost model, designers can explore the most cost-effective integration and testing strategies for 3D IC chips.","Three dimensional displays,
Testing,
Stacking,
Integrated circuit modeling,
Through-silicon vias,
Solid modeling"
Gaussian Process Regression for Estimating Chlorophyll Concentration in Subsurface Waters From Remote Sensing Data,"In this letter, we explore the effectiveness of a novel regression method in the context of the estimation of biophysical parameters from remotely sensed imagery as an alternative to state-of-the-art regression methods like those based on artificial neural networks and support vector machines. This method, called Gaussian process (GP) regression, formulates the learning of the regressor within a Bayesian framework, where the regression model is derived by assuming the model variables follow a Gaussian prior distribution encoding the prior knowledge about the output function. One of its interesting properties, which gives it a key advantage over state-of-the-art regression methods, is the possibility to tune the free parameters of the model in an automatic way. Experiments were focused on the problem of estimating chlorophyll concentration in subsurface waters. The achieved results suggest that the GP regression method is very promising from both viewpoints of estimation accuracy and free parameter tuning. Moreover, it handles particularly well the problem of limited availability of training samples, typically encountered in biophysical parameter estimation applications.","Gaussian processes,
Remote sensing,
Parameter estimation,
Bayesian methods,
Remote monitoring,
State estimation,
Artificial neural networks,
Support vector machines,
Machine learning,
Encoding"
Highway mobility and vehicular ad-hoc networks in ns-3,"The study of vehicular ad-hoc networks (VANETs) requires efficient and accurate simulation tools. As the mobility of vehicles and driver behavior can be affected by network messages, these tools must include a vehicle mobility model integrated with a quality network simulator. We present the first implementation of a well-known vehicle mobility model to ns-3, the next generation of the popular ns-2 networking simulator. Vehicle mobility and network communication are integrated through events. User-created event handlers can send network messages or alter vehicle mobility each time a network message is received and each time vehicle mobility is updated by the model. To aid in creating simulations, we have implemented a straight highway model that manages vehicle mobility, while allowing for various user customizations. We show that the results of our implementation of the mobility model matches that of the model's author and provide and example of using our implementation in ns-3.","Vehicles,
Road transportation,
Mathematical model,
Driver circuits,
Acceleration,
Safety,
Computational modeling"
Detecting image region duplication using SIFT features,"Region duplication is a common form of image manipulation where part of an image is pasted to another location to conceal undesirable contents. Most existing methods to detect region duplication are based on finding exact copies of pixel blocks, which cannot handle cases when a region is scaled or rotated before pasted to a new location. In this work, we describe a new detection method based on matching image SIFT features [6]. The robustness of the SIFT features with regards to local transforms renders this method able to detect general region duplications with efficient computation. The effectiveness of this method is demonstrated with experimental results, both qualitatively and quantitatively in terms of the detection accuracy and the false positive rate.","Digital images,
Pixel,
Noise robustness,
Forensics,
Computer science,
Educational institutions,
Rendering (computer graphics),
Digital cameras,
Internet,
Information resources"
Code-Centric RFID System Based on Software Agent Intelligence,Radiofrequency identification (RFID) technology could play a vital role in future smart-environment applications. This code-centric RFID system uses software-agent based intelligence to achieve faster service responses.,
Disturbance and Friction Compensations in Hard Disk Drives Using Neural Networks,"In this paper, we show that by using two adaptive neural networks (NNs), each of which is tailored for a specific task, the tracking performance of the hard-disk-drive (HDD) actuator can be significantly improved. The first NN utilizes accelerometer signal to detect external vibrations and compensates for its effect on HDD position via feedforward action. The second NN is designed to compensate for pivot friction. The appealing advantage of the NN compensators is that the design does not involve any information on the plant, sensor, disturbance dynamics, and friction model. The stability of the proposed scheme is analyzed by the Lyapunov criterion. Experimental results show that the tracking performance of the HDDs can be improved significantly with the use of the NN compensators as compared to the case without compensation.",
Probabilistic Topic Models,"In this article, we review probabilistic topic models: graphical models that can be used to summarize a large collection of documents with a smaller number of distributions over words. Those distributions are called ""topics"" because, when fit to data, they capture the salient themes that run through the collection. We describe both finite-dimensional parametric topic models and their Bayesian nonparametric counterparts, which are based on the hierarchical Dirichlet process (HDP). We discuss two extensions of topic models to time-series data-one that lets the topics slowly change over time and one that lets the assumed prevalence of the topics change. Finally, we illustrate the application of topic models to nontext data, summarizing some recent research results in image analysis.","Analytical models,
Data models,
Graphical models,
Computational modeling,
Bayesian methods,
Markov processes"
Positioning with OFDM signals for the next- generation GNSS,"Instead of spread spectrum signals used for positioning in current global navigation satellite systems (GNSS), this paper presents a novel positioning method using OFDM signals for the next-generation GNSS. In contrast to the existing positioning methods with OFDM signals based on timing synchronization or super resolution algorithms, the proposed scheme uses the property of the OFDM signal itself in the frequency domain with respect to transmission delay, resulting in the accurate time of arrival (TOA) estimation. Computer simulations verify that the positioning accuracy of the proposed algorithm with bearable complexity can reach the Cramer-Rao lower bound (CRLB) in the range of medium to high signal-to-noise ratio (SNR). The accuracy achievable is in the order of centimeters, higher than that of the state-of-the- art positioning methods using OFDM signals in the literature.","OFDM,
Signal generators,
Satellite navigation systems,
Delay estimation,
Spread spectrum communication,
Global Positioning System,
Timing,
Frequency synchronization,
Signal resolution,
Frequency domain analysis"
An Ultralow-Power Receiver for Wireless Sensor Networks,"An ultralow-power super-regenerative receiver for BFSK modulated signals has been designed and fabricated in a standard 0.18-μm CMOS process. The use of BFSK modulation allows the receiver to operate at higher data rates and also gives an approximate 3-dB SNR performance increase over the more traditional OOK modulation. A fast calibration scheme and the absence of an external inductor make it ideal for ultralow-power sensor networks. A power consumption of 215 μW from a 0.65-V supply and an area of 0.55 mm2 make it ideal for highly integrated energy harvesting sensor nodes. At 2 Mb/s, the receiver consumes 0.18 nJ/b, making it the lowest energy integrated super-regenerative receiver to date.",
An Approach to Solve Group-Decision-Making Problems With Ordinal Interval Numbers,"The ordinal interval number is a form of uncertain preference information in group decision making (GDM), while it is seldom discussed in the existing research. This paper investigates how the ranking order of alternatives is determined based on preference information of ordinal interval numbers in GDM problems. When ranking a large quantity of ordinal interval numbers, the efficiency and accuracy of the ranking process are critical. A new approach is proposed to rank alternatives using ordinal interval numbers when every ranking ordinal in an ordinal interval number is thought to be uniformly and independently distributed in its interval. First, we give the definition of possibility degree on comparing two ordinal interval numbers and the related theory analysis. Then, to rank alternatives, by comparing multiple ordinal interval numbers, a collective expectation possibility degree matrix on pairwise comparisons of alternatives is built, and an optimization model based on this matrix is constructed. Furthermore, an algorithm is also presented to rank alternatives by solving the model. Finally, two examples are used to illustrate the use of the proposed approach.","Decision making,
Information analysis,
Technological innovation,
Engineering management,
Aggregates,
Linear programming"
Towards the holy grail: Combining system dynamics and discrete-event simulation in healthcare,"The idea of combining discrete-event simulation and system dynamics has been a topic of debate in the operations research community for over a decade. Many authors have considered the potential benefits of such an approach from a methodological or practical standpoint. However, despite numerous examples of models with both discrete and continuous parameters in the computer science and engineering literature, nobody in the OR field has yet succeeded in developing a genuinely hybrid approach which truly integrates the philosophical approach and technical merits of both DES and SD in a single model. In this paper we consider some of the reasons for this and describe two practical healthcare examples of combined DES/SD models, which nevertheless fall short of the “holy grail” which has been so widely discussed in the literature over the past decade.","Biological system modeling,
Computational modeling,
Medical services,
Software,
Adaptation model,
Data models,
Communities"
Reinforcement learning-based multi-agent system for network traffic signal control,"A challenging application of artificial intelligence systems involves the scheduling of traffic signals in multi-intersection vehicular networks. This paper introduces a novel use of a multi-agent system and reinforcement learning (RL) framework to obtain an efficient traffic signal control policy. The latter is aimed at minimising the average delay, congestion and likelihood of intersection cross-blocking. A five-intersection traffic network has been studied in which each intersection is governed by an autonomous intelligent agent. Two types of agents, a central agent and an outbound agent, were employed. The outbound agents schedule traffic signals by following the longest-queue-first (LQF) algorithm, which has been proved to guarantee stability and fairness, and collaborate with the central agent by providing it local traffic statistics. The central agent learns a value function driven by its local and neighbours' traffic conditions. The novel methodology proposed here utilises the Q-Learning algorithm with a feedforward neural network for value function approximation. Experimental results clearly demonstrate the advantages of multi-agent RL-based control over LQF governed isolated single-intersection control, thus paving the way for efficient distributed traffic signal control in complex settings.",
Schottky-Drain Technology for AlGaN/GaN High-Electron Mobility Transistors,"In this letter, we demonstrate 27% improvement in the buffer breakdown voltage of AlGaN/GaN high-electron mobility transistors (HEMTs) grown on Si substrate by using a new Schottky-drain contact technology. Schottky-drain AlGaN/GaN HEMTs with a total 2-¿m-thick GaN buffer showed a three-terminal breakdown voltage of more than 700 V, while conventional AlGaN/GaN HEMTs of the same geometry showed a maximum breakdown voltage below 600 V. The improvement of the breakdown voltage has been associated with the planar contact morphology and lack of metal spikes in the Schottky-drain metallization.",
An Adaptive Greedy Algorithm With Application to Nonlinear Communications,"Greedy algorithms form an essential tool for compressed sensing. However, their inherent batch mode discourages their use in time-varying environments due to significant complexity and storage requirements. In this paper two existing powerful greedy schemes developed in the literature are converted into an adaptive algorithm which is applied to estimation of a class of nonlinear communication systems. Performance is assessed via computer simulations on a variety of linear and nonlinear channels; all confirm significant improvements over conventional methods.","Greedy algorithms,
Signal processing algorithms,
Matching pursuit algorithms,
Compressed sensing,
Adaptive algorithm,
Computer simulation,
Pursuit algorithms,
Minimization methods,
Least squares approximation,
Adaptive estimation"
Crawling Online Social Graphs,"Extensive research has been conducted on top of online social networks (OSNs), while little attention has been paid to the data collection process. Due to the large scale of OSNs and their privacy control policies, a partial data set is often used for analysis. The data set analyzed is decided by many factors including the choice of seeds, node selection algorithms, and the sample size. These factors may introduce biases and further contaminate or even skew the results. To evaluate the impact of different factors, this paper examines the OSN graph crawling problem, where the nodes are OSN users and the edges are the links (or relationship) among these users. More specifically, by looking at various factors in the crawling process, the following problems are addressed in this paper:* Efficiency: How fast different crawlers discover nodes/links;* Sensitivity: How different OSNs and the number of protected users affect crawlers;* Bias: How major graph properties are skewed.To the best of our knowledge, our simulations on four real world online social graphs provide the first in-depth empirical answers to these questions.","Crawlers,
Social network services,
Protection,
Computer science,
Data privacy,
Large-scale systems,
Data analysis,
Algorithm design and analysis,
Sampling methods,
Web and internet services"
Electrical centrality measures for electric power grid vulnerability analysis,Centrality measures are used in network science to rank the relative importance of nodes and edges of a graph. Here we define new measures of centrality for power grid structure that are based on its functionality. We show that the relative importance analysis based on centrality in graph theory can be generalized to power grid network with its electrical parameters taken into account. In the paper we experiment with the proposed electrical centrality measures on the NYISO-2935 system and the IEEE 300-bus system. We analyze the centrality distribution in order to identify important nodes or branches in the system which are of essential importance in terms of system vulnerability. We also present and discuss a number of interesting discoveries regarding the importance rank of power grid nodes and branches.,"Power grids,
Correlation,
Admittance,
Laplace equations,
Topology,
Network topology,
Power measurement"
FPGA-GPU architecture for kernel SVM pedestrian detection,"We present a real-time multi-sensor architecture for video-based pedestrian detection used within a road side unit for intersection assistance. The entire system is implemented on available PC hardware, combining a frame grabber board with embedded FPGA and a graphics card into a powerful processing network. Giving classification performance top priority, we use HOG descriptors with a Gaussian kernel support vector machine. In order to achieve real-time performance, we propose a hardware architecture that incorporates FPGA-based feature extraction and GPU-based classification. The FPGA-GPU pipeline is managed by a multi-core CPU that further performs sensor data fusion. Evaluation on the INRIA benchmark database and an experimental study on a real-world intersection using multi-spectral hypothesis generation confirm state-of-the-art classification and real-time performance.","Kernel,
Support vector machines,
Support vector machine classification,
Hardware,
Roads,
Field programmable gate arrays,
Graphics,
Feature extraction,
Pipelines,
Sensor fusion"
A Radius Adaptive K-Best Decoder With Early Termination: Algorithm and VLSI Architecture,This paper presents a novel algorithm and architecture for K-Best decoding that combines the benefits of radius shrinking commonly associated with sphere decoding and the architectural benefits associated with K-Best decoding approaches. The proposed algorithm requires much smaller K and possesses the advantages of branch pruning and adaptively updated pruning threshold while still achieving near-optimum performance. The algorithm examines a much smaller subset of points as compared to the K-Best decoder. The VLSI architecture of the decoder is based on a pipelined sorter-free scheme. The proposed K-Best decoder is designed to support a 4 × 4 64-QAM system and is synthesized with 65-nm technology at 158-MHz clock frequency and 1-V supply. The synthesized decoder can support a throughput of 285.8 Mb/s at 25-dB signal-to-noise ratio with an area of 210 kGE at 12.8-mW power consumption.,"Very large scale integration,
Maximum likelihood decoding,
Throughput,
MIMO,
Signal synthesis,
Signal to noise ratio,
Bit error rate,
Degradation,
Clocks,
Frequency synthesizers"
Numerical Study of Lightly Doped Drain and Source Carbon Nanotube Field Effect Transistors,"In this paper, we investigate the transport properties of carbon nanotube field-effect transistors (CNTFETs), with a nonequilibrium Green's function (NEGF) method. Tunneling leakage currents with respect to gate voltages are known effects for MOSFET-like CNTFETs (MOSCNTs). To minimize this phenomenon, we have proposed a structure with a simple modification of the MOSCNT by using lightly doped regions between the intrinsic channel and the highly doped source and drain regions, which we call the ¿lightly doped drain and source CNTFET (LDDS-CNTFET).¿ Simulations have shown that LDDS-CNTFET characteristics are related to the lightly doped region concentration. In comparison with an MOSCNT and a linearly doped CNTFET (LD-CNTFET), an LDDS-CNTFET with appropriately doped lightly doped drain and source regions has demonstrated a larger on current (I on), a larger on -off ratio (I on/I off), a superior ambipolar characteristic, a shorter delay time, and also a smaller power-delay product. Furthermore, our results show that the channel length for an LDDS-CNTFET is shorter than that for an LD-CNTFET having the same off-state characteristics. Finally, the effect of the unavoidable Schottky barriers at the interface of the heavily doped source/drain regions and their metal electrodes has been taken into account. Simulations have demonstrated that these Schottky barriers have almost the same deteriorating effects on the characteristics for both LD-CNTFETs and LDDS-CNTFETs. Hence, all discussions regarding the superiority of the proposed structure are also valid in presence of the Schottky barriers.",
Multi-provider service negotiation and contracting in network virtualization,"Network virtualization environment (VNE) affords great business flexibility to the customers and the providers as multiple providers can jointly support a customer's virtual network. Under the current network model, a group of Infrastructure Providers (InPs) peer with each other to provide a packaged deal. Such a business arrangement is not customer-driven, does not promote fair market competition and does not ensure cost minimization. Furthermore, the on-demand nature of virtual networks requires efficient and automated service negotiation and contracting. In this paper, we present V-Mart. To the InPs, V-Mart offers an environment to participate in a faithful and fair competition over the VN resources; and to the SPs, it offers a customer-driven virtual resource partitioning and contracting engine. V-Mart uses a two-stage Vickrey auction model that is strategy-proof, flexible to diverse InP pricing models, and functions over heterogenous multi-commodity market that characterizes the NVE. Through analysis and simulation we show the flexibility and effectiveness of V-Mart.","Indium phosphide,
Pricing,
Costs,
Engines,
Packaging,
Service oriented architecture,
Peer to peer computing,
Routing protocols,
Resource virtualization,
Computer science"
Memristor-based multilevel memory,A method to utilize the memristor as a multilevel memory has been proposed. There are several roadblocks in the practical use of memristors for multilevel memory. A difficulty comes from the nonlinearity in the φ vs. q curve which makes it difficult to determine the proper pulse width for desired resistance values. Another one comes from the property of the memristor which integrates any kind of signals including noise that appeared at the memristor and causes memristors to be perturbed from their original values. The proposed method enables the memristor to be used as multilevel memory using a reference resistance array by forcing the memristor to stick at a set of predetermined fixed reference resistance values. We propose the write-in (programming) circuit and the readout/restoration circuit which share the information storing technique using the reference resistance array.,
MCALab: Reproducible Research in Signal and Image Decomposition and Inpainting,"Morphological component analysis of signals and images has far-reaching applications in science and technology, but some consider it problematic and even intractable. Reproducible research is essential to give MCA a firm scientific foundation. Researchers developed MCALab to demonstrate key MCA concepts and make them available to interested researchers.","Image decomposition,
Mathematics,
Reproducibility of results,
Signal processing,
Gold,
Pixel,
Image analysis,
Signal analysis,
Heart,
Chemical technology"
Weighted Spectral Distribution for Internet Topology Analysis: Theory and Applications,"Comparing graphs to determine the level of underlying structural similarity between them is a widely encountered problem in computer science. It is particularly relevant to the study of Internet topologies, such as the generation of synthetic topologies to represent the Internet's AS topology. We derive a new metric that enables exactly such a structural comparison: the weighted spectral distribution. We then apply this metric to three aspects of the study of the Internet's AS topology. i) We use it to quantify the effect of changing the mixing properties of a simple synthetic network generator. ii) We use this quantitative understanding to examine the evolution of the Internet's AS topology over approximately seven years, finding that the distinction between the Internet core and periphery has blurred over time. iii) We use the metric to derive optimal parameterizations of several widely used AS topology generators with respect to a large-scale measurement of the real AS topology.","Internet,
Network topology,
IP networks,
Laboratories,
Application software,
Computer science,
Large-scale systems,
Graph theory,
Computer vision,
Speech processing"
Estimating the progress of MapReduce pipelines,"In parallel query-processing environments, accurate, time-oriented progress indicators could provide much utility given that inter- and intra-query execution times can have high variance. However, none of the techniques used by existing tools or available in the literature provide non-trivial progress estimation for parallel queries. In this paper, we introduce Parallax, the first such indicator. While several parallel data processing systems exist, the work in this paper targets environments where queries consist of a series of MapReduce jobs. Parallax builds on recently-developed techniques for estimating the progress of single-site SQL queries, but focuses on the challenges related to parallelism and variable execution speeds. We have implemented our estimator in the Pig system and demonstrate its performance through experiments with the PigMix benchmark and other queries running in a real, small-scale cluster.",
"NVLab, a Networking Virtual Web-Based Laboratory that Implements Virtualization and Virtual Network Computing Technologies","In various ICT courses, it is necessary to establish a proper space where each learner has access to a set of network devices with which he/she can build and test networks with different structures and components. This will enable the learners to practice working on multiple devices as in the case of real world context, and freely apply modifications to the network structure to solve any issue that may arise with the current scenario. While on-campus facilities are designed to meet this criterion, current Web-based laboratories either have fixed network designs, or do not offer a number of real devices to work on. Taking a step forward toward building a Web-based laboratory, we used open source Virtualization and Virtual Network Computing technologies in NVLab, a system that offers the learners tools to draw, configure, test, and troubleshoot network designs using real Operating System instances running in the virtual mode on a host machine. The functionality of the system has been experimented by introducing a case study exercise to a group of remote learners as part of Computer Networks course. Evaluating the participants' advancement was done by comparing their answers to a level test prior and after completing the exercise. The evaluation showed that the learners achieved better results in the level test after completing the exercise and were able to use the system efficiently.","Data mining,
Distance learning,
Decision support systems,
Reactive power,
Computer science education"
Virtual Point-to-Point Connections for NoCs,"In this paper, we aim to improve the performance and power metrics of packet-switched network-on-chips (NoCs) and benefits from the scalability and resource utilization advantages of NoCs and superior communication performance of point-to-point dedicated links. The proposed method sets up the virtual point-to-point (VIP) connections over one virtual channel (which bypasses the entire router pipeline) at each physical channel of the NoC. We present two schemes for constructing such VIP circuits. In the first scheme, the circuits are constructed for an application based on its task-graph at design time. The second scheme addresses constructing the connections at run-time using a light-weight setup network. It involves monitoring the NoC traffic in order to detect heavy communication flows and setting up a VIP connection for them using a run-time circuit construction mechanism. The proposed mechanism is compared to a traditional packet-switched NoC and some modern switching mechanisms and the results show a significant reduction in the network power and latency over the other considered NoCs.","Network-on-a-chip,
Circuits,
Runtime,
Scalability,
Resource management,
Pipelines,
Monitoring,
Telecommunication traffic,
Packet switching,
Communication switching"
Clustering disjoint subspaces via sparse representation,"Given a set of data points drawn from multiple low-dimensional linear subspaces of a high-dimensional space, we consider the problem of clustering these points according to the subspaces they belong to. Our approach exploits the fact that each data point can be written as a sparse linear combination of all the other points. When the subspaces are independent, the sparse coefficients can be found by solving a linear program. However, when the subspaces are disjoint, but not independent, the problem becomes more challenging. In this paper, we derive theoretical bounds relating the principal angles between the subspaces and the distribution of the data points across all the subspaces under which the coefficients are guaranteed to be sparse. The clustering of the data is then easily obtained from the sparse coefficients. We illustrate the validity of our results through simulation experiments.",
Robust Transceiver Design for K-Pairs Quasi-Static MIMO Interference Channels via Semi-Definite Relaxation,"In this paper, we propose a robust transceiver design for the K-pair quasi-static MIMO interference channel. Each transmitter is equipped with M antennas, each receiver is equipped with N antennas, and the kth transmitter sends Lk independent data streams to the desired receiver. In the literature, there exist a variety of theoretically promising transceiver designs for the interference channel such as interference alignment-based schemes, which have feasibility and practical limitations. In order to address practical system issues and requirements, we consider a transceiver design that enforces robustness against imperfect channel state information (CSI) as well as fair performance among the users in the interference channel. Specifically, we formulate the transceiver design as an optimization problem to maximize the worst-case signal-to-interference-plus-noise ratio among all users. We devise a low complexity iterative algorithm based on alternative optimization and semi-definite relaxation techniques. Numerical results verify the advantages of incorporating into transceiver design for the interference channel important practical issues such as CSI uncertainty and fairness performance.","Signal to noise ratio,
Optimization,
Decorrelation,
Transceivers,
Interference channels,
MIMO"
User-Based Collaborative-Filtering Recommendation Algorithms on Hadoop,"Collaborative Filtering(CF) algorithms are widely used in a lot of recommender systems, however, the computational complexity of CF is high thus hinder their use in large scale systems. In this paper, we implement user-based CF algorithm on a cloud computing platform, namely Hadoop, to solve the scalability problem of CF. Experimental results show that a simple method that partition users into groups according to two basic principles, i.e., tidy arrangement of mapper number to overcome the initiation of mapper and partition task equally such that all processors finish task at the same time, can achieve linear speedup.",
"Nanoindentation Methods to Measure Viscoelastic Properties of Single Cells Using Sharp, Flat, and Buckling Tips Inside ESEM","In this paper, methods to measure viscoelastic properties of time-dependent materials are proposed using sharp, flat, and buckling tips inside an environmental SEM. Single W303 yeast cells were employed in this study. Each of the tips was used to indent single cells in a nanoindentation test. Three loading histories were used: 1) a ramp loading history, in which a sharp indenter was used; 2) a step loading history, in which a flat indenter was implemented; and 3) a fast unloading history, in which a buckling nanoneedle was applied. Analysis of the viscoelastic properties of single cells was performed for each of the loading histories by choosing an appropriate theory between the correspondence principle and the functional equation. Results from each of the tests show good agreement, from which strong conclusion can be drawn.",
Stimulation of the Human Lumbar Spinal Cord With Implanted and Surface Electrodes: A Computer Simulation Study,"Human lumbar spinal cord networks controlling stepping and standing can be activated through posterior root stimulation using implanted electrodes. A new stimulation method utilizing surface electrodes has been shown to excite lumbar posterior root fibers similarly as with implants, an unexpected finding considering the distance to these target neurons. In the present study we apply computer modeling to compare the depolarization of posterior root fibers by both stimulation techniques. We further examine the potential for additional direct activation of motoneurons within the anterior roots. Using an implant, action potentials are initiated in the posterior root fibers at their entry into the spinal cord or along the longitudinal portions of the fiber trajectories, depending on the cathode position. For transcutaneous stimulation low threshold sites of the same fibers are identified at their exits from the spinal canal in addition to their spinal cord entries. In these exit regions anterior root fibers can also be activated. The simulation results provide a biophysical explanation for the electrophysiological findings of lower limb muscle responses induced by posterior root stimulation. Efficient excitation of afferent spinal cord structures with a simple noninvasive method can become a promising modality in the rehabilitation of people with motor disorders.","Humans,
Spinal cord,
Electrodes,
Computer simulation,
Irrigation,
Scientific computing,
Implants,
Electrical stimulation,
Postal services,
Permission"
Neuron geometry extraction by perceptual grouping in ssTEM images,"In the field of neuroanatomy, automatic segmentation of electron microscopy images is becoming one of the main limiting factors in getting new insights into the functional structure of the brain. We propose a novel framework for the segmentation of thin elongated structures like membranes in a neuroanatomy setting. The probability output of a random forest classifier is used in a regular cost function, which enforces gap completion via perceptual grouping constraints. The global solution is efficiently found by graph cut optimization. We demonstrate substantial qualitative and quantitative improvement over state-of the art segmentations on two considerably different stacks of ssTEM images as well as in segmentations of streets in satellite imagery. We demonstrate that the superior performance of our method yields fully automatic 3D reconstructions of dendrites from ssTEM data.","Neurons,
Geometry,
Image segmentation,
Biomembranes,
Image reconstruction,
Transmission electron microscopy,
Electron microscopy,
Animals,
Protocols,
Cost function"
Standby Leakage Power Reduction Technique for Nanoscale CMOS VLSI Systems,"In this paper, a novel low-power design technique is proposed to minimize the standby leakage power in nanoscale CMOS very large scale integration (VLSI) systems by generating the adaptive optimal reverse body-bias voltage. The adaptive optimal body-bias voltage is generated from the proposed leakage monitoring circuit, which compares the subthreshold current (I SUB) and the band-to-band tunneling (BTBT) current (I BTBT). The proposed circuit was simulated in HSPICE using 32-nm bulk CMOS technology and evaluated using ISCAS85 benchmark circuits at different operating temperatures (ranging from 25°C to 100°C). Analysis of the results shows a maximum of 551 and 1491 times leakage power reduction at 25°C and 100°C, respectively, on a circuit with 546 gates. The proposed approach demonstrates that the optimal body bias reduces a considerable amount of standby leakage power dissipation in nanoscale CMOS integrated circuits. In this approach, the temperature and supply voltage variations are compensated by the proposed feedback loop.","CMOS technology,
Very large scale integration,
Voltage,
Power generation,
Standby generators,
Monitoring,
Subthreshold current,
Tunneling,
Circuit simulation,
Temperature distribution"
An Object-Based Visual Attention Model for Robotic Applications,"By extending integrated competition hypothesis, this paper presents an object-based visual attention model, which selects one object of interest using low-dimensional features, resulting that visual perception starts from a fast attentional selection procedure. The proposed attention model involves seven modules: learning of object representations stored in a long-term memory (LTM), preattentive processing, top-down biasing, bottom-up competition, mediation between top-down and bottom-up ways, generation of saliency maps, and perceptual completion processing. It works in two phases: learning phase and attending phase. In the learning phase, the corresponding object representation is trained statistically when one object is attended. A dual-coding object representation consisting of local and global codings is proposed. Intensity, color, and orientation features are used to build the local coding, and a contour feature is employed to constitute the global coding. In the attending phase, the model preattentively segments the visual field into discrete proto-objects using Gestalt rules at first. If a task-specific object is given, the model recalls the corresponding representation from LTM and deduces the task-relevant feature(s) to evaluate top-down biases. The mediation between automatic bottom-up competition and conscious top-down biasing is then performed to yield a location-based saliency map. By combination of location-based saliency within each proto-object, the proto-object-based saliency is evaluated. The most salient proto-object is selected for attention, and it is finally put into the perceptual completion processing module to yield a complete object region. This model has been applied into distinct tasks of robots: detection of task-specific stationary and moving objects. Experimental results under different conditions are shown to validate this model.",
Building and using a semantivisual image hierarchy,"A semantically meaningful image hierarchy can ease the human effort in organizing thousands and millions of pictures (e.g., personal albums), and help to improve performance of end tasks such as image annotation and classification. Previous work has focused on using either low-level image features or textual tags to build image hierarchies, resulting in limited success in their general usage. In this paper, we propose a method to automatically discover the “semantivisual” image hierarchy by incorporating both image and tag information. This hierarchy encodes a general-to-specific image relationship. We pay particular attention to quantifying the effectiveness of the learned hierarchy, as well as comparing our method with others in the end-task applications. Our experiments show that humans find our semantivisual image hierarchy more effective than those solely based on texts or low-level visual features. And using the constructed image hierarchy as a knowledge ontology, our algorithm can perform challenging image classification and annotation tasks more accurately.","Humans,
Organizing,
Ontologies,
Image classification"
Two-Way MIMO Relay Precoder Design with Channel State Information,"In this paper, a two-way relay precoder is designed for multiple-input multiple-output (MIMO) distributed cooperative relay systems. A constrained optimization problem with respect to (w.r.t.) the relay precoder is formulated for the most general relay and antenna scenario, namely, multiple relays each with multiple antennas, It is shown that due to the difficulty of two-way distributed relaying mechanism as well as the block-diagonal nature of the relay precoding matrix, this optimization problem cannot be solved by existing one-way relaying methods. It is then proved that with full channel state information available at relays, the underlying problem can be converted to a convex optimization w.r.t. the non-zero entries of the relay precoding matrix only, such that the Lagrangian multiplier method is applicable to the relay precoder design, leading to a closed-form relay precoding solution. A simulation study is conducted to justify the superior performance of the proposed two-way relaying scheme.",
Automatic Segmentation of Pulmonary Lobes Robust Against Incomplete Fissures,"A method for automatic segmentation of pulmonary lobes from computed tomography (CT) scans is presented that is robust against incomplete fissures. The method is based on a multiatlas approach in which existing lobar segmentations are deformed to test scans in which the fissures, the lungs, and the bronchial tree have been automatically segmented. The key element of our method is a cost function that exploits information from fissures, lung borders, and bronchial tree in an effective way, such that less reliable information (lungs, airways) is only used when the most reliable information (fissures) is missing. To cope with the anatomical variation in lobe shape, an atlas selection mechanism is introduced. The method is evaluated on two test sets of 120 scans in total. The results show that the lobe segmentation closely follows the fissures when they are present. In a simulated experiment in which parts of complete fissures are removed, the robustness of the method against different levels of incomplete fissures is shown. When the fissures are incomplete, an observer study shows agreement of the automatically determined lobe borders with a radiologist for 81% of the lobe borders on average.",
Using Point Process Models to Compare Neural Spiking Activity in the Subthalamic Nucleus of Parkinson's Patients and a Healthy Primate,"Placement of deep brain stimulating electrodes in the subthalamic nucleus (STN) to treat Parkinson's disease (PD) also allows the recording of single neuron spiking activity. Analyses of these unique data offer an important opportunity to better understand the pathophysiology of PD. Despite the point process nature of PD neural spiking activity, point process methods are rarely used to analyze these recordings. We develop a point process representation of PD neural spiking activity using a generalized linear model to describe long- and short-term temporal dependencies in the spiking activity of 28 STN neurons from seven PD patients and 35 neurons from one healthy primate (surrogate control) recorded, while the subjects executed a directed-hand movement task. We used the point process model to characterize each neuron's bursting, oscillatory, and directional tuning properties during key periods in the task trial. Relative to the control neurons, the PD neurons showed increased bursting, increased 10-30 Hz oscillations, and increased fluctuations in directional tuning. These features, which traditional methods failed to capture accurately, were efficiently summarized in a single model in the point process analysis of each neuron. The point process framework suggests a useful approach for developing quantitative neural correlates that may be related directly to the movement and behavioral disorders characteristic of PD.","Neurons,
Electrodes,
Parkinson's disease,
Tuning,
Medical treatment,
Brain stimulation,
Satellite broadcasting,
History,
PD control,
Fluctuations"
Energy-efficient application-aware online provisioning for virtualized clouds and data centers,"As energy efficiency and associated costs become key concerns, consolidated and virtualized data centers and clouds are attractive computing platforms for data- and compute- intensive applications. These platforms provide an abstraction of nearly-unlimited computing resources through the elastic use of pools of consolidated resources, and provide opportunities for higher utilization and energy savings. Recently, these platforms are also being considered for more traditional high-performance computing (HPC) applications that have typically targeted Grids and similar conventional HPC platforms. However, maximizing energy efficiency, cost-effectiveness, and utilization for these applications while ensuring performance and other Quality of Service (QoS) guarantees, requires leveraging important and extremely challenging tradeoffs. These include, for example, the tradeoff between the need to efficiently create and provision Virtual Machines (VMs) on data center resources and the need to accommodate the heterogeneous resource demands and runtimes of these applications. In this paper we present an energy-aware online provisioning approach for HPC applications on consolidated and virtualized computing platforms. Energy efficiency is achieved using a workload-aware, just-right dynamic provisioning mechanism and the ability to power down subsystems of a host system that are not required by the VMs mapped to it. We evaluate the presented approach using real HPC workload traces from widely distributed production systems. The results presented demonstrated that compared to typical reactive or predefined provisioning, our approach achieves significant improvements in energy efficiency with an acceptable QoS penalty.",
Low rank matrix recovery for real-time cardiac MRI,"Real-time cardiac MRI is a very challenging problem because of limitations on imaging speed and resolution. To address this problem, the (k,t) - space MR signal is modeled as being partially separable along the spatial and temporal dimensions, which results in a rank-deficient data matrix. Image reconstruction is then formulated as a low-rank matrix recovery problem, which is solved using emerging low-rank matrix recovery techniques. In this paper, the Power Factorization algorithm is applied to efficiently recover the cardiac data matrix. Promising results are presented to demonstrate the performance of this novel approach.",
On Nodal Encounter Patterns in Wireless LAN Traces,"In this paper, we analyze multiple wireless LAN (WLAN) traces from university and corporate campuses. In particular, we consider important events between mobile nodes in wireless networks-encounters. We seek to understand encounter patterns in the mobile network from a holistic view, using a graph analysis approach. Such an analysis sheds light on the diverse, nonhomogeneous nature of users in the given environments in terms of their encounter events with other nodes. Furthermore, we evaluate the feasibility of forming an infrastructureless network to reach most of the nodes utilizing time-varying internode connectivity through encounters, and the robustness of such an ad hoc communication network. Our analysis shows that while the encounter events are “sparse” (i.e., any given node does not encounter with many other nodes), the connectivity of the whole network is well-maintained, and a Small World pattern of nodal encounter emerges for the observation periods longer than one day. More interestingly, the encounter events collectively form a robust communication network, in which store-carry-forward message dissemination can be successful even with over 20 percent noncooperative nodes or removal of short-lived (up to minutes) encounter events.","Wireless LAN,
Wireless networks,
Pattern analysis,
Robustness,
Communication networks,
Information science,
Information analysis,
Pressing,
Protocols,
Telecommunication traffic"
A Complex Adaptive Notch Filter,"A complex adaptive notch filter is developed, for tracking single-sided (a.k.a. analytic or complex) tones immersed in background noise. A complex all-pass based realization is pursued which inherits useful properties from its real counterpart: independent tuning of the notch frequency and attenuation bandwidth, easy realization of the complementary band-pass filter, unbiased frequency estimation, and faster convergence and tracking than a gradient descent algorithm.",
An Effective Architecture for Automated Appliance Management System Applying Ontology-Based Cloud Discovery,"Cloud computing is a computing paradigm which allows access of computing elements and storages on-demand over the Internet. Virtual Appliances, pre-configured, ready-to-run applications are emerging as a breakthrough technology to solve the complexities of service deployment on Cloud infrastructure. However, an automated approach to deploy required appliances on the most suitable Cloud infrastructure is neglected by previous works which is the focus of this work. In this paper, we propose an effective architecture using ontology-based discovery to provide QoS aware deployment of appliances on Cloud service providers. In addition, we test our approach on a case study and the result shows the efficiency and effectiveness of the proposed work.","Home appliances,
Ontologies,
Cloud computing,
Service oriented architecture,
Distributed computing,
Grid computing,
Computer architecture,
Computer science,
Software engineering,
Semantic Web"
Analysis of Computational Time of Simple Estimation of Distribution Algorithms,"Estimation of distribution algorithms (EDAs) are widely used in stochastic optimization. Impressive experimental results have been reported in the literature. However, little work has been done on analyzing the computation time of EDAs in relation to the problem size. It is still unclear how well EDAs (with a finite population size larger than two) will scale up when the dimension of the optimization problem (problem size) goes up. This paper studies the computational time complexity of a simple EDA, i.e., the univariate marginal distribution algorithm (UMDA), in order to gain more insight into EDAs complexity. First, we discuss how to measure the computational time complexity of EDAs. A classification of problem hardness based on our discussions is then given. Second, we prove a theorem related to problem hardness and the probability conditions of EDAs. Third, we propose a novel approach to analyzing the computational time complexity of UMDA using discrete dynamic systems and Chernoff bounds. Following this approach, we are able to derive a number of results on the first hitting time of UMDA on a well-known unimodal pseudo-boolean function, i.e., the LeadingOnes problem, and another problem derived from LeadingOnes, named BVLeadingOnes. Although both problems are unimodal, our analysis shows that LeadingOnes is easy for the UMDA, while BVLeadingOnes is hard for the UMDA. Finally, in order to address the key issue of what problem characteristics make a problem hard for UMDA, we discuss in depth the idea of ¿margins¿ (or relaxation). We prove theoretically that the UMDA with margins can solve the BVLeadingOnes problem efficiently.","Algorithm design and analysis,
Distributed computing,
Electronic design automation and methodology,
Application software,
Computer science,
Evolutionary computation,
Stochastic processes,
Computer applications,
Laboratories,
Time measurement"
Analysis of the Effects of Pansharpening in Change Detection on VHR Images,"In this letter, we investigate the effects of pansharpening (PS) applied to multispectral (MS) multitemporal images in change-detection (CD) applications. Although CD maps computed from pansharpened data show an enhanced spatial resolution, they can suffer from errors due to artifacts induced by the fusion process. The rationale of our analysis consists in understanding to which extent such artifacts can affect spatially enhanced CD maps. To this end, a quantitative analysis is performed which is based on a novel strategy that exploits similarity measures to rank PS methods according to their impact on CD performance. Many multiresolution fusion algorithms are considered, and CD results obtained from original MS and from spatially enhanced data are compared.","Image analysis,
Spatial resolution,
Image resolution,
Performance analysis,
Remote monitoring,
Performance evaluation,
Availability,
Environmental management,
Earth"
Optimal control of affine nonlinear continuous-time systems using an online Hamilton-Jacobi-Isaacs formulation,"Solving the Hamilton-Jacobi-Isaacs (HJI) equation, commonly used in H∞ optimal control, is often referred to as a two-player differential game where one player tries to minimize the cost function while the other tries to maximize it. In this paper, the HJI equation is formulated online and forward-in-time using a novel single online approximator (SOLA)-based scheme to achieve optimal regulation and tracking control of affine nonlinear continuous-time systems. The SOLA-based adaptive approach is designed to learn the infinite horizon HJI equation, the corresponding optimal control input, and the worst case disturbance. A novel parameter tuning algorithm is derived which not only achieves the optimal cost function, control input, and the disturbance, but also ensures the system states remain bounded during the online learning. Lyapunov methods are used to show that all signals are uniformly ultimately bounded (UUB) while ensuring the approximated signals approach their optimal values with small bounded error. In the absence of OLA reconstruction errors, asymptotic convergence to the optimal signals is demonstrated, and simulation results illustrate the effectiveness of the approach.",
Classification of Normal and Hypoxic Fetuses From Systems Modeling of Intrapartum Cardiotocography,"Recording of maternal uterine pressure (UP) and fetal heart rate (FHR) during labor and delivery is a procedure referred to as cardiotocography. We modeled this signal pair as an input-output system using a system identification approach to estimate their dynamic relation in terms of an impulse response function. We also modeled FHR baseline with a linear fit and FHR variability unrelated to UP using the power spectral density, computed from an auto-regressive model. Using a perinatal database of normal and pathological cases, we trained suport-vector-machine classifiers with feature sets from these models. We used the classification in a detection process. We obtained the best results with a detector that combined the decisions of classifiers using both feature sets. It detected half of the pathological cases, with very few false positives (7.5%), 1 h and 40 min before delivery. This would leave sufficient time for an appropriate clinical response. These results clearly demonstrate the utility of our method for the early detection of cases needing clinical intervention.",
Detection and Tracking Using Particle-Filter-Based Wireless Sensor Networks,"The work reported in this paper investigates the performance of the Particle Filter (PF) algorithm for tracking a moving object using a wireless sensor network (WSN). It is well known that the PF is particularly well suited for use in target tracking applications. However, a comprehensive analysis on the effect of various design and calibration parameters on the accuracy of the PF has been overlooked. This paper outlines the results from such a study. In particular, we evaluate the effect of various design parameters (such as the number of deployed nodes, number of generated particles, and sampling interval) and calibration parameters (such as the gain, path loss factor, noise variations, and nonlinearity constant) on the tracking accuracy and computation time of the particle-filter-based tracking system. Based on our analysis, we present recommendations on suitable values for these parameters, which provide a reasonable trade-off between accuracy and complexity. We also analyze the theoretical Cramér-Rao Bound as the benchmark for the best possible tracking performance and demonstrate that the results from our simulations closely match the theoretical bound. In this paper, we also propose a novel technique for calibrating off-the-shelf sensor devices. We implement the tracking system on a real sensor network and demonstrate its accuracy in detecting and tracking a moving object in a variety of scenarios. To the best of our knowledge, this is the first time that empirical results from a PF-based tracking system with off-the-shelf WSN devices have been reported. Finally, we also present simple albeit important building blocks that are essential for field deployment of such a system.","Particle tracking,
Wireless sensor networks,
Target tracking,
Calibration,
Particle filters,
Sampling methods,
Noise generators,
Performance analysis,
Analytical models,
Sensor systems"
Simplifying Mixture Models Through Function Approximation,"The finite mixture model is widely used in various statistical learning problems. However, the model obtained may contain a large number of components, making it inefficient in practical applications. In this paper, we propose to simplify the mixture model by minimizing an upper bound of the approximation error between the original and the simplified model, under the use of the L 2 distance measure. This is achieved by first grouping similar components together and then performing local fitting through function approximation. The simplified model obtained can then be used as a replacement of the original model to speed up various algorithms involving mixture models during training (e.g., Bayesian filtering, belief propagation) and testing [e.g., kernel density estimation, support vector machine (SVM) testing]. Encouraging results are observed in the experiments on density estimation, clustering-based image segmentation, and simplification of SVM decision functions.","Function approximation,
Support vector machines,
Testing,
Statistical learning,
Upper bound,
Approximation error,
Clustering algorithms,
Filtering algorithms,
Bayesian methods,
Belief propagation"
TSV redundancy: Architecture and design issues in 3D IC,"3D technology provides many benefits including high density, high band-with, low-power, and small form-factor. Through Silicon Via (TSV), which provides communication links for dies in vertical direction, is a critical design issue in 3D integration. Just like other components, the fabrication and bonding of TSVs can fail. A failed TSV may cause a number of known-good-dies that are stacked together to be discarded. This can severely increase the cost and decrease the yield as the number of dies to be stacked increases. A redundant TSV architecture with reasonable cost for ASICs is proposed in this paper. Design issues including recovery rate and timing problem are addressed. Based on probabilistic models, some interesting findings are reported. First, the probability that three or more TSVs are failed in a tier is less than 0.002%. Assumption of that there are at most two failed TSVs in a tier is sufficient to cover 99.998% of all possible faulty free and faulty cases. Next, with one redundant TSV allocated to one TSV block, limiting the number of TSVs in each TSV block to be no greater than 50 and 25 leads to 90% and 95% recovery rates when 2 failed TSVs are assumed. Finally, analysis on overall yield shows that the proposed design can successfully recover most of the failed chips and increase the yield of TSV bonding to 99.99%. This can effectively reduce the cost of manufacturing 3D ICs.","Through-silicon vias,
Three-dimensional integrated circuits,
Costs,
Bonding,
Redundancy,
Silicon,
Fabrication,
Timing,
Failure analysis,
Manufacturing"
Analyzing the potential of cooperative Cognitive Radio technology on inter-vehicle communication,"Recent studies demonstrate that Cognitive Radio (CR) technology can increase the spectrum efficiency of wireless systems, provided that the activity of primary users (PUs) must be carefully protected. For this reason, several sensing schemes leverage the cooperation among nodes to increase the accuracy of PU detection. In this paper, we propose to employ the CR principles in the vehicular environment in order to increase the spectrum opportunities for inter-vehicle communication (IVC). We propose a cooperative sensing and spectrum allocation scheme through which vehicles can share information about spectrum availability of TV channels on their path, and dynamically decide the channels to use on each road segment. Moreover, we investigate the role of vehicular mobility in the cooperation process, which might allow a vehicle to know in advance the spectrum availability on future locations along its path. Simulation results confirm the ability of our scheme in providing robust PU detection under fading conditions, and analyze the impact of some vehicular networks characteristics into the operations of CR systems.","Vehicles,
Sensors,
TV,
Road transportation,
Resource management,
Availability,
Schedules"
VMeter: Power modelling for virtualized clouds,"Datacenters are seeing unprecedented growth in recent years. The energy requirements to operate these large scale facilities are increasing significantly both in terms of operation cost as well as their indirect impact on ecology due to high carbon emissions. There are several ongoing research efforts towards the development of an integrated cloud management system to provide comprehensive online monitoring of resource utilization along with the implementation of power-aware policies to reduce the total energy consumption. However, most of these techniques provide online power monitoring based on the power consumption of a physical node running one or more Virtual Machines (VM). They lack a fine-grained mechanism to profile the power of an individual hosted VM. In this work we present a novel power modelling technique, VMeter, based on online monitoring of system-resources having high correlation with the total power consumption. The monitored system sub-components include: CPU, cache, disk, and DRAM. The proposed model predicts instantaneous power consumption of an individual VM hosted on a physical node besides the full system power consumption. Our model is validated using computationally diverse and industry standard benchmark programs. Our evaluation results show that our model is able to predict instantaneous power with an average mean and median accuracy of 93% and 94%, respectively, against the actual measured power using an externally attached power meter.","Clouds,
Energy consumption,
Power system modeling,
Virtual manufacturing,
Resource management,
Virtual machine monitors,
Predictive models,
Biological system modeling,
Large-scale systems,
Costs"
Fabrication and Characterization of a Surface-Acoustic-Wave Biosensor in CMOS Technology for Cancer Biomarker Detection,"Design, fabrication, and characterization of a novel surface acoustic wave (SAW) biosensor in complementary metal-oxide semiconductor (CMOS) technology are introduced. The biosensor employs a streptavidin/biotin-based five-layer immunoassay for detecting a prominent breast cancer biomarker, mammoglobin (hMAM). There is a growing demand to develop a sensitive and specific assay to detect biomarkers in serum that could be used in the early detection of breast cancer, determining prognosis and monitoring therapy. CMOS-SAW devices present a viable alternative to the existing biosensor technologies by providing higher sensitivity levels and better performance at low costs. Two architectures (circular and rectangular) were developed and respective tests were presented for performance comparison. The sensitivities of the devices were analyzed primarily based on center frequency shifts. A frequency sensitivity of 8.704 pg/Hz and a mass sensitivity of 2810.25 m2 /kg were obtained. Selectivity tests were carried out against bovine serum albumin. Experimental results indicate that it is possible to attach cancer biomarkers to functionalized CMOS-SAW sensor surfaces and selectively detect hMAM antigens with improved sensitivities, lowered costs, and increased repeatability of fabrication.","CMOS technology,
Fabrication,
Biosensors,
Biomarkers,
Cancer detection,
Surface acoustic waves,
Acoustic signal detection,
Breast cancer,
Testing,
Frequency"
Capacity Theorems for the AWGN multi-way relay channel,"The L-user additive white Gaussian noise multi-way relay channel is considered, where multiple users exchange information through a single relay at a common rate. Existing coding strategies, i.e., complete-decode-forward and compress-forward are shown to be bounded away from the cut-set upper bound at high signal-to-noise ratios (SNR). It is known that the gap between the compress-forward rate and the capacity upper bound is a constant at high SNR, and that between the complete-decode-forward rate and the upper bound increases with SNR at high SNR. In this paper, a functional-decode-forward coding strategy is proposed. It is shown that for L ≥ 3, complete-decode-forward achieves the capacity when SNR ≤ 0 dB, and functional-decode-forward achieves the capacity when SNR ≥ 0 dB. For L = 2, functional-decode-forward achieves the capacity asymptotically as SNR increases.","AWGN,
Relays,
Decoding,
Additive white noise,
Upper bound,
Signal to noise ratio,
Broadcasting,
Downlink,
Computer science,
Gaussian noise"
Harnessing battery recovery effect in wireless sensor networks: Experiments and analysis,"Many applications of wireless sensor networks rely on batteries. But most batteries are not simple energy reservoirs, and can exhibit battery recovery effect. That is, the deliverable energy in a battery can be self-replenished, if left idling for sufficient time. As a viable approach for energy optimisation, we made several contributions towards harnessing battery recovery effect in sensor networks. 1) We empirically examine the gain of battery runtime of sensor devices due to battery recovery effect, and affirm its significant benefit in sensor networks. We also observe a saturation threshold, beyond which more idle time will contribute only little to battery recovery. 2) Based on our experiments, we propose a Markov chain model to capture battery recovery considering saturation threshold and random sensing activities, by which we can study the effectiveness of duty cycling and buffering. 3) We devise a simple distributed duty cycle scheme to take advantage of battery recovery using pseudo-random sequences, and analyse its trade-off between the induced latency of data delivery and duty cycle rates.","Batteries,
Runtime,
Schedules,
Markov processes,
Chemicals,
Sensors,
Radio transceivers"
Tree-structured Data Regeneration in Distributed Storage Systems with Regenerating Codes,"Distributed storage systems provide large-scale reliable data storage by storing a certain degree of redundancy in a decentralized fashion on a group of storage nodes. To recover from data losses due to the instability of these nodes, whenever a node leaves the system, additional redundancy should be regenerated to compensate such losses. In this context, the general objective is to minimize the volume of actual network traffic caused by such regenerations. A class of codes, called regenerating codes, has been proposed to achieve an optimal trade-off curve between the amount of storage space required for storing redundancy and the network traffic during the regeneration. In this paper, we jointly consider the choices of regenerating codes and network topologies. We propose a new design, referred to as RCTREE, that combines the advantage of regenerating codes with a tree-structured regeneration topology. Our focus is the efficient utilization of network links, in addition to the reduction of the regeneration traffic. With the extensive analysis and quantitative evaluations, we show that RCTREE is able to achieve a both fast and stable regeneration, even with departures of storage nodes during the regeneration.",
Verification and validation of simulation models,"In this paper we discuss verification and validation of simulation models. Four different approaches to deciding model validity are described; two different paradigms that relate verification and validation to the model development process are presented; various validation techniques are defined; conceptual model validity, model verification, operational validity, and data validity are discussed; a way to document results is given; a recommended procedure for model validation is presented; and model accreditation is briefly discussed.","Computational modeling,
Data models,
Mathematical model,
Analytical models,
Computers,
Accuracy,
Programming"
Toward a Highly Accurate Ambulatory System for Clinical Gait Analysis via UWB Radios,"In this paper, we propose and investigate a low-cost and low-complexity wireless ambulatory human locomotion tracking system that provides a high ranging accuracy (intersensor distance) suitable for the assessment of clinical gait analysis using wearable ultra wideband (UWB) transceivers. The system design and transceiver performance are presented in additive-white-Gaussian noise and realistic channels, using industry accepted channel models for body area networks. The proposed system is theoretically capable of providing a ranging accuracy of 0.11 cm error at distances equivalent to interarker distances, at an 18 dB SNR in realistic on-body UWB channels. Based on real measurements, it provides the target ranging accuracy at an SNR = 20 dB. The achievable accuracy is ten times better than the accuracy reported in the literature for the intermarker-distance measurement. This makes it suitable for use in clinical gait analysis, and for the characterization and assessment of unstable mobility diseases, such as Parkinson's disease.","Optical sensors,
Biomedical optical imaging,
Humans,
Ultra wideband technology,
Transceivers,
Biological system modeling,
Parkinson's disease,
Magnetic sensors,
Sensor systems,
Ultrasonic variables measurement"
On the diversity gain in cooperative relaying channels with imperfect CSIT,"In this paper, we investigate the impact of imperfect channel state information at the transmitters (CSIT) on the achievable diversity gain in a cooperative relaying channel with multiple destination antennas, where the CSIT comes from channel estimation at the transmitters. Both decode-and-forward (DF) and amplify-and-forward (AF) relaying protocols are considered. We show that transmit power control based on the imperfect CSIT significantly improves the achievable diversity gain. The diversity and multiplexing tradeoff (DMT) as a function of the CSIT quality of the source-relay link, source-destination link and relay-destination link is derived for each of the considered relaying schemes. An upper bound on the DMT of the relaying channel is also provided.","Diversity methods,
Relays,
Transmitters,
OFDM modulation,
Channel state information,
Transmitting antennas,
Channel estimation,
Decoding,
Protocols,
Power control"
Blurred Image Recognition by Legendre Moment Invariants,"Processing blurred images is a key problem in many image applications. Existing methods to obtain blur invariants which are invariant with respect to centrally symmetric blur are based on geometric moments or complex moments. In this paper, we propose a new method to construct a set of blur invariants using the orthogonal Legendre moments. Some important properties of Legendre moments for the blurred image are presented and proved. The performance of the proposed descriptors is evaluated with various point-spread functions and different image noises. The comparison of the present approach with previous methods in terms of pattern recognition accuracy is also provided. The experimental results show that the proposed descriptors are more robust to noise and have better discriminative power than the methods based on geometric or complex moments.",
Evolutionary Game Design,"It is easy to create new combinatorial games but more difficult to predict those that will interest human players. We examine the concept of game quality, its automated measurement through self-play simulations, and its use in the evolutionary search for new high-quality games. A general game system called Ludi is described and experiments conducted to test its ability to synthesize and evaluate new games. Results demonstrate the validity of the approach through the automated creation of novel, interesting, and publishable games.","Artificial intelligence,
Game theory,
System testing,
Toy industry,
Computational intelligence,
Humans,
Competitive intelligence,
Prototypes"
Energy-efficient variable-flow liquid cooling in 3D stacked architectures,"Liquid cooling has emerged as a promising solution for addressing the elevated temperatures in 3D stacked architectures. In this work, we first propose a framework for detailed thermal modeling of the microchannels embedded between the tiers of the 3D system. In multicore systems, workload varies at runtime, and the system is generally not fully utilized. Thus, it is not energy-efficient to adjust the coolant flow rate based on the worst-case conditions, as this would cause an excess in pump power. For energy-efficient cooling, we propose a novel controller to adjust the liquid flow rate to meet the desired temperature and to minimize pump energy consumption. Our technique also includes a job scheduler, which balances the temperature across the system to maximize cooling efficiency and to improve reliability. Our method guarantees operating below the target temperature while reducing the cooling energy by up to 30%, and the overall energy by up to 12% in comparison to using the highest coolant flow rate.","Energy efficiency,
Liquid cooling,
Thermal management,
Multicore processing,
Coolants,
Microchannel,
Temperature control,
Fluid flow,
Energy consumption,
Power system modeling"
MusicBox: Personalized Music Recommendation Based on Cubic Analysis of Social Tags,"Social tagging is becoming increasingly popular in music information retrieval (MIR). It allows users to tag music items like songs, albums, or artists. Social tags are valuable to MIR, because they comprise a multifaced source of information about genre, style, mood, users' opinion, or instrumentation. In this paper, we examine the problem of personalized music recommendation based on social tags. We propose the modeling of social tagging data with three-order tensors, which capture cubic (three-way) correlations between users-tags-music items. The discovery of latent structure in this model is performed with the Higher Order Singular Value Decomposition (HOSVD), which helps to provide accurate and personalized recommendations, i.e., adapted to the particular users' preferences. To address the sparsity that incurs in social tagging data and further improve the quality of recommendation, we propose to enhance the model with a tag-propagation scheme that uses similarity values computed between the music items based on audio features. As a result, the proposed model effectively combines both information about social tags and audio features. The performance of the proposed method is examined experimentally with real data from Last.fm. Our results indicate the superiority of the proposed approach compared to existing methods that suppress the cubic relationships that are inherent in social tagging data. Additionally, our results suggest that the combination of social tagging data with audio features is preferable than the sole use of the former.",
Brief Paper: Output-feedback adaptive dynamic surface control of stochastic non-linear systems using neural network,"For the first time, a dynamic surface control approach is proposed for a class of stochastic non-linear systems with the standard output-feedback form using neural network. The proposed approach is a stochastic vision of the existing dynamic surface control approach which can overcome the problem of 'explosion of complexity' in the backstepping design of stochastic systems. Moreover, all unknown system functions are lumped into a suitable unknown function which is compensated for using only a neural network. The proposed control approach is simpler than the existing backstepping control methods for stochastic systems. Two examples are given to illustrate the effectiveness of the proposed design approach.",
Customizable FPGA IP Core Implementation of a General-Purpose Genetic Algorithm Engine,"Hardware implementation of genetic algorithms (GAs) is gaining importance because of their proven effectiveness as optimization engines for real-time applications (e.g., evolvable hardware). Earlier hardware implementations suffer from major drawbacks such as absence of GA parameter programmability, rigid predefined system architecture, and lack of support for multiple fitness functions. In this paper, we report the design of an IP core that implements a general-purpose GA engine that addresses these problems. Specifically, the proposed GA IP core can be customized in terms of the population size, number of generations, crossover and mutation rates, random number generator seed, and the fitness function. It has been successfully synthesized and verified on a Xilinx Virtex II Pro Field programmable gate arrays device (xc2vp30-7ff896) with only 13% logic slice utilization, 1% block memory utilization for GA memory, and a clock speed of 50 MHz. The GA core has been used as a search engine for real-time adaptive healing but can be tailored to any given application by interfacing with the appropriate application-specific fitness evaluation module as well as the required storage memory and by programming the values of the desired GA parameters. The core is soft in nature i.e., a gate-level netlist is provided which can be readily integrated with the user's system. The performance of the GA core was tested using standard optimization test functions. In the hardware experiments, the proposed core either found the globally optimum solution or found a solution that was within 3.7% of the value of the globally optimal solution. The experimental test setup including the GA core achieved a speedup of around 5.16× over an analogous software implementation.",
Projective Nonnegative Graph Embedding,"We present in this paper a general formulation for nonnegative data factorization, called projective nonnegative graph embedding (PNGE), which 1) explicitly decomposes the data into two nonnegative components favoring the characteristics encoded by the so-called intrinsic and penalty graphs , respectively, and 2) explicitly describes how to transform each new testing sample into its low-dimensional nonnegative representation. In the past, such a nonnegative decomposition was often obtained for the training samples only, e.g., nonnegative matrix factorization (NMF) and its variants, nonnegative graph embedding (NGE) and its refined version multiplicative nonnegative graph embedding (MNGE). Those conventional approaches for out-of-sample extension either suffer from the high computational cost or violate the basic nonnegative assumption. In this work, PNGE offers a unified solution to out-of-sample extension problem, and the nonnegative coefficient vector of each datum is assumed to be projected from its original feature representation with a universal nonnegative transformation matrix. A convergency provable multiplicative nonnegative updating rule is then derived to learn the basis matrix and transformation matrix. Extensive experiments compared with the state-of-the-art algorithms on nonnegative data factorization demonstrate the algorithmic properties in convergency, sparsity, and classification power.",
A Novel Impedance Definition of a Parallel Plate Pair for an Intrinsic Via Circuit Model,"Rigorous analysis of via-plate-pair interactions requires the impedance of a plate pair to be defined in terms of radial transmission lines on perfect magnetic conductor (PMC) ports. The plate domain is not a solid plate pair but one with multiple PMC holes where conventional impedance definitions are not suitable. A new impedance definition is proposed where port voltages and currents are expressed in terms of the inward and outward zero-order modes of a radial transmission line. Radial scattering parameters among multiple radial ports are then introduced and the transforms between the radial scattering and impedance matrices are given. An analytical formula for the radial scattering matrix in a circular plate pair is derived using the addition theorems of cylindrical waves. Furthermore, a boundary integral-equation method is developed to calculate the radial scattering matrix for any irregular plate pair. The method is validated by analytical and numerical simulations as well as measurements.","Impedance,
Transmission line matrix methods,
Scattering,
Integrated circuit modeling,
Transforms,
Scattering parameters,
Solids"
Precoding for PAPR Reduction of OFDM Signals With Minimum Error Probability,"The precoding technique is an effective and flexible way for reducing the peak-to-average power ratio (PAPR) of orthogonal frequency division multiplexing (OFDM) signals. However, different precoding schemes will increase error probabilities of the system. With the knowledge of the channel information and the receiver filter, we derive a necessary condition on the chosen precoding matrices for minimizing error probability of the OFDM system in the additive white Gaussian noise (AWGN) channel. A systematic procedure in designing such an optimal precoding matrix is provided. With a proper selection, the optimal precoding matrix can meet the requirements of PAPR reduction and achieve the minimum error probability in white Gaussian noise. Our simulation results show that the chosen precoding matrix notably outperforms other general precoding matrices in both AWGN and multipath fading channels. We also proved that the precoding matrix with all the singular values equal to 1 is one of the optimal solutions.","Peak to average power ratio,
OFDM,
Error probability,
AWGN,
Information filtering,
Information filters,
Frequency domain analysis,
Signal processing,
Partial transmit sequences,
Transmitters"
The Multicast Capacity of Large Multihop Wireless Networks,"We consider wireless ad hoc networks with a large number of users. Subsets of users might be interested in identical information, and so we have a regime in which several multicast sessions may coexist. We first calculate an upper bound on the achievable transmission rate per multicast flow as a function of the number of multicast sources in such a network. We then propose a simple comb-based architecture for multicast routing, which achieves the upper bound in an order sense under certain constraints. Compared to the approach of constructing a Steiner tree to decide multicast paths, our construction achieves the same order-optimal results while requiring little location information and no computational overhead.","Spread spectrum communication,
Wireless networks,
Mobile ad hoc networks,
Upper bound,
Military computing,
Ad hoc networks,
Context,
Telecommunication traffic,
Throughput,
Relays"
Regularization in Matrix Relevance Learning,"In this paper, we present a regularization technique to extend recently proposed matrix learning schemes in learning vector quantization (LVQ). These learning algorithms extend the concept of adaptive distance measures in LVQ to the use of relevance matrices. In general, metric learning can display a tendency towards oversimplification in the course of training. An overly pronounced elimination of dimensions in feature space can have negative effects on the performance and may lead to instabilities in the training. We focus on matrix learning in generalized LVQ (GLVQ). Extending the cost function by an appropriate regularization term prevents the unfavorable behavior and can help to improve the generalization ability. The approach is first tested and illustrated in terms of artificial model data. Furthermore, we apply the scheme to benchmark classification data sets from the UCI Repository of Machine Learning. We demonstrate the usefulness of regularization also in the case of rank limited relevance matrices, i.e., matrix learning with an implicit, low-dimensional representation of the data.",
Classification of Benign and Malignant Breast Tumors by 2-D Analysis Based on Contour Description and Scatterer Characterization,"Ultrasound B-mode scanning based on the echo intensity has become an important clinical tool for routine breast screening. The efficacy of the Nakagami parametric image based on the distribution of the backscattered signals for quantifying properties of breast tissue was recently evaluated. The B-mode and Nakagami images reflect different physical characteristic of breast tumors: the former describes the contour features, and the latter reflects the scatterer arrangement inside a tumor. The functional complementation of these two images encouraged us to propose a novel method of 2-D analysis based on describing the contour using the B-mode image and the scatterer properties using the Nakagami image, which may provide useful clues for classifying benign and malignant tumors. To validate this concept, raw data were acquired from 60 clinical cases, and five contour feature parameters (tumor circularity, standard deviation of the normalized radial length, area ratio, roughness index, and standard deviation of the shortest distance) and the Nakagami parameters of benign and malignant tumors were calculated. The receiver operating characteristic curve and fuzzy c-means clustering were used to evaluate the performances of combining the parameters in classifying tumors. The clinical results demonstrated the presence of a tradeoff between the sensitivity and specificity when either using a single parameter or combining two contour parameters to discriminate between benign and malignant cases. However, combining the contour parameters and the Nakagami parameter produces sensitivity and specificity that simultaneously exceed 80%, which means that the functional complementation from the B-scan and the Nakagami image indeed enhances the performance in diagnosing breast tumors.",
Closed-Form MMSE Estimation for Signal Denoising Under Sparse Representation Modeling Over a Unitary Dictionary,"This paper deals with the Bayesian signal denoising problem, assuming a prior based on a sparse representation modeling over a unitary dictionary. It is well known that the maximum a posteriori probability (MAP) estimator in such a case has a closed-form solution based on a simple shrinkage. The focus in this paper is on the better performing and less familiar minimum-mean-squared-error (MMSE) estimator. We show that this estimator also leads to a simple formula, in the form of a plain recursive expression for evaluating the contribution of every atom in the solution. An extension of the model to real-world signals is also offered, considering heteroscedastic nonzero entries in the representation, and allowing varying probabilities for the chosen atoms and the overall cardinality of the sparse representation. The MAP and MMSE estimators are redeveloped for this extended model, again resulting in closed-form simple algorithms. Finally, the superiority of the MMSE estimator is demonstrated both on synthetically generated signals and on real-world signals (image patches).",
3-D Visualization of Acute RF Ablation Lesions Using MRI for the Simultaneous Determination of the Patterns of Necrosis and Edema,"Catheter ablation using RF energy is a common treatment for atrial arrhythmias. Although this treatment provides a potential cure, currently, there remains a high proportion of patients returning for repeat ablations. Electrophysiologists have little information to verify that a lesion has been created in the myocardium. Temporary electrical block can be created from edema, which will subside. MRI can visualize acute and chronic ablation lesions using delayed-enhancement techniques. However, the ablation patterns cannot be determined from 2-D images alone. Using the combination of T2-weighted and delayed-enhancement MRI, ablation lesions can be characterized in terms of necrosis and edema. A novel 3-D visualization technique is presented that projects the image intensity due the lesions onto a 3-D cardiac surface, allowing the complete, simultaneous visualization of the delayed-enhancement and T2 -weighted ablation patterns. Results show successful visualization of ablation patterns in 18 patients, and an application of this technique is presented in which electroanatomical mapping systems can be validated by overlaying the acquired ablation points onto the cardiac surfaces and assessing the correlation with the lesion maps.","Visualization,
Radio frequency,
Lesions,
Magnetic resonance imaging,
Delay,
Catheters,
Biomedical imaging,
Heart,
Medical treatment,
Myocardium"
Reverse top-k queries,"Rank-aware query processing has become essential for many applications that return to the user only the top-k objects based on the individual user's preferences. Top-k queries have been mainly studied from the perspective of the user, focusing primarily on efficient query processing. In this work, for the first time, we study top-k queries from the perspective of the product manufacturer. Given a potential product, which are the user preferences for which this product is in the top-k query result set? We identify a novel query type, namely reverse top-k query, that is essential for manufacturers to assess the potential market and impact of their products based on the competition. We formally define reverse top-k queries and introduce two versions of the query, namely monochromatic and bichromatic. We first provide a geometric interpretation of the monochromatic reverse top-k query in the solution space that helps to understand the reverse top-k query conceptually. Then, we study in more details the case of bichromatic reverse top-k query, which is more interesting for practical applications. Such a query, if computed in a straightforward manner, requires evaluating a top-k query for each user preference in the database, which is prohibitively expensive even for moderate datasets. In this paper, we present an efficient threshold-based algorithm that eliminates candidate user preferences, without processing the respective top-k queries. Furthermore, we introduce an indexing structure based on materialized reverse top-k views in order to speed up the computation of reverse top-k queries. Materialized reverse top-k views trade preprocessing cost for query speed up in a controllable manner. Our experimental evaluation demonstrates the efficiency of our techniques, which reduce the required number of top-k computations by 1 to 3 orders of magnitude.",
Robust Class Similarity Measure for Traffic Sign Recognition,"Traffic sign recognition is an example of a hard multiclass classification problem. The existing approaches to that problem typically associate with each sign class a real-valued likelihood function and assign such a label to the unknown image that maximizes the value of this function. These template-matching techniques are usually based on arbitrary similarity metrics, such as normalized cross correlation, which do not capture the characteristics of the sign imagery. In this paper, we study the concept of a robust sign similarity measure that can be inferred from the domain-specific data. Two novel machine-learning techniques are proposed as a framework for automatic construction of such a measure from the pairs of images representing either the same or different classes. One is called SimBoost, which is a variation of the AdaBoost algorithm, and the other is based on the fuzzy regression tree framework. Through the experiments with low-quality images, we show that the proposed method admits efficient road sign recognition and outperforms the existing approaches in terms of the classification accuracy.","Robustness,
Humans,
Regression tree analysis,
Road vehicles,
Vehicle driving,
Image recognition,
Safety,
Object recognition,
Retina,
Photoreceptors"
MILD: Multiple-Instance Learning via Disambiguation,"In multiple-instance learning (MIL), an individual example is called an instance and a bag contains a single or multiple instances. The class labels available in the training set are associated with bags rather than instances. A bag is labeled positive if at least one of its instances is positive; otherwise, the bag is labeled negative. Since a positive bag may contain some negative instances in addition to one or more positive instances, the true labels for the instances in a positive bag may or may not be the same as the corresponding bag label and, consequently, the instance labels are inherently ambiguous. In this paper, we propose a very efficient and robust MIL method, called Multiple-Instance Learning via Disambiguation (MILD), for general MIL problems. First, we propose a novel disambiguation method to identify the true positive instances in the positive bags. Second, we propose two feature representation schemes, one for instance-level classification and the other for bag-level classification, to convert the MIL problem into a standard single-instance learning (SIL) problem that can be solved by well-known SIL algorithms, such as support vector machine. Third, an inductive semi-supervised learning method is proposed for MIL. We evaluate our methods extensively on several challenging MIL applications to demonstrate their promising efficiency, robustness, and accuracy.","Drugs,
Robustness,
Machine learning,
Support vector machines,
Support vector machine classification,
Semisupervised learning,
Object recognition,
Shape,
Predictive models"
Extending sensor networks into the Cloud using Amazon Web Services,"Sensor networks provide a method of collecting environmental data for use in a variety of distributed applications. However, to date, limited support has been provided for the development of integrated environmental monitoring and modeling applications. Specifically, environmental dynamism makes it difficult to provide computational resources that are sufficient to deal with changing environmental conditions. This paper argues that the Cloud Computing model is a good fit with the dynamic computational requirements of environmental monitoring and modeling. We demonstrate that Amazon EC2 can meet the dynamic computational needs of environmental applications. We also demonstrate that EC2 can be integrated with existing sensor network technologies to offer an end-to-end environmental monitoring and modeling solution.",
A Hybrid Evolutionary Approach to the Nurse Rostering Problem,"Nurse rostering is an important search problem with many constraints. In the literature, a number of approaches have been investigated including penalty function methods to tackle these constraints within genetic algorithm frameworks. In this paper, we investigate an extension of a previously proposed stochastic ranking method, which has demonstrated superior performance to other constraint handling techniques when tested against a set of constrained optimization benchmark problems. An initial experiment on nurse rostering problems demonstrates that the stochastic ranking method is better at finding feasible solutions, but fails to obtain good results with regard to the objective function. To improve the performance of the algorithm, we hybridize it with a recently proposed simulated annealing hyper-heuristic (SAHH) within a local search and genetic algorithm framework. Computational results show that the hybrid algorithm performs better than both the genetic algorithm with stochastic ranking and the SAHH alone. The hybrid algorithm also outperforms the methods in the literature which have the previously best known results.","Stochastic processes,
Genetic algorithms,
Constraint optimization,
Computer science,
Simulated annealing,
Computational modeling,
Hospitals,
Search problems,
Benchmark testing,
Evolutionary computation"
Spectrum sensing with active cognitive systems,"Spectrum sensing is critical for cognitive systems to locate spectrum holes. In the IEEE 802.22 proposal, short quiet periods are arranged inside frames to perform a coarse intra-frame sensing as a pre-alarm for fine inter-frame sensing. However, the limited sample size of the quiet periods may not guarantee a satisfying performance and an additional burden of quiet-period synchronization is required. To improve the sensing performance, we first propose a quiet-active sensing scheme in which inactive customer-provided equipments (CPEs) will sense the channels in both the quiet and active periods. To avoid quiet-period synchronization, we further propose to utilize (optimized) active sensing, in which the quiet periods are replaced by 'quiet samples' in other domains, such as quiet sub-carriers in OFDMA systems. By doing so, we not only save the need for synchronization, but also achieve selection diversity by choosing quiet sub-carriers based on channel conditions. The proposed active sensing scheme is also promising for spectrum sharing applications where both the cognitive and primary systems can be active simultaneously.","Proposals,
Computer vision,
Frequency synchronization,
Frequency diversity,
Resource management,
Councils,
Base stations,
TV,
Uncertainty,
Detectors"
A Study of the Human Flesh Search Engine: Crowd-Powered Expansion of Online Knowledge,This first comprehensive empirical study of a search function that originated in China examines its tremendous growth in recent years and its uniquely rich online/offline interactions.,"Media,
Internet,
Social network services,
Search engines,
Web and internet services,
Information services"
Designing a processor from the ground up to allow voltage/reliability tradeoffs,"Current processor designs have a critical operating point that sets a hard limit on voltage scaling. Any scaling beyond the critical voltage results in exceeding the maximum allowable error rate, i.e., there are more timing errors than can be effectively and gainfully detected or corrected by an error-tolerance mechanism. This limits the effectiveness of voltage scaling as a knob for reliability/power tradeoffs. In this paper, we present power-aware slack redistribution, a novel design-level approach to allow voltage/reliability tradeoffs in processors. Techniques based on power-aware slack redistribution reapportion timing slack of the frequently-occurring, near-critical timing paths of a processor in a power- and area-efficient manner, such that we increase the range of voltages over which the incidence of operational (timing) errors is acceptable. This results in soft architectures — designs that fail gracefully, allowing us to perform reliability/power tradeoffs by reducing voltage up to the point that produces maximum allowable errors for our application. The goal of our optimization is to minimize the voltage at which a soft architecture encounters the maximum allowable error rate, thus maximizing the range over which voltage scaling is possible and minimizing power consumption for a given error rate. Our experiments demonstrate 23% power savings over the baseline design at an error rate of 1%. Observed power reductions are 29%, 29%, 19%, and 20% for error rates of 2%, 4%, 8%, and 16% respectively. Benefits are higher in the face of error recovery using Razor. Area overhead of our techniques is up to 2.7%.",
Optimization of Training and Feedback Overhead for Beamforming Over Block Fading Channels,"We examine the capacity of beamforming over a single-user, multiantenna link taking into account the overhead due to channel estimation and limited feedback of channel state information. Multi-input-single-output (MISO) and multi-input-multi-output (MIMO) channels are considered subject to block Rayleigh fading. Each coherence block contains L symbols, and is spanned by T training symbols, B feedback bits, and the data symbols. The training symbols are used to obtain a minimum mean squared error estimate of the channel matrix. Given this estimate, the receiver selects a transmit beamforming vector from a codebook containing 2B i.i.d. random vectors, and sends the corresponding B bits back to the transmitter. We derive bounds on the beamforming capacity for MISO and MIMO channels and characterize the optimal (rate-maximizing) training and feedback overhead (T and B) as L and the number of transmit antennas Nt both become large. The optimal Nt is limited by the coherence time, and increases as L/logL. For the MISO channel the optimal T/L and B/L (fractional overhead due to training and feedback) are asymptotically the same, and tend to zero at the rate 1/log Nt. For the MIMO channel the optimal feedback overhead B/L tends to zero faster (as 1/log2 Nt).","Channel estimation,
MIMO,
Fading,
Coherence,
Antenna feeds,
Channel state information,
Feedback"
Optimization of Training and Feedback Overhead for Beamforming Over Block Fading Channels,,
Fast Mode Decision Based on Mode Adaptation,"This paper proposes an efficient algorithm for fast mode decision in H.264/advanced video coding by adaptively predicting the optimal mode for each macroblock (MB) to be coded. Firstly, encoding modes are projected as points onto a 2-D map, and an optimal 2-D point of the MB to be coded is predicted based on the encoding information of spatial-temporal neighboring blocks. Then, a priority-based mode candidate list with a descending order to be the best mode is constructed based on the optimal 2-D point. Finally, mode decision is performed according to the priority-based mode candidate list in the checking order, from the most important mode to the least one, with early termination conditions. Extensive experimental results demonstrate that the proposed algorithm is superior to three recent fast mode decision algorithms, with the entire encoding time being reduced by about 60% for quarter common intermediate format/common intermediate format/standard-definition sequences on average and the rate distortion performance being kept almost intact.",
Efficient computation of robust low-rank matrix approximations in the presence of missing data using the L1 norm,"The calculation of a low-rank approximation of a matrix is a fundamental operation in many computer vision applications. The workhorse of this class of problems has long been the Singular Value Decomposition. However, in the presence of missing data and outliers this method is not applicable, and unfortunately, this is often the case in practice. In this paper we present a method for calculating the low-rank factorization of a matrix which minimizes the L1 norm in the presence of missing data. Our approach represents a generalization the Wiberg algorithm of one of the more convincing methods for factorization under the L2 norm. By utilizing the differentiability of linear programs, we can extend the underlying ideas behind this approach to include this class of L1 problems as well. We show that the proposed algorithm can be efficiently implemented using existing optimization software. We also provide preliminary experiments on synthetic as well as real world data with very convincing results.","Robustness,
Computer vision,
Matrix decomposition,
Application software,
Singular value decomposition,
Particle measurements,
Least squares approximation,
Principal component analysis,
Computer science,
Software algorithms"
Robust MMSE Precoding in MIMO Channels With Pre-Fixed Receivers,"In this paper, we design robust precoders, under the minimum mean square error (MMSE) criterion, for different types of channel state information (CSI) in multiple-input multiple-output (MIMO) channels. We consider low-complexity pre-fixed receivers that may adapt to the channel but are oblivious to the existence of a precoder at the transmitter. In particular, three types of CSI are taken into account: i) perfect CSI, ii) statistical CSI in the form of mean feedback, and iii) deterministic imperfect CSI assuming that the actual channel is within the neighborhood of a nominal channel, which leads to the worst-case robust design that is the focus of this paper. Interestingly, it is found that, under some mild conditions, the optimal transmit directions, i.e., the left singular vectors of the precoder, are equal to the right singular vectors of the channel, the channel mean, and the nominal channel for perfect CSI, statistical CSI, and the worst-case design, respectively. Consequently, the matrix-valued problems can be simplified to scalar power allocation problems that either admit closed-form solutions or can be efficiently solved by the proposed algorithm.","Robustness,
MIMO,
Transmitters,
Channel state information,
Feedback,
Permission,
Stochastic processes,
Mean square error methods,
Minimax techniques,
Design optimization"
"MILSA: A New Evolutionary Architecture for Scalability, Mobility, and Multihoming in the Future Internet","Many challenges to the Internet including global routing scalability have drawn significant attention from both industry and academia, and have generated several new ideas for the next generation. MILSA (Mobility and Multihoming supporting Identifier Locator Split Architecture) and related enhancements are designed to address the naming, addressing, and routing scalability challenges, provide mobility and multihoming support, and easy transition from the current Internet. In this paper, we synthesize our research into a multiple-tier realm-based framework and present the fundamental principles behind the architecture. Through detailed presentation of these principles and different aspects of our architecture, the underlying design rationale is justified. We also discuss how our proposal can meet the IRTF RRG design goals. As an evolutionary architecture, MILSA balances the high-level long-run architecture design with ease of transition considerations. Additionally, detailed evaluation of the current inter-domain routing system and the achievable improvements deploying our architecture is presented that reveals the roots of the current difficulties and helps to shape our deployment strategy.","Routing,
Scalability,
Internet,
IP networks,
Protocols,
Educational institutions,
Security"
Application of functionally graded material for reducing electric field on electrode and spacer interface,"For the size reduction and the enhancing reliability of electric power equipment, the electric field stress around solid insulators should be considered enough. For the relaxation of the field stress, the application of FGM (Functionally Graded Materials) with spatial distribution of dielectric permittivity (¿-FGM) can be an effective solution. In this paper, we investigated the applicability of ¿-FGM for reducing the electric field stress on the electrode surface with contact to the solid dielectrics, which was one of the important factors dominating a long-term reliability of the insulating spacer. Firstly, we carried out numerical simulation of electric field to confirm the reduction of the electric stress by U-shape permittivity distribution. Secondly, we investigated the fabrication feasibility of ¿-FGM with the U-shape distribution. Thirdly, we estimated the longterm electrical insulation performance of the ¿-FGM. Finally, we verified the applicability and the fabrication technique of the ¿-FGM to solid dielectrics for improvement of the electric stress and the long-term insulation performance in electric power equipment.",
A novel Maximum Power Point tracking control of photovoltaic system under partial and rapidly fluctuating shadow conditions using Differential Evolution,"Photovoltaic (PV) system performance extremely depends on local insolation and temperature conditions. Under partial shading, P-I characteristics of PV systems are complicated and may have multiple local maxima. Conventional Maximum Power Point Tracking (MPPT) techniques can easily fail to track global maxima and may be trapped in local maxima under partial shading; this can be one of main causes for reduced energy yield for many PV systems. In order to solve this problem, this paper proposes a novel Maximum Power Point tracking algorithm based on Differential Evolution (DE) that is capable of tracking global MPP under partial shaded conditions. The ability of proposed algorithm and its excellent performances are evaluated with conventional and popular algorithm by means of simulation. The proposed algorithm works in conjunction with a Boost (step up) DC-DC converter to track the global peak. Moreover, this paper includes a MATLAB-based modeling and simulation scheme suitable for photovoltaic characteristics under partial shading.","Photovoltaic systems,
Converters,
Sun,
Optimization,
Artificial neural networks"
Toward a Personal Health Society in Cardiology,"In this paper, we present a new generation of health services that has emerged due to the development of advanced information and communication technology (ICT) solutions, like the Enhanced Personal, Intelligent, and Mobile system for Early Detection and Interpretation of Cardiac Syndromes (EPI-MEDICS). It is a personal self-care system that allows any citizen to self-record high-quality ECGs on demand with a smart portable device, which is endowed with powerful ICT capabilities: self-adaptive embedded intelligence, mobile health record management support on SmartMedia card, embedded Web server, and wireless communication. The EPI-MEDICS solution design also provides ambient, intelligent, and pervasive computing services offering any citizen a ubiquitous, reliable, and efficient management of his/her own cardiac status. A multicentric evaluation performed in Europe with a series of device prototypes and the performance assessment of the original methods of signal synthesis that were designed to guarantee a high interoperability level of the recorded data within the clinical practice, as well as of the decision-support methodologies that were developed for an early detection of life-threatening myocardial ischemia and arrhythmia, at home or anywhere, demonstrate the pertinence of going toward a personal health society in cardiology, which still yields the highest mortality rate in industrialized countries.","Cardiology,
Communications technology,
Intelligent systems,
Electrocardiography,
Energy management,
Health information management,
Power system management,
Web server,
Wireless communication,
Ambient intelligence"
An Intelligent Longitudinal Controller for Application in Semiautonomous Vehicles,"We present a neuro-fuzzy controller for intelligent cruise control of semiautonomous vehicles. This paper addresses the problem of longitudinal control that aims at regulating the speed of the controlled vehicle in order to maintain constant time headway with respect to the vehicle in front. A fuzzy radial basis function network (FRBFN) longitudinal controller is designed to incorporate the merits of fuzzy logics as well as neural networks. The FRBFN is prestructured, and its parameters are configured such that they are associated with their physical meaning. The parameters of the output layer are learned online via gradient algorithm. An attractive feature of the proposed method is that it does not require the training data and the vehicle longitudinal dynamic model. Simulation results on a vehicle theoretical model are provided to demonstrate the effectiveness of this controller. In order to investigate the proposed control algorithms in real-life situations, a small-scaled vehicle with computer and sensors onboard is developed. Experimental results of a conventional PID controller and the FRBFN controller are provided for comparison.",
Estimating Cohesion in Small Groups Using Audio-Visual Nonverbal Behavior,"Cohesiveness in teams is an essential part of ensuring the smooth running of task-oriented groups. Research in social psychology and management has shown that good cohesion in groups can be correlated with team effectiveness or productivity, so automatically estimating group cohesion for team training can be a useful tool. This paper addresses the problem of analyzing group behavior within the context of cohesion. Four hours of audio-visual group meeting data were used for collecting annotations on the cohesiveness of four-participant teams. We propose a series of audio and video features, which are inspired by findings in the social sciences literature. Our study is validated on a set of 61 2-min meeting segments which showed high agreement amongst human annotators when asked to identify meetings that have high or low cohesion.","Psychology,
Management training,
Humans,
Permission,
Gold,
Productivity,
Minutes,
Performance gain,
Fellows"
On-Body Radio Channel Characterization and System-Level Modeling for Multiband OFDM Ultra-Wideband Body-Centric Wireless Network,"Given the trend towards a user-centric concept in mobile communications, body area networks have received increasing attention within the wireless personal and body area networks community. In this paper, an experimental investigation is presented to derive suitable radio propagation models for ultra wideband (UWB) body-centric wireless communications. The performance of the body-centric UWB radio channel is investigated by considering several on-body links, including different body postures. System-level modeling of potential multiband orthogonal frequency-division multiplexed UWB system has been conducted and system performance is measured using bit error rate (BER) and signal-to-noise ratio. The conducted system analysis demonstrated that for 78% in the static case and 75% and 61% for stable and unstable transmitter locations in the pseudodynamic in-motion scenarios (respectively) of the specified on-body radio links, the BER is equal to or less than 0.1%. This demonstrates promising applications of the proposed UWB body-centric radio system. Based on these results, clear recommendations are given for best on-body locations leading to optimal system performance.","Bit error rate,
Antenna measurements,
Analytical models,
Radio link,
Wireless communication,
OFDM,
Radio propagation"
Iso-Map: Energy-Efficient Contour Mapping in Wireless Sensor Networks,"Contour mapping is a crucial part of many wireless sensor network applications. Many efforts have been made to avoid collecting data from all the sensors in the network and producing maps at the sink, which is proven to be inefficient. The existing approaches (often aggregation based), however, suffer from heavy transmission traffic and incur large computational overheads on each sensor node. We propose Iso-Map, an energy-efficient protocol for contour mapping, which builds contour maps based solely on the reports collected from intelligently selected ¿isoline nodes¿ in wireless sensor networks. Iso-Map achieves high-quality contour mapping while significantly reducing the generated traffic from O(n) to O(¿n), where n is the total number of sensor nodes in the field. The pernode computation overhead is also restrained as a constant. We conduct comprehensive trace-driven simulations to verify this protocol, and demonstrate that Iso-Map outperforms the previous approaches in the sense that it produces contour maps of high fidelity with significantly reduced energy cost.","Energy efficiency,
Wireless sensor networks,
Intelligent sensors,
Telecommunication traffic,
Wireless application protocol,
Computational intelligence,
Intelligent networks,
Traffic control,
Computational modeling,
Costs"
Computer-Aided Detection of Polyps in CT Colonography Using Logistic Regression,"We present a computer-aided detection (CAD) system for computed tomography colonography that orders the polyps according to clinical relevance. The CAD system consists of two steps: candidate detection and supervised classification. The characteristics of the detection step lead to specific choices for the classification system. The candidates are ordered by a linear logistic classifier (logistic regression) based on only three features: the protrusion of the colon wall, the mean internal intensity, and a feature to discard detections on the rectal enema tube. This classifier can cope with a small number of polyps available for training, a large imbalance between polyps and non-polyp candidates, a truncated feature space, unbalanced and unknown misclassification costs, and an exponential distribution with respect to candidate size in feature space. Our CAD system was evaluated with data sets from four different medical centers. For polyps larger than or equal to 6 mm we achieved sensitivities of respectively 95%, 85%, 85%, and 100% with 5, 4, 5, and 6 false positives per scan over 86, 48, 141, and 32 patients. A cross-center evaluation in which the system is trained and tested with data from different sources showed that the trained CAD system generalizes to data from different medical centers and with different patient preparations. This is essential to application in large-scale screening for colorectal polyps.",
Low-Resolution Gait Recognition,"Unlike other biometric authentication methods, gait recognition is noninvasive and effective from a distance. However, the performance of gait recognition will suffer in the low-resolution (LR) case. Furthermore, when gait sequences are projected onto a nonoptimal low-dimensional subspace to reduce the data complexity, the performance of gait recognition will also decline. To deal with these two issues, we propose a new algorithm called superresolution with manifold sampling and backprojection (SRMS), which learns the high-resolution (HR) counterparts of LR test images from a collection of HR/LR training gait image patch pairs. Then, we incorporate SRMS into a new algorithm called multilinear tensor-based learning without tuning parameters (MTP) for LR gait recognition. Our contributions include the following: 1) With manifold sampling, the redundancy of gait image patches is remarkably decreased; thus, the superresolution procedure is more efficient and reasonable. 2) Backprojection guarantees that the learned HR gait images and the corresponding LR gait images can be more consistent. 3) The optimal subspace dimension for dimension reduction is automatically determined without introducing extra parameters. 4) Theoretical analysis of the algorithm shows that MTP converges. Experiments on the USF human gait database and the CASIA gait database show the increased efficiency of the proposed algorithm, compared with previous algorithms.",
LISP-TREE: A DNS Hierarchy to Support the LISP Mapping System,"During the last years, some operators have expressed concerns about the continued growth of the BGP routing tables in the default-free zone. Several proposed solutions for this issue are centered around the idea of separating the network node's identifier from its topological location. Among the existing proposals, the Locator/ID Separation Protocol (LISP) has seen important development and implementation effort. LISP relies on a mapping system to provide bindings between locators and identifiers. The mapping system is a critical protocol component, and its design is still an open issue. In this paper we present a new mapping system: LISP-TREE. It is based on DNS and has a similar hierarchical topology: blocks of identifiers are assigned to the levels of the hierarchy by following the current IP address allocation policies. We also present measurement-driven simulations of mapping systems' performance, assuming a deployment of LISP in the current Internet.","Servers,
Internet,
Routing,
Security,
IP networks,
Routing protocols"
Capacitive Pressure Sensor With Very Large Dynamic Range,"A new capacitive pressure sensor with very large dynamic range is introduced. The sensor is based on a new technique for substantially changing the surface area of the electrodes, rather than the inter-electrode spacing as commonly done at the present. The prototype device has demonstrated a change in capacitance of approximately 2500 pF over a pressure range of 10 kPa.","Capacitive sensors,
Dynamic range,
Electrodes,
Capacitors,
Capacitance,
Slabs,
Prototypes,
Temperature sensors,
Dielectric materials,
Ceramics"
Mutual dependence for secret key agreement,"A mutual dependence expression is established for the secret key agreement problem when all users are active. In certain source networks, the expression can be interpreted as certain notions of connectivity and network information flow. In particular, the secrecy problem can be mapped to a new class of network coding problems with selectable links and undirected broadcast links. For such networks, the secrecy capacities serve as upper bounds on the maximum network throughputs, while the network coding solutions can be used for secret key agreement.",
Joint scheduling and dynamic power spectrum optimization for wireless multicell networks,"This paper proposes a joint proportionally fair scheduling and dynamic power spectrum adaptation algorithm for wireless multicell networks. The proposed system allows multiple base-stations in a multicell network to be coordinated by exchanging interference pricing messages among each other. The messages summarize the effect of intercell interference, and they are functions of transmit power spectra, signal-to-noise ratios, direct and interfering channel gains, and the proportional fairness variables for each user. The use of interference pricing allows the transmit power spectra and user schedule within each base-station to be optimized jointly, while taking into consideration both the intercell interference and the fairness among the users in multiple cells. This paper proposes two power spectrum optimization methods, one based on the Karush-Kuhn-Tucker (KKT) condition of the optimization problem, and another based on the Newton's method. The proposed methods can achieve a throughput improvement of 40%–55% for users at the cell edge as compared to a conventional per-cell optimized system, while maintaining proportional fairness.",
A Coupled Level Set Framework for Bladder Wall Segmentation With Application to MR Cystography,"In this paper, we propose a coupled level set (LS) framework for segmentation of bladder wall using T1-weighted magnetic resonance (MR) images with clinical applications to virtual cystoscopy (i.e., MR cystography). The framework uses two collaborative LS functions and a regional adaptive clustering algorithm to delineate the bladder wall for the wall thickness measurement on a voxel-by-voxel basis. It is significantly different from most of the pre-existing bladder segmentation work in four aspects. First of all, while most previous work only segments the inner border of the wall or at most manually segments the outer border, our framework extracts both the inner and outer borders automatically except that the initial seed point is given by manual selection. Secondly, it is adaptive to T1-weighted images with decreased intensities in urine, as opposed to enhanced intensities in T2-weighted scenario and computed tomography. Thirdly, by considering the image global intensity distribution and local intensity contrast, the defined image energy function in the framework is more immune to inhomogeneity effect, motion artifacts and image noise. Finally, the bladder wall thickness is measured by the length of integral path between the two borders which mimic the electric field line between two iso-potential surfaces. The framework was tested on six datasets with comparison to the well-known Chan-Vese (C-V) LS model. Five experts blindly scored the segmented inner and outer borders of the presented framework and the C-V model. The scores demonstrated statistically the improvement in detecting the inner and outer borders.","Level set,
Bladder,
Image segmentation,
Thickness measurement,
Capacitance-voltage characteristics,
Couplings,
Magnetic resonance,
Collaborative work,
Clustering algorithms,
Computed tomography"
Design of guaranteed safe maneuvers using reachable sets: Autonomous quadrotor aerobatics in theory and practice,"For many applications, the control of a complex nonlinear system can be made easier by modeling the system as a collection of simplified hybrid modes, each representing a particular operating regime. An example of this is the decomposition of complex aerobatic flights into sequences of discrete maneuvers, an approach that has proven very successful for both human piloted and autonomously controlled aircraft. However, a critical step when designing such control systems is to ensure the safety and feasibility of transitions between these maneuvers. This work presents a hybrid dynamics framework for the design of guaranteed safe switching regions and is applied to a quadrotor helicopter performing an autonomous backflip. The regions are constructed using reachable sets calculated via a Hamilton-Jacobi differential game formulation, and experimental results are presented from flight tests on the STARMAC quadrotor platform.",
Simultaneous Arithmetic Coding and Encryption Using Chaotic Maps,"Based on the observation that iterating a skew tent map reversely is equivalent to arithmetic coding, a simultaneous compression and encryption scheme is proposed in which the chaotic map model for arithmetic coding is determined by a secret key and keeps changing. Moreover, the compressed sequence is masked by a pseudorandom keystream generated by another chaotic map. This two-level protection enhances its security level, which results in high key and plaintext sensitivities. The compression performance of our scheme is comparable with arithmetic coding and approaches Shannon's entropy limit.","Arithmetic,
Cryptography,
Chaos,
Chaotic communication,
Source coding,
Security,
Entropy,
Protection,
Transform coding,
Table lookup"
Multi-volume occupancy grids: An efficient probabilistic 3D mapping model for micro aerial vehicles,"Advancing research into autonomous micro aerial vehicle navigation requires data structures capable of representing indoor and outdoor 3D environments. The vehicle must be able to update the map structure in real time using readings from range-finding sensors when mapping unknown areas; it must also be able to look up occupancy information from the map for the purposes of localization and path-planning. Mapping models that have been used for these tasks include voxel grids, multi-level surface maps, and octrees. In this paper, we suggest a new approach to 3D mapping using a multi-volume occupancy grid, or MVOG. MVOGs explicitly store information about both obstacles and free space. This allows us to correct previous potentially erroneous sensor readings by incrementally fusing in new positive or negative sensor information. In turn, this enables extracting more reliable probabilistic information about the occupancy of 3D space. MVOGs outperform existing probabilistic 3D mapping methods in terms of memory usage, due to the fact that observations are grouped together into continuous vertical volumes to save space. We describe the techniques required for mapping using MVOGs, and analyze their performance using indoor and outdoor experimental data.","Sensors,
Three dimensional displays,
Lasers,
Probabilistic logic,
Robots,
Computational modeling,
Runtime"
Adaptive real-time video-tracking for arbitrary objects,"In this paper, we present a visual object tracker for mobile systems that is able to specialize to individual objects during tracking. The core of our method is a novel observation model and the way it is automatically adapted to a changing object and background appearance over time. The model is integrated into the well known Condensation algorithm (SIR filter) for statistical inference, and it consists of a boosted ensemble of simple threshold classifiers built upon center-surround Haar-like features, which the filter continuously updates based on the images perceived. We present optimizations and reasonable approximations to limit the computational costs. Thus, the final algorithms are capable of processing video input at real-time. To experimentally investigate the gain of adapting the observation model we compare two different approaches with a non-adapting version of our observation model: maintaining a single observation model for all particles, and maintaining individual observation models for each particle. In addition, experiments were conducted to compare system performances between the proposed algorithms and two other state of the art Condensation based tracking approaches.","Adaptation model,
Computational modeling,
Histograms,
Training,
Target tracking,
Real time systems,
Image color analysis"
Probabilistic Model-Based Diagnosis: An Electrical Power System Case Study,"We present in this paper a case study of the probabilistic approach to model-based diagnosis. Here, the diagnosed system is a real-world electrical power system (EPS), i.e., the Advanced Diagnostic and Prognostic Testbed (ADAPT) located at the NASA Ames Research Center. Our probabilistic approach is formally well founded and based on Bayesian networks (BNs) and arithmetic circuits (ACs). We pay special attention to meeting two of the main challenges often associated with real-world application of model-based diagnosis technologies: model development and real-time reasoning. To address the challenge of model development, we develop a systematic approach to representing EPSs as BNs, supported by an easy-to-use specification language. To address the real-time reasoning challenge, we compile BNs into ACs. AC evaluation (ACE) supports real-time diagnosis by being predictable, fast, and exact. In experiments with the ADAPT BN, which contains 503 discrete nodes and 579 edges and produces accurate results, the time taken to compute the most probable explanation using ACs has a mean of 0.2625 ms and a standard deviation of 0.2028 ms. In comparative experiments, we found that, while the variable elimination and join tree propagation algorithms also perform very well in the ADAPT setting, ACE was an order of magnitude or more faster.",
Virtual Backoff Algorithm: An Enhancement to 802.11 Medium-Access Control to Improve the Performance of Wireless Networks,"This paper presents a scheme, called the virtual backoff algorithm (VBA), which is based on the sequencing technique for efficient medium-access control. The proposed method minimizes the number of collisions while reducing the delays that occur during the backoff periods. We present an analytical study on MAC-layer issues, which are very important when accessing a channel over wireless networks. The VBA scheme uses fair distributed mechanisms to access a channel. We introduce a counter at each node to maintain the discipline of the nodes. The performance of the proposed method is evaluated under various conditions, and the obtained results are very promising. The enhanced protocol improves the utilization of bandwidth by increasing the throughput up to 75%, and the amount of collisions is reduced to 65% when compared with legacy protocols. The proposed scheme shows that the energy requirements are minimum due to the limitation on the number of transmissions.",
Decision Diagram Based Methods and Complexity Analysis for Multi-State Systems,"Decision diagrams are graphical structures based on Shannon's decomposition. They have been extensively used for representing and manipulating logic functions in areas such as circuit verification, compact Markov chain representation, and symbolic model checking. However, their applicability in reliability modeling and analysis has only been recently studied. Moreover, the study had been mostly restricted to binary-state systems in which both the system and its components are either operational, or failed. Nevertheless, many practical systems are multi-state systems (MSS) in which both the system and its components may reside at multiple (more than two) performance levels (or states), varying from perfect operation to complete failure. This paper presents three forms of decision diagrams for the modeling and analysis of MSS: binary decision diagrams, logarithmically encoded binary decision diagrams, and multi-valued decision diagrams. We present both separated, and shared methods based on these decision diagrams. Comprehensive complexity analysis, and performance comparisons among these methods, are conducted with both mathematical, and empirical approaches.","Data structures,
Boolean functions,
Binary decision diagrams,
Computer science,
Multivalued logic,
Logic functions,
Circuits,
Performance analysis,
Microelectronics,
Computer industry"
Enhanced Plasma Wave Detection of Terahertz Radiation Using Multiple High Electron-Mobility Transistors Connected in Series,"We report on enhanced room-temperature detection of terahertz radiation by several connected field-effect transistors. For this enhanced nonresonant detection, we have designed, fabricated, and tested plasmonic structures consisting of multiple InGaAs/GaAs pseudomorphic high electron-mobility transistors connected in series. Results show a 1.63-THz response that is directly proportional to the number of detecting transistors biased by a direct drain current at the same gate-to-source bias voltages. The responsivity in the saturation regime was found to be 170 V/W with the noise equivalent power in the range of 10-7 W/Hz0.5. The experimental data are in agreement with the detection mechanism based on the rectification of overdamped plasma waves excited by terahertz radiation in the transistor channel.",
Output Feedback Fuzzy Controller Design With Local Nonlinear Feedback Laws for Discrete-Time Nonlinear Systems,"This paper considers the output feedback control problem for nonlinear discrete-time systems, which are represented by a type of fuzzy systems with local nonlinear models. By using the estimations of the states and nonlinear functions in local models, sufficient conditions for designing observer-based controllers are given for discrete-time nonlinear systems. First, a separation property, i.e., the controller and the observer can be independently designed, is proved for the class of fuzzy systems. Second, a two-step procedure with cone complementarity linearization algorithms is also developed for solving the H∞ dynamic output feedback (DOF) control problem. Moreover, for the case where the nonlinear functions in local submodels are measurable, a convex condition for designing H∞ controllers is given by a new DOF control scheme. In contrast to the existing methods, the new methods can design output feedback controllers with fewer fuzzy rules as well as less computational burden, which is helpful for controller designs and implementations. Lastly, numerical examples are given to illustrate the effectiveness of the proposed methods.",
Road Extraction From Satellite Images Using Particle Filtering and Extended Kalman Filtering,"Extended Kalman filter (EKF) has previously been employed to extract road maps in satellite images. This filter traces a single road until a stopping criterion is satisfied. In our new approach, we have combined EKF with a special particle filter (PF) in order to regain the trace of the road beyond obstacles, as well as to find and follow different road branches after reaching to a road junction. In this approach, first, EKF traces a road until a stopping criterion is met. Then, instead of terminating the process, the results are passed to the PF algorithm which tries to find the continuation of the road after a possible obstacle or to identify all possible road branches that might exist on the other side of a road junction. For further improvement, we have modified the procedure for obtaining the measurements by decoupling this process from the current state prediction of the filter. Removing the dependence of the measurement data to the predicted state reduces the potential for instability of the road-tracing algorithm. Furthermore, we have constructed a method for dynamic clustering of the road profiles in order to maintain tracking when the road profile undergoes some variations due to changes in the road width and intensity.",
Discontinuous Map Analysis of a DC-DC Converter Governed by Pulse Skipping Modulation,"This paper reports the bifurcation phenomena in a dc-dc converter governed by a pulse skipping modulation (PSM) scheme, which is normally used to improve efficiency under light load condition. It is shown that the discrete-time model of the system takes the form of a discontinuous map, where the discrete-time state space is piecewise smooth, divided into five regions, each with a different functional form and separated by four borderlines. One additional borderline is considered to identify an infeasible region during a PSM operation. For a restricted operating region, we show that the system is described by a one-dimensional discontinuous map; otherwise it is a combination 1-D and 2-D forms. We derive the conditions for the existence and stability of different periodic orbits. We observe a period-adding cascade in which the periodicity varies non-monotonically exhibiting abrupt changes in the spectral composition for a smooth parameter variation. The proposed method may be useful for modeling and analysis of other dc-dc converter topologies governed by a PSM operation.",
Phero-trail: a bio-inspired location service for mobile underwater sensor networks,"A SEA Swarm (Sensor Equipped Aquatic Swarm) is a collection of mobile underwater sensors that moves as a group with water current and enables 4D (space and time) monitoring of local underwater events such as contaminants and intruders. For prompt alert reporting, mobile sensors routes events to mobile sinks (i.e., autonomous underwater vehicles) via geographic routing that is known to be most efficient under mobility and scarce acoustic bandwidth. In order for a packet to be routed to the destination using geographical routing, it requires to know the location of the destination. This is accomplished by having a location service that returns the location of a requested node. Our goal is to design such location service for SEA Swarm. In this paper, we analyze various design choices to realize an efficient location service in SEA Swarm scenarios. We find that conventional ad hoc network location service protocols cannot be directly used, because the entire swarm moves along water current. We prove that maintaining location information in a 2D plane is a better design choice. Given this, we propose a bio-inspired location service called a Phero-Trail location service protocol. In Phero-Trail, location information is stored in a 2D upper hull of a SEA Swarm, and a mobile sink uses its trajectory (a la a pheromone trail of ants) projected to the 2D hull to maintain location information. This enables mobile sensors to efficiently locate a mobile sink. Our results show that Phero- Trail performs better than existing approaches.","Biosensors,
Monitoring,
Underwater vehicles,
Acoustic sensors,
Routing,
Sea surface,
Underwater acoustics,
Bandwidth,
Protocols,
Computer science"
Using Relational Topic Models to capture coupling among classes in object-oriented software systems,"Coupling metrics capture the degree of interaction and relationships among source code elements in software systems. A vast majority of existing coupling metrics rely on structural information, which captures interactions such as usage relations between classes and methods or execute after associations. However, these metrics lack the ability to identify conceptual dependencies, which, for instance, specify underlying relationships encoded by developers in identifiers and comments of source code classes. We propose a new coupling metric for object-oriented software systems, namely Relational Topic based Coupling (RTC) of classes, which uses Relational Topic Models (RTM), generative probabilistic model, to capture latent topics in source code classes and relationships among them. A case study on thirteen open source software systems is performed to compare the new measure with existing structural and conceptual coupling metrics. The case study demonstrates that proposed metric not only captures new dimensions of coupling, which are not covered by the existing coupling metrics, but also can be used to effectively support impact analysis.",
The 2009 Mario AI Competition,"This paper describes the 2009 Mario AI Competition, which was run in association with the IEEE Games Innovation Conference and the IEEE Symposium on Computational Intelligence and Games. The focus of the competition was on developing controllers that could play a version of Super Mario Bros as well as possible. We describe the motivations for holding this competition, the challenges associated with developing artificial intelligence for platform games, the software and API developed for the competition, the competition rules and organization, the submitted controllers and the results. We conclude the paper by discussing what the outcomes of the competition can teach us both about developing platform game AI and about organizing game AI competitions. The first two authors are the organizers of the competition, while the third author is the winner of the competition.",
Layered Graph Matching with Composite Cluster Sampling,"This paper presents a framework of layered graph matching for integrating graph partition and matching. The objective is to find an unknown number of corresponding graph structures in two images. We extract discriminative local primitives from both images and construct a candidacy graph whose vertices are matching candidates (i.e., a pair of primitives) and whose edges are either negative for mutual exclusion or positive for mutual consistence. Then we pose layered graph matching as a multicoloring problem on the candidacy graph and solve it using a composite cluster sampling algorithm. This algorithm assigns some vertices into a number of colors, each being a matched layer, and turns off all the remaining candidates. The algorithm iterates two steps: 1) Sampling the positive and negative edges probabilistically to form a composite cluster, which consists of a few mutually conflicting connected components (CCPs) in different colors and 2) assigning new colors to these CCPs with consistence and exclusion relations maintained, and the assignments are accepted by the Markov Chain Monte Carlo (MCMC) mechanism to preserve detailed balance. This framework demonstrates state-of-the-art performance on several applications, such as multi-object matching with large motion, shape matching and retrieval, and object localization in cluttered background.","Sampling methods,
Shape,
Image sampling,
Clustering algorithms,
Image segmentation,
Layout,
Stereo vision,
Monte Carlo methods,
Application software,
Computer vision"
SamACO: Variable Sampling Ant Colony Optimization Algorithm for Continuous Optimization,"An ant colony optimization (ACO) algorithm offers algorithmic techniques for optimization by simulating the foraging behavior of a group of ants to perform incremental solution constructions and to realize a pheromone laying-and-following mechanism. Although ACO is first designed for solving discrete (combinatorial) optimization problems, the ACO procedure is also applicable to continuous optimization. This paper presents a new way of extending ACO to solving continuous optimization problems by focusing on continuous variable sampling as a key to transforming ACO from discrete optimization to continuous optimization. The proposed SamACO algorithm consists of three major steps, i.e., the generation of candidate variable values for selection, the ants' solution construction, and the pheromone update process. The distinct characteristics of SamACO are the cooperation of a novel sampling method for discretizing the continuous search space and an efficient incremental solution construction method based on the sampled values. The performance of SamACO is tested using continuous numerical functions with unimodal and multimodal features. Compared with some state-of-the-art algorithms, including traditional ant-based algorithms and representative computational intelligence algorithms for continuous optimization, the performance of SamACO is seen competitive and promising.",
Compact Modeling of Nonlinear Analog Circuits Using System Identification via Semidefinite Programming and Incremental Stability Certification,"This paper presents a system identification technique for generating stable compact models of typical analog circuit blocks in radio frequency systems. The identification procedure is based on minimizing the model error over a given training data set subject to an incremental stability constraint, which is formulated as a semidefinite optimization problem. Numerical results are presented for several analog circuits, including a distributed power amplifier, as well as a MEM device. It is also shown that our dynamical models can accurately predict important circuit performance metrics, and may thus, be useful for design optimization of analog systems.","Analog circuits,
System identification,
Circuit stability,
Certification,
Power system modeling,
Radio frequency,
Radiofrequency identification,
Training data,
Constraint optimization,
Distributed amplifiers"
Experimental Demonstration of Fanout for Nanomagnetic Logic,"Nanomagnet logic (NML) shows great promise as an alternative to conventional digital architectures. We present the first experimental demonstration of fanout using magnetizations of nanomagnets in the NML scheme. Specifically, we show magnetic force microscopy images of functioning fanout circuits.",
Load identification in nonintrusive load monitoring using steady-state and turn-on transient energy algorithms,"Non-intrusive load monitoring (NILM) techniques are based on the analysis of load energy signatures. With characterizing associated transient energy signature, the reliability and accuracy of recognition results can be accurately understood or ascertained. In this study, the computer supported cooperative work techniques (CSCW), artificial neural networks (ANN), in combination with turn-on transient energy analysis, are used to identify loads and to improve recognition accuracy and computational speed of NILM results. The experimental results indicated that the incorporation of turn-on transient energy signature analysis into NILM revealed more information than traditional NILM methods, and the resulting recognition accuracy and computational speed were improved. In addition, in combination with computer supported cooperative work in electromagnetic transient program (EMTP) simulation, calculations of turn-on transient energy facilitated load identification that had significant effect on NILM results.","Steady-state,
Transient analysis,
Computerized monitoring,
Computer networks,
Collaborative work,
Artificial neural networks,
Electromagnetic transients,
EMTP,
Computer network reliability,
Character recognition"
RRED: robust RED algorithm to counter low-rate denial-of-service attacks,"The existing Random Early Detection (RED) algorithm and its variants are found vulnerable to emerging attacks, especially the Low-rate Denial-of-Service (LDoS) attacks. In this letter we propose a Robust RED (RRED) algorithm to improve the TCP throughput against LDoS attacks. The basic idea behind the RRED is to detect and filter out attack packets before a normal RED algorithm is applied to incoming flows. We conduct a set of simulations to evaluate the performance of the proposed RRED algorithm. The results show that, compared to existing RED-like algorithms, the RRED algorithm nearly fully preserves the TCP throughput in the presence of LDoS attacks.",
Boosting Through Optimization of Margin Distributions,"Boosting has been of great interest recently in the machine learning community because of the impressive performance for classification and regression problems. The success of boosting algorithms may be interpreted in terms of the margin theory. Recently, it has been shown that generalization error of classifiers can be obtained by explicitly taking the margin distribution of the training data into account. Most of the current boosting algorithms in practice usually optimize a convex loss function and do not make use of the margin distribution. In this brief, we design a new boosting algorithm, termed margin-distribution boosting (MDBoost), which directly maximizes the average margin and minimizes the margin variance at the same time. This way the margin distribution is optimized. A totally corrective optimization algorithm based on column generation is proposed to implement MDBoost. Experiments on various data sets show that MDBoost outperforms AdaBoost and LPBoost in most cases.",
Towards Timbre-Invariant Audio Features for Harmony-Based Music,"Chroma-based audio features are a well-established tool for analyzing and comparing harmony-based Western music that is based on the equal-tempered scale. By identifying spectral components that differ by a musical octave, chroma features possess a considerable amount of robustness to changes in timbre and instrumentation. In this paper, we describe a novel procedure that further enhances chroma features by significantly boosting the degree of timbre invariance without degrading the features' discriminative power. Our idea is based on the generally accepted observation that the lower mel-frequency cepstral coefficients (MFCCs) are closely related to timbre. Now, instead of keeping the lower coefficients, we discard them and only keep the upper coefficients. Furthermore, using a pitch scale instead of a mel scale allows us to project the remaining coefficients onto the 12 chroma bins. We present a series of experiments to demonstrate that the resulting chroma features outperform various state-of-the art features in the context of music matching and retrieval applications. As a final contribution, we give a detailed analysis of our enhancement procedure revealing the musical meaning of certain pitch-frequency cepstral coefficients.","Timbre,
Cepstral analysis,
Discrete cosine transforms,
Robustness,
Instruments,
Music information retrieval,
Boosting,
Degradation,
Art,
Mel frequency cepstral coefficient"
Constructing low-connectivity and full-coverage three dimensional sensor networks,"Low-connectivity and full-coverage three dimensional Wireless Sensor Networks (WSNs) have many real-world applications. By low connectivity, we mean there are at least k disjoint paths between any two sensor nodes in a WSN, where k ≤ 4. In this paper, we design a set of patterns to achieve 1-, 2-, 3- and 4-connectivity and full-coverage, and prove their optimality under any value of the ratio of communication range rc over sensing range rs, among regular lattice deployment patterns. We further investigate the evolutions among all the proposed low-connectivity patterns. Finally, we study the proposed patterns under several practical settings.",
A New Method for Complete Stability Analysis of Cellular Neural Networks With Time Delay,"This paper presents new complete stability results for delayed cellular neural networks (DCNNs). A novel method is proposed for complete stability analysis of DCNNs. By applying the M-matrix theory and introducing some new estimation techniques on the solutions of DCNNs, a simple and improved complete stability criterion is derived. The new criterion unifies the delay-dependent and delay-independent complete stability conditions for DCNNs. Moreover, the obtained delay-dependent criterion can give a larger upper bound of the time delay than the existing ones such that the complete stability can still be retained. Numerical examples are presented which show that the new complete stability results for DCNNs are compared favorably with the existing results.","Stability analysis,
Cellular neural networks,
Delay effects,
Neural networks,
Stability criteria,
Upper bound,
Australia,
Mathematics,
Image processing,
Asymptotic stability"
A Contamination Aware Droplet Routing Algorithm for the Synthesis of Digital Microfluidic Biochips,"Recent advances of digital microfluidic biochips (DMFBs) have revolutionized the traditional laboratory procedures. By providing the droplet-based system, DMFB can perform real-time biological analysis and safety-critical biomedical applications. However, different droplets being transported and manipulated on the DMFB may introduce the contamination problem caused by liquid residue between different biomolecules. To overcome this problem, a wash droplet is introduced to clean the contaminations on the surface of the microfluidic array. However, current scheduling of wash droplet does not restrict the extra used cells and execution time of bioassay, thereby degrading the reliability and fault-tolerance significantly. In this paper, we propose a contamination aware droplet routing algorithm for DMFBs. To reduce the routing complexity and the used cells, we first construct preferred routing tracks by analyzing the global moving vector of droplets to guide the droplet routing. To cope with contaminations within one subproblem, we first apply a k -shortest path routing technique to minimize the contaminated spots. Then, to take advantage of multiple wash droplets, we adopt a minimum cost circulation (MCC) algorithm for optimal wash-droplet routing to simultaneously minimize used cells and the cleaning time. Since the droplet routing problem consists of several subproblems, a look-ahead prediction technique is further used to determine the contaminations between successive subproblems. After that, we can simultaneously clean both contaminations within one subproblem and those between successive subproblems by using the MCC-based algorithm to reduce the execution time and the used cells significantly. Based on four widely used bioassays, our algorithm reduces the used cells and the execution time significantly compared with the state-of-the-art algorithm.",
Beyond active noun tagging: Modeling contextual interactions for multi-class active learning,"We present an active learning framework to simultaneously learn appearance and contextual models for scene understanding tasks (multi-class classification). Existing multi-class active learning approaches have focused on utilizing classification uncertainty of regions to select the most ambiguous region for labeling. These approaches, however, ignore the contextual interactions between different regions of the image and the fact that knowing the label for one region provides information about the labels of other regions. For example, the knowledge of a region being sea is informative about regions satisfying the “on” relationship with respect to it, since they are highly likely to be boats. We explicitly model the contextual interactions between regions and select the question which leads to the maximum reduction in the combined entropy of all the regions in the image (image entropy). We also introduce a new methodology of posing labeling questions, mimicking the way humans actively learn about their environment. In these questions, we utilize the regions linked to a concept with high confidence as anchors, to pose questions about the uncertain regions. For example, if we can recognize water in an image then we can use the region associated with water as an anchor to pose questions such as “what is above water?”. Our active learning framework also introduces questions which help in actively learning contextual concepts. For example, our approach asks the annotator: “What is the relationship between boat and water?” and utilizes the answer to reduce the image entropies throughout the training dataset and obtain more relevant training examples for appearance models.","Tagging,
Context modeling,
Entropy,
Labeling,
Boats,
Humans,
Layout,
Uncertainty,
Computer science,
Educational institutions"
Penalized Preimage Learning in Kernel Principal Component Analysis,"Finding the preimage of a feature vector in kernel principal component analysis (KPCA) is of crucial importance when KPCA is applied in some applications such as image preprocessing. Since the exact preimage of a feature vector in the kernel feature space, normally, does not exist in the input data space, an approximate preimage is learned and encouraging results have been reported in the last few years. However, it is still difficult to find a ""good"" estimation of preimage. As estimation of preimage in kernel methods is ill-posed, how to guide the preimage learning for a better estimation is important and still an open problem. To address this problem, a penalized strategy is developed in this paper, where some penalization terms are used to guide the preimage learning process. To develop an efficient penalized technique, we first propose a two-step general framework, in which a preimage is directly modeled by weighted combination of the observed samples and the weights are learned by some optimization function subject to certain constraints. Compared to existing techniques, this would also give advantages in directly turning preimage learning into the optimization of the combination weights. Under this framework, a penalized methodology is developed by integrating two types of penalizations. First, to ensure learning a well-defined preimage, of which each entry is not out of data range, convexity constraint is imposed for learning the combination weights. More insight effects of the convexity constraint are also explored. Second, a penalized function is integrated as part of the optimization function to guide the preimage learning process. Particularly, the weakly supervised penalty is proposed, discussed, and extensively evaluated along with Laplacian penalty and ridge penalty. It could be further interpreted that the learned preimage can preserve some kind of pointwise conditional mutual information. Finally, KPCA with preimage learning is applied on face image data sets in the aspects of facial expression normalization, face image denoising, recovery of missing parts from occlusion, and illumination normalization. Experimental results show that the proposed preimage learning algorithm obtains lower mean square error (MSE) and better visual quality of reconstructed images.",
Tracking Vertex Flow and Model Adaptation for Three-Dimensional Spatiotemporal Face Analysis,"Research in the areas of 3-D face recognition and 3-D facial expression analysis has intensified in recent years. However, most research has been focused on 3-D static data analysis. In this paper, we investigate the facial analysis problem using dynamic 3-D face model sequences. One of the major obstacles for analyzing such data is the lack of correspondences of features due to the variable number of vertices across individual models or 3-D model sequences. In this paper, we present an effective approach for establishing vertex correspondences using a tracking-model-based approach for vertex registration, coarse-to-fine model adaptation, and vertex motion trajectory (called vertex flow) estimation. We propose to establish correspondences across frame models based on a 2-D intermediary, which is generated using conformal mapping and a generic model adaptation algorithm. Based on our newly created 3-D dynamic face database, we also propose to use a spatiotemporal hidden Markov model (ST-HMM) that incorporates 3-D surface feature characterization to learn the spatial and temporal information of faces. The advantage of using 3-D dynamic data for face recognition has been evaluated by comparing our approach to three conventional approaches: 2-D-video-based temporal HMM model, conventional 2-D-texture-based approach (e.g., Gabor-wavelet-based approach), and static 3-D-model-based approaches. To further evaluate the usefulness of vertex flow and the adapted model, we have also applied a spatial-temporal face model descriptor for facial expression classification based on dynamic 3-D model sequences.","Adaptation model,
Spatiotemporal phenomena,
Hidden Markov models,
Face recognition,
Data analysis,
Tracking,
Trajectory,
Motion estimation,
Conformal mapping,
Spatial databases"
Asymmetric Quantum Codes: Characterization and Constructions,"The stabilizer method for constructing a class of asymmetric quantum codes (AQC), called additive AQC, has been established by Aly et.al. In this paper, we present a new characterization of AQC, which generalizes a result of the symmetric case known previously. As an application of the characterization, we establish a relationship of AQC with classical error-correcting codes and show a few examples of good AQC with specific parameters. By using this relationship, we obtain an asymptotic bound on AQCs from algebraic geometry codes.","Error correction codes,
Geometry,
Quantum computing,
Quantum mechanics,
Computer errors,
Chaos,
Convolutional codes,
Fault tolerance,
Information theory,
Galois fields"
Adaptive Input-Power Distribution in Doherty Power Amplifiers for Linearity and Efficiency Enhancement,"A new technique based on an adaptive input-power distribution is introduced to overcome the limitations of practical Doherty power amplifiers. The proposed Doherty amplifier employs an extended-resonance power-divider at its input. By taking advantage of the auxiliary cell's nonlinear input impedance, the extended-resonance divider is designed such that it provides a proper power-dependent power-division between the main and auxiliary cells. Therefore, the two cells are efficiently driven and can generate output current and voltage characteristics similar to the ideal Doherty amplifier, resulting in both linearity and efficiency improvements. The performance of the new Doherty amplifier is compared with a conventional design through simulations and measurements. The proposed Doherty amplifier achieves a measured ACLR improvement of 5-7 dB over a wide range of output power levels, as well as an increased power-added-efficiency of up to 5% for WCDMA signals. The proposed Doherty design does not require complex circuitry and yields a compact circuit.",
Dynamic legged robots for rough terrain,"Only about half the Earth's landmass is accessible to wheeled and tracked vehicles, yet people and animals can go almost everywhere on foot. Our goal is to harness the power of legs to create robot vehicles that can go where legged animals and people can go. These systems combine dynamic control systems, actuated mechanisms and a variety of sensors to travel on rough terrain that is too rocky, sandy, muddy, snowy and wet for existing conventional vehicles. Raibert will talk about progress at Boston Dynamics in building such systems, including BigDog, PETMAN, LS3 and others.",
Exploiting Internal Parallelism of Flash-based SSDs,"For the last few years, the major driving force behind the rapid performance improvement of SSDs has been the increment of parallel bus channels between a flash controller and flash memory packages inside the solid-state drives (SSDs). However, there are other internal parallelisms inside SSDs yet to be explored. In order to improve performance further by utilizing the parallelism, this paper suggests request rescheduling and dynamic write request mapping. Simulation results with real workloads have shown that the suggested schemes improve the performance of the SSDs by up to 15% without any additional hardware support.",
Learning to Represent Spatial Transformations with Factored Higher-Order Boltzmann Machines,"To allow the hidden units of a restricted Boltzmann machine to model the transformation between two successive images, Memisevic and Hinton (2007) introduced three-way multiplicative interactions that use the intensity of a pixel in the first image as a multiplicative gain on a learned, symmetric weight between a pixel in the second image and a hidden unit. This creates cubically many parameters, which form a three-dimensional interaction tensor. We describe a low-rank approximation to this interaction tensor that uses a sum of factors, each of which is a three-way outer product. This approximation allows efficient learning of transformations between larger image patches. Since each factor can be viewed as an image filter, the model as a whole learns optimal filter pairs for efficiently representing transformations. We demonstrate the learning of optimal filter pairs from various synthetic and real image sequences. We also show how learning about image transformations allows the model to perform a simple visual analogy task, and we show how a completely unsupervised network trained on transformations perceives multiple motions of transparent dot patterns in the same way as humans.",
A Two-Stage Dynamic Model for Visual Tracking,"We propose a new dynamic model which can be used within blob trackers to track the target's center of gravity. A strong point of the model is that it is designed to track a variety of motions which are usually encountered in applications such as pedestrian tracking, hand tracking, and sports. We call the dynamic model a two-stage dynamic model due to its particular structure, which is a composition of two models: a liberal model and a conservative model. The liberal model allows larger perturbations in the target's dynamics and is able to account for motions in between the random-walk dynamics and the nearly constant-velocity dynamics. On the other hand, the conservative model assumes smaller perturbations and is used to further constrain the liberal model to the target's current dynamics. We implement the two-stage dynamic model in a two-stage probabilistic tracker based on the particle filter and apply it to two separate examples of blob tracking: 1) tracking entire persons and 2) tracking of a person's hands. Experiments show that, in comparison to the widely used models, the proposed two-stage dynamic model allows tracking with smaller number of particles in the particle filter (e.g., 25 particles), while achieving smaller errors in the state estimation and a smaller failure rate. The results suggest that the improved performance comes from the model's ability to actively adapt to the target's motion during tracking.","Target tracking,
Particle tracking,
Particle filters,
Uncertainty,
Gravity,
State estimation,
Information science,
Humans,
Computer vision,
Computer interfaces"
Real-time tracking of multiple occluding objects using level sets,"We derive a probabilistic framework for robust, realtime, visual tracking of multiple previously unseen objects from a moving camera. This framework models the discrete depth ordering of the objects being tracked in the scene. The method uses the observed image data to compute a posterior over the objects' poses, shapes and relative depths. The poses are group transformations, the shapes are implicit contours represented using level-sets and the relative depths give the discrete depth ordering of the objects. All nuisance variables are marginalised out at the pixel-level resulting in a pixel-wise posterior, as opposed to a pixel-wise likelihood, and we show using quantitative results that this provides increased resilience to noise. We also demonstrate how motion models can be incorporated within the same probabilistic framework and show how this enables the system to track complete occlusions. The effectiveness of our method is demonstrated on a variety of challenging video sequences.","Level set,
Shape,
Resilience,
Layout,
Particle tracking,
Filtering,
Robustness,
Cameras,
Video sequences,
Application software"
High-Dimensional Neural-Network Technique and Applications to Microwave Filter Modeling,"Neural networks are useful for developing fast and accurate parametric model of electromagnetic (EM) structures. However, existing neural-network techniques are not suitable for developing models that have many input variables because data generation and model training become too expensive. In this paper, we propose an efficient neural-network method for EM behavior modeling of microwave filters that have many input variables. The decomposition approach is used to simplify the overall high-dimensional neural-network modeling problem into a set of low-dimensional sub-neural-network problems. By incorporating the knowledge of filter decomposition with neural-network decomposition, we formulate a set of neural-network submodels to learn filter subproblems. A new method to combine the submodels with a filter empirical/equivalent model is developed. An additional neural-network mapping model is formulated with the neural-network submodels and empirical/equivalent model to produce the final overall filter model. An H -plane waveguide filter model and a side-coupled circular waveguide dual-mode filter model are developed using the proposed method. The result shows that with a limited amount of data, the proposed method can produce a much more accurate high-dimensional model compared to the conventional neural-network method and the resulting model is much faster than an EM model.",
Ultracompact TM-Pass Silicon Nanophotonic Waveguide Polarizer and Design,"An ultracompact transverse magnetic (TM)-pass polarizer based on silicon nanophotonic waveguides is proposed, which contains two tapered waveguides sandwiching a narrow waveguide section only supporting TM-mode propagation. A full-vectorial eigenmode solver is employed to determine the appropriate cross section of the silicon nanophotonic waveguide. The device is first designed in a 2-D approximate model using a wide-angle beam propagation method, and numerical verification is carried out afterward using a parallel full-vectorial 3-D finite-difference time-domain simulation. Both approaches indicate that the finite thickness of the buried SiO2 layerand the reflection at the substrate play important roles on the extinction ratio of the device. A designed numerical example shows an extinction ratio of ~26 dB for the waveguide polarizer with a length of ~10 ¿m, while the insertion loss for the TM mode is negligible.","Silicon,
Optical waveguides,
Optical propagation,
Optical polarization,
Extinction ratio,
Photonics,
Time domain analysis,
Nanoscale devices,
Optical sensors,
Tellurium"
Application of Classical Hermitian Self-Orthogonal MDS Codes to Quantum MDS Codes,"In this paper, we first construct several classes of classical Hermitian self-orthogonal maximum distance separable (MDS) codes. Through these classical codes, we are able to obtain various quantum MDS codes. It turns out that many of our quantum codes are new in the sense that the parameters of our quantum codes cannot be obtained from all previous constructions.","Geometry,
Error correction codes,
Chaos,
Protection,
Hilbert space,
Mathematics,
Quantum mechanics,
Information theory,
Computer errors"
Coupled graphical models and their thresholds,"The excellent performance of convolutional low-density parity-check codes is the result of the spatial coupling of individual underlying codes across a window of growing size, but much smaller than the length of the individual codes. Remarkably, the belief-propagation threshold of the coupled ensemble is boosted to the maximum-a-posteriori one of the individual system. We investigate the generality of this phenomenon beyond coding theory: we couple general graphical models into a one-dimensional chain of large individual systems. For the later we take the Curie-Weiss, random field Curie-Weiss, If-satisfiability, and Q-coloring models. We always find, based on analytical as well as numerical calculations, that the message passing thresholds of the coupled systems come very close to the static ones of the individual models. The remarkable properties of convolutional low-density parity-check codes are a manifestation of this very general phenomenon.","Mathematical model,
Equations,
Parity check codes,
Couplings,
Convolutional codes,
Magnetization,
Entropy"
Computing the Lattice of All Fixpoints of a Fuzzy Closure Operator,"We present a fast bottom-up algorithm to compute all fixpoints of a fuzzy closure operator in a finite set over a finite chain of truth degrees, along with the partial order on the set of all fixpoints. Fuzzy closure operators appear in several areas of fuzzy logic and its applications, including formal concept analysis (FCA) that we use as a reference area of application in this paper. Several problems in FCA, such as computing all formal concepts from data with graded attributes or computing non-redundant bases of all attribute dependencies, can be reduced to the problem of computing fixpoints of particular fuzzy closure operators associated with the input data. The development of a general algorithm that is applicable, in particular, to these problems is the ultimate purpose of this paper. We present the algorithm, its theoretical foundations, and experimental evaluation.","Lattices,
Fuzzy logic,
Fuzzy sets,
Mathematics,
Equations,
Computer science,
Fuzzy reasoning,
Industrial engineering,
Biometrics,
Process control"
Planning active cannula configurations through tubular anatomy,"Medical procedures such as lung biopsy and brachytherapy require maneuvering through tubular structures such as the trachea and bronchi to reach clinical targets. We introduce a new method to plan configurations for active cannulas, medical devices composed of thin, pre-curved, telescoping lumens that are capable of following controlled, curved paths through open or liquid-filled cavities. Planning optimal configurations for these devices is challenging due to their complex kinematics, which involve both beam mechanics and space curves. In this paper, we propose an optimization-based planning algorithm that computes active cannula configurations through tubular structures that reach specified targets. Given the target location, the start position and orientation, and a geometric representation of the physical environment extracted from pre-procedure medical images, the planner optimizes insertion length and orientation angle of each lumen of the active cannula. The planner models active cannula kinematics using a physically-based simulation that incorporates beam mechanics and minimizes energy. The algorithm typically computes plans in less than 2 minutes on a standard PC. We apply the method in simulation to anatomy extracted from a human CT scan and demonstrate configurations for a 5-lumen active cannula that maneuver it through the bronchi to targets in the lung.",
Silver chalcogenide based memristor devices,"We have fabricated two-terminal chalcogenide-based devices containing Ge2Se3 and Ag that function as memristors. These devices have been electrically characterized at room temperature using quasi-static DC methods, AC sinusoidal methods, and AC pulse testing methods. In all cases, the devices exhibit memristive behavior.","Resistance,
Memristors,
Electrodes,
Programming,
Materials,
Threshold voltage,
Temperature measurement"
Asymmetrical Round Trip Based Synchronization-Free Localization in Large-Scale Underwater Sensor Networks,"Underwater sensor networks (UWSNs) have been proposed for many location-dependent applications such as oceanographic data collection, pollution monitoring, mine reconnaissance, etc. Accurate node localization plays an important role in realizing the potential gains of these applications. Although many localization algorithms have been proposed for terrestrial sensor networks in recent years, it is not feasible to directly use these algorithms in UWSNs since UWSNs lack a fast and reliable communication channel. Further, due to their slow convergence speeds and high communication overhead, distributed localization algorithms designed for small-scale UWSNs are not practical for large-scale underwater sensor systems. To achieve accurate and energy efficient node localization in large-scale UWSNs, an asymmetrical round trip based localization (ARTL) algorithm is proposed in this paper. This algorithm has low computational complexity and excellent scalability. Without time synchronization, this algorithm can achieve highly accurate ranging in large-scale UWSNs. Simulation results demonstrate the effectiveness of our design in terms of both localization accuracy and energy consumption.",
Nonlinear Control of FACTS Controllers for Damping Interarea Oscillations in Power Systems,"This paper introduces a new nonlinear control of flexible ac transmission systems (FACTS) controllers for the purpose of damping interarea oscillations in power systems. FACTS controllers consist of series, shunt, or a combination of series-shunt devices which are interfaced with the bulk power system through injection buses. Controlling the angle of these buses can effectively damp low frequency interarea oscillations in the system. The proposed control method is based on finding an equivalent reduced affine nonlinear system for the network from which the dominant machines are extracted based on dynamic coherency. It is shown that if properly selected, measurements obtained from this subsystem of machines are sufficient inputs to the FACTS controllers to stabilize the power system. The effectiveness of the proposed method on damping interarea oscillations is validated on the 68 bus, 16 generator system of the New England/New York network.",
Local positioning for environmental monitoring in wireless sensor and actor networks,"Location estimation of sensor nodes is an essential part of most applications for wireless sensor and actor networks (WSAN). The ambiguous location information often makes the collected data useless in these applications. Environmental monitoring in particular, relies on an accurate position estimation in order to process or evaluate the collected data. In this paper, we present a novel and scalable approach for positioning of mobile sensor nodes with the goal of monitoring the Amazon river. The actors in the scenario are stationary and positioned at reachable spots on the land alongside the river whereas sensor nodes are thrown into the river to collect data such as water temperature, depth and geographical features. The actors are not equipped with positioning adaptors and they are only aware of their distances from the other actors. The sensor nodes collect data and forward it to the actors. While floating in the river, sensor nodes are often multiple hops away from the actor nodes, which makes it challenging to apply traditional positioning techniques. Through extensive simulations, we show that the positioning of the nodes is feasible using a multi-hop approach with local information exchange only.","Rivers,
Estimation,
Wireless sensor networks,
Mathematical model,
Mobile communication,
Monitoring,
Clustering algorithms"
CIMDS: Adapting Postprocessing Techniques of Associative Classification for Malware Detection,"Malware is software designed to infiltrate or damage a computer system without the owner's informed consent (e.g., viruses, backdoors, spyware, trojans, and worms). Nowadays, numerous attacks made by the malware pose a major security threat to computer users. Unfortunately, along with the development of the malware writing techniques, the number of file samples that need to be analyzed, named ""gray list,"" on a daily basis is constantly increasing. In order to help our virus analysts, quickly and efficiently pick out the malicious executables from the ""gray list,"" an automatic and robust tool to analyze and classify the file samples is needed. In our previous work, we have developed an intelligent malware detection system (IMDS) by adopting associative classification method based on the analysis of application programming interface (API) execution calls. Despite its good performance in malware detection, IMDS still faces the following two challenges: (1) handling the large set of the generated rules to build the classifier; and (2) finding effective rules for classifying new file samples. In this paper, we first systematically evaluate the effects of the postprocessing techniques (e.g., rule pruning, rule ranking, and rule selection) of associative classification in malware detection, and then, propose an effective way, i.e., CIDCPF, to detect the malware from the ""gray list."" To the best of our knowledge, this is the first effort on using postprocessing techniques of associative classification in malware detection. CIDCPF adapts the postprocessing techniques as follows: first applying Chi-square testing and Insignificant rule pruning followed by using Database coverage based on the Chi-square measure rule ranking mechanism and Pessimistic error estimation, and finally performing prediction by selecting the best First rule. We have incorporated the CIDCPF method into our existing IMDS system, and we call the new system as CIMDS system. Case studies are performed on the large collection of file samples obtained from the Antivirus Laboratory at Kingsoft Corporation and promising experimental results demonstrate that the efficiency and ability of detecting malware from the ""gray list"" of our CIMDS system outperform popular antivirus software tools, such as McAfee VirusScan and Norton Antivirus, as well as previous data-mining-based detection systems, which employed Naive Bayes, support vector machine, and decision tree techniques. In particular, our CIMDS system can greatly reduce the number of generated rules, which makes it easy for our virus analysts to identify the useful ones.",
Retiring Replicants: Congestion Control for Intermittently-Connected Networks,"The widespread availability of mobile wireless devices offers growing opportunities for the formation of temporary networks with only intermittent connectivity. These intermittently-connected networks (ICNs) typically lack stable end-to-end paths. In order to improve the delivery rates of the networks, new store-carry-and-forward protocols have been proposed which often use message replication as a forwarding mechanism. Message replication is effective at improving delivery, but given the limited resources of ICN nodes, such as buffer space, bandwidth and energy, as well as the highly dynamic nature of these networks, replication can easily overwhelm node resources. In this work we propose a novel node-based replication management algorithm which addresses buffer congestion by dynamically limiting the replication a node performs during each encounter. The insight for our algorithm comes from a stochastic model of message delivery in ICNs with constrained buffer space. We show through simulation that our algorithm is effective, nearly tripling delivery rates in some scenarios, and imposes little overhead.","Peer to peer computing,
Protocols,
Bandwidth,
Communications Society,
Communication system control,
Computer science,
Mobile computing,
Stochastic processes,
Mobile communication,
Disruption tolerant networking"
A Simulation of Bonding Effects and Their Impacts on Pedestrian Dynamics,"This paper simulates bonding effects inside pedestrian crowds. Based on the social force model, this paper derives an exponential formulation of the bonding force, as opposed to the repulsive force, and surveys the degree of interpersonal cohesion under various circumstances. Parameters associated with the model are calibrated by preliminary simulation runs. With the proper simulation environment configuration, the effect of the bonding force is extensively demonstrated. Results show that the bonding force results in pedestrians' walking speeds being different from their initial intended ones. Specifically, delays in walking and the overtaking phenomenon, which are empirically observed, are explained using this model. In the zigzag walkway defined in the experiment, up to approximately 4% fewer pedestrians are able to escape in the prescribed time, due to bonding effects. To sum up, the bonding forces cause negative effects on pedestrian evacuation and should be taken into consideration for crowd dynamics research.",
Effect of Intrusion Detection on Reliability of Mission-Oriented Mobile Group Systems in Mobile Ad Hoc Networks,"For mission-oriented mobile group systems designed to continue mission execution in hostile environments in the presence of security attacks, it is critical to properly deploy intrusion detection techniques to cope with insider attacks to enhance the system reliability. In this paper, we analyze the effect of intrusion detection system (IDS) techniques on the reliability of a mission-oriented group communication system consisting of mobile groups set out for mission execution in mobile ad hoc networks. Unlike the common belief that IDS should be executed as often as possible to cope with insider attacks to prolong the system lifetime, we discover that IDS should be executed at an optimal rate to maximize the mean time to failure of the system. Further, the optimal rate at which IDS is executed depends on the operational conditions, system failure definitions, attacker behaviors, and IDS techniques used. We develop mathematical models based on Stochastic Petri nets to identify the optimal rate for IDS execution to maximize the mean time to failure of the system, when given a set of parameter values characterizing the operational conditions, and attacker behaviors.","Intrusion detection,
Mobile ad hoc networks,
Communication system security,
Object detection,
Stochastic systems,
Wireless networks,
Military communication,
Telecommunication network reliability,
Mathematical model,
Petri nets"
Compact Multibranch Inverted-F Antenna to be Embedded in a Laptop Computer for LTE/WWAN/IMT-E Applications,"A multibranch inverted-F antenna with multiband operations for long-term evolution (LTE), pentaband wireless wide area network (WWAN) and IMT-E (2.6 GHz) applications is presented. The antenna consists of multibranch strips and is fabricated on a direct bond copper (DBC) substrate, which has a compact size of 96 (L) × 11.2 (W) × 0.5 (H) mm3 to be embedded in the laptop computer as an internal antenna. Three operating bands covering 663-993, 1689-2190, and 2449-2783 MHz for the LTE, GSM850/900 and DCS/PCS/UMTS, and IMT-E systems are achieved with good radiation efficiencies. The proposed antenna can be embedded in the laptop computer for the LTE, WWAN, and IMT-E applications.","Antennas,
Antenna measurements,
Portable computers,
Strips,
Frequency measurement,
3G mobile communication"
Robust 3-D Airway Tree Segmentation for Image-Guided Peripheral Bronchoscopy,"A vital task in the planning of peripheral bronchoscopy is the segmentation of the airway tree from a 3-D multidetector computed tomography chest scan. Unfortunately, existing methods typically do not sufficiently extract the necessary peripheral airways needed to plan a procedure. We present a robust method that draws upon both local and global information. The method begins with a conservative segmentation of the major airways. Follow-on stages then exhaustively search for additional candidate airway locations. Finally, a graph-based optimization method counterbalances both the benefit and cost of retaining candidate airway locations for the final segmentation. Results demonstrate that the proposed method typically extracts 2-3 more generations of airways than several other methods, and that the extracted airway trees enable image-guided bronchoscopy deeper into the human lung periphery than past studies.","Robustness,
Image segmentation,
Bronchoscopy,
Data mining,
Computed tomography,
Optimization methods,
Cost function,
Tree graphs,
Humans,
Lungs"
Distributed Monitoring and Aggregation in Wireless Sensor Networks,"Self-monitoring the sensor statuses such as liveness, node densityand residue energy is critical for maintaining the normal operation of the sensor network. When building the monitoring architecture, most existing work focuses on minimizing the number of monitoring nodes. However, with less monitoring points, the false alarm rate may increase as a consequence. In this paper, we study the fundamental tradeoff between the number of monitoring nodes and the false alarm rate in the wireless sensor networks. Specifically, we propose fully distributed monitoring algorithms, to build up a poller-pollee based architecture with the objective to minimize the number of overall pollers while bounding the false alarm rate. Based on the established monitoring architecture, we further explore the hop-by-hop aggregation opportunity along the multihop path from the polee to the poller, with the objective to minimize the monitoring overhead. We show that the optimal aggregation path problem is NP-hard and propose an opportunistic greedy algorithm, which achieves an approximation ratio of
5
4
. As far as we know, this is the first proved constant approximation ratio applied to the aggregation path selection schemes over the wireless sensor networks.","Wireless sensor networks,
Computerized monitoring,
Peer to peer computing,
Costs,
Buildings,
Energy efficiency,
Communications Society,
Computer science,
Maintenance engineering,
Power engineering and energy"
Edge-Directed Error Concealment,"In this paper we propose an edge-directed error concealment (EDEC) algorithm, to recover lost slices in video sequences encoded by flexible macroblock ordering. First, the strong edges in a corrupted frame are estimated based on the edges in the neighboring frames and the received area of the current frame. Next, the lost regions along these estimated edges are recovered using both spatial and temporal neighboring pixels. Finally, the remaining parts of the lost regions are estimated. Simulation results show that compared to the existing boundary matching algorithm [1] and the exemplar-based inpainting approach [2] , the proposed EDEC algorithm can reconstruct the corrupted frame with both a better visual quality and a higher decoder peak signal-to-noise ratio.","Video compression,
Decoding,
Resilience,
Gold,
Sun,
Video coding,
Propagation losses,
Error correction,
Erbium,
Codecs"
A System-on-Chip EPC Gen-2 Passive UHF RFID Tag With Embedded Temperature Sensor,"This paper presents a system-on-chip passive RFID tag with an embedded temperature sensor for the EPC Gen-2 protocol in the 900-MHz UHF frequency band. A dual-path clock generator is proposed to support both applications with either very accurate link frequency or very low power consumption. On-chip temperature sensing is accomplished with a time-readout scheme to reduce the power consumption. Moreover, a gain-compensation technique is proposed to reduce the temperature sensing error due to process variations by using the same bandgap reference of the tag to generate bias currents for both the current-to-digital converter and the clock generator of the sensor. Also integrated is a 128-bit one-time-programmable (OTP) memory array based on gate-oxide antifuse without extra mask steps. Fabricated in a standard 0.18- μm CMOS process with analog options, the 1.1-mm2 tag chip is bonded onto an antenna using flip-chip technology to realize a complete tag inlay, which is successfully demonstrated and evaluated in real-time wireless communications with commercial RFID readers. The tag inlay achieves a sensitivity of -6 dBm and a sensing inaccuracy of ±0.8° C (3 σ inaccuracy) over operating temperature range from -20°C to 30°C with one-point calibration.",
A Dual-Population Genetic Algorithm for Adaptive Diversity Control,"A variety of previous works exist on maintaining population diversity of genetic algorithms (GAs). Dual-population GA (DPGA) is a type of multipopulation GA (MPGA) that uses an additional population as a reservoir of diversity. The main population is similar to that of an ordinary GA and evolves to find good solutions. The reserve population evolves to maintain and provide diversity to the main population. While most MPGAs use migration as a means of information exchange between different populations, DPGA uses crossbreeding because the two populations have entirely different fitness functions. The reserve population cannot provide useful diversity to the main population unless the two maintain an appropriate distance. Therefore, DPGA adjusts the distance dynamically to achieve an appropriate balance between exploration and exploitation. The experimental results on various classes of problems using binary, real-valued, and order-based representations show that DPGA quite often outperforms not only the standard GAs but also other GAs having additional mechanisms of diversity preservation.",
A novel Si-Tunnel FET based SRAM design for ultra low-power 0.3V VDD applications,"Steep sub-threshold transistors are promising candidates to replace the traditional MOSFETs for sub-threshold leakage reduction. In this paper, we explore the use of Inter-Band Tunnel Field Effect Transistors (TFETs) in SRAMs at ultra low supply voltages. The uni-directional current conducting TFETs limit the viability of 6T SRAM cells. To overcome this limitation, 7T SRAM designs were proposed earlier at the cost of extra silicon area. In this paper, we propose a novel 6T SRAM design using Si-TFETs for reliable operation with low leakage at ultra low voltages. We also demonstrate that a functional 6T TFET SRAM design with comparable stability margins and faster performances at low voltages can be realized using proposed design when compared with the 7T TFET SRAM cell. We achieve a leakage reduction improvement of 700X and 1600X over traditional CMOS SRAM designs at VDD of 0.3V and 0.5V respectively which makes it suitable for use at ultra-low power applications.",
Integrating usability engineering and agile software development: A literature review,"The various agile software development methodologies have promoted since their inception and even demanded high degree to improve the quality of the software product. Usability engineering has made its way into the software mainstream and has caught the attention of software engineers and researchers worldwide due to rapidly growing and volatile internet software industry, despite their different perspectives on creating software both have a major role in making good software. Usability focuses on how the end users will work with the software and agile development focuses on how the software should be developed. The way these two perspectives are being combined in practice is still not well understood. This study is a preliminary literature review that describes the key question that how usability-engineering practices should be integrated with agile software development in order to make stronger and effective usable software system. This paper focuses on identifying the tensions between usability and agile methods. The research aim is to identify the common approach of agile methods and usability engineering by surveying extensive related work on integration of usability and agile methods.",
A Scalable and Energy-Efficient Context Monitoring Framework for Mobile Personal Sensor Networks,"The key feature of many emerging pervasive computing applications is to proactively provide services to mobile individuals. One major challenge in providing users with proactive services lies in continuously monitoring users' context based on numerous sensors in their PAN/BAN environments. The context monitoring in such environments imposes heavy workloads on mobile devices and sensor nodes with limited computing and battery power. We present SeeMon, a scalable and energy-efficient context monitoring framework for sensor-rich, resource-limited mobile environments. Running on a personal mobile device, SeeMon effectively performs context monitoring involving numerous sensors and applications. On top of SeeMon, multiple applications on the mobile device can proactively understand users' contexts and react appropriately. This paper proposes a novel context monitoring approach that provides efficient processing and sensor control mechanisms. We implement and test a prototype system on two mobile devices: a UMPC and a wearable device with a diverse set of sensors. Example applications are also developed based on the implemented system. Experimental results show that SeeMon achieves a high level of scalability and energy efficiency.",
Toward Predicting Collective Behavior via Social Dimension Extraction,"The SocioDim framework demonstrates promising results toward predicting collective behavior. However, many challenges require further research. For example, networks in social media are continually evolving, with new members joining a network and new connections established between existing members each day. This dynamic nature of networks entails efficient update of the model for collective behavior prediction. It is also intriguing to consider temporal fluctuation into the problem of collective behavior prediction.","Social network services,
Twitter,
Facebook,
YouTube,
Advertising,
Data mining,
Supervised learning,
Large-scale systems,
MySpace,
Videos"
A Novel Approach to Interarea Oscillation Damping by Unified Power Flow Controllers Utilizing Ultracapacitors,"This paper discusses a novel approach for damping interarea oscillations in a bulk power network using multiple unified power flow controllers (UPFCs) utilizing ultracapacitors, also known more generally as electrochemical capacitors (ECs). In this paper, a new control is introduced to mitigate interarea oscillations by directly controlling the UPFCs' sending and receiving bus voltages that better utilizes the stored energy in the ECs. The results of this controller are compared with and without ECs. The proposed control provides better interarea oscillation mitigation when applied to multiple UPFCs in the 118-bus IEEE test system.",
A Quantitative Investigation of the Acceptable Risk Levels of Object-Oriented Metrics in Open-Source Systems,"Object-oriented metrics have been validated empirically as measures of design complexity. These metrics can be used to mitigate potential problems in the software complexity. However, there are few studies that were conducted to formulate the guidelines, represented as threshold values, to interpret the complexity of the software design using metrics. Classes can be clustered into low and high risk levels using threshold values. In this paper, we use a statistical model, derived from the logistic regression, to identify threshold values for the Chidamber and Kemerer (CK) metrics. The methodology is validated empirically on a large open-source system-the Eclipse project. The empirical results indicate that the CK metrics have threshold effects at various risk levels. We have validated the use of these thresholds on the next release of the Eclipse project-Version 2.1-using decision trees. In addition, the selected threshold values were more accurate than those were selected based on either intuitive perspectives or on data distribution parameters. Furthermore, the proposed model can be exploited to find the risk level for an arbitrary threshold value. These findings suggest that there is a relationship between risk levels and object-oriented metrics and that risk levels can be used to identify threshold effects.","Open source software,
Object oriented modeling,
Software metrics,
Software quality,
Software testing,
Software design,
Predictive models,
Quality assurance,
Probability,
Fault diagnosis"
Realization of the Conscience Mechanism in CMOS Implementation of Winner-Takes-All Self-Organizing Neural Networks,"This paper presents a complementary metal-oxide-semiconductor (CMOS) implementation of a conscience mechanism used to improve the effectiveness of learning in the winner-takes-all (WTA) artificial neural networks (ANNs) realized at the transistor level. This mechanism makes it possible to eliminate the effect of the so-called ¿dead neurons,¿ which do not take part in the learning phase competition. These neurons usually have a detrimental effect on the network performance, increasing the quantization error. The proposed mechanism comes as part of the analog implementation of the WTA neural networks (NNs) designed for applications to ultralow power portable diagnostic devices for online analysis of ECG biomedical signals. The study presents Matlab simulations of the network's model, discusses postlayout circuit level simulations and includes results of measurement completed for the physical realization of the circuit.",
Ssecrett and NeuroTrace: Interactive Visualization and Analysis Tools for Large-Scale Neuroscience Data Sets,"Data sets imaged with modern electron microscopes can range from tens of terabytes to about one petabyte. Two new tools, Ssecrett and NeuroTrace, support interactive exploration and analysis of large-scale optical-and electron-microscopy images to help scientists reconstruct complex neural circuits of the mammalian nervous system.","Data visualization,
Large-scale systems,
Neuroscience,
Electron microscopy,
Image analysis,
Electron optics,
Image reconstruction,
Circuits,
Nervous system"
A survey of error-correcting codes for channels with symbol synchronization errors,We present a comprehensive survey of error-correcting codes for channels corrupted by synchronization errors. We discuss potential applications as well as the obstacles that need to be overcome before such codes can be used in practical systems.,
Linear view synthesis using a dimensionality gap light field prior,"Acquiring and representing the 4D space of rays in the world (the light field) is important for many computer vision and graphics applications. Yet, light field acquisition is costly due to their high dimensionality. Existing approaches either capture the 4D space explicitly, or involve an error-sensitive depth estimation process. This paper argues that the fundamental difference between different acquisition and rendering techniques is a difference between prior assumptions on the light field. We use the previously reported dimensionality gap in the 4D light field spectrum to propose a new light field prior. The new prior is a Gaussian assigning a non-zero variance mostly to a 3D subset of entries. Since there is only a low-dimensional subset of entries with non-zero variance, we can reduce the complexity of the acquisition process and render the 4D light field from 3D measurement sets. Moreover, the Gaussian nature of the prior leads to linear and depth invariant reconstruction algorithms. We use the new prior to render the 4D light field from a 3D focal stack sequence and to interpolate sparse directional samples and aliased spatial measurements. In all cases the algorithm reduces to a simple spatially invariant deconvolution which does not involve depth estimation.",
Two-dimensional blood velocity estimation with ultrasound: speckle tracking versus crossed-beam vector doppler based on flow simulations in a carotid bifurcation model,"Detailed imaging of complex blood flow may improve early diagnosis of cardiovascular disease. In clinical practice, non-invasive flow imaging has been limited to one-dimensional Doppler techniques. Searching for multi-dimensional estimators, research has given attention to speckle tracking (ST) and vector Doppler (VD). However, these techniques have yet to be validated for complex flow patterns as may arise in diseased arteries. In this work, the properties of ST and crossed-beam VD are compared with a ground truth for clinically relevant flow using an ultrasonic simulation environment coupled with the output from computational fluid dynamics (CFD). The statistical properties (n = 80) of ST and VD were first evaluated for stationary flow in a tube for varying vessel positions and angles, and for varying noise levels. The parameter study demonstrated VD to be a more robust axial velocity estimator, and similar results were obtained overall for the lateral velocity component. As an example, the relative standard deviation was 15% and 8% for ST compared with 3% and 10% for VD, for the axial and lateral velocity component, respectively. Further, performance was evaluated for pulsatile flow conditions in a stenosed carotid bifurcation model. A linear regression analysis showed that both methods overall had a good agreement to the CFD reference, however VD suffered from more spurious artifacts and was severely hampered by aliasing in parts of the cardiac cycle. ST was less accurate in estimating the axial component, but prevailed in estimating velocities well beyond the Nyquist range. Based on our simulations, both methods may be used to image complex flow behavior in the carotid bifurcation, however, considering also the scanning limitations of VD, ST may provide a more consistent and practical approach. Future work will entail in vitro and in vivo validation of these results.","Ultrasonic imaging,
Speckle,
Bifurcation,
Computational fluid dynamics,
Blood flow,
Cardiovascular diseases,
Arteries,
Computational modeling,
Noise level,
Noise robustness"
GPU sample sort,"We present the design of a sample sort algorithm for manycore GPUs. Despite being one of the most efficient comparison-based sorting algorithms for distributed memory architectures its performance on GPUs was previously unknown. For uniformly distributed keys our sample sort is at least 25% and on average 68% faster than the best comparison-based sorting algorithm, GPU Thrust merge sort, and on average more than 2 times faster than GPU quicksort. Moreover, for 64-bit integer keys it is at least 63% and on average 2 times faster than the highly optimized GPU Thrust radix sort that directly manipulates the binary representation of keys. Our implementation is robust to different distributions and entropy levels of keys and scales almost linearly with the input size. These results indicate that multi-way techniques in general and sample sort in particular achieve substantially better performance than two-way merge sort and quicksort.","Sorting,
Computer architecture,
Parallel processing,
Graphics processing unit,
Algorithm design and analysis,
Robustness,
Databases,
Libraries,
Memory architecture,
Entropy"
Detection and Segmentation of Colonic Polyps on Implicit Isosurfaces by Second Principal Curvature Flow,"Today's computer aided detection systems for computed tomography colonography (CTC) enable automated detection and segmentation of colorectal polyps. We present a paradigm shift by proposing a method that measures the amount of protrudedness of a candidate object in a scale adaptive fashion. One of the main results is that the performance of the candidate detection depends only on one parameter, the amount of protrusion. Additionally the method yields correct polyp segmentation without the need of an additional segmentation step. The supervised pattern recognition involves a clear distinction between size related features and features related to shape or intensity. A Mahalanobis transformation of the latter facilitates ranking of the objects using a logistic classifier. We evaluate two implementations of the method on 84 patients with a total of 57 polyps larger than or equal to 6 mm. We obtained a performance of 95% sensitivity at four false positives per scan for polyps larger than or equal to 6 mm.","Colonic polyps,
Isosurfaces,
Colon,
Surface morphology,
Colonography,
Computed tomography,
Shape,
Pattern recognition,
Partial differential equations,
Logistics"
"Design, simulation and evaluation of kinematic alternatives for Insertable Robotic Effectors Platforms in Single Port Access Surgery","This paper presents the task specifications for designing a novel Insertable Robotic Effectors Platform (IREP) with integrated stereo vision and surgical intervention tools for Single Port Access Surgery (SPAS). This design provides a compact deployable mechanical architecture that may be inserted through a single Ø15 mm access port. Dexterous surgical intervention and stereo vision are achieved via the use of two snake-like continuum robots and two controllable CCD cameras. Simulations and dexterity evaluation of our proposed design are compared to several design alternatives with different kinematic arrangements. Results of these simulations show that dexterity is improved by using an independent revolute joint at the tip of a continuum robot instead of achieving distal rotation by transmission of rotation about the backbone of the continuum robot. Further, it is shown that designs with two robotic continuum robots as surgical arms have diminished dexterity if the bases of these arms are close to each other. This result justifies our design and points to ways of improving the performance of existing designs that use continuum robots as surgical arms.",
Context-Dependent Multisensor Fusion and Its Application to Land Mine Detection,"We present a novel method for fusing the results of multiple land mine detection algorithms which use different sensors, features, and different classification methods. The proposed multisensor/multialgorithm fusion method, which is called context-dependent fusion (CDF), is motivated by the fact that the relative performance of different sensors and algorithms can vary significantly depending on the mine type, geographical site, soil and weather conditions, and burial depth. CDF is a local approach that adapts the fusion method to different regions of the feature space. The training part of CDF has two components: context extraction and algorithm fusion. In context extraction, the features used by the different algorithms are combined and used to partition the feature space into groups of similar signatures, or contexts. The algorithm fusion component assigns a degree of worthiness to each detector in each context based on its relative performance within the context. To test a new alarm using CDF, each detection algorithm extracts its set of features and assigns a confidence value. Then, the features are used to identify the best context, and the degrees of worthiness of this context are used to fuse the individual confidence values. Results on large and diverse ground-penetrating radar and wideband electromagnetic data collections show that the proposed method can identify meaningful and coherent clusters and that different expert algorithms can be identified for the different contexts. Typically, the contexts correspond to groups of alarm signatures that share a subset of common features. Our extensive experiments have also indicated that CDF outperforms all individual detectors and the global fusion that uses the same method to assign aggregation weights.","Landmine detection,
Partitioning algorithms,
Detectors,
Sensor phenomena and characterization,
Sensor fusion,
Soil,
Feature extraction,
Testing,
Detection algorithms,
Data mining"
Cyclic Codes and Sequences: The Generalized Kasami Case,"In this paper, the large family of generalized Kasami sequences has been studied. In particular, the cross-correlation distribution among these sequences has been explicitly calculated. Meanwhile, the weight distributions of two classes of cyclic codes could also be determined. This paper generalizes the results from several previous papers.","Galois fields,
Hamming weight,
Parity check codes,
Application specific integrated circuits,
Information theory,
Physics,
Materials science and technology,
Computer aided software engineering,
Autocorrelation,
Binary sequences"
Efficiency Improvement of Grid-Tied Inverters at Low Input Power Using Pulse-Skipping Control Strategy,"A pulse-skipping control strategy is proposed to improve efficiency of grid-tied inverters at light loads. To maximize the efficiency of pulse-skipping operation mode, three key parameters are identified and optimized based on a loss model, which is developed to find the maximal efficiency points using a 3-D search technique. A 200-W prototype inverter was setup to verify the proposed control strategy. The experimental results show that the proposed pulse-skipping control strategy greatly improves the inverter's efficiency at light loads and match the simulation results fairly well, thus, validating the proposed optimization method for pulse-skipping operation.",
ASAP: Scalable Identification and Counting for Contactless RFID Systems,"The growing importance of operations such as identification, location sensing and object tracking has led to increasing interests in contact less Radio Frequency Identification (RFID) systems. Enjoying the low cost of RFID tags, modern RFID systems tend to be deployed for large-scale mobile objects. Both the theoretical and experimental results suggest that when tags are mobile and with large numbers, two classical MAC layer collision-arbitration protocols, slotted ALOHA and Tree-traversal, do not satisfy the scalability and time-efficiency requirements of many applications. To address this problem, we propose Adaptively Splitting-based Arbitration Protocol (ASAP), a scheme that provides low-latency RFID identification and has stable performance for massive RFID networks. Theoretical analysis and experimental evaluation show that ASAP outperforms most existing collision-arbitration solutions. ASAP is efficient for both small and large deployment of RFID tags, in terms of time and energy cost. Hence it can benefit dynamic and large-scale RFID systems.","Radiofrequency identification,
RFID tags,
Costs,
Computer science,
Large-scale systems,
Airports,
Road transportation,
Distributed computing,
Media Access Protocol,
Scalability"
Parasitic Effects of Grounding Paths on Common-Mode EMI Filter's Performance in Power Electronics Systems,"High-frequency common-mode (CM) electromagnetic-interference (EMI) noise is difficult to suppress in electronics systems. EMI filters are used to suppress CM noise, but their performance is greatly affected by the parasitic effects of the grounding paths. In this paper, the parasitic effects of the grounding paths on an EMI filter's performance are investigated in a motor-drive system. The effects of the mutual inductance between two grounding paths are explored. Guidelines for the grounding of CM EMI filters are derived. Simulations and experiments are finally carried out to verify the theoretical analysis.","Grounding,
Electromagnetic interference,
Power filters,
Power electronics,
Delta modulation,
Inductance,
Inductors,
Circuit noise,
Parasitic capacitance,
Frequency"
Adaptive resource allocation for preemptable jobs in cloud systems,"In cloud computing, computational resources are provided to remote users in the form of leases. For a cloud user, he/she can request multiple cloud services simultaneously. In this case, parallel processing in the cloud system can improve the performance. When applying parallel processing in cloud computing, it is necessary to implement a mechanism to allocate resource and schedule the tasks execution order. Furthermore, a resource allocation mechanism with preemptable task execution can increase the utilization of clouds. In this paper, we propose an adaptive resource allocation algorithm for the cloud system with preemptable tasks. Our algorithms adjust the resource allocation adaptively based on the updated of the actual task executions. And the experimental results show that our algorithms works significantly in the situation where resource contention is fierce.","Resource management,
Cloud computing,
Processor scheduling,
Scheduling,
Computational modeling,
Heuristic algorithms,
Schedules"
"Clifford Support Vector Machines for Classification, Regression, and Recurrence","This paper introduces the Clifford support vector machines (CSVM) as a generalization of the real and complex-valued support vector machines using the Clifford geometric algebra. In this framework, we handle the design of kernels involving the Clifford or geometric product. In this approach, one redefines the optimization variables as multivectors. This allows us to have a multivector as output. Therefore, we can represent multiple classes according to the dimension of the geometric algebra in which we work. We show that one can apply CSVM for classification and regression and also to build a recurrent CSVM. The CSVM is an attractive approach for the multiple input multiple output processing of high-dimensional geometric entities. We carried out comparisons between CSVM and the current approaches to solve multiclass classification and regression. We also study the performance of the recurrent CSVM with experiments involving time series. The authors believe that this paper can be of great use for researchers and practitioners interested in multiclass hypercomplex computing, particularly for applications in complex and quaternion signal and image processing, satellite control, neurocomputation, pattern recognition, computer vision, augmented virtual reality, robotics, and humanoids.",
A Permeance-Based Transformer Model and Its Application to Winding Interturn Arcing Fault Studies,"This paper investigates the behavior of power transformers under the occurrence of permanent or intermittent winding insulation faults. For the study of these phenomena, a simple and efficient permeance-based electromagnetic transformer model is proposed, which is based on the simultaneous consideration of magnetic and electric equivalent circuits. To incorporate the internal faults in this model, a suitable equivalent circuit of the faulty winding is described. With the aid of this transformer model, the onload exciting current Park's Vector Approach will be applied for diagnosing the occurrence of permanent and intermittent winding faults. Experimental and simulation tests results are presented in this paper, which demonstrate not only the adequacy of the digital transformer model for winding fault studies, but also the effectiveness of the proposed technique for detecting winding interturn insulation faults in operating three-phase transformers.",
Intestinal Motility Assessment With Video Capsule Endoscopy: Automatic Annotation of Phasic Intestinal Contractions,"Intestinal motility assessment with video capsule endoscopy arises as a novel and challenging clinical fieldwork. This technique is based on the analysis of the patterns of intestinal contractions shown in a video provided by an ingestible capsule with a wireless micro-camera. The manual labeling of all the motility events requires large amount of time for offline screening in search of findings with low prevalence, which turns this procedure currently unpractical. In this paper, we propose a machine learning system to automatically detect the phasic intestinal contractions in video capsule endoscopy, driving a useful but not feasible clinical routine into a feasible clinical procedure. Our proposal is based on a sequential design which involves the analysis of textural, color, and blob features together with SVM classifiers. Our approach tackles the reduction of the imbalance rate of data and allows the inclusion of domain knowledge as new stages in the cascade. We present a detailed analysis, both in a quantitative and a qualitative way, by providing several measures of performance and the assessment study of interobserver variability. Our system performs at 70% of sensitivity for individual detection, whilst obtaining equivalent patterns to those of the experts for density of contractions.",
Machine Learning in Medical Imaging,"This article will discuss very different ways of using machine learning that may be less familiar, and we will demonstrate through examples the role of these concepts in medical imaging. Although the term machine learning is relatively recent, the ideas of machine learning have been applied to medical imaging for decades, perhaps most notably in the areas of computer-aided diagnosis (CAD) and functional brain mapping. We will not attempt in this brief article to survey the rich literature of this field. Instead our goals will be 1) to acquaint the reader with some modern techniques that are now staples of the machine-learning field and 2) to illustrate how these techniques can be employed in various ways in medical imaging.",
A Hybrid Optimization Algorithm and Its Application for Conformal Array Pattern Synthesis,"Investigations on conformal phased array pattern synthesis using a novel hybrid evolutionary algorithm are presented. First, in order to overcome the drawbacks of the standard genetic algorithm (GA) and the particle swarm optimization (PSO), an improved genetic algorithm (IGA) and an improved particle swarm optimization (IPSO) algorithm are proposed by introducing novel mechanisms. Then, inspired by the idea of grafting in botany, a hybrid algorithm called HIGAPSO is proposed, which combines IGA and IPSO to take advantages of both methods. After that, a spherical array antenna using wide-band stacked patch antenna elements is selected as a synthesis example to illustrate the power of HIGAPSO in solving realistic optimization problems. Finally, HIGAPSO is used to optimize the amplitude of the element current excitation of the spherical conformal array. Experimental results show that the hybrid algorithm is superior to GAs and PSOs when applied to both the classical test function and the practical problem of conformal antenna array synthesis.","Linear antenna arrays,
Antenna arrays,
Phased arrays,
Evolutionary computation,
Genetic algorithms,
Particle swarm optimization,
Microstrip antenna arrays,
Reflector antennas,
Planar arrays,
Robustness"
A Stochastic Approach to Image Retrieval Using Relevance Feedback and Particle Swarm Optimization,"Understanding the subjective meaning of a visual query, by converting it into numerical parameters that can be extracted and compared by a computer, is the paramount challenge in the field of intelligent image retrieval, also referred to as the ¿semantic gap¿ problem. In this paper, an innovative approach is proposed that combines a relevance feedback (RF) approach with an evolutionary stochastic algorithm, called particle swarm optimizer (PSO), as a way to grasp user's semantics through optimized iterative learning. The retrieval uses human interaction to achieve a twofold goal: 1) to guide the swarm particles in the exploration of the solution space towards the cluster of relevant images; 2) to dynamically modify the feature space by appropriately weighting the descriptive features according to the users' perception of relevance. Extensive simulations showed that the proposed technique outperforms traditional deterministic RF approaches of the same class, thanks to its stochastic nature, which allows a better exploration of complex, nonlinear, and highly-dimensional solution spaces.",
Efficient Cooperative Spectrum Sensing with Minimum Overhead in Cognitive Radio,"This letter studies cooperative spectrum sensing (CSS) in which secondary users efficiently cooperate to achieve superior detection accuracy with minimum cooperation overhead. We consider each cooperative user only spends ""1 bit"" on reporting its own sensing decision to data fusion center as the total cooperation overhead. However, this ""1 bit"" CSS could not gain better sensing outcomes in current data fusion rules (DFRs). To ameliorate this issue, we derive theorems to reveal the optimum threshold of general DFR. Then we propose three novel DFRs and related three algorithms to efficiently obtain the optimum decision threshold for different objectives. By simulations, the proposed DFRs indicate evident improvement on CSS performance.","Detectors,
Cognitive radio,
Base stations,
Wireless sensor networks,
Optimization"
SafeQ: Secure and Efficient Query Processing in Sensor Networks,"The architecture of two-tiered sensor networks, where storage nodes serve as an intermediate tier between sensors and a sink for storing data and processing queries, has been widely adopted because of the benefits of power and storage saving for sensors as well as the efficiency of query processing. However, the importance of storage nodes also makes them attractive to attackers. In this paper, we propose SafeQ, a protocol that prevents attackers from gaining information from both sensor collected data and sink issued queries. SafeQ also allows a sink to detect compromised storage nodes when they misbehave. To preserve privacy, SafeQ uses a novel technique to encode both data and queries such that a storage node can correctly process encoded queries over encoded data without knowing their values. To preserve integrity, we propose a new data structure called neighborhood chains that allows a sink to verify whether the result of a query contains exactly the data items that satisfy the query. In addition, we propose a solution to adapt SafeQ for event-driven sensor networks.","Query processing,
Peer to peer computing,
Protocols,
Art,
Communications Society,
Computer science,
Power engineering and energy,
Computer architecture,
Data privacy,
Data structures"
5-GHz-Band Vehicle-to-Vehicle Channels: Models for Multiple Values of Channel Bandwidth,"In Sen and Matolak's earlier paper, 5-GHz-band vehicle-to-vehicle (V2V) channel models were presented for channel bandwidths of 5 and 10 MHz. In this paper, we provide additional tapped delay line models for bandwidths of 1, 20, 33.33, and 50 MHz based upon the data used in Sen and Matolak's paper. We provide tables of channel parameters for five types of V2V channel classes and also include example tap correlation coefficients. Root-mean-square delay spread values are summarized, as are values of bandwidth for which the channel frequency correlation takes values of 0.7 and 0.5. As with the results from Sen and Matolak's paper, these models should be useful for designers in future V2V communication systems.","Bandwidth,
Frequency,
Intelligent transportation systems,
Computer science,
Senior members,
Delay lines,
Fading,
Radio propagation,
Narrowband,
Wideband"
A low-complexity subcarrier-power allocation scheme for frequency-division multiple-access systems,"This letter aims to design a low-complexity subcarrier-power allocation scheme to improve the communication reliability of various types of frequency-division multiple-access (FDMA) systems. Both uplink and downlink are considered. Specifically, a low-complexity worst subcarrier avoiding (WSA) subcarrier-allocation scheme is proposed, in order to avoid assigning users the subcarriers experiencing severe fading. After the subcarrier-allocation, channel-inversion assisted power-allocation is employed to assign the subcarriers the corresponding power. Our studies and simulation results show that the achievable error performance of the FDMA systems employing the proposed subcarrier-power allocation algorithm is independent of the multiplexing method. The proposed algorithm outperforms the existing subcarrier-power allocation algorithms that have a similar complexity as the proposed one.",
Sensitivity-Based Approaches for Handling Discrete Variables in Optimal Power Flow Computations,"This paper proposes and compares three iterative approaches for handling discrete variables in optimal power flow (OPF) computations. The first two approaches rely on the sensitivities of the objective and inequality constraints with respect to discrete variables. They set the discrete variables values either by solving a mixed-integer linear programming (MILP) problem or by using a simple procedure based on a merit function. The third approach relies on the use of Lagrange multipliers corresponding to the discrete variables bound constraints at the OPF solution. The classical round-off technique and a progressive round-off approach have been also used as a basis of comparison. We provide extensive numerical results with these approaches on four test systems with up to 1203 buses, and for two OPF problems: loss minimization and generation cost minimization, respectively. These results show that the sensitivity-based approach combined with the merit function clearly outperforms the other approaches in terms of: objective function quality, reliability, and computational times. Furthermore, the objective value obtained with this approach has been very close to that provided by the continuous relaxation OPF. This approach constitutes therefore a viable alternative to other methods dealing with discrete variables in an OPF.",
DAG Scheduling Using a Lookahead Variant of the Heterogeneous Earliest Finish Time Algorithm,"Among the numerous DAG scheduling heuristics suitable for heterogeneous systems, the Heterogeneous Earliest Finish Time (HEFT) heuristic is known to give good results in short time. In this paper, we propose an improvement of HEFT, where the locally optimal decisions made by the heuristic do not rely on estimates of a single task only, but also look ahead in the schedule and take into account information about the impact of this decision to the children of the task being allocated. Preliminary simulation results indicate that the lookahead variation of HEFT can effectively reduce the makespan of the schedule in most cases without making the algorithm’s execution time prohibitively high.","Scheduling algorithm,
Processor scheduling,
Computer networks,
Concurrent computing,
Distributed computing,
Proposals,
Computer science,
Parallel processing,
Computational efficiency,
Data communication"
"Computational Study on the Performance of Si Nanowire pMOSFETs Based on the k \cdot p
Method","Full-quantum device simulations on p-type Si nanowire field-effect transistors based on the k · p method, using the k ·p parameters tuned against the sp3s* tight-binding method, are carried out. Full transport calculations from both methods agree reasonably well, and the spin-orbit coupling effect is found to be negligible in the final current-voltage characteristics. Use of the highly efficient simulator based on the 3 × 3 k ·p Hamiltonian is therefore justified, and simulations of nanowire devices with cross sections from 3 × 3 nm2 up to 10 × 10 nm2 are performed. The subthreshold characteristics, threshold voltages, and ON-state currents for the three respective transport directions of the [100], [110], and [111] directions are examined. The device characteristics for the [110] and [111] directions are quite similar in every respect, and the [100] direction has the advantage with regard to the subthreshold behavior when the channel length is aggressively scaled down. The on-current magnitudes for the three respective orientations do not differ much, although the on-current in the [100] direction is a little smaller, compared with that in the other two directions when the channel width becomes smaller. An uncoupled mode space approach has been used to determine the contributions from individual heavy and light hole subbands, enabling an insightful analysis of the device characteristics.","Silicon,
Couplings,
Effective mass,
Nanoscale devices,
Logic gates,
Performance evaluation,
Tunneling"
A New Class of Nonlinear Finite-Volume Methods for Vlasov Simulation,"Methods for the numerical discretization of the Vlasov equation should efficiently use the phase-space discretization and should introduce only enough numerical dissipation to promote stability and control oscillations. A new high-order nonlinear finite-volume algorithm for the Vlasov equation that discretely conserves particle number and controls oscillations is presented. The method is fourth order in space and time in well-resolved regions but smoothly reduces to a third-order upwind scheme as features become poorly resolved. The new scheme is applied to several standard problems for the Vlasov-Poisson system, and the results are compared with those from other finite-volume approaches, including an artificial viscosity scheme and the piecewise parabolic method. It is shown that the new scheme is able to control oscillations while preserving a higher degree of fidelity of the solution than the other approaches.",
Numerically Efficient Modeling of CNT Transistors With Ballistic and Nonballistic Effects for Circuit Simulation,This paper presents an efficient carbon nanotube (CNT) transistor modeling technique that is based on cubic spline approximation of the nonequilibrium mobile charge density. The approximation facilitates the solution of the self-consistent voltage equation in a CNT so that calculation of the CNT drain-source current is accelerated by at least two orders of magnitude. A salient feature of the proposed technique is its ability to incorporate both ballistic and nonballistic transport effects without a significant computational cost. The proposed models have been extensively validated against reported CNT ballistic and nonballistic transport theories and experimental results.,
An EMI-Aware Prioritized Wireless Access Scheme for e-Health Applications in Hospital Environments,"Wireless communications technologies can support efficient healthcare services in medical and patient-care environments. However, using wireless communications in a healthcare environment raises two crucial issues. First, the RF transmission can cause electromagnetic interference (EMI) to biomedical devices, which could critically malfunction. Second, the different types of electronic health (e-Health) applications require different quality of service (QoS). In this paper, we introduce an innovative wireless access scheme, called EMI-aware prioritized wireless access, to address these issues. First, the system architecture for the proposed scheme is introduced. Then, an EMI-aware handshaking protocol is proposed for e-Health applications in a hospital environment. This protocol provides safety to the biomedical devices from harmful interference by adapting transmit power of wireless devices based on the EMI constraints. A prioritized wireless access scheme is proposed for channel access by two different types of applications with different priorities. A Markov chain model is presented to study the queuing behavior of the proposed system. Then, this queuing model is used to optimize the performance of the system given the QoS requirements. Finally, the performance of the proposed wireless access scheme is evaluated through extensive simulations.","Hospitals,
Electromagnetic interference,
Quality of service,
Wireless communication,
Medical services,
Access protocols,
Power system modeling,
Communications technology,
Radio frequency,
Wireless application protocol"
Determination of the Heating Effect of Magnetic Fluid in Alternating Magnetic Field,"In this paper, we have investigated the heating power of magnetic fluid, when exposed to a high-frequency magnetic field. Commercially available sample of magnetic fluid has been used and some basic investigation revealed maghemite ¿-Fe2O3 particles with 10.9-nm mean diameter and 10.57% volume concentration. We present an improved experimental system, capable of generating homogeneous magnetic field of amplitudes up to 4 kA/m and frequencies from 10 kHz to 1 MHz. In this paper, none of the heating generation mechanisms (NE¿el or Brownian relaxation or eddy current losses) have been determined solemnly, therefore, the outcome of their activity has been examined by two methods. In case of calorimetric measurements method key parameter is temperature rise while in case of magnetic measurement method key parameters are time-dependent magnetic field strength H and appurtenant magnetic flux density B. Calorimetric measurements are performed and used to determine specific absorption rate curve. Alternatively, this curve has been obtained with the measurement of B(t) and H(t), when a sample is exposed to the same magnetic conditions. Integration of the hysteresis loops has resulted in loss power of the fluid. Proposed magnetic measurement methods proved to be a decent alternative in the process of determining losses.","Heating,
Magnetic liquids,
Magnetic field measurement,
Magnetic fields,
Magnetic variables measurement,
Frequency,
Eddy currents,
Density measurement,
Temperature,
Magnetic flux density"
Entanglement-Assisted Communication of Classical and Quantum Information,"In this paper, we consider the problem of transmitting classical and quantum information reliably over an entanglement-assisted quantum (EAQ) channel. Our main result is a capacity theorem that gives a 3-D achievable rate region. Points in the region are rate triples, consisting of the classical communication rate, the quantum communication rate, and the entanglement consumption rate of a particular coding scheme. The crucial protocol in achieving the boundary points of the capacity region is a protocol that we name the classically enhanced father (CEF) protocol. The CEF protocol is more general than other protocols in the family tree of quantum Shannon theoretic protocols, in the sense that several previously known quantum protocols are now child protocols of it. The CEF protocol also shows an improvement over a timesharing strategy for the case of a qubit dephasing channel-this result justifies the need for simultaneous coding of classical and quantum information over an EAQ channel. Our capacity theorem is of a multiletter nature (requiring a limit over many uses of the channel), but it reduces to a single-letter characterization for at least three channels: the completely depolarizing channel, the quantum erasure channel, and the qubit dephasing channel.","Quantum entanglement,
Protocols,
Quantum mechanics,
Codes,
Quantum computing,
Channel capacity,
Channel coding,
International collaboration,
Computer science"
Current Frontiers in Computer Go,"This paper presents the recent technical advances in Monte Carlo tree search (MCTS) for the game of Go, shows the many similarities and the rare differences between the current best programs, and reports the results of the Computer Go event organized at the 2009 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE2009), in which four main Go programs played against top level humans. We see that in 9 × 9, computers are very close to the best human level, and can be improved easily for the opening book; whereas in 19 × 19, handicap 7 is not enough for the computers to win against top level professional players, due to some clearly understood (but not solved) weaknesses of the current algorithms. Applications far from the game of Go are also cited. Importantly, the first ever win of a computer against a 9th Dan professional player in 9 × 9 Go occurred in this event.","Games,
Decision trees,
Monte Carlo methods,
Game theory,
Algorithm design and analysis"
Adaptive Time-Variant Models for Fuzzy-Time-Series Forecasting,"A fuzzy time series has been applied to the prediction of enrollment, temperature, stock indices, and other domains. Related studies mainly focus on three factors, namely, the partition of discourse, the content of forecasting rules, and the methods of defuzzification, all of which greatly influence the prediction accuracy of forecasting models. These studies use fixed analysis window sizes for forecasting. In this paper, an adaptive time-variant fuzzy-time-series forecasting model (ATVF) is proposed to improve forecasting accuracy. The proposed model automatically adapts the analysis window size of fuzzy time series based on the prediction accuracy in the training phase and uses heuristic rules to generate forecasting values in the testing phase. The performance of the ATVF model is tested using both simulated and actual time series including the enrollments at the University of Alabama, Tuscaloosa, and the Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). The experiment results show that the proposed ATVF model achieves a significant improvement in forecasting accuracy as compared to other fuzzy-time-series forecasting models.",
Feature Based Nonrigid Brain MR Image Registration With Symmetric Alpha Stable Filters,"A new feature based nonrigid image registration method for magnetic resonance (MR) brain images is presented in this paper. Each image voxel is represented by a rotation invariant feature vector, which is computed by passing the input image volumes through a new bank of symmetric alpha stable (S?S) filters. There are three main contributions presented in this paper. First, this work is motivated by the fact that the frequency spectrums of the brain MR images often exhibit non-Gaussian heavy-tail behavior which cannot be satisfactorily modeled by the conventional Gabor filters. To this end, we propose the use of S?S filters to model such behavior and show that the Gabor filter is a special case of the S?S filter. Second, the maximum response orientation (MRO) selection criterion is designed to extract rotation invariant features for registration tasks. The MRO selection criterion also significantly reduces the number of dimensions of feature vectors and therefore lowers the computation time. Third, in case the segmentations of the input image volumes are available, the Fisher's separation criterion (FSC) is introduced such that the discriminating power of different feature types can be directly compared with each other before performing the registration process. Using FSC, weights can also be assigned automatically to different voxels in the brain MR images. The weight of each voxel determined by FSC reflects how distinctive and salient the voxel is. Using the most distinctive and salient voxels at the initial stage to drive the registration can reduce the risk of being trapped in the local optimum during image registration process. The larger the weight, the more important the voxel. With the extracted feature vectors and the associated weights, the proposed method registers the source and the target images in a hierarchical multiresolution manner. The proposed method has been intensively evaluated on both simulated and real 3-D datasets obtained from BrainWeb and Internet Brain Segmentation Repository (IBSR), respectively, and compared with HAMMER, an extended version of HAMMER based on local histograms (LHF), FFD, Demons, and the Gabor filter based registration method. It is shown that the proposed method achieves the highest registration accuracy among the five widely used image registration methods.",
iVisClassifier: An interactive visual analytics system for classification based on supervised dimension reduction,"We present an interactive visual analytics system for classification, iVisClassifier, based on a supervised dimension reduction method, linear discriminant analysis (LDA). Given high-dimensional data and associated cluster labels, LDA gives their reduced dimensional representation, which provides a good overview about the cluster structure. Instead of a single two- or three-dimensional scatter plot, iVisClassifier fully interacts with all the reduced dimensions obtained by LDA through parallel coordinates and a scatter plot. Furthermore, it significantly improves the interactivity and interpretability of LDA. LDA enables users to understand each of the reduced dimensions and how they influence the data by reconstructing the basis vector into the original data domain. By using heat maps, iVisClassifier gives an overview about the cluster relationship in terms of pairwise distances between cluster centroids both in the original space and in the reduced dimensional space. Equipped with these functionalities, iVisClassifier supports users' classification tasks in an efficient way. Using several facial image data, we show how the above analysis is performed.",
New Binomial Bent Functions Over the Finite Fields of Odd Characteristic,The p-ary function f(x) mapping GF(p4k) to GF(p) and given by f(x)=Tr4k(xp3k+p2k-pk+1+x2) is proven to be a weakly regular bent function and the exact value of its Walsh transform coefficients is found. This is the first proven infinite class of nonquadratic generalized bent functions over the fields of an arbitrary odd characteristic. The proof is based on a few new results in the area of exponential sums and polynomials over finite fields that may also be interesting as independent problems.,
Design of a Multifunctional Wireless Sensor for In-Situ Monitoring of Debris Flows,"Debris flows carrying saturated solid materials in water flowing downslopes often cause severe damage to the lives and properties in their path. Close monitoring and early warning are imperative to save lives and reduce damage. Current debris-flow-monitoring systems usually install sensor equipment along the riverbanks and mountain slopes to detect debris flows and track their data. Unfortunately, most of this equipment indirectly collects data only from a distance. So far, there is no way to understand what is happening inside a debris flow and to collect its internal parameters, not to mention doing this in real time. To answer this challenge, this paper presents a novel multifunctional wireless sensor for monitoring debris flows. The core idea is to let these sensors drift with the debris flow, to collect flow information as they move along, and to wirelessly transmit the collected data to base stations in real time. The design of such a sensor needs to address many challenging issues, including cost, deployment efforts, long-term standby, and fast reaction. This paper addresses these issues and reports our evaluation results.",
The High-Mobility Bended n-Channel Silicon Nanowire Transistor,"This work demonstrates a method for incorporating strain in silicon nanowire gate-all-around (GAA) n-MOSFETs by oxidation-induced bending of the nanowire channel and reports on the resulting improvement in device performance. The variation in strain measured during processing is discussed. The strain profile in silicon nanowires is evaluated by Raman spectroscopy both before device gate stack fabrication (tensile strains of up to 2.5% are measured) and by measurement through the polysilicon gate on completed electrically characterized devices. Drain current boosting in bended n-channels is investigated as a function of the transistor operation regime, and it is shown that the enhancement depends on the effective electrical field. The maximum observed electron mobility enhancement is on the order of 100% for a gate bias near the threshold voltage. Measurements of stress through the full gate stack and experimental device characteristics of the same transistor reveal a stress of 600 MPa and corresponding improvements of the normalized drain current, normalized transconductance, and low-field mobility by 34% (at maximum gate overdrive), 50% (at g max), and 53%, respectively, compared with a reference nonstrained device at room temperature. Finally, it is found that, at low temperatures, the low-field mobility is much higher in bended devices, compared with nonbended devices.",
On a Methodology for Robust Segmentation of Nonideal Iris Images,"Iris biometric is one of the most reliable biometrics with respect to performance. However, this reliability is a function of the ideality of the data. One of the most important steps in processing nonideal data is reliable and precise segmentation of the iris pattern from remaining background. In this paper, a segmentation methodology that aims at compensating various nonidealities contained in iris images during segmentation is proposed. The virtue of this methodology lies in its capability to reliably segment nonideal imagery that is simultaneously affected with such factors as specular reflection, blur, lighting variation, occlusion, and off-angle images. We demonstrate the robustness of our segmentation methodology by evaluating ideal and nonideal data sets, namely, the Chinese Academy of Sciences iris data version 3 interval subdirectory, the iris challenge evaluation data, the West Virginia University (WVU) data, and the WVU off-angle data. Furthermore, we compare our performance to that of our implementation of Camus and Wildes's algorithm and Masek's algorithm. We demonstrate considerable improvement in segmentation performance over the formerly mentioned algorithms.","Robustness,
Image segmentation,
Iris recognition,
Biometrics,
Optical reflection,
Degradation,
Algorithm design and analysis,
Surveillance,
Image quality,
Image edge detection"
Mitral Annulus Segmentation From 3D Ultrasound Using Graph Cuts,"The shape of the mitral valve annulus is used in diagnostic and modeling applications, yet methods to accurately and reproducibly delineate the annulus are limited. This paper presents a mitral annulus segmentation algorithm designed for closed mitral valves which locates the annulus in three-dimensional ultrasound using only a single user-specified point near the center of the valve. The algorithm first constructs a surface at the location of the thin leaflets, and then locates the annulus by finding where the thin leaflet tissue meets the thicker heart wall. The algorithm iterates until convergence metrics are satisfied, resulting in an operator-independent mitral annulus segmentation. The accuracy of the algorithm was assessed from both a diagnostic and surgical standpoint by comparing the algorithm's results to delineations made by a group of experts on clinical ultrasound images of the mitral valve, and to delineations made by an expert with a surgical view of the mitral annulus on excised porcine hearts using an electromagnetically tracked pointer. In the former study, the algorithm was statistically indistinguishable from the best performing expert (p = 0.85 ) and had an average RMS difference of 1.81±0.78 mm to the expert average. In the latter, the average RMS difference between the algorithm's annulus and the electromagnetically tracked points across six hearts was 1.19±0.17 mm .","Ultrasonic imaging,
Valves,
Shape,
Surgery,
Heart,
Image segmentation,
Geometry,
Visualization,
Pediatrics,
Hospitals"
High Quality Sensor Placement for SHM Systems: Refocusing on Application Demands,"There are heavy studies recently on applying wireless sensor networks for structural health monitoring. These works usually focus on the computer science aspect, and the considerations include energy consumption, network connectivity, etc. It is commonly believed that for the current resource limited wireless sensors, system design could be more efficient if the application requirements are incorporated. Nevertheless, we often find that, rather than integration, assumptions have to be made due to lack of knowledge of civil engineering; for example, to evaluate routing algorithms, the sensor placement is assumed to be random or on grids/trees. These may not be practically meaningful to the respective application demands, and make the great efforts by the computer science community on developing efficient methods from the sensor network aspect less useful. In this paper, we study the very first problem of the SHM systems: the sensor placement and focus on the civil requirements. We first study the current general framework of structure health monitoring. We redevelop the framework that includes a new sensor placement module. This module implements the most widely accepted sensor placement scheme from civil engineering but focusing on its usefulness for computer science. It provides such interfaces that can rank the placement quality of the candidate locations in a step by step manner. We then optimize system performance by considering network connectivity and data routing issues; with the objective on energy efficiency. We evaluate our scheme using the data from the structural health monitoring system on the Ting Kau Bridge, Hong Kong. We show that a uniform and a state-of-the-art placement are not very meaningful in placement quality. Our scheme achieves almost the same sensor placement quality with that of the civil engineering with five-fold improvement in system lifetime. We conduct an experiment on the in-built Guangzhou New TV Tower, China; and the results validate the effectiveness of our scheme.",
Fine-grained incremental learning and multi-feature tossing graphs to improve bug triaging,"Software bugs are inevitable and bug fixing is a difficult, expensive, and lengthy process. One of the primary reasons why bug fixing takes so long is the difficulty of accurately assigning a bug to the most competent developer for that bug kind or bug class. Assigning a bug to a potential developer, also known as bug triaging, is a labor-intensive, time-consuming and fault-prone process if done manually. Moreover, bugs frequently get reassigned to multiple developers before they are resolved, a process known as bug tossing. Researchers have proposed automated techniques to facilitate bug triaging and reduce bug tossing using machine learning-based prediction and tossing graphs. While these techniques achieve good prediction accuracy for triaging and reduce tossing paths, they are vulnerable to several issues: outdated training sets, inactive developers, and imprecise, single-attribute tossing graphs. In this paper we improve triaging accuracy and reduce tossing path lengths by employing several techniques such as refined classification using additional attributes and intra-fold updates during training, a precise ranking function for recommending potential tossees in tossing graphs, and multi-feature tossing graphs. We validate our approach on two large software projects, Mozilla and Eclipse, covering 856,259 bug reports and 21 cumulative years of development. We demonstrate that our techniques can achieve up to 83.62% prediction accuracy in bug triaging. Moreover, we reduce tossing path lengths to 1.5–2 tosses for most bugs, which represents a reduction of up to 86.31% compared to original tossing paths. Our improvements have the potential to significantly reduce the bug fixing effort, especially in the context of sizable projects with large numbers of testers and developers.","Computer bugs,
Accuracy,
Training,
Training data,
History,
Software,
Machine learning"
Estimation of Image Rotation Angle Using Interpolation-Related Spectral Signatures With Application to Blind Detection of Image Forgery,"Motivated by the image rescaling estimation method proposed by Gallagher (2nd Canadian Conf. Computer & Robot Vision, 2005: 65-72), we develop an image rotation angle estimator based on the relations between the rotation angle and the frequencies at which peaks due to interpolation occur in the spectrum of the image's edge map. We then use rescaling/rotation detection and parameter estimation to detect fake objects inserted into images. When a forged image contains areas from different sources, or from another part of the same image, rescaling and/or rotation are often involved. In these geometric operations, interpolation is a necessary step. By dividing the image into blocks, detecting traces of rescaling and rotation in each block, and estimating the parameters, we can effectively reveal the forged areas in an image that have been rescaled and/or rotated. If multiple geometrical operations are involved, different processing sequences, i.e., repeated zooming, repeated rotation, rotation-zooming, or zooming-rotation, may be determined from different behaviors of the peaks due to rescaling and rotation. This may also provide a useful clue to image authentication.","Forgery,
Frequency estimation,
Interpolation,
Object detection,
Parameter estimation,
Application software,
Computer vision,
Robot vision systems,
Image edge detection,
Authentication"
Affective Visualization and Retrieval for Music Video,"In modern times, music video (MV) has become an important favorite pastime to people because of its conciseness, convenience, and the ability to bring both audio and visual experiences to audiences. As the amount of MVs is explosively increasing, it has become an important task to develop new techniques for effective MV analysis, retrieval, and management. By stimulating the human affective response mechanism, affective video content analysis extracts the affective information contained in videos, and, with the affective information, natural, user-friendly, and effective MV access strategies could be developed. In this paper, a novel integrated system (i.MV) is proposed for personalized MV affective analysis, visualization, and retrieval. In i.MV, we not only perform the personalized MV affective analysis, which is a challenging and insufficiently covered problem in current affective content analysis field, but also propose novel affective visualization to convert the abstract affective states intuitive and friendly to users. Based on the affective analysis and visualization, affective information based MV retrieval is achieved. Both comprehensive experiments and subjective user studies on a large MV dataset demonstrate that our personalized affective analysis is more effective than the previous algorithms. In addition, affective visualization is proved to be more suitable for affective information-based MV retrieval than the commonly used affective state representation strategies.",
Robust Stability Analysis for Stochastic Neural Networks With Time-Varying Delay,"This brief investigates the problem of mean square exponential stability of uncertain stochastic delayed neural networks (DNNs) with time-varying delay. A novel Lyapunov functional is introduced with the idea of the discretized Lyapunov-Krasovskii functional (LKF) method. Then, a new delay-dependent mean square exponential stability criterion is derived by applying the free-weighting matrix technique and by equivalently eliminating time-varying delay through the idea of convex combination. Numerical examples illustrate the effectiveness of the proposed method and the improvement over some existing methods.","Robust stability,
Stochastic processes,
Neural networks,
Delay,
Stability criteria,
Artificial neural networks,
Stability analysis,
Linear matrix inequalities,
Australia,
Mathematics"
Energy-efficient MAC protocols for wireless body area networks: Survey,"In this paper, we provide a comprehensive survey of recent energy-efficient medium access control (MAC) protocols for wireless body area networks (WBANs) and presents a comparison of the various approaches pursued. At the outset, we outline the crucial attributes for a good MAC. Several sources that contribute to the energy inefficiency are identified. Then, we investigate few MAC protocols devised for WBAN by emphasizing their salient features. As a conclusion, we put forward a number of open research challenges with regard to prospects of medium access techniques and other issues.","Media Access Protocol,
Time division multiple access,
Energy efficiency,
Synchronization,
Bandwidth"
MapReduce as a programming model for association rules algorithm on Hadoop,"As association rules widely used, it needs to study many problems, one of which is the generally larger and multi-dimensional datasets, and the rapid growth of the mount of data. Single-processor's memory and CPU resources are very limited, which makes the algorithm performance inefficient. Recently the development of network and distributed technology makes cloud computing a reality in the implementation of association rules algorithm. In this paper we describe the improved Apriori algorithm based on MapReduce mode, which can handle massive datasets with a large number of nodes on Hadoop platform.",
Design equations for tapered microstrip-to-Substrate Integrated Waveguide transitions,"This paper presents design equations for the microstrip-to-Substrate Integrated Waveguide (SIW) transition. The transition is decomposed in two distinct parts: the microstrip taper and the microstrip-to-SIW step. Analytical equations are used for the microstrip taper. As for the step, the microstrip is modeled by an equivalent transverse electromagnetic (TEM) waveguide. An equation relating the optimum microstrip width to the SIW width is derived using a curve fitting technique. It is shown that when the step is properly sized, it provides a return loss superior to 20 dB. Three design examples are presented using different substrate permittivity and frequency bands between 18 GHz and 75 GHz. An experimental verification is also presented. The presented technique allows to design transitions covering the complete single-mode SIW bandwidth.","Equations,
Waveguide transitions,
Electromagnetic waveguides,
Microstrip components,
Electromagnetic modeling,
Electromagnetic scattering,
Curve fitting,
Permittivity,
Frequency,
Bandwidth"
Image Segmentation Using Active Contours With Normally Biased GVF External Force,"Gradient vector flow (GVF) is an effective external force for active contours, but its isotropic nature handicaps its performance. The recently proposed NGVF model is anisotropic since it only keeps the diffusion along the normal direction of the isophotes; however, it is sensitive to noise and could erase weak boundaries. In this letter, the normally biased GVF (NBGVF) external force is proposed for snake models, which keeps the diffusion along the tangential direction of the isophotes and biases that along the normal direction. The biasing weight approaches zero at boundaries and is 1 in homogeneous regions. Consequently, the NBGVF snake can preserve weak edges and smooth out noise while maintaining other desirable properties of GVF and NGVF snakes such as enlarged capture range, insensitivity to initialization and convergence to u-shape concavity. These properties are evaluated on synthetic and real images.","Image segmentation,
Active contours,
Educational technology,
Anisotropic magnetoresistance,
Solid modeling,
Information technology,
Partial response channels,
Convergence,
Image restoration,
Level set"
Image and Video Segmentation by Combining Unsupervised Generalized Gaussian Mixture Modeling and Feature Selection,"In this letter, we propose a clustering model that efficiently mitigates image and video under/over-segmentation by combining generalized Gaussian mixture modeling and feature selection. The model has flexibility to accurately represent heavy-tailed image/video histograms, while automatically discarding uninformative features, leading to better discrimination and localization of regions in high-dimensional spaces. Experimental results on a database of real-world images and videos showed us the effectiveness of the proposed approach.","Image segmentation,
Pixel,
Image color analysis,
Accuracy,
Complexity theory,
Computational modeling,
Pattern analysis"
Variability in Si Nanowire MOSFETs Due to the Combined Effect of Interface Roughness and Random Dopants: A Fully Three-Dimensional NEGF Simulation Study,"In this paper, we study the impact of surface roughness and its combination with random discrete dopants on the current variability in nanometer-scale nanowire metal-oxidesemiconductor field-effect transistors. It is shown that these two variability sources cannot be regarded as independent in their effect on transport. Interface roughness results in body thickness fluctuations and scattering, which degrades transistor performance. This paper extends our previous study, in which we concentrated only on the impact of random discrete dopants in the source/drain regions in the same type of devices that lead to current variability. We have simulated ensembles of 30 devices, which differ due to the physical manifestation of the variability sources, including the detailed microscopic pattern of the interface in the channel and the number and configuration of discrete dopants in the source/drain regions. An ensemble of devices, with rough interfaces and continuous doping, has first been simulated to differentiate the effect of the interface roughness from the random discrete dopants before considering the combined case. It was found that, in some peculiar cases, the surface roughness induced resonant structures inside the device, producing quasibound states. These resonant states are similar to those related to individual discrete dopants in our previous study. We found that there is strong correlation between the microscopic patterns of the interface and the device performance due to the non-self-averaging of the microscopic features, which plagues devices with small channel lengths. The surface roughness induces a threshold voltage shift and decreases the ON-current of the device due to scattering. In the fully 3-D nonequilibrium Green's function formalism, both effects are combined in the propagation of the electron wave through the device. We have extracted the surface roughness related scattering contribution and estimated the associated mobility.",
A New Cluster Based Routing Protocol for VANET,"With the development of vehicles and mobile Ad Hoc network technology, the Vehicle Ad hoc Network (VANET) has become an emerging field of study. It is a challenging problem for searching and maintaining an effective route for transporting some data information. In this paper the authors designed a new routing protocol for VANET based on the former results, called CBR (Cluster Based Routing). Compared with other routing protocols, the new one has obvious improvement in the average routing overhead and small average end to end delay jitter with the increase of vehicles number. The real-time traffic applications require data transmission delay time to be relatively stable, small average end to end delay jitter with the increase of vehicles number just meets the real-time application needs.","Routing protocols,
Road vehicles,
Delay,
Computer science,
Intelligent transportation systems,
Vehicle safety,
Broadcasting,
Wireless communication,
Mobile ad hoc networks,
Ad hoc networks"
Recognizing engagement in human-robot interaction,"Based on a study of the engagement process between humans, we have developed and implemented an initial computational model for recognizing engagement between a human and a humanoid robot. Our model contains recognizers for four types of connection events involving gesture and speech: directed gaze, mutual facial gaze, conversational adjacency pairs and backchannels. To facilitate integrating and experimenting with our model in a broad range of robot architectures, we have packaged it as a node in the open-source Robot Operating System (ROS) framework. We have conducted a preliminary validation of our computational model and implementation in a simple human-robot pointing game.","Humans,
Robot kinematics,
Humanoid robots,
Computational modeling,
Operating systems,
Robot vision systems,
Computer science,
Face recognition,
Speech recognition,
Computer architecture"
Dynamic duty cycle control for end-to-end delay guarantees in wireless sensor networks,"It is well known that periodically putting nodes into sleep can effectively save energy in wireless sensor networks, at the cost of increased communication delays. However, most existing work mainly focuses on static sleep scheduling, which cannot guarantee the desired delay when the network conditions change dynamically. In many applications with user-specified end-to-end delay requirements, the duty cycle of every node should be tuned individually at runtime based on the network conditions to achieve the desired end-to-end delay guarantees and energy efficiency. In this paper, we propose DutyCon, a control theory-based dynamic duty cycle control approach. DutyCon decomposes the end-to-end delay guarantee problem into a set of single-hop delay guarantee problems along each data flow in the network. We then formulate the single-hop delay guarantee problem as a dynamic feedback control problem and design the controller rigorously, based on feedback control theory, for analytic assurance of control accuracy and system stability. DutyCon also features a queuing delay adaptation scheme that adapts the duty cycle of each node to unpredictable packet rates, as well as a novel energy balancing approach that extends the network lifetime by dynamically adjusting the delay requirement allocated to each hop. Our empirical results on a hardware testbed demonstrate that DutyCon can effectively achieve the desired tradeoff between end-to-end delay and energy conservation. Extensive simulation results also show that DutyCon outperforms two baseline sleep scheduling protocols by having more energy savings while meeting the end-to-end delay requirements.",
Epigenetic Robotics Architecture (ERA),"In this paper, we discuss the requirements of cognitive architectures for epigenetic robotics, and highlight the wider role that they can play in the development of the cognitive sciences. We discuss the ambitious goals of ongoing development, scalability, concept use and transparency, and introduce the epigenetic robotics architecture (ERA) as a framework guiding modeling efforts. A formal implementation is provided, demonstrated, and discussed in terms of meeting these goals. Extensions of the architecture are also introduced and we show how the dynamics of resulting models can transparently account for a wide range of psychological phenomena, without task dependant tuning, thereby making progress in all of the goal areas we highlight.","Cognitive science,
Robot sensing systems,
Computer architecture,
Psychology,
Cognitive robotics"
Convex shape decomposition,"In this paper, we propose a new shape decomposition method, called convex shape decomposition. We formalize the convex decomposition problem as an integer linear programming problem, and obtain approximate optimal solution by minimizing the total cost of decomposition under some concavity constraints. Our method is based on Morse theory and combines information from multiple Morse functions. The obtained decomposition provides a compact representation, both geometrical and topological, of original object. Our experiments show that such representation is very useful in many applications.","Shape,
Data mining,
Cost function,
Topology,
Integer linear programming,
Q measurement,
Motion detection,
Image edge detection,
Image segmentation,
Image processing"
Classification of Mycobacterium tuberculosis in Images of ZN-Stained Sputum Smears,"Screening for tuberculosis (TB) in low- and middle-income countries is centered on the microscope. We present methods for the automated identification of Mycobacterium tuberculosis in images of Ziehl-Neelsen (ZN) stained sputum smears obtained using a bright-field microscope. We segment candidate bacillus objects using a combination of two-class pixel classifiers. The algorithm produces results that agree well with manual segmentations, as judged by the Hausdorff distance and the modified Williams index. The extraction of geometric-transformation-invariant features and optimization of the feature set by feature subset selection and Fisher transformation follow. Finally, different two-class object classifiers are compared. The sensitivity and specificity of all tested classifiers is above 95% for the identification of bacillus objects represented by Fisher-transformed features. Our results may be used to reduce technician involvement in screening for TB, and would be particularly useful in laboratories in countries with a high burden of TB, where, typically, ZN rather than auramine staining of sputum smears is the method of choice.","Microscopy,
Image segmentation,
Fluorescence,
Image edge detection,
Pixel,
Pathology,
Cities and towns,
Costs,
Zinc,
Automation"
Towards an architecture for service-oriented process monitoring and control,"The initiative AESOP (ArchitecturE for Service-Oriented Process-Monitoring and — Control) envisions a Service-oriented Architecture approach for monitoring and control of Process Control applications (batch and continuous process). Large process industry systems are a complex (potentially very large) set of (frequently) multi-disciplinary, connected, heterogeneous systems that function as a complex system of which the components are themselves systems. The future “Perfect Plant” will be able to seamlessly collaborate and enable monitoring and control information flow in a cross-layer way. As such the different systems will be part of an SCADA/DCS ecosystem, where components can be dynamically added or removed and dynamic discovery enables the on-demand information combination and collaboration. All current and future systems will be able to share information in a timely and open manner, enabling an enterprise-wide system of systems that will dynamically evolve based on business needs. The SOA-based approach proposed by AESOP can, on one hand, simplify the integration of monitoring and control systems on application layer. On the other hand, the networking technologies that are already known to control engineers could also simplify the inclusion of or migration from existing solutions and integration of the next generation SCADA and DCS systems at network layer.",
Accelerating Correlated Quantum Chemistry Calculations Using Graphical Processing Units,Graphical processing units are now being used with dramatic effect to accelerate quantum chemistry applications. The authors give a brief introduction to electronic structure methods and describe their efforts to accelerate a correlated quantum chemistry code. They propose and analyze two new tools for accelerating matrix-multiplications where single-precision accuracy is insuffcient.,"Acceleration,
Chemistry,
Quantum mechanics,
Quantum computing,
Drugs,
Chemical technology,
Pharmaceutical technology,
Computational efficiency,
Coprocessors,
Costs"
Toward Large-Scale Face Recognition Using Social Network Context,"Personal photographs are being captured in digital form at an accelerating rate, and our computational tools for searching, browsing, and sharing these photos are struggling to keep pace. One promising approach is automatic face recognition, which would allow photos to be organized by the identities of the individuals they contain. However, achieving accurate recognition at the scale of the Web requires discriminating among hundreds of millions of individuals and would seem to be a daunting task. This paper argues that social network context may be the key for large-scale face recognition to succeed. Many personal photographs are shared on the Web through online social network sites, and we can leverage the resources and structure of such social networks to improve face recognition rates on the images shared. Drawing upon real photo collections from volunteers who are members of a popular online social network, we asses the availability of resources to improve face recognition and discuss techniques for applying these resources.",
Layout Decomposition Approaches for Double Patterning Lithography,"In double patterning lithography (DPL) layout decomposition for 45 nm and below process nodes, two features must be assigned opposite colors (corresponding to different exposures) if their spacing is less than the minimum coloring spacing. However, there exist pattern configurations for which pattern features separated by less than the minimum coloring spacing cannot be assigned different colors. In such cases, DPL requires that a layout feature be split into two parts. We address this problem using two layout decomposition approaches based on a conflict graph. First, node splitting is performed at all feasible dividing points. Then, one approach detects conflict cycles in the graph which are unresolvable for DPL coloring, and determines the coloring solution for the remaining nodes using integer linear programming (ILP). The other approach, based on a different ILP problem formulation, deletes some edges in the graph to make it two-colorable, then finds the coloring solution in the new graph. We evaluate our methods on both real and artificial 45 nm test-cases. Experimental results show that our proposed layout decomposition approaches effectively decompose given layouts to satisfy the key goals of minimized line-ends and maximized overlap margin. There are no design rule violations in the final decomposed layout.","Lithography,
Page description languages,
Ultraviolet sources,
Resists,
Integer linear programming,
Circuits,
Computer science,
Optical materials,
Color,
Testing"
Stable LPV Realization of Parametric Transfer Functions and Its Application to Gain-Scheduling Control Design,"The paper deals with the stabilizability of linear plants whose parameters vary with time in a compact set. First, necessary and sufficient conditions for the existence of a linear gain-scheduled stabilizing compensator are given. Next, it is shown that, if these conditions are satisfied, any compensator transfer function depending on the plant parameters and internally stabilizing the closed-loop control system when the plant parameters are constant, can be realized in such a way that the closed-loop asymptotic stability is guaranteed under arbitrary parameter variations. To this purpose, it is preliminarily proved that any transfer function that is stable for all constant parameters values admits a realization that is stable under arbitrary parameter variations (linear parameter-varying (LPV) stability). Then, the Youla-Kucera parametrization of all stabilizing compensators is exploited; precisely, closed-loop LPV stability can be ensured by taking an LPV stable realization of the Youla-Kucera parameter. To find one such realization, a reasonably simple and general algorithm based on Lyapunov equations and Cholesky's factorization is provided. These results can be exploited to apply linear time-invarient design to LPV systems, thus achieving both pointwise optimality (or pole placement) and LPV stability. Some potential applications in adaptive control and online tuning are pointed out.",
Duality of MIMO multiple access channel and broadcast channel with amplify-and-forward relays,"In this work, we consider a two-hop multiuser amplify-and-forward relay network with multi-antenna nodes. The results are three-fold. First, for any relay amplification matrix D in the multiple-access channel (MAC), we show that duality holds when ¿D¿ is employed in the broadcast channel (BC), and vice versa, where re is obtained from switching the total source and relay power constraints. Second, under a total network power constraint, we show that MAC-BC duality holds when D and D¿ are the relaying matrices in the MAC and BC respectively. Third, for any D in the MAC and cD¿ in the BC where c is any positive real scalar, MAC-BC duality under total network power constraint holds only for the above two cases.",
On the bias of BFS (Breadth First Search),"Breadth First Search (BFS) and other graph traversal techniques are widely used for measuring large unknown graphs, such as online social networks. It has been empirically observed that incomplete BFS is biased toward high degree nodes. In contrast to more studied sampling techniques, such as random walks, the bias of BFS has not been characterized to date. In this paper, we quantify the degree bias of BFS sampling. In particular, we calculate the node degree distribution expected to be observed by BFS as a function of the fraction of covered nodes, in a random graph RG(pk) with a given (and arbitrary) degree distribution pk. Furthermore, we also show that, for RG(pk), all commonly used graph traversal techniques (BFS, DFS, Forest Fire, and Snowball Sampling) lead to the same bias, and we show how to correct for this bias. To give a broader perspective, we compare this class of exploration techniques to random walks that are well-studied and easier to analyze. Next, we study by simulation the effect of graph properties not captured directly by our model. We find that the bias gets amplified in graphs with strong positive assortativity. Finally, we demonstrate the above results by sampling the Facebook social network, and we provide some practical guidelines for graph sampling in practice.","Peer to peer computing,
Facebook,
Fires,
Indexes,
World Wide Web,
Mathematical model"
Atlas Generation for Subcortical and Ventricular Structures With Its Applications in Shape Analysis,"Atlas-driven morphometric analysis has received great attention for studying anatomical shape variation across clinical populations in neuroimaging research as it provides a local coordinate representation for understanding the family of anatomic observations. We present a procedure for generating atlas of subcortical and ventricular structures, including amygdala, hippocampus, caudate, putamen, globus pallidus, thalamus, and lateral ventricles, using the large deformation diffeomorphic metric atlas generation algorithm. The atlas was built based on manually labeled volumes of 41 subjects randomly selected from the database of Open Access Series of Imaging Studies (OASIS, 10 young adults, 10 middle-age adults, 10 healthy elders, and 11 patients with dementia). We show that the estimated atlas is representative of the population in terms of its metric distance to each individual subject in the population. In the application of detecting shape variations, using the estimated atlas may potentially increase statistical power in identifying group shape difference when comparing with using a single subject atlas. In shape-based classification, the metric distances between subjects and each of within-class estimated atlases construct a shape feature space, which allows for performing a variety of classification algorithms to distinguish anatomies.",
A Novel Analog Broadband RF Predistortion Circuit to Linearize Electro-Absorption Modulators in Multiband OFDM Radio-Over-Fiber Systems,"We propose and demonstrate a novel and simple predistortion circuit using reflective antiparallel diodes for linearization of electro-absorption modulators (EAMs) in multiband orthogonal frequency-division multiplexing (MB-OFDM) ultra-wideband (UWB) radio-over-fiber systems for UWB signals from 3.1 to 4.8 GHz. In this novel predistortion circuit, neither amplifiers, nor phase shifters are used, while only two antiparallel connected diodes are used, and the predistortion signal is adjusted by tuning the diodes' dc-bias current. The simple architecture makes the circuit cost effective and suitable for UWB system applications. By adding the predistortion circuit before the EAM, more than 7-dB suppression in third-order intermodulation distortion and 11-dB improvement in spurious-free dynamic range are achieved over the frequency range of 3.1-4.8 GHz, i.e., bandgroup 1 of MB-OFDM UWB. Correspondingly, 1-dB improvement in error vector magnitude is obtained experimentally when the designed predistortion circuit is used.",
Performance and Area Scaling Benefits of FD-SOI Technology for 6-T SRAM Cells at the 22-nm Node,"The performance and threshold voltage variability of fully depleted silicon-on-insulator (FD-SOI) MOSFETs are compared against those of conventional bulk MOSFETs via 3-D device simulation with atomistic doping profiles. Compact (analytical) modeling is then used to estimate six-transistor SRAM cell performance metrics (i.e., read and write margins, and read current) at the 22 nm CMOS technology node. The dependences of these metrics on cell ratio, pull-up ratio, and operating voltage are analyzed for FD-SOI versus bulk SRAM cells. Iso-area and iso-yield comparisons are then made to determine the yield and cell-area benefits of FD-SOI technology, respectively. Finally, the minimum operating voltages required for FD-SOI and bulk SRAM cells to meet the six-sigma yield requirement are compared.",
Opportunistic Bandwidth Sharing Through Reinforcement Learning,"As an initial step toward solving the spectrum-shortage problem, the Federal Communications Commission (FCC) has started the so-called opportunistic spectrum access (OSA), which allows unlicensed users to exploit the unused licensed spectrum, but in a manner that limits interference to licensed users. Fortunately, technological advances have enabled cognitive radios, which have recently been recognized as the key enabling technology for realizing OSA. In this paper, we propose a machine-learning-based scheme that will exploit the cognitive radios' capabilities to enable effective OSA, thus improving the efficiency of spectrum utilization. Our proposed learning technique requires no prior knowledge of the environment's characteristics and dynamics, yet it can still achieve high performance by learning from interaction with the environment.",
Applying Wearable Solutions in Dependent Environments,"This paper proposes a multiagent system (MAS) that uses smart wearable devices and mobile technology for the care of patients in a geriatric home care facility. The system is based on an advanced ZigBee wireless sensor network (WSN) and includes location and identification microchips installed in patient clothing and caregiver uniforms. The use of radio-frequency identification and near-field communication technologies allows remote monitoring of patients, and makes it possible for them to receive treatment according to preventive medical protocol. The proposed MAS manage the infrastructure of services within the environment both efficiently and securely by reasoning, task-planning, and synchronizing the data obtained from the sensors. Additionally, this paper presents the design and implementation of the reasoning agent in the MAS. A system prototype was installed in a real environment and the results obtained are presented in this paper.",
On Probabilistic Automata in Continuous Time,"We develop a compositional behavioural model that integrates a variation of probabilistic automata into a conservative extension of interactive Markov chains. The model is rich enough to embody the semantics of generalised stochastic Petri nets. We define strong and weak bisimulations and discuss their compositionality properties. Weak bisimulation is partly oblivious to the probabilistic branching structure, in order to reflect some natural equalities in this spectrum of models. As a result, the standard way to associate a stochastic process to a generalised stochastic Petri net can be proven sound with respect to weak bisimulation.","Markov processes,
Probabilistic logic,
Automata,
Concurrent computing,
Delay,
Petri nets"
Test generation via Dynamic Symbolic Execution for mutation testing,"Mutation testing has been used to assess and improve the quality of test inputs. Generating test inputs to achieve high mutant-killing ratios is important in mutation testing. However, existing test-generation techniques do not provide effective support for killing mutants in mutation testing. In this paper, we propose a general test-generation approach, called PexMutator, for mutation testing using Dynamic Symbolic Execution (DSE), a recent effective test-generation technique. Based on a set of transformation rules, PexMutator transforms a program under test to an instrumented meta-program that contains mutant-killing constraints. Then PexMutator uses DSE to generate test inputs for the meta-program. The mutant-killing constraints introduced via instrumentation guide DSE to generate test inputs to kill mutants automatically. We have implemented our approach as an extension for Pex, an automatic structural testing tool developed at Microsoft Research. Our preliminary experimental study shows that our approach is able to strongly kill more than 80% of all the mutants for the five studied subjects. In addition, PexMutator is able to outperform Pex, a state-of-the-art test-generation tool, in terms of strong mutant killing while achieving the same block coverage.","Testing,
Engines,
Instruments,
Wrapping,
Syntactics,
Connectors,
Software"
Exploring e-Learning Knowledge Through Ontological Memetic Agents,"E-Learning systems have proven to be fundamental in several areas of tertiary education and in business companies. There are many significant advantages for people who learn online such as convenience, portability, flexibility and costs. However, the remarkable velocity and volatility of modern knowledge due to the exponential growth of the World Wide Web, requires novel learning methods that offer additional features such as information structuring, efficiency, task relevance and personalization. This paper proposes a novel multi-agent e-Learning system empowered with (ontological) knowledge representation and memetic computing to efficiently manage complex and unstructured information that characterize e-Learning. In particular, differing from other similar approaches, our proposal uses (1) ontologies to provide a suitable method for modeling knowledge about learning content and activities, and (2) memetic agents as intelligent explorers in order to create ¿in time¿ and personalized e-Learning experiences that satisfy learners' specific preferences. The proposed method has been tested by realizing a multi-agent software plug-in for an industrial e-Learning platform with experimentations to validate our memetic proposal in terms of flexibility, efficiency and interoperability.","Electronic learning,
Ontologies,
Proposals,
Companies,
Costs,
Web sites,
Learning systems,
Knowledge representation,
Knowledge management,
Intelligent agent"
A distributed Newton method for Network Utility Maximization,"Most existing work uses dual decomposition and subgradient methods to solve Network Utility Maximization (NUM) problems in a distributed manner, which suffer from slow rate of convergence properties. This work develops an alternative distributed Newton-type fast converging algorithm for solving network utility maximization problems with self-concordant utility functions. By using novel matrix splitting techniques, both primal and dual updates for the Newton step can be computed using iterative schemes in a decentralized manner with limited scalar information exchange. Similarly, the stepsize can be obtained via an iterative consensus-based averaging scheme. We show that even when the Newton direction and the stepsize in our method are computed within some error (due to finite truncation of the iterative schemes), the resulting objective function value still converges superlinearly to an explicitly characterized error neighborhood. Simulation results demonstrate significant convergence rate improvement of our algorithm relative to the existing subgradient methods based on dual decomposition.","Convergence,
Newton method,
Algorithm design and analysis,
Iterative algorithm,
Iterative methods,
Aggregates,
Routing"
P-Coding: Secure Network Coding against Eavesdropping Attacks,"Though providing an intrinsic secrecy, network coding is still vulnerable to eavesdropping attacks, by which an adversary may compromise the confidentiality of message content. Existing studies mainly deal with eavesdroppers that can intercept a lim-ited number of packets. However, real scenarios often consist of more capable adversaries, e.g., global eavesdroppers, which can defeat these techniques. In this paper, we propose P-Coding, a novel security scheme against eavesdropping attacks in network coding. With the lightweight permutation encryption performed on each message and its coding vector, P-Coding can efficiently thwart global eavesdroppers in a transparent way. Moreover, P-Coding is also featured in scalability and robustness, which enable it to be integrated into practical network coded systems. Security analysis and simulation results demonstrate the efficacy and efficiency of the P-Coding scheme.","Network coding,
Cryptography,
Peer to peer computing,
Robustness,
Throughput,
Information security,
Communications Society,
Computer science,
Scalability,
Computational modeling"
Binaural Estimation of Sound Source Distance via the Direct-to-Reverberant Energy Ratio for Static and Moving Sources,"One of the principal cues believed to be used by listeners to estimate the distance to a sound source is the ratio of energies along the direct and indirect paths to the receiver. In essence, this “direct-to-reverberant” energy ratio reveals the absolute distance component of the direct energy by normalizing by what is assumed to be distance-independent reverberant energy. Earlier approaches to direct-to-reverberant energy ratio calculation made use of the estimated room impulse response, but these techniques are computationally expensive and inaccurate in practice. This paper proposes and evaluates an alternative approach which uses binaural signals to segregate energy arriving from the estimated direction of the direct source from that arriving from other directions, employing a novel binaural equalization-cancellation technique. The system is integrated with a probabilistic inference framework, particle filtering, to handle the nonstationarity of energy-based measurements. The algorithm is capable of using reverberation to estimate source distance in large rooms with errors of less than 1 m for static sources and 1.5-3.5 m for sources with varying degrees of motion complexity. Model performance can be accounted for largely in terms of a competition between auditory horizon and source energy fluctuation effects.",
Tactile object class and internal state recognition for mobile manipulation,"Tactile information is valuable in determining properties of objects that are inaccessible from visual perception. In this work, we present a tactile perception strategy that allows any mobile robot with tactile sensors in its gripper to measure a set of generic tactile features while grasping an object. We propose a hybrid velocity-force controller, that grasps an object safely and reveals at the same time its deformation properties. As an application, we show that a robot can use these features to distinguish the open/closed and fill state of bottles and cans - purely from tactile sensing - from a small training set. To prove that this is a hard recognition problem, we also conducted a comperative study with 17 human test subjects. We found that the recognition rate of the human subjects were comparable to our robotic gripper.",
Fuzzy Decision-Making Based on Likelihood-Based Comparison Relations,"In this paper, we present a new fuzzy decision-making method, which is based on likelihood-based comparison relations. First, we introduce the concepts of likelihood-based comparison relations for intervals. Then, we propose the concept of likelihood-based comparison relations for type-1 fuzzy sets and interval type-2 fuzzy sets. Then, we present a new method to rank fuzzy sets by using fuzzy targets based on the proposed likelihood-based comparison relations for fuzzy sets. Finally, we present a new fuzzy decision-making method based on the proposed likelihood-based comparison relations for fuzzy sets and the proposed fuzzy ranking method. The proposed fuzzy decision-making method has the advantage that the evaluated values can either be represented by crisp values, intervals, type-1 fuzzy sets or interval type-2 fuzzy sets. It can overcome the drawbacks of Huynh et al.'s method due to the fact that Huynh et al.'s method cannot deal with the ranking of interval type-2 fuzzy sets for fuzzy decision-making and cannot distinguish the ranking order between the alternatives in some situations.","Decision making,
Fuzzy sets,
Optimization methods,
Councils,
Computer science,
Arithmetic"
Analysis of Worst-Case Delay Bounds for On-Chip Packet-Switching Networks,"In network-on-chip (NoC), computing worst-case delay bounds for packet delivery is crucial for designing predictable systems but yet an intractable problem. This paper presents an analysis technique to derive per-flow communication delay bound. Based on a network contention model, this technique, which is topology independent, employs network calculus to first compute the equivalent service curve for an individual flow and then calculate its packet delay bound. To exemplify this method, this paper also presents the derivation of a closed-form formula to compute a flow's delay bound under all-to-one gather communication. Experimental results demonstrate that the theoretical bounds are correct and tight.","Network-on-a-chip,
Delay,
Telecommunication traffic,
Computer networks,
Calculus,
Switches,
Traffic control,
Network topology,
Performance analysis,
Quality of service"
Massive-Training Artificial Neural Network Coupled With Laplacian-Eigenfunction-Based Dimensionality Reduction for Computer-Aided Detection of Polyps in CT Colonography,"A major challenge in the current computer-aided detection (CAD) of polyps in CT colonography (CTC) is to reduce the number of false-positive (FP) detections while maintaining a high sensitivity level. A pattern-recognition technique based on the use of an artificial neural network (ANN) as a filter, which is called a massive-training ANN (MTANN), has been developed recently for this purpose. The MTANN is trained with a massive number of subvolumes extracted from input volumes together with the teaching volumes containing the distribution for the “likelihood of being a polyp;” hence the term “massive training.” Because of the large number of subvolumes and the high dimensionality of voxels in each input subvolume, the training of an MTANN is time-consuming. In order to solve this time issue and make an MTANN work more efficiently, we propose here a dimension reduction method for an MTANN by using Laplacian eigenfunctions (LAPs), denoted as LAP-MTANN. Instead of input voxels, the LAP-MTANN uses the dependence structures of input voxels to compute the selected LAPs of the input voxels from each input subvolume and thus reduces the dimensions of the input vector to the MTANN. Our database consisted of 246 CTC datasets obtained from 123 patients, each of whom was scanned in both supine and prone positions. Seventeen patients had 29 polyps, 15 of which were 5-9 mm and 14 were 10-25 mm in size. We divided our database into a training set and a test set. The training set included 10 polyps in 10 patients and 20 negative patients. The test set had 93 patients including 19 polyps in seven patients and 86 negative patients. To investigate the basic properties of a LAP-MTANN, we trained the LAP-MTANN with actual polyps and a single source of FPs, which were rectal tubes. We applied the trained LAP-MTANN to simulated polyps and rectal tubes. The results showed that the performance of LAP-MTANNs with 20 LAPs was advantageous over that of the original MTANN with 171 inputs. To test the feasibility of the LAP-MTANN, we compared the LAP-MTANN with the original MTANN in the distinction between actual polyps and various types of FPs. The original MTANN yielded a 95% (18/19) by-polyp sensitivity at an FP rate of 3.6 (338/93) per patient, whereas the LAP-MTANN achieved a comparable performance, i.e., an FP rate of 3.9 (367/93) per patient at the same sensitivity level. With the use of the dimension reduction architecture, the time required for training was reduced from 38 h to 4 h. The classification performance in terms of the area under the receiver-operating-characteristic curve of the LAP-MTANN (0.84) was slightly higher than that of the original MTANN (0.82) with no statistically significant difference (p-value= 0.48).","Artificial neural networks,
Computer networks,
Colonic polyps,
Virtual colonoscopy,
Testing,
Databases,
Filters,
Education,
Laplace equations,
Eigenvalues and eigenfunctions"
Synthesis of Multitask Implementations of Simulink Models With Minimum Delays,"Model-based design of embedded control systems using Synchronous Reactive (SR) models is among the best practices for software development in the automotive and aeronautic industry. SR models allow to formally verify the correctness of the design and automatically generate the implementation code. This feature is a major productivity enhancement and, more importantly, can ensure correct-by-design software provided that the code generator is provably correct. This paper presents an improvement of code generation technology for SR obtained via a novel algorithm for optimizing the multitask implementation of Simulink models on single-processor platforms with limited availability of memory. Existing code generation tools require the addition of zero-order hold (ZOH) blocks, and therefore additional memory, and possibly also additional functional delays whenever there is a rate transition in the computation and communication flow. Our algorithm leverages a novel efficient encoding of the scheduling feasibility region to find the task implementation of function blocks with minimum additional functional delays within timing and memory constraints. The algorithm is applied to an automotive case study with tens of function blocks and very high utilization to test its applicability to complex systems.","Delay,
Computational modeling,
Multitasking,
Real time systems,
Mixed integer linear programming,
Random access memory,
Embedded systems"
Eigen-Based Transceivers for the MIMO Broadcast Channel With Semi-Orthogonal User Selection,"This paper studies the sum rate performance of two low complexity eigenmode-based transmission techniques for the MIMO broadcast channel, employing greedy semi-orthogonal user selection (SUS). The first approach, termed ZFDPC-SUS, is based on zero-forcing dirty paper coding; the second approach, termed ZFBF-SUS, is based on zero-forcing beamforming. We first employ new analytical methods to prove that as the number of users K grows large, the ZFDPC-SUS approach can achieve the optimal sum rate scaling of the MIMO broadcast channel. We also prove that the average sum rates of both techniques converge to the average sum capacity of the MIMO broadcast channel for large K. In addition to the asymptotic analysis, we investigate the sum rates achieved by ZFDPC-SUS and ZFBF-SUS for finite K , and show that ZFDPC-SUS has significant performance advantages. Our results also provide key insights into the benefit of multiple receive antennas, and the effect of the SUS algorithm. In particular, we show that whilst multiple receive antennas only improves the asymptotic sum rate scaling via the second-order behavior of the multi-user diversity gain; for finite K, the benefit can be very significant. We also show the interesting result that the semi-orthogonality constraint imposed by SUS, whilst facilitating a very low complexity user selection procedure, asymptotically does not reduce the multi-user diversity gain in either first ( K) or second-order (K) terms.","Transceivers,
MIMO,
Broadcasting,
Receiving antennas,
Sun,
Array signal processing,
Transmitting antennas,
Diversity methods,
Permission,
Covariance matrix"
Detecting and parsing architecture at city scale from range data,"We present a method for detecting and parsing buildings from unorganized 3D point clouds into a compact, hierarchical representation that is useful for high-level tasks. The input is a set of range measurements that cover large-scale urban environment. The desired output is a set of parse trees, such that each tree represents a semantic decomposition of a building – the nodes are roof surfaces as well as volumetric parts inferred from the observable surfaces. We model the above problem using a simple and generic grammar and use an efficient dependency parsing algorithm to generate the desired semantic description. We show how to learn the parameters of this simple grammar in order to produce correct parses of complex structures. We are able to apply our model on large point clouds and parse an entire city.","Cities and towns,
Buildings,
Clouds,
Laboratories,
Large-scale systems,
Robustness,
Computer architecture,
Computer science,
Layout,
Encoding"
Topomorphologic Separation of Fused Isointensity Objects via Multiscale Opening: Separating Arteries and Veins in 3-D Pulmonary CT,"A novel multiscale topomorphologic approach for opening of two isointensity objects fused at different locations and scales is presented and applied to separating arterial and venous trees in 3-D pulmonary multidetector X-ray computed tomography (CT) images. Initialized with seeds, the two isointensity objects (arteries and veins) grow iteratively while maintaining their spatial exclusiveness and eventually form two mutually disjoint objects at convergence. The method is intended to solve the following two fundamental challenges: how to find local size of morphological operators and how to trace continuity of locally separated regions. These challenges are met by combining fuzzy distance transform (FDT), a morphologic feature with a topologic fuzzy connectivity, and a new morphological reconstruction step to iteratively open finer and finer details starting at large scales and progressing toward smaller scales. The method employs efficient user intervention at locations where local morphological separability assumption does not hold due to imaging ambiguities or any other reason. The approach has been validated on mathematically generated tubular objects and applied to clinical pulmonary noncontrast CT data for separating arteries and veins. The tradeoff between accuracy and the required user intervention for the method has been quantitatively examined by comparing with manual outlining. The experimental study, based on a blind seed selection strategy, has demonstrated that above 95% accuracy may be achieved using 25-40 seeds for each of arteries and veins. Our method is very promising for semiautomated separation of arteries and veins in pulmonary CT images even when there is no object-specific intensity variation at conjoining locations.",
Binary Tissue Classification on Wound Images With Neural Networks and Bayesian Classifiers,"A pressure ulcer is a clinical pathology of localized damage to the skin and underlying tissue caused by pressure, shear, or friction. Diagnosis, treatment, and care of pressure ulcers are costly for health services. Accurate wound evaluation is a critical task for optimizing the efficacy of treatment and care. Clinicians usually evaluate each pressure ulcer by visual inspection of the damaged tissues, which is an imprecise manner of assessing the wound state. Current computer vision approaches do not offer a global solution to this particular problem. In this paper, a hybrid approach based on neural networks and Bayesian classifiers is used in the design of a computational system for automatic tissue identification in wound images. A mean shift procedure and a region-growing strategy are implemented for effective region segmentation. Color and texture features are extracted from these segmented regions. A set of k multilayer perceptrons is trained with inputs consisting of color and texture patterns, and outputs consisting of categorical tissue classes which are determined by clinical experts. This training procedure is driven by a k-fold cross-validation method. Finally, a Bayesian committee machine is formed by training a Bayesian classifier to combine the classifications of the k neural networks. Specific heuristics based on the wound topology are designed to significantly improve the results of the classification. We obtain high efficiency rates from a binary cascade approach for tissue identification. Results are compared with other similar machine-learning approaches, including multiclass Bayesian committee machine classifiers and support vector machines. The different techniques analyzed in this paper show high global classification accuracy rates. Our binary cascade approach gives high global performance rates (average sensitivity =78.7% , specificity =94.7% , and accuracy =91.5% ) and shows the highest average sensitivity score ( =86.3%) when detecting necrotic tissue in the wound.",
Cyber-physical energy systems: Focus on smart buildings,"Operating at the intersection of multiple sensing and control systems designed for occupant comfort, performability and operational efficiency, modern buildings represent a prototypical cyber-physical system with deeply coupled embedded sensing and networked information processing that has increasingly become part of our daily lives. In this paper, we look at modern buildings entirely as a cyber-physical energy system and examine the opportunities presented by the joint optimization of energy use by its occupants and information processing equipment. This paper makes two contributions: one, a careful examination of different types of buildings and their energy use; two, opportunities available to improve energy efficient operation through various strategies from lighting to computing. Using a modern 150,000 sq feet office building as a closed system, we detail different strategies to reduce energy use from LEED certification to zero net energy use.","Smart buildings,
Information processing,
Energy efficiency,
Control systems,
Smart grids,
Water heating,
Permission,
Buffer storage,
Production,
Aerospace engineering"
The contribution of real-time mirror reflections of motor actions on virtual body ownership in an immersive virtual environment,"This paper reports an experiment that investigated people's body ownership of an avatar that was observed in a virtual mirror. Twenty subjects were recruited in a within-groups study where 10 first experienced a virtual character that synchronously reflected their upper-body movements as seen in a virtual mirror, and then an asynchronous condition where the mirror avatar displayed prerecorded actions, unrelated to those of the participant. The other 10 subjects experienced the conditions in the opposite order. In both conditions the participant could carry out actions that led to elevation above ground level, as seen from their first person perspective and correspondingly in the mirror. A rotating virtual fan eventually descended to 2 m above the ground. The hypothesis was that synchronous mirror reflection would result in higher subjective sense of ownership. A questionnaire analysis showed that the body ownership illusion was significantly greater for the synchronous than asynchronous condition. Additionally participants in the synchronous condition avoided collision with the descending fan significantly more often than those in the asynchronous condition. The results of this experiment are put into context within similar experiments on multisensory correlation and body ownership within cognitive neuroscience.",
ContextML: A light-weight context representation and context management schema,"Context representation is a fundamental process in developing context aware systems for the pervasive world. We present a light weight XML based context representation schema called ContextML in which context information is categorized into scopes and related to different types of entities (e.g. user, device). The schema is also applied for encoding management messages in order to allow for a flexible framework supporting gradual plug & play extendibility and mobility. ContextML is tailored to be used for REST-based communication between the framework components. Explanation of the schema is provided with the help of real world examples. Moreover, the European C-CAST testbed is introduced, embracing a variety of context providers and application domains.",
11-Level cascaded H-bridge grid-tied inverter interface with solar panels,This paper presents a single-phase 11-level (5 H-bridges) cascade multilevel DC-AC grid-tied inverter. Each inverter bridge is connected to a 200 W solar panel. OPAL-RT lab was used as the hardware in the loop (HIL) real-time control system platform where a Maximum Power Point Tracking (MPPT) algorithm was implemented based on the inverter output power to assure optimal operation of the inverter when connected to the power grid as well as a Phase Locked Loop (PLL) for phase and frequency match. A novel SPWM scheme is proposed in this paper to be used with the solar panels that can account for voltage profile fluctuations among the panels during the day. Simulation and experimental results are shown for voltage and current during synchronization mode and power transferring mode to validate the methodology for grid connection of renewable resources.,
Ground-Bouncing-Noise-Aware Combinational MTCMOS Circuits,Ground bouncing noise produced during the SLEEP to ACTIVE mode transitions is an important challenge in standard multithreshold CMOS (MTCMOS) circuits. The effectiveness of different noise-aware combinational MTCMOS circuit techniques to deal with the ground-bouncing-noise phenomenon is evaluated in this paper. An intermediate relaxation mode is investigated to gradually dump the charge stored on the virtual lines to the real ground distribution network during the SLEEP to ACTIVE mode transitions. The dependence of ground bouncing noise on the sleep transistor size and temperature is characterized with different power-gating structures. The peak amplitude of ground bouncing noise is reduced by up to 76.62% with the noise-aware techniques without sacrificing the savings in leakage power consumption as compared with standard MTCMOS circuits in a 90-nm CMOS technology.,
Analysis of CM Volt-Second Influence on CM Inductor Saturation and Design for Input EMI Filters in Three-Phase DC-Fed Motor Drive Systems,"Common-mode (CM) choke saturation is a practical problem in CM filter applications. It is generally believed that the leakage inductance of CM chokes makes the core saturated. This paper analyzes two new mechanisms for CM choke saturation due to CM voltage, and these mechanisms are verified in experiment. CM choke saturation is particularly important for motor drive systems, which have a high CM voltage and comparably higher stray grounding capacitance. A model is established to describe the relationship between the CM voltage and the volume of the CM magnetic components. According to the analysis, line impedance stabilization networks (LISNs) play an important role in the design of CM magnetic components.",
Multi-agent control system with intelligent optimization for smart and energy-efficient buildings,"In this paper, a new control system with an intelligent optimizer is developed which can be applied to energy and comfort management in the smart and energy-efficient buildings. Hierarchical multi-agent theory is used to build this control system, which contains agent-controllers at two levels — a central coordinator-agent at the higher level and multiple local controller-agents at the lower level. Particle Swarm Optimization (PSO) is adopted to optimize the set points of the control system during system operations. This multi-agent intelligent control system is utilized to minimize the main conflict in smart and energy-efficient buildings in terms of power consumption and customers' comfort.","Lighting,
Buildings,
Niobium,
Temperature measurement,
Temperature control,
Energy efficiency"
Time-Varying Path-Shadowing Model for Indoor Populated Environments,"This paper presents a path-shadowing model for indoor populated environments that has been developed based on computer simulations. The propagation paths between the transmitting and receiving points in an empty rectangular space are determined using the ray-tracing method, in which moving quasi-human bodies that are modeled as cylinders with a finite height are generated in the space, and intersections of the paths with the bodies are counted. From the results, the shadowing probabilities, durations, and intervals are evaluated for each propagation path, and this shadowing process is characterized as a Markov process. This paper proposes a method that individually generates the shadowing effects on each propagation path. The measurement results of the path-shadowing characteristics using a 5.2-GHz high-resolution channel sounder are presented, and the validity of this model is confirmed. Similar measurement results using a photoelectric sensor are also presented to reinforce the channel-sounding measurement results.","Shadow mapping,
Humans,
Acoustic propagation,
Indoor environments,
Biological system modeling,
Computer simulation,
Ray tracing,
Markov processes,
Sensor phenomena and characterization,
Acoustic sensors"
Automatic filter design for synthesis of haptic textures from recorded acceleration data,"Sliding a probe over a textured surface generates a rich collection of vibrations that one can easily use to create a mental model of the surface. Haptic virtual environments attempt to mimic these real interactions, but common haptic rendering techniques typically fail to reproduce the sensations that are encountered during texture exploration. Past approaches have focused on building a representation of textures using a priori ideas about surface properties. Instead, this paper describes a process of synthesizing probe-surface interactions from data recorded from real interactions. We explain how to apply the mathematical principles of Linear Predictive Coding (LPC) to develop a discrete transfer function that represents the acceleration response under specific probe-surface interaction conditions. We then use this predictive transfer function to generate unique acceleration signals of arbitrary length. In order to move between transfer functions from different probe-surface interaction conditions, we develop a method for interpolating the variables involved in the texture synthesis process. Finally, we compare the results of this process with real recorded acceleration signals, and we show that the two correlate strongly in the frequency domain.","Filters,
Haptic interfaces,
Acceleration,
Surface texture,
Transfer functions,
Signal synthesis,
Linear predictive coding,
Probes,
Cognitive science,
Virtual environment"
Active Learning Methods for Electrocardiographic Signal Classification,"In this paper, we present three active learning strategies for the classification of electrocardiographic (ECG) signals. Starting from a small and suboptimal training set, these learning strategies select additional beat samples from a large set of unlabeled data. These samples are labeled manually, and then added to the training set. The entire procedure is iterated until the construction of a final training set representative of the considered classification problem. The proposed methods are based on support vector machine classification and on the: 1) margin sampling; 2) posterior probability; and 3) query by committee principles, respectively. To illustrate their performance, we conducted an experimental study based on both simulated data and real ECG signals from the MIT-BIH arrhythmia database. In general, the obtained results show that the proposed strategies exhibit a promising capability to select samples that are significant for the classification process, i.e., to boost the accuracy of the classification process while minimizing the number of involved labeled samples.","Accuracy,
Electrocardiography,
Support vector machines,
Training,
Classification algorithms,
Learning methods,
Pattern classification"
Needle-Based Interventions With the Image-Guided Surgery Toolkit (IGSTK): From Phantoms to Clinical Trials,"We present three image-guided navigation systems developed for needle-based interventional radiology procedures, using the open source image-guided surgery toolkit (IGSTK). The clinical procedures we address are vertebroplasty, RF ablation of large lung tumors, and lung biopsy. In vertebroplasty, our system replaces the use of fluoroscopy, reducing radiation exposure to patient and physician. We evaluate this system using a custom phantom and compare the results obtained by a medical student, an interventional radiology fellow, and an attending physician. In RF ablation of large lung tumors, our system provides an automated interventional plan that minimizes damage to healthy tissue and avoids critical structures, in addition to accurate guidance of multiple electrode insertions. We evaluate the system's performance using an animal model. Finally, in the lung biopsy procedure, our system replaces the use of computed tomographic (CT) fluoroscopy, reducing radiation exposure to patient and physician, while at the same time enabling oblique trajectories which are considered challenging under CT fluoroscopy. This system is currently being used in an ongoing clinical trial at Georgetown University Hospital and was used in three cases.","Surgery,
Imaging phantoms,
Clinical trials,
Radiology,
Radio frequency,
Lung neoplasms,
Biopsy,
Computed tomography,
Radio navigation,
Biomedical imaging"
Parallel MRI Using Phased Array Coils,"Parallel MRI using phased array coils can be viewed as an application of the multichannel sampling theory. Specifically, in the case of uniform 1-D undersampling, Papoulis' classical reconstruction formulas correspond well to the existing parallel MRI reconstruction algorithms, and a number of practical issues can be analyzed in this context. However, parallel MRI also presents several unique signal processing problems, whose solutions can help maximize the potential of parallel MRI for fast imaging. While existing parallel MRI methods were developed independently of the multichannel sampling theory, making such a connection may help develop more optimal methods for parallel MRI data acquisition and image reconstruction.","Phased arrays,
Magnetic resonance imaging,
Coils,
Signal sampling,
Image reconstruction,
Reconstruction algorithms,
Algorithm design and analysis,
Signal processing algorithms,
Image sampling,
Data acquisition"
Learning an Intrinsic-Variable Preserving Manifold for Dynamic Visual Tracking,"Manifold learning is a hot topic in the field of computer science, particularly since nonlinear dimensionality reduction based on manifold learning was proposed in Science in 2000. The work has achieved great success. The main purpose of current manifold-learning approaches is to search for independent intrinsic variables underlying high dimensional inputs which lie on a low dimensional manifold. In this paper, a new manifold is built up in the training step of the process, on which the input training samples are set to be close to each other if the values of their intrinsic variables are close to each other. Then, the process of dimensionality reduction is transformed into a procedure of preserving the continuity of the intrinsic variables. By utilizing the new manifold, the dynamic tracking of a human who can move and rotate freely is achieved. From the theoretical point of view, it is the first approach to transfer the manifold-learning framework to dynamic tracking. From the application point of view, a new and low dimensional feature for visual tracking is obtained and successfully applied to the real-time tracking of a free-moving object from a dynamic vision system. Experimental results from a dynamic tracking system which is mounted on a dynamic robot validate the effectiveness of the new algorithm.","Humans,
Mathematics,
Robots,
Laboratories,
Automation,
Image reconstruction,
Computer science,
Real time systems,
Machine vision"
Robust Web Image/Video Super-Resolution,"This paper proposes a robust single-image super-resolution method for enlarging low quality web image/video degraded by downsampling and compression. To simultaneously improve the resolution and perceptual quality of such web image/video, we bring forward a practical solution which combines adaptive regularization and learning-based super-resolution. The contribution of this work is twofold. First, we propose to analyze the image energy change characteristics during the iterative regularization process, i.e., the energy change ratio between primitive (e.g., edges, ridges and corners) and nonprimitive fields. Based on the revealed convergence property of the energy change ratio, appropriate regularization strength can then be determined to well balance compression artifacts removal and primitive components preservation. Second, we verify that this adaptive regularization can steadily and greatly improve the pair matching accuracy in learning-based super-resolution. Consequently, their combination effectively eliminates the quantization noise and meanwhile faithfully compensates the missing high-frequency details, yielding robust super-resolution performance in the compression scenario. Experimental results demonstrate that our solution produces visually pleasing enlargements for various web images/videos.","Robustness,
Image resolution,
Video compression,
Strontium,
Image coding,
Degradation,
Energy resolution,
Spatial resolution,
Image storage,
Sun"
Perfectly Complementary Relay Design for Digital Logic Applications,"A dual-ended (¿seesaw¿) relay design is proposed for ultralow-power digital logic applications. Fabricated seesaw relays demonstrate a perfectly complementary switching behavior that is symmetric about V DD/2, with extremely steep switching behavior (< 0.1 mV/dec) and low on -state resistance (< 1 k¿). The perfectly complementary and symmetric operation provides for maximum operating voltage margin and minimal crowbar current, as evidenced by an abrupt inverter voltage transfer characteristic.","Digital relays,
Logic design,
Voltage,
Electrodes,
Nanoelectromechanical systems,
Switching circuits,
Electrostatics,
Fabrication,
Immune system,
Inverters"
The Impact of Delta-Rays on Single-Event Upsets in Highly Scaled SOI SRAMs,"Monte-Carlo radiation transport simulations are used to quantify energy deposition from δ -rays in sensitive volumes representative of future SRAM technologies. The results show that single and multiple δ-ray events are capable of depositing sufficient energy to cause SEUs in nonadjacent SRAM cells separated by many micrometers. These results indicate the necessity of considering the variability of the charge track structure when evaluating the single event response of these highly scaled technology nodes. These effects have important implications forradiation hardening techniques that rely upon spatial separation of critical and redundant nodes, and simulation of device and circuit level response to heavy ions with respect to ion track structure.","Single event upset,
SRAM chips,
Monte Carlo methods,
Radiation hardening"
Interrobot Transformations in 3-D,"In this paper, we provide a study of motion-induced 3-D extrinsic calibration based on robot-to-robot sensor measurements. In particular, we introduce algebraic methods to compute the relative translation and rotation between two robots using known robot motion and robot-to-robot (1) distance and bearing, (2) bearing-only, and (3) distance-only measurements. We further conduct a nonlinear observability analysis and provide sufficient conditions for the 3-D relative position and orientation (pose) to become locally weakly observable. Finally, we present a nonlinear weighted least-squares estimator to refine the algebraic pose estimate in the presence of noise. We use simulations to evaluate the performance of our methods in terms of accuracy and robustness.",
A Fuzzy-Statistics-Based Affinity Propagation Technique for Clustering in Multispectral Images,"Due to a high number of spectral channels and a large information quantity, multispectral remote-sensing images are difficult to be classified with high accuracy and efficiency by conventional classification methods, particularly when training data are not available and when unsupervised clustering techniques should be considered for data analysis. In this paper, we propose a novel image clustering method [called fuzzy-statistics-based affinity propagation (FS-AP)] which is based on a fuzzy statistical similarity measure (FSS) to extract land-cover information in multispectral imagery. AP is a clustering algorithm proposed recently in the literature, which exhibits a fast execution speed and finds clusters with small error, particularly for large datasets. FSS can get objective estimates of how closely two pixel vectors resemble each other. The proposed method simultaneously considers all data points to be equally suitable as initial exemplars, thus reducing the dependence of the final clustering from the initialization. Results obtained on three kinds of multispectral images (Landsat-7 ETM+, Quickbird, and moderate resolution imaging spectroradiometer) by comparing the proposed technique with K-means, fuzzy K-means, and AP based on Euclidean distance (ED-AP) demonstrate the good efficiency and high accuracy of FS-AP.","Multispectral imaging,
Remote sensing,
Frequency selective surfaces,
Training data,
Data analysis,
Clustering methods,
Data mining,
Clustering algorithms,
Satellites,
MODIS"
Almost Isometric Mesh Parameterization through Abstract Domains,"In this paper, we propose a robust, automatic technique to build a global hi-quality parameterization of a two-manifold triangular mesh. An adaptively chosen 2D domain of the parameterization is built as part of the process. The produced parameterization exhibits very low isometric distortion, because it is globally optimized to preserve both areas and angles. The domain is a collection of equilateral triangular 2D regions enriched with explicit adjacency relationships (it is abstract in the sense that no 3D embedding is necessary). It is tailored to minimize isometric distortion, resulting in excellent parameterization qualities, even when meshes with complex shape and topology are mapped into domains composed of a small number of large continuous regions. Moreover, this domain is, in turn, remapped into a collection of 2D square regions, unlocking many advantages found in quad-based domains (e.g., ease of packing). The technique is tested on a variety of cases, including challenging ones, and compares very favorably with known approaches. An open-source implementation is made available.",
On a taxonomy of facial features,"After nearly a decade of intensive research in face recognition, no standard organization exists for grouping the salient information available in 2D face images into feature categories. At the same time, human verification of a subject's identity based on facial images lacks a consistent methodology. In this paper we propose a taxonomy of available facial features that: (i) serves as a precursor to studies on the individuality of facial features, (ii) follows a similar well established and accepted organization for fingerprint features, and (iii) contains features computable by both machines and humans as well as by machines alone. This manuscript is intended as a strawman of an organization of facial features, that would hopefully lead to a standardization of such features. Such a facial feature organization will (i) enable studies on the individuality of facial features, which has important ramifications for the acceptance of expert testimony in legal proceedings for determining the identity of an individual from a facial photograph, and (ii) help standardize the framework of commercial face recognition systems.","Face,
Face recognition,
Facial features,
Feature extraction,
Humans,
Law"
Affective Audio-Visual Words and Latent Topic Driving Model for Realizing Movie Affective Scene Classification,"This paper presents a novel method for movie affective scene classification that outputs the emotion (in the form of labels) that the scene is likely to arouse in viewers. Since the affective preferences of users play an important role in movie selection, affective scene classification has the potential to develop more attractive user-centric movie search and browsing applications. Two main issues in designing movie affective scene classification are considered. One is “how to extract features that are strongly related to the viewer's emotions”, and the other is “how to map the extracted features to the emotion categories”. For the former, we propose a method to extract emotion-category-specific audio-visual features named affective audio-visual words (AAVWs). For the latter issue, we propose a classification model named latent topic driving model (LTDM). Assuming that viewers' emotions are dynamically changed by the movie scene sequences, LTDM models emotions as Markovian dynamic systems driven by the sequential stimuli of the movie content. Experiments on 206 movie scenes extracted from 24 movie titles and the corresponding labels of eight emotion categories given by 16 subjects show that our method outperforms conventional approaches in terms of the subject agreement rate.",
Real-time semi-global dense stereo solution with improved sub-pixel accuracy,"In this work we focus on creating a real-time dense stereo reconstruction system with accurate sub-pixel estimation. We selected the Semi-Global Matching method as the basis of our system due to its high quality and possible real-time implementations. In our solution we use the Census transform as the matching metric because our results show that it can reduce the matching errors for traffic images compared to classical solutions. We also propose several modifications to the original Semi-Global algorithm to improve the sub-pixel accuracy and the execution time. One of these proposals is the reduction in the number of optimization directions without affecting the results. The second modification is a correction of the energy function to reduce the spread of depth values. Besides these improvements, the paper also introduces a new aggregation method used to reduce the spread of sub-pixel values. Finally we propose a new method to generate sub-pixel interpolation functions based on real-world data. The result of these enhancements is a significant improvement in sub-pixel accuracy. The system was implemented and evaluated on a current generation GPU with a running time of 19ms for image having the resolution 512×383.",
Silicon-Controlled Rectifier Stacking Structure for High-Voltage ESD Protection Applications,"Latchup immunity is a challenging issue for the design of power supply clamps used in high-voltage electrostatic discharge (ESD) protection applications. While silicon-controlled rectifiers (SCRs) are highly robust ESD devices, they are traditionally not suited for high-voltage ESD due to their inherent low holding voltage and, thus, vulnerability to latchup. In this letter, a novel SCR stacking structure with an extremely high holding voltage, very small snapback, and acceptable failure current has been developed. The new and existing high holding voltage ESD devices are also compared to demonstrate the advancement of this work.","Rectifiers,
Stacking,
Electrostatic discharge,
Protection,
Thyristors,
Low voltage,
Robustness,
Clamps,
MOSFET circuits,
Computer science"
Off-State Breakdown Characterization in AlGaN/GaN HEMT Using Drain Injection Technique,"AlGaN/GaN high-electron mobility transistor's (HEMT's) off-state breakdown is investigated using drain-current injection techniques with different injection current levels. Competitions between the source leakage and gate leakage, pure leakage and impact ionization, and source- and gate-injection-induced impact ionization during the drain-injection measurement are discussed in detail. It was found that the breakdown originates from the source/gate leakage at low drain injection levels but is dominated by source/gate-induced impact ionization process at high drain injection currents. The source-induced impact ionization usually precedes the gate-induced impact ionization in low-gate leakage devices, resulting in a premature three-terminal off-state breakdown. We also found that the gate-bias value affects the breakdown voltage in the conventional three-terminal off-state breakdown I-V measurement and should be carefully considered.",
Towards an Affect Space for robots to display emotional body language,"In order for robots to be socially accepted and generate empathy it is necessary that they display rich emotions. For robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve its sociability. This research investigates the creation of an Affect Space for the generation of emotional body language to be displayed by robots. To create an Affect Space for body language, one has to establish the contribution of the different positions of the joints to the emotional expression. The experiment reported in this paper investigated the effect of varying a robot's head position on the interpretation, Valence, Arousal and Stance of emotional key poses. It was found that participants were better than chance level in interpreting the key poses. This finding confirms that body language is an appropriate medium for robot to express emotions. Moreover, the results of this study support the conclusion that Head Position is an important body posture variable. Head Position up increased correct identification for some emotion displays (pride, happiness, and excitement), whereas Head Position down increased correct identification for other displays (anger, sadness). Fear, however, was identified well regardless of Head Position. Head up was always evaluated as more highly Aroused than Head straight or down. Evaluations of Valence (degree of negativity to positivity) and Stance (degree to which the robot was aversive to approaching), however, depended on both Head Position and the emotion displayed. The effects of varying this single body posture variable were complex.","Robots,
Head,
Joints,
Analysis of variance,
Atmospheric measurements,
Particle measurements,
Position measurement"
Supervised Neural Network Modeling: An Empirical Investigation Into Learning From Imbalanced Data With Labeling Errors,"Neural network algorithms such as multilayer perceptrons (MLPs) and radial basis function networks (RBFNets) have been used to construct learners which exhibit strong predictive performance. Two data related issues that can have a detrimental impact on supervised learning initiatives are class imbalance and labeling errors (or class noise). Imbalanced data can make it more difficult for the neural network learning algorithms to distinguish between examples of the various classes, and class noise can lead to the formulation of incorrect hypotheses. Both class imbalance and labeling errors are pervasive problems encountered in a wide variety of application domains. Many studies have been performed to investigate these problems in isolation, but few have focused on their combined effects. This study presents a comprehensive empirical investigation using neural network algorithms to learn from imbalanced data with labeling errors. In particular, the first component of our study investigates the impact of class noise and class imbalance on two common neural network learning algorithms, while the second component considers the ability of data sampling (which is commonly used to address the issue of class imbalance) to improve their performances. Our results, for which over two million models were trained and evaluated, show that conclusions drawn using the more commonly studied C4.5 classifier may not apply when using neural networks.","Neural networks,
Labeling,
Training data,
Sampling methods,
Sociotechnical systems,
Multilayer perceptrons,
Radial basis function networks,
Supervised learning,
Data mining,
Machine learning"
Step Construction of Visual Cryptography Schemes,"Two common drawbacks of the visual cryptography scheme (VCS) are the large pixel expansion of each share image and the small contrast of the recovered secret image. In this paper, we propose a step construction to construct VCSOR and VCSXOR for general access structure by applying (2,2)-VCS recursively, where a participant may receive multiple share images. The proposed step construction generates VCSOR and VCSXOR which have optimal pixel expansion and contrast for each qualified set in the general access structure in most cases. Our scheme applies a technique to simplify the access structure, which can reduce the average pixel expansion (APE) in most cases compared with many of the results in the literature. Finally, we give some experimental results and comparisons to show the effectiveness of the proposed scheme.","Cryptography,
Pixel,
Laboratories,
Information security,
Computer science,
Marine technology,
Oceans"
Hybrid Multiple Description Coding Based on H.264,"Multiple description (MD) video coding is one of the approaches that can be used to reduce the detrimental effects caused by transmission over error-prone networks. A number of approaches have been proposed for MD coding, where each provides a different tradeoff between compression efficiency and error resilience. This paper first presents two basic MD coding methods; one segments the video in the spatial domain, while the other in the frequency domain. Then a hybrid MD coding method is proposed. The hybrid MD encoder segments the video in both the spatial and frequency domains. In the case of data loss, the hybrid MD decoder takes advantage of the residual-pixel correlations in the spatial domain, and the coefficient correlations in the frequency domain, for error concealment. As a result, better error resilience can be achieved at high compression efficiency. The advantages of the proposed hybrid MD method are demonstrated in the contexts of descriptor loss in ideal channels and in packet-loss networks.",
Discrimination of Breast Tumors in Ultrasonic Images Using an Ensemble Classifier Based on the AdaBoost Algorithm With Feature Selection,"This paper proposes a novel algorithm to estimate a log-compressed K distribution parameter and presents an algorithm to discriminate breast tumors in ultrasonic images. We computed a total of 208 features for discrimination, including those based on a parameter of a log-compressed K-distribution, which quantifies the homogeneity of the echo pattern in the tumor, but is influenced by compression parameters in the ultrasonic device. The proposed algorithm estimates the parameter of the log-compressed K-distribution in a manner free from this influence. To quantify irregularities in tumor shape, pattern-spectrum-based features were newly developed in this paper. The discrimination process uses an ensemble classifier trained by a multiclass AdaBoost learning algorithm (AdaBoost.M2), combined with a sequential feature-selection process. A 10-fold cross-validation test validated the performance, and the results were compared with those of a Mahalanobis distance-based classifier and a multiclass support vector machine. A total of 200 carcinomas, 50 fibroadenomas, and 50 cysts were used in the experiments. This paper demonstrates that the combination of a classifier trained by AdaBoost.M2 and features based on the estimated parameter of a log-compressed K-distribution, as well as those of the pattern spectrum, are useful for the discrimination of tumors.",
Current Trends in Industrial Electronics Education,"Technology development creates many challenges in the education of industrial-electronics (IE)-related subjects. At the same time, it allows new educational paradigms to be implemented. The main contribution of this paper is to initiate a discussion for the needs and challenges of IE education both at university level and in lifelong learning, in order to meet the requirements of the emerging technologies of the 21st century. Educational challenges and opportunities are first identified and analyzed. Afterward, an overview of state-of-the-art learning methodologies and tools is presented. New educational paradigms and future directions are also identified.",
New Classes of Balanced Quaternary and Almost Balanced Binary Sequences With Optimal Autocorrelation Value,"Sequences with optimal autocorrelation property are needed in certain communication systems and cryptography. In this paper, a construction of balanced quaternary sequences with period N ≡ 2 (mod 4) and optimal autocorrelation value and a construction of almost balanced binary sequences with period N ≡ 0 (mod 4) and optimal autocorrelation value are presented. Both constructions are a generalization of earlier ones.","Cryptography,
Binary sequences,
Correlation,
Communication systems"
Collaborative Quickest Spectrum Sensing via Random Broadcast in Cognitive Radio Systems,"Quickest detection is applied in spectrum sensing in cognitive radio systems when multiple secondary users collaborate with limited communication time slots. When the transmissions of sensing results are not coordinated to avoid confliction, random broadcast is used to exchange information. A necessary condition for the optimal broadcast probability, as a function of the log likelihood ratio of local observation, is obtained using variational analysis. To alleviate the difficulty of computing the optimal broadcast probability, a simple threshold broadcast scheme is proposed. Simulation shows that the proposed threshold broadcast scheme can achieve substantial performance gain (less than 60% in detection delay for the same false alarm rate) over schemes of random broadcast without regulation and single-user spectrum sensing.","Collaboration,
Radio broadcasting,
Cognitive radio,
Delay,
Robustness,
Computational modeling,
Performance gain,
Wireless communication,
Licenses,
Frequency"
Secure Wireless Communication with Dynamic Secrets,"This paper introduces a set of low-complexity algorithms that when coupled with link layer retransmission mechanisms, strengthen wireless communication security. Our basic idea is to generate a series of secrets from inevitable transmission errors and other random factors in wireless communications. Because these secrets are constantly extracted from the communication process in realtime, we call them dynamic secrets. Dynamic secrets have interesting security properties. They offer a complementary mechanism to existing security protocols. Even if the adversary exploits a vulnerability and steals the underlying system secret, security can be automatically replenished. In many scenarios, it is also possible to bootstrap a secure communication with the dynamic secrets.","Wireless communication,
Communication system security,
Public key,
Communications Society,
Computer science,
Couplings,
Computer security,
Computer errors,
Protocols,
Mobile communication"
A Father Protocol for Quantum Broadcast Channels,"A new protocol for quantum broadcast channels based on the fully quantum Slepian-Wolf protocol is presented. The protocol yields an achievable rate region for entanglement-assisted transmission of quantum information through a quantum broadcast channel that can be considered the quantum analogue of Marton's region for classical broadcast channels. The protocol can be adapted to yield achievable rate regions for unassisted quantum communication and for entanglement-assisted classical communication; in the case of unassisted transmission, the region we obtain has no independent constraint on the sum rate, only on the individual transmission rates. Regularized versions of all three rate regions are provably optimal.","Protocols,
Broadcasting,
Quantum entanglement,
Quantum mechanics,
Computer science,
Information theory,
Degradation,
Probability distribution,
Laboratories,
Codes"
Energy-Optimal Dynamic Thermal Management: Computation and Cooling Power Co-Optimization,"Conventional dynamic thermal management (DTM) assumes that the thermal resistance of a heat-sink is a given constant determined at design time. However, the thermal resistance of a common forced-convection heat sink is inversely proportional to the flow rate of the air or coolant at the expense of the cooling power consumption. The die temperature of the silicon devices strongly affects its leakage power consumption and reliability, and it can be changed by adjusting the thermal resistance of the cooling devices. Different from conventional DTM which aims to avoid the thermal emergency, our proposed DTM regards the thermal resistance of a forced-convection heat sink as a control variable, and minimize the total power consumption both for computation and cooling. We control the cooling power consumption together with the microprocessor clock frequency and supply voltage, and track the energy-optimal die temperature. Consequently, we reduce a significant amount of the temperature-dependent leakage power consumption of the microprocessor while spending a bit higher cooling power than conventional DTM, and eventually consume less total power. Experimental results show the proposed DTM saves up to 8.2% of the total energy compared with a baseline DTM approach. Our proposed DTM also enhances the Failures in Time (FIT) up to 80% in terms of the electromigration lifetime reliability.",
An In-VM Measuring Framework for Increasing Virtual Machine Security in Clouds,"Cloud computing relies heavily on virtualization. Virtualization technology has developed rapidly because of the rapid decrease in hardware cost and concurrent increase in hardware computing power. A virtual machine monitor (VMM, also called a hγpervisor) between the hardware and the OS enables multiple virtual machines (VMs) to run on top of a single physical machine. The VMM manages scheduling and dispatching the physical resources to the individual VMs as needed, and the VMs appear to users as separate computers. Widely used virtualization technologies include VMWare, Xen, Denali, and the Kernel-Based Virtual Machine (KVM). In this framework, a module measures executables running in virtual machines (VMs) and transfers the values to a trusted VM. Comparing those values to a reference table containing the trusted measurement values of running executables verifies the executable/s status.","Cloud computing,
Monitoring,
Hardware,
Prototypes,
Virtual machine monitors"
Multiple-Shape Reconstruction by Means of Multiregion Level Sets,"In the framework of inverse scattering techniques for microwave imaging, this paper proposes an approach based on the integration between a multiscaling procedure and the level-set-based optimization in order to properly deal with the shape reconstruction of multiple and disconnected homogeneous scatterers. The effectiveness and robustness of the proposed approach is assessed against both synthetic and experimental data. A selected set of results concerned with complex shapes is presented and discussed.",
Securing multi-antenna two-way relay channels with analog network coding against eavesdroppers,"This work investigates the vulnerability of analog network coding (ANC) to physical layer attacks from adversarial users, when all nodes are equipped with multiple antennas. Specifically, we examine the MIMO two way relay channel (TWRC) with two users trying to communicate with each other via a relay node in the presence of a passive eavesdropper. We propose a new performance metric, namely the secrecy sum rate of the MIMO TWRC, to quantify performance. We then consider secure transmission strategies for the scenarios of no eavesdropper channel state information at the transmitters (ECSIT) and complete ECSIT, respectively. Finally, numerical results are presented to illustrate the improvement in secrecy obtained with the proposed transmission schemes.",
High-Voltage Generation With Stacked Photodiodes in Standard CMOS Process,"In this letter, a method to generate a high open-circuit voltage using integrated photodiodes fabricated in a standard CMOS process is described. In contrast to conventional high-voltage generation schemes that serially connect photodiodes using different substrates or high-cost silicon-on-insulator processes, the proposed scheme preserves a single substrate solution using a low-cost standard CMOS process. The proposed scheme exploits the photocurrent generation capabilities of different photodiode implementations available in a standard CMOS process and provides compensation for parasitic losses to generate a high output voltage using series connections of photodiodes. Output voltages of 0.84 and 1.3 V are successfully generated by two-stage and three-stage photodiode connections using an AMS 0.35-μm standard CMOS process, respectively. Our proposed scheme is therefore suitable for low-cost high-integration-level system-on-chip implementations utilizing integrated solar energy harvesting with high-voltage generation.",
Device Physics and Characteristics of Graphene Nanoribbon Tunneling FETs,"We present a detailed simulation study on the current-voltage characteristics of ballistic graphene nanoribbon (GNR) tunneling FETs of different widths with varying temperatures and channel length. Our model uses the self-consistent nonequilibrium Green's function and the quasi-2-D Poisson solver with the material details of the GNRs modeled by the uncoupled mode space Dirac equation. We find that, in general, the GNR tunneling FETs from the 3p + 1 family have better ION/IOFF characteristics than those from the 3p family due to smaller effective masses of the former. A lower drain doping concentration relative to that of the source enhances the ION/IOFF. Most significantly, we find that a higher doping concentration at the source enhances ION but degrades the subthreshold swing (SS). As a function of temperature, the SS shows highly nonlinear behaviors. In terms of intrinsic delay and power-delay product, the GNR tunneling FETs show very promising scaling behaviors and can be optimized to meet the International Technology Roadmap for Semiconductors roadmap requirements through adjustment in doping concentrations and other parameters.",
Sparse representation using nonnegative curds and whey,"It has been of great interest to find sparse and/or nonnegative representations in computer vision literature. In this paper we propose a novel method to such a purpose and refer to it as nonnegative curds and whey (NNCW). The NNCW procedure consists of two stages. In the first stage we consider a set of sparse and nonnegative representations of a test image, each of which is a linear combination of the images within a certain class, by solving a set of regressiontype nonnegative matrix factorization problems. In the second stage we incorporate these representations into a new sparse and nonnegative representation by using the group nonnegative garrote. This procedure is particularly appropriate for discriminant analysis owing to its supervised and nonnegativity nature in sparsity pursuing. Experiments on several benchmark face databases and Caltech 101 image dataset demonstrate the efficiency and effectiveness of our nonnegative curds and whey method.",
A system for online power prediction in virtualized environments using gaussian mixture models,"In this paper we present a system for online power prediction in vir-tualized environments. It is based on Gaussian mixture models that use architectural metrics of the physical and virtual machines (VM) collected dynamically by our system to predict both the physical machine and per VM level power consumption. A real implementation of our system shows that it can achieve average prediction error of less than 10%, outperforming state of the art regression based approaches at negligible runtime overhead.","Predictive models,
Power system modeling,
Energy consumption,
Voice mail,
Virtual manufacturing,
Costs,
Runtime,
Energy management,
Virtual machining,
Cooling"
A novel method to detect Heart Beat Rate using a mobile phone,"Heart Beat Rate calculation has traditionally been conducted using specialized hardware most commonly in the form of pulse oximeters or Electrocardiogram devices. Even though these methods offer high reliability, they require the users to have special sensor to measure their heart rate. In this paper we propose a system capable of estimating the heart beat rate using just a camera from a commercially available mobile phone. The advantage of this method is that the user does not need specialized hardware and s/he can take a measurement in virtually any place under almost any circumstances. Moreover the measurement provided can be used as a tool for health coaching applications or effective telecare services aimed in enhancing the user's well being.",
"A
Ku
-Band Two-Antenna Four-Simultaneous Beams SiGe BiCMOS Phased Array Receiver","This paper presents a Ku-band SiGe BiCMOS phased array receive chip capable of forming four-simultaneous beams from two antenna inputs. The design is based on the all-RF architecture with 4-bit active phase shifters and 4-bit variable gain amplifiers in each channel. The four-beam chip results in a gain of 4-6 dB per channel at 13-15 GHz, a noise figure of 10-11 dB, a worst case input P1 dB of -14.3 dBm per channel (input third-order intercept point of -7 dBm), and an rms phase and gain error of < 12° and 1.5 dB, respectively. A gain control of 17 dB is also achieved with a phase change of < 5°. The four-beam chip was tested using two input signals and results in a gain of 9-11 dB at 13-15 GHz. The on-chip isolation between the channels has been fully characterized and is > 40 dB at 13-15 GHz. The chips can operate over an instantaneous bandwidth of > 1 GHz at any frequency from 13 to 15 GHz, and the four beams can be at the same frequency if required. With all digital control circuitry and electrostatic discharge protection for all I/O pads, the chip occupies an area of 2.4 × 4.3 mm2 and consumes 520 mA at 3.5-V supply voltage. To our knowledge, this is the first demonstration of an all-RF phased array silicon chip capable of producing four-simultaneous beams from two different antennas or four-simultaneous beams of different polarizations from a dual polarization antenna. The application areas are in satellite communications and defense systems.",
On the Hardness of Approximating Stopping and Trapping Sets,"We prove that approximating the size of stopping and trapping sets in Tanner graphs of linear block codes, and more restrictively, the class of low-density parity-check (LDPC) codes, is NP-hard. The ramifications of our findings are that methods used for estimating the height of the error-floor of moderate- and long-length LDPC codes, based on stopping and trapping set enumeration, cannot provide accurate worst-case performance predictions for most codes.","Iterative decoding,
Parity check codes,
Block codes,
Maximum likelihood decoding,
Message passing,
AWGN,
Iterative algorithms,
Performance loss,
Bit error rate,
Maximum likelihood estimation"
A Survey of BitTorrent Performance,"Since its inception, BitTorrent has proved to be the most popular approach for sharing large files using the peer-to-peer paradigm. BitTorrent introduced several innovative mechanisms such as tit-for-tat (TFT) and rarest first to enable efficient distribution of files among the participating peers. Several studies examining the performance of BitTorrent and its mechanisms have been published in the literature. In this paper, we present a survey of performance studies of BitTorrent from 2003 to 2008. We categorize these studies based on the techniques used, the mechanisms studied and the resulting observations about BitTorrent performance. Many of the performance studies also suggested modifications to BitTorrent's mechanisms to further improve its performance. We also present a survey of the suggested improvements and categorize them into different groups.","Peer to peer computing,
Thin film transistors,
Network servers,
Computer science,
Telecommunication traffic,
Robustness,
Scalability,
Large-scale systems,
Linux"
A Novel Neural-Network Model for Deriving Standard 12-Lead ECGs From Serial Three-Lead ECGs: Application to Self-Care,"Synthesis of the 12-lead ECG has been investigated in the past decade as a method to improve patient monitoring in situations where the acquisition of the 12-lead ECG is cumbersome and time consuming. This paper presents and assesses a novel approach for deriving 12-lead ECGs from a pseudoorthogonal three-lead subset via generic and patient-specific nonlinear reconstruction methods based on the use of artificial neural-networks (ANNs) committees. We train and test the ANN on a set of serial ECGs from 120 cardiac inpatients from the intensive care unit of the Cardiology Hospital of Lyon. We then assess the similarity between the synthesized ECGs and the original ECGs at the quantitative level in comparison with generic and patient-specific multiple-regression-based methods. The ANN achieved accurate reconstruction of the 12-lead ECGs of the study population using both generic and patient-specific ANN transforms, showing significant improvements over generic (p -value ¿ 0.05) and patient-specific ( p-value ¿ 0.01) multiple-linear-regression-based models. Consequently, our neural-network-based approach has proven to be sufficiently accurate to be deployed in home care as well as in ambulatory situations to synthesize a standard 12-lead ECG from a reduced lead-set ECG recording.",
LMI Approach for Stationary Oscillation of Interval Neural Networks With Discrete and Distributed Time-Varying Delays Under Impulsive Perturbations,"In this paper, a class of impulsive interval neural networks with discrete and distributed time-varying delays is discussed. Several new sufficient conditions are obtained ensuring the existence, uniqueness, and global exponential stability of periodic solution (i.e., stationary oscillation) for the addressed models based on inequality analysis techniques. The obtained results can be checked easily by the linear matrix inequality control toolbox in MATLAB. Finally, two numerical examples are given to show the effectiveness of our results.","Artificial neural networks,
Delay,
Oscillators,
Biological neural networks,
Linear matrix inequalities,
Symmetric matrices,
Stability analysis"
Docitive networks: an emerging paradigm for dynamic spectrum management [Dynamic Spectrum Management],"Prime design goals for next-generation wireless networks to support emerging applications are spectral efficiency and low operational cost. Among a gamut of technical solutions, cognitive approaches have long been perceived as a catalyst for the above goals by facilitating the coexistence of primary and secondary users by means of efficient dynamic spectrum management. While most available techniques today are essentially opportunistic in nature, a truly cognitive device needs to exhibit a certain degree of intelligence to draw optimum decisions based on prior observations and anticipated actions. Said intelligence however, comes along with high complexity and poor convergence, which currently prevents any viable deployment of cognitive networks. We thus introduce an emerging and largely unexplored concept of docitive networks, where nodes effectively teach other nodes with the prime aims of reducing cognitive complexity, speeding up the learning process, and drawing better and more reliable decisions. To this end, we review some important concepts borrowed from the machine learning community for both centralized and decentralized systems, in order to position the emerging docitive with known cognitive approaches. Finally, we validate introduced concepts in the context of a primary digital television system dynamically coexisting with IEEE 802.22 secondary networks. For this scenario, we demonstrate the superiority of various unprecedented docitive over known opportunistic/cognitive algorithms.","Radio spectrum management,
Machine learning,
Cognition,
Artificial intelligence,
Costs,
Learning systems,
Convergence,
Problem-solving,
Biology,
Computer science"
Propagating multi-class pixel labels throughout video frames,"The effective propagation of pixel labels through the spatial and temporal domains is vital to many computer vision and multimedia problems, yet little attention have been paid to the temporal/video domain propagation in the past. Previous video label propagation algorithms largely avoided the use of dense optical flow estimation due to their computational costs and inaccuracies, and relied heavily on complex (and slower) appearance models. We show in this paper the limitations of pure motion and appearance based propagation methods alone, especially the fact that their performances vary on different type of videos. We propose a probabilistic framework that estimates the reliability of the sources and automatically adjusts the weights between them. Our experiments show that the “dragging effect” of pure optical-flow-based methods are effectively avoided, while the problems of pure appearance-based methods such the large intra-class variance is also effectively handled.","Pixel,
Optical propagation,
Optical imaging,
Containers,
Probabilistic logic,
Adaptive optics,
Reliability"
Exact and Closed-Form Outage Probability of Opportunistic Decode-and-Forward Relaying with Unequal-Power Interferers,"In this letter, we study outage performance of opportunistic single relay selection (OSRS) in decode-and-forward (DF) relaying with unequal-power co-channel interferers under Rayleigh fading channels. With the interferers, signal-to-interference-plus-noise ratio (SINR) may not be so great when the interferers also transmit signals at a power level similar to the source. In this case, high signal-to-noise ratio (SNR) approximation often used in outage analysis is not suitable for giving an adequate outage expression. We provide an exact and closed-form outage expression. And using asymptotic analysis, we show that OSRS still achieves full diversity gain in the presence of a finite number of interferers whose transmission powers are finite. When a finite number of interferers also transmit signals at the power level proportional to the source, we show that the asymptotic outage decreases log-linearly as the density of nodes increases. Finally, we show that when the number of interferers is proportional to the node density, the higher density, though creating the greater number of potential relays, does not necessarily contribute to improving the outage performance but deteriorates the performance.","Relays,
Signal to noise ratio,
Interference,
Fading,
Wireless communication,
Diversity methods,
Protocols"
Identifying suspicious activities through DNS failure graph analysis,"As a key approach to securing large networks, existing anomaly detection techniques focus primarily on network traffic data. However, the sheer volume of such data often renders detailed analysis very expensive and reduces the effectiveness of these tools. In this paper, we propose a light-weight anomaly detection approach based on unproductive DNS traffic, namely, the failed DNS queries, with a novel tool - DNS failure graphs. A DNS failure graph captures the interactions between hosts and failed domain names. We apply a graph decomposition algorithm based on the tri-nonnegative matrix factorization technique to iteratively extract coherent co-clusters (dense subgraphs) from DNS failure graphs. By analyzing the co-clusters in the daily DNS failure graphs from a 3-month DNS trace captured at a large campus network, we find these co-clusters represent a variety of anomalous activities, e.g., spamming, trojans, bots, etc.. In addition, these activities often exhibit distinguishable subgraph structures. By exploring the temporal properties of the co-clusters, we show our method can identify new anomalies that likely correspond to unreported domain-flux bots.",
An Inverse Problem Approach for Elasticity Imaging through Vibroacoustics,"A methodology for estimating the spatial distribution of elastic moduli using the steady-state dynamic response of solids immersed in fluids is presented. The technique relies on the ensuing acoustic field from a remotely excited solid to inversely estimate the spatial distribution of Young's modulus of biological structures (e.g., breast tissue). This work proposes the use of Gaussian radial basis functions (GRBF) to represent the spatial variation of elastic moduli. GRBF are shown to possess the advantage of representing smooth functions with quasi-compact support and can efficiently represent elastic moduli distributions such as those that occur in soft biological tissue in the presence of unhealthy tissue (e.g., tumors and calcifications). The direct problem consists of a coupled acoustic-structure interaction boundary-value problem solved in the frequency domain using the finite element method. The inverse problem is cast as an optimization problem in which the error functional is defined as a measure of discrepancy between an experimentally measured response and a finite element representation of the system. Nongradient based optimization algorithms are used to solve the resulting optimization problem. The feasibility of the proposed approach is demonstrated through a series of simulations and an experiment. For comparison purposes, the surface velocity response was also used for the inverse characterization as the measured response in place of the acoustic pressure.",
A shield ring enhanced equilateral hexagon distributed multi-needle electrospinning spinneret,"The multi-needle electrospinning system is a convenient way to produce fibers with special structures such as core-shell morphologies at a high production rate. In this paper, a specially designed multi-needle electrospinning system is presented. The spinnerets were built-up with an equilateral hexagon array. Each set of 3 needles of the spinnerets were distributed as an equilateral triangle. A coaxial shield ring was used to create an approximate uniform electric field near the tips of the needles and to restrict the collection area. The simulation results also show that the outside needles can help to create a more uniform electric field near the inside tips of the needles and restrict the path of the inside jets, which works almost the same as the additional shield ring. Based on the simulation results, several multi-needle systems were tested. A 7 cm diameter shield ring was used in a 7 needle system, a 9 cm diameter shield ring was used in a 19 needle system and a 10.5 cm diameter shield ring was used in a 37 needle system. Polyethylene Oxide (PEO) aqueous solution was used as the test solution in experiments. The electrospinning results demonstrated that the use of multi-needle spinnerets is robust and that uniform nanofibers can be produced. The more needles used, the smaller the mean fiber diameter for larger mean electric field strengths. These distributions of needles show the scale up possibility of special structure electrospun nanofiber manufacturing.","Needles,
Electric fields,
Electrodes,
Three dimensional displays,
Simulation,
Electron tubes"
Incremental learning of subtasks from unsegmented demonstration,"We propose to incrementally learn the segmentation of a demonstrated task into subtasks and the individual subtask policies themselves simultaneously. Previous robot learning from demonstration techniques have either learned the individual subtasks in isolation, combined known subtasks, or used knowledge of the overall task structure to perform segmentation. Our infinite mixture of experts approach instead automatically infers an appropriate partitioning (number of subtasks and assignment of data points to each one) directly from the data. We illustrate the applicability of our technique by learning a suitable set of subtasks from the demonstration of a finite-state machine robot soccer goal scorer.","Data models,
Approximation methods,
Gaussian processes,
Robot sensing systems,
Equations,
Learning"
A Hierarchical RBF Online Learning Algorithm for Real-Time 3-D Scanner,"In this paper, a novel real-time online network model is presented. It is derived from the hierarchical radial basis function (HRBF) model and it grows by automatically adding units at smaller scales, where the surface details are located, while data points are being collected. Real-time operation is achieved by exploiting the quasi-local nature of the Gaussian units: through the definition of a quad-tree structure to support their receptive field local network reconfiguration can be obtained. The model has been applied to 3-D scanning, where an updated real-time display of the manifold to the operator is fundamental to drive the acquisition procedure itself. Quantitative results are reported, which show that the accuracy achieved is comparable to that of two batch approaches: batch HRBF and support vector machines (SVMs). However, these two approaches are not suitable to real-time online learning. Moreover, proof of convergence is also given.","Displays,
Surface reconstruction,
Surface emitting lasers,
Manifolds,
Neural networks,
Laser feedback,
Drives,
Support vector machines,
Convergence,
Parameter estimation"
"A High-Resolution Silicon-on-Glass
Z
Axis Gyroscope Operating at Atmospheric Pressure","This paper describes a high-resolution silicon-on-glass z axis gyroscope operating at atmospheric pressure. The mechanical structure is designed in such a way that it exhibits low cross coupling between drive and sense mode of less than 0.5% simulated using finite-element method and 1.35% verified by experimental measurements. Due to a symmetrically designed structure, the specified bandwidth can be maintained despite of fabrication imperfections. The fabrication process flow is based on a combination of silicon on glass bonding and deep reactive ion etching which results in a large proof mass and capacitances. A closed loop self-oscillation drive interface is used to resonate the gyroscope in the drive mode, which reaches steady-state after 150 ms. Using area-varying capacitors, large quality factors of 217 and 97 for drive and sense mode, respectively, were achieved operating at atmospheric pressure. A low drive voltage, with a 1 Vpeak-peak AC drive amplitude and 10 V DC bias was used to excite the drive mode. The measured scale factor was 10.7 mV/°/s in a range of ±300°/s with a R 2-nonlinearity of 0.12%. The noise equivalent angular rate is 0.0015°/s/Hz1/2 (=5.4°/h/Hz1/2) in a 50 Hz bandwidth. The measured SNR was 34 dB at an angular rate input signal with an amplitude of 12.5°/s and a frequency of 10 Hz. Without any active temperature control, zero bias stability of 1°/s was achieved for long-term measurements over six hours and 0.3°/s for short-term measurements over 120 seconds (1-¿).","Frequency measurement,
Gyroscopes,
Atmospheric measurements,
Bandwidth,
Fabrication,
Atmospheric modeling,
Finite element methods,
Mechanical variables measurement,
Silicon,
Glass"
Thyroid Segmentation and Volume Estimation in Ultrasound Images,"Physicians usually diagnose the pathology of the thyroid gland by its volume. However, even if the thyroid glands are found and the shapes are hand-marked from ultrasound (US) images, most physicians still depend on computed tomography (CT) images, which are expensive to obtain, for precise measurements of the volume of the thyroid gland. This approach relies heavily on the experience of the physicians and is very time consuming. Patients are exposed to high radiation when obtaining CT images. In contrast, US imaging does not require ionizing radiation and is relatively inexpensive. US imaging is thus one of the most commonly used auxiliary tools in clinical diagnosis. The present study proposes a complete solution to estimate the volume of the thyroid gland directly from US images. The radial basis function neural network is used to classify blocks of the thyroid gland. The integral region is acquired by applying a specific-region-growing method to potential points of interest. The parameters for evaluating the thyroid volume are estimated using a particle swarm optimization algorithm. Experimental results of the thyroid region segmentation and volume estimation in US images show that the proposed approach is very promising.","Image segmentation,
Ultrasonic imaging,
Glands,
Computed tomography,
Shape measurement,
Pathology,
Volume measurement,
Ultrasonic variables measurement,
Ionizing radiation,
Clinical diagnosis"
Planetary-Scale RFID Services in an Age of Uberveillance,"Radio-frequency identification (RFID) has a great number of unfulfilled prospects. Part of the problem until now has been the value proposition behind the technology-it has been marketed as a replacement technique for the barcode when the reality is that it has far greater capability than simply non-line-of-sight identification, towards decision making in strategic management and reengineered business processes. The vision of the internet of things (IOT) has not eventuated but a world in which every object you can see around you carries the possibility of being connected to the internet is still within the realm of possibility. However incremental innovations may see RFID being sold as a service (much like photocopiers are maintained today) than a suite of technologies within a system that are sold as individual or bundled packaged components. This paper outlines the vision for such a product service system, what kinds of smart applications we are likely to see in the future as a result, and the importance of data management capabilities in planetary-scale systems.","Radiofrequency identification,
Internet,
Radio frequency,
Technological innovation,
Decision making,
Technology management,
Business process re-engineering,
Packaging,
Supply chains,
Australia"
"An Efficient Numerical Method for General
L
p
Regularization in Fluorescence Molecular Tomography","Reconstruction algorithms for fluorescence tomography have to address two crucial issues: 1) the ill-posedness of the reconstruction problem, 2) the large scale of numerical problems arising from imaging of 3-D samples. Our contribution is the design and implementation of a reconstruction algorithm that incorporates general Lp regularization (p ¿ 1). The originality of this work lies in the application of general Lp constraints to fluorescence tomography, combined with an efficient matrix-free strategy that enables the algorithm to deal with large reconstruction problems at reduced memory and computational costs. In the experimental part, we specialize the application of the algorithm to the case of sparsity promoting constraints (L 1). We validate the adequacy of L 1 regularization for the investigation of phenomena that are well described by a sparse model, using data acquired during phantom experiments.",
Mobile Sink based Routing Protocol (MSRP) for Prolonging Network Lifetime in Clustered Wireless Sensor Network,"In WSN, sensors near the sink have to relay the data of the nodes away from the sink and as a result they drain their energy very quickly. It result in network partitioning and can significantly limit the network lifetime. This problem is termed as hotspot problem. Recently, formation of hot spot or energy hole near the sink has emerged as a critical issue for data gathering in WSN. In this paper, we address hotspot problem and purposed Mobile Sink based Routing Protocol (MSRP) for Prolonging Network Lifetime in Clustered Wireless Sensor Network. In MSRP, mobile sink moves in the clustered WSN to collect sensed data from the CHs within its vicinity. During data gathering mobile sink also maintains information about the residual energy of the CHs. Mobile sink based on the residual energy of CHs move to the CHs having higher energy. Consequently, the hotspot problem is minimized as the immediate neighbor of the sink is high energy node and it changes because of regular sink movement. It results in a balanced use of WSN energy and improves network life time. To evaluate the performance of the proposed strategy intensive simulation are carried out using OMNet-4.0. Performance of the proposed strategy is compared to the static sink and multiple sinks strategies, using metrics such as energy per packet, and throughput. The simulation results demonstrate that MSRP is effective in prolonging the network lifetime as well as in improving throughput than static sink and multiple sink strategies.","Mobile communication,
Wireless sensor networks,
Sensors,
Mobile computing,
Protocols,
Peer to peer computing,
Throughput"
IPADE: Iterative Prototype Adjustment for Nearest Neighbor Classification,"Nearest prototype methods are a successful trend of many pattern classification tasks. However, they present several shortcomings such as time response, noise sensitivity, and storage requirements. Data reduction techniques are suitable to alleviate these drawbacks. Prototype generation is an appropriate process for data reduction, which allows the fitting of a dataset for nearest neighbor (NN) classification. This brief presents a methodology to learn iteratively the positioning of prototypes using real parameter optimization procedures. Concretely, we propose an iterative prototype adjustment technique based on differential evolution. The results obtained are contrasted with nonparametric statistical tests and show that our proposal consistently outperforms previously proposed methods, thus becoming a suitable tool in the task of enhancing the performance of the NN classifier.",
Index-Based Selective Audio Encryption for Wireless Multimedia Sensor Networks,"Wireless multimedia sensor networks (WMSNs) support many acoustic applications for audio surveillance, animal tracking/vocalization, human health monitoring, etc. However, resource constraints in sensor networks (such as limited battery power, bandwidth/computation capability, etc.) pose challenges for the quality and security of audio data transmission and processing. The security is a critical issue since audio information can be accessed or even manipulated in WMSNs. In order to ensure security, audio quality and energy efficiency, we propose an index-based selective audio encryption scheme for WMSNs. The scheme protects data transmissions by incorporating both resource allocation and selective encryption based on modified discrete cosine transform (MDCT). In this proposed scheme, the audio data importance is leveraged using the MDCT audio index, and wireless audio data transmission proceeds with energy efficient selective encryption. The simulation results show that the proposed approach offers a significant gain in terms of energy efficiency, encryption performance and audio transmission quality.","Wireless sensor networks,
Cryptography,
Acoustic sensors,
Data security,
Information security,
Data communication,
Energy efficiency,
Communication system security,
Acoustic applications,
Surveillance"
Security attacks and solutions for vehicular ad hoc networks,Vehicular ad hoc networks (VANETs) have attracted a lot of attention over the last few years. They have become a fundamental component of many intelligent transportation systems and VANETs are being used to improve road safety and enable a wide variety of value-added services. Many forms of attacks against VANETs have emerged recently that attempt to compromise the security of such networks. Such security attacks on VANETs may lead to catastrophic results such as the loss of lives or loss of revenue for those value-added services. Therefore making VANETs secure has become a key objective for VANET designers. To develop and deploy secure VANET infrastructures remains a significant challenge. The authors discuss some of the main security threats and attacks that can be exploited in VANETs and present the corresponding security solutions that can be implemented to thwart those attacks.,
Blind Image Deconvolution Using Machine Learning for Three-Dimensional Microscopy,"In this work, we propose a novel method for the regularization of blind deconvolution algorithms. The proposed method employs example-based machine learning techniques for modeling the space of point spread functions. During an iterative blind deconvolution process, a prior term attracts the point spread function estimates to the learned point spread function space. We demonstrate the usage of this regularizer within a Bayesian blind deconvolution framework and also integrate into the latter a method for noise reduction, thus creating a complete blind deconvolution method. The application of the proposed algorithm is demonstrated on synthetic and real-world three-dimensional images acquired by a wide-field fluorescence microscope, where the need for blind deconvolution algorithms is indispensable, yielding excellent results.",
Artifact Trapping During Time Reversal Photoacoustic Imaging for Acoustically Heterogeneous Media,"Several different reconstruction algorithms have been proposed for photoacoustic tomography, most of which presuppose that the acoustic properties of the medium are constant and homogeneous. In practice, there are often unknown spatial variations in the acoustic properties, and these algorithms give, at best, only approximate estimates of the true image. The question as to which approach is the most robust in these circumstances is therefore one of practical importance. Image reconstruction by ¿time reversal¿-using a numerical propagation model with a time-varying boundary condition corresponding to the measured data in reversed temporal order-has been shown to be less restrictive in its assumptions than most, and therefore a good candidate for a general and practically useful algorithm. Here, it is shown that such reconstruction algorithms can ¿trap¿ time reversed scattered waves, leading to artifacts within the image region. Two ways to mitigate this effect are proposed.","Acoustic imaging,
Nonhomogeneous media,
Reconstruction algorithms,
Tomography,
Robustness,
Image reconstruction,
Acoustic propagation,
Numerical models,
Boundary conditions,
Acoustic scattering"
On Conditions for Convergence to Consensus,"A new theorem on conditions for convergence to consensus of a multiagent time-dependent time-discrete dynamical system is presented. The theorem is build up on the notion of averaging maps. We compare this theorem to results by Moreau [6] (IEEE TRANSACTIONS ON AUTOMATIC CONTROL, vol. 50, no. 2, 2005) about set-valued Lyapunov theory and convergence under switching communication topologies. We give examples that point out differences of approaches including examples where Moreau's theorem is not applicable but ours is. Further on, we give examples that demonstrate that the theory of convergence to consensus is still not complete.",
Random Pixel Purity Index,"Endmember extraction has received increasing interest in hyperspectral image analysis. One widely used endmember extraction algorithm is pixel purity index (PPI), which finds endmembers via a set of random vectors, called skewers. Several issues arise in its implementation. One is the prior knowledge of the number of skewers K required to be used. Second, due to random nature in skewers, the final results are inconsistent and unreproducible. Third, it needs to know the number of dimensions to be retained after dimensionality reduction. Fourth, it needs to preset a cutoff threshold to extract potential endmembers. Finally, it involves human intervention to manually select final endmembers. This letter derives a random PPI (RPPI) to resolve the aforementioned issues. It considers the result produced by PPI using a random set of initial vectors as skewers as a realization of a random algorithm. From a statistical signal processing view point, if endmembers are crucial in terms of information, they should occur in realizations produced by PPI regardless of what set is chosen for skewers. By virtue of this assumption, the proposed RPPI is developed and validated by experiments.","Hyperspectral imaging,
Indexes,
Data mining,
Signal processing algorithms,
Computer science,
Chaos,
Humans,
Image resolution,
Remote sensing,
Signal processing"
A Symbol-Based Approach to Gait Analysis From Acceleration Signals: Identification and Detection of Gait Events and a New Measure of Gait Symmetry,"Gait analysis can convey important information about one's physical and cognitive condition. Wearable inertial sensor systems can be used to continuously and unobtrusively assess gait during everyday activities in uncontrolled environments. An important step in the development of such systems is the processing and analysis of the sensor data. This paper presents a symbol-based method used to detect the phases of gait and convey important dynamic information from accelerometer signals. The addition of expert knowledge substitutes the need for supervised learning techniques, rendering the system easy to interpret and easy to improve incrementally. The proposed method is compared to an approach based on peak detection. A new symbol-based symmetry index is created and compared to a traditional temporal symmetry index and a symmetry measure based on cross correlation. The symbol-based symmetry index exemplifies how the proposed method can extract more information from the acceleration signal than previous approaches.","Signal analysis,
Accelerometers,
Acceleration,
Signal processing,
Signal detection,
Event detection,
Sensor systems,
Information analysis,
Wearable sensors,
Phase detection"
Optical Coherence Tomography: The Intraoperative Assessment of Lymph Nodes in Breast Cancer,"During breast-conserving surgeries, axillary lymph nodes draining from the primary tumor site are removed for disease staging. Although a high number of lymph nodes are often resected during sentinel and lymph-node dissections, only a relatively small percentage of nodes are found to be metastatic, a fact that must be weighed against potential complications such as lymphedema. Without a real-time in vivo or in situ intraoperative imaging tool to provide a microscopic assessment of the nodes, postoperative paraffin section histopathological analysis currently remains the gold standard in assessing the status of lymph nodes. This paper investigates the use of optical coherence tomography (OCT), a high-resolution real-time microscopic optical-imaging technique, for the intraoperative ex vivo imaging and assessment of axillary lymph nodes. Normal (13), reactive (1), and metastatic (3) lymph nodes from 17 human patients with breast cancer were imaged intraoperatively with OCT. These preliminary clinical studies have identified scattering changes in the cortex, relative to the capsule, which can be used to differentiate normal from reactive and metastatic nodes. These optical scattering changes are correlated with inflammatory and immunological changes observed in the follicles and germinal centers. These results suggest that intraoperative OCT has the potential to assess the real-time node status in situ, without having to physically resect and histologically process specimens to visualize microscopic features.","Tomography,
Lymph nodes,
Breast cancer,
Optical scattering,
Biomedical optical imaging,
Metastasis,
High-resolution imaging,
Optical imaging,
Optical microscopy,
Surges"
An Adaptive and Stable Method for Fitting Implicit Polynomial Curves and Surfaces,"Representing 2D and 3D data sets with implicit polynomials (IPs) has been attractive because of its applicability to various computer vision issues. Therefore, many IP fitting methods have already been proposed. However, the existing fitting methods can be and need to be improved with respect to computational cost for deciding on the appropriate degree of the IP representation and to fitting accuracy, while still maintaining the stability of the fit. We propose a stable method for accurate fitting that automatically determines the moderate degree required. Our method increases the degree of IP until a satisfactory fitting result is obtained. The incrementability of QR decomposition with Gram-Schmidt orthogonalization gives our method computational efficiency. Furthermore, since the decomposition detects the instability element precisely, our method can selectively apply ridge regression-based constraints to that element only. As a result, our method achieves computational stability while maintaining fitting accuracy. Experimental results demonstrate the effectiveness of our method compared with prior methods.",
Independent Spanning Trees on Multidimensional Torus Networks,"Two spanning trees rooted at vertex r in a graph G are called independent spanning trees (ISTs) if for each vertex v in G, vner, the paths from vertex v to vertex r in these two trees are internally distinct. If the connectivity of G is k, the IST problem is to construct k ISTs rooted at each vertex. The IST problem has found applications in fault-tolerant broadcasting, but it is still open for general graphs with connectivity greater than four. In this paper, we shall propose a very simple algorithm for solving the IST problem on multidimensional torus networks. In our algorithm, every vertex can determine its parent for a specific independent spanning tree only depending on its own label. Thus, our algorithm can also be implemented in parallel systems or distributed systems very easily.","Color,
Data mining,
Computers,
Algorithm design and analysis,
Electronic mail,
Broadcasting,
Hypercubes"
The autonomic network architecture (ANA),"The objective of autonomic networking is to enable the autonomous formation and parametrization of nodes and networks by letting protocols sense and adapt to the networking environment at run time. Besides its dynamic aspects, a core requirement of autonomic networking is to define a structured framework and execution environment that enables algorithms to operate in a continously changing environment. This paper presents the major design principles of the Autonomic Network Architecture (ANA) and reports on a first implementation. The guiding principle of ANA is to strive for flexibility and genericity at all levels of the architecture. In our approach we explicitly avoid to impose a ""one-size-fits-all"" architecture (where communication protocols and paradigms are fixed by the architecture). To this end, ANA introduces generic abstractions, for example ""information dispatch points"" instead of addressable endpoints, as well as communication primitives that support network heterogeneity, adaptability, and evolution. These core abstractions allow for the coexistance of multiple and diverse networking styles and protocols. With the public release of the ANA prototype, we aim at federating autonomics related networking projects, enabling different actors to share, compare, and build upon each other¿s work. The ANA runtime can host clean slate network designs as well as legacy Internet technology and serves as a platform for demonstrating autonomic communication principles.","Internet,
IP networks,
Multicast protocols,
Electronic mail,
Humans,
Prototypes,
Runtime,
Neodymium,
Network address translation,
Computer science"
18-GHz 3.65-W/mm Enhancement-Mode AlGaN/GaN HFET Using Fluorine Plasma Ion Implantation,"Enhancement-mode (E-mode) AlGaN/GaN heterojunction field effect transistors (HFETs) with a nominal gate length of 0.35 μm are fabricated on a SiC substrate by fluorine plasma ion implantation without the use of gate recess. The threshold voltage is measured to be +0.2 V by linear extrapolation from the transfer characteristics. The E-mode device exhibits a saturation drain current density of 735 mA/mm at a gate bias of 4 V, a peak transconductance of 269 mS/mm, a current-gain cutoff frequency (fT) of 39 GHz, and a maximum oscillation frequency (fmax) of 91 GHz. At 18 GHz, the fabricated E-mode device exhibits a maximum output power density of 3.65 W/mm, a linear gain of 11.6 dB, and a peak power-added efficiency of 42%. This is the first report of the large-signal performance of AlGaN/GaN E-mode HFETs in the Ku-band.",
Automated Layer Segmentation of Optical Coherence Tomography Images,"Under the framework of computer-aided diagnosis, optical coherence tomography (OCT) has become an established ocular imaging technique that can be used in glaucoma diagnosis by measuring the retinal nerve fiber layer thickness. This letter presents an automated retinal layer segmentation technique for OCT images. In the proposed technique, an OCT image is first cut into multiple vessel and nonvessel sections by the retinal blood vessels that are detected through an iterative polynomial smoothing procedure. The nonvessel sections are then filtered by a bilateral filter and a median filter that suppress the local image noise but keep the global image variation across the retinal layer boundary. Finally, the layer boundaries of the filtered nonvessel sections are detected, which are further classified to different retinal layers to determine the complete retinal layer boundaries. Experiments over OCT for four subjects show that the proposed technique segments an OCT image into five layers accurately.","Image segmentation,
Tomography,
Retina,
Optical filters,
Computer aided diagnosis,
Optical computing,
Optical imaging,
Thickness measurement,
Nerve fibers,
Blood vessels"
Audio forensics from acoustic reverberation,"An audio recording is subject to a number of possible distortions and artifacts. For example, the persistence of sound, due to multiple reflections from various surfaces in a room, causes temporal and spectral smearing of the recorded sound. This distortion is referred to as audio reverberation time. We describe a technique to model and estimate the amount of reverberation in an audio recording. Because reverberation depends on the shape and composition of a room, differences in the estimated reverberation can be used in a forensic and ballistic setting.","Forensics,
Reverberation,
Audio recording,
Random variables,
Acoustic distortion,
Acoustic reflection,
Frequency,
Additive noise,
Acoustical engineering,
Shape"
Exploiting simple hierarchies for unsupervised human behavior analysis,"We propose a data-driven, hierarchical approach for the analysis of human actions in visual scenes. In particular, we focus on the task of in-house assisted living. In such scenarios the environment and the setting may vary considerably which limits the performance of methods with pre-trained models. Therefore our model of normality is established in a completely unsupervised manner and is updated automatically for scene-specific adaptation. The hierarchical representation on both an appearance and an action level paves the way for semantic interpretation. Furthermore we show that the model is suitable for coupled tracking and abnormality detection on different hierarchical stages. As the experiments show, our approach, simple yet effective, yields stable results, e.g. the detection of a fall, without any human interaction.","Humans,
Layout,
Monitoring,
Surveillance,
Event detection,
Image analysis,
Pattern analysis,
Streaming media,
Image sequence analysis,
Computer vision"
Design and Implementation of Grid Multiwing Butterfly Chaotic Attractors From a Piecewise Lorenz System,"The intrinsic dynamics of the Lorenz system are confined in the positive half-space with respect to the vertical axis due to a limiting threshold effect. To break such a threshold effect, a novel piecewise Lorenz system is introduced, equipped with a staircase function and an even symmetric piecewise-linear function. The new system is autonomous, and yet, it can generate various grid multiwing butterfly chaotic attractors without requiring any external forcing. A module-based circuit is designed for implementation, with experiments reported for verification and demonstration.","Chaotic communication,
Bifurcation,
Limiting,
Indexes,
Manifolds,
Control systems"
Using Statistical Methods to Compute the Probability Distribution of Message Response Time in Controller Area Network,"Automotive electrical/electronic (E/E) architectures need to be evaluated and selected based on the estimated performance of the functions deployed on them before the details of these functions are known. End-to-end delays of controls must be estimated using incomplete and aggregate information on the computation and communication load for ECUs and buses. We describe the use of statistical analysis to compute the probability distribution of Controller Area Network (CAN) message response times when only partial information is available about the functionality and architecture of a vehicle. We provide results compared to simulations as well as trace data. These results demonstrate that our statistical inference can be used for predicting the distribution of the response time of a CAN message, once its priority has been assigned, from limited information such as the bus utilization of higher priority messages.","Statistical analysis,
Computer networks,
Distributed computing,
Probability distribution,
Computer architecture,
Delay estimation,
Communication system control,
Automotive engineering,
Aggregates,
Vehicles"
A new circuit design and control to reduce input harmonic current for a three-phase ac machine drive system having a very small dc-link capacitor,"This paper presents a new circuit topology to meet the input harmonic current standard for an ac machine drive system which has a very small dc-link capacitor. The proposed circuit topology is based on a harmonic current injection method, and it keeps up size and cost competitiveness of an ac machine drive system having a very small dc-link capacitor. Also, this paper proposes an appropriate control algorithm and a stability analysis for the proposed circuit topology. Experimental results reveal the validity of the proposed circuit topology and its control method. Also, it is confirmed that the harmonic current standard can be satisfied with the proposed circuit and its control method.",
Shear modulus estimation with vibrating needle stimulation,"An ultrasonic shear wave imaging technique is being developed for estimating the complex shear modulus of biphasic hydropolymers including soft biological tissues. A needle placed in the medium is vibrated along its axis to generate harmonic shear waves. Doppler pulses synchronously track particle motion to estimate shear wave propagation speed. Velocity estimation is improved by implementing a k-lag phase estimator. Fitting shear-wave speed estimates to the predicted dispersion relation curves obtained from two rheological models, we estimate the elastic and viscous components of the complex shear modulus. The dispersion equation estimated using the standard linear solid-body (Zener) model is compared with that from the Kelvin-Voigt model to estimate moduli in gelatin gels in the 50 to 450 Hz shear wave frequency bandwidth. Both models give comparable estimates that agree with independent shear rheometer measurements obtained at lower strain rates.","Needles,
Frequency estimation,
Phase estimation,
Solid modeling,
Strain measurement,
Ultrasonic imaging,
Biological tissues,
Particle tracking,
Motion estimation,
Curve fitting"
Three Dimensions of Pitched Instrument Onset Detection,"In this paper, we suggest a novel group delay based method for the onset detection of pitched instruments. It is proposed to approach the problem of onset detection by examining three dimensions separately: phase (i.e., group delay), magnitude and pitch. The evaluation of the suggested onset detectors for phase, pitch and magnitude is performed using a new publicly available and fully onset annotated database of monophonic recordings which is balanced in terms of included instruments and onset samples per instrument, while it contains different performance styles. Results show that the accuracy of onset detection depends on the type of instruments as well as on the style of performance. Combining the information contained in the three dimensions by means of a fusion at decision level leads to an improvement of onset detection by about 8% in terms of F-measure, compared to the best single dimension.",
A Shoot-Through Protection Scheme for Converters Built With SiC JFETs,"The SiC JFET is an attractive semiconductor device due to its superior switching performance and high-temperature operating capability. Its shoot-through protection remains a challenge due to the limited practical knowledge existent on this device and due to its inherent normally on nature. Addressing this limitation, this paper presents a novel shoot-through protection scheme in which a bidirectional switch, compounded by a Si insulated-gate bipolar transistor (IGBT) and a relay,is embedded into the dc-link midpoint in order to detect and clear shoot-through faults, taking advantage of the well-known desaturation protection schemes of IGBTs to protect SiC JFETs. This paper describes in detail the proposed protection mechanism and its circuit design, presenting as well the experimental results that verified the effectiveness of the proposed scheme using, first, Si MOSFETs and second, a 10-kW ac-ac converter system using SiC JFETs.",
Cleansing Test Suites from Coincidental Correctness to Enhance Fault-Localization,"Researchers have argued that for failure to be observed the following three conditions must be met: 1) the defect is executed, 2) the program has transitioned into an infectious state, and 3) the infection has propagated to the output. Coincidental correctness arises when the program produces the correct output, while conditions 1) and 2) are met but not 3). In previous work, we showed that coincidental correctness is prevalent and demonstrated that it is a safety reducing factor for coverage-based fault localization. This work aims at cleansing test suites from coincidental correctness to enhance fault localization. Specifically, given a test suite in which each test has been classified as failing or passing, we present three variations of a technique that identify the subset of passing tests that are likely to be coincidentally correct. We evaluated the effectiveness of our techniques by empirically quantifying the following: 1) how accurately did they identify the coincidentally correct tests, 2) how much did they improve the effectiveness of coverage-based fault localization, and 3) how much did coverage decrease as a result of applying them. Using our better performing technique and configuration, the safety and precision of fault-localization was improved for 88% and 61% of the programs, respectively.",
Connectivity-Based Skeleton Extraction in Wireless Sensor Networks,"Many sensor network applications are tightly coupled with the geometric environment where the sensor nodes are deployed. The topological skeleton extraction for the topology has shown great impact on the performance of such services as location, routing, and path planning in wireless sensor networks. Nonetheless, current studies focus on using skeleton extraction for various applications in wireless sensor networks. How to achieve a better skeleton extraction has not been thoroughly investigated. There are studies on skeleton extraction from the computer vision community; their centralized algorithms for continuous space, however, are not immediately applicable for the discrete and distributed wireless sensor networks. In this paper, we present a novel Connectivity-bAsed Skeleton Extraction (CASE) algorithm to compute skeleton graph that is robust to noise, and accurate in preservation of the original topology. In addition, CASE is distributed as no centralized operation is required, and is scalable as both its time complexity and its message complexity are linearly proportional to the network size. The skeleton graph is extracted by partitioning the boundary of the sensor network to identify the skeleton points, then generating the skeleton arcs, connecting these arcs, and finally refining the coarse skeleton graph. We believe that CASE has broad applications and present a skeleton-assisted segmentation algorithm as an example. Our evaluation shows that CASE is able to extract a well-connected skeleton graph in the presence of significant noise and shape variations, and outperforms the state-of-the-art algorithms.",
A Non-Iterative Technique for Phase Noise ICI Mitigation in Packet-Based OFDM Systems,"A practical approach for detecting packet-based orthogonal-frequency-division multiplexing (OFDM) signals in the presence of phase noise is presented. An OFDM packet consists of several OFDM symbols with full-pilot symbols at the beginning followed by consecutive data symbols. Based on the full-pilot OFDM symbol, a frequency-domain joint phase noise and channel vector estimator is first derived. It is shown that the phase noise vector can be estimated by maximizing a constrained quadratic form without requiring knowledge of the channel vector. This estimated phase noise vector is then used to compute the least squares channel estimator. Assuming that the channel is constant during each packet, the estimated channel is used in subsequent data OFDM symbols for equalization and data detection. Since phase noise changes from one OFDM symbol to the next, the scattered pilots in each data OFDM symbol are used to non-iteratively estimate and mitigate the phase noise induced interference. A significant improvement in the signal-to-interference-plus-noise ratio is achieved using the proposed algorithm.",
Lossy Source Compression Using Low-Density Generator Matrix Codes: Analysis and Algorithms,"We study the use of low-density generator matrix (LDGM) codes for lossy compression of the Bernoulli symmetric source. First, we establish rigorous upper bounds on the average distortion achieved by check-regular ensemble of LDGM codes under optimal minimum distance source encoding. These bounds establish that the average distortion using such bounded degree families rapidly approaches the Shannon limit as the degrees are increased. Second, we propose a family of message-passing algorithms, ranging from the standard belief propagation algorithm at one extreme to a variant of survey propagation algorithm at the other. When combined with a decimation subroutine and applied to LDGM codes with suitably irregular degree distributions, we show that such a message-passing/decimation algorithm yields distortion very close to the Shannon rate-distortion bound for the binary symmetric source.","Algorithm design and analysis,
Symmetric matrices,
Rate-distortion,
Source coding,
Parity check codes,
Tree graphs,
Belief propagation,
Turbo codes,
Decoding,
Linear code"
Size-Dependent Infiltration and Optical Detection of Nucleic Acids in Nanoscale Pores,"Experiments and complimentary simulations are presented to demonstrate the size-dependent infiltration and detection of variable length nucleic acids in porous silicon with controllable pore diameters in the range of 15-60 nm. The pore diameter must be tuned according to target molecule size in order to most effectively balance sensitivity and size-exclusion. A quantitative relationship between pore size (15-60 nm), nucleic acid length (up to ~ 5.3 nm), and sensor response is presented with smaller molecules detected more sensitively in smaller pores as long as the pore diameter is sufficient to enable molecular infiltration and binding in the pores. The density of probe molecules on the pore walls and subsequent hybridization efficiency for target molecule binding are also reported and are shown to depend strongly on the method of infiltration as well as the target molecule size.","Optical detectors,
Silicon,
Optical sensors,
Optical filters,
Size control,
Optical waveguides,
Optical surface waves,
Fabrication,
Biological materials,
Permission"
Margin-Maximizing Feature Elimination Methods for Linear and Nonlinear Kernel-Based Discriminant Functions,"Feature selection for classification in high-dimensional spaces can improve generalization, reduce classifier complexity, and identify important, discriminating feature ¿markers.¿ For support vector machine (SVM) classification, a widely used technique is recursive feature elimination (RFE). We demonstrate that RFE is not consistent with margin maximization, central to the SVM learning approach. We thus propose explicit margin-based feature elimination (MFE) for SVMs and demonstrate both improved margin and improved generalization, compared with RFE. Moreover, for the case of a nonlinear kernel, we show that RFE assumes that the squared weight vector 2-norm is strictly decreasing as features are eliminated. We demonstrate this is not true for the Gaussian kernel and, consequently, RFE may give poor results in this case. MFE for nonlinear kernels gives better margin and generalization. We also present an extension which achieves further margin gains, by optimizing only two degrees of freedom-the hyperplane's intercept and its squared 2-norm-with the weight vector orientation fixed. We finally introduce an extension that allows margin slackness. We compare against several alternatives, including RFE and a linear programming method that embeds feature selection within the classifier design. On high-dimensional gene microarray data sets, University of California at Irvine (UCI) repository data sets, and Alzheimer's disease brain image data, MFE methods give promising results.","Support vector machines,
Support vector machine classification,
Kernel,
Biomedical imaging,
Magnetic resonance imaging,
Bioinformatics,
Decision making,
Linear programming,
Alzheimer's disease,
Brain"
Cryptography against Continuous Memory Attacks,"We say that a cryptographic scheme is Continuous Leakage-Resilient (CLR), if it allows users to refresh their secret keys, using only fresh local randomness, such that: 1. The scheme remains functional after any number of key refreshes, although the public key never changes. Thus, the “outside world'' is neither affected by these key refreshes, nor needs to know about their frequency. 2. The scheme remains secure even if the adversary can continuously leak arbitrary information about the current secret-key, as long as the amount of leaked information is bounded in between any two successive key refreshes. There is no bound on the total amount of information that can be leaked during the lifetime of the system. In this work, we construct a variety of practical CLR schemes, including CLR one-way relations, CLR signatures, CLR identification schemes, and CLR authenticated key agreement protocols. For each of the above, we give general constructions, and then show how to instantiate them efficiently using a well established assumption on bilinear groups, called the K-Linear assumption (for any constant K greater than or equal to 1). Our constructions are highly modular, and we develop many interesting techniques and building-blocks along the way, including: leakage-indistinguishable re-randomizable relations, homomorphic NIZKs, and leakage-of-cipher text non-malleable encryption schemes.","Encryption,
Public key,
Syntactics,
Context,
Entropy"
Stability Analysis of Multiplicative Update Algorithms and Application to Nonnegative Matrix Factorization,"Multiplicative update algorithms have proved to be a great success in solving optimization problems with nonnegativity constraints, such as the famous nonnegative matrix factorization (NMF) and its many variants. However, despite several years of research on the topic, the understanding of their convergence properties is still to be improved. In this paper, we show that Lyapunov's stability theory provides a very enlightening viewpoint on the problem. We prove the exponential or asymptotic stability of the solutions to general optimization problems with nonnegative constraints, including the particular case of supervised NMF, and finally study the more difficult case of unsupervised NMF. The theoretical results presented in this paper are confirmed by numerical simulations involving both supervised and unsupervised NMF, and the convergence speed of NMF multiplicative updates is investigated.",
Semi-Blind Joint Channel Estimation and Data Detection for Space-Time Shift Keying Systems,"A low-complexity semi-blind joint channel estimation and data detection scheme is proposed for space-time shift keying (STSK) based multiple-input multiple-output systems. The minimum number of STSK training blocks, which is related to the number of transmitter antennas, is first utilized to provide a rough initial least square channel estimate (LSCE). Then low-complexity single-stream maximum likelihood (ML) data detection is carried out based on the initial LSCE and the detected data are employed to refine the decision-directed LSCE. It is demonstrated that a few iterations are sufficient to approach the optimal ML detection performance obtained with the perfect channel state information.","Training,
Channel estimation,
MIMO,
Bit error rate,
Maximum likelihood detection,
Least squares approximation"
Applications of a Simple Characterization of Human Gait in Surveillance,"Applications of a simple spatiotemporal characterization of human gait in the surveillance domain are presented. The approach is based on decomposing a video sequence into x-t slices, which generate periodic patterns referred to as double helical signatures (DHSs). The features of DHS are given as follows: 1) they naturally encode the appearance and kinematics of human motion and reveal geometric symmetries and 2) they are effective and efficient for recovering gait parameters and detecting simple events. We present an iterative local curve embedding algorithm to extract the DHS from video sequences. Two applications are then considered. First, the DHS is used for simultaneous segmentation and labeling of body parts in cluttered scenes. Experimental results showed that the algorithm is robust to size, viewing angles, camera motion, and severe occlusion. Then, the DHS is used to classify load-carrying conditions. By examining various symmetries in DHS, activities such as carrying, holding, and walking with objects that are attached to legs are detected. Our approach possesses several advantages: a compact representation that can be computed in real time is used; furthermore, it does not depend on silhouettes or landmark tracking, which are sensitive to errors in background subtraction stage.",
Fast Computation of Tchebichef Moments for Binary and Grayscale Images,"Discrete orthogonal moments have been recently introduced in the field of image analysis. It was shown that they have better image representation capability than the continuous orthogonal moments. One problem concerning the use of moments as feature descriptors is the high computational cost, which may limit their application to the problems where the online computation is required. In this paper, we present a new approach for fast computation of the 2-D Tchebichef moments. By deriving some properties of Tchebichef polynomials, and using the image block representation for binary images and intensity slice representation for grayscale images, a fast algorithm is proposed for computing the moments of binary and grayscale images. The theoretical analysis shows that the computational complexity of the proposed method depends upon the number of blocks of the image, thus, it can speed up the computational efficiency as far as the number of blocks is smaller than the image size.",
"Optimal, Systematic,
q
-Ary Codes Correcting All Asymmetric and Symmetric Errors of Limited Magnitude","Systematic q-ary (q > 2) codes capable of correcting all asymmetric errors of maximum magnitude l , where l ¿ q - 2, are given. These codes are shown to be optimal. Further, simple encoding/decoding algorithms are described. The proposed code can be modified to design codes correcting all symmetric errors of maximum magnitude l, where l ¿ (q-2)/2.",
Distributed Sampling of Signals Linked by Sparse Filtering: Theory and Applications,"We study the distributed sampling and centralized reconstruction of two correlated signals, modeled as the input and output of an unknown sparse filtering operation. This is akin to a Slepian-Wolf setup, but in the sampling rather than the lossless compression case. Two different scenarios are considered: In the case of universal reconstruction, we look for a sensing and recovery mechanism that works for all possible signals, whereas in what we call almost sure reconstruction, we allow to have a small set (with measure zero) of unrecoverable signals. We derive achievability bounds on the number of samples needed for both scenarios. Our results show that, only in the almost sure setup can we effectively exploit the signal correlations to achieve effective gains in sampling efficiency. In addition to the above theoretical analysis, we propose an efficient and robust distributed sampling and reconstruction algorithm based on annihilating filters. We evaluate the performance of our method in one synthetic scenario, and two practical applications, including the distributed audio sampling in binaural hearing aids and the efficient estimation of room impulse responses. The numerical results confirm the effectiveness and robustness of the proposed algorithm in both synthetic and practical setups.","Sampling methods,
Filtering theory,
Decoding,
Robustness,
Filters,
Compressed sensing,
Source coding,
Signal processing,
Performance analysis,
Algorithm design and analysis"
Automatic Extraction of Control Points for the Registration of Optical Satellite and LiDAR Images,"A novel method for automatic extraction of control points for the registration of optical images with Light Detection And Ranging (LiDAR) data is proposed. It is based on transformation-invariant detection of salient image disks (SIDs), which determine the location of control points as the centers of the corresponding image fragments. The SID is described by a feature vector, which, in addition to the coordinates and diameter, includes intensity descriptors and region shape characteristics of the image fragment. SIDs are effectively extracted using multiscale isotropic matched filtering-a visual attention operator that indicates image locations with high-intensity contrast, homogeneity, and local shape saliency. This paper discusses the extraction of control points from both natural landscapes and structured scenes with man-made objects. Registration experiments conducted on QuickBird imagery with corresponding LiDAR data validated the proposed approach.",
Integration of Active Vision and Reaching From a Developmental Robotics Perspective,"Inspired by child development and brain research, we introduce a computational framework which integrates robotic active vision and reaching. Essential elements of this framework are sensorimotor mappings that link three different computational domains relating to visual data, gaze control, and reaching. The domain of gaze control is the central computational substrate that provides, first, a systematic visual search and, second, the transformation of visual data into coordinates for potential reach actions. In this respect, the representation of object locations emerges from the combination of sensorimotor mappings. The framework is tested in the form of two different architectures that perform visually guided reaching. Systematic experiments demonstrate how visual search influences reaching accuracy. The results of these experiments are discussed with respect to providing a reference architecture for developmental learning in humanoid robot systems.","Robot sensing systems,
Robot kinematics,
Robot vision systems,
Humanoid robots"
Quantum Dot Superluminescent Diodes for Optical Coherence Tomography: Device Engineering,"We present a 18 mW fiber-coupled single-mode superluminescent diode with 85 nm bandwidth for application in optical coherence tomography (OCT). First, we describe the effect of quantum dot (QD) growth temperature on optical spectrum and gain, highlighting the need for the optimization of epitaxy for broadband applications. Then, by incorporating this improved material into a multicontact device, we show how bandwidth and power can be controlled. We then go on to show how the spectral shape influences the autocorrelation function, which exhibits a coherence length of <;11 μm, and relative noise is found to be 10 dB lower than that of a thermal source. Finally, we apply the optimum device to OCT of in vivo skin and show the improvement that can be made with higher power, wider bandwidth, and lower noise, respectively.","Optical devices,
Quantum dots,
Superluminescent diodes,
Tomography,
Bandwidth,
Optical fiber devices,
Temperature,
Epitaxial growth,
Optical materials,
Spectral shape"
DMND: Collecting data from mobiles using Named Data,"Technology advances in both computations and wireless communications have made it economically feasible for manufacturers to collect data from all the cars in order to monitor their operations and detect any potential problems. However to make this a reality requires a new architecture that can effectively handle vehicle mobility, intermittent connectivity, and data security, as well as scale to large number of vehicles. In this paper we address these design challenges by exploring the direction of Named Date Networking (NDN) (aka CCN1). We evaluated our design, dubbed DMND, through simulations in Qualnet. Our results show that, when data publishers (vehicles) are stationary, more than 99% of collection requests can successfully pull data packets back; even when vehicles move at a high speed of 40–50 meters per second (89.48–111.8 miles/hour), DMND can still retain its high efficiency of 97% of data replies. In contrast, under the same simulation experimental setting, the request-reply ratio of MobileIP drops from 97.9% for static publishers to 9.6% when publishers are moving at a speed of 10–20 meters/second (22.37–44.74 miles/hour).","Vehicles,
Mobile communication,
Servers,
Mobile computing,
IP networks,
Databases,
Base stations"
A Coupled Global Registration and Segmentation Framework With Application to Magnetic Resonance Prostate Imagery,"Extracting the prostate from magnetic resonance (MR) imagery is a challenging and important task for medical image analysis and surgical planning. We present in this work a unified shape-based framework to extract the prostate from MR prostate imagery. In many cases, shape-based segmentation is a two-part problem. First, one must properly align a set of training shapes such that any variation in shape is not due to pose. Then segmentation can be performed under the constraint of the learnt shape. However, the general registration task of prostate shapes becomes increasingly difficult due to the large variations in pose and shape in the training sets, and is not readily handled through existing techniques. Thus, the contributions of this paper are twofold. We first explicitly address the registration problem by representing the shapes of a training set as point clouds. In doing so, we are able to exploit the more global aspects of registration via a certain particle filtering based scheme. In addition, once the shapes have been registered, a cost functional is designed to incorporate both the local image statistics as well as the learnt shape prior. We provide experimental results, which include several challenging clinical data sets, to highlight the algorithm's capability of robustly handling supine/prone prostate registration and the overall segmentation task.","Couplings,
Image segmentation,
Magnetic resonance,
Shape,
Biomedical imaging,
Image analysis,
Surgery,
Clouds,
Filtering,
Cost function"
Distributed routing algorithms to manage power flow in agent-based active distribution network,"The current transition from passive to active electric distribution networks comes with problems and challenges on bi-directional power flow in the network and the uncertainty in the forecast of power generation from grid-connected renewable and distributed energy sources. The power flow management would need to be distributed, flexible, and intelligent in order to cope with these challenges. Considering the optimal power flow (OPF) problem as a minimum cost flow represented with the graph, this paper applies a cost-scaling push-relabel algorithm in order to solve the OPF in a distributed agent environment. The algorithm's performance is compared with the successive shortest path algorithm developed in our previous work. The simulation is implemented for both meshed and radial networks. The simulation results show the advantages of the cost-scaling push-relabel algorithm over the shortest path algorithm in the radial networks with respect to significantly reduced number of exchanged messages on the agent platform, and thus the reduced time for calculation. This will be of great importance if the method is to be applied to a large system.",
Coded exposure imaging for projective motion deblurring,"We propose a method for deblurring of spatially variant object motion. A principal challenge of this problem is how to estimate the point spread function (PSF) of the spatially variant blur. Based on the projective motion blur model of [27], we present a blur estimation technique that jointly utilizes a coded exposure camera and simple user interactions to recover the PSF. With this spatially variant PSF, objects that exhibit projective motion can be effectively de-blurred. We validate this method with several challenging image examples.",
Comparison of FPGA and GPU implementations of real-time stereo vision,"Real-time stereo vision systems have many applications - from autonomous navigation for vehicles through surveillance to materials handling. Accurate scene interpretation depends on an ability to process high resolution images in real-time, but, although the calculations for stereo matching are basically simple, a practical system needs to evaluate at least 109 disparities every second - beyond the capability of a single processor. Stereo correspondence algorithms have high degrees of inherent parallelism and are thus good candidates for parallel implementations. In this paper, we compare the performance obtainable with an FPGA and a GPU to understand the trade-off between the flexibility but relatively low speed of an FPGA and the high speed and fixed architecture of the GPU. Our comparison highlights the relative strengths and limitations of the two systems. Our experiments show that, for a range of image sizes, the GPU manages 2 × 109 disparities per second, compared with 2∶6 × 109 disparities per second for an FPGA.","Field programmable gate arrays,
Stereo vision,
Real time systems,
Navigation,
Remotely operated vehicles,
Mobile robots,
Surveillance,
Materials handling,
Layout,
Image resolution"
Trust-based on-demand multipath routing in mobile ad hoc networks,"A mobile ad hoc network (MANET) is a self-organised system comprised of mobile wireless nodes. All nodes act as both communicators and routers. Owing to multi-hop routing and absence of centralised administration in open environment, MANETs are vulnerable to attacks by malicious nodes. In order to decrease the hazards from malicious nodes, the authors incorporate the concept of trust to MANETs and build a simple trust model to evaluate neighbours' behaviours ' forwarding packets. Extended from the ad hoc on-demand distance vector (AODV) routing protocol and the ad hoc on-demand multipath distance vector (AOMDV) routing protocol, a trust-based reactive multipath routing protocol, ad hoc on-demand trusted-path distance vector (AOTDV), is proposed for MANETs. This protocol is able to discover multiple loop-free paths as candidates in one route discovery. These paths are evaluated by two aspects: hop counts and trust values. This two-dimensional evaluation provides a flexible and feasible approach to choose the shortest path from the candidates that meet the requirements of data packets for dependability or trust. Furthermore, the authors give a routing example in details to describe the procedures of route discovery and the differences among AODV, AOMDV and AOTDV. Several experiments have been conducted to compare these protocols and the results show that AOTDV improves packet delivery ratio and mitigates the impairment from black hole, grey hole and modification attacks.","routing protocols,
mobile ad hoc networks"
Absorptive Capacity in R&D Project Teams: A Conceptualization and Empirical Test,"The purpose of this study is to answer a call for the rejuvenation of the absorptive capacity (ACAP) construct by offering a novel conceptualization and empirical test of a multidimensional model of R&D project team ACAP that portrays it as a capability distinct from prior knowledge, specifies each dimension's level of analysis, distinguishes between individual and collective assimilation, and considers the moderating effects of team structure. Using a dataset from survey and archival sources on 100 innovations by R&D project teams, we find that the capability of R&D team members to evaluate external knowledge is related to their ability to assimilate it and that both individual assimilation capabilities and collective assimilation capabilities, in the form of ability to reach a shared understanding, are important to the team's ability to apply external knowledge. We also find that prior knowledge negatively moderates the relationship between individual assimilation and application ability and that team autonomy positively moderates this relationship. By clarifying levels of analysis and encompassing multiple dimensions of ACAP, this work leads to a more fine-grained understanding of the complex nature of ACAP. Implications of these findings for future research and R&D team management are presented.",
Is Network Coding Always Good for Cooperative Communications?,"Network coding (NC) is a promising approach to reduce time-slot overhead for cooperative communications (CC) in a multi-session environment. Most of the existing works take advantage of the benefits of NC in CC but do not fully recognize its potential adverse effect. In this paper, we show that employing NC may not always benefit CC. We substantiate this important finding in the context of analog network coding (ANC) and amplify-and-forward (AF) CC. This paper, for the first time, introduces an important concept of network coding noise (NC noise). Specifically, we analyze the signal aggregation at a relay node and signal extraction at a destination node. We then use the analysis to derive a closed-form expression for NC noise at each destination node in a multi-session environment. We show that NC noise can diminish the advantage of NC in CC. Our results formalizes an important concept on using NC in CC.",
The chains model for detecting parts by their context,"Detecting an object part relies on two sources of information - the appearance of the part itself and the context supplied by surrounding parts. In this paper we consider problems in which a target part cannot be recognized reliably using its own appearance, such as detecting low-resolution hands, and must be recognized using the context of surrounding parts. We develop the `chains model' which can locate parts of interest in a robust and precise manner, even when the surrounding context is highly variable and deformable. In the proposed model, the relation between context features and the target part is modeled in a non-parametric manner using an ensemble of feature chains leading from parts in the context to the detection target. The method uses the configuration of the features in the image directly rather than through fitting an articulated 3-D model of the object. In addition, the chains are composable, meaning that new chains observed in the test image can be composed of sub-chains seen during training. Consequently, the model is capable of handling object poses which are infrequent, even non-existent, during training. We test the approach in different settings, including object parts detection, as well as complete object detection. The results show the advantages of the chains model for detecting and localizing parts of complex deformable objects.",
Anatomically Corresponded Regional Analysis of Cartilage in Asymptomatic and Osteoarthritic Knees by Statistical Shape Modelling of the Bone,"Magnetic resonance imaging (MRI) is emerging as the method of choice for measuring cartilage loss in osteoarthritis (OA), but current methods of analysis are imperfect for therapeutic clinical trials. In this paper, we present and evaluate, in two multicenter multivendor studies, a new method for anatomically corresponded regional analysis of cartilage (ACRAC) that allows analysis of knee cartilage morphology in anatomically corresponding focal regions defined on the bone surface. In our first study, 3-D knee MR Images were obtained from 19 asymptomatic female volunteers, followed by segmentations of the bone and cartilage. Minimum description length (MDL) statistical shape models (SSMs) were constructed from the segmented bone surfaces, providing mean bone shapes and a dense set of anatomically corresponding positions on each individual bone, the accuracy of which were measured using repeat images from a subset of the volunteers. Cartilage thicknesses were measured at these locations along 3-D normals to the bone surfaces, yielding corresponded cartilage thickness maps. Functional subregions of the joint were defined on the mean bone shapes, and propagated, using the correspondences, to each individual. ACRAC improved reproducibility, particularly in the central, load bearing subregions of the joint, compared with measures of volume obtained directly from the segmented cartilage surfaces. In our second study, MR Images were obtained from 31 female patient-volunteers with knee OA at baseline and six months. We obtained manual segmentations of the cartilage, and automatic segmentations of the bone using active appearance models (AAMs) built from the bone SSMs of the first study. ACRAC enabled the detection of significant thickness loss in the central, load-bearing regions of the whole femur ( -5.57% p = 0.01, annualized) and the medial condyle (-13.08% , p = 0.024 Bonferroni corrected, annualized). We conclude that statistical shape modelling of bone surfaces defines correspondences invariant to individual joint size or shape, providing focal measures of cartilage with improved reproducibility compared to whole compartment measures. It permits the identification of anatomically equivalent regions, and provides the ability to identify the main load-bearing regions of the joint, based on the imputed premorbid state. The method permitted detection of tiny morphological change in cartilage thickness over six months in a small study, and may be useful for OA disease analysis and treatment monitoring.","Knee,
Bones,
Shape measurement,
Surface morphology,
Image segmentation,
Joints,
Magnetic analysis,
Magnetic resonance imaging,
Reproducibility of results,
Size measurement"
Sample complexity for 1-bit compressed sensing and sparse classification,"This paper considers the problem of identifying the support set of a high-dimensional sparse vector, from noise-corrupted 1-bit measurements. We present passive and adaptive algorithms for this problem, both requiring no more than O(d log(D)) measurements to recover the unknown support. The adaptive algorithm has the additional benefit of robustness to the dynamic range of the unknown signal.","Compressed sensing,
Dynamic range,
Adaptive algorithm,
Signal to noise ratio,
Signal processing,
Gaussian noise,
Telecommunication computing,
Electric variables measurement,
Noise measurement,
Noise robustness"
On Combining Morphological Component Analysis and Concentric Morphology Model for Mammographic Mass Detection,"Mammographic mass detection is an important task for the early diagnosis of breast cancer. However, it is difficult to distinguish masses from normal regions because of their abundant morphological characteristics and ambiguous margins. To improve the mass detection performance, it is essential to effectively preprocess mammogram to preserve both the intensity distribution and morphological characteristics of regions. In this paper, morphological component analysis is first introduced to decompose a mammogram into a piecewise-smooth component and a texture component. The former is utilized in our detection scheme as it effectively suppresses both structural noises and effects of blood vessels. Then, we propose two novel concentric layer criteria to detect different types of suspicious regions in a mammogram. The combination is evaluated based on the Digital Database for Screening Mammography, where 100 malignant cases and 50 benign cases are utilized. The sensitivity of the proposed scheme is 99% in malignant, 88% in benign, and 95.3% in all types of cases. The results show that the proposed detection scheme achieves satisfactory detection performance and preferable compromises between sensitivity and false positive rates.",
Keystroke dynamics: Characteristics and opportunities,"Significant research into the feasibility of keystroke dynamics as a potential biometric authentication method has taken place since the advent of computers. The studies have progressed from examining typing patterns on desktop keyboards using statistical pattern classifiers to mobile keyboards using neural networks as a pattern classifier. The studies do not have a unifying method of comparing results, which limits comparison between the methods presented. Without the ability to compare studies within research areas, future study is limited in its ability to provide important modifications to the work in question. This paper reviews a representative subset of the current research in keystroke dynamics, and provides recommendations on the potential direction of future work in this area. This will provide a set of guidelines that can be followed by researchers intending to do further work in the area of keystroke dynamics.","Authentication,
Error analysis,
Keyboards,
Measurement,
Artificial neural networks,
Mobile handsets,
Computers"
An Efficient Algorithm for Constructing Maximum lifetime Tree for Data Gathering Without Aggregation in Wireless Sensor Networks,"Data gathering is a broad research area in wireless sensor networks. The basic operation in sensor networks is the systematic gathering and transmission of sensed data to a sink for further processing. The lifetime of the network is defined as the time until the first node depletes its energy. A key challenge in data gathering without aggregation is to conserve the energy consumption among nodes so as to maximize the network lifetime. We formalize the problem of tackling the challenge as to construct a min-max-weight spanning tree, in which the bottleneck nodes have the least number of descendants according to their energy. However, the problem is NP-complete. A O(\log n/\log\log n)-approximation algorithm MITT is proposed to solve the problem without location information. Simulation results show that MITT can achieve longer network lifetime than existing algorithms.","Wireless sensor networks,
Protocols,
Peer to peer computing,
Energy consumption,
Computer networks,
Communications Society,
Information science,
Data engineering,
Computer science,
USA Councils"
Performance Analysis of Contention Based Bandwidth Request Mechanisms in WiMAX Networks,"WiMAX networks have received wide attention as they support high data rate access and amazing ubiquitous connectivity with great quality-of-service (QoS) capabilities. In order to support QoS, bandwidth request (BW-REQ) mechanisms are suggested in the WiMAX standard for resource reservation, in which subscriber stations send BW-REQs to a base station which can grant or reject the requests according to the available radio resources. In this paper we propose a new analytical model for the performance analysis of various contention based bandwidth request mechanisms, including grouping and no-grouping schemes, as suggested in the WiMAX standard. Our analytical model covers both unsaturated and saturated traffic load conditions in both error-free and error-prone wireless channels. The accuracy of this model is verified by various simulation results. Our results show that the grouping mechanism outperforms the no-grouping mechanism when the system load is high, but it is not preferable when the system load is light. The channel noise degrades the performance of both throughput and delay.",
Efficient integral image computation on the GPU,"We present an integral image algorithm that can run in real-time on a Graphics Processing Unit (GPU). Our system exploits the parallelisms in computation via the NIVIDA CUDA programming model, which is a software platform for solving non-graphics problems in a massively parallel high-performance fashion. This implementation makes use of the work-efficient scan algorithm that is explicated elsewhere. Treating the rows and the columns of the target image as independent input arrays for the scan algorithm, our method manages to expose a second level of parallelism in the problem. We compare the performance of the parallel approach running on the GPU with the sequential CPU implementation across a range of image sizes and report a speed up by a factor of 8 for a 4 megapixel input. We further investigate the impact of using packed vector type data on the performance, as well as the effect of double precision arithmetic on the GPU.",
Generation NXT: Building Young Engineers With LEGOs,"This paper describes key success factors for the implementation and development of a LEGO robotics engineering outreach program for elementary school students in West Texas. The outreach program not only aims at getting young students excited about engineering but at the same time aims at improving retention rates among electrical and computer engineering freshman-level college students by involving them as paid mentors. It particularly takes into consideration the rural character of West Texas, which provides hardly any electrical and computer engineering job opportunities, and the fact that a university with a college of engineering serves as academic hub for the area.","Educational institutions,
Gears,
Educational robots,
Games,
Buildings,
Programming"
Fluctuating emg signals: Investigating long-term effects of pattern matching algorithms,"In this paper, we investigate the behavior of state-of-the-art pattern matching algorithms when applied to electromyographic data recorded during 21 days. To this end, we compare the five classification techniques k-nearest-neighbor, linear discriminant analysis, decision trees, artificial neural networks and support vector machines. We provide all classifiers with features extracted from electromyographic signals taken from forearm muscle contractions, and try to recognize ten different hand movements. The major result of our investigation is that the classification accuracy of initially trained pattern matching algorithms might degrade on subsequent data indicating variations in the electromyographic signals over time.","Electromyography,
Accuracy,
Feature extraction,
Support vector machines,
IEEE Press,
Signal processing algorithms,
Pattern matching"
Wavelet Phase Synchronization Analysis of Cerebral Blood Flow Autoregulation,"The dynamic relationship between beat-to-beat mean arterial blood pressure (ABP) fluctuations and cerebral blood flow velocity (CBFV) variations have been intensively studied. The experimentally observed low coherence in the low-frequency band has previously indicated that the assumptions of linearity and/or stationarity, the preconditions of the linear transfer function analysis, are not valid in that frequency region. Latka et al. [M. Latka, M. Turalska, M. Glaubic-Latka, W. Kolodziej, D. Latka, and B. J. J. West, ?Phase dynamics in cerebral autoregulation,? Amer. J. Physiol. Heart Circ. Physiol., vol. 289 pp. H2272-H2279, Jul. 2005] used a wavelet phase synchronization method to identify the instantaneous phase difference between ABP and CBFV, and low values of synchronization index were found in the low-frequency range, seeming to provide further evidence that the cerebral autoregulation system is nonstationary. Here, we focus on another possible factor corresponding for this low synchronization index-unmeasured variability. We demonstrate analytically and with a physiologically based cerebral hemodynamic model that, in the case of multiple inputs, the phase difference between one input, ABP, and the output, CBFV, will be distorted by an additional input, end-tidal CO2 ( P ETCO2), and no longer accurately represent the true ABP-CBFV system phase shift. We also prove that this phase distortion can be corrected if the transfer functions for ABP-CBFV and P ETCO2-CBFV are known or can be estimated. A significantly increased value of synchronization index in the low-frequency band is found by using the CO2 correction term with experimental data on 13 subjects. This essentially indicates that the lack of synchronization between ABP and CBFV previously identified by Latka et al. [M. Latka, M. Turalska, M. Glaubic-Latka, W. Kolodziej, D. Latka, and B. J. J. West, ?Phase dynamics in cerebral autoregulation,? Amer. J. Physiol. Heart Circ. Physiol., vol. 289, pp. H2272-H2279, Jul. 2005] can be partly attributed to unmeasured variability.","Wavelet analysis,
Blood flow,
Frequency synchronization,
Transfer functions,
Heart,
Phase distortion,
Arterial blood pressure,
Fluctuations,
Coherence,
Linearity"
Convexification of optimal power flow problem,"The optimal power flow (OPF) problem is nonconvex and generally hard to solve. We provide a sufficient condition under which the OPF problem is equivalent to a convex problem and therefore is efficiently solvable. Specifically, we prove that the dual of OPF is a semidefinite program and our sufficient condition guarantees that the duality gap is zero and a globally optimal solution of OPF is recoverable from a dual optimal solution. This sufficient condition is satisfied by standard IEEE benchmark systems with 14, 30, 57, 118 and 300 buses after small resistance (10−5 per unit) is added to every transformer that originally assumes zero resistance. We justify why the condition might hold widely in practice from algebraic and geometric perspectives. The main underlying reason is that physical quantities such as resistance, capacitance and inductance, are all positive.",
Joint Scheduling and Resource Allocation in CDMA Systems,"In this paper, the scheduling and resource allocation problem for the downlink in a code-division multiple access (CDMA)-based wireless network is considered. The problem is to select a subset of the users for transmission and for each of the users selected, to choose the modulation and coding scheme, transmission power, and number of codes used. We refer to this combination as the physical layer operating point (PLOP). Each PLOP consumes different amounts of code and power resources. The resource allocation task is to pick the ¿optimal¿ PLOP taking into account both system-wide and individual user resource constraints that can arise in a practical system. This problem is tackled as part of a utility maximization problem framed in earlier papers that includes both scheduling and resource allocation. In this setting, the problem reduces to maximizing the weighted throughput over the state-dependent downlink capacity region while taking into account the system-wide and individual user constraints. This problem is studied for the downlink of a Gaussian broadcast channel with orthogonal CDMA transmissions. This results in a tractable convex optimization problem. A dual formulation is used to obtain several key structural properties. By exploiting this structure, algorithms are developed to find the optimal solution with geometric convergence.",
Energy-Efficient Design Methodologies: High-Performance VLSI Adders,"Energy-efficient design requires exploration of available algorithms, recurrence structures, energy and wire tradeoffs, circuit design techniques, circuit sizing and system constraints. In this paper, methodology for energy-efficient design applied to 64-bit adders implemented with static CMOS, dynamic CMOS and CMOS compound domino logic families, is presented. We also examined 65 nm, 45 nm, 32 nm, and 22 nm technology nodes to explore the applicability of the results in deep submicron technologies. By applying energy-delay tradeoffs on various levels, we developed adder topology yielding up to 20% performance improvement and 4.5× energy reduction over existing designs.","Energy efficiency,
Design methodology,
Very large scale integration,
Adders,
CMOS technology,
Algorithm design and analysis,
Wire,
Circuit synthesis,
CMOS logic circuits,
Logic design"
Space Mapping Design Framework Exploiting Tuning Elements,"Inspired by the ideas of ¿simulator-based¿ tuning, implicit space mapping, and surrogate optimization, we propose an implementable microwave design framework. In this framework, we alter an electromagnetic (EM) model by embedding suitable tuning elements. The resulting tuning model is aligned with the original unaltered EM model. We then designate the aligned tuning model as surrogate for design optimization purposes. We illustrate our tuning space mapping framework using a simple microstrip line example. Several microwave examples, including a low-temperature co-fired ceramic filter demonstrate the framework's implementation and robustness.",
Reputation-Based QoS Provisioning in Cloud Computing via Dirichlet Multinomial Model,"In Cloud computing, users with different service requirements often need to negotiate with service provider via Service Level Agreement (SLA). The unique pay-as-you-go billing way in Cloud computing challenges resource provisioning for service providers. In this paper, based on the Dirichlet multinomial model, we present an efficient reputation-based QoS provisioning scheme, which can minimize the cost of computing resources, while satisfying the desired QoS metrics. Unlike the previous counterparts, we consider the statistical probability of the response time as a practical metric rather than the typical mean response time. Numerical results show the efficiency and effectiveness of the proposed scheme.","Cloud computing,
Delay,
Costs,
Computer architecture,
Computer science,
Pervasive computing,
Monitoring,
Communications Society,
Paper technology,
Probability"
Non-Orthogonal View Iris Recognition System,"This paper proposes a non-orthogonal view iris recognition system comprising a new iris imaging module, an iris segmentation module, an iris feature extraction module and a classification module. A dual-charge-coupled device camera was developed to capture four-spectral (red, green, blue, and near-infrared) iris images which contain useful information for simplifying the iris segmentation task. An intelligent random sample consensus iris segmentation method is proposed to robustly detect iris boundaries in a four-spectral iris image. In order to match iris images acquired at different off-axis angles, we propose a circle rectification method to reduce the off-axis iris distortion. The rectification parameters are estimated using the detected elliptical pupillary boundary. Furthermore, we propose a novel iris descriptor which characterizes an iris pattern with multiscale step/ridge edge-type maps. The edge-type maps are extracted with the derivative of Gaussian and the Laplacian of Gaussian filters. The iris pattern classification is accomplished by edge-type matching which can be understood intuitively with the concept of classifier ensembles. Experimental results show that the equal error rate of our approach is only 0.04% when recognizing iris images acquired at different off-axis angles within ±30°.","Iris recognition,
Image segmentation,
Image edge detection,
Feature extraction,
Cameras,
Robustness,
Parameter estimation,
Laplace equations,
Filters,
Pattern classification"
Group Connectivity Model for Industrial Wireless Sensor Networks,"It is a recent trend to consider wireless sensor networks in harsh industrial environments. With actual deployment of wireless sensor networks, it would be desirable to make a concrete deployment plan regarding connectivities and to place sensors by grouping them according to the planned deployment points, even more in case of targeting multiple objects to be sensed and monitored in harsh environments. The connectedness of groups as well as individual sensors is important specifically for real-time data acquisitions and even more if there are no external communication links among these groups. In this paper, we focus on the connectivity of sensor groups, rather than the individual sensors only, and propose a novel group connectivity model so as to analyze group connectivity and to make a concrete deployment plan of sensor groups with regard to the internal distribution of sensors and group positions. We believe that the proposed model should be useful in planning the deployment of wireless sensor networks in harsh industrial environments where running wires is less practical and also prohibitively expensive.","Wireless sensor networks,
Chemical sensors,
Monitoring,
Industrial control,
Electrical equipment industry,
Fuel processing industries,
Computer science,
Concrete,
Gas industry,
Gases"
Wideband Bandpass Filter With Reconfigurable Bandwidth,"This letter proposes a novel building block for developing tunable wideband bandpass filters. The proposed circuit block mainly consists of short circuit coupled lines and short circuit stubs with pin diodes as tuning elements. This work aims to demonstrate reconfigurable bandwidth of this type of filter. Two filters are designed and fabricated; one can be switched between a fractional bandwidth (FBW) of 16.3% and 35% at a center frequency of 1.9 GHz, and the other can be switched from a FBW of 27.8% to 37.4% at a center frequency of 1.9 GHz. The insertion loss and return loss in the first filter range from 4.17 dB to 0.4 dB and 27.54 dB to 19.04 dB. The second filter exhibits an insertion loss ranging from 0.73 dB to 0.43 dB and a return loss range from 31.1 dB to 27.7 dB. The tested filters show good agreement with EM simulations.",
"Network vulnerability to single, multiple, and probabilistic physical attacks","Telecommunications networks heavily rely on the physical infrastructure and, are therefore, vulnerable to natural disasters, such as earthquakes or floods, as well as to physical attacks, such as an Electromagnetic Pulse (EMP) attack. Large-scale disasters are likely to destroy network equipment and to severely affect interdependent systems such as the power-grid. In turn, long-term outage of the power-grid might cause additional failures to the telecommunication network. In this paper, we model an attack as a disk around its epicenter, and provide efficient algorithms to find vulnerable points within the network, under various metrics. In addition, we consider the case in which multiple disasters happen simultaneously and provide an approximation algorithm to find the points which cause the most significant destruction. Finally, since a network element does not always fail, even when it is close to the attack's epicenter, we consider a simple probabilistic model in which the probability of a network element failure is given. Under this model, we tackle the cases of single and multiple attacks and develop algorithms that identify potential points where an attack is likely to cause a significant damage.","Face,
Approximation algorithms,
Probabilistic logic,
Approximation methods,
Reliability,
Network topology,
EMP radiation effects"
On Maximizing Reliability of Real-Time Embedded Applications Under Hard Energy Constraint,"The dynamic voltage and frequency scaling (DVFS) technique is the basis of numerous state-of-the-art energy management schemes proposed for real-time embedded systems. However, recent research has illustrated the alarmingly negative impact of DVFS on task and system reliability. In this paper, we consider the problem of assigning processing frequencies to a set of real-time tasks in order to maximize the overall reliability, under given time and energy constraints. First, under the frame-based task model, we formulate the problem as a nonlinear optimization problem and show how to obtain the static optimal solution. Then, we propose online (dynamic) algorithms that detect early completions and adjust the task frequencies at runtime, to improve overall reliability. Furthermore, we extend these solutions to the periodic task model, with both static and dynamic solutions. All our solutions ensure that all timing constraints are met while the cumulative energy consumption of tasks does not exceed the given energy budget. Our simulation results indicate that our algorithms perform comparably to a clairvoyant optimal scheduler that knows the exact workload in advance.","Frequency,
Dynamic voltage scaling,
Energy management,
Real time systems,
Embedded system,
Reliability,
Time factors,
Heuristic algorithms,
Runtime,
Timing"
Is the rubber hand illusion induced by immersive virtual reality?,"The rubber hand illusion is a simple illusion where participants can be induced to report and behave as if a rubber hand is part of their body. The induction is usually done by an experimenter tapping both a rubber hand prop and the participant's real hand: the touch and visual feedback of the taps must be synchronous and aligned to some extent. The illusion is usually tested by several means including a physical threat to the rubber hand. The response to the threat can be measured by galvanic skin response (GSR): those that have the illusion showed a marked rise in GSR. Based on our own and reported experiences with immersive virtual reality (IVR), we ask whether a similar illusion is induced naturally within IVR? Does the participant report and behave as if the virtual arm is part of their body? We show that participants in a HMD-based IVR who see a virtual body can experience similar responses to threats as those in comparable rubber hand illusion experiments. We show that these responses can be negated by replacing the virtual body with an abstract cursor representing the hand, and that the responses are stable under some gradual forced distortion of tracker space so that proprioceptive and visual information are not matched.","Rubber,
Virtual reality,
Galvanizing,
Skin,
Neuroscience,
Testing,
Stress,
Protocols,
Computer science,
Educational institutions"
Resonant Tunneling Barriers in Quantum Dots-in-a-Well Infrared Photodetectors,"The use of resonant tunneling (RT) barriers in the design of quantum dots-in-a-well (DWELL) infrared photodetectors is reported. The design of RT barriers for a variety of goals has been discussed. For simple DWELL designs, we demonstrate 2-3 orders-of-magnitude reduction in the dark current, with significant increase in the specific detectivity (D *) of the device. Two RT barriers are designed to selectively extract midwave and longwave components of the spectral response. We also report the use of RT barriers on strain-optimized quantum dots-in-a-double-well (DDWELL) structures to achieve very low dark current levels with peak D * of 2.9 ×1010 cm· Hz1/2 /W for a longwave infrared detection. Ability to select a particular wavelength in the spectral response is demonstrated with DDWELL architectures as well.","Resonant tunneling devices,
Quantum dots,
Photodetectors,
Dark current,
Infrared detectors,
Infrared imaging,
Shape control,
Optical scattering,
Phonons,
Laboratories"
An opportunistic relay protocol for vehicular road-side access with fading channels,"In the drive-thru Internet access systems, vehicles connect to road-side access points (APs) to use IP-based services, such as web-browsing, e-mail, and file download, in addition to the customized vehicular applications. However, the mobility of vehicles and the limited coverage of APs result in the short connectivity duration and low throughput, thus leading to low availability of Internet to vehicle services. Vehicle-to-vehicle (V2V) relay support is an attractive backup solution that can address these limitations by extending the coverage. To fully realize the benefit of V2V relay support, however, the vehicle that gives the best performance must be selected as relay, yet the dynamic wireless channel conditions and the high speed of vehicles render relay selection a challenging problem. In this paper, we evaluate several relay strategies in an analytic framework to compute the resulting overall network capacity with fading channels. We then propose and devise an efficient opportunistic relay protocol that exploits multiuser diversity and effectively copes with the dynamic channel. Through both capacity analysis and Qualnet simulations, we show that the opportunistic relay scheme significantly outperforms others.","Relays,
Vehicles,
Throughput,
Fading,
Protocols,
Internet,
Downlink"
Give2Get: Forwarding in Social Mobile Wireless Networks of Selfish Individuals,"In this paper we present two forwarding protocols for mobile wireless networks of selfish individuals. We assume that all the nodes are selfish and show formally that both protocols are Nash equilibria, that is, no individual has an interest to deviate. Extensive simulations with real traces show that our protocols introduce an extremely small overhead in terms of delay, while the techniques we introduce to force faithful behavior have the positive side-effect to improve performance by reducing the number of message considerably (more than 20\%). We test our protocols also in the presence of a natural variation of the notion of selfishness—nodes that are selfish with outsiders and faithful with people from the same community. Even in this case, our protocols are shown to be very efficient in detecting possible misbehavior.",
A Novel Middleware Solution to Improve Ubiquitous Healthcare Systems Aided by Affective Information,"The arousal of emotion might have consequences for physical health is a broadly acknowledged idea. Therapy for depression, prevention for heart pathologies, and rehabilitation treatments for drug addiction are just a few examples of application domains that may benefit from technologies capable of monitoring, detecting, representing, and disseminating information pertaining to patients' physical and psychological/emotional states. However, the design and development of healthcare applications of this kind is a rather challenging issue that requires to integrate sensor infrastructures, which are able to detect changes in patients' physiological and emotional states, and of sharing this information to interested caregivers, such as professional medical staff, relatives, and friends. This paper proposes the Pervasive Environment for AffeCtive Healthcare (PEACH) framework, a middleware level support for affective healthcare that incarnates these ideas and describes its effective functions in a drug addiction treatment application scenario.",
Discovery-driven graph summarization,"Large graph datasets are ubiquitous in many domains, including social networking and biology. Graph summarization techniques are crucial in such domains as they can assist in uncovering useful insights about the patterns hidden in the underlying data. One important type of graph summarization is to produce small and informative summaries based on user-selected node attributes and relationships, and allowing users to interactively drill-down or roll-up to navigate through summaries with different resolutions. However, two key components are missing from the previous work in this area that limit the use of this method in practice. First, the previous work only deals with categorical node attributes. Consequently, users have to manually bucketize numerical attributes based on domain knowledge, which is not always possible. Moreover, users often have to manually iterate through many resolutions of summaries to identify the most interesting ones. This paper addresses both these key issues to make the interactive graph summarization approach more useful in practice. We first present a method to automatically categorize numerical attributes values by exploiting the domain knowledge hidden inside the node attributes values and graph link structures. Furthermore, we propose an interestingness measure for graph summaries to point users to the potentially most insightful summaries. Using two real datasets, we demonstrate the effectiveness and efficiency of our techniques.",
High-Resolution Imaging Using a Wideband MIMO Radar System With Two Distributed Arrays,"Imaging a fast maneuvering target has been an active research area in past decades. Usually, an array antenna with multiple elements is implemented to avoid the motion compensations involved in the inverse synthetic aperture radar (ISAR) imaging. Nevertheless, there is a price dilemma due to the high level of hardware complexity compared to complex algorithm implemented in the ISAR imaging system with only one antenna. In this paper, a wideband multiple-input multiple-output (MIMO) radar system with two distributed arrays is proposed to reduce the hardware complexity of the system. Furthermore, the system model, the equivalent array production method and the imaging procedure are presented. As compared with the classical real aperture radar (RAR) imaging system, there is a very important contribution in our method that the lower hardware complexity can be involved in the imaging system since many additive virtual array elements can be obtained. Numerical simulations are provided for testing our system and imaging method.","High-resolution imaging,
MIMO,
Radar imaging,
Radar antennas,
Hardware,
Antenna arrays,
Aperture antennas,
Motion compensation,
Inverse synthetic aperture radar,
Production systems"
Recent Developments on EOS 2-D/3-D Electron Gun and Collector Modeling Code,"Recent developments on our electron optics simulator (EOS) are reported in this paper. EOS is the finite-element 2-D and 3-D steady-state beam trajectory codes which target problem classes, including axisymmetric guns, gridded guns, multibeam guns, and multistage depressed collectors at present. In order to improve the accuracy, to reduce computational time and computer memory consumption, and to extend the application scope, four significant advances to EOS have been made, and they are presented in this paper. The quadratic interpolation function, which has a higher accuracy than the linear interpolation function, is employed. A time-domain electrostatic model is built to simulate some transient effects. The symmetric computation algorithm and the 2-D model are applied for symmetric and axisymmetric structures to reduce the computational time and the computer memory consumption. Moreover, the results of the modified model and the original model are compared and analyzed in detail.",
Energy-Efficient Long-Reach Passive Optical Network: A Network Planning Approach Based on User Behaviors,"Long-reach passive optical network (LR-PON) is a cost-effective solution for providing broadband access spanning large areas. LR-PON extends the coverage span of PONs from the traditional 20 km range to 100 km and consolidates the multiple optical line terminals (OLTs) and central offices, thus reducing the operational cost and serving many more users. There are two type of LR-PONs: “tree-and-branch” and “ring-and-spur” LR-PON. To “green” the LR-PON and make it energy-efficient, we study a network planning approach based on user behaviors. By considering the different network usage behaviors of different kind of users (i.e., daily bandwidth demand profiles), we can assign users (e.g., business and residential users) efficiently to different wavelengths in “tree-and-branch” or “ring-and-spur” LR-PONs at networking planning stage and achieve high network utilization at all times. Heuristic searches can provide such assignments and their approximate solutions are very close to the lower bound. The behavior-aware user assignment achieves significant improvement over the traditional method in terms of used wavelengths and could thus saves the energy consumed by the LR-PON.","Access control,
Passive optical networks,
Telecommunication network management,
Behavioral science"
Advanced Architectures and Execution Models to Support Green Computing,"Creating the next generation of power-efficient parallel computers requires a rethink of the mechanisms and methodology for building parallel applications. Energy constraints have pushed us into a regime where parallelism will be ubiquitous rather than limited to highly specialized high-end supercomputers. New execution models are required to span all scales, from desktop to supercomputer.","Program processors,
Supercomputers,
Multicore processing,
Green design,
Performance gain,
Parallel processing,
Energy efficiency,
Power demand"
Exploring facial expressions with compositional features,"Most previous work focuses on how to learn discriminating appearance features over all the face without considering the fact that each facial expression is physically composed of some relative action units (AU). However, the definition of AU is an ambiguous semantic description in Facial Action Coding System (FACS), so it makes accurate AU detection very difficult. In this paper, we adopt a scheme of compromise to avoid AU detection, and try to interpret facial expression by learning some compositional appearance features around AU areas. We first divided face image into local patches according to the locations of AUs, and then we extract local appearance features from each patch. A minimum error based optimization strategy is adopted to build compositional features based on local appearance features, and this process embedded into Boosting learning structure. Experiments on the Cohn-Kanada database show that the proposed method has a promising performance and the built compositional features are basically consistent to FACS.","Gold,
Face detection,
Feature extraction,
Support vector machines,
Support vector machine classification,
Computer science,
Boosting,
Image databases,
Spatial databases,
Psychology"
An Efficient Message-Passing Algorithm for Optimizing Decentralized Detection Networks,"A promising feature of emerging wireless sensor networks is the opportunity for each spatially-distributed node to measure its local state and transmit only information relevant to effective global decision-making. An equally important design objective, as a result of each node's finite power, is for measurement processing to satisfy explicit constraints on, or perhaps make selective use of, the distributed algorithmic resources. We formulate this multi-objective design problem within the Bayesian decentralized detection paradigm, modeling resource constraints by a directed acyclic network with low-rate, unreliable communication links. Existing team theory establishes when necessary optimality conditions reduce to a convergent iterative algorithm to be executed offline (i.e., before measurements are processed). Even so, this offline algorithm has exponential complexity in the number of nodes, and its distributed implementation assumes a fully-connected communication network. We state conditions under which the offline algorithm admits an efficient message-passing interpretation, featuring linear complexity and a natural distributed implementation. We experiment with a simulated network of binary detectors, applying the message-passing algorithm to optimize the achievable tradeoff between global detection performance and network-wide online communication. The empirical analysis also exposes a design tradeoff between constraining in-network processing to preserve resources (per online measurement) and then having to consume resources (per offline reorganization) to maintain detection performance.","Signal processing algorithms,
Iterative algorithms,
Decision making,
Wireless sensor networks,
Power measurement,
Bayesian methods,
Algorithm design and analysis,
Communication networks,
Detectors,
Performance analysis"
Interactive motion planning for steerable needles in 3D environments with obstacles,"Bevel-tip steerable needles for minimally invasive medical procedures can be used to reach clinical targets that are behind sensitive or impenetrable areas and are inaccessible to straight, rigid needles. We present a fast algorithm that can compute motion plans for steerable needles to reach targets in complex, 3D environments with obstacles at interactive rates. The fast computation makes this method suitable for online control of the steerable needle based on 3D imaging feedback and allows physicians to interactively edit the planning environment in real-time by adding obstacle definitions as they are discovered or become relevant. We achieve this fast performance by using a Rapidly Exploring Random Tree (RRT) combined with a reachability-guided sampling heuristic to alleviate the sensitivity of the RRT planner to the choice of the distance metric. We also relax the constraint of constant-curvature needle trajectories by relying on duty-cycling to realize bounded-curvature needle trajectories. These characteristics enable us to achieve orders of magnitude speed-up compared to previous approaches; we compute steerable needle motion plans in under 1 second for challenging environments containing complex, polyhedral obstacles and narrow passages.","Needles,
Trajectory,
Planning,
Three dimensional displays,
Measurement,
Kinematics,
Imaging"
The Convex algebraic geometry of linear inverse problems,"We study a class of ill-posed linear inverse problems in which the underlying model of interest has simple algebraic structure. We consider the setting in which we have access to a limited number of linear measurements of the underlying model, and we propose a general framework based on convex optimization in order to recover this model. This formulation generalizes previous methods based on `1-norm minimization and nuclear norm minimization for recovering sparse vectors and low-rank matrices from a small number of linear measurements. For example some problems to which our framework is applicable include (1) recovering an orthogonal matrix from limited linear measurements, (2) recovering a measure given random linear combinations of its moments, and (3) recovering a low-rank tensor from limited linear observations.","Extraterrestrial measurements,
Minimization,
Vectors,
Tensile stress,
Symmetric matrices,
Equations,
Sparse matrices"
Retrodirective distributed transmit beamforming with two-way source synchronization,"Distributed transmit beamforming has recently been proposed as a technique in which several single-antenna sources cooperate to form a virtual antenna array and simultaneously transmit with phase-aligned carriers such that the passband signals coherently combine at an intended destination. The power gains of distributed transmit beamforming can provide increased range, rate, energy efficiency, and/or security, as well as reduce interference. Distributed transmit beamforming, however, typically requires precise synchronization between the sources with timing errors on the order of picoseconds. In this paper, a new two-way synchronization protocol is developed to facilitate precise source synchronization and retrodirective distributed transmit beamforming. The two-way synchronization protocol is developed under the assumption that all processing at each source node is performed with local observations in local time. An analysis of the statistical properties of the phase and frequency estimation errors in the two-way synchronization protocol and the resulting power gain of a distributed transmit beamformer using this protocol is provided. Numerical examples are also presented characterizing the performance of distributed transmit beamforming in a system using two-way source synchronization. The numerical results demonstrate that near-ideal beamforming performance can be achieved with low synchronization overhead.","Array signal processing,
Frequency synchronization,
Protocols,
Phased arrays,
Transmitting antennas,
Antenna arrays,
Passband,
Energy efficiency,
Security,
Interference"
Performance of dual-hop amplify-and-forward beamforming and its equivalent systems in rayleigh fading channels,"Combining a dual-hop relaying with multi-input multi-output (MIMO) transmission is a natural extension to overcome the channel impairments. Transmit beamforming (TBF) and maximal ratio combining (MRC) are widely accepted ones, which maximize the signal-to-noise ratio (SNR) at the receiver when channel state information is available. With these methods, there are four possible combinations in constructing dual-hop transmission: TBF-TBF, MRC-MRC, MRC-TBF, and TBF-MRC, respectively. We provide optimal amplify-and-forward (AF) weights at a relay, which maximize the end-to-end SNR for the four systems, respectively, and show the equivalence of the four systems in terms of the SNR. Using relaxed AF weights from the optimal ones, we provide a probability density function (PDF) and a moment generating function (MGF) for the end-to- end SNR per bit with an assumption of an equal number of diversity branch for each hop, which is used to obtain the BER performance for M-ary QAM and PSK constellations, respectively. Numerical results show that the BERs with the relaxed AF weights provide tight lower bounds for those with optimal AF weights. We also compare the BER performance of above AF relaying with that of dual-hop decode-and-forward (DF) relaying.","Array signal processing,
Fading,
Relays,
Diversity reception,
Bit error rate,
MIMO,
Signal to noise ratio,
Channel state information,
Probability density function,
Quadrature amplitude modulation"
Neural Decoding of Finger Movements Using Skellam-Based Maximum-Likelihood Decoding,"We present an optimal method for decoding the activity of primary motor cortex (M1) neurons in a nonhuman primate during single finger movements. The method is based on the maximum-likelihood (ML) inference, which assuming the probability of finger movements is uniform, is equivalent to the maximum a posteriori (MAP) inference. Each neuron's activation is first quantified by the change in firing rate before and after finger movement. We then estimate the probability density function of this activation given finger movement, i.e., Pr(neuronal activation (x)| finger movements (m)). Based on the ML criterion, we choose finger movements to maximize Pr(x|m). Experimentally, data were collected from 115 task-related neurons in M1 as the monkey performed flexion and extension of each finger and the wrist (12 movements). With as few as 20-25 randomly selected neurons, the proposed method decoded single-finger movements with 99% accuracy. Since the training and decoding procedures in the proposed method are simple and computationally efficient, the method can be extended for real-time neuroprosthetic control of a dexterous hand.","Maximum likelihood decoding,
Fingers,
Neural prosthesis,
Maximum likelihood estimation,
Neurons,
Biomedical engineering,
Information technology,
Probability density function,
Wrist,
Prosthetics"
Wavelet-Based ECG Data Compression System With Linear Quality Control Scheme,"Maintaining reconstructed signals at a desired level of quality is crucial for lossy ECG data compression. Wavelet-based approaches using a recursive decomposition process are unsuitable for real-time ECG signal recoding and commonly obtain a nonlinear compression performance with distortion sensitive to quantization error. The sensitive response is caused without compromising the influences of word-length-growth (WLG) effect and unfavorable for the reconstruction quality control of ECG data compression. In this paper, the 1-D reversible round-off nonrecursive discrete periodic wavelet transform is applied to overcome the WLG magnification effect in terms of the mechanisms of error propagation resistance and significant normalization of octave coefficients. The two mechanisms enable the design of a multivariable quantization scheme that can obtain a compression performance with the approximate characteristics of linear distortion. The quantization scheme can be controlled with a single control variable. Based on the linear compression performance, a linear quantization scale prediction model is presented for guaranteeing reconstruction quality. Following the use of the MIT-BIH arrhythmia database, the experimental results show that the proposed system, with lower computational complexity, can obtain much better reconstruction quality control than other wavelet-based methods.","Electrocardiography,
Data compression,
Quality control,
Quantization,
Nonlinear distortion,
Discrete wavelet transforms,
Signal processing,
Linear approximation,
Predictive models,
Databases"
Modeling and Analysis of Multichannel P2P Live Video Systems,"In recent years, there have been several large-scale deployments of P2P live video systems. Existing and future P2P live video systems will offer a large number of channels, with users switching frequently among the channels. In this paper, we develop infinite-server queueing network models to analytically study the performance of multichannel P2P live video systems. Our models capture essential aspects of multichannel video systems, including peer channel switching, peer churn, peer bandwidth heterogeneity, and Zipf-like channel popularity. We apply the queueing network models to two P2P streaming designs: the isolated channel design (ISO) and the View-Upload Decoupling (VUD) design. For both of these designs, we develop efficient algorithms to calculate critical performance measures, develop an asymptotic theory to provide closed-form results when the number of peers approaches infinity, and derive near-optimal provisioning rules for assigning peers to groups in VUD. We use the analytical results to compare VUD with ISO. We show that VUD design generally performs significantly better, particularly for systems with heterogeneous channel popularities and streaming rates.","Streaming media,
ISO,
Switches,
Large-scale systems,
Bandwidth,
Computer science,
Queueing analysis,
Performance analysis,
Algorithm design and analysis,
H infinity control"
Hand-Drawn Face Sketch Recognition by Humans and a PCA-Based Algorithm for Forensic Applications,"Because face sketches represent the original faces in a very concise yet recognizable form, they play an important role in criminal investigations, human visual perception, and face biometrics. In this paper, we compared the performances of humans and a principle component analysis (PCA)-based algorithm in recognizing face sketches. A total of 250 sketches of 50 subjects were involved. All of the sketches were drawn manually by five artists (each artist drew 50 sketches, one for each subject). The experiments were carried out by matching sketches in a probe set to photographs in a gallery set. This study resulted in the following findings: 1) A large interartist variation in terms of sketch recognition rate was observed; 2) fusion of the sketches drawn by different artists significantly improved the recognition accuracy of both humans and the algorithm; 3) human performance seems mildly correlated to that of PCA algorithm; 4) humans performed better in recognizing the caricature-like sketches that show various degrees of geometrical distortion or deviation, given the particular data set used; 5) score level fusion with the sum rule worked well in combining sketches, at least for a small number of artists; and 6) the algorithm was superior with the sketches of less distinctive features, while humans seemed more efficient in handling tonality (or pigmentation) cues of the sketches that were not processed with advanced transformation functions.","Face recognition,
Humans,
Forensics,
Visual perception,
Biometrics,
Performance analysis,
Algorithm design and analysis,
Probes,
Principal component analysis,
Pigmentation"
Finite Controllability of Infinite-Dimensional Quantum Systems,"Quantum phenomena of interest in connection with applications to computation and communication often involve generating specific transfers between eigenstates, and their linear superpositions. For some quantum systems, such as spin systems, the quantum evolution equation (the Schrödinger equation) is finite-dimensional and old results on controllability of systems defined on on Lie groups and quotient spaces provide most of what is needed insofar as controllability of non-dissipative systems is concerned. However, in an infinite-dimensional setting, controlling the evolution of quantum systems often presents difficulties, both conceptual and technical. In this paper we present a systematic approach to a class of such problems for which it is possible to avoid some of the technical issues. In particular, we analyze controllability for infinite-dimensional bilinear systems under assumptions that make controllability possible using trajectories lying in a nested family of pre-defined subspaces. This result, which we call the Finite Controllability Theorem, provides a set of sufficient conditions for controllability in an infinite-dimensional setting. We consider specific physical systems that are of interest for quantum computing, and provide insights into the types of quantum operations (gates) that may be developed.","Controllability,
Quantum computing,
Control systems,
Schrodinger equation,
Computer applications,
Control system analysis,
Nonlinear systems,
Sufficient conditions,
Physics computing,
Algebra"
Multiframe Super-Resolution Reconstruction Using Sparse Directional Regularization,"We present a variational approach to obtain high-resolution images from multiframe low-resolution video stills. The objective functional for the variational approach consists of a data fidelity term and a regularizer. The fidelity term is formed by adaptively mimicking l1 and l2 norms. The regularization uses the l1 norm of the framelet coefficients of a high-resolution image with a geometric tight framelet system constructed in this paper. The tight framelet system has abilities to detect multi-orientation and multi-order variations of an image. A two-phase iterative method for super-resolution reconstruction is proposed to construct a high-resolution image. The first phase is to get an approximation of the solution (i.e., the ideal image) using the steepest descent method. The second phase is to enhance the sparsity of the approximate solution by using the soft thresholding operator with variable thresholding parameters. Numerical results based on both synthetic data and real videos show that our algorithm is efficient in terms of removing visual artifacts and preserving edges in restored images.","Image reconstruction,
Strontium,
Image resolution,
Sensor arrays,
Mathematics,
Multiresolution analysis,
Image registration,
Iterative methods,
Image restoration,
Layout"
Long-Wavelength High-Contrast Grating Vertical-Cavity Surface-Emitting Laser,"A novel long-wavelength vertical-cavity surface-emitting laser (VCSEL) structure based on a subwavelength high-contrast grating (HCG) as the output mirror has been realized. By design, these devices are highly polarization stable, are single mode at large apertures, and solve the VCSEL-mirror problem at long wavelengths in an elegant way. With cost-effective mass fabrication in mind, the top HCG reflector consists of amorphous silicon on isolator (amorphous silica). The single-mode laser emission is tailored to be around 1320-nm wavelength, targeting applications in high-speed optical data transmission, particularly those for passive optical networks. We report single-mode emission for devices with apertures as large as 11 μm operating in continuous wave with output powers in excess of 0.4 mW. Pulsed operation with output powers up to 4 mW at room temperature is demonstrated as well. This is the first electrically pumped VCSEL structure realized in this wavelength regime utilizing an HCG mirror.","Vertical cavity surface emitting lasers,
Gratings,
Surface emitting lasers,
Laser modes,
Optical surface waves,
Mirrors,
Apertures,
Passive optical networks,
Power generation,
Polarization"
Effect of Measurement Noise and Bias on Hill-Climbing MPPT Algorithms,"Erroneous measurement of solar array voltage and current degrades the performance of hill-climbing, maximum power point tracking (MPPT) systems. This degradation is observed as a reduced climbing rate, erroneous settling point, and/or random operating point excursions. The effect of measurement bias and noise on MPPT performance is analyzed. Tracking problems are then classified according to their cause, which allows for easier debugging of a faulty tracker. The effectiveness of several error-mitigating techniques is then studied, and recommendations are given accordingly. Conclusions of the analysis are then experimentally verified.","Noise measurement,
Voltage,
Power electronics,
Systolic arrays,
Space vehicles,
Temperature,
Current measurement,
Power measurement,
Degradation,
Computer science"
Large-Girth Nonbinary QC-LDPC Codes of Various Lengths,"In this paper, we construct nonbinary quasi-cyclic low-density parity-check (QC-LDPC) codes whose parity check matrices consist of an array of square sub-matrices which are either zero matrices or circulant permutation matrices. We propose a novel method to design the shift offset values of the circulant permutation sub-matrices, so that the code length can vary while maintaining a large girth. Extensive Monte Carlo simulations demonstrate that the obtained codes of a wide range of rates (from 1/2 to 8/9) with length from 1000 to 10000 bits have very good performance over both AWGN and Rayleigh fading channels. Furthermore, the proposed method is extended to design multiple nonbinary QC-LDPC codes simultaneously where each individual code can achieve large girth with variable lengths. The proposed codes are appealing to practical adaptive systems where the block length and code rate need to be adaptively adjusted depending on traffic characteristics and channel conditions.","Parity check codes,
Algorithm design and analysis,
Phase change materials,
Decoding,
Encoding,
Design methodology,
Computers"
Metrics for Evaluating Video Streaming Quality in Lossy IEEE 802.11 Wireless Networks,"Peak Signal-to-Noise Ratio (PSNR) is the simplest and the most widely used video quality evaluation methodology. However, traditional PSNR calculations do not take the packet loss into account. This shortcoming, which is amplified in wireless networks, contributes to the inaccuracy in evaluating video streaming quality in wireless communications. Such inaccuracy in PSNR calculations adversely affects the development of video communications in wireless networks. This paper proposes a novel video quality evaluation methodology. As it not only considers the PSNR of a video, but also with modifications to handle the packet loss issue, we name this evaluation method MPSNR. MPSNR rectifies the inaccuracies in traditional PSNR computation, and helps us to approximate subjective video quality, Mean Opinion Score (MOS), more accurately. Using PSNR values calculated from MPSNR and simple network measurements, we apply linear regression techniques to derive two specific objective video quality metrics, PSNR-based Objective MOS (POMOS) and Rates-based Objective MOS (ROMOS). Through extensive experiments and human subjective tests, we show that the two metrics demonstrate high correlation with MOS. POMOS takes the averaged PSNR value of a video calculated from MPSNR as the only input. Despite its simplicity, it has a Pearson correlation of 0.8664 with the MOS. By adding a few other simple network measurements, such as the proportion of distorted frames in a video, ROMOS achieves an even higher Pearson correlation (0.9350) with the MOS. Compared with the PSNR metric from the traditional PSNR calculations, our metrics evaluate video streaming quality in wireless networks with a much higher accuracy while retaining the simplicity of PSNR calculation.","Streaming media,
Wireless networks,
PSNR,
Wireless mesh networks,
Humans,
Communications Society,
Lifting equipment,
Computer science,
Electronic mail,
Multimedia communication"
Efficient techniques for monitoring missing RFID tags,"As RFID tags become more widespread, new approaches for managing larger numbers of RFID tags will be needed. In this paper, we consider the problem of how to accurately and efficiently monitor a set of RFID tags for missing tags. Our approach accurately monitors a set of tags without collecting IDs from them. It differs from traditional research which focuses on faster ways for collecting IDs from every tag. We present two monitoring protocols, one designed for a trusted reader and the other for an untrusted reader.","RFID tags,
Protocols,
Radiofrequency identification,
Intrusion detection,
Costs,
Hardware,
Remote monitoring,
Privacy,
Security,
Frequency"
Min-Max Fair Power Flow Tracing for Transmission System Usage Cost Allocation: A Large System Perspective,"Power flow tracing has been suggested as an approach for evaluating 1) transmission system usage (TSU) cost and 2) loss (MW) cost for generator and load entities in the system. Recently, optimal power flow tracing methods have been proposed to “explicitly” model fairness constraints in the tracing framework. This paper, further, strengthens the tracing-compliant min-max fair cost allocation approach. The min-max model proposed in this paper is robust. It addresses concerns like scalability, numerical stability and termination in a finite number of steps while searching the optimal solution. We also propose a methodology to model DISCOMs and GENCOs as coalition within min-max framework. Case studies on an all India network of 1699 nodes and comparison with average participation and marginal participation methods bring out the better conflict resolution feature of the proposed approach. A method to model HVDC lines within the marginal participation scheme is also proposed. Quantitative and qualitative comparison of various TSU cost allocation methods on such a large system is another noteworthy contribution of the paper.","Load flow,
Costs,
Power system modeling,
HVDC transmission,
Propagation losses,
Robustness,
Scalability,
Numerical stability,
Game theory,
Vectors"
Dimensionality Reduction in Control and Coordination of the Human Hand,"The concept of kinematic synergies is proposed to address the dimensionality reduction problem in control and coordination of the human hand. This paper develops a method for extracting kinematic synergies from joint-angular-velocity profiles of hand movements. Decomposition of a limited set of synergies from numerous movements is a complex optimization problem. This paper splits the decomposition process into two stages. The first stage is to extract synergies from rapid movement tasks using singular value decomposition (SVD). A bank of template functions is then created from shifted versions of the extracted synergies. The second stage is to find weights and onset times of the synergies based on l 1 -minimization, whose solutions provide sparse representations of hand movements using synergies.","Humans,
Kinematics,
Sun,
Singular value decomposition,
Virtual reality,
Fingers,
Central nervous system,
Centralized control,
Control systems"
Long-Term Effects of Feed-In Tariffs and Carbon Taxes on Distribution Systems,"In deregulated electricity sector climates, such as in Ontario, the production of clean or renewable energy by small power producers through distributed generation (DG) is encouraged. This paper examines the policies that can be used to encourage DG investment and incorporates them into a mathematical model. This model is then used to create scenarios for examining the economic and environmental supply-side effects of policies to a distribution system over a ten-year period. The policies analyzed include a combination of feed-in-tariffs, CO2 tax, and cap-and-trade schemes. The results are discussed in the context of the Ontario market and its Standard Offer Program, implemented on a 32-bus radial distribution system.","Carbon tax,
Electricity supply industry deregulation,
Production,
Renewable energy resources,
Distributed control,
Investments,
Mathematical model,
Power system modeling,
Power system economics,
Power generation economics"
Retransmission Strategies for Cyclic Polling Over Wireless Channels in the Presence of Interference,"In this paper, we consider retransmission strategies for centralized cyclic polling-based systems over wireless channels subject to external interference. The considered strategies differ in the time when retransmissions for one particular node are carried out, and in the number of retransmissions that can be carried out for one node. We show experimentally and by simulation that two related strategies introduced in this paper, called the queueing-based strategies, significantly outperform the traditional strategy (in which all admissible trials towards one node are carried out subsequently) in terms of the average number of nodes that cannot be successfully served in a cycle. These performance gains are achieved without increasing the average total transmission effort.",
Tracking with local spatio-temporal motion patterns in extremely crowded scenes,"Tracking individuals in extremely crowded scenes is a challenging task, primarily due to the motion and appearance variability produced by the large number of people within the scene. The individual pedestrians, however, collectively form a crowd that exhibits a spatially and temporally structured pattern within the scene. In this paper, we extract this steady-state but dynamically evolving motion of the crowd and leverage it to track individuals in videos of the same scene. We capture the spatial and temporal variations in the crowd's motion by training a collection of hidden Markov models on the motion patterns within the scene. Using these models, we predict the local spatio-temporal motion patterns that describe the pedestrian movement at each space-time location in the video. Based on these predictions, we hypothesize the target's movement between frames as it travels through the local space-time volume. In addition, we robustly model the individual's unique motion and appearance to discern them from surrounding pedestrians. The results show that we may track individuals in scenes that present extreme difficulty to previous techniques.","Layout,
Videos,
Hidden Markov models,
Steady-state,
Predictive models,
Surveillance,
Computer science,
Robustness,
Target tracking,
Cameras"
Content-based image retrieval using color moment and Gabor texture feature,"Aim to currently content-based image retrieval method having high computational complexity and low retrieval accuracy problem, this paper proposes a content-based image retrieval method based on color and texture features. As its color features, color moments of the Hue, Saturation and Value (HSV) component images in HSV color space are used. As its texture features, Gabor texture descriptors are adopted. Users assign the weights to each feature respectively and calculate the similarity with combined features of color and texture according to normalized Euclidean distance. Experiment results show that the proposed method has higher retrieval accuracy than conventional methods using color and texture features even though its feature vector dimension results in a lower rate than the conventional method.","Image color analysis,
Gabor filters,
Feature extraction,
Image retrieval,
Band pass filters,
Histograms,
Machine learning"
Outlier removal using duality,"In this paper we consider the problem of outlier removal for large scale multiview reconstruction problems. An efficient and very popular method for this task is RANSAC. However, as RANSAC only works on a subset of the images, mismatches in longer point tracks may go undetected. To deal with this problem we would like to have, as a post processing step to RANSAC, a method that works on the entire (or a larger) part of the sequence. In this paper we consider two algorithms for doing this. The first one is related to a method by Sim & Hartley where a quasiconvex problem is solved repeatedly and the error residuals with the largest error is removed. Instead of solving a quasiconvex problem in each step we show that it is enough to solve a single LP or SOCP which yields a significant speedup. Using duality we show that the same theoretical result holds for our method. The second algorithm is a faster version of the first, and it is related to the popular method of L1-optimization. While it is faster and works very well in practice, there is no theoretical guarantee of success. We show that these two methods are related through duality, and evaluate the methods on a number of data sets with promising results.1","Image reconstruction,
Geometry,
Cameras,
Computer science,
Large-scale systems,
Image sequences,
Statistical distributions,
Motion estimation,
Layout,
Computer errors"
A Useful Control Model for Tandem Hot Metal Strip Rolling,"The tandem hot metal strip rolling process is a highly complex nonlinear system that presents a difficult control challenge. This challenge is exacerbated by the hostile hot metal rolling environment, which precludes the location of sensors to measure variables that are important for control. In addition, the controller must have a structure that offers simplicity of tuning during commissioning by personnel who usually are unfamiliar with advanced process control techniques. Based on our previous work using a state-dependent Riccati equation technique for control of the tandem cold metal rolling process, it is considered that a similar method might also be useful for control of tandem hot strip rolling. For the hot rolling process, the development of a process model in a form that is suitable for control development is a significant and challenging task. This paper describes our work to expand on an initial portion of this model to develop a comprehensive nonlinear model of this process. Based on simulation results, it is determined that the complete model has the potential to be useful in the development of a viable nonlinear control method for significant improvement in the control of the tandem hot rolling process.","Strips,
Mathematical model,
Process control,
Computational modeling,
Torque,
Metals"
Simple virtual channel allocation for high throughput and high frequency on-chip routers,"Technology scaling has led to the integration of many cores into a single chip. As a result, on-chip interconnection networks start to play a more and more important role in determining the performance and power of the entire chip. Packet-switched network-on-chip (NoC) has provided a scalable solution to the communications for tiled multi-core processors. However the virtual-channel (VC) buffers in the NoC consume significant dynamic and leakage power of the system. To improve the energy efficiency of the router design, it is advantageous to use small buffer sizes while still maintaining throughput of the network. This paper proposes two new virtual channel allocation (VA) mechanisms, termed Fixed VC Assignment with Dynamic VC Allocation (FVADA) and Adjustable VC Assignment with Dynamic VC Allocation (AVADA). The idea is that VCs are assigned based on the designated output port of a packet to reduce the Head-of-Line (HoL) blocking. Also, the number of VCs allocated for each output port can be adjusted dynamically. Unlike previous buffer-pool based designs, we only use a small number of VCs to keep the arbitration latency low. Simulation results show that FVADA and AVADA can improve the network throughput by 41% on average, compared to a baseline design with the same buffer size. AVADA can still outperform the baseline even when our buffer size is halved. Moreover, we are able to achieve comparable or better throughput than a previous dynamic VC allocator while reducing its critical path delay by 60%. Our results prove that the proposed VA mechanisms are suitable for low-power, high-throughput, and high-frequency on-chip network designs.","Channel allocation,
Throughput,
Radio spectrum management,
Network-on-a-chip,
Virtual colonoscopy,
Buffer storage,
Delay,
Multiprocessor interconnection networks,
Energy efficiency,
Power engineering and energy"
Gap-Filling for the High-Resolution PET Sinograms With a Dedicated DCT-Domain Filter,"High-resolution positron emission tomography (PET) scanners have brought many improvements to the nuclear medicine imaging field. However, the mechanical limitations in the construction of the scanners introduced gaps between the detectors, and accordingly, to the acquired projection data. When the methods requiring full-sinogram dataset, e.g., filtered backprojection (FBP) are applied, the missing parts degrade the reconstructed images. In this study, we aim to compensate the sinograms for the missing parts, i.e., gaps. For the gap filling, we propose an iterative discrete-cosine transform (DCT) domain method with two versions: (1) with basic DCT domain filter and (2) with dedicated and gap-dependent DCT domain filter. For the testing of the methods, 2-D FBP reconstructions were applied to the gap-filled sinograms. The proposed DCT domain gap-filling method with two different filters was compared to the constrained Fourier space (CFS) method. For the quantitative analysis, we used numerical phantoms at eight different Poisson noise levels with 100 realizations. Mean-square error, bias, and variance evaluations were performed over the selected regions of interest. Only the dedicated gap-dependent DCT domain filter showed quantitative improvement in all regions, at each noise level. We also assessed the methods visually with a [11C] raclopride human brain study reconstructed by 2-D FBP after gap filling. The visual comparisons of the methods showed that the gap filling with both DCT domain filters performed better than the CFS method. The proposed technique can be used for the sinograms, not only with limited range of projections as in the high-resolution research tomograph (ECAT HRRT) PET scanner, but also with detector failure artifacts.","Positron emission tomography,
Filters,
Discrete cosine transforms,
Image reconstruction,
Filling,
Detectors,
Noise level,
Nuclear medicine,
High-resolution imaging,
Degradation"
Hybrid CMOS/memristor circuits,"This is a brief review of recent work on the prospective hybrid CMOS/memristor circuits. Such hybrids combine the flexibility, reliability and high functionality of the CMOS subsystem with very high density of nanoscale thin film resistance switching devices operating on different physical principles. Simulation and initial experimental results demonstrate that performance of CMOS/memristor circuits for several important applications is well beyond scaling limits of conventional VLSI paradigm.","Memristors,
Circuits"
An automated system for colored retinal image background and noise segmentation,"Retinal images are used for the automated diagnosis of diabetic retinopathy. The retinal image quality must be improved for the detection of features and abnormalities and for this purpose segmentation of retinal images is vital. In this paper, we present a novel automated approach for segmentation of colored retinal images. Our segmentation technique smoothes and strengthens images by separating the background and noisy area from the overall image thus resulting in retinal image enhancement and lower processing time. It contains coarse segmentation and fine segmentation. Standard retinal images databases Diaretdb0 and Diaretdb1 are used to test the validation of our segmentation technique. Experimental results indicate our approach is effective and can get higher segmentation accuracy.","Image segmentation,
Retina,
Pixel,
Diabetes,
Image color analysis,
Colored noise"
Annealing of Heavy-Ion Induced Floating Gate Errors: LET and Feature Size Dependence,"We discuss the room temperature annealing of Floating Gate errors in Flash memories with NAND and NOR architecture after heavy-ion irradiation. We present the evolution of raw bit errors as a function of time after the exposure, examining the annealing dependence on the particle LET, cell feature size, and, for Multi Level Cells, on the program level. The results are explained based on the statistical properties of the cell threshold voltage distributions before and after heavy-ion strikes.","Annealing,
Nonvolatile memory,
Flash memory,
Circuits,
Ionizing radiation,
Temperature dependence,
Threshold voltage,
Radiation effects,
Digital audio players,
Digital cameras"
Invariant Trajectory Tracking With a Full-Size Autonomous Road Vehicle,"Safe handling of dynamic inner-city scenarios with autonomous road vehicles involves the problem of stabilization of precalculated state trajectories. In order to account for the practical requirements of the holistic autonomous system, we propose two complementary nonlinear Lyapunov-based tracking-control laws to solve the problem for speeds between ±6 m/s. Their designs are based on an extended kinematic one-track model, and they provide a smooth, singularity-free stopping transient. With regard to autonomous test applications, the proposed tracking law without orientation control performs much better with respect to control effort and steering-input saturation than the one with orientation control but needs to be prudently combined with the latter for backward driving. The controller performance is illustrated with a full-size test vehicle.","Trajectory,
Road vehicles,
Sliding mode control,
Mobile robots,
Robotics and automation,
Automatic control,
Control systems,
Feedback,
Remotely operated vehicles,
Intelligent robots"
A Fuzzy Petri-Nets Model for Computing With Words,"Motivated by Zadeh's paradigm of computing with words (CWs) rather than numbers, several formal models of CWs have recently been proposed. These models are based on automata and, thus, are not well suited for concurrent computing. In this paper, we incorporate the well-known model of concurrent computing, which is called the Petri net, together with fuzzy-set theory and, thereby, establish a concurrency model of CWs-fuzzy Petri nets for CWs (FPNCWs). The new feature of such fuzzy Petri nets is that the labels of transitions are some special words modeled by fuzzy sets. By employing the methodology of fuzzy reasoning, we give a faithful extension of an FPNCW that makes computing with more words possible. The language expressiveness of the two formal models of CWs, i.e., fuzzy automata for CWs as well as FPNCWs, is compared. A few small examples are provided to illustrate the theoretical development.","Automata,
Fuzzy sets,
Petri nets,
Fuzzy reasoning,
Concurrent computing,
Fuzzy control,
Humans,
Computer science,
Laboratories,
Manipulator dynamics"
A Family of Fuzzy Learning Algorithms for Robust Principal Component Analysis Neural Networks,"In this paper, we analyze Xu and Yuille's robust principal component analysis (RPCA) learning algorithms by means of the distance measurement in space. Based on the analysis, a family of fuzzy RPCA learning algorithms is proposed, which is robust against outliers. These algorithms can explicitly be understood from the viewpoint of fuzzy set theory, though Xu and Yuille's algorithms were proposed based on a statistical physics approach. In the proposed algorithms, an adaptive learning procedure overcomes the difficulty of selection of learning parameters in Xu and Yuille's algorithms. Furthermore, the robustness of proposed algorithms is investigated by using the theory of influence functions. Simulations are carried out to illustrate the robustness of these algorithms.","Fuzzy neural networks,
Robustness,
Principal component analysis,
Neural networks,
Fuzzy set theory,
Algorithm design and analysis,
Distance measurement,
Extraterrestrial measurements,
Physics,
Set theory"
Modeling enjoyment preference from physiological responses in a car racing game,"We propose a framework to estimate player enjoyment preference from physiological signals. This can produce objective measures that could be used to adapt dynamically a game to maintain the player in an optimal status of enjoyment. We present a case study on The Open Racing Car Simulator (TORCS) video game. In particular, we focus both on the experimental protocol, which we designed with special attention to produce physiological responses related to the game experience only, and on signal analysis, which produces a simple and general model good enough to estimate player enjoyment preference in real applications.","Games,
Correlation,
Computers,
Protocols,
Biomedical monitoring,
Computational modeling,
Driver circuits"
Practical Online Near-Duplicate Subsequence Detection for Continuous Video Streams,"Online video content is surging to an unprecedented level. Massive video publishing and sharing impose heavy demands on online near-duplicate detection for many novel video applications. This paper presents an accurate and practical system for online near-duplicate subsequence detection over continuous video streams. We propose to transform a video stream into a one-dimensional video distance trajectory (VDT) monitoring the continuous changes of consecutive frames with respect to a reference point, which is further segmented and represented by a sequence of compact signatures called linear smoothing functions (LSFs). LSFs of each subsequence of the incoming video stream are continuously generated and temporally stored in a buffer for comparison with query LSFs. LSF adopts compound probability to combine three independent video factors for effective segment similarity measure, which is then utilized to compute sequence similarity for near-duplicate detection. To avoid unnecessary sequence similarity computations, an efficient sequence skipping strategy is also embedded. Experimental results on detecting diverse near-duplicates of TV commercials in real video streams show the superior performance of our system on both effectiveness and efficiency over existing methods.",
Location-based augmented reality on mobile phones,"The computational capability of mobile phones has been rapidly increasing, to the point where augmented reality has become feasible on cell phones. We present an approach to indoor localization and pose estimation in order to support augmented reality applications on a mobile phone platform. Using the embedded camera, the application localizes the device in a familiar environment and determines its orientation. Once the 6 DOF pose is determined, 3D virtual objects from a database can be projected into the image and displayed for the mobile user. Off-line data acquisition consists of acquiring images at different locations in the environment. The online pose estimation is done by a feature-based matching between the cell phone image and an image selected from the precomputed database using the phone's sensors (accelerometer and magnetometer). The application enables the user both to visualize virtual objects in the camera image and to localize the user in a familiar environment. We describe in detail the process of building the database and the pose estimation algorithm used on the mobile phone. We evaluate the algorithm performance as well as its accuracy in terms of reprojection distance of the 3D virtual objects in the cell phone image.",
Learning to open new doors,"We consider the problem of enabling a robot to autonomously open doors, including novel ones that the robot has not previously seen. Given the large variation in the appearances and locations of doors and door handles, this is a challenging perception and control problem; but this capability will significantly enlarge the range of environments that our robots can autonomously navigate through. In this paper, we focus on the case of doors with door handles. We propose an approach that, rather than trying to build a full 3d model of the door/door handle—which is challenging because of occlusion, specularity of many door handles, and the limited accuracy of our 3d sensors—instead uses computer vision to choose a manipulation strategy. Specifically, it uses an image of the door handle to identify a small number of “3d key locations,” such as the axis of rotation of the door handle, and the location of the end-point of the door-handle. These key locations then completely define a trajectory for the robot end-effector (hand) that successfully turns the door handle and opens the door. Evaluated on a large set of doors that the robot had not previously seen, it successfully opened 31 out of 34 doors. We also show that this approach of using vision to identify a small number of key locations also generalizes to a range of other tasks, including turning a thermostat knob, pulling open a drawer, and pushing elevator buttons.","Three dimensional displays,
Robot sensing systems,
Cameras,
Trajectory,
Feature extraction,
Solid modeling"
Robust Reconstruction of MRSI Data Using a Sparse Spectral Model and High Resolution MRI Priors,"We introduce a novel algorithm to address the challenges in magnetic resonance (MR) spectroscopic imaging. In contrast to classical sequential data processing schemes, the proposed method combines the reconstruction and postprocessing steps into a unified algorithm. This integrated approach enables us to inject a range of prior information into the data processing scheme, thus constraining the reconstructions. We use high resolution, 3-D estimate of the magnetic field inhomogeneity map to generate an accurate forward model, while a high resolution estimate of the fat/water boundary is used to minimize spectral leakage artifacts. We parameterize the spectrum at each voxel as a sparse linear combination of spikes and polynomials to capture the metabolite and baseline components, respectively. The constrained model makes the problem better conditioned in regions with significant field inhomogeneity, thus enabling the recovery even in regions with high field map variations. To exploit the high resolution MR information, we formulate the problem as an anatomically constrained total variation optimization scheme on a grid with the same spacing as the magnetic resonance imaging data. We analyze the performance of the proposed scheme using phantom and human subjects. Quantitative and qualitative comparisons indicate a significant improvement in spectral quality and lower leakage artifacts.",
Synthesis of Linear Quantum Stochastic Systems via Quantum Feedback Networks,"Recent theoretical and experimental investigations of coherent feedback quantum control, the feedback control of a quantum system with another quantum system, has raised the important problem of how to synthesize a class of quantum systems, called the class of linear quantum stochastic systems, from basic quantum optical components and devices in a systematic way. The synthesis theory sought in this case can be naturally viewed as a quantum analogue of linear electrical network synthesis theory and as such has potential for applications beyond the realization of coherent quantum feedback controllers. In earlier work, Nurdin et al. have established that an arbitrary linear quantum stochastic system can be realized as a cascade connection of simpler one degree of freedom quantum harmonic oscillators, together with a direct interaction Hamiltonian which is bilinear in the canonical operators of the oscillators. However, from an experimental perspective and based on current methods and technologies, direct interaction Hamiltonians are challenging to implement for systems with more than just a few degrees of freedom. In order to facilitate more tractable physical realizations of these systems, this technical note develops a new synthesis algorithm for linear quantum stochastic systems that relies solely on field-mediated interactions, including in implementation of the direct interaction Hamiltonian. Explicit synthesis examples are provided to illustrate the realization of two degrees of freedom linear quantum stochastic systems using the new algorithm.","Network synthesis,
Stochastic systems,
Quantum mechanics,
Control system synthesis,
Optical feedback,
Oscillators,
Linear feedback control systems,
Optical control,
Feedback control,
Optical devices"
Smarter Phones for Healthier Lifestyles: An Adaptive Fitness Game,"Mobile phones can persuade users to adopt healthy behaviors such as regular exercise. Monsters & Gold, a context-aware, user-adaptive mobile fitness game, runs on mobile phones to motivate and train users in jogging outdoors. The game dynamically presents virtual monsters, gold, and other items-according to factors such as users' heart rate, age, and exercise phase-to encourage users to speed up or slow down. A first evaluation led to an improved game design; a subsequent evaluation confirmed beneficial effects on training and motivation.","Game theory,
Mobile handsets,
Gold,
Heart rate,
Pervasive computing,
Human computer interaction,
Computer science,
Global Positioning System,
Navigation,
Cardiovascular diseases"
Novel Wideband Transition Between Coplanar Waveguide and Microstrip Line,"A novel wideband vertical transition for connecting the coplanar waveguide (CPW) to the microstrip line is proposed. This transition can be very useful for millimeter-wave packaging and vertical interconnects. It is multilayered, partly tapered, and consists of only one via interconnect. Two different transitions are designed. The first transition allows connectivity of a CPW with Zc=50 Ω to a microstrip line with Zc=16 Ω with a bandwidth of 10-60 GHz. The second transition has the same characteristic impedance, Zc=50 Ω, at the two ports. In this case, the operating frequency is from 40 MHz to 60 GHz. The return losses of both transitions are generally lower than -10 dB over their indicated frequency ranges, while the maximum measured insertion losses are 1.8 and 2.4 dB for the first and second transition, respectively. To extract the S-parameters of the transitions, a new thru-line technique, based on the standard thru-reflect-line two-tier calibration is introduced. Simulation and experimental results, showing good agreement, are presented and discussed.","Wideband,
Coplanar waveguides,
Waveguide transitions,
Microstrip,
Frequency,
Joining processes,
Millimeter wave technology,
Packaging,
Bandwidth,
Impedance"
A Service-Based Approach to Designing Cyber Physical Systems,"A Cyber-Physical System (CPS) is defined as integrations of computation and physical processes. In CPS, downsized embedded devices monitor and manage the physical process. Mobile Internet Device (MID), as a portable handheld device designed for mobility providing a down-graded computing capability, can be used as a strong candidate for client-side devices in CPS. Since these physical devices have limited resources, it is not possible to execute complex computation and processes. To cope with this challenge, we apply Service-oriented Architecture (SOA) or Cloud Computing (CC) concepts to CPS, called a service-based CPS. To realize a service-based CPS, we first define overall architecture with three tiers. And, we present key methods to design each tier in the architecture. The design methods are defined to deal with design challenges of CPSs such as dynamic composition, dynamic adaptation, and high confidence CPS management. Then, we perform a case study to show applicability of our approach. With this approach, we hope that CPS can even handle complex and resource-consuming physical processes with a downsized MID.","Monitoring,
Control systems,
Computational modeling,
Context,
Quality of service,
Service oriented architecture,
Computer architecture"
Bluetooth indoor localization with multiple neural networks,"Over the last years, many different methods have been proposed for indoor localization and navigation services based on Radio frequency (RF) technology and Radio Signal Strength Indicator (RSSI). The accuracy achieved with such systems is typically low, mainly due to the variability of RSSI values, unsuitable for classic localization methods (e.g. triangulation). In this paper, we propose a novel approach based on multiple neural networks. We demonstrate with experimental results that by training and then activating different neural networks, tailored on the user orientation, high definition accuracy is achievable, allowing indoor navigation with a cost effective Bluetooth (BT) architecture.","Bluetooth,
Neural networks,
Radio frequency,
Navigation,
Global Positioning System,
Absorption,
Pervasive computing,
Computer vision,
RF signals,
Costs"
Covariance Estimation in Decomposable Gaussian Graphical Models,"Graphical models are a framework for representing and exploiting prior conditional independence structures within distributions using graphs. In the Gaussian case, these models are directly related to the sparsity of the inverse covariance (concentration) matrix and allow for improved covariance estimation with lower computational complexity. We consider concentration estimation with the mean-squared error (MSE) as the objective, in a special type of model known as decomposable. This model includes, for example, the well known banded structure and other cases encountered in practice. Our first contribution is the derivation and analysis of the minimum variance unbiased estimator (MVUE) in decomposable graphical models. We provide a simple closed form solution to the MVUE and compare it with the classical maximum likelihood estimator (MLE) in terms of performance and complexity. Next, we extend the celebrated Stein's unbiased risk estimate (SURE) to graphical models. Using SURE, we prove that the MSE of the MVUE is always smaller or equal to that of the biased MLE, and that the MVUE itself is dominated by other approaches. In addition, we propose the use of SURE as a constructive mechanism for deriving new covariance estimators. Similarly to the classical MLE, all of our proposed estimators have simple closed form solutions but result in a significant reduction in MSE.",
False Negative Problem of Counting Bloom Filter,"Bloom filter is effective, space-efficient data structure for concisely representing a data set and supporting approximate membership queries. Traditionally, researchers often believe that it is possible that a Bloom filter returns a false positive, but it will never return a false negative under well-behaved operations. By investigating the mainstream variants, however, we observe that a Bloom filter does return false negatives in many scenarios. In this work, we show that the undetectable incorrect deletion of false positive items and detectable incorrect deletion of multiaddress items are two general causes of false negative in a Bloom filter. We then measure the potential and exposed false negatives theoretically and practically. Inspired by the fact that the potential false negatives are usually not fully exposed, we propose a novel Bloom filter scheme, which increases the ratio of bits set to a value larger than one without decreasing the ratio of bits set to zero. Mathematical analysis and comprehensive experiments show that this design can reduce the number of exposed false negatives as well as decrease the likelihood of false positives. To the best of our knowledge, this is the first work dealing with both the false positive and false negative problems of Bloom filter systematically when supporting standard usages of item insertion, query, and deletion operations.",
SPANC: Optimizing Scheduling Delay for Peer-to-Peer Live Streaming,"In peer-to-peer (P2P) live streaming using unstructured mesh, packet scheduling is an important factor in overall playback delay. In this paper, we propose a scheduling algorithm to minimize scheduling delay. To achieve low delay, our scheduling is predominantly push in nature, and the schedule needs to be changed only upon significant change in network states (due to, for examples, bandwidth change or parent churns). Our scheme, termed SPANC (Substream Pushing and Network Coding), pushes video packets in substreams and recovers packet loss using network coding. Given heterogeneous contents, delays, and bandwidths of parents of a peer, we formulate the substream assignment (SA) problem to assign substreams to parents with minimum delay. The SA problem can be optimally solved in polynomial time by transforming it to a max-weighted bipartite matching problem. We then formulate the fast recovery with network coding (FRNC) problem, which is to assign network coded packets to each parent to achieve minimum recovery delay. The FRNC problem can also be solved exactly in polynomial time with dynamic programming. Simulation results show that SPANC achieves substantially lower delay with little cost in bandwidth, as compared with recent approaches based on pull, network coding and hybrid pull-push.","Peer to peer computing,
Bandwidth,
Network coding,
Streaming media,
Processor scheduling,
Scheduling algorithm,
Polynomials,
Robustness,
Propagation delay,
Kelvin"
Constrained and Dimensionality-Independent Path Openings,"Path openings and closings are morphological operations with flexible line segments as structuring elements. These line segments have the ability to adapt to local image structures, and can be used to detect lines that are not perfectly straight. They also are a convenient and efficient alternative to straight line segments as structuring elements when the exact orientation of lines in the image is not known. These path operations are defined by an adjacency relation, which typically allows for lines that are approximately horizontal, vertical or diagonal. However, because this definition allows zig-zag lines, diagonal paths can be much shorter than the corresponding horizontal or vertical paths. This undoubtedly causes problems when attempting to use path operations for length measurements. This paper 1) introduces a dimensionality-independent implementation of the path opening and closing algorithm by Appleton and Talbot, 2) proposes a constraint on the path operations to improve their ability to perform length measurements, and 3) shows how to use path openings and closings in a granulometry to obtain the length distribution of elongated structures directly from a gray-value image, without a need for binarizing the image and identifying individual objects.","Image segmentation,
Length measurement,
Image color analysis,
Morphology,
Pixel,
Morphological operations,
Performance evaluation"
Emotional Stress Recognition System Using EEG and Psychophysiological Signals: Using New Labelling Process of EEG Signals in Emotional Stress State,"this paper proposes a new emotional stress recognition system using multi-modal bio-signals. Since electroencephalogram (EEG) is the reflection of brain activity and is widely used in clinical diagnosis and biomedical research, it is used as the main signal. In order to choose the proper EEG channels we used the cognitive model of the brain under emotional stress. We designed an efficient acquisition protocol to acquire the EEG and psychophysiological signals under pictures induction environment (calm-neutral and negative-excited) for participants. Qualitative and quantitative evaluation of psychophysiological signals have been tried to select suitable segments of EEG signal for improving efficiency and performance of emotional stress recognition system. After pre-processing the signals, both Linear and nonlinear features were employed to extract the EEG parameters. Wavelet coefficients and chaotic invariants like fractal dimension by Higuchi's algorithm and correlation dimension were used to extract the characteristics of the EEG signal which showed that the classification accuracy in two emotional states was 82.7% using the Elman classifier. This is a great improvement in results compared with other similar published work.","Human factors,
Electroencephalography,
Signal processing,
Emotion recognition,
Psychology,
Labeling,
Reflection,
Clinical diagnosis,
Brain modeling,
Signal design"
Constructive Approximation to Multivariate Function by Decay RBF Neural Network,"It is well known that single hidden layer feedforward networks with radial basis function (RBF) kernels are universal approximators when all the parameters of the networks are obtained through all kinds of algorithms. However, as observed in most neural network implementations, tuning all the parameters of the network may cause learning complicated, poor generalization, overtraining and unstable. Unlike conventional neural network theories, this brief gives a constructive proof for the fact that a decay RBF neural network with n + 1 hidden neurons can interpolate n + 1 multivariate samples with zero error. Then we prove that the given decay RBFs can uniformly approximate any continuous multivariate functions with arbitrary precision without training. The faster convergence and better generalization performance than conventional RBF algorithm, BP algorithm, extreme learning machine and support vector machines are shown by means of two numerical experiments.","Neural networks,
Feedforward neural networks,
Artificial neural networks,
Iterative algorithms,
Neurons,
Multi-layer neural network,
Computers,
Kernel,
Convergence of numerical methods,
Machine learning"
Search-based planning for manipulation with motion primitives,"Heuristic searches such as A* search are highly popular means of finding least-cost plans due to their generality, strong theoretical guarantees on completeness and optimality and simplicity in the implementation. In planning for robotic manipulation however, these techniques are commonly thought of as impractical due to the high-dimensionality of the planning problem. In this paper, we present a heuristic search-based manipulation planner that does deal effectively with the high-dimensionality of the problem. The planner achieves the required efficiency due to the following three factors: (a) its use of informative yet fast-to-compute heuristics; (b) its use of basic (small) motion primitives as atomic actions; and (c) its use of ARA* search which is an anytime heuristic search with provable bounds on solution suboptimality. Our experimental analysis on a real mobile manipulation platform with a 7-DOF robotic manipulator shows the ability of the planner to solve manipulation in cluttered spaces by generating consistent, low-cost motion trajectories while providing guarantees on completeness and bounds on suboptimality.","Motion planning,
Orbital robotics,
Manipulators,
USA Councils,
Mobile robots,
Robotics and automation,
Information science,
Laboratories,
Motion analysis,
Trajectory"
Monte Carlo Tree Search in Lines of Action,"The success of Monte Carlo tree search (MCTS) in many games, where αβ-based search has failed, naturally raises the question whether Monte Carlo simulations will eventually also outperform traditional game-tree search in game domains where αβ -based search is now successful. The forte of αβ-based search are highly tactical deterministic game domains with a small to moderate branching factor, where efficient yet knowledge-rich evaluation functions can be applied effectively. In this paper, we describe an MCTS-based program for playing the game Lines of Action (LOA), which is a highly tactical slow-progression game exhibiting many of the properties difficult for MCTS. The program uses an improved MCTS variant that allows it to both prove the game-theoretical value of nodes in a search tree and to focus its simulations better using domain knowledge. This results in simulations superior in both handling tactics and ensuring game progression. Using the improved MCTS variant, our program is able to outperform even the world's strongest αβ-based LOA program. This is an important milestone for MCTS because the traditional game-tree search approach has been considered to be the better suited for playing LOA.","Imaging phantoms,
Filling"
Purely Automated Attacks on PassPoints-Style Graphical Passwords,"We introduce and evaluate various methods for purely automated attacks against PassPoints-style graphical passwords. For generating these attacks, we introduce a graph-based algorithm to efficiently create dictionaries based on heuristics such as click-order patterns (e.g., five points all along a line). Some of our methods combine click-order heuristics with focus-of-attention scan-paths generated from a computational model of visual attention, yielding significantly better automated attacks than previous work. One resulting automated attack finds 7%-16% of passwords for two representative images using dictionaries of approximately 226 entries (where the full password space is 243). Relaxing click-order patterns substantially increased the attack efficacy albeit with larger dictionaries of approximately 235 entries, allowing attacks that guessed 48%-54% of passwords (compared to previous results of 1% and 9% on the same dataset for two images with 235 guesses). These latter attacks are independent of focus-of-attention models, and are based on image-independent guessing patterns. Our results show that automated attacks, which are easier to arrange than human-seeded attacks and are more scalable to systems that use multiple images, require serious consideration when deploying basic PassPoints-style graphical passwords.",
Scalable Secret Image Sharing With Smaller Shadow Images,"In 2007, Wang and Shyu proposed a scalable secret image sharing scheme in which three sharing styles, namely the multisecret, priority, and progressive modes, are designed to encode an image with diverse revealing effects. Their scheme is a (2, n ) sharing method where each generated shadow image is half size of the original image. This letter proposes a general (t,n), 2 ¿ t ¿ n, scalable secret image sharing scheme with the same revealing effects. Notably, the size of each generated shadow image is only (2n-t)/n 2 times of the original image. The smaller size of the generated shadow images makes their transmission and storage more efficient.",
Sparse Signal Recovery and Acquisition with Graphical Models,"A great deal of theoretic and algorithmic research has revolved around sparsity view of signals over the last decade to characterize new, sub-Nyquist sampling limits as well as tractable algorithms for signal recovery from dimensionality reduced measurements. Despite the promising advances made, real-life applications require more realistic signal models that can capture the underlying, application-dependent order of sparse coefficients, better sampling matrices with information preserving properties that can be implemented in practical systems, and ever faster algorithms with provable recovery guarantees for real-time operation.","Signal processing algorithms,
Sparse matrices,
Approximation methods,
Approximation algorithms,
Noise,
Graphical models,
Algorithm design and analysis"
Physics-based fast single image fog removal,"Imaging in poor weather is often severely degraded by scattering due to suspended particles in the atmosphere such as haze, fog and mist. Poor visibility becomes a major problem for most outdoor vision applications. In this paper, we propose a novel fast defogging method from a single image of a scene based on a fast bilateral filtering approach. The complexity of our method is only a linear function of the number of input image pixels and this thus allows a very fast implementation. Results on a variety of outdoor foggy images demonstrate that our method achieves good restoration for contrast and color fidelity, resulting in a large improvement in image visibility.","Pixel,
Atmospheric modeling,
Image color analysis,
Image restoration,
Image edge detection,
Scattering,
Estimation"
Deriving Concept-Based User Profiles from Search Engine Logs,"User profiling is a fundamental component of any personalization applications. Most existing user profiling strategies are based on objects that users are interested in (i.e., positive preferences), but not the objects that users dislike (i.e., negative preferences). In this paper, we focus on search engine personalization and develop several concept-based user profiling methods that are based on both positive and negative preferences. We evaluate the proposed methods against our previously proposed personalized query clustering method. Experimental results show that profiles which capture and utilize both of the user's positive and negative preferences perform the best. An important result from the experiments is that profiles with negative preferences can increase the separation between similar and dissimilar queries. The separation provides a clear threshold for an agglomerative clustering algorithm to terminate and improve the overall quality of the resulting query clusters.",
Systematic Microwave Network Analysis for Multilayer Printed Circuit Boards With Vias and Decoupling Capacitors,"An efficient microwave network method is proposed for signal and power integrity analysis of a multilayer printed circuit board with multiple vias and decoupling capacitors. The multilayer parallel plate structure is described as a cascaded microwave network. The admittance matrix of a single plate pair with ports defined in via holes both on top and bottom plates is obtained through the intrinsic via circuit model and impedance matrix between two plates. A recursive algorithm is provided to obtain the combined admittance matrix of two layers of plate pair coupled through via holes on a common plate. Decoupling capacitors are naturally treated as impedance loads to the cascaded admittance network. Numerical simulations and measurements have been used to validate the method and good agreements have been observed. While the method is as accurate as full-wave numerical solvers, it achieves much higher efficiencies both in CPU time and memory requirements.","Integrated circuit modeling,
Transmission line matrix methods,
Admittance,
Nonhomogeneous media,
Capacitors,
Impedance,
Microwave circuits"
Convergence and Objective Functions of Some Fault/Noise-Injection-Based Online Learning Algorithms for RBF Networks,"In the last two decades, many online fault/noise injection algorithms have been developed to attain a fault tolerant neural network. However, not much theoretical works related to their convergence and objective functions have been reported. This paper studies six common fault/noise-injection-based online learning algorithms for radial basis function (RBF) networks, namely 1) injecting additive input noise, 2) injecting additive/multiplicative weight noise, 3) injecting multiplicative node noise, 4) injecting multiweight fault (random disconnection of weights), 5) injecting multinode fault during training, and 6) weight decay with injecting multinode fault. Based on the Gladyshev theorem, we show that the convergence of these six online algorithms is almost sure. Moreover, their true objective functions being minimized are derived. For injecting additive input noise during training, the objective function is identical to that of the Tikhonov regularizer approach. For injecting additive/multiplicative weight noise during training, the objective function is the simple mean square training error. Thus, injecting additive/multiplicative weight noise during training cannot improve the fault tolerance of an RBF network. Similar to injective additive input noise, the objective functions of other fault/noise-injection-based online algorithms contain a mean square error term and a specialized regularization term.","Convergence,
Radial basis function networks,
Additive noise,
Circuit faults,
Fault tolerance,
Neural networks,
Field programmable gate arrays,
Recurrent neural networks,
Mean square error methods,
Local government"
Max-matching diversity in OFDMA systems,"This paper considers the problem of optimal subcarrier allocation in OFDMA systems to achieve the minimum outage probability while guaranteeing fairness. The optimal subcarrier allocation algorithm and the maximum frequency diversity gain are both analyzed through the maximum matching method based on the random bipartite graph theory. Accordingly, a surprising result is found, which shows that the maximum frequency diversity gain in subcarrier-sharing OFDMA systems is the same as that in point-to-point OFDM systems that serve only one user by using N subcarriers. It is then demonstrated that this maximum frequency diversity gain can be achieved by a proposed Random Vertex Rotation based Hopcroft-Karp (RVRHK) algorithm with the time complexity of O(N2.5), where N is the number of subcarriers. Because the theoretical analysis and the RVRHK algorithm are both based on the maximum matching method, the maximum frequency diversity in OFDMA systems is referred to as the max-matching diversity in this paper.","OFDM,
Frequency diversity,
Resource management,
Quality of service,
Algorithm design and analysis,
Bipartite graph,
Wireless communication,
Transceivers,
Laboratories,
Downlink"
Phone recognition using Restricted Boltzmann Machines,"For decades, Hidden Markov Models (HMMs) have been the state-of-the-art technique for acoustic modeling despite their unrealistic independence assumptions and the very limited representational capacity of their hidden states. Conditional Restricted Boltzmann Machines (CRBMs) have recently proved to be very effective for modeling motion capture sequences and this paper investigates the application of this more powerful type of generative model to acoustic modeling. On the standard TIMIT corpus, one type of CRBM outperforms HMMs and is comparable with the best other methods, achieving a phone error rate (PER) of 26.7% on the TIMIT core test set.","Hidden Markov models,
Automatic speech recognition,
Stochastic processes,
Smoothing methods,
Computer science,
Power generation,
Acoustic applications,
Error analysis,
Acoustic testing,
Bipartite graph"
Learning to grasp objects with multiple contact points,"We consider the problem of grasping novel objects and its application to cleaning a desk. A recent successful approach applies machine learning to learn one grasp point in an image and a point cloud. Although those methods are able to generalize to novel objects, they yield suboptimal results because they rely on motion planner for finger placements. In this paper, we extend their method to accommodate grasps with multiple contacts. This approach works well for many human-made objects because it models the way we grasp objects. To further improve the grasping, we also use a method that learns the ranking between candidates. The experiments show that our method is highly effective compared to a state-of-the-art competitor.","Fingers,
Robots,
Grasping,
Cleaning,
Machine learning,
Motion detection,
Robotics and automation,
USA Councils,
Clouds,
Shape"
A Memetic Algorithm for Multi-Level Redundancy Allocation,"Redundancy allocation problems (RAPs) have attracted much attention for the past thirty years due to its wide applications in improving the reliability of various engineering systems. Because RAP is an NP-hard problem, and exact methods are only applicable to small instances, various heuristic and meta-heuristic methods have been proposed to solve it. In the literature, most studies on RAPs have been conducted for single-level systems. However, real-world engineering systems usually contain multiple levels. In this paper, the RAP on multi-level systems is investigated. A novel memetic algorithm (MA) is proposed to solve this problem. Two genetic operators, namely breadth-first crossover and breadth-first mutation, and a local search method are designed for the MA. Comprehensive experimental studies have shown that the proposed MA outperformed the state-of-the-art approach significantly on two representative examples.","Redundancy,
Costs,
Computer science,
Reliability engineering,
Systems engineering and theory,
Genetic algorithms,
Computer applications,
Application software,
Laboratories,
NP-hard problem"
Transforming relational database into HBase: A case study,"With the development of distributed system and cloud computing, more and more applications might be migrated to the cloud to exploit its computing power and scalability, where the first task is data migration. In this paper, we propose a novel approach that transforms a relational database into HBase, which is an open-source distributed database similar to BigTable. Our method is comprised of two phases. In the first phase, relational schema is transformed into HBase schema based on the data model of HBase. We present three guidelines in this phase, which could be further utilized to develop an HBase application. In the second phase, relationships between two schémas are expressed as a set of nested schema mappings, which would be employed to create a set of queries or programs that transform the source relational data into the target representation automatically.",
Robust Trust-Region Space-Mapping Algorithms for Microwave Design Optimization,"Convergence is a well-known issue for standard space-mapping optimization algorithms. It is heavily dependent on the choice of coarse model, as well as the space-mapping transformations employed in the optimization process. One possible convergence safeguard is the trust region approach where a surrogate model is optimized in a restricted neighborhood of the current iteration point. In this paper, we demonstrate that although formal conditions for applying trust regions are not strictly satisfied for space-mapping surrogate models, the approach improves the overall performance of the space-mapping optimization process. Further improvement can be realized when approximate fine model Jacobian information is exploited in the construction of the space-mapping surrogate. A comprehensive numerical comparison between standard and trust-region-enhanced space mapping is provided using several examples of microwave design problems.","Robustness,
Design optimization,
Convergence,
Space technology,
Computational modeling,
Computer simulation,
Laboratories,
Algorithm design and analysis,
Jacobian matrices,
Design automation"
A three-step methodology to improve domestic energy efficiency,"Increasing energy prices and the greenhouse effect lead to more awareness of energy efficiency of electricity supply. During the last years, a lot of technologies have been developed to improve this efficiency. Next to large scale technologies such as windturbine parks, domestic technologies are developed. These domestic technologies can be divided in 1) Distributed Generation (DG), 2) Energy Storage and 3) Demand Side Load Management. Control algorithms optimizing a combination of these techniques can raise the energy reduction potential of the individual techniques. In this paper an overview of current research is given and a general concept is deducted. Based on this concept, a three-step optimization methodology is proposed using 1) offline local prediction, 2) offline global planning and 3) online local scheduling. The paper ends with results of simulations and field tests showing that the methodology is promising.",
A Categorisation of Cloud Computing Business Models,"This paper reviews current cloud computing business models and presents proposals on how organisations can achieve sustainability by adopting appropriate models. We classify cloud computing business models into eight types: (1) Service Provider and Service Orientation; (2) Support and Services Contracts; (3) In- House Private Clouds; (4) All-In-One Enterprise Cloud; (5) One-Stop Resources and Services; (6) Government funding; (7) Venture Capitals; and (8) Entertainment and Social Networking. Using the Jericho Forum’s ‘Cloud Cube Model’ (CCM), the paper presents a summary of the eight business models. We discuss how the CCM fits into each business model, and then based on this discuss each business model’s strengths and weaknesses. We hope adopting an appropriate cloud computing business model will help organisations investing in this technology to stand firm in the economic downturn.","Cloud computing,
Contracts,
Government,
Venture capital,
Social network services,
Quality of service,
Investments,
Grid computing,
Computer science,
Proposals"
An exploratory study of co-located collaborative visual analytics around a tabletop display,"Co-located collaboration can be extremely valuable during complex visual analytics tasks. This paper presents an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cam-biera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams' collaboration influenced how well they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive novel design implications for future co-located collaborative tabletop problem solving systems.","Collaboration,
Visual analytics,
Data visualization,
Problem-solving,
Image color analysis,
Context,
Video coding"
Energy- and endurance-aware design of phase change memory caches,"Phase change memory (PCM) is one of the most promising technology among emerging non-volatile random access memory technologies. Implementing a cache memory using PCM provides many benefits such as high density, non-volatility, low leakage power, and high immunity to soft error. However, its disadvantages such as high write latency, high write energy, and limited write endurance prevent it from being used as a drop-in replacement of an SRAM cache. In this paper, we study a set of techniques to design an energy- and endurance-aware PCM cache. We also modeled the timing, energy, endurance, and area of PCM caches and integrated them into a PCM cache simulator to evaluate the techniques. Experiments show that our PCM cache design can achieve 8% of energy saving and 3.8 years of lifetime compared with a baseline PCM cache having less than a hour of lifetime.",
On the scaling of polar codes: I. The behavior of polarized channels,"We consider the asymptotic behavior of the polarization process for polar codes when the blocklength tends to infinity. In particular, we study the asymptotics of the cumulative distribution ℙ(Zn ≤ z), where Zn = Z(Wn) is the Bhat-tacharyya process, and its dependence on the rate of transmission R. We show that for a BMS channel W, for R < I(W) we have limn→8 ℙ equations R and for R < 1 − I(W) we have n→8 ℙ equations R, where Q(x) is the probability that a standard normal random variable exceeds x. As a result, if we denote by ℙSCe (n,R) the probability of error using polar codes of block-length N = 2n and rate R < I(W) under successive cancellation decoding, then log(−log(ℙSCe (n,R))) scales as equations. We also prove that the same result holds for the block error probability using the MAP decoder, i.e., for log(−log(ℙMAPe (n,R))).",
Context-Aware Emotion-Based Model for Group Decision Making,This context-aware emotion-based model can help design intelligent agents for group decision making processes. Experiments show that agents with emotional awareness reach agreement more quickly than those without it.,"Context modeling,
Decision making,
Mood,
Intelligent agent,
Intelligent systems,
Context awareness,
Artificial intelligence,
Computer science,
Software systems,
Counting circuits"
Dependent Randomized Rounding via Exchange Properties of Combinatorial Structures,"We consider the problem of randomly rounding a fractional solution
x
in an integer polytope
P⊆[0,1
]
n
to a vertex
X
of
P
, so that
Undefined control sequence \E
. Our goal is to achieve {\em concentration properties} for linear and sub modular functions of the rounded solution. Such dependent rounding techniques, with concentration bounds for linear functions, have been developed in the past for two polytopes: the assignment polytope (that is, bipartite matchings and
b
-matchings)~\cite{S01, GKPS06, KMPS09}, and more recently for the spanning tree polytope~\cite{AGMGS10}. These schemes have led to a number of new algorithmic results. In this paper we describe a new {\em swap rounding} technique which can be applied in a variety of settings including {\em matroids} and {\em matroid intersection}, while providing Chernoff-type concentration bounds for linear and sub modular functions of the rounded solution. In addition to existing techniques based on negative correlation, we use a martingale argument to obtain an exponential tail estimate for monotone sub modular functions. The rounding scheme explicitly exploits {\em exchange properties} of the underlying combinatorial structures, and highlights these properties as the basis for concentration bounds. Matroids and matroid intersection provide a unifying framework for several known applications~\cite{GKPS06, KMPS09, CCPV09, KST09, AGMGS10} as well as new ones, and their generality allows a richer set of constraints to be incorporated easily. We give some illustrative examples, with a more comprehensive discussion deferred to a later version of the paper.","Correlation,
Entropy,
Greedy algorithms,
Random processes,
USA Councils,
Approximation methods,
Electronic mail"
Robust place recognition for 3D range data based on point features,"The problem of place recognition appears in different mobile robot navigation problems including localization, SLAM, or change detection in dynamic environments. Whereas this problem has been studied intensively in the context of robot vision, relatively few approaches are available for three-dimensional range data. In this paper, we present a novel and robust method for place recognition based on range images. Our algorithm matches a given 3D scan against a database using point features and scores potential transformations by comparing significant points in the scans. A further advantage of our approach is that the features allow for a computation of the relative transformations between scans which is relevant for registration processes. Our approach has been implemented and tested on different 3D data sets obtained outdoors. In several experiments we demonstrate the advantages of our approach also in comparison to existing techniques.","Robustness,
Mobile robots,
Motion planning,
Simultaneous localization and mapping,
Robot vision systems,
Image recognition,
Change detection algorithms,
Image databases,
Spatial databases,
Testing"
Generic Centralized Multi Sensor Data Fusion Based on Probabilistic Sensor and Environment Models for Driver Assistance Systems,"Modern driver assistance and safety systems are using a combination of two or more sensors for reliable tracking and classification of relevant road users like vehicles, trucks, cars and others. In these systems, processing and fusion stages are optimized for the properties of the sensor combination and the application requirements. A change of either sensor hardware or application involves expensive redesign and evaluation cycles. In this contribution, we present a multi sensor fusion system which is implemented to be independent of both sensor hardware properties and application requirements. This supports changes in sensor combination or application requirements. Furthermore, the environmental model can be used by more than one application at the same time. A probabilistic approach for this generic fusion system is presented and discussed.","Target tracking,
Probability,
Sensor fusion,
Probabilistic logic,
Vehicle dynamics,
Springs,
Radar tracking"
SAR Image Despeckling Using Edge Detection and Feature Clustering in Bandelet Domain,"To effectively preserve the edges of a synthetic aperture radar (SAR) image when despeckling, an algorithm with edge detection and fuzzy clustering in the translation-invariant second-generation bandelet transform (TIBT) domain is proposed in this letter. A Canny operator is first utilized to detect and remove edges from the SAR image. Then, TIBT and fuzzy C-mean clustering are employed to decompose and despeckle the edge-removed image, respectively. Finally, the removed edges are added to the reconstructed image. The algorithm suggests each coefficient in high-frequency subbands as the clustering feature, proposes a calculation method of the best clustering number, and defines the signal and noise in the clustering results. Experimental results show that the visual quality and evaluation indexes outperform the other methods with no edge preservation. The proposed algorithm effectively realizes both despeckling and edge preservation and reaches the state-of-the-art performance.",
Flexible Cache Consistency Maintenance over Wireless Ad Hoc Networks,"One of the major applications of wireless ad hoc networks is to extend the Internet coverage and support pervasive and efficient data dissemination and sharing. To reduce data access cost and delay, caching has been widely used as an important technique. The efficiency of data access in caching systems largely depends on the cost for maintaining cache consistency, which can be high in wireless ad hoc networks due to network dynamism. Therefore, to make better trade-off between cache consistency and the cost incurred, it would be highly desirable to provide users the flexibility in specifying consistency requirements for their applications. In this paper, we propose a general consistency model called Probabilistic Delta Consistency (PDC), which integrates the flexibility granted by existing consistency models, covering them as special cases. We also propose the Flexible Combination of Push and Pull (FCPP) algorithm which satisfies user-specified consistency requirements under the PDC model. The analytical model of FCPP is used to derive the balance of minimizing the consistency maintenance cost and ensuring the specified consistency requirement. Extensive simulations are conducted to evaluate whether FCPP can satisfy arbitrarily specified consistency requirements, and whether FCPP works cost-effectively in dynamic wireless ad hoc networks. The evaluation results show that FCPP can adaptively tune itself to satisfy various user-specified consistency requirements. Moreover, it can save the traffic cost by up to 50 percent and reduce the query delay by up to 40 percent, compared with the widely used Pull with TTR algorithm.","Mobile ad hoc networks,
Costs,
IP networks,
Delay,
Ad hoc networks,
Batteries,
Analytical models,
Telecommunication traffic,
Traffic control,
Assembly"
F-TIMER: Fast Tensor Image Morphing for Elastic Registration,"We propose a novel diffusion tensor imaging (DTI) registration algorithm, called fast tensor image morphing for elastic registration (F-TIMER). F-TIMER leverages multiscale tensor regional distributions and local boundaries for hierarchically driving deformable matching of tensor image volumes. Registration is achieved by utilizing a set of automatically determined structural landmarks, via solving a soft correspondence problem. Based on the estimated correspondences, thin-plate splines are employed to generate a smooth, topology preserving, and dense transformation, and to avoid arbitrary mapping of nonlandmark voxels. To mitigate the problem of local minima, which is common in the estimation of high dimensional transformations, we employ a hierarchical strategy where a small subset of voxels with more distinctive attribute vectors are first deployed as landmarks to estimate a relatively robust low-degrees-of-freedom transformation. As the registration progresses, an increasing number of voxels are permitted to participate in refining the correspondence matching. A scheme as such allows less conservative progression of the correspondence matching towards the optimal solution, and hence results in a faster matching speed. Compared with its predecessor TIMER, which has been shown to outperform state-of-the-art algorithms, experimental results indicate that F-TIMER is capable of achieving comparable accuracy at only a fraction of the computation cost.","Tensile stress,
Diffusion tensor imaging,
Biomedical imaging,
Anisotropic magnetoresistance,
Magnetic resonance imaging,
Radiology,
Optimization methods,
Topology,
Robustness,
Computational efficiency"
Depth Evaluation of Shallow Surface Cracks in Metals Using Rectangular Waveguides at Millimeter-Wave Frequencies,"This paper presents a resonant technique, which is founded on previous extensive work on millimeter-wave surface crack detection and sizing, for the accurate depth evaluation of long and shallow surface damages (scratches or cracks), which are represented as rectangular slots, in metal plates. A crack in a metal plate may be considered a short-circuited rectangular waveguide, which presents certain resonant characteristics when its electrical depth coincides with a quarter of the operating wavelength. Furthermore, a shallow crack may be filled with a dielectric material to electromagnetically make it appear deeper and hence facilitate its depth evaluation. The resonant properties of a crack depend on the dielectric properties of the material filling the crack and the crack dimensions. It is shown that a slight amount of loss, which is associated with the dielectric material, causes a relatively significant and characteristic change in the reflection coefficient measured using a probing rectangular waveguide aperture. In particular, this change affects the magnitude of the reflection coefficient, which is an easier parameter to measure than the phase. This information, as a function of frequency, may then be used to determine the shallow crack depth. This paper presents the foundation of this technique at millimeter-wave frequencies, along with supporting electromagnetic simulations and experimental results.","Surface waves,
Surface cracks,
Rectangular waveguides,
Frequency,
Electromagnetic waveguides,
Millimeter wave technology,
Resonance,
Dielectric materials,
Dielectric loss measurement,
Dielectric measurements"
Fair energy-efficient resource allocation in wireless sensor networks over fading TDMA channels,"In this paper we consider the energy-efficient resource allocation that minimizes a general cost function of average user powers for small- or medium-scale wireless sensor networks, where the simple time-division multiple-access (TDMA) is adopted as the multiple access scheme. A class of so-called ß-fair cost functions is derived to balance the tradeoff between efficiency and fairness in energy-efficient designs. Based on such cost functions, optimal channel-adaptive resource allocation schemes are developed for both single-hop and multihop TDMA sensor networks. Relying on stochastic optimization tools, we further develop stochastic resource allocation schemes which are capable of dynamically learning the intended wireless channels and converging to the optimal benchmark without a priori knowledge of channel fading distribution function.",
Observations of UDP to TCP Ratio and Port Numbers,"Widely used protocols (UDP and TCP) are observed for variations of the UDP to TCP ratio and of port number distribution, both over time and between different networks. The purpose of the study was to understand the impact of application trends, especially the growth in media streaming, on traffic characteristics. The results showed substantial variability but little sign of a systematic trend over time, and only wide spreads of port number usage.",
"Discovering Unique, Low-Energy Pure Water Isomers: Memetic Exploration, Optimization, and Landscape Analysis","The discovery of low-energy stable and meta-stable molecular structures remains an important and unsolved problem in search and optimization. In this paper, we contribute two stochastic algorithms, the archiving molecular memetic algorithm (AMMA) and the archiving basin hopping algorithm (ABHA) for sampling low-energy isomers on the landscapes of pure water clusters (H2O)n. We applied our methods to two sophisticated empirical water cluster models, TTM2.1-F and OSS2, and generated archives of low-energy water isomers (H2O)n n=3-15. Our algorithms not only reproduced previously-found best minima, but also discovered new global minima candidates for sizes 9-15 on OSS2. Further numerical results show that AMMA and ABHA outperformed a baseline stochastic multistart local search algorithm in terms of convergence and isomer archival. Noting a performance differential between TTM2.1-F and OSS2, we analyzed both model landscapes to reveal that the global and local correlation properties of the empirical models differ significantly. In particular, the OSS2 landscape was less correlated and hence, more difficult to explore and optimize. Guided by our landscape analyses, we proposed and demonstrated the effectiveness of a hybrid local search algorithm, which significantly improved the sampling performance of AMMA on the larger OSS2 landscapes. Although applied to pure water clusters in this paper, AMMA and ABHA can be easily modified for subsequent studies in computational chemistry and biology. Moreover, the landscape analyses conducted in this paper can be replicated for other molecular systems to uncover landscape properties and provide insights to both physical chemists and evolutionary algorithmists.","Clustering algorithms,
Stochastic processes,
Sampling methods,
Performance analysis,
Algorithm design and analysis,
Convergence of numerical methods,
Biology computing,
Chemistry,
Computational biology,
Evolution (biology)"
A New One-Layer Neural Network for Linear and Quadratic Programming,"In this paper, we present a new neural network for solving linear and quadratic programming problems in real time by introducing some new vectors. The proposed neural network is stable in the sense of Lyapunov and can converge to an exact optimal solution of the original problem when the objective function is convex on the set defined by equality constraints. Compared with existing one-layer neural networks for quadratic programming problems, the proposed neural network has the least neurons and requires weak stability conditions. The validity and transient behavior of the proposed neural network are demonstrated by some simulation results.","Neural networks,
Quadratic programming,
Artificial neural networks,
Stability,
Linear programming,
Mathematics,
Design optimization,
Computer networks,
Vectors,
Neurons"
Sliding-window motion artifact rejection for Functional Near-Infrared Spectroscopy,"Functional Near-Infrared Spectroscopy (fNIR) is an optical brain monitoring technology that tracks changes in hemodynamic responses within the cortex. fNIR uses specific wavelengths of light, introduced at the scalp, to enable the noninvasive measurement of changes in the relative ratios of deoxygenated hemoglobin (deoxy-Hb) and oxygenated hemoglobin (oxy-Hb) during brain activity. This technology allows the design of portable, safe, affordable, noninvasive, and minimally intrusive monitoring systems that can be used to measure brain activity in natural environments, ambulatory and field conditions. However, for such applications fNIR signals can get prone to noise due to motion of the head. Improving signal quality and reducing noise, can be especially challenging for real time applications. Here, we study motion artifact related noise especially due to poor and changing sensor coupling. We have developed a simple and iterative method that can be used to automate the preprocessing of data to identify segments with such noise for exclusion and this method is also suitable for real time applications.","Spectroscopy,
Signal to noise ratio,
Wavelength measurement,
Light sources,
Adaptive optics,
Detectors"
Haptic terrain classification for legged robots,"In this paper, we are presenting a method to estimate terrain properties (such as small-scale geometry or surface friction) to improve the assessment of stability and the guiding of foot placement of legged robots in rough terrain. Haptic feedback, expressed through joint motor currents and ground contact force measurements that arises when prescribing a predefined motion was collected for a variety of ground samples (four different shapes and four different surface properties). Features were extracted from this data and used for training and classification by a multiclass AdaBoost machine learning algorithm. In a single leg testbed, the algorithm could correctly classify about 94% of the terrain shapes, and about 73% of the surface samples.",
A Dual Perspective on Separable Semidefinite Programming With Applications to Optimal Downlink Beamforming,"This paper considers the downlink beamforming optimization problem that minimizes the total transmission power subject to global shaping constraints and individual shaping constraints, in addition to the constraints of quality of service (QoS) measured by signal-to-interference-plus-noise ratio (SINR). This beamforming problem is a separable homogeneous quadratically constrained quadratic program (QCQP), which is difficult to solve in general. Herein we propose efficient algorithms for the problem consisting of two main steps: 1) solving the semidefinite programming (SDP) relaxed problem, and 2) formulating a linear program (LP) and solving the LP (with closed-form solution) to find a rank-one optimal solution of the SDP relaxation. Accordingly, the corresponding optimal beamforming problem (OBP) is proven to be “hidden” convex, namely, strong duality holds true under certain mild conditions. In contrast to the existing algorithms based on either the rank reduction steps (the purification process) or the Perron-Frobenius theorem, the proposed algorithms are based on the linear program strong duality theorem.",
Entwined Planar Spirals for Artificial Surfaces,Entwining planar quadrifilar spirals arranged in doubly periodic arrays enables a strong subwavelength response of the unit cell smaller than 1/40 of wavelength. It is shown that interleaving counterwound spiral arms extended into adjacent unit cells dramatically increases the equivalent capacitance while reducing the inductance. The dielectric substrate enhances this effect of the unit cell miniaturization with concurrent bandwidth expansion. The proposed topology of compact planar spiral array exhibits excellent angular and polarization stability and circular polarization selectivity in a broad frequency band. Negligible variations of the resonance frequency are demonstrated for both TE and TM polarized waves at incidence angles up to 45 with a common fractional bandwidth over 40% at the level of -10 dB.,"Spirals,
Resonant frequency,
Conductors,
Frequency selective surfaces,
Capacitance,
Inductance,
Bandwidth"
Investigation of LOCOS- and Polysilicon-Bound Diodes for Robust Electrostatic Discharge (ESD) Applications,"In this paper, the current-carrying and voltage-clamping capabilities of LOCal Oxidation of Silicon (LOCOS)- and polysilicon-bound diodes are first investigated. Comparison of these capabilities leads to the conclusion that the polysilicon-bound diode is more suited for electrostatic discharge (ESD) protection applications. Then, to achieve an optimal diode structure for ESD applications, the effects of the cathode/anode length, cathode/anode width, polysilicon width, finger number, terminal connection, and metal layout on the polysilicon-bound diode's ESD robustness are studied and discussed in detail.",
A privacy-compliant fingerprint recognition system based on homomorphic encryption and Fingercode templates,"The privacy protection of the biometric data is an important research topic, especially in the case of distributed biometric systems. In this scenario, it is very important to guarantee that biometric data cannot be steeled by anyone, and that the biometric clients are unable to gather any information different from the single user verification/identification. In a biométrie system with high level of privacy compliance, also the server that processes the biométrie matching should not learn anything on the database and it should be impossible for the server to exploit the resulting matching values in order to extract any knowledge about the user presence or behavior. Within this conceptual framework, in this paper we propose a novel complete demonstrator based on a distributed biométrie system that is capable to protect the privacy of the individuals by exploiting cryptosystems. The implemented system computes the matching task in the encrypted domain by exploiting homomorphic encryption and using Fingercode templates. The paper describes the design methodology of the demonstrator and the obtained results. The demonstrator has been fully implemented and tested in real applicative conditions. Experimental results show that this method is feasible in the cases where the privacy of the data is more important than the accuracy of the system and the obtained computational time is satisfactory.","Servers,
Accuracy,
Encryption,
Bandwidth,
Biometrics,
Data privacy"
Supporting top-K keyword search in XML databases,"Keyword search is considered to be an effective information discovery method for both structured and semi-structured data. In XML keyword search, query semantics is based on the concept of Lowest Common Ancestor (LCA). However, naive LCA-based semantics leads to exponential computation and result size. In the literature, LCA-based semantic variants (e.g., ELCA and SLCA) were proposed, which define a subset of all the LCAs as the results. While most existing work focuses on algorithmic efficiency, top-K processing for XML keyword search is an important issue that has received very little attention. Existing algorithms focusing on efficiency are designed to optimize the semantic pruning and are incapable of supporting top-K processing. On the other hand, straightforward applications of top-K techniques from other areas (e.g., relational databases) generate LCAs that may not be the results and unnecessarily expand efforts in the semantic pruning. In this paper, we propose a series of join-based algorithms that combine the semantic pruning and the top-K processing to support top-K keyword search in XML databases. The algorithms essentially reduce the keyword query evaluation to relational joins, and incorporate the idea of the top-K join from relational databases. Extensive experimental evaluations show the performance advantages of our algorithms.","Keyword search,
XML,
Relational databases,
Algorithm design and analysis,
Design optimization,
Computer science,
Data engineering,
Query processing,
Database languages,
Information retrieval"
Carrier Frequency Offset Estimation for OFDM Systems Over Mobile Radio Channels,"In this paper, a new technique is proposed for blind estimation of carrier frequency offset (CFO) in wireless orthogonal frequency-division multiplexing (OFDM) systems with constant-modulus constellations. The proposed scheme is based on the assumption that the channel slowly changes in the time domain with respect to the OFDM symbol duration. As a consequence, the channel effect on a given subcarrier in two consecutive OFDM symbols is approximately the same. Based on this assumption, a cost function is derived such that the power difference between all subcarriers in two consecutive OFDM symbols is minimized. Using Monte Carlo simulation, we demonstrate that the proposed scheme has superior performance in both static and time-varying frequency-selective fading channels. The proposed system can rapidly and accurately estimate the CFO using only three trial values, given that the CFO is less than half of the subcarriers' frequency spacing.","Frequency estimation,
Land mobile radio,
Frequency division multiplexing,
Frequency synchronization,
Timing,
Discrete Fourier transforms,
Doppler shift,
Digital modulation,
OFDM modulation,
Time domain analysis"
An Adaptive Multiobjective Approach to Evolving ART Architectures,"In this paper, we present the evolution of adaptive resonance theory (ART) neural network architectures (classifiers) using a multiobjective optimization approach. In particular, we propose the use of a multiobjective evolutionary approach to simultaneously evolve the weights and the topology of three well-known ART architectures; fuzzy ARTMAP (FAM), ellipsoidal ARTMAP (EAM), and Gaussian ARTMAP (GAM). We refer to the resulting architectures as MO-GFAM, MO-GEAM, and MO-GGAM, and collectively as MO-GART. The major advantage of MO-GART is that it produces a number of solutions for the classification problem at hand that have different levels of merit [accuracy on unseen data (generalization) and size (number of categories created)]. MO-GART is shown to be more elegant (does not require user intervention to define the network parameters), more effective (of better accuracy and smaller size), and more efficient (faster to produce the solution networks) than other ART neural network architectures that have appeared in the literature. Furthermore, MO-GART is shown to be competitive with other popular classifiers, such as classification and regression tree (CART) and support vector machines (SVMs).","Subspace constraints,
Neural networks,
Fuzzy logic,
Resonance,
Network topology,
Classification tree analysis,
Genetic algorithms,
Computer architecture,
Regression tree analysis,
Support vector machines"
Heart Rate and Accelerometer Data Fusion for Activity Assessment of Rescuers During Emergency Interventions,"The current state of the art in wearable electronics is the integration of very small devices into textile fabrics, the so-called ¿smart garment.¿ The ProeTEX project is one of many initiatives dedicated to the development of smart garments specifically designed for people who risk their lives in the line of duty such as fire fighters and Civil Protection rescuers. These garments have integrated multipurpose sensors that monitor their activities while in action. To this aim, we have developed an algorithm that combines both features extracted from the signal of a triaxial accelerometer and one ECG lead. Microprocessors integrated in the garments detect the signal magnitude area of inertial acceleration, step frequency, trunk inclination, heart rate (HR), and HR trend in real time. Given these inputs, a classifier assigns these signals to nine classes differentiating between certain physical activities (walking, running, moving on site), intensities (intense, mild, or at rest) and postures (lying down, standing up). Specific classes will be identified as dangerous to the rescuer during operation, such as, ¿subject motionless lying down¿ or ¿subject resting with abnormal HR.¿ Laboratory tests were carried out on seven healthy adult subjects with the collection of over 4.5 h of data. The results were very positive, achieving an overall classification accuracy of 88.8%.","Heart rate,
Accelerometers,
Clothing,
Biomedical monitoring,
Textiles,
Fabrics,
Fires,
Protection,
Intelligent sensors,
Feature extraction"
Stochastic Resource Allocation Over Fading Multiple Access and Broadcast Channels,"We consider the optimal rate and power allocation that maximizes a general utility function of average user rates in a fading multiple-access or broadcast channel. By exploiting the greedy structure of the capacity-achieving resource allocation for both multiple-access and broadcast channels, it is established that a utility-maximizing allocation policy can be obtained through dual-based gradient descent iterations with fast convergence and low complexity per iteration. Relying on stochastic averaging tools, we further develop a class of stochastic gradient iterations which are capable of asymptotically converging to the optimal benchmark with guarantees on the minimum average user rates, even when the fading channel distribution is unknown a priori.","Stochastic processes,
Resource management,
Fading,
Broadcasting,
Information analysis,
Statistics,
Convergence,
Land mobile radio cellular systems,
Downlink,
Channel capacity"
Evolution of Internet Address Space Deaggregation: Myths and Reality,"Internet routing table size growth and BGP update churn are two prominent Internet scaling issues. There is widespread belief in a high and fast growing number of ASs that deaggregate prefixes, e.g., due to multi-homing and for the purpose of traffic engineering. Moreover, researchers often blame specific classes of ASs for generating a disproportionate amount of BGP updates. Our primary objective is to challenge such widespread assumptions (“myths”) and not solely to confirm previous findings. Surprisingly, we find severe discrepancies between existing myths and reality. According to our results, there is no trend towards more aggressive prefix deaggregation or traffic engineering over time. With respect to update dynamics, we observe that deaggregated prefixes generally do not generate a disproportionate number of BGP updates, with respect to their share of the BGP routing table. On the other side, we observe much more widespread traffic engineering in the form of AS path prepending and scoped advertisements compared to previous studies. Overall, our work gives a far more positive picture compared to the alarming discourses typically heard: The impact of “bad guys” on routing table size growth and BGP churn has not changed for the worse in recent years. Rather, it increases at the same pace as the Internet itself.","Routing,
Internet,
Resource management,
IP networks,
Logic gates,
Electric breakdown"
Fuzzy Forecasting Based on Fuzzy-Trend Logical Relationship Groups,"In this paper, we present a new method to predict the Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX) based on fuzzy-trend logical relationship groups (FTLRGs). The proposed method divides fuzzy logical relationships into FTLRGs based on the trend of adjacent fuzzy sets appearing in the antecedents of fuzzy logical relationships. First, we apply an automatic clustering algorithm to cluster the historical data into intervals of different lengths. Then, we define fuzzy sets based on these intervals of different lengths. Then, the historical data are fuzzified into fuzzy sets to derive fuzzy logical relationships. Then, we divide the fuzzy logical relationships into FTLRGs for forecasting the TAIEX. Moreover, we also apply the proposed method to forecast the enrollments and the inventory demand, respectively. The experimental results show that the proposed method gets higher average forecasting accuracy rates than the existing methods.","Fuzzy logic,
Demand forecasting,
Fuzzy sets,
Temperature,
Predictive models,
Stock markets,
Clustering algorithms,
Genetic algorithms,
Councils,
Computer science"
Polyp detection in Wireless Capsule Endoscopy videos based on image segmentation and geometric feature,Wireless Capsule Endoscopy (WCE) is a relatively new technology (FDA approved in 2002) allowing doctors to view most of the small intestine. One of the most important goals of WCE is the early detection of colorectal polyps. In this paper an unsupervised method for the detection of polyps in WCE videos is presented. Our method involves watershed segmentation with a novel initial marker selection method based on Gabor texture features and K-means clustering. Geometric information from the resulting segments is extracted to identify polyp candidates. Initial experiments indicate that the proposed method can detect polyps with 100% sensitivity and over 81% specificity.,"Endoscopes,
Videos,
Image segmentation"
Professional Skills in the Engineering Curriculum,"Faculty from the Department of Electrical and Computer Engineering and the College of Education at the University of Missouri (MU), Columbia, developed a novel course for engineering graduate students emphasizing pedagogy and professional skills. The two-semester course sequence, titled “Preparing Engineering Faculty and Professionals,” includes readings from books that cover several different areas: How People Learn, with focus on the latest findings from cognitive science and their applicability to teaching; The 7 Habits of Highly Effective People for discussion of other professional skills; and The World is Flat for discussion of global trends and its effects on professionals. Other components of the course include lectures by guest speakers on topics ranging from how universities work and how to run successful research centers to leadership traits for engineers. A pilot survey of students at the end of the two-course sequence revealed that students had acquired little knowledge about pedagogy and professional skills from other courses in their undergraduate and graduate engineering curriculum; this course addresses such deficits by raising awareness and knowledge of these skills.",
A Stable Online Algorithm for Energy-Efficient Multiuser Scheduling,"In this paper, we consider the problem of energy-efficient uplink scheduling with delay constraint for a multiuser wireless system. We address this problem within the framework of constrained Markov decision processes (CMDPs) wherein one seeks to minimize one cost (average power) subject to a hard constraint on another (average delay). We do not assume the arrival and channel statistics to be known. To handle state-space explosion and informational constraints, we split the problem into individual CMDPs for the users, coupled through their Lagrange multipliers; and a user selection problem at the base station. To address the issue of unknown channel and arrival statistics, we propose a reinforcement learning algorithm. The users use this learning algorithm to determine the rate at which they wish to transmit in a slot and communicate this to the base station. The base station then schedules the user with the highest rate in a slot. We analyze convergence, stability, and optimality properties of the algorithm. We also demonstrate the efficacy of the algorithm through simulations within IEEE 802.16 system.","Scheduling algorithm,
Energy efficiency,
Base stations,
Delay,
Statistics,
Costs,
Explosions,
Lagrangian functions,
Learning,
Algorithm design and analysis"
Providing OS Support for Wireless Sensor Networks: Challenges and Approaches,"Recently, wireless sensor networks (WSNs) attract a great deal of research attention, and are envisioned to support a variety of applications, including military surveillance, habitat monitoring, and infrastructure protection, etc. Operating system (OS) support for WSNs plays a central role in building scalable distributed applications that are efficient and reliable. Over the years, we have seen a variety of OSes emerging in the sensornet community to facilitate developing WSN applications. Aside from the basic system implementations, there is also a large body of work devoted to improving OS capabilities in different dimensions. In this paper, we provide a comprehensive review of existing work in sensornet OS design. We first examine the challenges in the OS design space. We then introduce the major components of a sensornet OS. Next, we provide an overview of existing work, present a taxonomy of state-of-the-art OSes, and discuss various approaches to address the design challenges. Finally we discuss evaluations of a sensornet OS and present some recommendations from the perspectives of OS developers and OS users. We have also identified several open problems that need further investigation to make the OS provide stronger support for WSNs.","Wireless sensor networks,
Operating systems,
Hardware,
Application software,
Surveillance,
Monitoring,
Protection,
Taxonomy,
Computer science,
Resource management"
Robust Adaptive 3-D Segmentation of Vessel Laminae From Fluorescence Confocal Microscope Images and Parallel GPU Implementation,"This paper presents robust 3-D algorithms to segment vasculature that is imaged by labeling laminae, rather than the lumenal volume. The signal is weak, sparse, noisy, nonuniform, low-contrast, and exhibits gaps and spectral artifacts, so adaptive thresholding and Hessian filtering based methods are not effective. The structure deviates from a tubular geometry, so tracing algorithms are not effective. We propose a four step approach. The first step detects candidate voxels using a robust hypothesis test based on a model that assumes Poisson noise and locally planar geometry. The second step performs an adaptive region growth to extract weakly labeled and fine vessels while rejecting spectral artifacts. To enable interactive visualization and estimation of features such as statistical confidence, local curvature, local thickness, and local normal, we perform the third step. In the third step, we construct an accurate mesh representation using marching tetrahedra, volume-preserving smoothing, and adaptive decimation algorithms. To enable topological analysis and efficient validation, we describe a method to estimate vessel centerlines using a ray casting and vote accumulation algorithm which forms the final step of our algorithm. Our algorithm lends itself to parallel processing, and yielded an 8× speedup on a graphics processor (GPU). On synthetic data, our meshes had average error per face (EPF) values of (0.1-1.6) voxels per mesh face for peak signal-to-noise ratios from (110-28 dB). Separately, the error from decimating the mesh to less than 1% of its original size, the EPF was less than 1 voxel/face. When validated on real datasets, the average recall and precision values were found to be 94.66% and 94.84%, respectively.","Image segmentation,
Fluorescence,
Microscopy,
Geometry,
Labeling,
Adaptive filters,
Filtering,
Noise robustness,
Testing,
Solid modeling"
Labelled data collection for anomaly detection in wireless sensor networks,"Security of wireless sensor networks (WSN) is an important research area in computer and communications sciences. Anomaly detection is a key challenge in ensuring the security of WSN. Several anomaly detection algorithms have been proposed and validated recently using labeled datasets that are not publicly available. Our group proposed an ellipsoid-based anomaly detection algorithm but demonstrated its performance using synthetic datasets and real Intel Berkeley Research Laboratory and Grand St. Bernard datasets which are not labeled with anomalies. This approach requires manual assignment of the anomalies' positions based on visual estimates for performance evaluation. In this paper, we have implemented a single-hop and multi-hop sensor-data collection network. In both scenarios we generated real labeled data for anomaly detection and identified different types of anomalies. These labeled sensor data and types of anomalies are useful for research, such as machine learning, and this information will be disseminated to the research community.","Wireless sensor networks,
Humidity,
Temperature sensors,
Detection algorithms,
Temperature measurement,
Base stations,
Security"
TCP Throughput Adaptation in WiMax Networks Using Replicator Dynamics,"The high-frequency segment (10-66 GHz) of the IEEE 802.16 standard seems promising for the implementation of wireless backhaul networks carrying large volumes of Internet traffic. In contrast to wireline backbone networks, where channel errors seldom occur, the TCP protocol in IEEE 802.16 Worldwide Interoperability for Microwave Access networks is conditioned exclusively by wireless channel impairments rather than by congestion. This renders a cross-layer design approach between the transport and physical layers more appropriate during fading periods. In this paper, an adaptive coding and modulation (ACM) scheme for TCP throughput maximization is presented. In the current approach, Internet traffic is modulated and coded employing an adaptive scheme that is mathematically equivalent to the replicator dynamics model. The stability of the proposed ACM scheme is proven, and the dependence of the speed of convergence on various physical-layer parameters is investigated. It is also shown that convergence to the strategy that maximizes TCP throughput may be further accelerated by increasing the amount of information from the physical layer.","Throughput,
WiMAX,
Telecommunication traffic,
Physical layer,
Modulation coding,
Convergence,
IP networks,
Spine,
Wireless application protocol,
Access protocols"
ProgressFace: An Algorithm to Improve Routing Efficiency of GPSR-Like Routing Protocols in Wireless Ad Hoc Networks,"In GPSR-like routing, such as GPSR, GFG, GOAFR+, and GPVFR, perimeter forwarding is used to recover from a greedy forwarding failure by routing the packet to a progress node along the face boundary. The problem of perimeter forwarding is that many hops may be taken if the packet is forwarded in the wrong direction. We propose an algorithm, termed ProgressFace, that uses an additional traversal step to decide the direction of perimeter forwarding. A concave node sends a short packet to traverse the face boundary to identify the progress set, which consists of at most four nodes, such that, for any destination, at least one progress node is in the progress set or the neighbor set. Additionally, the hop distances of the nodes in the progress set along both directions are evaluated so that the shorter one is identified. The following packets encountering the concave node each are then sent along the corresponding direction toward the progress node in the progress set or the neighbor set. Simulations show that GPSR, GFG, GOAFR+, and GPVFR each conduct a shorter routing path, if augmented with the ProgressFace algorithm.",
Low-power sub-threshold design of secure physical unclonable functions,"The unique and unpredictable nature of silicon enables the use of physical unclonable functions (PUFs) for chip identification and authentication. Since the function of PUFs depends on minute uncontrollable process variations, a low supply voltage can benefit PUFs by providing high sensitivity to variations and low power consumption as well. Motivated by this, we explore the feasibility of sub-threshold arbiter PUFs in 45nm CMOS technology. By modeling process variations and interconnect imbalance effects at the post-layout design level, we optimize the PUF supply voltage for the minimum power-delay product and investigate the trade-offs on PUF uniqueness and reliability. Moreover, we demonstrate that such a design optimization does not compromise the security of PUFs regarding modeling attacks and side-channel analysis attacks. Our final 64-stage sub-threshold PUF design only needs 418 gates and consumes 0.047pJ energy per cycle, which is very promising for low-power wireless sensing and security applications.","Security,
Reliability,
Integrated circuit modeling,
Delay,
Logic gates,
Latches,
Analytical models"
The Smarter Grid,"In the US, tens of millions of ""smart meters,"" which are vulnerable to remote exploitation, viruses, worms, malicious upgrades, and all manner of other attacks, have been deployed. Attackers can and already have used these meters, on a small scale, to disable the power infrastructure and cause both long-term physical damage to it and harm to the public. These deployments and other related control mechanisms will be expanded in the coming years, as a necessary step toward better energy efficiency and to enable the next generation of electrical systems to integrate into the grid. The question is, how can we make this deployment safe and secure?","Smart grids,
Viruses (medical),
Control systems,
Energy efficiency"
Enhancing the low quality images using Unsupervised Colour Correction Method,"Underwater images are affected by reduced contrast and non-uniform colour cast due to the absorption and scattering of light in the aquatic environment. This affects the quality and reliability of image processing and therefore colour correction is a necessary pre-processing stage. In this paper, we propose an Unsupervised Colour Correction Method (UCM) for underwater image enhancement. UCM is based on colour balancing, contrast correction of RGB colour model and contrast correction of HSI colour model. Firstly, the colour cast is reduced by equalizing the colour values. Secondly, an enhancement to a contrast correction method is applied to increase the Red colour by stretching red histogram towards the maximum (i.e., right side), similarly the Blue colour is reduced by stretching the blue histogram towards the minimum (i.e., left side). Thirdly, the Saturation and Intensity components of the HSI colour model have been applied for contrast correction to increase the true colour using Saturation and to address the illumination problem through Intensity. We compare our results with three well known methods, namely Gray World, White Patch and Histogram Equalisation using Adobe Photoshop. The proposed method has produced better results than the existing methods.","Image color analysis,
Manganese"
Synchronization Between Adaptively Coupled Systems With Discrete and Distributed Time-Delays,"This paper investigates complete synchronization of unidirectionally and adaptively coupled systems with discrete and distributed time delays. Instead of the conventional hypothesis of a uniform Lipschitz condition on the system's vector fields, only a local Lipschitz condition is adopted. It is proved that the local complete synchronization can be achieved through a unidirectional and adaptive coupling, and that the global complete synchronization can be realized when the nonlinear degree of the vector fields is smaller than some derived critical value. The results are illustrated in some representative models with time delays. Also considered is complete synchronization with an exponential convergence rate on the adaptively coupled time-delayed systems with vector fields that are one-sided uniformly Lipschitz (systems of this type can admit time-varying discrete and distributed delays). All the results can be further generalized to various types of synchronization between bidirectionally coupled time-delayed systems or among delayed kinetic systems of a complex network.",
Designing topology-aware collective communication algorithms for large scale InfiniBand clusters: Case studies with Scatter and Gather,"Modern high performance computing systems are being increasingly deployed in a hierarchical fashion with multi-core computing platforms forming the base of the hierarchy. These systems are usually comprised of multiple racks, with each rack consisting of a finite number of chassis, and each chassis having multiple compute nodes or blades, based on multi-core architectures. The networks are also hierarchical with multiple levels of switches. Message exchange operations between processes that belong to different racks involve multiple hops across different switches and this directly affects the performance of collective operations. In this paper, we take on the challenges involved in detecting the topology of large scale InfiniBand clusters and leveraging this knowledge to design efficient topology-aware algorithms for collective operations. We also propose a communication model to analyze the communication costs involved in collective operations on large scale supercomputing systems. We have analyzed the performance characteristics of two collectives, MPI_Gather and MPI_Scatter, on such systems and we have proposed topology-aware algorithms for these operations. Our experimental results have shown that the proposed algorithms can improve the performance of these collective operations by almost 54% at the micro-benchmark level.","Algorithm design and analysis,
Clustering algorithms,
Large-scale systems,
Scattering,
High performance computing,
Switches,
Blades,
Computer architecture,
Communication switching,
Network topology"
Accurate mobile robot localization in indoor environments using bluetooth,"In this paper, we describe an accurate method for localization of a mobile robot using bluetooth. We introduce novel approaches for obtaining distance estimates and trilateration that overcome the hitherto known limitations of using bluetooth for localization. Our approach is reliable and has the potential of being scaled to multi-agent scenarios. The proposed approach was tested on a mobile robot, and we present the experimental results. The error obtained was 0.427 ± 0.229 m, which proves the accuracy of our method.","Mobile robots,
Indoor environments,
Bluetooth,
Particle filters,
Computer science,
Mobile communication,
Energy consumption,
Radiofrequency identification,
Radio control,
Robotics and automation"
Fighting Perebor: New and Improved Algorithms for Formula and QBF Satisfiability,"We investigate the possibility of finding satisfying assignments to Boolean formulae and testing validity of quantified Boolean formulae (QBF) asymptotically faster than a brute force search. Our first main result is a simple deterministic algorithm running in time
2
n−Ω(n)
for satisfiability of formulae of linear size in
n
, where
n
is the number of variables in the formula. This algorithm extends to exactly counting the number of satisfying assignments, within the same time bound. Our second main result is a deterministic algorithm running in time
2
n−Ω(n/log(n))
for solving QBFs in which the number of occurrences of any variable is bounded by a constant. For instances which are ``structured'', in a certain precise sense, the algorithm can be modified to run in time
2
n−Ω(n)
. To the best of our knowledge, no non-trivial algorithms were known for these problems before. As a byproduct of the technique used to establish our first main result, we show that every function computable by linear-size formulae can be represented by decision trees of size
2
n−Ω(n)
. As a consequence, we get strong super linear {\it average-case} formula size lower bounds for the Parity function.","Force,
Algorithm design and analysis,
Complexity theory,
Decision trees,
Approximation algorithms,
Polynomials,
Search problems"
Wireless Sensing Systems in Clinical Environments: Improving the Efficiency of the Patient Monitoring Process,"Multiple studies suggest that the level of patient care may decline in the future because of a larger aging population and medical staff shortages. Wireless sensing systems that automate some of the patient monitoring tasks can potentially improve the efficiency of patient workflows, but their efficacy in clinical settings is an open question. This article examines the potential of wireless sensor network (WSN) technologies to improve the efficiency of the patient-monitoring process in clinical environments. MEDiSN, a WSN designed to continuously monitor the vital signs of ambulatory patients, is designed. The usefulness of MEDiSN is validated with test bed experiments and results from a pilot study performed at the Emergency Department, Johns Hopkins Hospital. Promising results indicate that MEDiSN can tolerate high degrees of human mobility, is well received by patients and staff members, and performs well in real clinical environments.",
Factorization Method and Its Physical Justification in Frequency-Difference Electrical Impedance Tomography,"Time-difference electrical impedance tomography (tdEIT) requires two data sets measured at two different times. The difference between them is utilized to produce images of time-dependent changes in a complex conductivity distribution inside the human body. Frequency-difference EIT (fdEIT) was proposed to image frequency-dependent changes of a complex conductivity distribution. It has potential applications in tumor and stroke imaging since it can visualize an anomaly without requiring any time-reference data obtained in the absence of an anomaly. In this paper, we provide a rigorous analysis for the detectability of an anomaly based on a constructive and quantitative physical correlation between a measured fdEIT data set and an anomaly. From this, we propose a new noniterative frequency-difference anomaly detection method called the factorization method (FM) and elaborate its physical justification. To demonstrate its practical applicability, we performed fdEIT phantom imaging experiments using a multifrequency EIT system. Applying the FM to measured frequency-difference boundary voltage data sets, we could quantitatively evaluate indicator functions inside the imaging domain, of which values at each position reveal presence or absence of an anomaly. We found that the FM successfully localizes anomalies inside an imaging domain with a frequency-dependent complex conductivity distribution. We propose the new FM as an anomaly detection algorithm in fdEIT for potential applications in tumor and stroke imaging.","Frequency,
Tomography,
Conductivity,
Neoplasms,
Impedance measurement,
Electric variables measurement,
Humans,
Data visualization,
Imaging phantoms,
Voltage measurement"
State space pruning for power system reliability evaluation using genetic algorithms,Methods have previously been developed that improve the computational efficiency and convergence of Monte Carlo simulation (MCS) when computing the reliability indices of power systems. One of these techniques works by pruning the state space in such a manner that the MCS samples a state space that has a higher density of failure states than the original state space. This paper presents a new approach to limiting the state space sampled when calculating reliability indices by pruning the state space through the use of a genetic algorithm. This paper concludes that this technique is promising to improve the computational efficiency when calculating the loss of load probability (LOLP). This is tested using two power systems: the IEEE Reliability Test System (RTS79) and the Modified Reliability Test System (MRTS).,
"A Wideband, Dual-Polarized, Substrate-Integrated Cavity-Backed Slot Antenna","A new technique for designing wideband dual-polarized slot antennas is presented. The proposed structure is in the form of a differentially fed cross-slot antenna backed by a shallow substrate-integrated cavity with a depth of approximately λ0/10 . This technique takes advantage of a double-resonance observed in off-center microstrip-fed slot antennas to enhance its bandwidth to double that of typical cavity-backed cross-slot antennas of the same size. Experimental results demonstrate a bandwidth of 19%, average gain of 5.3 dBi, isolation better than 28 dB, and wideband polarization purity.","Broadband antennas,
Slot antennas,
Microstrip antennas,
Bandwidth,
Antennas and propagation,
Wideband,
Dielectric substrates,
Polarization,
Communication system security,
Antenna accessories"
C-VeT the UCLA campus vehicular testbed: Integration of VANET and Mesh networks,"Vehicular communications are becoming a reality under the push of increased transportation safety requirements and huge investments of several actors in the field like car manufacturers and Public Transport Authorities. As a consequence, the building blocks of the ”Vehicle Grid” (radios, Access Points, spectrum, standards, etc.) will soon be in place enabling a broad gamut of applications ranging from automatic safety systems, intelligent transport, entertainment, urban sensing and environmental protection/monitoring. In this paper, we take a visionary look at ”Vehicular Grid” and we argue that the cooperation of pure ad-hoc vehicle-to-vehicle communications and roadside infrastructure is fundamental to broaden the supported applications. The paper further describes the activities carried out at UCLA to deploy an open testbed integrating ad hoc vehicle-to-vehicle communications and a wireless mesh backhaul based on MobiMESH hardware/software solutions.","Testing,
Mesh networks,
Road transportation,
Vehicle safety,
Investments,
Intelligent manufacturing systems,
Intelligent structures,
Protection,
Computerized monitoring,
Application software"
Fuzzy Compositional Modeling,"Automated modeling refers to automatic (re-)formulation of alternative system models that embody the simplification, abstraction, and approximation of knowledge and data for a given task. This technique is highly desirable for effective problem solving in many application domains. Over the past two decades, compositional modeling (CM) has established itself as a leading approach in automated modeling. CM is a framework to construct system models by composing generic and reusable model fragments (MFs) selected from a knowledge base. However, the existing work mainly concerns the knowledge and data that are represented by crisp and precise information. Little work has been carried out to explore its potential to deal with uncertain environments. This paper presents an innovative framework of fuzzy compositional modeling (FCM) to develop such work. The proposed approach is capable of representing and reasoning with a wide range of inexact information. An innovative notion of fuzzy complex numbers (FCNs) is developed in an effort to enable synthesis of consistent scenario descriptions from imprecise MFs. This paper also introduces the modulus of FCNs to constrain the resulting scenario descriptions. The usefulness of this study is illustrated by means of an example to construct possible scenario descriptions from given evidence, which is in support of crime investigation.",
Noninteractive Pairwise Key Establishment for Sensor Networks,"As a security primitive, key establishment plays the most crucial role in the design of the security mechanisms. Unfortunately, the resource limitation of sensor nodes poses a great challenge for designing an efficient and effective key establishment scheme for wireless sensor networks (WSNs). In spite of the fact that many elegant and clever solutions have been proposed, no practical key establishment scheme has emerged. In this paper, a ConstrAined Random Perturbation-based pairwise keY establishment (CARPY) scheme and its variant, a CARPY+ scheme, for WSNs, are presented. Compared to all existing schemes which satisfy only some requirements in so-called sensor-key criteria, including (1) resilience to the adversary's intervention, (2) directed and guaranteed key establishment, (3) resilience to network configurations, (4) efficiency, and (5) resilience to dynamic node deployment, the proposed CARPY+ scheme meets all requirements. In particular, to the best of our knowledge, CARPY+ is the first noninteractive key establishment scheme with great resilience to a large number of node compromises designed for WSNs. We examine the CARPY and CARPY+ schemes from both the theoretical and experimental aspects. Our schemes have also been practically implemented on the TelosB compatible mote to evaluate the corresponding performance and overhead.","Wireless sensor networks,
Resilience,
Permission,
Communications Society,
Mobile communication,
Mobile computing,
Computer networks,
Information science,
Content management"
An MRI Receiver Coil Produced by Inkjet Printing Directly on to a Flexible Substrate,"Inkjet printing has been used to produce resonant radio frequency coils that are comparable to those produced by conventional printed circuit board (PCB) methods. The coils, which consist of a conductive loop and in-series capacitors, form part of a receiver circuit that is used for magnetic resonance imaging (MRI). The resonant circuit is selective at the predetermined frequency of 400 MHz. The required electrical components (resistor, capacitor, and inductor) were produced by inkjet printing, with scaling experiments for resistor and capacitor performed before the complete loops with integrated capacitors were printed. Numerical simulation was used to determine the required values for the components. The inkjet printed circuit was combined with a small tuning and matching board before being connected to a network analyzer and the MRI hardware. With a matching of -38 dB at 400 MHz the achieved results were comparable to those from standard PCB techniques. The performance of the inkjet printed component as a receiver device for nuclear magnetic resonance and MRI was verified by imaging reference phantoms and a whole kiwifruit; it compares favorably to standard MRI devices. Inkjet printing can, therefore, be considered a feasible technique for producing MRI receiver circuits on flexible substrates.",
Collaborative spectrum sensing from sparse observations using matrix completion for cognitive radio networks,"In cognitive radio, spectrum sensing is a key component to detect spectrum holes (i.e., channels not used by any primary users). Collaborative spectrum sensing among the cognitive radio nodes is expected to improve the ability of checking complete spectrum usage states. Unfortunately, due to power limitation and channel fading, available channel sensing information is far from being sufficient to tell the unoccupied channels directly. Aiming at breaking this bottleneck, we apply recent matrix completion techniques to greatly reduce the sensing information needed. We formulate the collaborative sensing problem as a matrix completion subproblem and a joint-sparsity reconstruction subproblem. Results of numerical simulations that validated the effectiveness and robustness of the proposed approach are presented. In particular, in noiseless cases, when number of primary user is small, exact detection was obtained with no more than 8% of the complete sensing information, whilst as number of primary user increases, to achieve a detection rate of 95.55%, the required information percentage was merely 16.8%.","Collaboration,
Sparse matrices,
Cognitive radio,
Chromium,
Fading,
Collaborative work,
Centralized control,
Propagation losses,
Frequency measurement,
Time measurement"
3-D Scalable Medical Image Compression With Optimized Volume of Interest Coding,"We present a novel 3-D scalable compression method for medical images with optimized volume of interest (VOI) coding. The method is presented within the framework of interactive telemedicine applications, where different remote clients may access the compressed 3-D medical imaging data stored on a central server and request the transmission of different VOIs from an initial lossy to a final lossless representation. The method employs the 3-D integer wavelet transform and a modified EBCOT with 3-D contexts to create a scalable bit-stream. Optimized VOI coding is attained by an optimization technique that reorders the output bit-stream after encoding, so that those bits belonging to a VOI are decoded at the highest quality possible at any bit-rate, while allowing for the decoding of background information with peripherally increasing quality around the VOI. The bit-stream reordering procedure is based on a weighting model that incorporates the position of the VOI and the mean energy of the wavelet coefficients. The background information with peripherally increasing quality around the VOI allows for placement of the VOI into the context of the 3-D image. Performance evaluations based on real 3-D medical imaging data showed that the proposed method achieves a higher reconstruction quality, in terms of the peak signal-to-noise ratio, than that achieved by 3D-JPEG2000 with VOI coding, when using the MAXSHIFT and general scaling-based methods.","Image coding,
Biomedical imaging,
Decoding,
Propagation losses,
Scalability,
Telemedicine,
Magnetic resonance imaging,
Image resolution,
Discrete wavelet transforms,
Permission"
Comparative object similarity for improved recognition with few or no examples,"Learning models for recognizing objects with few or no training examples is important, due to the intrinsic long-tailed distribution of objects in the real world. In this paper, we propose an approach to use comparative object similarity. The key insight is that: given a set of object categories which are similar and a set of categories which are dissimilar, a good object model should respond more strongly to examples from similar categories than to examples from dissimilar categories. We develop a regularized kernel machine algorithm to use this category dependent similarity regularization. Our experiments on hundreds of categories show that our method can make significant improvement, especially for categories with no examples.","Kernel,
Humans,
Birds,
Computer science,
Management training,
Object recognition,
Leg,
Computer vision,
Extraterrestrial measurements,
Clouds"
High-Power Pulse Generator With Flexible Output Pattern,"This paper presents a high-voltage bipolar rectangular pulse generator using a solid-state boosting front-end and an H-bridge output stage. The topology generates rectangular pulses with fast enough rise time and allows easy step-up input voltage. In addition, the circuit is able to adjust positive or negative pulsewidth, dead time between two pulses, and operating frequency. The topology can also be controlled to produce unipolar pulses and other pulse patterns without changing its configuration. With an appropriate dc source, the output voltage can also be adjusted to requirements of different applications. The intended application for such a circuit is algal cell membrane rupture for oil extraction, although additional applications, include biotechnology and plasma sciences, medicine, and food industry. A 1 kV/200 A bipolar solid-state pulse generator was fabricated to validate the theoretical analysis presented in this paper. In addition, to validate the analysis with simulations and prototype tests, biological test were conducted in order to examine the technical value of the proposed circuit. These evaluations seem to suggest that oil production rate from bipolar pulses may double that of an equivalent process with unipolar pulses.","Pulse generation,
Circuit testing,
Solid state circuits,
Circuit topology,
Voltage,
Pulse circuits,
Petroleum,
Boosting,
Space vector pulse width modulation,
Frequency"
A Semi Range-Based Iterative Localization Algorithm for Cognitive Radio Networks,"In cognitive radio networks (CRNs), knowledge of the position of the primary users (PUs) is important as it can be used to avoid harmful interference to the primary network while at the same time be exploited to improve the spectrum utilization. In this paper, a semi range-based localization algorithm is proposed for secondary users (SUs) in CRNs to estimate the positions of the PUs. The basic idea of the proposed algorithm is to take advantage of the estimated detection probabilities, which can be obtained from the binary detection indicators of the SUs, to estimate the distances between themselves and the PUs. Moreover, the accuracy of the proposed localization algorithm is further improved by introducing both a weighted least-squares method and an iterative procedure. The Cramer-Rao lower bound (CRLB) of the mean-square error (MSE) of the proposed localization estimator is also derived. A scenario with malicious users (MUs) is further considered, where the proposed method is modified to detect MUs. To illustrate the benefits of localization, we design a location-aware medium access control (MAC) protocol and show that significant throughput gains can be realized over conventional MAC protocols.",
Anomaly detection in GPS data based on visual analytics,"Modern machine learning techniques provide robust approaches for data-driven modeling and critical information extraction, while human experts hold the advantage of possessing high-level intelligence and domain-specific expertise. We combine the power of the two for anomaly detection in GPS data by integrating them through a visualization and human-computer interaction interface. In this paper we introduce GPSvas (GPS Visual Analytics System), a system that detects anomalies in GPS data using the approach of visual analytics: a conditional random field (CRF) model is used as the machine learning component for anomaly detection in streaming GPS traces. A visualization component and an interactive user interface are built to visualize the data stream, display significant analysis results (i.e., anomalies or uncertain predications) and hidden information extracted by the anomaly detection model, which enable human experts to observe the real-time data behavior and gain insights into the data flow. Human experts further provide guidance to the machine learning model through the interaction tools; the learning model is then incrementally improved through an active learning procedure.",
Speech enhancement with sparse coding in learned dictionaries,"The enhancement of speech degraded by non-stationary interferers is a highly relevant and difficult task of many signal processing applications. We present a monaural speech enhancement method based on sparse coding of noisy speech signals in a composite dictionary, consisting of the concatenation of a speech and interferer dictionary, both being possibly over-complete. The speech dictionary is learned off-line on a training corpus, while an environment specific interferer dictionary is learned on-line during speech pauses. Our approach optimizes the trade-off between source distortion and source confusion, and thus achieves significant improvements on objective quality measures like cepstral distance, in the speaker dependent and independent case, in several real-world environments and at low signal-to-noise ratios. Our enhancement method outperforms state-of-the-art methods like multi-band spectral subtraction and approaches based on vector quantization.","Speech enhancement,
Dictionaries,
Speech coding,
Speech processing,
Degradation,
Signal processing,
Working environment noise,
Distortion measurement,
Cepstral analysis,
Signal to noise ratio"
L1 regularized room modeling with compact microphone arrays,"Acoustic room modeling has several applications. Recent results using large microphone arrays show good performance, and are helpful in many applications. For example, when designing a better acoustic treatment for a concert hall, these large arrays can be used to help map the acoustic environment and aid in the design. However, in real-time applications - including de-reverberation, sound source localization, speech enhancement and 3D audio - it is desirable to model the room with existing small arrays and existing loudspeakers. In this paper we propose a novel room modeling algorithm, which uses a constrained room model and ℓ1-regularized least-squares to achieve good estimation of room geometry. We present experimental results on both real and synthetic data.","Microphone arrays,
Optical reflection,
Floors,
Acoustic arrays,
Loudspeakers,
Data mining,
Acoustic reflection,
Acoustic propagation,
Ultrasonic imaging,
Application software"
Free-form mesh tracking: A patch-based approach,"In this paper, we consider the problem of tracking nonrigid surfaces and propose a generic data-driven mesh deformation framework. In contrast to methods using strong prior models, this framework assumes little on the observed surface and hence easily generalizes to most free-form surfaces while effectively handling large deformations. To this aim, the reference surface is divided into elementary surface cells or patches. This strategy ensures robustness by providing natural integration domains over the surface for noisy data, while enabling to express simple patch-level rigidity constraints. In addition, we associate to this scheme a robust numerical optimization that solves for physically plausible surface deformations given arbitrary constraints. In order to demonstrate the versatility of the proposed framework, we conducted experiments on open and closed surfaces, with possibly non-connected components, that undergo large deformations and fast motions. We also performed quantitative and qualitative evaluations in multi-cameras and monocular environments, and with different types of data including 2D correspondences and 3D point clouds.","Deformable models,
Robustness,
Surface reconstruction,
Application software,
Shape,
Noise shaping,
Computational modeling,
Solid modeling,
Computer science,
Constraint optimization"
Exposing digital forgeries from 3-D lighting environments,"When creating a photographic composite, it can be difficult to match lighting conditions. We describe a technique for measuring lighting conditions in an image, and describe its use in detecting photographic composites. Specifically, we describe how to approximate a 3-D lighting environment with a low-dimensional model and how to estimate the model's parameters from a single image. Inconsistencies in the lighting model are then used as evidence of tampering.","Lighting,
Solid modeling,
Mathematical model,
Head,
Light sources,
Harmonic analysis,
Equations"
Detecting and Extracting the Photo Composites Using Planar Homography and Graph Cut,"With the advancement of photo and video editing tools, it has become fairly easy to tamper with photos and videos. One common way is to insert visually plausible composites into target images and videos. In this paper, we propose an automatic fake region detection method based on the planar homography constraint, and an automatic extraction method using graph cut with online feature/parameter selection. Two steps are taken in our method: 1) the targeting step, and 2) the segmentation step. First, the fake region is located roughly by enforcing the planar homography constraint. Second, the fake object is segmented via graph cut with the initialization given by the targeting step. To achieve an automatic segmentation, the optimal features and parameters for graph cut are dynamically selected via the proposed online feature/parameter selection. Performance of this method is evaluated on both semisimulated and real images. Our method works efficiently on images as long as there are regions satisfying the planar homography constraint, including image pairs captured by the approximately cocentered cameras, image pairs photographing planar or distant scenes, and a single image with duplications.","Image segmentation,
Cameras,
Permission,
Forensics,
Watermarking,
Layout,
Computer science,
Materials science and technology,
Software,
Humans"
On the Broadcast Capacity of Wireless Networks With Cooperative Relays,"A fundamental problem in wireless networks is determining the broadcast capacity, i.e., the maximum data transfer rate from a given node to every other node in a relay network. This paper studies the scaling of the broadcast capacity for a network with a single source and N destinations, of which f(N) are randomly selected to also act as relays. In high-density networks (i.e., the node density goes to infinity; the network area is fixed), it is shown that the broadcast capacity is upper bounded by Θ(log f(N)). Schemes are provided that achieve i) Θ(log f(N)) throughput if the channel fading is spatially continuous; ii) Θ(log log f(N)) throughput if the channel fading is spatially i.i.d.. For extended networks (i.e., the node density is fixed; the network area goes to infinity), the broadcast capacity is upper bounded by Θ(1) under channel models with fading and path-loss exponent α > 2. A multistage cooperative broadcasting scheme, which achieves Θ(1) broadcast rate for the high-density extended networks with pathloss channel model is proposed. These results quantifies the gains obtained due to cooperation compared to multihop noncooperative broadcasting, which has a maximum rate that scales as Θ(1) for high-density and Θ(1/(log f(N))α/2) for extended networks.",
Use bin-ratio information for category and scene classification,"In this paper we propose using bin-ratio information, which is collected from the ratios between bin values of histograms, for scene and category classification. To use such information, a new histogram dissimilarity, bin-ratio dissimilarity (BRD), is designed. We show that BRD provides several attractive advantages for category and scene classification tasks: First, BRD is robust to cluttering, partial occlusion and histogram normalization; Second, BRD captures rich co-occurrence information while enjoying a linear computational complexity; Third, BRD can be easily combined with other dissimilarity measures, such as L1 and χ2, to gather complimentary information. We apply the proposed methods to category and scene classification tasks in the bag-of-words framework. The experiments are conducted on several widely tested datasets including PASCAL 2005, PASCAL 2008, Oxford flowers, and Scene-15 dataset. In all experiments, the proposed methods demonstrate excellent performance in comparison with previously reported solutions.","Layout,
Histograms,
Robustness,
Computational complexity,
Testing,
Frequency,
Earth,
Laboratories,
Pattern recognition,
Automation"
Power system reliability assessment using intelligent state space pruning techniques: A comparative study,"State space pruning is a methodology that has been used to improve the computational efficiency and convergence of Monte Carlo Simulation (MCS) when computing the reliability indices of power systems. This methodology improves performance of MCS by pruning state spaces in such a manner that a new state space with a higher density of failure states than the original state space is created. We have previously proposed using Population-based Intelligent Search (PIS), specifically Genetic Algorithms (GA) and Binary Particle Swarm Optimization (BPSO), to prune the state space. This paper reexamines these techniques, suggests improvements, examines the extension of these techniques to a larger test system, and extends the method to include both Repulsive Binary Particle Swarm Optimization (RBPSO) and Binary Ant Colony Optimization (BACO). These methods are tested using the single and three area IEEE Reliability Test Systems.","Gallium,
Genetic algorithms,
Particle swarm optimization,
Reliability,
Power system reliability,
Ant colony optimization,
Generators"
Signaling Potential Adverse Drug Reactions from Administrative Health Databases,"The work is motivated by real-world applications of detecting Adverse Drug Reactions (ADRs) from administrative health databases. ADRs are a leading cause of hospitalization and death worldwide. Almost all current postmarket ADR signaling techniques are based on spontaneous ADR case reports, which suffer from serious underreporting and latency. However, administrative health data are widely and routinely collected. They, especially linked together, would contain evidence of all ADRs. To signal unexpected and infrequent patterns characteristic of ADRs, we propose a domain-driven knowledge representation Unexpected Temporal Association Rule (UTAR), its interestingness measure, unexlev, and a mining algorithm MUTARA (Mining UTARs given the Antecedent). We then establish an improved algorithm, HUNT, for highlighting infrequent and unexpected patterns by comparing their ranks based on unexlev with those based on traditional leverage. Various experimental results on real-world data substantiate that both MUTARA and HUNT can signal suspected ADRs while traditional association mining techniques cannot. HUNT can reliably shortlist statistically significantly more ADRs than MUTARA (p=0.00078). HUNT, e.g., not only shortlists the drug alendronate associated with esophagitis as MUTARA does, but also shortlists alendronate with diarrhoea and vomiting for older (age ¿ 60) females. We also discuss signaling ADRs systematically by using HUNT.","Drugs,
Databases,
Data mining,
Medical diagnostic imaging,
Australia,
Esophagus,
Hospitals,
Costs,
Patient monitoring"
Automated mapping of regular communication graphs on mesh interconnects,"Network contention has a significantly adverse effect on the performance of parallel applications with increasing size of parallel machines. Machines of the petascale era are forcing application developers to map tasks intelligently to job partitions to achieve the best performance possible. This paper presents a framework for automated mapping of parallel applications with regular communication graphs to two and three dimensional mesh and torus networks. This framework will save much effort on the part of application developers to generate mappings for their individual applications. One component of the framework is a process topology analyzer to find regular patterns and if found, to determine the dimensions of the communication graphs of applications. The other component is a suite of heuristic techniques for mapping 2D object grids to 2D and 3D processor meshes. The framework chooses the best heuristic from the suite for a given object grid and processor mesh pair based on the hop-bytes metric. We show performance improvements using the framework, for a 2D Stencil benchmark in MPI and the Weather Research and Forecasting model running on the IBM Blue Gene/P. We also compare our algorithms with others discussed in literature.","Topology,
Measurement,
Three dimensional displays,
Heuristic algorithms,
Network topology,
Meteorology,
Bandwidth"
Guided test generation for coverage criteria,"Test coverage criteria including boundary-value and logical coverage such as Modified Condition/Decision Coverage (MC/DC) have been increasingly used in safety-critical or mission-critical domains, complementing those more popularly used structural coverage criteria such as block or branch coverage. However, existing automated test-generation approaches often target at block or branch coverage for test generation and selection, and therefore do not support testing against boundary-value coverage or logical coverage. To address this issue, we propose a general approach that uses instrumentation to guide existing test-generation approaches to generate test inputs that achieve boundary-value and logical coverage for the program under test. Our preliminary evaluation shows that our approach effectively helps an approach based on Dynamic Symbolic Execution (DSE) to improve boundary-value and logical coverage of generated test inputs. The evaluation results show 30.5% maximum (23% average) increase in boundary-value coverage and 26% maximum (21.5% average) increase in logical coverage of the subject programs under test using our approach over without using our approach. In addition, our approach improves the fault-detection capability of generated test inputs by 12.5% maximum (11% average) compared to the test inputs generated without using our approach.","Instruments,
Generators,
Testing,
Transforms,
Concrete,
Boundary conditions,
Algorithm design and analysis"
Line matching leveraged by point correspondences,"A novel method for line matching is proposed. The basic idea is to use tentative point correspondences, which can be easily obtained by keypoint matching methods, to significantly improve line matching performance, even when the point correspondences are severely contaminated by outliers. When matching a pair of image lines, a group of corresponding points that may be coplanar with these lines in 3D space is firstly obtained from all corresponding image points in the local neighborhoods of these lines. Then given such a group of corresponding points, the similarity between this pair of lines is calculated based on an affine invariant from one line and two points. The similarity is defined on the basis of median statistic in order to handle the problem of inevitable incorrect correspondences in the group of point correspondences. Furthermore, the relationship of rotation between the reference and query images is estimated from all corresponding points to filter out those pairs of lines which are obviously impossible to be matches, hence speeding up the matching process as well as further improving its robustness. Extensive experiments on real images demonstrate the good performance of the proposed method as well as its superiority to the state-of-the-art methods.","Robustness,
Layout,
Pattern matching,
Geometry,
Histograms,
Lighting,
Laboratories,
Pattern recognition,
Automation,
Statistics"
A new design for a Turing Test for Bots,"Interesting, human-like opponents add to the entertainment value of a video game, and creating such opponents is a difficult challenge for programmers. Can artificial intelligence and computational intelligence provide the means to convincingly simulate a human opponent? Or are simple programming tricks and deceptions more effective? To answer these questions, the author designed and organised a game bot programming competition, the BotPrize, in which competitors submit bots that try to pass a “Turing Test for Bots”. In this paper, we describe a new design for the competition, which will make it simpler to run, and, we hope, open up new opportunities for innovative use of the testing platform. We illustrate the potential of the new platform by describing an implementation of a bot that is designed to learn how to appear more human using feedback obtained during play.","Games,
Humans,
Weapons,
Computers,
Artificial intelligence,
Servers,
Computational intelligence"
An Evolutionary Approach to the Multidepot Capacitated Arc Routing Problem,"The capacitated arc routing problem (CARP) is a challenging vehicle routing problem with numerous real world applications. In this paper, an extended version of CARP, the multidepot capacitated arc routing problem (MCARP), is presented to tackle practical requirements. Existing CARP heuristics are extended to cope with MCARP and are integrated into a novel evolutionary framework: the initial population is constructed either by random generation, the extended random path-scanning heuristic, or the extended random Ulusoy's heuristic. Subsequently, multiple distinct operators are employed to perform selection, crossover, and mutation. Finally, the partial replacement procedure is implemented to maintain population diversity. The proposed evolutionary approach (EA) is primarily characterized by the exploitation of attributes found in near-optimal MCARP solutions that are obtained throughout the execution of the algorithm. Two techniques are employed toward this end: the performance information of an operator is applied to select from a range of operators for selection, crossover, and mutation. Furthermore, the arc assignment priority information is employed to determine promising positions along the genome for operations of crossover and mutation. The EA is evaluated on 107 instances with up to 140 nodes and 380 arcs. The experimental results suggest that the integrated evolutionary framework significantly outperforms these individual extended heuristics.",
Automatic code generation for embedded systems: From UML specifications to VHDL code,"The design of modern embedded systems becomes more complex every day, due to the increasing amount of components and distinct functionalities incorporated into a single system. To address this situation, projects' abstraction level is continuously raised. In addition, techniques to speed up the code production process have emerged. These new trends lead to an important issue: the development of a consistent engineering process for systems co-design, from the requirements phase to the source code production. In this context, the UML is an interesting option for the embedded systems projects, leading to techniques to generate source code for both hardware and software. Currently, there are some works and commercial tools to generate source code from UML specifications to mainstream languages, such as C++ and Java. However, there are few works addressing the automatic source code generation for VHDL language, which is widely used in the embedded systems development. Thus, this work proposes a methodology to generate automatically VHDL source code from UML specifications. This methodology is supported by the GenERTiCA tool. A use case focused on the use of embedded systems for the maintenance systems is presented in this paper to demonstrate the feasibility of the proposed approach.","Embedded system,
Unified modeling language,
Competitive intelligence,
Machine intelligence,
Intelligent sensors,
Hardware,
Embedded computing,
Embedded software,
Intelligent systems,
Intelligent actuators"
Argos: An Advanced In-Vehicle Data Recorder on a Massively Sensorized Vehicle for Car Driver Behavior Experimentation,"A crucial factor in traffic safety is driver behavior. A better understanding of driver actions will help in determining the most common reasons for car accidents. Therefore, research in this field helps to reduce accidents due to driver distraction. This paper presents Argos, which is a complex and powerfully computerized car to help researchers in the study of car driver behavior. The Argos system is an improved in-vehicle data recorder (IVDR) that allows recording many kinds of alphanumerical data such as the speed (vehicle data), the point of gaze (driver data), or the current distance to lateral road marks (environmental data). In addition, Argos can record up to nine simultaneous video images which are synchronized with the alphanumerical data. Argos can also generate and record different kinds of in-car light and audio stimuli, allowing an experiment supervisor to interact or to schedule specific actions to take place during an experiment.",
Orbital angular momentum in radio: Measurement methods,"Novel measurement and approximation methodologies for studying orbital angular momentum (OAM) modes in radio beams, i.e., electromagnetic beam modes having helical phase fronts, are presented. We show that OAM modes can be unambiguously determined by measuring two electric field components at one point, or one electric field component at two points.",
Demosaicking by Alternating Projections: Theory and Fast One-Step Implementation,"Color image demosaicking is a key process in the digital imaging pipeline. In this paper, we study a well-known and influential demosaicking algorithm based upon alternating projections (AP), proposed by Gunturk, Altunbasak and Mersereau in 2002. Since its publication, the AP algorithm has been widely cited and compared against in a series of more recent papers in the demosaicking literature. Despite good performances, a limitation of the AP algorithm is its high computational complexity. We provide three main contributions in this paper. First, we present a rigorous analysis of the convergence property of the AP demosaicking algorithm, showing that it is a contraction mapping, with a unique fixed point. Second, we show that this fixed point is in fact the solution to a constrained quadratic minimization problem, thus, establishing the optimality of the AP algorithm. Finally, using the tool of polyphase representation, we show how to obtain the results of the AP algorithm in a single step, implemented as linear filtering in the polyphase domain. Replacing the original iterative procedure by the proposed one-step solution leads to substantial computational savings, by about an order of magnitude in our experiments.",
The Communication Complexity of Correlation,"Let X and Y be finite nonempty sets and (X,Y) a pair of random variables taking values in X?Y. We consider communication protocols between two parties, Alice and Bob, for generating X and Y. Alice is provided an x ? X generated according to the distribution of X , and is required to send a message to Bob in order to enable him to generate y ? Y, whose distribution is the same as that of Y|X=x. Both parties have access to a shared random string generated in advance. Let T[X:Y] be the minimum (over all protocols) of the expected number of bits Alice needs to transmit to achieve this. We show that I[X:Y] ? T[X:Y] ? I [X:Y] + 2 log2 (I[X:Y]+ O(1). We also consider the worst case communication required for this problem, where we seek to minimize the average number of bits Alice must transmit for the worst case x ? X. We show that the communication required in this case is related to the capacity C(E) of the channel E, derived from (X,Y) , that maps x ? X to the distribution of Y|X=x. We also show that the required communication T(E) satisfies C(E) ? T(E) ? C (E) + 2 log2 (C(E)+1) + O(1). Using the first result, we derive a direct-sum theorem in communication complexity that substantially improves the previous such result shown by Jain, Radhakrishnan, and Sen [In Proc. 30th International Colloquium of Automata, Languages and Programming (ICALP), ser. Lecture Notes in Computer Science, vol. 2719. 2003, pp. 300-315]. These results are obtained by employing a rejection sampling procedure that relates the relative entropy between two distributions to the communication complexity of generating one distribution from the other.","Complexity theory,
Random variables,
Entropy,
Computer science,
Sampling methods,
Mutual information,
Access protocols,
Automata,
Automatic programming,
Computational complexity"
Results of Using a Wireless Inertial Measuring System to Quantify Gait Motions in Control Subjects,"Gait analysis is important for the diagnosis of many neurological diseases such as Parkinson's. The discovery and interpretation of minor gait abnormalities can aid in early diagnosis. We have used an inertial measuring system mounted on the subject's foot to provide numerical measures of a subject's gait (3-D displacements and rotations), thereby creating an automated tool intended to facilitate diagnosis and enable quantitative prognostication of various neurological disorders in which gait is disturbed. This paper describes the process used for ensuring that these inertial measurement units yield accurate and reliable displacement and rotation data, and for validating the preciseness and robustness of the gait-deconstruction algorithms. It also presents initial results from control subjects, focusing on understanding the data recorded by the shoe-mounted sensor to quantify relevant gait-related motions.","Motion control,
Control systems,
Parkinson's disease,
Displacement measurement,
Information technology,
Rotation measurement,
Laboratories,
Legged locomotion,
Performance analysis,
Motion analysis"
Wireless Cellular Networks,"When aiming for achieving high spectral efficiency in wireless cellular networks, cochannel interference (CCI) becomes the dominant performance limiting factor. This article provides a survey of CCI mitigation techniques, where both active and passive approaches are discussed in the context of both open and closed-loop designs.","Wireless communication,
Cellular networks,
Interference,
Interchannel interference"
A Probabilistic Model of Overt Visual Attention for Cognitive Robots,"Visual attention is one of the major requirements for a robot to serve as a cognitive companion for human. The robotic visual attention is mostly concerned with overt attention which accompanies head and eye movements of a robot. In this case, each movement of the camera head triggers a number of events, namely transformation of the camera and the image coordinate systems, change of content of the visual field, and partial appearance of the stimuli. All of these events contribute to the reduction in probability of meaningful identification of the next focus of attention. These events are specific to overt attention with head movement and, therefore, their effects are not addressed in the classical models of covert visual attention. This paper proposes a Bayesian model as a robot-centric solution for the overt visual attention problem. The proposed model, while taking inspiration from the primates visual attention mechanism, guides a robot to direct its camera toward behaviorally relevant and/or visually demanding stimuli. A particle filter implementation of this model addresses the challenges involved in overt attention with head movement. Experimental results demonstrate the performance of the proposed model.","Cognitive robotics,
Robot kinematics,
Head,
Cameras,
Robot vision systems,
Focusing,
Humans,
Bayesian methods,
Particle filters"
Persistence-based segmentation of deformable shapes,"In this paper, we combine two ideas: persistence-based clustering and the Heat Kernel Signature (HKS) function to obtain a multi-scale isometry invariant mesh segmentation algorithm. The key advantages of this approach is that it is tunable through a few intuitive parameters and is stable under near-isometric deformations. Indeed the method comes with feedback on the stability of the number of segments in the form of a persistence diagram. There are also spatial guarantees on part of the segments. Finally, we present an extension to the method which first detects regions which are inherently unstable and segments them separately. Both approaches are reasonably scalable and come with strong guarantees. We show numerous examples and a comparison with the segmentation benchmark and the curvature function.","Shape,
Quadratic programming,
Printing,
Optimization methods,
Image converters,
Computer science,
Video on demand,
High definition video,
Functional programming"
Influence of Die Attach Layer on Thermal Performance of High Power Light Emitting Diodes,"In this paper, the influence of the die attach adhesive (DAA) layer on the thermal performance of high power light emitting diodes was first investigated by using finite element analysis, and some key results were verified by the experimental data. Effective thermal management of the studied light emitting diode package can be achieved by selecting a DAA material with a proper thermal conductivity and by manipulating the geometry parameters of the DAA layer, such as the DAA area, and the bond-line thickness. The significance of DAA thermal conductivity to heat dissipation was further demonstrated by an analysis of the bottleneck to heat transfer.","Microassembly,
Light emitting diodes,
Thermal conductivity,
Thermal management,
Heat transfer,
Finite element methods,
Performance analysis,
Packaging,
Conducting materials,
Geometry"
Comments on Fuzzy Control Systems Design via Fuzzy Lyapunov Functions,"This paper considers the work entitled ¿Fuzzy Control Systems Design via Fuzzy Lyapunov Functions¿ and published in IEEE Transactions on Systems, Man, and Cybernetics-Part B , where the authors try to extend the work of Rhee and Won. Nevertheless, the results proposed by Li have been obtained without taking into account a necessary path independency condition to ensure the line integral function to be a Lyapunov function candidate, and consequently, the proposed global asymptotic stability and stabilization conditions are unsuitable.","Fuzzy control,
Fuzzy systems,
Lyapunov method,
Control systems,
Asymptotic stability,
Linear matrix inequalities,
Sufficient conditions"
MOEA/D with NBI-style Tchebycheff approach for portfolio management,"MOEA/D is a generic multiobjective evolutionary optimization algorithm. MOEA/D needs a approach to decompose a multiobjective optimization problem into a number of single objective optimization problems. The commonly-used weighted sum approach and the Tchebycheff approach may not be able to handle disparately scaled objectives. This paper suggests a new decomposition approach, called NBI-style Tchebycheff approach, for MOEA/D to deal with such objectives. A portfolio management MOP has been used as an example to test the effectiveness of MOEA/D with NBI-style Tchebycheff approach.","Optimization,
Portfolios,
Approximation methods,
Evolutionary computation,
Electronic mail,
Indexes,
Maintenance engineering"
Minimax Robust Optimal Estimation Fusion in Distributed Multisensor Systems With Uncertainties,"In this paper, the robust estimation fusion problem in multisensor systems with norm-bounded uncertainties concerning the error covariance matrix between local estimates is addressed. A robust fusion method by minimizing the worst-case fused mean-squared error (MSE) for all feasible error covariance matrices of local estimates is proposed. The minimax robust fusion weighting matrices can be explicitly formulated as a function of solution of a semidefinite programming (SDP). Some numerical examples demonstrate that when the error covariance matrix suffers disturbance, the proposed fusion method is more robust than the nominal fusion method which ignores the uncertainties, and can improve the performance when the disturbance is considerably large.","Minimax techniques,
Robustness,
Multisensor systems,
Uncertainty,
Covariance matrix,
Sensor fusion,
Sensor systems,
Yield estimation,
Working environment noise,
Estimation error"
Scale-hierarchical 3D object recognition in cluttered scenes,"3D object recognition in scenes with occlusion and clutter is a difficult task. In this paper, we introduce a method that exploits the geometric scale-variability to aid in this task. Our key insight is to leverage the rich discriminative information provided by the scale variation of local geometric structures to constrain the massive search space of potential correspondences between model and scene points. In particular, we exploit the geometric scale variability in the form of the intrinsic geometric scale of each computed feature, the hierarchy induced within the set of these intrinsic geometric scales, and the discriminative power of the local scale-dependent/invariant 3D shape descriptors. The method exploits the added information in a hierarchical coarse-to-fine manner that lets it cull the space of all potential correspondences effectively. We experimentally evaluate the accuracy of our method on an extensive set of real scenes with varying amounts of partial occlusion and achieve recognition rates higher than the state-of-the-art. Furthermore, for the first time we systematically demonstrate the method's ability to accurately localize objects despite changes in their global scales.","Object recognition,
Layout,
Libraries,
Shape,
Feature extraction,
Solid modeling,
Image recognition,
Computer science,
Information geometry,
Image analysis"
Wireless Sensor Network: A Pervasive Technology for Earth Observation,"Thanks to the coordinated infrastructure composed by a distributed collection of different resources, sensor webs currently represent a very effective solution to earth observation. These global entities are able to coordinate networks of heterogeneous sensing platform, such as spacecrafts, airborne instruments, or ground-based devices. In the framework of technologies operating at local level, wireless sensor networks (WSNs) are characterized by small, low-cost, and autonomous devices that collect data about physical quantities in a distribute and pervasive fashion. This paper is aimed at reviewing some innovative implementations of WSNs for earth observation purposes.","Wireless sensor networks,
Monitoring,
Earth,
Computer architecture,
Real time systems,
Sensors,
Power demand"
Parallel and distributed graph cuts by dual decomposition,"Graph cuts methods are at the core of many state-of-the-art algorithms in computer vision due to their efficiency in computing globally optimal solutions. In this paper, we solve the maximum flow/minimum cut problem in parallel by splitting the graph into multiple parts and hence, further increase the computational efficacy of graph cuts. Optimality of the solution is guaranteed by dual decomposition, or more specifically, the solutions to the subproblems are constrained to be equal on the overlap with dual variables. We demonstrate that our approach both allows (i) faster processing on multi-core computers and (ii) the capability to handle larger problems by splitting the graph across multiple computers on a distributed network. Even though our approach does not give a theoretical guarantee of speedup, an extensive empirical evaluation on several applications with many different data sets consistently shows good performance. An open source implementation of the dual decomposition method is also made publicly available.","Computer vision,
Distributed computing,
Concurrent computing,
Computer networks,
Computer aided manufacturing,
Application software,
Computational efficiency,
Tree graphs,
Grid computing"
UWB Bandpass Filter Using Cascaded Miniature High-Pass and Low-Pass Filters With Multilayer Liquid Crystal Polymer Technology,"This paper presents a new ultra-wideband (UWB) bandpass filter that is formed by cascading miniature high-pass and low-pass filters implemented with multilayer liquid crystal polymer technology. The miniature high-pass and low-pass filters can be designed independently and the design procedures are described. Experiments are carried out to validate the designs. Small sizes for the fabricated high-pass filter, low-pass filter, and UWB bandpass filter are achieved, which are 4.0 mm × 4.4 mm (0.162 ¿g × 0.178 ¿g), 4.56 mm × 4.9 mm (0.185 ¿g × 0.198 ¿g) and 5.1 mm × 8.86 mm (0.207 ¿g X 0.359 ¿g), respectively, where ¿g is the guided wavelength at 6.85 GHz. Excellent performance is obtained for all the measured filters, including low insertion losses and high selectivity. Due to its simple structure and excellent performance, the proposed UWB bandpass filter is favorable for practical UWB communication and radar systems.","Band pass filters,
Low pass filters,
Nonhomogeneous media,
Liquid crystal polymers,
Ultra wideband technology,
Performance loss,
Loss measurement,
Wavelength measurement,
Insertion loss,
Ultra wideband communication"
Flexible management of resource service composition in cloud manufacturing,"With the development of microelectronics, computer technology, information technology, and intelligent of machinery and control equipment, the flexible manufacturing technique has become one of the key developing directions for advanced manufacturing technology. The cloud manufacturing (CMfg), which is a new generation service-oriented networked manufacturing model, can provide the users distributed in different places with the manufacturing resource and manufacturing ability services through the centralized management. In order to improve the quality of resource service optimal-allocation and cope with the flexible issues in CMfg, this paper investigated the definition and classification of flexibility in the whole life-cycle of resource service composition in CMfg, and the related factors in life-cycle of resource service composition were analyzed. The flexible management architecture for resource service composition in CMfg was designed. The key issues and their solutions in flexible management of resource service composition were preliminarily discussed.","Silicon,
Computational modeling,
Quality of service,
Monitoring,
Communities,
Clouds"
Design of a Low-Cost Underwater Acoustic Modem,"There has been an increasing interest in creating short-range, low data rate, underwater wireless sensor networks for scientific marine exploration and monitoring. However, the lack of an inexpensive, underwater acoustic modem is preventing the proliferation of these sensor networks. Thus, we are building an underwater acoustic modem starting with the most critical component from a cost perspective-the transducer. The design substitutes a commercial transducer with a homemade transducer using cheap piezoceramic material and builds the rest of the modem's components around the properties of the transducer to extract as much performance as possible. This letter describes the high level design, and cost and power characteristics of each of the major modem components: the transducer, the analog transceiver, and the digital signal processor of our modem prototype.",
Real-Time Visualized Freehand 3D Ultrasound Reconstruction Based on GPU,"Visualized freehand 3-D ultrasound reconstruction offers to image incremental reconstruction during acquisition and guide users to scan interactively for high-quality volumes. We originally used the graphics processing unit (GPU) to develop a visualized reconstruction algorithm that achieves real-time level. Each newly acquired image was transferred to the memory of the GPU and inserted into the reconstruction volume on the GPU. The partially reconstructed volume was then rendered using GPU-based incremental ray casting. After visualized reconstruction, hole-filling was performed on the GPU to fill remaining empty voxels in the reconstruction volume. We examine the real-time nature of the algorithm using in vitro and in vivo datasets. The algorithm can image incremental reconstruction at speed of 26-58 frames/s and complete 3-D imaging in the acquisition time for the conventional freehand 3-D ultrasound.","Image reconstruction,
Rendering (computer graphics),
Ultrasonic imaging,
Three dimensional displays,
Visualization,
Real time systems,
Graphics processing unit"
Domain-Driven Classification Based on Multiple Criteria and Multiple Constraint-Level Programming for Intelligent Credit Scoring,"Extracting knowledge from the transaction records and the personal data of credit card holders has great profit potential for the banking industry. The challenge is to detect/predict bankrupts and to keep and recruit the profitable customers. However, grouping and targeting credit card customers by traditional data-driven mining often does not directly meet the needs of the banking industry, because data-driven mining automatically generates classification outputs that are imprecise, meaningless, and beyond users' control. In this paper, we provide a novel domain-driven classification method that takes advantage of multiple criteria and multiple constraint-level programming for intelligent credit scoring. The method involves credit scoring to produce a set of customers' scores that allows the classification results actionable and controllable by human interaction during the scoring process. Domain knowledge and experts' experience parameters are built into the criteria and constraint functions of mathematical programming and the human and machine conversation is employed to generate an efficient and precise solution. Experiments based on various data sets validated the effectiveness and efficiency of the proposed methods.","Banking,
Credit cards,
Mathematical programming,
Humans,
Pattern analysis,
Classification tree analysis,
Support vector machines,
Support vector machine classification,
Recruitment"
Seesaw Relay Logic and Memory Circuits,Various logic functions can be implemented by appropriately biasing a single seesaw relay. The seesaw relay can also be configured as a bistable latch so that a memory cell can be implemented with one relay and one access transistor. Measurements of seesaw relay switching speed are well matched to lumped-parameter modeling results.,"Logic circuits,
Electrodes,
Digital relays,
CMOS technology,
Logic functions,
Nanoelectromechanical systems,
Voltage,
Latches,
Velocity measurement,
Integrated circuit measurements"
Measurement of Dielectric Properties of Nematic Liquid Crystals at Millimeter Wavelength,"Due to their large birefringence and moderately low loss, liquid crystals (LCs) are a promising dielectric media for development of a variety of reconfigurable millimeter-wave devices. In order to optimize the design of tunable millimeter-wave devices, accurate values of the dielectric and elastic constants, as well as the loss tangents of LCs, are needed. However, characterization of LCs at millimeter-wave frequencies is a very challenging and demanding task. In this work, a transmission line method is used for the broadband characterization of nematic LCs in the frequency range of 30-60 GHz. For this purpose, a unique LC cell is proposed and using this, five different nematic LCs, including E7, K15, E44, E63, and MDA-00-3506, are measured and the values of their electrical and mechanical parameters are extracted. The extraction of these parameters from the measurements involves an optimization using two finite-element computer programs recently developed by the authors for the prediction of the local alignments of LC molecules and the wave propagation within the test cell. The highest values of the dielectric birefringence and the highest values of the loss tangents are recorded for E44 and MDA-00-3506. The loss tangent for all the LCs shows a general downward trend as the frequency increases, which is a useful characteristic in the development of reconfigurable millimeter-wave devices.",
A modified Invasive Weed Optimization algorithm for time-modulated linear antenna array synthesis,"Time modulated antenna arrays attracted the attention of researchers for the synthesis of low/ultra-low side lobes in recent past. In this article we propose an improved variant of a recently developed ecologically inspired metaheuristic, well-known as Invasive Weed Optimization (IWO), to solve the real parameter optimization problem related to the design of time-modulated linear antenna arrays with ultra low Side Lobe Level (SLL), Side Band Level (SBL) and Main Lobe Beam Width (BWFN). We improvise the classical IWO by introducing two parallel populations and a more explorative routine of changing the mutation step-size with iterations. Experimental results indicate that the proposed algorithm achieves better performance over the design problem as compared to the conventional Taylor Series based method and the only known metaheuristic approach based on the Differential Evolution (DE) algorithm.",
Learning Graphical Models for Hypothesis Testing and Classification,"Sparse graphical models have proven to be a flexible class of multivariate probability models for approximating high-dimensional distributions. In this paper, we propose techniques to exploit this modeling ability for binary classification by discriminatively learning such models from labeled training data, i.e., using both positive and negative samples to optimize for the structures of the two models. We motivate why it is difficult to adapt existing generative methods, and propose an alternative method consisting of two parts. First, we develop a novel method to learn tree-structured graphical models which optimizes an approximation of the log-likelihood ratio. We also formulate a joint objective to learn a nested sequence of optimal forests-structured models. Second, we construct a classifier by using ideas from boosting to learn a set of discriminative trees. The final classifier can interpreted as a likelihood ratio test between two models with a larger set of pairwise features. We use cross-validation to determine the optimal number of edges in the final model. The algorithm presented in this paper also provides a method to identify a subset of the edges that are most salient for discrimination. Experiments show that the proposed procedure outperforms generative methods such as Tree Augmented Naïve Bayes and Chow-Liu as well as their boosted counterparts.",
Segmentation of the Outer Vessel Wall of the Common Carotid Artery in CTA,"A novel method is presented for carotid artery vessel wall segmentation in computed tomography angiography (CTA) data. First the carotid lumen is semi-automatically segmented using a level set approach initialized with three seed points. Subsequently, calcium regions located within the vessel wall are automatically detected and classified using multiple features in a GentleBoost framework. Calcium regions segmentation is used to improve localization of the outer vessel wall because it is an easier task than direct outer vessel wall segmentation. In a third step, pixels outside the lumen area are classified as vessel wall or background, using the same GentleBoost framework with a different set of image features. Finally, a 2-D ellipse shape deformable model is fitted to a cost image derived from both the calcium and vessel wall classifications. The method has been validated on a dataset of 60 CTA images. The experimental results show that the accuracy of the method is comparable to the interobserver variability.","Carotid arteries,
Calcium,
Image segmentation,
Computed tomography,
Angiography,
Level set,
Pixel,
Shape,
Deformable models,
Costs"
Camera-based drowsiness reference for driver state classification under real driving conditions,"Experts assume that accidents caused by drowsiness are significantly under-reported in police crash investigations (1–3%). They estimate that about 24–33% of the severe accidents are related to drowsiness. In order to develop warning systems that detect reduced vigilance based on the driving behavior, a reliable and accurate drowsiness reference is needed. Studies have shown that measures of the driver's eyes are capable to detect drowsiness under simulator or experiment conditions. In this study, the performance of the latest eye tracking based in-vehicle fatigue prediction measures are evaluated. These measures are assessed statistically and by a classification method based on a large dataset of 90 hours of real road drives. The results show that eye-tracking drowsiness detection works well for some drivers as long as the blinks detection works properly. Even with some proposed improvements, however, there are still problems with bad light conditions and for persons wearing glasses. As a summary, the camera based sleepiness measures provide a valuable contribution for a drowsiness reference, but are not reliable enough to be the only reference.","Computer crashes,
Accidents,
Fatigue,
Roads,
US Department of Transportation,
Signal processing,
Cameras,
Electroencephalography,
Electrooculography,
Intelligent vehicles"
"Modeling, Quantification, and Reduction of the Impact of Uncontrolled Return Currents of Vias Transiting Multilayered Packages and Boards","The returning displacement currents of vias transiting multilayered stack-ups in electronic packages and boards excite parasitic transverse electromagnetic modes in power-ground plane pairs, causing them to behave as parallel-plate waveguides. These waves may cause significant coupling in the power-ground cavity, leading to electromagnetic reliability (EMR) issues such as simultaneous switching noise coupling, high insertion loss degradation of signal vias, and stray radiation from the periphery/edges of the package/board. In this contribution, we model and quantify EMR problems caused by uncontrolled return currents of signal vias in conventional multilayer stack-ups. Traditional methods used to minimize these problems, and their limitations are discussed. We propose a low-cost layer stack-up, which overcomes most of the limitations of conventional stack-ups by providing well-defined return-current paths for microstrip-to-microstrip via transitions. Test samples of the proposed configuration are designed, fabricated, and measured. Very good correlation is obtained between measurement and simulation. Finally, a circuit model for the microstrip-to-microstrip via transition, considering the return-current paths, is developed and the circuit parameters are analytically calculated. Conventional closed-form expressions used for the extraction of these parameters, particularly the via capacitance, are extended and modified.","Capacitors,
Microstrip,
Cavity resonators,
Couplings,
Impedance,
Resonant frequency,
Electromagnetic interference"
Effects of V2G reactive power compensation on the component selection in an EV or PHEV bidirectional charger,"Electric vehicles (EVs) and plug-in hybrid electric vehicles (PHEVs) are becoming a part of the electric grid day by day. Chargers for these vehicles have the ability to make this interaction better for the consumer and for the grid. Vehicle to grid (V2G) power transfer has been under research for more than a decade because of the large energy reserve of an electric vehicle battery and the potential of thousands of these connected to the grid. Rather than discharging the vehicle batteries, reactive power compensation in particular is beneficial for both consumers and for the utility. However, certain adverse effects or requirements of reactive power transfer should be defined before a design stage. To understand the dynamics of this operation, this study investigates the effect of reactive power transfer on the charger system components, especially on the dc-link capacitor and the battery.","Reactive power,
Capacitors,
Batteries,
Vehicles,
Mathematical model,
Inverters,
Couplings"
Distributed Design Methods for Linear Quadratic Control and Their Limitations,"We introduce the notion of distributed design methods, which construct controllers by accessing a plant's description in a constrained manner. We propose performance and information metrics for these design methods, and investigate the connection between closed-loop performance of the best controller they can produce and the amount of exchanged information about the plant. For a class of linear discrete-time, time invariant plants, we show that any communication-less distributed control method results in controllers whose performance is, at least, twice the optimal in the worst-case. We then give a bound on the minimal amount of exchanged information necessary to beat the best communication-less design strategy. We also show that, in the case of continuous-time plants, the worst-case performance of controllers constructed by communication-less design strategies is unbounded.","Design methodology,
Communication system control,
Distributed control,
Automatic control,
Power system modeling,
Large-scale systems,
Control design,
Optimal control,
Computer science,
Mathematics"
Optimal coverage of a known arbitrary environment,"The problem of coverage of known space by a mobile robot has many applications. Of particular interest is providing a solution that guarantees the complete coverage of the free space by traversing an optimal path, in terms of the distance travelled. In this paper we introduce a new algorithm based on the Boustrophedon cellular decomposition. The presented algorithm encodes the areas (cells) to be covered as edges of the Reeb graph. The optimal solution to the Chinese Postman Problem (CPP) is used to calculate an Euler tour, which guarantees complete coverage of the available free space while minimizing the path of the robot. In addition, we extend the classical solution of the CPP to account for the entry point of the robot for cell coverage by changing the weights of the Reeb graph edges. Proof of correctness is provided together with experimental results in different environments.","Orbital robotics,
Robot sensing systems,
Robotics and automation,
Mobile robots,
Cleaning,
Space exploration,
USA Councils,
Painting,
Legged locomotion,
Marketing and sales"
A Multimode Shuffled Iterative Decoder Architecture for High-Rate RS-LDPC Codes,"For an efficient multimode low-density parity-check (LDPC) decoder, most hardware resources, such as permutators, should be shared among different modes. Although an LDPC code constructed based on a Reed-Solomon (RS) code with two information symbols is not quasi-cyclic, in this paper, we reveal that the structural properties inherent in its parity-check matrix can be adopted in the design of configurable permutators. A partially parallel architecture combined with the proposed permutators is used to mitigate the increase in implementation complexity for the multimode function. The high check-node degree of a high-rate RS-LDPC code leads to challenges in the efficient implementation of a high-throughput decoder. To overcome this difficulty, the variable nodes have been partitioned into several groups, and each group is processed sequentially in order to shorten the critical-path delay and hence increase the maximum operating frequency. In addition, shuffled message-passing decoding is adopted, since fewer iterations can be used to achieve the desired bit-error-rate performance. In order to demonstrate the usefulness of the proposed flexible-permutator-based architecture, one single-mode rate-0.84 decoder and two multimode decoders whose code rates range between 0.79 and 0.93 have been implemented. These decoders can achieve multigigabit-per-second throughput. Using the proposed architecture to support lower rate RS-LDPC codes, e.g., rate-0.568 code, is also investigated.","Iterative decoding,
Parity check codes,
Code standards,
Throughput,
Communication standards,
Computer science,
Hardware,
Parallel architectures,
Delay,
Frequency"
The Power of Forgetting: Improving the Last-Good-Reply Policy in Monte Carlo Go,"The dominant paradigm for programs playing the game of Go is Monte Carlo tree search. This algorithm builds a search tree by playing many simulated games (playouts). Each playout consists of a sequence of moves within the tree followed by many moves beyond the tree. Moves beyond the tree are generated by a biased random sampling policy. The recently published last-good-reply policy makes moves that, in previous playouts, have been successful replies to immediately preceding moves. This paper presents a modification of this policy that not only remembers moves that recently succeeded but also immediately forgets moves that recently failed. This modification provides a large improvement in playing strength. We also show that responding to the previous two moves is superior to responding to the previous one move. Surprisingly, remembering the win rate of every reply performs much worse than simply remembering the last good reply (and indeed worse than not storing good replies at all).","Games,
Algorithm design and analysis,
Machine learning,
Monte Carlo methods,
Decision trees"
Material classification by tactile sensing using surface textures,"In this paper we describe an application of machine learning to distinguish between seven different materials, based on their surface texture. Applications of such a system includes quality assurance and estimating surface friction during manipulation tasks. A naive Bayes classifier is used to distinguish textures sensed by a bio-inspired artificial finger. The finger has randomly distributed strain gauges and Polyvinylidene Fluoride (PVDF) films embedded in silicone. Different textures induce different intensity of vibrations in the silicone. Textures can be distinguished by the presence of different frequencies in the signal. The data from the finger is pre-processed and the Fourier coefficients of the sensor outputs are used to learn a classifier for different textures. The performance of the classifier is evaluated against a naive time domain based learner. Preliminary results show that our classifier performs better.","Surface texture,
Robot kinematics,
Mobile robots,
Shape,
Friction,
Wheels,
Robotics and automation,
Anisotropic magnetoresistance,
Gravity,
Joining processes"
"Route optimization in network mobility: Solutions, classification, comparison, and future research directions","Network mobility (NEMO) handles mobility of a set of mobile nodes in an aggregate way using one or more mobile routers. NEMO introduces several advantages, such as reduced signaling, increased manageability, reduced power consumption and conservation of bandwidth when compared to individual host mobility. NEMO Basic Support Protocol (BSP), the IETF standard for NEMO, suffers from a number of limitations, like inefficient route and increased handoff latency. Most of the recent research efforts on NEMO have concentrated on solving the problem of inefficient route resulting in several route optimization schemes to solve the problem. To choose a route optimization scheme, it is very important to have a quantitative comparison of the available route optimization schemes. The objective of this article is to survey, classify and compare the route optimization schemes proposed in the literature over the last five years. We classify the schemes based on the basic approach for route optimization, and compare the schemes based on protocol overhead, such as header overhead, amount of signalling, and memory requirements. We conclude that performance of the classes of schemes has to be evaluated under criteria such as available bandwidth, topology of the mobile network and mobility type.","Energy management,
Bandwidth,
Delay,
Local area networks,
Energy consumption,
Internet,
NASA,
Electronic mail,
Access protocols,
Encapsulation"
A New Optical-CT Apparatus for 3-D Radiotherapy Dosimetry: Is Free Space Scanning Feasible?,"In this paper, we present a new optical computed tomography (Optical-CT) scanner for the verification of the radiation dose schemes delivered in modern radiotherapy applications. The optical-CT scanner is capable of providing rapid relative 3-D dosimetry with high spatial resolution with the use of normoxic N-Vinylpyrrolidone based polymer gel dosimeter. The scanner employs a diffuse uncollimated light illumination beam, a computer controlled motorized rotation stage and a charge-coupled device (CCD) camera. Various test experiments were performed to determine the performance characteristics of the optical-CT apparatus. Attenuation coefficient (¿ ) versus dose calibration data were generated from two calibration experiments using gel containers of two different diameters. All irradiations were performed using a 6 MV linear accelerator. A comparison of the reconstructed images between optical-CT scans using refractive index (RI) matching fluid and corresponding scans performed in free space was demonstrated. The dose readout of a test irradiation model was found to be in good agreement with independent readout performed by MR imaging. The findings presented in this study suggest that polymer dosimeters combined with the new optical-CT scanner constitute a potentially feasible method capable of measuring complex 3-D dose distributions with high resolution and in a wide dose range.","Dosimetry,
Optical attenuators,
Optical polymers,
Optical refraction,
Optical variables control,
Optical computing,
Testing,
Performance evaluation,
Calibration,
Computed tomography"
Settling the Polynomial Learnability of Mixtures of Gaussians,"Given data drawn from a mixture of multivariate Gaussians, a basic problem is to accurately estimate the mixture parameters. We give an algorithm for this problem that has running time and data requirements polynomial in the dimension and the inverse of the desired accuracy, with provably minimal assumptions on the Gaussians. As a simple consequence of our learning algorithm, we we give the first polynomial time algorithm for proper density estimation for mixtures of k Gaussians that needs no assumptions on the mixture. It was open whether proper density estimation was even statistically possible (with no assumptions) given only polynomially many samples, let alone whether it could be computationally efficient. The building blocks of our algorithm are based on the work (Kalai \emph{et al}, STOC 2010) that gives an efficient algorithm for learning mixtures of two Gaussians by considering a series of projections down to one dimension, and applying the method of moments to each univariate projection. A major technical hurdle in the previous work is showing that one can efficiently learn univariate mixtures of two Gaussians. In contrast, because pathological scenarios can arise when considering projections of mixtures of more than two Gaussians, the bulk of the work in this paper concerns how to leverage a weaker algorithm for learning univariate mixtures (of many Gaussians) to learn in high dimensions. Our algorithm employs hierarchical clustering and rescaling, together with methods for backtracking and recovering from the failures that can occur in our univariate algorithm. Finally, while the running time and data requirements of our algorithm depend exponentially on the number of Gaussians in the mixture, we prove that such a dependence is necessary.","Polynomials,
Clustering algorithms,
Estimation,
Probability,
Additives,
Accuracy,
Computer science"
Feature Selection Using Principal Component Analysis,"Principal component analysis (PCA) has been widely applied in the area of computer science. It is well-known that PCA is a popular transform method and the transform result is not directly related to a sole feature component of the original sample. However, in this paper, we try to apply principal components analysis (PCA) to feature selection. The proposed method well addresses the feature selection issue, from a viewpoint of numerical analysis. The analysis clearly shows that PCA has the potential to perform feature selection and is able to select a number of important individuals from all the feature components. Our method assumes that different feature components of original samples have different effects on feature extraction result and exploits the eigenvectors of the covariance matrix of PCA to evaluate the significance of each feature component of the original sample. When evaluating the significance of the feature components, the proposed method takes a number of eigenvectors into account. Then it uses a reasonable scheme to perform feature selection. The devised algorithm is not only subject to the nature of PCA but also computationally efficient. The experimental results on face recognition show that when the proposed method is able to greatly reduce the dimensionality of the original samples, it also does not bring the decrease in the recognition accuracy.","Feature extraction,
Principal component analysis,
Face,
Databases,
Face recognition,
Transforms"
Heat Kernel Based Local Binary Pattern for Face Representation,"Face classification has recently become a very hot research topic in computer vision and multimedia information processing. It has many potential applications, in which face representation is the most fundamental task. Most existing face representation methods perform poorly in capturing the intrinsic structural information of face appearance. To address this problem, we propose a novel multiscale heat kernel based face representation, for heat kernels perform well in characterizing the topological structural information of face appearance. Further, the local binary pattern (LBP) descriptor is incorporated into the multiscale heat kernel face representation for the purpose of capturing texture information of face appearance. As a result, we have the heat kernel based local binary pattern (HKLBP) descriptor. Finally, a Support Vector Machine (SVM) classifier is learned in the HKLBP feature space for face classification. Experimental results demonstrate the effectiveness and superiority of our face classification framework.","Kernel,
Face detection,
Lighting,
Support vector machines,
Support vector machine classification,
Principal component analysis,
Independent component analysis,
Linear discriminant analysis,
Robustness,
Computer vision"
Reduction of stray inductance in power electronic modules using basic switching cells,"This paper introduces the concepts of two basic switching cells, P-cell and N-cell, along with their implications in power electronic circuits. The basic switching cells exist in almost every power electronic circuit. To take advantage of these structures, this paper proposes a novel packaging method for power electronics modules. The proposed packaging method uses the basic switching cells as the unit in a module, instead of traditional anti-parallel connection of active switch and diode. This rearrangement can reduce the stray inductance in the current commutation pass; therefore, the performance and reliability of the power device module and the power electronic system can be improved. A conventional phase leg module and a proposed module are modeled. Electromagnetic simulation is carried out to extract the stray inductance from the two modules. Switching behavior under different package parasitics is studied based on Saber simulation.","Inductance,
Insulated gate bipolar transistors,
Switches,
Converters,
Leg,
Switching circuits"
Low-Complexity and Distributed Energy Minimization in Multihop Wireless Networks,"In this work, we study the problem of minimizing the total power consumption in a multihop wireless network subject to a given offered load. It is well-known that the total power consumption of multihop wireless networks can be substantially reduced by jointly optimizing power control, link scheduling, and routing. However, the known optimal cross-layer solution to this problem is centralized and with high computational complexity. In this paper, we develop a low-complexity and distributed algorithm that is provably power-efficient. In particular, under the node-exclusive interference model and with suitable assumptions on the power-rate function, we can show that the total power consumption of our algorithm is at most (2+¿) times as large as the power consumption of the optimal (but centralized and complex) algorithm, where ¿ is an arbitrarily small positive constant. Our algorithm is not only the first such distributed solution with provable performance bound, but its power-efficiency ratio is also tighter than that of another suboptimal centralized algorithm in the literature.",
Robust Surface Reconstruction via Laplace-Beltrami Eigen-Projection and Boundary Deformation,"In medical shape analysis, a critical problem is reconstructing a smooth surface of correct topology from a binary mask that typically has spurious features due to segmentation artifacts. The challenge is the robust removal of these outliers without affecting the accuracy of other parts of the boundary. In this paper, we propose a novel approach for this problem based on the Laplace-Beltrami (LB) eigen-projection and properly designed boundary deformations. Using the metric distortion during the LB eigen-projection, our method automatically detects the location of outliers and feeds this information to a well-composed and topology-preserving deformation. By iterating between these two steps of outlier detection and boundary deformation, we can robustly filter out the outliers without moving the smooth part of the boundary. The final surface is the eigen-projection of the filtered mask boundary that has the correct topology, desired accuracy and smoothness. In our experiments, we illustrate the robustness of our method on different input masks of the same structure, and compare with the popular SPHARM tool and the topology preserving level set method to show that our method can reconstruct accurate surface representations without introducing artificial oscillations. We also successfully validate our method on a large data set of more than 900 hippocampal masks and demonstrate that the reconstructed surfaces retain volume information accurately.","Robustness,
Surface reconstruction,
Topology,
Image reconstruction,
Biomedical imaging,
Shape,
USA Councils,
Geometry,
Image analysis,
Performance analysis"
Replica Placement in P2P Storage: Complexity and Game Theoretic Analyses,"In peer-to-peer storage systems, peers replicate each others' data in order to increase availability. If the matching is done centrally, the algorithm can optimize data availability in an equitable manner for all participants. However, if matching is decentralized, the peers' selfishness can greatly alter the results, leading to performance inequities that can render the system unreliable and thus ultimately unusable. We analyze the problem using both theoretical approaches (complexity analysis for the centralized system, game theory for the decentralized one) and simulation. We prove that the problem of optimizing availability in a centralized system is NP-hard. In decentralized settings, we show that the rational behavior of selfish peers will be to replicate only with similarly-available peers. Compared to the socially-optimal solution, highly available peers have their data availability increased at the expense of decreased data availability for less available peers. The price of anarchy is high: unbounded in one model, and linear with the number of time slots in the second model. We also propose centralized and decentralized heuristics that, according to our experiments, converge fast in the average case. The high price of anarchy means that a completely decentralized system could be too \emph{hostile} for peers with low availability, who could never achieve satisfying replication parameters. Moreover, we experimentally show that even explicit consideration and exploitation of diurnal patterns of peer availability has a small effect on the data availability—except when the system has truly global scope. Yet a fully centralized system is infeasible, not only because of problems in information gathering, but also the complexity of optimizing availability. The solution to this dilemma is to create system-wide cooperation rules that allow a decentralized algorithm, but also limit the selfishness of the participants.","Game theory,
Availability,
Peer to peer computing,
Distributed computing,
Data engineering,
Memory,
Computer science,
Analytical models,
Social network services,
Bandwidth"
A Hybrid Knowledge-Guided Detection Technique for Screening of Infectious Pulmonary Tuberculosis From Chest Radiographs,"Tuberculosis (TB) is a deadly infectious disease and the presence of cavities in the upper lung zones is a strong indicator that the disease has developed into a highly infectious state. Currently, the detection of TB cavities is mainly conducted by clinicians observing chest radiographs. Diagnoses performed by radiologists are labor intensive and very often there is insufficient health care personnel available, especially in remote communities. After assessing existing approaches, we propose an automated segmentation technique, which takes a hybrid knowledge-based Bayesian classification approach to detect TB cavities automatically. We apply gradient inverse coefficient of variation and circularity measures to classify detected features and confirm true TB cavities. By comparing with nonhybrid approaches and the classical active contour techniques for feature extraction in medical images, experimental results demonstrate that our approach achieves high accuracy with a low false positive rate in detecting TB cavities.","Diagnostic radiography,
Diseases,
Lungs,
Medical services,
Personnel,
Bayesian methods,
Computer vision,
Active contours,
Feature extraction,
Biomedical imaging"
A context management architecture for large-scale smart environments,"Context-aware architecture collects various context data from heterogeneous sensors and provides an intelligent service by exploiting the collected data. In this article we explain the generalized context-aware software architecture for heterogeneous smart environments. The proposed architecture integrates large-scale contexts from multiple heterogeneous sensors, and makes a semantic decision by fusing and reasoning about the collected contexts. Moreover, we discuss a designed architecture that manages communities between large numbers of heterogeneous information entities and enhances intelligence abilities.",
A 2.16 mW Low Power Digitally-Controlled Variable Gain Amplifier,"A low power digitally-controlled CMOS variable gain amplifier (VGA) was fabricated in a TSMC 0.18 ¿m CMOS technology. By extending the transconductor operation range from saturation mode for high gain to triode mode for low gain, the proposed VGA can obtain a wide gain range with low power dissipation. The power consumption of the proposed VGA is as small as 2.16 mW while keeping a wide gain range of 53 dB. The proposed VGA has a controlled gain from -22 dB to 31 dB with 1 dB steps. When the proposed VGA was set to a maximum gain, the total harmonic distortion (THD) and the 3 dB bandwidth are -48 dB and at least 65 MHz, respectively.","Gain,
Energy consumption,
Digital control,
Transconductance,
Bandwidth,
Circuits,
CMOS technology,
Transconductors,
Power amplifiers,
Operational amplifiers"
"Automatic Bayesian Classification of Healthy Controls, Bipolar Disorder, and Schizophrenia Using Intrinsic Connectivity Maps From fMRI Data","We present a method for supervised, automatic, and reliable classification of healthy controls, patients with bipolar disorder, and patients with schizophrenia using brain imaging data. The method uses four supervised classification learning machines trained with a stochastic gradient learning rule based on the minimization of Kullback-Leibler divergence and an optimal model complexity search through posterior probability estimation. Prior to classification, given the high dimensionality of functional MRI (fMRI) data, a dimension reduction stage comprising two steps is performed: first, a one-sample univariate t-test mean-difference Tscore approach is used to reduce the number of significant discriminative functional activated voxels, and then singular value decomposition is performed to further reduce the dimension of the input patterns to a number comparable to the limited number of subjects available for each of the three classes. Experimental results using functional brain imaging (fMRI) data include receiver operation characteristic curves for the three-way classifier with area under curve values around 0.82, 0.89, and 0.90 for healthy control versus nonhealthy, bipolar disorder versus nonbipolar, and schizophrenia patients versus nonschizophrenia binary problems, respectively. The average three-way correct classification rate (CCR) is in the range of 70%-72%, for the test set, remaining close to the estimated Bayesian optimal CCR theoretical upper bound of about 80% , estimated from the one nearest-neighbor classifier over the same data.","Magnetic resonance imaging,
Temporal lobe,
Machine learning,
Artificial neural networks,
Training,
Brain"
Blind Multiuser Detector for Chaos-Based CDMA Using Support Vector Machine,"The algorithm and the results of a blind multiuser detector using a machine learning technique called support vector machine (SVM) on a chaos-based code division multiple access system is presented in this paper. Simulation results showed that the performance achieved by using SVM is comparable to existing minimum mean square error (MMSE) detector under both additive white Gaussian noise (AWGN) and Rayleigh fading conditions. However, unlike the MMSE detector, the SVM detector does not require the knowledge of spreading codes of other users in the system or the estimate of the channel noise variance. The optimization of this algorithm is considered in this paper and its complexity is compared with the MMSE detector. This detector is much more suitable to work in the forward link than MMSE. In addition, original theoretical bit-error rate expressions for the SVM detector under both AWGN and Rayleigh fading are derived to verify the simulation results.","Detectors,
Chaos,
Multiaccess communication,
Support vector machines,
AWGN,
Additive white noise,
Rayleigh channels,
Machine learning algorithms,
Machine learning,
Mean square error methods"
An Ultra Compact Integrated Front End for Wireless Neural Recording Microsystems,"Abstract-The design and performance of an integrated front end for high-channel-count neural recording microsystems is presented. This front end consists of a 3-D micromachined microelectrode array, realized using a new architecture that allows simple and rapid microassembly. A 64-site 3-D multiprobe, realized using the new architecture, interfaces with tissue volumes of less than 0.01 mm3 and has a footprint of 1 mm2. For amplification, filtering, and buffering of the recorded neural signals, a custom signal-conditioning circuit provides high gain (60 dB), low noise (4.8 μVrms), and low power (50 μW) in an area of 0.098 mm2. In addition, this circuitry implements bandwidth tuning, offset compensation, and wireless gain programmability. This new approach to system integration uses a microfabricated parylene overlay cable to electrically interconnect the 3-D array and signal-conditioning circuitry. In vivo results obtained using this integrated microsystem front end in its most compact form are presented.","Wireless communication,
Implantable biomedical devices,
Neural prosthesis,
Microassembly"
Distributed Construction of Connected Dominating Sets with Minimum Routing Cost in Wireless Networks,"In this paper, we will study a special Connected Dominating Set (CDS) problem — between any two nodes in a network, there exists at least one shortest path, all of whose intermediate nodes should be included in a special CDS, named Minimum rOuting Cost CDS (MOC-CDS). Therefore, routing by MOC-CDS can guarantee that each routing path between any pair of nodes is also the shortest path in the network. Thus, energy consumption and delivery delay can be reduced greatly. CDS has been studied extensively in Unit Disk Graph (UDG) or Disk Graph (DG). However, nodes in networks may have different transmission ranges and some communications may be obstructed by obstacles. Therefore, we model network as a bidirectional general graph in this paper. We prove that constructing a minimum MOC-CDS in general graph is NP-hard. We also prove that there does not exist a polynomial-time approximation algorithm for constructing a minimum MOCCDS with performance ratio ρlnδ, where ρ is an arbitrary positive number (ρ","Costs,
Wireless networks,
Spine,
Routing protocols,
Wireless sensor networks,
Computer science,
Delay,
Distributed computing,
Mathematics,
Energy consumption"
Anonymizing weighted social network graphs,"The increasing popularity of social networks has initiated a fertile research area in information extraction and data mining. Although such analysis can facilitate better understanding of sociological, behavioral, and other interesting phenomena, there is a growing concern about personal privacy being breached, thereby requiring effective anonymization techniques. In this paper, we consider edge weight anonymization in social graphs. Our approach builds a linear programming (LP) model which preserves properties of the graph that are expressible as linear functions of the edge weights. Such properties form the foundations of many important graph-theoretic algorithms such as shortest paths, k-nearest neighbors, minimum spanning tree, etc. Off-the-shelf LP solvers can then be used to find solutions to the resulting model where the computed solution constitutes the weights in the anonymized graph. As a proof of concept, we choose the shortest paths problem, and experimentally evaluate the proposed techniques using real social network data sets.",
FI3D: Direct-Touch Interaction for the Exploration of 3D Scientific Visualization Spaces,"We present the design and evaluation of FI3D, a direct-touch data exploration technique for 3D visualization spaces. The exploration of three-dimensional data is core to many tasks and domains involving scientific visualizations. Thus, effective data navigation techniques are essential to enable comprehension, understanding, and analysis of the information space. While evidence exists that touch can provide higher-bandwidth input, somesthetic information that is valuable when interacting with virtual worlds, and awareness when working in collaboration, scientific data exploration in 3D poses unique challenges to the development of effective data manipulations. We present a technique that provides touch interaction with 3D scientific data spaces in 7 DOF. This interaction does not require the presence of dedicated objects to constrain the mapping, a design decision important for many scientific datasets such as particle simulations in astronomy or physics. We report on an evaluation that compares the technique to conventional mouse-based interaction. Our results show that touch interaction is competitive in interaction speed for translation and integrated interaction, is easy to learn and use, and is preferred for exploration and wayfinding tasks. To further explore the applicability of our basic technique for other types of scientific visualizations we present a second case study, adjusting the interaction to the illustrative visualization of fiber tracts of the brain and the manipulation of cutting planes in this context.",
Linear Passive Networks With Ideal Switches: Consistent Initial Conditions and State Discontinuities,"This paper studies linear passive electrical networks with ideal switches. We employ the so-called linear switched systems framework in which these circuits can be analyzed for any given switch configuration. After providing a complete characterization of admissible inputs and consistent initial states with respect to a switch configuration, the paper introduces a new state reinitialization rule that is based on energy minimization at the time of switching. This new rule is proven to be equivalent to the classical methods of Laplace transform and charge/flux conservation principle. Also we illustrate the new rule on typical examples that have been treated in the literature.",
The Limits of Two-Party Differential Privacy,"We study differential privacy in a distributed setting where two parties would like to perform analysis of their joint data while preserving privacy for both datasets. Our results imply almost tight lower bounds on the accuracy of such data analyses, both for specific natural functions (such as Hamming distance) and in general. Our bounds expose a sharp contrast between the two-party setting and the simpler client-server setting (where privacy guarantees are one-sided). In addition, those bounds demonstrate a dramatic gap between the accuracy that can be obtained by differentially private data analysis versus the accuracy obtainable when privacy is relaxed to a computational variant of differential privacy. The first proof technique we develop demonstrates a connection between differential privacy and deterministic extraction from Santha-Vazirani sources. A second connection we expose indicates that the ability to approximate a function by a low-error differentially private protocol is strongly related to the ability to approximate it by a low communication protocol. (The connection goes in both directions.)","Protocols,
Privacy,
Complexity theory,
Data privacy,
Hamming distance,
Sensitivity,
Additives"
Quickest Change Detection of a Markov Process Across a Sensor Array,"Recent attention in quickest change detection in the multisensor setting has been on the case where the densities of the observations change at the same instant at all the sensors due to the disruption. In this work, a more general scenario is considered where the change propagates across the sensors, and its propagation can be modeled as a Markov process. A centralized, Bayesian version of this problem is considered, with a fusion center that has perfect information about the observations and a priori knowledge of the statistics of the change process. The problem of minimizing the average detection delay subject to false alarm constraints is formulated in a dynamic programming framework. Insights into the structure of the optimal stopping rule are presented. In the limiting case of rare disruptions, it is shown that the structure of the optimal test reduces to thresholding the a posteriori probability of the hypothesis that no change has happened. Under a certain condition on the Kullback-Leibler (K-L) divergence between the post- and the pre-change densities, it is established that the threshold test is asymptotically optimal (in the vanishing false alarm probability regime). It is shown via numerical studies that this low-complexity threshold test results in a substantial improvement in performance over naive tests such as a single-sensor test or a test that incorrectly assumes that the change propagates instantaneously.","Sensor arrays,
Markov processes,
Testing,
Computerized monitoring,
Delay,
Object detection,
Bayesian methods,
Application software,
Biological information theory,
Condition monitoring"
Near optimal demand-side energy management under real-time demand-response pricing,"In this paper, we present demand-side energy management under real-time demand-response pricing as a task scheduling problem which is NP-hard. Using minmax as the objective, we show that the schedule produced by our minMax scheduling algorithm has a number of salient advantages: significant peak-shaving, cost reduction, and risk-aversion for the consumers. We prove that our algorithm finds near-optimal solutions and our simulation study show that the actual performance is better than the worst-case bound. The algorithm is simple to implement and efficient at the scale of large enterprises.",
Fault Localization via Risk Modeling,"Internet backbone networks are under constant flux in order to keep up with demand and offer new features. The pace of change in technology often outstrips the pace of introduction of associated fault monitoring capabilities that are built into today's IP protocols and routers. Moreover, some of these new technologies cross networking layers, raising the potential for unanticipated interactions and service disruptions, which the individual layers' built-in monitoring capabilities may not detect. In these instances, operators typically employ higher layer monitoring techniques such as end-to-end liveness probing to detect lower or cross-layer failures, but lack tools to precisely determine where a detected failure may have occurred. In this paper, we evaluate the effectiveness of using risk modeling to translate high-level failure notifications into lower layer root causes in two specific scenarios in a tier-1 ISP. We show that a simple greedy heuristic works with accuracy exceeding 80 percent for many failure scenarios in simulation, while delivering extremely high precision (greater than 80 percent). We report our operational experience using risk modeling to isolate optical component and MPLS control plane failures in an ISP backbone.","Spine,
Condition monitoring,
Optical fiber networks,
Computer science,
Protocols,
Ultraviolet sources,
Optical devices,
Multiprotocol label switching,
Optical control,
Hardware"
Logspace Versions of the Theorems of Bodlaender and Courcelle,"Bodlaender's Theorem states that for every k there is a linear-time algorithm that decides whether an input graph has tree width k and, if so, computes a width-k tree composition. Courcelle's Theorem builds on Bodlaender's Theorem and states that for every monadic second-order formula φ and for every k there is a linear-time algorithm that decides whether a given logical structure A of tree width at most k satisfies φ. We prove that both theorems still hold when ""linear time"" is replaced by ""logarithmic space."" The transfer of the powerful theoretical framework of monadic second-order logic and bounded tree width to logarithmic space allows us to settle a number of both old and recent open problems in the log space world.","Particle separators,
Automata,
NP-complete problem,
Approximation algorithms,
Periodic structures,
Binary trees"
A Fast ICP Algorithm for 3-D Human Body Motion Tracking,"Iterative closest point (ICP) algorithm has been widely used for registering the geometry, shape and color of the 3-D meshes. However, ICP requires a long computation time to find the corresponding closest points between the model points and the data points. To overcome this problem, we propose a fast ICP algorithm that consists of two acceleration techniques: hierarchical model point selection (HMPS) and logarithmic data point search (LDPS). HMPS accelerates the search by reducing the search region of the data points corresponding to a model point effectively: it selects the model points in a coarse-to-fine manner and employs the four neighboring closest data points in the upper layer to make the search region for finding the closest data point corresponding to a model point in the lower layer. LDPS accelerates the search by visiting the data points within the search region using 2-D logarithm search. The HMPS method and the LDPS method can be operating separately or together. To evaluate the speed of the proposed ICP, we apply it to the 3-D human body motion tracking. The proposed fast ICP is about 3.17 times faster than the existing ICP such as the K-D tree.",
"A study of MANET routing protocols: Joint node density, packet length and mobility","The dynamic topology of a mobile ad hoc network (MANET) poses a real challenge in the design of a MANET routing protocol. Over the last 10 years, a variety of routing protocols have been developed and their performance simulations are made by network researchers. Most of the previous research on MANET routing protocols have focused on simulation study by varying network parameters, such as network size (node density), pause times, or node mobility independently. This paper considers the problem from a different perspective, using a simulation model the combined effect of node density and packet length; node density and mobility on the performance of a typical 802.11 MANET is investigated. This is a common and realistic scenario in MANETs where nodes move around, join and leave the network at any time. Based on the QoS (end-to-end delay, throughput), routing load and packet retransmissions, this paper systematically analyzes the performance of four diverse MANET routing protocols with the different simulation model and configurations, and drew more complete conclusions.","Routing protocols,
Mobile computing,
Ad hoc networks,
Electrostatic discharge"
Radon-Like features and their application to connectomics,"In this paper we present a novel class of so-called Radon-Like features, which allow for aggregation of spatially distributed image statistics into compact feature descriptors. Radon-Like features, which can be efficiently computed, lend themselves for use with both supervised and unsupervised learning methods. Here we describe various instantiations of these features and demonstrate there usefulness in context of neural connectivity analysis, i.e. Connectomics, in electron micrographs. Through various experiments on simulated as well as real data we establish the efficacy of the proposed features in various tasks like cell membrane enhancement, mitochondria segmentation, cell background segmentation, and vesicle cluster detection as compared to various other state-of-the-art techniques.",
Comparative Visualization for Parameter Studies of Dataset Series,"This paper proposes comparison and visualization techniques to carry out parameter studies for the special application area of dimensional measurement using 3D X-ray computed tomography (3DCT). A dataset series is generated by scanning a specimen multiple times by varying parameters of an industrial 3DCT device. A high-resolution series is explored using our planar-reformatting-based visualization system. We present a novel multi-image view and an edge explorer for comparing and visualizing gray values and edges of several datasets simultaneously. Visualization results and quantitative data are displayed side by side. Our technique is scalable and generic. It can be effective in various application areas like parameter studies of imaging modalities and dataset artifact detection. For fast data retrieval and convenient usability, we use bricking of the datasets and efficient data structures. We evaluate the applicability of the proposed techniques in collaboration with our company partners.","Computed tomography,
Data visualization,
X-ray imaging,
Image edge detection,
Computer industry,
Attenuation measurement,
Automotive engineering,
Aerospace industry,
Electronics industry,
Machinery production industries"
Parameter independent maximum torque per ampere (MTPA) control of IPM machine based on signal injection,"This paper presents a new maximum torque per ampere (MTPA) control method for Interior Permanent Magnet Synchronous Machine (IPMSM) drives. The proposed method uses the conventional speed control scheme, where speed control loop produces the magnitude of the stator current reference. According to the current angle in the rotor reference frame, θ, the current reference is decomposed to the d-/q-axis current references. To operate IPMSM in the MTPA mode, this paper presents the new MTPA tracking method using signal injection. This method works based on the inherent definition of MTPA, which is that the torque variation due to the current angle variation should be zero at the specific torque. The proposed method detects the accurate current angle where the magnitude of the stator current is the minimum at the specific torque without any pre-made look-up tables and machine parameters.",
A new MEMS sensor for AC electric current,"This paper presents new results in the testing and characterization of a MEMS sensor for AC electric current. The sensor is comprised of a piezoelectric MEMS cantilever with a microscale permanent magnet mounted to its free end. When placed near a wire carrying AC current the magnet couples to the oscillating magnetic field around the wire, deflecting the cantilever and generating a sinusoidal voltage proportional to the current. Unlike inductive sensors, this sensor does not need to encircle the conductor and it can measure current in a two-wire “zip-cord”. It is also self-powered, and is thus more suitable for wireless sensor node applications than a powered sensor device. The theoretical basis of this new sensor's operation is presented, as well as the fabrication of a MEMS sensor device, and the first test results of this new sensor measuring current in single-wire and two-wire conductors. Sensor response is linear (R2 > 0.99) with sensitivity in the range of 0.1–1.1 mV/A. An integrated self-powered sensor device is also presented, which employs a piezoelectric energy harvester to power the sensor's signal conditioning circuitry at a 2.6% duty cycle.","Wire,
Micromechanical devices,
Force,
Magnetic resonance imaging,
Current measurement,
Electrodes,
Sensitivity"
"K
-Dimensional Coding Schemes in Hilbert Spaces","This paper presents a general coding method where data in a Hilbert space are represented by finite dimensional coding vectors. The method is based on empirical risk minimization within a certain class of linear operators, which map the set of coding vectors to the Hilbert space. Two results bounding the expected reconstruction error of the method are derived, which highlight the role played by the codebook and the class of linear operators. The results are specialized to some cases of practical importance, including K-means clustering, nonnegative matrix factorization and other sparse coding methods.",
Planning pre-grasp manipulation for transport tasks,"Studies of human manipulation strategies suggest that pre-grasp object manipulation, such as rotation or sliding of the object to be grasped, can improve task performance by increasing both the task success rate and the quality of load-supporting postures. In previous demonstrations, pre-grasp object rotation by a robot manipulator was limited to manually-programmed actions. We present a method for automating the planning of pre-grasp rotation for object transport tasks. Our technique optimizes the grasp acquisition point by selecting a target object pose that can be grasped by high-payload manipulator configurations. Careful selection of the transition states leads to successful transport plans for tasks that are otherwise infeasible. In addition, optimization of the grasp acquisition posture also indirectly improves the transport plan quality, as measured by the safety margin of the manipulator payload limits.","USA Councils,
Robotics and automation,
Humans,
Manipulators,
Safety,
Payloads,
Strategic planning,
Computer science,
Kinematics,
Robustness"
Numerical Study of the Shielding Properties of Macroscopic Hybrid Ferromagnetic/Superconductor Hollow Cylinders,"We study the magnetic shielding properties of hybrid ferromagnetic/superconductor (F/S) structures consisting of two coaxial cylinders, with one of each material. We use an axisymmetric finite-element model in which the electrical properties of the superconducting tube are modeled by a nonlinear E-J power law with a magnetic-field-dependent critical current density whereas the magnetic properties of the ferromagnetic material take saturation into account. We study and compare the penetration of a uniform axial magnetic field in two cases: 1) a ferromagnetic tube placed inside a larger superconducting tube (Ferro-In configuration) and 2) a ferromagnetic tube placed outside the superconducting one (Ferro-Out configuration). In both cases, we assess how the ferromagnetic tube improves the shielding properties of the sole superconducting tube. The influence of the geometrical parameters of the ferromagnetic tube is also studied: It is shown that, upon an optimal choice of the geometrical parameters, the range of magnetic fields that are efficiently shielded by the high-temperature superconductor tube alone can be increased by a factor of up to 7 (2) in a Ferro-Out (Ferro-In) configuration. The optimal configuration uses a 1020 carbon steel with a thickness of 2 mm and a height that is half that of the superconducting cylinder (80 mm).","High temperature superconductors,
Magnetic shielding,
Magnetic properties,
Superconducting materials,
Magnetic materials,
Coaxial components,
Finite element methods,
Saturation magnetization,
Superconducting magnets,
Critical current density"
Preparing Students and Engineers for Global Software Development: A Systematic Review,"In recent years, the evolution of Global Software Development (GSD) has grown both rapidly and significantly, and although the efficiency of this new type of development has been proven, some challenging issues must still be confronted. Of all these, our research line is focused on designing the specific training that members of virtual teams must receive. Universities and companies therefore need to design training schemas to deal with the specifics of GSD, which are principally related to communication difficulties and time and cultural differences. In this work we present the findings of a Systematic Literature Review in the field of GSD training and teaching. Our intention is twofold: on the one hand we wish to discover the existing strategies and proposals available up to the present day, and on the other hand we wish to identify the open challenges, that will be helpful for practitioners and researchers in the future.","Training,
Software,
Proposals,
Companies,
Programming,
Book reviews"
Synthesis of Structurally Simple Supervisors Enforcing Generalized Mutual Exclusion Constraints in Petri Nets,"Generalized mutual exclusion constraints (GMECs) are a typical class of specifications for the supervisory control of discrete event systems in a Petri net formalism. This paper classifies the given constraints into elementary and dependent ones according to the linear dependency of their characteristic transition vectors that indicate the token count change of the concerned places. The dependent constraints are further divided into strongly and weakly dependent ones. A constraint is usually enforced by explicitly adding a monitor to a plant model. This research develops the conditions under which a dependent constraint is enforced due to the enforcement of the elementary constraints. The results developed in this paper are applied to the existing manufacturing-oriented Petri net classes. An algorithm is also proposed to identify a set of elementary constraints. Examples are used to demonstrate the proposed methods. Some potential extensions and applications are also discussed. This research improves the existing methods in computational efficiency and structure simplification of the supervisor, given a set of GMECs.",
Generalized model learning for Reinforcement Learning on a humanoid robot,"Reinforcement learning (RL) algorithms have long been promising methods for enabling an autonomous robot to improve its behavior on sequential decision-making tasks. The obvious enticement is that the robot should be able to improve its own behavior without the need for detailed step-by-step programming. However, for RL to reach its full potential, the algorithms must be sample efficient: they must learn competent behavior from very few real-world trials. From this perspective, model-based methods, which use experiential data more efficiently than model-free approaches, are appealing. But they often require exhaustive exploration to learn an accurate model of the domain. In this paper, we present an algorithm, Reinforcement Learning with Decision Trees (RL-DT), that uses decision trees to learn the model by generalizing the relative effect of actions across states. The agent explores the environment until it believes it has a reasonable policy. The combination of the learning approach with the targeted exploration policy enables fast learning of the model. We compare RL-DT against standard model-free and model-based learning methods, and demonstrate its effectiveness on an Aldebaran Nao humanoid robot scoring goals in a penalty kick scenario.","Humanoid robots,
Decision trees,
Machine learning,
Learning systems,
Robotics and automation,
USA Councils,
Computer science,
Decision making,
Robot programming,
Helicopters"
Feature selection for Spam and Phishing detection,"Unsolicited Bulk Email (UBE) has become a large problem in recent years. The number of mass mailers in existence is increasing dramatically. Automatically detecting UBE has become a vital area of current research. Many email clients (such as Outlook and Thunderbird) already have junk filters built in. Mass mailers are continually evolving and overcoming some of the junk filters. This means that the need for research in the area is ongoing. Many existing techniques seem to randomly choose the features that will be used for classification. This paper aims to address this issue by investigating the utility of over 40 features that have been used in recent literature. Information gain for these features are calculated over Ham, Spam and Phishing corpora.","Feature extraction,
Unsolicited electronic mail,
HTML,
Suspensions,
Equations,
IP networks"
A realistic game system using multi-modal user interfaces,"This study is to propose a realistic game system using a multi-modal interface, including gaze tracking, hand gesture recognition and bio-signal analysis. Our research is novel in the following four ways, compared to previous game systems. First, a highly immersive and realistic game is implemented on a head mounted display (HMD), with a gaze tracker, a gesture recognizer and a bio-signal analyzer. Second, since the camera module for eye tracking is attached below the HMD, a user's gaze position onto the HMD display can be calculated without wearing any additional eye tracking devices. Third, an aiming cursor in the game system is controlled by the gaze tracking. The grabbing and throwing behaviors toward a target are performed by the user's hand gestures using a data glove. Finally, the level of difficulty in the game system is adaptively controlled according to the measurement and analysis of a user's bio-signals. Experimental results show that the proposed method provides more effect on experience of immersion and interest than conventional device such as a keyboard and or a mouse.","Games,
Gesture recognition,
Cameras,
Monitoring,
Fingers,
Calibration,
Three dimensional displays"
Neural-Mechanical Feedback Control Scheme Generates Physiological Ankle Torque Fluctuation During Quiet Stance,"We have recently demonstrated in simulations and experiments that a proportional and derivative (PD) feedback controller can regulate the active ankle torque during quiet stance and stabilize the body despite a long sensory-motor time delay. The purpose of the present study was to: 1) model the active and passive ankle torque mechanisms and identify their contributions to the total ankle torque during standing and 2) investigate whether a neural-mechanical control scheme that implements the PD controller as the neural controller can successfully generate the total ankle torque as observed in healthy individuals during quiet stance. Fourteen young subjects were asked to stand still on a force platform to acquire data for model optimization and validation. During two trials of 30 s each, the fluctuation of the body angle, the electromyogram of the right soleus muscle, and the ankle torque were recorded. Using these data, the parameters of: 1) the active and passive torque mechanisms (Model I) and 2) the PD controller within the neural-mechanical control scheme (Model II) were optimized to achieve potential matching between the measured and predicted ankle torque. The performance of the two models was finally validated with a new set of data. Our results indicate that not only the passive, but also the active ankle torque mechanism contributes significantly to the total ankle torque and, hence, to body stabilization during quiet stance. In addition, we conclude that the proposed neural-mechanical control scheme successfully mimics the physiological control strategy during quiet stance and that a PD controller is a legitimate model for the strategy that the central nervous system applies to regulate the active ankle torque in spite of a long sensory-motor time delay.","Feedback control,
Fluctuations,
Torque control,
PD control,
Centralized control,
Delay effects,
Predictive models,
Adaptive control,
Muscles,
Torque measurement"
Corrective consensus: Converging to the exact average,"Consensus algorithms provide an elegant distributed way for computing the average of a set of measurements across a sensor network. However, the convergence of the node estimates to the global average depends on the timely and reliable exchange of the measurements to neighboring sensors. These assumptions are violated in practice due to random packet losses, causing the estimated average to be biased. In this paper we present and analyze a practical consensus protocol that overcomes these difficulties and assures convergence to the correct average. Simulation results show that the proposed corrective consensus has ten times less overhead to reach the same level of accuracy as the one achieved by a variant of standard consensus that uses retransmissions to (partially) overcome the negative effects of packet losses. In networks with more severe packet loss rates, corrective consensus is more than forty times more accurate than standard consensus that uses retransmissions. More importantly, by continuing to execute the corrective consensus algorithm the estimation error can become arbitrarily small.","Convergence,
Topology,
Wireless networks,
Temperature measurement,
Eigenvalues and eigenfunctions,
Network topology"
Informative path planning for an autonomous underwater vehicle,"We present a path planning method for autonomous underwater vehicles in order to maximize mutual information. We adapt a method previously used for surface vehicles, and extend it to deal with the unique characteristics of underwater vehicles. We show how to generate near-optimal paths while ensuring that the vehicle stays out of high-traffic areas during predesignated time intervals. In our objective function we explicitly account for the fact that underwater vehicles typically take measurements while moving, and that they do not have the ability to communicate until they resurface. We present field results from ocean trials on planning paths for a specific AUV, an underwater glider.","Path planning,
Underwater vehicles,
Sea measurements,
Spatial resolution,
Sea surface,
Ocean temperature,
Remotely operated vehicles,
Computer science,
Boats,
Robotics and automation"
UWB Channel Modeling in Roadway and Indoor Parking Environments,"In this paper, the characteristics of ultrawideband (UWB) channels on outdoor roadway and indoor parking environments are investigated. A set of propagation measurements were conducted on roadways and in underground parking garages, and the resulting propagation data consist of approximately 1200 measured signals. Multipath properties are characterized using tapped-delay-line and Saleh-Valenzuela (S-V) models. Power-law-type decay patterns are observed in the ray-energy decay, as well as in the power delay profile. Results are compared with existing UWB models, including the IEEE 802.15.4a channel model.","Correlators,
Indoor environments,
Permission,
Performance evaluation,
Time measurement,
Transmitters,
Frequency synchronization,
Dynamic range,
Ultra wideband technology,
Delay"
Active monitoring and alarm management for fault localization in transparent all-optical networks,"Achieving accurate and efficient fault localization in large transparent all-optical networks (TONs) is an important and challenging problem due to unique fault-propagation, time constraints, and scalability requirements. In this paper, we introduce a novel technique for optimizing the speed of fault-localization through the selection of an active set of monitors for centralized and hierarchically-distributed management. The proposed technique is capable of providing multiple levels of fault-localization-granularity, from individual discrete optical components to the entire monitoring domains. We formulate and prove the NP-completeness of the optimal monitor activation problem and present its Integer Linear Program (ILP) formulation. Furthermore, we propose a novel heuristic whose solution quality is verified by comparing it with an ILP. Extensive simulation results provide supporting analysis and comparisons of achievable alarm-vector reduction, localization coverage, and time complexity, for flat and hierarchically distributed monitoring approaches. The impact of network connectivity on fault localization complexity in randomly generated topologies is also studied. Results demonstrate the effectiveness of the proposed technique in efficient and scalable monitoring of transparent optical networks.","All-optical networks,
Condition monitoring,
Optical fiber networks,
Scalability,
Optical devices,
Network topology,
Optical fiber devices,
Protocols,
Bandwidth,
Computer science"
Secure network coding for multi-resolution wireless video streaming,"Emerging practical schemes indicate that algebraic mixing of different packets by means of random linear network coding can increase the throughput and robustness of streaming services over wireless networks. However, concerns with the security of wireless video, in particular when only some of the users are entitled to the highest quality, have uncovered the need for a network coding scheme capable of ensuring different levels of confidentiality under stringent complexity requirements. We show that the triple goal of hierarchical fidelity levels, robustness against wireless packet loss and efficient security can be achieved by exploiting the algebraic structure of network coding. The key idea is to limit the encryption operations to a critical set of network coding coefficients in combination with multi-resolution video coding. Our contributions include an information-theoretic security analysis of the proposed scheme, a basic system architecture for hierarchical wireless video with network coding and simulation results.","Network coding,
Communication system security,
Streaming media,
Robustness,
Information security,
Throughput,
Wireless networks,
Cryptography,
Video coding,
Information analysis"
On the Efficacy of Frequency Hopping in Coping with Jamming Attacks in 802.11 Networks,"Frequency hopping (FH) has been the most popularly considered approach for alleviating the effects of jamming attacks. We re-examine, the efficacy of FH based on both experimentation and analysis. Briefly, the limitations of FH are: (a) the energy spill over between adjacent channels that are considered to be orthogonal, and (b) the small number of available orthogonal bands. In a nutshell, the main contributions of our work are: (a) Construction of a measurement-driven game theoretic framework which models the interactions between a jammer and a communication link employing FH. Our model accounts for the above limiting factors and provides bounds on the performance of proactive FH in coping with jamming. (b) Extensive experimentation to quantify the impact of a jammer on 802.11a/g/n networks. Interestingly, we find that 802.11n devices can be more vulnerable to jamming as compared with legacy devices. We carefully analyze the reasons behind this observation. (c) Application of our framework to quantify the efficacy of proactive FH and validation of our analytical bounds across various 802.11 network configurations. (d) Formal derivation of the optimal strategies for both the link and the jammer in 802.11 networks. Our results demonstrate that FH seems to be inadequate in coping with jamming attacks in current 802.11 networks.","Jamming,
IEEE 802.11 Standards,
Games,
Throughput,
Spread spectrum communication,
Wireless communication,
Switches"
An eye tracking study on the effects of layout in understanding the role of design patterns,"The effect of layout in the comprehension of design pattern roles in UML class diagrams is assessed. This work replicates and extends a previous study using questionnaires but uses an eye tracker to gather additional data. The purpose of the replication is to gather more insight into the eye gaze behavior not evident from questionnaire-based methods. Similarities and differences between the studies are presented. Four design patterns are examined in two layout schemes in the context of three open source systems. Fifteen participants answered a series of eight design pattern role detection questions. Results show a significant improvement in role detection accuracy and visual effort with a certain layout for the Strategy and Observer patterns and a significant improvement in role detection time for all four patterns. Eye gaze data indicates classes participating in a design pattern act like visual beacons when they are in close physical proximity and follow the canonical layout, even though they violate some general graph aesthetics.","Layout,
Visualization,
Accuracy,
Unified modeling language,
Observers,
Tracking,
Area measurement"
Designing airfoils using a reference point based evolutionary many-objective particle swarm optimization algorithm,"In this paper, we illustrate the use of a reference point based many-objective particle swarm optimization algorithm to optimize low-speed airfoil aerodynamic designs. Our framework combines a flexible airfoil parameterization scheme and a computational flow solver in the evaluation of particles. Each particle, which represents a set of decision variables, is passed through this framework to construct and evaluate the airfoils and assign fitness. We used the baseline NLF0416 airfoil to obtain aspiration values, which are used to define the reference point. This reference point guides the swarm towards the preferred region of the objective landscape to find solutions of interest to the decision maker. The proficiency of the algorithm is highlighted by monitoring convergence and spread of solution using a hyper-volume calculation scheme suitable for user-preference based evolutionary many-objective algorithms. The results comparing the reference point based approach with a standard unguided non-dominated sorting based approach shows that the guided algorithm performs better in this many-objective problem instance. Final solutions found from the reference point based algorithm reveal an evident improvement over the NLF0416 airfoil across all operating conditions.","Automotive components,
Measurement,
Algorithm design and analysis,
Shape,
Unmanned aerial vehicles,
Lead,
Aerodynamics"
Evolutionary Cross-Domain Discriminative Hessian Eigenmaps,"Is it possible to train a learning model to separate tigers from elks when we have 1) labeled samples of leopard and zebra and 2) unlabelled samples of tiger and elk at hand? Cross-domain learning algorithms can be used to solve the above problem. However, existing cross-domain algorithms cannot be applied for dimension reduction, which plays a key role in computer vision tasks, e.g., face recognition and web image annotation. This paper envisions the cross-domain discriminative dimension reduction to provide an effective solution for cross-domain dimension reduction. In particular, we propose the cross-domain discriminative Hessian Eigenmaps or CDHE for short. CDHE connects training and test samples by minimizing the quadratic distance between the distribution of the training set and that of the test set. Therefore, a common subspace for data representation can be well preserved. Furthermore, we basically expect the discriminative information used to separate leopards and zebra can be shared to separate tigers and elks, and thus we have a chance to duly address the above question. Margin maximization principle is adopted in CDHE so the discriminative information for separating different classes (e.g., leopard and zebra here) can be well preserved. Finally, CDHE encodes the local geometry of each training class (e.g., leopard and zebra here) in the local tangent space which is locally isometric to the data manifold and thus CDHE preserves the intraclass local geometry. The objective function of CDHE is not convex, so the gradient descent strategy can only find a local optimal solution. In this paper, we carefully design an evolutionary search strategy to find a better solution of CDHE. Experimental evidence on both synthetic and real word image datasets demonstrates the effectiveness of CDHE for cross-domain web image annotation and face recognition.","Face recognition,
Shape,
Testing,
Geometry,
Computer vision,
Data analysis,
Pattern classification,
Research and development,
Computer science education,
Computer science"
"Tunable Wavelength Conversion by XPM in a Silicon Nanowire, and the Potential for XPM-Multicasting","Tunable wavelength conversion of a 10-Gb/s, return-to-zero on-off-keyed (RZ-OOK) signal has been carried out in a silicon (Si) nanowire waveguide (Si nanowire) using a pump-probe configuration and cross-phase modulation (XPM), followed by a tunable filter. This filter spectrally emulated the pass-band of a commercial 50-GHz DWDM arrayed waveguide grating (AWG). The tunability of the wavelength conversion process was demonstrated over a range of 20 nm, limited only by the amplifiers and the filter, while keeping the 10-9-BER receiver sensitivity penalty of the converted signal to a 0.5-dB maximum. A comprehensive model of wavelength conversion by XPM (XPM-WC) was developed, which took into account two-photon absorption, the Kerr effect, and free-carrier generation. The results of the model demonstrate good agreement with the experiment, especially with respect to the observed spectral broadening. The numerical model was also used to assess the dominant contribution among the various mechanisms within the context of XPM-WC, and to investigate the potential of multicasting by XPM in the nanowire.","Silicon,
Probes,
Optical wavelength conversion,
Optical waveguides,
Semiconductor optical amplifiers,
Arrayed waveguide gratings,
Optical modulation,
Optical filters,
Wire,
Laboratories"
Online algorithms for the multi-armed bandit problem with Markovian rewards,"We consider the classical multi-armed bandit problem with Markovian rewards. When played an arm changes its state in a Markovian fashion while it remains frozen when not played. The player receives a state-dependent reward each time it plays an arm. The number of states and the state transition probabilities of an arm are unknown to the player. The player's objective is to maximize its long-term total reward by learning the best arm over time. We show that under certain conditions on the state transition probabilities of the arms, a sample mean based index policy achieves logarithmic regret uniformly over the total number of trials. The result shows that sample mean based index policies can be applied to learning problems under the rested Markovian bandit model without loss of optimality in the order. Moreover, comparision between Anantharam's index policy and UCB shows that by choosing a small exploration parameter UCB can have a smaller regret than Anantharam's index policy.","Markov processes,
Indexes,
Silicon,
Eigenvalues and eigenfunctions,
Space stations,
Context,
Numerical models"
Task Scheduling in Multiprocessor System Using Genetic Algorithm,"The general problem of multiprocessor scheduling can be stated as scheduling a task graph onto a multiprocessor system so that schedule length can be optimized. Task scheduling in multiprocessor system is a NP-complete problem. In literature, several heuristic methods have been developed that obtain suboptimal solutions in less than the polynomial time. Recently, Genetic algorithms have received much awareness as they are robust and guarantee for a good solution. In this paper, we have developed a genetic algorithm based on the principles of evolution found in nature for finding an optimal solution. Genetic algorithm is based on three operators: Natural Selection, Crossover and Mutation. To compare the performance of our algorithm, we have also implemented another scheduling algorithm HEFT which is a heuristic algorithm. Simulation results comprises of three parts: Quality of solutions, robustness of genetic algorithm, and effect of mutation probability on performance of genetic algorithm.","Multiprocessing systems,
Genetic algorithms,
Processor scheduling,
Scheduling algorithm,
Genetic mutations,
Dynamic scheduling,
Clustering algorithms,
Computer science,
Robustness,
Heuristic algorithms"
Asymptotic Mean and Variance of Gini Correlation for Bivariate Normal Samples,"This paper derives the asymptotic analytical forms of the mean and variance of the Gini correlation (GC) with respect to samples drawn from bivariate normal populations. The asymptotic relative efficiency (ARE) of the Gini correlation to Pearson's product moment correlation coefficient (PPMCC) is investigated under the normal assumptions. To gain further insight into GC, we also compare the Gini correlation to other two closely related correlation coefficients, namely, the order statistics correlation coefficient (OSCC) and Spearman's rho (SR). Theoretical and simulation results suggest that the performance of GC lies in between those of OSCC and SR when estimating the correlation coefficient of the bivariate normal population. The newly found theoretical results along with other desirable properties enable GC to be a useful alternative to the existing coefficients, especially when one wants to make a trade-off between the efficiency and robustness to monotone nonlinearity.","Strontium,
Statistics,
Robustness,
Robust stability,
Analysis of variance,
Signal analysis,
Signal processing,
Random variables,
Probability distribution,
Computer science"
Development of a pneumatic robot for MRI-guided transperineal prostate biopsy and brachytherapy: New approaches,"Magnetic Resonance Imaging (MRI) guided prostate biopsy and brachytherapy has been introduced in order to enhance the cancer detection and treatment. For the accurate needle positioning, a number of robotic assistants have been developed. However, problems exist due to the strong magnetic field and limited workspace. Pneumatically actuated robots have shown the minimum distraction in the environment but the confined workspace limits optimal robot design and thus controllability is often poor. To overcome the problem, a simple external damping mechanism using timing belts was sought and a 1-DOF mechanism test result indicated sufficient positioning accuracy. Based on the damping mechanism and modular system design approach, a new workspace-optimized 4-DOF parallel robot was developed for the MRI-guided prostate biopsy and brachytherapy. A preliminary evaluation of the robot was conducted using previously developed pneumatic controller and satisfying results were obtained.","Robots,
Biopsy,
Brachytherapy,
Magnetic resonance imaging,
Damping,
Cancer detection,
Needles,
Magnetic fields,
Magnetic confinement,
Controllability"
Interactive volumetric lighting simulating scattering and shadowing,"In this paper we present a volumetric lighting model, which simulates scattering as well as shadowing in order to generate high quality volume renderings. By approximating light transport in inhomogeneous participating media, we are able to come up with an efficient GPU implementation, in order to achieve the desired effects at interactive frame rates. Moreover, in many cases the frame rates are even higher as those achieved with conventional gradient-based shading. To evaluate the impact of the proposed illumination model on the spatial comprehension of volumetric objects, we have conducted a user study, in which the participants had to perform depth perception tasks. The results of this study show, that depth perception is significantly improved when comparing our illumination model to conventional gradient-based volume shading. Additionally, since our volumetric illumination model is not based on gradient calculation, it is also less sensitive to noise and therefore also applicable to imaging modalities incorporating a higher degree of noise, as for instance magnet resonance tomography or 3D ultrasound.","Light scattering,
Shadow mapping,
Lighting,
Resonance light scattering,
Computed tomography,
Ultrasonic imaging,
Computer graphics,
Mice,
Visualization,
Magnetic separation"
Recovery-driven design: A power minimization methodology for error-tolerant processor modules,"Conventional CAD methodologies optimize a processor module for correct operation, and prohibit timing violations during nominal operation. In this paper, we propose recovery-driven design, a design approach that optimizes a processor module for a target timing error rate instead of correct operation. We show that significant power benefits are possible from a recovery-driven design flow that deliberately allows errors caused by voltage overscaling to occur during nominal operation, while relying on an error recovery technique to tolerate these errors. We present a detailed evaluation and analysis of such a CAD methodology that minimizes the power of a processor module for a target error rate. We demonstrate power benefits of up to 25%, 19%, 22%, 24%, 20%, 28%, and 20% versus traditional P&R at error rates of 0.125%, 0.25%, 0.5%, 1%, 2%, 4%, and 8%, respectively. Coupling recovery-driven design with an error recovery technique enables increased efficiency and additional power savings.","Minimization methods,
Error analysis,
Error correction,
Voltage,
Design automation,
Timing,
Hardware,
Circuits,
Design optimization,
Computer applications"
On Energy Efficient Encryption for Video Streaming in Wireless Sensor Networks,"Selective encryption for video streaming was proposed for efficient multimedia content protection. However, the issues on joint optimization of video quality, content protection, and communication energy efficiency in a wireless sensor network (WSN) have not been fully addressed in the literature. In this paper, we propose a scheme to optimize the energy, distortion, and encryption performance of video streaming in WSNs. The contribution of this work is twofold. First, a channel-aware selective encryption approach is proposed to minimize the extra encryption dependency overhead at the application layer. Second, an unequal error protection (UEP)-based network resource allocation scheme is proposed to improve the communication efficiency at the lower layers. Simulation experiments demonstrate that the proposed joint selective encryption and resource allocation scheme can improve the video transmission quality significantly with guaranteed content protection and energy efficiency.",
BiDirectional optical communication with AquaOptical II,"This paper describes AquaOptical II, a bidirectional, high data-rate, long-range, underwater optical communication system. The system uses the software radio principle. Each AquaOptical II modem can be programmed to transmit user defined waveforms and record the received waveforms for detailed analysis. This allows for the use of many different modulation schemes. We describe the hardware and software architecture we developed for these goals. We demonstrate bidirectional communication between two AquaOptical II modems in a pool experiment. During the experiment AquaOptical II achieved a signal to noise ration of 5.1 over a transmission distance of 50 m at pulse widths of 1 µsec, 500 ns, and 250 ns. When using discrete pulse interval modulation (DPIM) this corresponds to a bit-rate of 0.57 Mbit/s, 1.14 Mbit/s, and 2.28 Mbit/s.","Modems,
Field programmable gate arrays,
Optical sensors,
Software,
Optical receivers,
High speed optical techniques,
Optical fiber communication"
3D Nonlinear Super-Resolution Microwave Inversion Technique Using Time-Domain Data,"A nonlinear three-dimensional full-wave inverse scattering method using time-domain data and models is presented. It successfully reconstructs 3D images of various unknown objects using time-domain data. The method uses Born-type iterations and a constrained minimization to reconstruct successively improved images. The use of time-domain data allows very few transmitters and receivers to be used. It is shown that this technique achieves super-resolution, namely 0.1 wavelength. The method is able to recover contrasts of over 2:1. It can also recover objects with minute contrasts of as low as 10%, thus taking a step towards addressing recent findings in the breast cancer imaging community, for example, that some breast tumors have only a 10% contrast with respect to the glandular tissues. This method could present a promising tool for the early-stage breast cancer detection as well as other medical and subsurface imaging applications.","Microwave theory and techniques,
Time domain analysis,
Image reconstruction,
Breast cancer,
Inverse problems,
Minimization methods,
Transmitters,
Breast tumors,
Cancer detection,
Biomedical imaging"
Fast and robust object segmentation with the Integral Linear Classifier,"We propose an efficient method, built on the popular Bag of Features approach, that obtains robust multiclass pixellevel object segmentation of an image in less than 500ms, with results comparable or better than most state of the art methods. We introduce the Integral Linear Classifier (ILC), that can readily obtain the classification score for any image sub-window with only 6 additions and 1 product by fusing the accumulation and classification steps in a single operation. In order to design a method as efficient as possible, our building blocks are carefully selected from the quickest in the state of the art. More precisely, we evaluate the performance of three popular local descriptors, that can be very efficiently computed using integral images, and two fast quantization methods: the Hierarchical K-Means, and the Extremely Randomized Forest. Finally, we explore the utility of adding spatial bins to the Bag of Features histograms and that of cascade classifiers to improve the obtained segmentation. Our method is compared to the state of the art in the difficult Graz-02 and PASCAL 2007 Segmentation Challenge datasets.","Robustness,
Object segmentation,
Histograms,
Pixel,
Image segmentation,
Feature extraction,
Computer vision,
Computer science,
Artificial intelligence,
Quantization"
Fuzzy Clustering With Viewpoints,"In this study, we introduce a certain knowledge-guided scheme of fuzzy clustering in which domain knowledge is represented in the form of so-called viewpoints. Viewpoints capture a way in which the user introduces his/her point of view at the data by identifying some representatives, which, being treated as externally introduced prototypes, have to be included in the clustering process. More formally, the viewpoints (views) augment the original, data-based objective function by including the term that expresses distances between data and the viewpoints. Depending upon the nature of domain knowledge, the viewpoints are represented either in a plain numeric format (considering that there is a high level of specificity with regard to how one establishes perspective from which the data need to be analyzed) or through some information granules (which reflect a more relaxed way in which the views at the data are being expressed). The detailed optimization schemes are presented, and the performance of the method is illustrated through some numeric examples. We also elaborate on a way in which the clustering with viewpoints enhances fuzzy models and mechanisms of decision making in the sense that the resulting constructs reflect the preferences and requirement that are present in the modeling environment.","Prototypes,
Clustering algorithms,
Fuzzy sets,
Information analysis,
Optimization methods,
Decision making,
Supervised learning,
Taxonomy,
Unsupervised learning,
Modeling"
Attack and Flee: Game-Theory-Based Analysis on Interactions Among Nodes in MANETs,"In mobile ad hoc networks, nodes have the inherent ability to move. Aside from conducting attacks to maximize their utility and cooperating with regular nodes to deceive them, malicious nodes get better payoffs with the ability to move. In this paper, we propose a game theoretic framework to analyze the strategy profiles for regular and malicious nodes. We model the situation as a dynamic Bayesian signaling game and analyze and present the underlining connection between nodes' best combination of actions and the cost and gain of the individual strategy. Regular nodes consistently update their beliefs based on the opponents' behavior, while malicious nodes evaluate their risk of being caught to decide when to flee. Some possible countermeasures for regular nodes that can impact malicious nodes' decisions are presented as well. An extensive analysis and simulation study shows that the proposed equilibrium strategy profile outperforms other pure or mixed strategies and proves the importance of restricting malicious nodes' advantages brought by the flee option.","Mobile ad hoc networks,
Game theory,
Bayesian methods,
Costs,
Signal analysis,
Analytical models,
Uncertainty,
Collaboration,
Network topology"
Decoding Frequency Permutation Arrays Under Chebyshev Distance,"A frequency permutation array (FPA) of length n = mλ and distance d is a set of permutations on a multiset over m symbols, where each symbol appears exactly λ times and the distance between any two elements in the array is at least d. FPA generalizes the notion of permutation array. In this paper, under the Chebyshev distance, we first prove lower and upper bounds on the size of FPA. Then we give several constructions of FPAs, and some of them come with efficient encoding and decoding capabilities. Moreover, we show one of our designs is locally decodable, i.e., we can decode a message bit by reading at most λ+1 symbols, which has an interesting application to private information retrieval.","Decoding,
Encoding,
Ash,
Chebyshev approximation,
Upper bound,
Information rates,
Symmetric matrices"
Compliant Modular Shape Memory Alloy Actuators,"We have presented a simple but effective method to design flexible actuators. This process relies on understanding the behavior of a simple unit cell element built out of SMA sheet. The unit cell effectively uses the properties of flat SMA sheets: it operates in the bent region where more force is generated; it minimizes the nonbent SMA; and it heats up only the bent regions. However, the force generated by this unit cell does not scale up well, and an array of them is needed to increase the force generated. Building an actuator out of an array of unit cells increases its complexity but provides advantages, including the control of expansion length, trajectory, and generated force. Given the current technologies, including 3-D printing and laser cutting, a variety of support structures can be built to create an actuator with a given behavior. We have shown three types of configurations: linear, rotational, and surface. The linear actuator has been tested for endurance and can easily perform over 10,000 repetitions under load without breaking. These actuators have been tested in actual systems, such as the battery-operated HexRoller robot that uses six actuators connected in a chain. The robot demonstrates that this SMA actuator is power efficient compared with other SMA designs that cannot operate with batteries. We have also showed that a rotational version of this type of actuator is comparable with an electromagnetic motor.","Actuators,
Force,
Robots,
Heating,
Materials,
Force measurement,
Wires"
Exploring power-performance tradeoffs in database systems,"With the total energy consumption of computing systems increasing in a steep rate, much attention has been paid to the design of energy-efficient computing systems and applications. So far, database system design has focused on improving performance of query processing. The objective of this study is to experimentally explore the potential of power conservation in relational database management systems. We hypothesize that, by modifying the query optimizer in a DBMS to take the power cost of query plans into consideration, we will be able to reduce the power usage of database servers and control the tradeoffs between power consumption and system performance. We also identify the sources of such savings by investigating the resource consumption features during query processing in DBMSs. To that end, we provide an in-depth anatomy and qualitatively analyze the power profile of typical queries in the TPC benchmarks. We perform extensive experiments on a physical testbed based on the PostgreSQL system using workloads generated from the TPC benchmarks. Our hypothesis is supported by such experimental results: power savings in the range of 11% - 22% can be achieved by equipping the DBMS with a query optimizer that selects query plans based on both estimated processing time and power requirements.1","Database systems,
Energy consumption,
Query processing,
Relational databases,
Benchmark testing,
Energy efficiency,
Computer applications,
Energy management,
Power system management,
Cost function"
Single image deblurring with adaptive dictionary learning,"We propose a motion deblurring algorithm that exploits sparsity constraints of image patches using one single frame. In our formulation, each image patch is encoded with sparse coefficients using an over-complete dictionary. The sparsity constraints facilitate recovering the latent image without solving an ill-posed deconvolution problem. In addition, the dictionary is learned and updated directly from one single frame without using additional images. The proposed method iteratively utilizes sparsity constraints to recover latent image, estimates the deblur kernel, and updates the dictionary directly from one single image. The final deblurred image is then recovered once the deblur kernel is estimated using our method. Experiments show that the proposed algorithm achieves favorable results against the state-of-the-art methods.",
A novel riemannian framework for shape analysis of 3D objects,"In this paper we introduce a novel Riemannian framework for shape analysis of parameterized surfaces. We derive a distance function between any two surfaces that is invariant to rigid motion, global scaling, and re-parametrization. It is the last part that presents the main difficulty. Our solution to this problem is twofold: (1) we define a special representation, called a q-map, to represent each surface, and (2) we develop a gradient-based algorithm to optimize over different re-parameterizations of a surface. The second step is akin to deforming the mesh on a fixed surface to optimize its placement. (This is different from the current methods that treat the given meshes as fixed.) Under the chosen representation, with the L2 metric, the action of the re-parametrization group is by isometries. This results in, to our knowledge, the first Riemannian distance between parameterized surfaces to have all the desired invariances. We demonstrate this framework with several examples using some toy shapes, and real data with anatomical structures, and cropped facial surfaces. We also successfully demonstrate clustering and classification of these objects under the proposed metric.","Shape,
Surface treatment,
Image analysis,
Surface reconstruction,
Statistical analysis,
Anatomical structure,
Humans,
Mathematics,
Optimization methods,
Computer displays"
Despeckling of TerraSAR-X Data Using Second-Generation Wavelets,"This letter presents the despeckling of synthetic aperture radar (SAR) images within the bandelet and contourlet domains. A model-based approach is presented for the despeckling of SAR images. The speckle-reduced estimate is found using the first-order Bayesian inference, and the best model's parameters are estimated using the second-order Bayesian inference. Synthetic and real images are used for evaluating the qualities of the despeckling methods. The experimental results showed that the combination of Bayesian inference and bandelet transform outperforms the contourlet-based despeckling algorithm using synthetic data and objective measurements.","Bayesian methods,
Wavelet domain,
Filters,
Signal processing algorithms,
Synthetic aperture radar,
Parameter estimation,
Inference algorithms,
Speckle,
Wavelet transforms,
Layout"
Codes for Computationally Simple Channels: Explicit Constructions with Optimal Rate,"In this paper, we consider coding schemes for computationally bounded channels, which can introduce an arbitrary set of errors as long as (a) the fraction of errors is bounded with high probability by a parameter p and (b) the process which adds the errors can be described by a sufficiently ""simple"" circuit. Codes for such channel models are attractive since, like codes for standard adversarial errors, they can handle channels whose true behavior is unknown or varying over time. For three classes of channels, we provide explicit, efficiently encodable/decodable codes of optimal rate where only inefficiently decodable codes were previously known. In each case, we provide one encoder/decoder that works for every channel in the class. Unique decoding for additive errors: We give the first construction of a poly-time encodable/decodable code for additive (a.k.a. oblivious) channels that achieve the Shannon capacity 1-H(p). List-decoding for online log-space channels: A space-S(N) bounded channel reads and modifies the transmitted codeword as a stream, using at most S(N) bits of workspace on transmissions of N bits. For constant S, this captures many models from the literature, including ""discrete channels with finite memory"" and ""arbitrarily varying channels"". We give an efficient code with optimal rate (arbitrarily close to 1-H(p)) that recovers a short list containing the correct message with high probability for channels which read and modify the transmitted codeword as a stream, using at most O(\log N) bits of workspace on transmissions of N bits. List-decoding for poly-time channels: For any constant c we give a similar list-decoding result for channels describable by circuits of size at most N^c, assuming the existence of pseudorandom generators.","Decoding,
Additives,
Stochastic processes,
Channel coding,
Automatic voltage control,
Polynomials"
Fault-tolerant and reliable computation in cloud computing,"Cloud computing, with its great potentials in low cost and on-demand services, is a promising computing platform for both commercial and non-commercial computation clients. In this work, we investigate the security perspective of scientific computation in cloud computing. We investigate a cloud selection strategy to decompose the matrix multiplication problem into several tasks which will be submitted to different clouds. In particular, we propose techniques to improve the fault-tolerance and reliability of a rather general scientific computation: matrix multiplication. Through our techniques, we demonstrate that fault-tolerance and reliability against faulty and even malicious clouds in cloud computing can be achieved.","Cloud computing,
Fault tolerance,
Fault tolerant systems,
Security,
Browsers,
Servers"
Assessing the Uniqueness and Permanence of Facial Actions for Use in Biometric Applications,"Although the human face is commonly used as a physiological biometric, very little work has been done to exploit the idiosyncrasies of facial motions for person identification. In this paper, we investigate the uniqueness and permanence of facial actions to determine whether these can be used as a behavioral biometric. Experiments are carried out using 3-D video data of participants performing a set of very short verbal and nonverbal facial actions. The data have been collected over long time intervals to assess the variability of the subjects' emotional and physical conditions. Quantitative evaluations are performed for both the identification and the verification problems; the results indicate that emotional expressions (e.g., smile and disgust) are not sufficiently reliable for identity recognition in real-life situations, whereas speech-related facial movements show promising potential.","Biometrics,
Face recognition,
Humans,
Pattern recognition,
Computer science,
Face detection,
Magnetic heads,
Lighting,
Performance evaluation,
Emotion recognition"
Image segmentation using fuzzy clustering: A survey,"This paper presents a survey of latest image segmentation techniques using fuzzy clustering. Fuzzy C-Means (FCM) Clustering is the most wide spread clustering approach for image segmentation because of its robust characteristics for data classification. In this paper, four image segmentation algorithms using clustering, taken from the literature are reviewed. To address the drawbacks of conventional FCM, all these approaches have modified the objective function of conventional FCM and have incorporated spatial information in the objective function of the standard FCM. The techniques that have been reviewed in this survey are Segmentation for noisy medical images with spatial probability, Novel Fuzzy C-Means Clustering (NFCM), Fuzzy Local Information C-Means (FLICM) Clustering Algorithm and Improved Spatial Fuzzy C-Means Clustering (ISFCM) algorithm.","Image segmentation,
Clustering algorithms,
Pixel,
Robustness,
Noise,
Classification algorithms,
Biomedical imaging"
A Level Set Formulation of Geodesic Curvature Flow on Simplicial Surfaces,"Curvature flow (planar geometric heat flow) has been extensively applied to image processing, computer vision, and material science. To extend the numerical schemes and algorithms of this flow on surfaces is very significant for corresponding motions of curves and images defined on surfaces. In this work, we are interested in the geodesic curvature flow over triangulated surfaces using a level set formulation. First, we present the geodesic curvature flow equation on general smooth manifolds based on an energy minimization of curves. The equation is then discretized by a semi-implicit finite volume method (FVM). For convenience of description, we call the discretized geodesic curvature flow as dGCF. The existence and uniqueness of dGCF are discussed. The regularization behavior of dGCF is also studied. Finally, we apply our dGCF to three problems: the closed-curve evolution on manifolds, the discrete scale-space construction, and the edge detection of images painted on triangulated surfaces. Our method works for compact triangular meshes of arbitrary geometry and topology, as long as there are no degenerate triangles. The implementation of the method is also simple.","Level set,
Image edge detection,
Image processing,
Computer vision,
Materials science and technology,
Equations,
Surface morphology,
Geometry,
Topology,
Image segmentation"
Security in multi-tenancy cloud,"Cloud computing creates exciting opportunities like reduced costs and flexibility to the users. It also comprises of some risks like data security within the cloud. Several common security threats like data leakage, insecure API's, and malicious inside users are applicable to cloud computing environment as well. In this paper, the authors consider a cloud computing service where multiple Virtual Machines (VM's) are co-located on the same physical server. In such systems, physical resources are transparently shared by the VMs belonging to multiple users. In systems like these, a malicious user having control of a VM can try to gain control over other VM's resources or utilize all system resources leading to denial of resource attack over other VM users. A malicious user can also try to steal the data of other users located on the same server by compromising hypervisor file system (logical volumes). In this paper, security threats associated with cloud computing environment are evaluated. Authors also explore how such co-existent of VM's can be exploited to gain access over other user's data or deny service and propose constructive security measures that can be deployed to avoid such attacks.","Virtual machine monitors,
Clouds,
Security,
Hardware,
Servers,
Software,
Cloud computing"
A Micromachined Nanopositioner With On-Chip Electrothermal Actuation and Sensing,"This letter describes the design of a micromachined nanopositioner with thermal actuation and sensing capabilities in a single chip. The positioner has a dynamic range of 14.4 m, and the sensor drift is 8.9 nm over 2000 s with a differential sensing scheme. The on-chip displacement sensing enables a feedback control capability. A proportional-integral feedback controller is designed and implemented digitally. The closed-loop step response results show a positioning resolution of 7.9 nm and a time constant of 1.6 ms.","Actuators,
Nanopositioning,
Micromechanical devices,
Resistance,
Thermal sensors,
Microscopy"
Clinical study of neurorehabilitation in stroke using EEG-based motor imagery brain-computer interface with robotic feedback,"This clinical study investigates the ability of hemiparetic stroke patients in operating EEG-based motor imagery brain-computer interface (MI-BCI). It also assesses the efficacy in motor improvements on the stroke-affected upper limb using EEG-based MI-BCI with robotic feedback neurorehabilitation compared to robotic rehabilitation that delivers movement therapy. 54 hemiparetic stroke patients with mean age of 51.8 and baseline Fugl-Meyer Assessment (FMA) 14.9 (out of 66, higher = better) were recruited. Results showed that 48 subjects (89%) operated EEG-based MI-BCI better than at chance level, and their ability to operate EEG-based MI-BCI is not correlated to their baseline FMA (r=0.358). Those subjects who gave consent are randomly assigned to each group (N=11 and 14) for 12 1-hour rehabilitation sessions for 4 weeks. Significant gains in FMA scores were observed in both groups at post-rehabilitation (4.5, 6.2; p=0.032, 0.003) and 2-month post-rehabilitation (5.3, 7.3; p=0.020, 0.013), but no significant differences were observed between groups (p=0.512, 0.550). Hence, this study showed evidences that a majority of hemiparetic stroke patients can operate EEG-based MI-BCI, and that EEG-based MI-BCI with robotic feedback neurorehabilitation is effective in restoring upper extremities motor function in stroke.","Robots,
Accuracy,
Brain computer interfaces,
Medical treatment,
Electroencephalography,
Calibration,
Extremities"
Quantum Dot Superluminescent Diodes for Optical Coherence Tomography: Skin Imaging,"We present a high-power (18 mW continuous wave exiting a single-mode fiber and 35 mW exiting the facet), broadband (85 nm full-width at half-maximum) quantum dot-based superluminescent diode, and apply it to a time-domain optical coherence tomography (OCT) setup. First, we test its performance with increasing optical feedback. Then we demonstrate its imaging properties on tissue-engineered (TE) skin and in vivo skin. OCT allows the tracking of epidermal development in TE skin, while the higher power source allows better sensitivity and depth penetration for imaging of in vivo skin layers.","Quantum dots,
Superluminescent diodes,
Tomography,
Skin,
Optical imaging,
Optical feedback,
Optical sensors,
Coherence,
Tellurium,
In vivo"
Interference alignment through staggered antenna switching for MIMO BC with no CSIT,"In this paper, we explore the degrees of freedom (DoF) of the broadcast channel (BC) where the transmitter is equipped with M antennas and there are K receivers, each equipped with N reconfigurable antennas capable of switching among M preset modes. Without any knowledge of the channel coefficient values but only receiver antenna switching modes at the transmitter, we propose an interference alignment scheme for this channel. We show that if N &#60; M, then a total of MNKoverM+KN−N DoF are achievable, almost surely. The key to this interference alignment scheme is the ability of the receivers to switch between reconfigurable antenna modes to create short term channel fluctuation patterns that are exploited by the transmitter. Compared to the results we showed for MISO BC [6], the supersymbol of MIMO BC may have diverse structures depending M and N, and it can be determined from that of MISO BC through an iterative mapping function.",
Modal Properties of Hybrid Plasmonic Waveguides for Nanolaser Applications,"We investigate the modal properties of nanowire-metal hybrid plasmonic waveguides by use of the coupled-mode theory and finite-element method. We show that the coupling between the nanowire fundamental HE11 mode and surface plasmon mode results in three different supermodes. We numerically calculate the dispersion relations, normalized mode areas, and confinement factors of these different modes for plasmonic nanolaser applications and show that the lowest threshold mode is determined by the waveguide geometry.",
A Computer-Aided Diagnosis System of Nuclear Cataract,"Cataracts are the leading cause of blindness worldwide, and nuclear cataract is the most common form of cataract. An algorithm for automatic diagnosis of nuclear cataract is investigated in this paper. Nuclear cataract is graded according to the severity of opacity using slit lamp lens images. Anatomical structure in the lens image is detected using a modified active shape model. On the basis of the anatomical landmark, local features are extracted according to clinical grading protocol. Support vector machine regression is employed for grade prediction. This is the first time that the nucleus region can be detected automatically in slit lamp images. The system is validated using clinical images and clinical ground truth on >5000 images. The success rate of structure detection is 95% and the average grading difference is 0.36 on a 5.0 scale. The automatic diagnosis system can improve the grading objectivity and potentially be used in clinics and population studies to save the workload of ophthalmologists.","Computer aided diagnosis,
Lenses,
Lamps,
Blindness,
Australia,
Proteins,
Retina,
Surgery,
Anatomical structure,
Active shape model"
Preventing black hole attack in mobile ad-hoc networks using Anomaly Detection,"Mobile ad-hoc networks are prone to a number of security threats. The fact that mobile ad-hoc networks lack fixed infrastructure and use wireless link for communication makes them very susceptible to an adversary's malicious attacks. Black hole attack is one of the severe security threats in ad-hoc networks which can be easily employed by exploiting vulnerability of on-demand routing protocols such as AODV. In this paper, we have proposed a solution based on Intrusion Detection using Anomaly Detection (IDAD) to prevent black hole attacks imposed by both single and multiple black hole nodes. Result of a simulation study proves the particular solution maximizes network performance by minimizing generation of control (routing) packets as well as effectively preventing black hole attacks against mobile ad-hoc networks.","Ad hoc networks,
Routing protocols,
Communication system security,
Telecommunication traffic,
Mobile computing,
Computer science,
Educational technology,
Computer science education,
Wireless communication,
Intrusion detection"
Roadside Units Deployment for Efficient Short-Time Certificate Updating in VANETs,"Roadside Units (RSUs) aided distributed certificate service is a promising approach for ensuring security and privacy preservation in vehicular ad hoc networks (VANETs), where the existence of RSUs is critical for such a scheme in order to allow On-Board Units (OBUs) to update their short-time certificates on time. However, RSUs may only be deployed at some critical points along roads due to the cost. In this paper, we propose a cost-efficient RSUs deployment scheme to guarantee that OBUs at any place could communicate with RSUs in certain driving time (DT), and the extra overhead time (ET) of adjusting routes to update short-time certificate is small. Based on a real-world map, several deployment examples are given illustrating the influence of key factors in RSUs deployment such as wireless communication range, DT and ET. Furthermore, extensive analysis demonstrates that our RSUs deployment scheme can meet the required design goals.","Privacy,
Information security,
Ad hoc networks,
Costs,
Wireless communication,
Vehicles,
Authentication,
Communications Society,
Computer science,
Paper technology"
Bridging Domains Using World Wide Knowledge for Transfer Learning,"A major problem of classification learning is the lack of ground-truth labeled data. It is usually expensive to label new data instances for training a model. To solve this problem, domain adaptation in transfer learning has been proposed to classify target domain data by using some other source domain data, even when the data may have different distributions. However, domain adaptation may not work well when the differences between the source and target domains are large. In this paper, we design a novel transfer learning approach, called BIG (Bridging Information Gap), to effectively extract useful knowledge in a worldwide knowledge base, which is then used to link the source and target domains for improving the classification performance. BIG works when the source and target domains share the same feature space but different underlying data distributions. Using the auxiliary source data, we can extract a ¿bridge¿ that allows cross-domain text classification problems to be solved using standard semisupervised learning algorithms. A major contribution of our work is that with BIG, a large amount of worldwide knowledge can be easily adapted and used for learning in the target domain. We conduct experiments on several real-world cross-domain text classification tasks and demonstrate that our proposed approach can outperform several existing domain adaptation approaches significantly.","Data mining,
Text categorization,
Wikipedia,
Information retrieval,
Semisupervised learning,
Content based retrieval,
Web search,
Supervised learning,
Terminology,
Knowledge transfer"
"Switch-and-Examine Diversity Over Arbitrarily Correlated Nakagami-
m
Fading Channels","The performance of switch-and-examine diversity (SED) over L arbitrarily correlated and not necessarily identically distributed Nakagami-m fading channels is studied. Analytical expressions for the distribution of the SED output signal-to-noise ratio (SNR) are obtained for the constant correlation model. For the most general case of arbitrary correlation, by assuming half-integer or integer values for the fading parameter m, analytical expressions for the distribution of the output SNR with L ¿ 3 are derived. Moreover, for L > 3, analytical approximations for the output SNR are presented. The derived expressions are used to study the outage and average symbol error probability of SED receivers. Performance results obtained by numerical evaluation and verified by means of computer simulations show that the performance of the receivers under consideration is degraded with increasing branch correlation. Nevertheless, SED receivers outperform uncorrelated switch-and-stay diversity receivers, even when they operate under high branch correlation.","Fading,
Error probability,
Channel estimation,
Data communication,
Wireless communication,
Informatics,
Space technology,
Switches,
Senior members,
Signal analysis"
Improved GPS sensor model for mobile robots in urban terrain,"Autonomous robot navigation in out-door scenarios gains increasing importance in various growing application areas. Whereas in non-urban domains such as deserts the problem of successful GPS-based navigation appears to be almost solved, navigation in urban domains particularly in the close vicinity of buildings is still a challenging problem. In such situations GPS accuracy significantly drops down due to multiple signal reflections with larger objects causing the so-called multipath error. In this paper we contribute a novel approach for incorporating multipath errors into the conventional GPS sensor model by analyzing environmental structures from online generated point clouds. The approach has been validated by experimental results conducted with an allterrain robot operating in scenarios requiring close-to-building navigation. Presented results show that positioning accuracy can significantly be improved within urban domains.",
Improved solar PV cell Matlab simulation model and comparison,This paper presents an improved mathematical and simulation model for Solar Photovoltaic (PV) cells and compares it to an existing model. The model is able to simulate both the I-V characteristics curves and the P-V characteristics curves. The model is used to study different parameters variations effects on the PV array including operating temperature and solar irradiation level The results of the PV characteristics curves are compared to the curves provided by BPSX150 PV module datasheet. Matlab®/Simulink® software is used to implement the models and obtain the simulation results.,"Mathematical model,
Solar power generation,
Power system modeling,
Computational modeling,
Solar energy,
Photovoltaic systems,
Temperature,
Power generation,
Circuit simulation,
Equivalent circuits"
Shortest Path Refinement for Motion Estimation From Tagged MR Images,"Magnetic resonance tagging makes it possible to measure the motion of tissues such as muscles in the heart and tongue. The harmonic phase (HARP) method largely automates the process of tracking points within tagged MR images, permitting many motion properties to be computed. However, HARP tracking can yield erroneous motion estimates due to 1) large deformations between image frames, 2) through-plane motion, and 3) tissue boundaries. Methods that incorporate the spatial continuity of motion-so-called refinement or flood-filling methods-have previously been reported to reduce tracking errors. This paper presents a new refinement method based on shortest path computations. The method uses a graph representation of the image and seeks an optimal tracking order from a specified seed to each point in the image by solving a single source shortest path problem. This minimizes the potential errors for those path dependent solutions that are found in other refinement methods. In addition to this, tracking in the presence of through-plane motion is improved by introducing synthetic tags at the reference time (when the tissue is not deformed). Experimental results on both tongue and cardiac images show that the proposed method can track the whole tissue more robustly and is also computationally efficient.","Motion estimation,
Tracking,
Tongue,
Magnetic resonance,
Tagging,
Motion measurement,
Muscles,
Heart,
Yield estimation,
Shortest path problem"
C-Band Polarimetric Backscattering Signatures of Newly Formed Sea Ice During Fall Freeze-Up,"A study of the polarimetric backscattering response of newly formed sea ice types under a large assortment of surface coverage was conducted using a ship-based C-band polarimetric radar system. Polarimetric backscattering results and physical data for 40 stations during the fall freeze-up of 2003, 2006, and 2007 are presented. Analysis of the copolarized correlation coefficient showed its sensitivity to both sea ice thickness and surface coverage and resulted in a statistically significant separation of ice thickness into two regimes: ice less than 6 cm thick and ice greater than 8 cm thick. A case study quantified the backscatter of a layer of snow infiltrated frost flowers on new sea ice, showing that the presence of the old frost flowers can enhance the backscatter by more than 6 dB. Finally, a statistical analysis of a series of temporal-spatial measurements over a visually homogeneous frost-flower-covered ice floe identified temperature as a significant, but not exclusive, factor in the backscattering measurements.",
Hybrid Map Task Scheduling for GPU-Based Heterogeneous Clusters,"MapReduce is a programming model that enables efficient massive data processing in large-scale computing environments such as supercomputers and clouds. Such large-scale computers employ GPUs to enjoy its good peak performance and high memory bandwidth. Since the performace of each job is depending on running application characteristics and underlying computing environments, scheduling MapReduce tasks onto CPU cores and GPU devices for efficient execution is difficult. To address this problem, we have proposed a hybrid scheduling technique for GPU-based computer clusters, which minimizes the execution time of a submitted job using dynamic profiles of Map tasks running on CPU cores and GPU devices. We have implemented a prototype of our proposed scheduling technique by extending MapReduce framework, Hadoop. We have conducted some experiments for this prototype by using a K-means application as a benchmark on a supercomputer. The results show that the proposed technique achieves 1.93 times faster than the Hadoop original scheduling algorithm at 64 nodes (1024 CPU cores and 128 GPU devices). The results also indicate that the performance of map tasks, including both CPU and GPU tasks, is significantly affected by the overhead of map task invocation in the Hadoop framework.","Graphics processing unit,
Java,
Performance evaluation,
Processor scheduling,
Prototypes,
Central Processing Unit,
Computers"
When Transportation Meets Communication: V2P over VANETs,"Information interaction is a crucial part of modern transportation activities. In this paper, we propose the idea of Vehicle-to-Passenger communication (V2P), which allows direct, instant, and flexible communication between moving vehicles and roadside passengers. With pocket wireless devices, passengers can easily join VANETs as roadside nodes, and express their travel demands, e.g., taking a free ride or calling a taxi via radio queries over VANETs. Once a matched vehicle is found through the disseminated queries, the driver can decide whether to provide corresponding services, especially the carrying of passengers and goods. We investigate the main challenges in vehicle calling, establish a trip history model to predict vehicle movement, and develop typical query dissemination schemes to match the target vehicle in vehicular networks. With V2P over VANETs, vehicle transportation is capable of open and efficient P2P information interaction, and thus benefits from relevant efficiency improvement. Based on a realistic travel survey and simulation, we prove that vehicle calling is effective and efficient in casual carpooling and taxi calling.","Road transportation,
Distributed computing,
Computer science,
Supply and demand,
Peer to peer computing,
Road vehicles,
Vehicle driving,
Mobile communication,
Internet,
Mobile computing"
Modeling and design of energy efficient variable stiffness actuators,"In this paper, we provide a port-based mathematical framework for analyzing and modeling variable stiffness actuators. The framework provides important insights in the energy requirements and, therefore, it is an important tool for the design of energy efficient variable stiffness actuators. Based on new insights gained from this approach, a novel conceptual actuator is presented. Simulations show that the apparent output stiffness of this actuator can be dynamically changed in an energy efficient way.",
Improving RFID-based indoor positioning accuracy using Gaussian processes,"The received signal strength (RSS) of radiofrequency signals emitted from beacons placed at known locations in an environment, can be used by a local positioning system (LPS) to estimate the location of a person or a mobile object. In indoor environments, interference, multipath propagation of RF signals, and the presence of obstacles and people, lead to a complex spatial distribution of the RSS, which is inaccurately described by simple parametric models. In this work, we present a Bayesian method for an indoor RFID location system which uses an observation model based in Gaussian processes (GPs) nonparametric regression to represent the environment-specific RSS distributions for the individual RFID tags. The experimental results in an indoor environment demonstrate the effectiveness of GPs in order to increase positioning accuracy.",
Approximate string search in spatial databases,"This work presents a novel index structure, MHR-tree, for efficiently answering approximate string match queries in large spatial databases. The MHR-tree is based on the R-tree augmented with the min-wise signature and the linear hashing technique. The min-wise signature for an index node u keeps a concise representation of the union of q-grams from strings under the sub-tree of u. We analyze the pruning functionality of such signatures based on set resemblance between the query string and the q-grams from the sub-trees of index nodes. MHR-tree supports a wide range of query predicates efficiently, including range and nearest neighbor queries. We also discuss how to estimate range query selectivity accurately. We present a novel adaptive algorithm for finding balanced partitions using both the spatial and string information stored in the tree. Extensive experiments on large real data sets demonstrate the efficiency and effectiveness of our approach.","Spatial databases,
Keyword search,
Nearest neighbor searches,
Computer science,
Indexes,
Adaptive algorithm,
Uncertainty,
Dynamic programming,
Costs"
Automatic grading of diabetic maculopathy severity levels,"Diabetic maculopathy is the major cause of irreversible vision loss due to retinopathy and is found in 10% of the world diabetic population. Compulsory mass screening will help to identify the maculopathy at early stage and reduce the risk of severe vision loss. In this paper, we present a computer based system for automatic detection and grading of diabetic maculopathy severity level without manual intervention. The optic disc is detected automatically and its location and diameter is used to detect fovea and to mark the macular region respectively. Next, hard exudates are detected using clustering and mathematical morphological techniques. Based on the location of exudates in marked macular region the severity level of maculopathy is classified into mild, moderate and severe. The method achieves a sensitivity of 95.6% and specificity of 96.15% with 148 retinal images for detecting maculopathy stages in fundus images as comparable to that of human expert.","Diabetes,
Retina,
Optical imaging,
Biomedical optical imaging,
Retinopathy,
Sensitivity"
Web Data Mining research: A survey,"Web Data Mining is an important area of Data Mining which deals with the extraction of interesting knowledge from the World Wide Web, It can be classified into three different types i.e. web content mining, web structure mining and web usages mining. The aim of this paper is to provide past, current evaluation and update in each of the three different types of web mining i.e. web content mining, web structure mining and web usages mining and also outlines key future research directions. This paper also reports the comparisons and summary of various methods of web data mining with applications, which gives the overview of development in research and some important research issues.","knowledge acquisition,
data mining,
Internet"
Self-supervised cross-modal online learning of basic object affordances for developmental robotic systems,"For a developmental robotic system to function successfully in the real world, it is important that it be able to form its own internal representations of affordance classes based on observable regularities in sensory data. Usually successful classifiers are built using labeled training data, but it is not always realistic to assume that labels are available in a developmental robotics setting. There does, however, exist an advantage in this setting that can help circumvent the absence of labels: co-occurrence of correlated data across separate sensory modalities over time. The main contribution of this paper is an online classifier training algorithm based on Kohonen's learning vector quantization (LVQ) that, by taking advantage of this co-occurrence information, does not require labels during training, either dynamically generated or otherwise. We evaluate the algorithm in experiments involving a robotic arm that interacts with various household objects on a table surface where camera systems extract features for two separate visual modalities. It is shown to improve its ability to classify the affordances of novel objects over time, coming close to the performance of equivalent fully-supervised algorithms.","Robot sensing systems,
Robotics and automation,
Vector quantization,
Robot vision systems,
Cameras,
Data mining,
Feature extraction,
Shape,
USA Councils,
Information science"
Multichannel Intraneural and Intramuscular Techniques for Multiunit Recording and Use in Active Prostheses,"During the last decade there has been a renewed interest in the development of advanced, active hand prosthetic devices for amputees. In contrast to passive prostheses, active devices can be controlled by the user's intention. Active prosthetic devices have been substantially improved by integrating robot technology to achieve more functionalities and lifelike movements. Despite important progress in the technological development of prosthetics, their clinical application is still limited by the quantity and quality of biological signals that can be used for understanding the user's intention, and by the relatively poor performance of the algorithms that translate the user's intention into a desired movement. In this review we describe a solution to some of these limitations, i.e., the flexible, multichannel, implantable intraneural and intramuscular electrodes to interface the body's peripheral nerves or muscles. We aim to review the historic development, the underlying technology, and the design concepts of these electrodes. Moreover, the signal processing methods applied to these recordings and their use for the control of prosthetic devices will be discussed. Although the focus is on hand prostheses, the interface approach described is general.",
A Transductive Neuro-Fuzzy Controller: Application to a Drilling Process,"Recently, new neuro-fuzzy inference algorithms have been developed to deal with the time-varying behavior and uncertainty of many complex systems. This paper presents the design and application of a novel transductive neuro-fuzzy inference method to control force in a high-performance drilling process. The main goal is to study, analyze, and verify the behavior of a transductive neuro-fuzzy inference system for controlling this complex process, specifically addressing the dynamic modeling, computational efficiency, and viability of the real-time application of this algorithm as well as assessing the topology of the neuro-fuzzy system (e.g., number of clusters, number of rules). A transductive reasoning method is used to create local neuro-fuzzy models for each input/output data set in a case study. The direct and inverse dynamics of a complex process are modeled using this strategy. The synergies among fuzzy, neural, and transductive strategies are then exploited to deal with process complexity and uncertainty through the application of the neuro-fuzzy models within an internal model control (IMC) scheme. A comparative study is made of the adaptive neuro-fuzzy inference system (ANFIS) and the suggested method inspired in a transductive neuro-fuzzy inference strategy. The two neuro-fuzzy strategies are evaluated in a real drilling force control problem. The experimental results demonstrated that the transductive neuro-fuzzy control system provides a good transient response (without overshoot) and better error-based performance indices than the ANFIS-based control system. In particular, the IMC system based on a transductive neuro-fuzzy inference approach reduces the influence of the increase in cutting force that occurs as the drill depth increases, reducing the risk of rapid tool wear and catastrophic tool breakage.",
Surface-from-Gradients without Discrete Integrability Enforcement: A Gaussian Kernel Approach,"Representative surface reconstruction algorithms taking a gradient field as input enforce the integrability constraint in a discrete manner. While enforcing integrability allows the subsequent integration to produce surface heights, existing algorithms have one or more of the following disadvantages: They can only handle dense per-pixel gradient fields, smooth out sharp features in a partially integrable field, or produce severe surface distortion in the results. In this paper, we present a method which does not enforce discrete integrability and reconstructs a 3D continuous surface from a gradient or a height field, or a combination of both, which can be dense or sparse. The key to our approach is the use of kernel basis functions, which transfer the continuous surface reconstruction problem into high-dimensional space, where a closed-form solution exists. By using the Gaussian kernel, we can derive a straightforward implementation which is able to produce results better than traditional techniques. In general, an important advantage of our kernel-based method is that the method does not suffer discretization and finite approximation, both of which lead to surface distortion, which is typical of Fourier or wavelet bases widely adopted by previous representative approaches. We perform comparisons with classical and recent methods on benchmark as well as challenging data sets to demonstrate that our method produces accurate surface reconstruction that preserves salient and sharp features. The source code and executable of the system are available for downloading.","Kernel,
Surface reconstruction,
Reconstruction algorithms,
Noise reduction,
Surface treatment,
Closed-form solution,
Surface waves,
Discrete wavelet transforms,
Photometry,
Anisotropic magnetoresistance"
K nearest neighbor queries and kNN-Joins in large relational databases (almost) for free,"Finding the k nearest neighbors (kNN) of a query point, or a set of query points (kNN-Join) are fundamental problems in many application domains. Many previous efforts to solve these problems focused on spatial databases or stand-alone systems, where changes to the database engine may be required, which may limit their application on large data sets that are stored in a relational database management system. Furthermore, these methods may not automatically optimize kNN queries or kNN-Joins when additional query conditions are specified. In this work, we study both the kNN query and the kNN-Join in a relational database, possibly augmented with additional query conditions. We search for relational algorithms that require no changes to the database engine. The straightforward solution uses the user-defined-function (UDF) that a query optimizer cannot optimize.We design algorithms that could be implemented by SQL operators without changes to the database engine, hence enabling the query optimizer to understand and generate the “best” query plan. Using only a small constant number of random shifts for databases in any fixed dimension, our approach guarantees to find the approximate kNN with only logarithmic number of page accesses in expectation with a constant approximation ratio and it could be extended to find the exact kNN efficiently in any fixed dimension. Our design paradigm easily supports the kNN-Join and updates. Extensive experiments on large, real and synthetic, data sets confirm the efficiency and practicality of our approach.","Nearest neighbor searches,
Relational databases,
Spatial databases,
Engines,
Algorithm design and analysis,
Design optimization,
Computer science,
Application software,
Optimization methods,
Pattern recognition"
Determinant Sums for Undirected Hamiltonicity,"We present a Monte Carlo algorithm for Hamilton city detection in an
n
-vertex undirected graph running in
O
∗
(
1.657
n
)
time. To the best of our knowledge, this is the first super polynomial improvement on the worst case runtime for the problem since the
O
∗
(
2
n
)
bound established for TSP almost fifty years ago (Bellman 1962, Held and Karp 1962). It answers in part the first open problem in Woe ginger's 2003 survey on exact algorithms for NP-hard problems. For bipartite graphs, we improve the bound to
O
∗
(
1.414
n
)
time. Both the bipartite and the general algorithm can be implemented to use space polynomial in
n
. We combine several recently resurrected ideas to get the results. Our main technical contribution is a new reduction inspired by the algebraic sieving method for
k
-Path (Koutis ICALP 2008, Williams IPL 2009). We introduce the Labeled Cycle Cover Sum in which we are set to count weighted arc labeled cycle covers over a finite field of characteristic two. We reduce Hamiltonicity to Labeled Cycle Cover Sum and apply the determinant summation technique for Exact Set Covers (Bj\""orklund STACS 2010) to evaluate it.",
A Utility-Based TMCR Scheduling Scheme for Downlink Multiuser MIMO-OFDMA Systems,"In this paper, a utility-based throughput maximization and complexity-reduction (U_TMCR) scheduling scheme is proposed for downlink multiuser multiple-input-multiple-output orthogonal frequency-division multiple-access (MIMO-OFDMA) systems. The U_TMCR scheme allocates subchannels, antenna sequence, and modulation order to multimedia users with goals not only to maximize system throughput under quality-of-service (QoS) guarantee but to reduce computational complexity as well. Based on the channel quality and the QoS requirements of each user, the U_TMCR scheme designs a utility function for every user and formulates the scheduling into an optimization problem of overall system utility function subject to system constraints. It also contains a heuristic TMCR algorithm to efficiently solve the optimization problem. Simulation results show that the U_TMCR scheme achieves system throughput very close to the optimal solution by exhaustive search and higher than conventional schemes such as adaptive radio resource allocation (ARRA) and cross-layer design of packet scheduling (CDPS) by about 8% and 21%, respectively. The U_TMCR scheme also has a QoS satisfaction ratio that is better than the ARRA and CDPS schemes. Moreover, the U_TMCR scheme can reduce computational complexity. Generally, the total number of allocation trials of the U_TMCR scheme in a frame is smaller than that of the ARRA scheme by 6.25%-29.2%.",
Multiple View Clustering Using a Weighted Combination of Exemplar-Based Mixture Models,"Multiview clustering partitions a dataset into groups by simultaneously considering multiple representations (views) for the same instances. Hence, the information available in all views is exploited and this may substantially improve the clustering result obtained by using a single representation. Usually, in multiview algorithms all views are considered equally important, something that may lead to bad cluster assignments if a view is of poor quality. To deal with this problem, we propose a method that is built upon exemplar-based mixture models, called convex mixture models (CMMs). More specifically, we present a multiview clustering algorithm, based on training a weighted multiview CMM, that associates a weight with each view and learns these weights automatically. Our approach is computationally efficient and easy to implement, involving simple iterative computations. Experiments with several datasets confirm the advantages of assigning weights to the views and the superiority of our framework over single-view and unweighted multiview CMMs, as well as over another multiview algorithm which is based on kernel canonical correlation analysis.","Coordinate measuring machines,
Clustering algorithms,
Kernel,
Partitioning algorithms,
Web pages,
Estimation"
EDDIE for investment opportunities forecasting: Extending the search space of the GP,"In this paper we present a new version of a GP-based financial forecasting tool called EDDIE. The novelty of this new version (EDDIE 8), is its enlarged search space, where we allow the GP to search in the space of the technical indicators, in order to form its Genetic Decision Trees. In this way, EDDIE 8 is not constrained in using pre-specified indicators, but it is left up to the GP to choose the optimal ones. We then proceed to compare EDDIE 8 with EDDIE 7, which is based on previous EDDIE versions; EDDIE 7 has a smaller space where the indicators are pre-specified by the user and are part of EDDIE 8's space. Results show that thanks to the bigger search space, new and improved solutions can be found by EDDIE 8. However, there are cases where EDDIE 8 can still be outperformed by its predecessor. Analysis shows that this depends on the nature of the solutions. If the solutions come from EDDIE 8's search space, then EDDIE 8 can find them and perform better; if, however, solutions come from the smaller search space of EDDIE 7, then EDDIE 8 is having difficulties focusing in such a small space and is thus outperformed by EDDIE 7.",
Simultaneous localization and mapping using ambient magnetic field,"In this paper we propose a simultaneous localization and mapping (SLAM) method that utilizes local anomalies of the ambient magnetic field present in many indoor environments. We use a Rao-Blackwellized particle filter to estimate the pose distribution of the robot and Gaussian Process regression to model the magnetic field map. The feasibility of the proposed approach is validated by real world experiments, which demonstrate that the approach produces geometrically consistent maps using only odometric data and measurements obtained from the ambient magnetic field. The proposed approach provides a simple, low-cost, and space-efficient solution for solving the SLAM problem present in many domestic and swarm robotics application domains.","Simultaneous localization and mapping,
Particle measurements,
Atmospheric measurements,
Magnetometers,
Computational modeling"
Year,,
Transient Behavior of Two-Machine Geometric Production Lines,"Production system transients characterize the process of reaching the steady state throughput. Reducing transients' duration is important in a number of applications. This technical note is intended to analyze transients in serial production lines with machines obeying the geometric reliability model. The Markov chain approach is used, and the second largest eigenvalue of the transition matrices is utilized to characterize the transients. Due to large dimensionality of the transition matrices, only two-machine systems are addressed, and the second largest eigenvalue is investigated as a function of the breakdown and repair probabilities. Conditions under which shorter up- and downtimes lead to faster transients are provided.","Transient analysis,
Solid modeling,
Production systems,
Steady-state,
Eigenvalues and eigenfunctions,
Electric breakdown,
Assembly,
Machining,
Throughput,
Paints"
Finding stationary brain sources in EEG data,"Neurophysiological measurements obtained from e.g. EEG or fMRI are inherently non-stationary because the properties of the underlying brain processes vary over time. For example, in Brain-Computer-Interfacing (BCI), deteriorating performance (bitrate) is a common phenomenon since the parameters determined during the calibration phase can be suboptimal under the application regime, where the brain state is different, e.g. due to increased tiredness or changes in the experimental paradigm. We show that Stationary Subspace Analysis (SSA), a time series analysis method, can be used to identify the underlying stationary and non-stationary brain sources from high-dimensional EEG measurements. Restricting the BCI to the stationary sources found by SSA can significantly increase the performance. Moreover, SSA yields topographic maps corresponding to stationary- and non-stationary brain sources which reveal their spatial characteristics.",
Switched Oscillators and Their Integration Into Helical Antennas,"In this paper, the problem of designing switched oscillators at four different frequencies (200, 300, 400, and 500 MHz) has been addressed. These oscillators are quarter-wavelength long coaxial transmission lines with a nitrogen spark gap switch at one end. Two of these switched oscillators at 200 and 500 MHz with a charge voltage of 30 kV have also been fabricated. These two oscillators are modeled using PSpice and their output into a 100 Ω load is estimated and tested by fabricating a 100 Ω transmission line. Use is made of a modified commercial helical antenna with a bandwidth of 400-600 MHz and a switched oscillator has been integrated into this helical antenna. Measurements have been made of the S11 , the voltage into the antenna, and also the transient fields at two distances. Indeed, starting from electrical power from a 12 V battery, electrical field strengths in excess of 10 kV/m with damped sinusoidal waveforms at 500 MHz (for example) have been demonstrated.","Helical antennas,
Power transmission lines,
Switches,
Frequency,
Coaxial components,
Nitrogen,
Sparks,
Voltage-controlled oscillators,
Testing,
Bandwidth"
Remote Sensing Image Registration Based on Retrofitted SURF Algorithm and Trajectories Generated From Lissajous Figures,"In this letter, we propose a novel remote sensing image registration method by optimizing the Speeded Up Robust Features (SURF) and developing a new similarity measure function based on trajectories generated from Lissajous figures. Compared with SURF which has a low feature-matching rate in some complex cases, the retrofitted SURF algorithm is more robust and accurate. The algorithm greatly improves the correct matching rate to over 80%. Furthermore, the recognition capability of the similarity measure is enhanced by using a trajectory disturbance strategy, which is a significant displacement in the trajectory induced by a minor error of the transformation parameters. Experiments show the promising performance of the proposed image registration method.",
An Initial Model for Control of a Tandem Hot Metal Strip Rolling Process,"The tandem rolling of hot metal strip presents a significant control challenge because of nonlinearities and process complexities. The challenge is heightened by an extremely hostile environment that precludes the location of sensors to measure process variables that are important for control. In addition, it is essential that the controller structure allows for a high degree of physical intuition in the design process and provides for simplicity of tuning during commissioning. Based on our previous work using a state-dependent Riccati equation (SDRE) technique for control of the tandem cold rolling process, it is considered that a similar method might also be useful as a basis for the development of a control technique for tandem hot strip rolling. For the hot rolling process, the development of a process model in a form that is suitable for use with a SDRE-based method is a significant and challenging task. This paper describes our work to develop an initial model for this process. Based on simulation results, it is determined that this initial model has the potential to be the basis for the development of the complete nonlinear model that can be used for development of a viable control method which offers the likelihood for improvement in the control of the hot metal rolling process.","Strips,
Milling machines,
Finishing,
Riccati equations,
Manufacturing processes,
Steel,
Slabs,
Industry Applications Society,
Temperature,
Control nonlinearities"
Low Phase-Noise Planar Oscillators Based on Low-Noise Active Resonators,"A very low phase-noise planar X -band oscillator employing an active resonator has been demonstrated. The high frequency selectivity of the active filter, used as the resonator, is the key factor in phase-noise reduction. A design procedure to achieve the resonator's optimum performance for low phase-noise applications is presented. In particular, the effect of the excess noise introduced by the active filter is addressed and its impact on the oscillator's phase noise is minimized. The oscillator, operating at 8 GHz, shows a measured phase noise of -150 dBc/Hz at 1-MHz frequency offset with 10-dBm output power. To the best of our knowledge, this oscillator demonstrates the lowest phase noise among published X -band planar oscillators to date.","Oscillators,
Phase noise,
Active filters,
Band pass filters,
Resonator filters,
Q factor,
Active noise reduction,
Resonant frequency,
Dielectric losses,
Feedback"
Predictive Network Anomaly Detection and Visualization,"Various approaches have been developed for quantifying and displaying network traffic information for determining network status and in detecting anomalies. Although many of these methods are effective, they rely on the collection of long-term network statistics. Here, we present an approach that uses short-term observations of network features and their respective time averaged entropies. Acute changes are localized in network feature space using adaptive Wiener filtering and auto-regressive moving average modeling. The color-enhanced datagram is designed to allow a network engineer to quickly capture and visually comprehend at a glance the statistical characteristics of a network anomaly. First, average entropy for each feature is calculated for every second of observation. Then, the resultant short-term measurement is subjected to first- and second-order time averaging statistics. These measurements are the basis of a novel approach to anomaly estimation based on the well-known Fisher linear discriminant (FLD). Average port, high port, server ports, and peered ports are some of the network features used for stochastic clustering and filtering. We empirically determine that these network features obey Gaussian-like distributions. The proposed algorithm is tested on real-time network traffic data from Ohio University's main Internet connection. Experimentation has shown that the presented FLD-based scheme is accurate in identifying anomalies in network feature space, in localizing anomalies in network traffic flow, and in helping network engineers to prevent potential hazards. Furthermore, its performance is highly effective in providing a colorized visualization chart to network analysts in the presence of bursty network traffic.","Visualization,
Telecommunication traffic,
Statistics,
Entropy,
Wiener filter,
Data engineering,
Design engineering,
Time measurement,
Network servers,
Web server"
Machines and Drives Comparison for Low-Power Renewable Energy and Oscillating Applications,"The objective of this paper is to analyze, test, and compare machines and drives in oscillating applications. In particular, this paper is focused on low-power wave energy generator applications, such as autonomous weather and monitoring buoys with power requirements in the 100 W and less range. Due to the oscillating motion of waves, the ocean environment can require bidirectional and variable speed operation of the generator. In this research, the efficiency of a set of small brushed dc, induction, brushless dc, and synchronous reluctance drives and machines were compared in constant and oscillating operation. The presented results show that drives and machines used in low-power oscillating applications (e.g., ocean wave energy) should not expect a significant derating with respect to their nameplate rating. In addition, it is shown that the frequency of oscillation (e.g., ocean wave frequency) has little impact on efficiency.","Torque,
Generators,
Marine transportation,
Power generation,
Frequency modulation,
DC machines,
Synchronous motors"
In Vivo Supervised Analysis of Stent Reendothelialization From Optical Coherence Tomography,"The aim of this study is to interactively assess reendothelialization of stents at an accuracy of down to a few micrometer by analyzing endovascular optical coherence tomography (OCT) sequences. Vessel wall and stent struts are automatically detected by using morphological, gradient, and symmetry operators coupled with active contour models; alerts are issued to ask for user supervision over some extreme irregular geometries caused by thrombotic lesions or dissections. A complete distance map is then computed from sparse distances measured between wall and struts. Missing values are interpolated by thin-plate spline (TPS) functions. Accuracy and robustness are increased by taking into account the inhomogeneity of data points and integrating in the same framework orthogonalized forward selection of support points, optimal selection of regularization parameters by generalized cross-validation, and rejection of detection outliers. Validation is performed on simulated data, phantom acquisitions and 11 typical in vivo OCT sequences. The comparison against manual expert measurements demonstrates a bias of the order of OCT resolution (less than 10 ¿m) and a standard deviation of the order of the strut width (less than 150 ¿m ).","In vivo,
Coherence,
Tomography,
Active contours,
Solid modeling,
Ultraviolet sources,
Geometrical optics,
Lesions,
Spline,
Robustness"
Illustrative Stream Surfaces,"Stream surfaces are an intuitive approach to represent 3D vector fields. In many cases, however, they are challenging objects to visualize and to understand, due to a high degree of self-occlusion. Despite the need for adequate rendering methods, little work has been done so far in this important research area. In this paper, we present an illustrative rendering strategy for stream surfaces. In our approach, we apply various rendering techniques, which are inspired by the traditional flow illustrations drawn by Dallmann and Abraham & Shaw in the early 1980s. Among these techniques are contour lines and halftoning to show the overall surface shape. Flow direction as well as singularities on the stream surface are depicted by illustrative surface streamlines. ;To go beyond reproducing static text book images, we provide several interaction features, such as movable cuts and slabs allowing an interactive exploration of the flow and insights into subjacent structures, e.g., the inner windings of vortex breakdown bubbles. These methods take only the parameterized stream surface as input, require no further preprocessing, and can be freely combined by the user. We explain the design, GPU-implementation, and combination of the different illustrative rendering and interaction methods and demonstrate the potential of our approach by applying it to stream surfaces from various flow simulations.","Rendering (computer graphics),
Shape,
Visualization,
Streaming media,
Pixel,
Data visualization,
Surface texture"
Low-Swing Signaling on Monolithically Integrated Global Graphene Interconnects,"In this paper, we characterize the performance of monolithically integrated graphene interconnects on a prototype 0.35-μm CMOS chip. The test chip implements an array of transmitter/receivers to analyze the end-to-end data communication on graphene wires. Large-area graphene sheets are first grown by chemical vapor deposition, which are then subsequently processed into narrow wires up to 1 mm in length. A low-swing signaling technique is applied, which results in a transmitter energy of 0.3-0.7 pJ/b·mm-1 and a total energy of 2.4-5.2 pJ/b·mm-1. Bit error rates below 2 × 10-10 are measured using a 231 - 1 pseudorandom binary sequence. Minimum voltage swings of 100 mV at 1.5-V supply and 500 mV at 3.3-V supply have also been demonstrated. At present, the graphene wire is largely limited by its growth quality and high sheet resistance.",
An Automatic Personal Calibration Procedure for Advanced Gaze Estimation Systems,"Gaze estimation systems use calibration procedures to estimate subject-specific parameters that are needed for the calculation of the point-of-gaze. In these procedures, subjects are required to fixate on a specific point or points in space at specific time instances. Advanced remote gaze estimation systems can estimate the optical axis of the eye without any personal calibration procedure, but use a single calibration point to estimate the angle between the optical axis and the visual axis (line-of-gaze). This paper presents a novel calibration procedure that does not require active user participation. To estimate the angles between the optical and visual axes of each eye, this procedure minimizes the distance between the intersections of the visual axes of the left and right eyes with one or more observation surfaces (displays) while subjects look naturally at these displays (e.g., watching a video clip). Theoretical analysis and computer simulations show that the performance of the proposed procedure improves when the range of angles between the visual axes and vectors normal to the observation surfaces increases. Experiments with four subjects show that the subject-specific angles between the optical and visual axes can be estimated with an rms error of 0.5°.","Calibration,
Biomedical optical imaging,
Parameter estimation,
Computer displays,
Humans,
Eyes,
Performance analysis,
Computer simulation,
Computer errors"
Nested Support Vector Machines,"One-class and cost-sensitive support vector machines (SVMs) are state-of-the-art machine learning methods for estimating density level sets and solving weighted classification problems, respectively. However, the solutions of these SVMs do not necessarily produce set estimates that are nested as the parameters controlling the density level or cost-asymmetry are continuously varied. Such nesting not only reflects the true sets being estimated, but is also desirable for applications requiring the simultaneous estimation of multiple sets, including clustering, anomaly detection, and ranking. We propose new quadratic programs whose solutions give rise to nested versions of one-class and cost-sensitive SVMs. Furthermore, like conventional SVMs, the solution paths in our construction are piecewise linear in the control parameters, although here the number of breakpoints is directly controlled by the user. We also describe decomposition algorithms to solve the quadratic programs. These methods are compared to conventional (non-nested) SVMs on synthetic and benchmark data sets, and are shown to exhibit more stable rankings and decreased sensitivity to parameter settings.","Support vector machines,
Support vector machine classification,
Level set,
Costs,
Statistical learning,
Training data,
Learning systems,
State estimation,
Piecewise linear techniques,
Machine learning algorithms"
Energy minimization for linear envelope MRFs,"Markov random fields with higher order potentials have emerged as a powerful model for several problems in computer vision. In order to facilitate their use, we propose a new representation for higher order potentials as upper and lower envelopes of linear functions. Our representation concisely models several commonly used higher order potentials, thereby providing a unified framework for minimizing the corresponding Gibbs energy functions. We exploit this framework by converting lower envelope potentials to standard pairwise functions with the addition of a small number of auxiliary variables. This allows us to minimize energy functions with lower envelope potentials using conventional algorithms such as BP, TRW and α-expansion. Furthermore, we show how the minimization of energy functions with upper envelope potentials leads to a difficult minmax problem. We address this difficulty by proposing a new message passing algorithm that solves a linear programming relaxation of the problem. Although this is primarily a theoretical paper, we demonstrate the efficacy of our approach on the binary (fg/bg) segmentation problem.","Computer vision,
Random variables,
Message passing,
Labeling,
Markov random fields,
Linear programming,
Computer science,
Minimax techniques,
Contracts,
Higher order statistics"
Multi-robot monitoring in dynamic environments with guaranteed currency of observations,"In this paper we consider the problem of monitoring a known set of stationary features (or locations of interest) in an environment. To observe a feature, a robot must visit its location. Each feature changes over time, and we assume that the currency, or accuracy of an observation decays linearly with time. Thus, robots must repeatedly visit the features to update their observations. Each feature has a known rate of change, and so the frequency of visits to a feature should be proportional to its rate. The goal is to route the robots so as to minimize the maximum change of a feature between observations. We focus on the asymptotic regime of a large number of features distributed according to a probability density function. In this regime we determine a lower bound on the maximum change of a feature between visits, and develop a robot control policy that, with probability one, performs within a factor of two of the optimal. We also provide a single robot lower bound which holds outside of the asymptotic regime, and present a heuristic algorithm motivated by our asymptotic analysis.","Robots,
Trajectory,
Monitoring,
Routing,
Vehicle dynamics,
Cost function,
Vehicles"
Real-Time Measurement of Link Vehicle Count and Travel Time in a Road Network,"A system is described that measures the vehicle count and travel time in the links of a road network. The measurements require matching vehicle signatures recorded by a wireless magnetic sensor network. The matching algorithm is based on a statistical model of the signatures. The model itself is estimated from the data. The approach is first discussed for a single-lane road and extended to multiple-lane roads. The algorithm yields a correct matching rate of 75% for a false matching rate of 5% and reliably estimates the number of vehicles on each link and its travel-time distribution. The system is tested on a 0.9-mi-long segment of San Pablo Avenue, Albany, CA.","Time measurement,
Road vehicles,
Magnetic sensors,
System testing,
Velocity measurement,
Wireless sensor networks,
Traffic control,
Detectors,
Current measurement,
Volume measurement"
Constructing Concept Lexica With Small Semantic Gaps,"In recent years, constructing mathematical models for visual concepts by using content features, i.e., color, texture, shape, or local features, has led to the fast development of concept-based multimedia retrieval. In concept-based multimedia retrieval, defining a good lexicon of high-level concepts is the first and important step. However, which concepts should be used for data collection and model construction is still an open question. People agree that concepts that can be easily described by low-level visual features can construct a good lexicon. These concepts are called concepts with small semantic gaps. Unfortunately, there is very little research found on semantic gap analysis and on automatically choosing multimedia concepts with small semantic gaps, even though differences of semantic gaps among concepts are well worth investigating. In this paper, we propose a method to quantitatively analyze semantic gaps and develop a novel framework to identify high-level concepts with small semantic gaps from a large-scale web image dataset. Images with small semantic gaps are selected and clustered first by defining a confidence score and a content-context similarity matrix in visual space and textual space. Then, from the surrounding descriptions (titles, categories, and comments) of these images, concepts with small semantic gaps are automatically mined. In addition, considering that semantic gap analysis depends on both features and content-contextual consistency, we construct a lexicon family of high-level concepts with small semantic gaps (LCSS) based on different low-level features and different consistency measurements. This set of lexica is both independent to each other and mutually complimentary. LCSS is very helpful for data collection, feature selection, annotation, and modeling for large-scale image retrieval. It also shows a promising application potential for image annotation refinement and rejection. The experimental results demonstrate the validity of the developed concept lexica.","Large-scale systems,
Information retrieval,
Multimedia systems,
Computer science,
Mathematical model,
Shape,
Content based retrieval,
Image analysis,
Image retrieval,
Terrorism"
A PVDF Receiver for Ultrasound Monitoring of Transcranial Focused Ultrasound Therapy,"Focused ultrasound (FUS) shows great promise for use in the area of transcranial therapy. Currently dependent on MRI for monitoring, transcranial FUS would benefit from a real-time technique to monitor acoustic emissions during therapy. A polyvinylidene fluoride receiver with an active area of 17.8 mm2 and a film thickness of 110 μm was constructed. A compact preamplifier was designed to fit within the receiver to improve the receiver SNR and allow the long transmission line needed to remove the receiver electronics outside of the MRI room. The receiver was compared with a 0.5 mm commercial needle hydrophone and focused and unfocused piezoceramics. The receiver was found to have a higher sensitivity than the needle hydrophone, a more wideband response than the piezoceramic, and sufficient threshold for detection of microbubble emissions. Sonication of microbubbles directly and through a fragment of human skull demonstrated the ability of the receiver to detect harmonic bubble emissions, and showed potential for use in a larger scale array. Monitoring of disruption of the blood-brain barrier in rats showed functionality in vivo and the ability to detect subharmonic, harmonic, and wideband emissions during therapy. The receiver shows potential for monitoring acoustic emissions during treatments and providing additional parameters to assist treatment planning. Future work will focus on developing a multi-element array for transcranial treatment monitoring.",
A study of Through Silicon Via impact to 3D Network-on-Chip design,"The adoption of a 3D Network-on-Chip (NoC) design depends on the performance and manufacturing cost of the chip. Therefore, a study of Through Silicon Via (TSV), that connects different layers of a 3D chip, is crucial. In this paper, we analysis the impact of TSV design in 3D NoCs. A 3D NoC with five layers is modeled based on modern 2D chips. We discuss the TSV number required for a 3D NoC. Different placements of half and quarter layer-layer connections are explored. We present benchmark results using a cycle accurate full system simulator based on realistic workloads. Experiments show that under different workloads, the average network latencies in full and half layer-layer connection are reduced by 5.24% and 2.18% respectively, compared with quarter design. Our analysis and experiment results provide a guideline for designing TSVs in 3D NoCs to leverage the tradeoff between performance and manufacturing cost.","Three dimensional displays,
Through-silicon vias,
Manufacturing,
Solid modeling,
System-on-a-chip,
Computer architecture,
Routing"
A measurement distribution framework for cooperative navigation using multiple AUVs,"In recent years underwater survey and surveillance missions with more than a single Autonomous Underwater Vehicle (AUV) have become more common thanks to more reliable and cheaper platforms, as well as the addition of remote command and control communications using, for example, the WHOI acoustic modem. However cooperative navigation of AUVs has thus far been limited to a single AUV supported by a dedicated surface vehicle with access to GPS. In this paper a scalable and modular framework is presented in which any number of vehicles can broadcast, forward and acknowledge range, dead-reckoning, feature and GPS measurements so that the full fleet of AUVs can navigate and cooperate in a consistent and accurate manner. The approach is independent of the resultant application—such as recursive state estimation or full pose optimization. Trade-offs between the number of vehicles, the condition of the communication channel and rate at which updates are available are also discussed. Finally performance is illustrated in a realistic experiment.",
Statistical Projection Completion in X-ray CT Using Consistency Conditions,"Projection data incompleteness arises in many situations relevant to X-ray computed tomography (CT) imaging. We propose a penalized maximum likelihood statistical sinogram restoration approach that incorporates the Helgason-Ludwig (HL) consistency conditions to accommodate projection data incompleteness. Image reconstruction is performed by the filtered-backprojection (FBP) in a second step. In our problem formulation, the objective function consists of the log-likelihood of the X-ray CT data and a penalty term; the HL condition poses a linear constraint on the restored sinogram and can be implemented efficiently via fast Fourier transform (FFT) and inverse FFT. We derive an iterative algorithm that increases the objective function monotonically. The proposed algorithm is applied to both computer simulated data and real patient data. We study different factors in the problem formulation that affect the properties of the final FBP reconstructed images, including the data truncation level, the amount of prior knowledge on the object support, as well as different approximations of the statistical distribution of the available projection data. We also compare its performance with an analytical truncation artifacts reduction method. The proposed method greatly improves both the accuracy and the precision of the reconstructed images within the scan field-of-view, and to a certain extent recovers the truncated peripheral region of the object. The proposed method may also be applied in areas such as limited angle tomography, metal artifacts reduction, and sparse sampling imaging.","X-ray imaging,
Computed tomography,
Image reconstruction,
Image restoration,
Iterative algorithms,
Optical imaging,
Fast Fourier transforms,
Computational modeling,
Computer simulation,
Statistical distributions"
Graphical Models for Time-Series,"Time-series analysis is central to many problems in signal processing, including acoustics, image processing, vision, tracking, information retrieval, and finance, to name a few. Because of the wide base of application areas, having a common description of the models is useful in transferring ideas between the various communities. Graphical models provide a compact way to represent such models and thereby rapidly transfer ideas. We will discuss briefly how classical timeseries models such as Kalman filters and hidden Markov models (HMMs) can be represented as graphical models and critically how this representation differs from other common graphical representations such as state-transition and block diagrams. We will use this framework to show how one may easily envisage novel models and gain insight into their computational implementation.",
Introduction to Mobile Information Retrieval,The new frontier of mobile information retrieval will combine context awareness and content adaptation.,"Information retrieval,
Content based retrieval,
Context awareness"
An FFT-Accelerated Time-Domain Multiconductor Transmission Line Simulator,"A fast time-domain multiconductor transmission line (MTL) simulator for analyzing general MTL networks is presented. The simulator models the networks as homogeneous MTLs that are excited by external fields and driven/terminated/connected by potentially nonlinear lumped circuitry. It hybridizes an MTL solver derived from time-domain integral equations (TDIEs) in unknown wave coefficients for each MTL with a circuit solver rooted in modified nodal analysis equations in unknown node voltages and voltage-source currents for each circuit. These two solvers are rigorously interfaced at MTL and circuit terminals, and the resulting coupled system of equations is solved simultaneously for all MTL and circuit unknowns at each time step. The proposed simulator is amenable to hybridization, is fast Fourier transform (FFT)-accelerated, and is highly accurate: 1) It can easily be hybridized with TDIE-based field solvers (in a fully rigorous mathematical framework) for performing electromagnetic interference and compatibility analysis on electrically large and complex structures loaded with MTL networks; 2) It is accelerated by an FFT algorithm that calculates temporal convolutions of time-domain MTL Green functions in only O(N t log2 N t ) rather than O(N t 2) operations, where N t is the number of time steps of simulation. Moreover, the algorithm, which operates on temporal samples of MTL Green functions, is indifferent to the method used to obtain them; 3) It approximates MTL voltages, currents, and wave coefficients, using high-order temporal basis functions. Various numerical examples, including the crosstalk analysis of a (twisted) unshielded twisted-pair (UTP)-CAT5 cable and the analysis of field coupling into UTP-CAT5 and RG-58 cables located on an airplane, are presented to demonstrate the accuracy, efficiency, and versatility of the proposed simulator.",
Sub-ontology mapping based web services discovery framework,"In order to improve the efficiency of semantic web service discovery and overcome the ontology heterogeneity problem in distributed environment. This paper proposed a sub-ontology mapping based framework for the discovery of web services, and then presented a discovery algorithm that supports the service discovery across the ontologies. In this framework, sub-ontology extraction module was introduced to reduce the ontology mapping scale. The sub-ontology was extracted from the reference ontology through the extraction concept set of service functional description information. The experimental results confirm the viability and efficiency of the discovery system.",
Concurrent Negotiation and Coordination for Grid Resource Coallocation,"Bolstering resource coallocation is essential for realizing the Grid vision, because computationally intensive applications often require multiple computing resources from different administrative domains. Given that resource providers and consumers may have different requirements, successfully obtaining commitments through concurrent negotiations with multiple resource providers to simultaneously access several resources is a very challenging task for consumers. The impetus of this paper is that it is one of the earliest works that consider a concurrent negotiation mechanism for Grid resource coallocation. The concurrent negotiation mechanism is designed for 1) managing (de)commitment of contracts through one-to-many negotiations and 2) coordination of multiple concurrent one-to-many negotiations between a consumer and multiple resource providers. The novel contributions of this paper are devising 1) a utility-oriented coordination (UOC) strategy, 2) three classes of commitment management strategies (CMSs) for concurrent negotiation, and 3) the negotiation protocols of consumers and providers. Implementing these ideas in a testbed, three series of experiments were carried out in a variety of settings to compare the following: 1) the CMSs in this paper with the work of others in a single one-to-many negotiation environment for one resource where decommitment is allowed for both provider and consumer agents; 2) the performance of the three classes of CMSs in different resource market types; and 3) the UOC strategy with the work of others [e.g., the patient coordination strategy (PCS )] for coordinating multiple concurrent negotiations. Empirical results show the following: 1) the UOC strategy achieved higher utility, faster negotiation speed, and higher success rates than PCS for different resource market types; and 2) the CMS in this paper achieved higher final utility than the CMS in other works. Additionally, the properties of the three classes of CMSs in different kinds of resource markets are also verified.","Resource management,
Grid computing,
Computer vision,
Application software,
Computer applications,
Contracts,
Personal communication networks,
Collision mitigation,
Computer displays,
Protocols"
Comparison of Bootstrap Resampling Methods for 3-D PET Imaging,"Two groups of bootstrap methods have been proposed to estimate the statistical properties of positron emission tomography (PET) images by generating multiple statistically equivalent data sets from few data samples. The first group generates resampled data based on a parametric approach assuming that data from which resampling is performed follows a Poisson distribution while the second group consists of nonparametric approaches. These methods either require a unique original sample or a series of statistically equivalent data that can be list-mode files or sinograms. Previous reports regarding these bootstrap approaches suggest different results. This work compares the accuracy of three of these bootstrap methods for 3-D PET imaging based on simulated data. Two methods are based on a unique file, namely a list-mode based nonparametric (LMNP) method and a sinogram based parametric (SP) method. The third method is a sinogram-based nonparametric (SNP) method. Another original method (extended LMNP) was also investigated, which is an extension of the LMNP methods based on deriving a resampled list-mode file by drawings events from multiple original list-mode files. Our comparison is based on the analysis of the statistical moments estimated on the repeated and resampled data. This includes the probability density function and the moments of order 1 and 2. Results show that the two methods based on multiple original data (SNP and extended LMNP) are the only methods that correctly estimate the statistical parameters. Performances of the LMNP and SP methods are variable. Simulated data used in this study were characterized by a high noise level. Differences among the tested strategies might be reduced with clinical data sets with lower noise.",
Exploiting Prosody Hierarchy and Dynamic Features for Pitch Modeling and Generation in HMM-Based Speech Synthesis,"This paper proposes a method for modeling and generating pitch in hidden Markov model (HMM)-based Mandarin speech synthesis by exploiting prosody hierarchy and dynamic pitch features. The prosodic structure of a sentence is represented by a prosody hierarchy, which is constructed from the predicted prosodic breaks using a supervised classification and regression tree (S-CART). The S-CART is trained by maximizing the proportional reduction of entropy to minimize the errors in the prediction of the prosodic breaks. The pitch contour of a speech sentence is estimated using the STRAIGHT algorithm and decomposed into the prosodic features (static features) at prosodic word, syllable, and frame layers, based on the predicted prosodic structure. Dynamic features at each layer are estimated to preserve the temporal correlation between adjacent units. A hierarchical prosody model is constructed using an unsupervised CART (U-CART) for generating pitch contour. Minimum description length (MDL) is adopted in U-CART training. Objective and subjective evaluations with statistical hypothesis testing were conducted, and the results compared to corresponding results for HMM-based pitch modeling. The comparison confirms the improved performance of the proposed method.","Hidden Markov models,
Speech synthesis,
Cost function,
Medical services,
Computer industry,
Computer science,
Classification tree analysis,
Regression tree analysis,
Entropy,
Testing"
Post-production performance calibration in analog/RF devices,"In semiconductor device fabrication, continual demand for high performance, high yield devices has caused designers to look to post-production tunable circuits as the next logical step in analog/RF design and test development. These approaches have not yet achieved the maturity necessary for industrial adoption, primarily due to complexity and cost. In this work, we develop a general model which systematically outlines several key observations constraining the complexity of performance calibration in analog/RF devices. Moreover, we develop a detailed cost model permitting direct comparison of performance calibration methods to industry standard specification testing. Our analysis is demonstrated on a tunable RF LNA device simulated in 0.18µm RFCMOS.",
Towards Intelligent Team Composition and Maneuvering in Real-Time Strategy Games,"Players of real-time strategy (RTS) games are often annoyed by the inability of the game AI to select and move teams of units in a natural way. Units travel and battle separately, resulting in huge losses and the AI looking unintelligent, as can the choice of units sent to counteract the opponents. Players are affected as well as computer commanded factions because they cannot micromanage all team related issues. We suggest improving AI behavior by combining well-known computational intelligence techniques applied in an original way. Team composition for battling spatially distributed opponent groups is supported by a learning self-organizing map (SOM) that relies on an evolutionary algorithm (EA) to adapt it to the game. Different abilities of unit types are thus employed in a near-optimal way, reminiscent of human ad hoc decisions. Team movement is greatly enhanced by flocking and influence map-based path finding, leading to a more natural behavior by preserving individual motion types. The team decision to either attack or avoid a group of enemy units is easily parametrizable, incorporating team characteristics from fearful to daredevil. We demonstrate that these two approaches work well separately, but also that they go together naturally, thereby leading to an improved and flexible group behavior.","Artificial intelligence,
Game theory,
Computational intelligence,
Humans,
Computer science,
Competitive intelligence,
Military computing,
Evolutionary computation,
Neural networks,
Decision making"
Large-Scale Software Testing Environment Using Cloud Computing Technology for Dependable Parallel and Distributed Systems,"Various information systems are widely used in information society era, and the demand for highly dependable system is increasing year after year. However, software testing for such a system becomes more difficult due to the enlargement and the complexity of the system. In particular, it is too difficult to test parallel and distributed systems sufficiently although dependable systems such as high-availability servers usually form parallel and distributed systems. To solve these problems, we proposed a software testing environment for dependable parallel and distributed system using the cloud computing technology, named D-Cloud. D-Cloud includes Eucalyptus as the cloud management software, and FaultVM based on QEMU as the virtualization software, and D-Cloud frontend for interpreting test scenario. D-Cloud enables not only to automate the system configuration and the test procedure but also to perform a number of test cases simultaneously, and to emulate hardware faults flexibly. In this paper, we present the concept and design of D-Cloud, and describe how to specify the system configuration and the test scenario. Furthermore, the preliminary test example as the software testing using D-Cloud was presented. Its result shows that D-Cloud allows to set up the environment easily, and to test the software testing for the distributed system.","Large-scale systems,
Software testing,
Cloud computing,
System testing,
Hardware,
Information systems,
Automatic testing,
Performance evaluation,
Computer science,
Concurrent computing"
OncoPET_DB: A Freely Distributed Database of Realistic Simulated Whole Body 18F-FDG PET Images for Oncology,"The purpose of this paper is to generate and distribute a database of simulated whole body 18F-FDG positron emission tomography (PET) oncology images. As far as we know, this database is the first addressing the need for simulated 18F-FDG PET oncology images by providing a series of realistic whole-body patient images with well-controlled inserted lesions of calibrated uptakes. It also fulfills the requirements of detection performance studies by including normal and pathological cases. The originality of the database is based on three points. First, we built a complex model of 18F-FDG patient based on the Zubal phantom in combination with activity distributions in the main organs of interest derived from a series of 70 clinical cases. Secondly, we proposed a model of lesions extent corresponding to real lymphoma patients. The lesion contrast levels were derived from a human observer detection study so as to cover the entire range of detectability. Lastly, the simulated database was generated with the PET-SORTEO Monte Carlo simulation tool that was fully validated against the geometry of the ECAT EXACT HR+ (CTI/Siemens Knoxville). The oncoPET_DB database is composed of 100 whole-body PET simulated images, including 50 normal cases coming from different realizations of noise of the healthy model and 50 pathological cases including lesions of calibrated uptakes and various diameters. Such a database will be useful to evaluate algorithms that may impact quantification or contrast recovery, to perform observer studies or to assess computer-aided diagnosis methods. Perspectives include enriching the present database with new pathological and normal cases accounting for interindividual variability of anatomy and FDG uptake.",
GOOFI-2: A tool for experimental dependability assessment,"This paper presents GOOFI-2, a comprehensive fault injection tool for experimental dependability assessment of embedded systems. The tool includes a large number of extensions and improvements over its predecessor, GOOFI. These include support for three widely used fault injection techniques, two target processors, and a variety of new features for storing, disseminating and analyzing experimental data. We report on our experiences and lessons learned from the use and development of GOOFI-2. In particular, we compare and discuss properties of three fault injection techniques: Nexus-based, exception-based and instrumentation-based injection. The comparison relies on several sets of experiments with two target processors, Freescale's MPC565 and MPC5554.","Debugging,
Instruments,
Testing,
Fault diagnosis,
Fault tolerance,
ISO standards,
Road safety,
Computer science,
Embedded system,
Data analysis"
On ultra wideband channel modeling for in-body communications,"Innovative medical applications such as implant wireless sensors for health monitoring, automatic drug deliverance, etc. can be realized with the use of ultra wideband (UWB) radio technology. Nevertheless, for efficient design of wireless systems operating inside the human body a radio communication channel model is essential. Although a lot of research effort has recently been devoted to the characterization of the on-body UWB radio communication channel, just a few works describing the radio propagation inside the human body have been reported. To address this problem, a computational study of the propagation of UWB signals through human tissues in the 0.1-1 GHz and 1-6 GHz frequency bands is presented in this paper. This is based on numerical simulations using a heterogeneous anatomical model of the human body with frequency dependent tissue material properties. Subsequently, a statistical channel model is introduced for UWB in-body communications in the 1-6 GHz frequency band. The model is provided for two typical depths inside the human chest. This work contributes to the practical design of UWB medical implant communication systems.","Ultra wideband technology,
Biological system modeling,
Humans,
Implants,
Wireless sensor networks,
Radio communication,
Frequency,
Medical services,
Biomedical equipment,
Biomedical monitoring"
Active Temperature Programming for Metal-Oxide Chemoresistors,"Modulating the operating temperature of metal-oxide (MOX) chemical sensors gives rise to gas-specific signatures that provide a wealth of analytical information. In most cases, the operating temperature is modulated according to a standard waveform (e.g., ramp, sine wave). A few studies have approached the optimization of temperature profiles systematically, but these optimizations are performed offline and cannot adapt to changes in the environment. Here, we present an ¿active perception¿ strategy based on Partially Observable Markov Decision Processes (POMDP) that allows the temperature program to be optimized in real time, as the sensor reacts to its environment. We characterize the method on a ternary classification problem using a simulated sensor model subjected to additive Gaussian noise, and compare it against two ¿passive¿ approaches, a nai¿ve Bayes classifier and a nearest neighbor classifier. Finally, we validate the method in real time using a Taguchi sensor exposed to three volatile compounds. Our results show that the POMDP outperforms both passive approaches and provides a strategy to balance classification performance and sensing costs.","Temperature sensors,
Chemical sensors,
Hidden Markov models,
Sensor phenomena and characterization,
Chemical analysis,
Information analysis,
Gas detectors,
Optimization methods,
Predictive models,
Additive noise"
Home monitoring of patients with Parkinson's disease via wearable technology and a web-based application,"Objective long-term health monitoring can improve the clinical management of several medical conditions ranging from cardiopulmonary diseases to motor disorders. In this paper, we present our work toward the development of a home-monitoring system. The system is currently used to monitor patients with Parkinson's disease who experience severe motor fluctuations. Monitoring is achieved using wireless wearable sensors whose data are relayed to a remote clinical site via a web-based application. The work herein presented shows that wearable sensors combined with a web-based application provide reliable quantitative information that can be used for clinical decision making.","Monitoring,
Fluctuations,
Wearable sensors,
Feature extraction,
Parkinson's disease,
Classification algorithms,
Biomedical monitoring"
Rotating sensor-matrix camera calibration,"Panoramic images and panoramic cameras (or sensors) are of increasing importance for various applications in computer vision, computer graphics, visualization, and robotics. Various panoramic image capturing sensors have been developed for different purposes. But many of the sensing devices do not support stereo visualization. This paper reviews a methodology for stereo panorama acquisition using a widely available digital matrix camera. Two sensor parameters, off-axis distance and principle angle, are critical to achieving high quality stereo visualization. In this paper, a new camera calibration method will be presented, which supports accurate estimations of these two essential parameters. To our best knowledge, there is no other camera calibration method published so far for such a purpose.",
Keystroke biometrics with number-pad input,"Keystroke dynamics is the process of identifying individual users on the basis of their typing rhythms, which are in turn derived from the timestamps of key-press and key-release events in the keyboard. Many researchers have explored this domain, with mixed results, but few have examined the relatively impoverished territory of digits only, particularly when restricted to using a single finger - which might come into play on an automated teller machine, a mobile phone, a digital telephone dial, or a digital electronic security keypad at a building entrance. In this work, 28 users typed the same 10-digit number, using only the right-hand index finger. Employing statistical machine-learning techniques (random forest), we achieved an unweighted correct-detection rate of 99.97% with a corresponding false-alarm rate of 1.51%, using practiced 2-of-3 encore typing with outlier handling. This level of accuracy approaches sufficiency for two-factor authentication for passwords or PIN numbers.",
Mining for Computing Jobs,"A Web content mining approach identified 20 job categories and the associated skills needs prevalent in the computing professions. Using a Web content data mining application, we extracted almost a quarter million unique IT job descriptions from various job search engines and distilled each to its required skill sets. We statistically examined these, revealing 20 clusters of similar skill sets that map to specific job definitions. The results allow software engineering professionals to tune their skills portfolio to match those in demand from real computing jobs across the US to attain more lucrative salaries and more mobility in a chaotic environment.","Data mining,
Application software,
Search engines,
Software engineering,
Portfolios,
Remuneration,
Chaos"
"Smile When You Read This, Whether You Like It or Not: Conceptual Challenges to Affect Detection","The survey by Calvo and D'Mello presents a useful overview of the progress of and issues in affect detection. They focus on emotion theories that are relevant to Affective Computing (AC) and suggest stronger collaborations between disciplines. My contribution emphasizes the importance of these issues for AC. In fact, empirical research strongly suggests that facial, vocal, and bodily expressions, subjective experience, and physiological changes are often not very highly correlated in spontaneous situations. Overestimating this cohesion limits the usefulness of affect detection methods in real-world applications. Other factors, such as social context, knowledge regarding the goals of certain interactions, as well as interindividual differences are critically important factors for improving affect detection. At times, social concepts, such as politeness, might be more conducive to model realistic behavior. Knowledge on affect perception is important to estimate the level of realism required to create satisfying and productive interactions between users and artificial systems. Interdisciplinary joint research between social and biological scientists on the one hand and computer scientists and engineers on the other is necessary to deal with the complexity of affective processes. All disciplines involved have much to gain in the process.","Biology computing,
Humans,
Application software,
Collaboration,
Biological system modeling,
Face detection,
Books,
Design for experiments,
Statistical analysis,
Frequency"
Capacity-Achieving Codes With Bounded Graphical Complexity and Maximum Likelihood Decoding,"In this paper, the existence of capacity-achieving codes for memoryless binary-input output-symmetric (MBIOS) channels under maximum-likelihood (ML) decoding with bounded graphical complexity is investigated. Graphical complexity of a code is defined as the number of edges in the graphical representation of the code per information bit and is proportional to the decoding complexity per information bit per iteration under iterative decoding. Irregular repeat-accumulate (IRA) codes are studied first. Utilizing the asymptotic average weight distribution (AAWD) of these codes and invoking Divsalar's bound on the binary-input additive white Gaussian noise (BIAWGN) channel, it is shown that simple nonsystematic IRA ensembles outperform systematic IRA and regular low-density parity-check (LDPC) ensembles with the same graphical complexity, and are at most 0.124 dB away from the Shannon limit. However, a conclusive result as to whether these nonsystematic IRA codes can really achieve capacity cannot be reached. Motivated by this inconclusive result, a new family of codes is proposed, called low-density parity-check and generator matrix (LDPC-GM) codes, which are serially concatenated codes with an outer LDPC code and an inner low-density generator matrix (LDGM) code. It is shown that these codes can achieve capacity on any MBIOS channel using ML decoding and also achieve capacity on any BEC using belief propagation (BP) decoding, both with bounded graphical complexity. Moreover, it is shown that, under certain conditions, these capacity-achieving codes have linearly increasing minimum distances and achieve the asymptotic Gilbert-Varshamov bound for all rates.","Maximum likelihood decoding,
Parity check codes,
Iterative decoding,
Belief propagation,
Additive white noise,
Concatenated codes,
Communication system control,
Bipartite graph,
Message passing,
Iterative algorithms"
Sub-meter indoor localization in unmodified environments with inexpensive sensors,"The interpretation of uncertain sensor streams for localization is usually considered in the context of a robot. Increasingly, however, portable consumer electronic devices, such as smartphones, are equipped with sensors including WiFi radios, cameras, and inertial measurement units (IMUs). Many tasks typically associated with robots, such as localization, would be valuable to perform on such devices. In this paper, we present an approach for indoor localization exclusively using the low-cost sensors typically found on smartphones. Environment modification is not needed. We rigorously evaluate our method using ground truth acquired using a laser range scanner. Our evaluation includes overall accuracy and a comparison of the contribution of individual sensors. We find experimentally that fusion of multiple sensor modalities is necessary for optimal performance and demonstrate sub-meter localization accuracy.","IEEE 802.11 Standards,
Histograms,
Cameras,
Robot sensing systems,
Training"
Enabling active storage on parallel I/O software stacks,"As data sizes continue to increase, the concept of active storage is well fitted for many data analysis kernels. Nevertheless, while this concept has been investigated and deployed in a number of forms, enabling it from the parallel I/O software stack has been largely unexplored. In this paper, we propose and evaluate an active storage system that allows data analysis, mining, and statistical operations to be executed from within a parallel I/O interface. In our proposed scheme, common analysis kernels are embedded in parallel file systems. We expose the semantics of these kernels to parallel file systems through an enhanced runtime interface so that execution of embedded kernels is possible on the server. In order to allow complete server-side operations without file format or layout manipulation, our scheme adjusts the file I/O buffer to the computational unit boundary on the fly. Our scheme also uses server-side collective communication primitives for reduction and aggregation using interserver communication. We have implemented a prototype of our active storage system and demonstrate its benefits using four data analysis benchmarks. Our experimental results show that our proposed system improves the overall performance of all four benchmarks by 50.9% on average and that the compute-intensive portion of the k-means clustering kernel can be improved by 58.4% through GPU offloading when executed with a larger computational load. We also show that our scheme consistently outperforms the traditional storage model with a wide variety of input dataset sizes, number of nodes, and computational loads.","Kernel,
File systems,
Data analysis,
Computational modeling,
Data engineering,
File servers,
Runtime,
Mathematics,
Computer science,
Laboratories"
How Reliable Are Systematic Reviews in Empirical Software Engineering?,"BACKGROUND-The systematic review is becoming a more commonly employed research instrument in empirical software engineering. Before undue reliance is placed on the outcomes of such reviews it would seem useful to consider the robustness of the approach in this particular research context. OBJECTIVE-The aim of this study is to assess the reliability of systematic reviews as a research instrument. In particular, we wish to investigate the consistency of process and the stability of outcomes. METHOD-We compare the results of two independent reviews undertaken with a common research question. RESULTS-The two reviews find similar answers to the research question, although the means of arriving at those answers vary. CONCLUSIONS-In addressing a well-bounded research question, groups of researchers with similar domain experience can arrive at the same review outcomes, even though they may do so in different ways. This provides evidence that, in this context at least, the systematic review is a robust research method.","Software engineering,
Instruments,
Robustness,
Best practices,
Stability,
Costs,
Mathematics,
Computer science"
Fuzzy Key Binding Strategies Based on Quantization Index Modulation (QIM) for Biometric Encryption (BE) Applications,"Biometric encryption (BE) has recently been identified as a promising paradigm to deliver security and privacy, with unique technical merits and encouraging social implications. An integral component in BE is a key binding method, which is the process of securely combining a signal, containing sensitive information to be protected (i.e., the key), with another signal derived from physiological features (i.e., the biometric). A challenge to this approach is the high degree of noise and variability present in physiological signals. As such, fuzzy methods are needed to enable proper operations, with adequate performance results in terms of false acceptance rate and false rejection rate. In this work, the focus will be on a class of fuzzy key binding methods based on dirty paper coding known as quantization index modulation. While the methods presented are applicable to a wide range of biometric modalities, the face biometric is selected for illustrative purposes, in evaluating the QIM-based solutions for BE systems. Performance evaluation of the investigated methods is reported using data from the CMU PIE face database.","Quantization,
Biometrics,
Cryptography,
Privacy,
Signal processing,
Databases,
Data security,
Strontium,
Information security,
Protection"
Demonstration of a Differential Layout Solution for Improved ASET Tolerance in CMOS A/MS Circuits,Layout techniques that exploit charge-sharing phenomena for analog single-event transient (ASET) mitigation in fully-differential analog/mixed-signal (A/MS) designs are experimentally explored in a 65 nm CMOS process. Benefits of the proposed RHBD layout techniques are illustrated through circuit simulations. Preliminary RHBD layout guidelines are discussed.,"Radiation hardening,
Single event transient,
CMOS technology,
Circuit simulation"
Exploring the Design of 64- and 256-Core Power Efficient Nanophotonic Interconnect,"High-performance and low-power network-on-chips (NoCs) will be required to support the increasing number of cores in future chip multiprocessors. In this paper, we propose a scalable low-power 64-core NoC design called PROPEL that uses emerging nanophotonic technology. PROPEL strikes a balance between cheaper electronics and more expensive optics by facilitating nanophotonic interconnects for long distance interrouter communication and electrical switching for routing and flow control. In addition, PROPEL reduces the number of required components by facilitating communication in both the x- and y-directions. We also propose a 256-core scaled version of PROPEL called E-PROPEL that uses four separate PROPEL networks connected together by an optical crossbar. We also propose two different optical crossbar implementations using single and double microring resonators, where the single microring design has minimal optical losses (-4.32 dB) and the double microring design has minimal area overhead (0.0576 mm2). We have simulated both PROPEL and E-PROPEL using synthetic and SPLASH-2 traffic, where our results indicate that PROPEL and E-PROPEL significantly reduce power (tenfold) and increase performance (twofold) over other well-known electrical networks.","Propulsion,
Optical resonators,
Network-on-a-chip,
Optical design,
Optical interconnections,
Communication switching,
Routing,
Image motion analysis,
Optical control,
Communication system control"
Phase-Redundant-Based Reliable Direct AC/AC Converter Drive for Series Hybrid Off-Highway Heavy Electric Vehicles,"Hybrid electric vehicle (HEV) technology has numerous advantages over conventional vehicles, from standpoints of fuel economy, energy independence, and environmental concerns. Effective solutions for HEVs have been expanding their applications over highway vehicles, such as sedans and sport utility vehicles, into a variety of traditional vehicles. HEV systems applied to off-highway heavy-duty vehicles, which are operated by an engine, a generator, and traction motors, are investigated in this paper. This paper explores the use of a direct ac/ac converter for off-highway heavy-duty HEVs, which can directly drive traction motors from the generator with no intermediate dc conversion. In addition, a phase-redundant matrix converter structure with a backup leg and a control scheme is proposed to guarantee reliable and safe vehicle operations by providing continuous disturbance-free operations against converter faults. Fault-diagnosis techniques using line-to-line and phase voltages are presented not only to detect system malfunctions but to locate a failed switching device among 18 switching components as well. Appropriate reconfiguration structure and control actions with accurate knowledge about fault occurrence can avoid propagation of fault, which may lead to a catastrophic system failure.","Hybrid electric vehicles,
Road vehicles,
Traction motors,
Matrix converters,
Fuel economy,
Road transportation,
Engines,
Analog-digital conversion,
AC generators,
DC generators"
Automatic discovery of meaningful object parts with latent CRFs,"Object recognition is challenging due to high intra-class variability caused, e.g., by articulation, viewpoint changes, and partial occlusion. Successful methods need to strike a balance between being flexible enough to model such variation and discriminative enough to detect objects in cluttered, real world scenes. Motivated by these challenges we propose a latent conditional random field (CRF) based on a flexible assembly of parts. By modeling part labels as hidden nodes and developing an EM algorithm for learning from class labels alone, this new approach enables the automatic discovery of semantically meaningful object part representations. To increase the flexibility and expressiveness of the model, we learn the pairwise structure of the underlying graphical model at the level of object part interactions. Efficient gradient-based techniques are used to estimate the structure of the domain of interest and carried forward to the multi-label or object part case. Our experiments illustrate the meaningfulness of the discovered parts and demonstrate state-of-the-art performance of the approach.",
Negative correlation learning for classification ensembles,"This paper proposes a new negative correlation learning (NCL) algorithm, called AdaBoost.NC, which uses an ambiguity term derived theoretically for classification ensembles to introduce diversity explicitly. All existing NCL algorithms, such as CELS [1] and NCCD [2], and their theoretical backgrounds were studied in the regression context. We focus on classification problems in this paper. First, we study the ambiguity decomposition with the 0–1 error function, which is different from the one proposed by Krogh et al. [3]. It is applicable to both binary-class and multi-class problems. Then, to overcome the identified drawbacks of the existing algorithms, AdaBoost.NC is proposed by exploiting the ambiguity term in the decomposition to improve diversity. Comprehensive experiments are performed on a collection of benchmark data sets. The results show AdaBoost.NC is a promising algorithm to solve classification problems, which gives better performance than the standard AdaBoost and NCCD, and consumes much less computation time than CELS.","Training,
Correlation,
Training data,
Algorithm design and analysis,
Accuracy,
Context,
Measurement uncertainty"
An Annealing Approach to Router Nodes Placement Problem in Wireless Mesh Networks,"Mesh router nodes placement is a central problem to Wireless Mesh Networks (WMNs). An efficient placement of mesh router nodes is indispensable for achieving network performance in terms of both network connectivity and user coverage. Unfortunately the problem is computationally hard to solve to optimality even for small deployment areas and a small number of mesh router nodes. As WMNs are becoming an important networking infrastructure for providing cost-efficient broadband wireless connectivity, researchers are paying attention to the resolution of the mesh router placement problem through heuristic approaches in order to achieve near optimal, yet high quality solutions in reasonable time. In this work we propose and evaluate a Simulated Annealing (SA) approach to placement of mesh router nodes in WMNs. The optimization model uses two maximization objectives, namely, the size of the giant component in the network and user coverage. Both objectives are important to deployment of WMNs; the former is crucial to achieve network connectivity while the later is an indicator of the QoS in WMNs. The SA approach distinguishes for its simplicity yet its policy of neighborhood exploration allows to reach promising areas of the solution space where quality solutions could be found. We have experimentally evaluated the SA algorithm through a benchmark of generated instances, varying from small to large size, and capturing different characteristics of WMNs such as topological placements of mesh clients. The experimental results showed the efficiency of the annealing approach for the placement of mesh router nodes in WMNs.","Wireless mesh networks,
Simulated annealing,
Intelligent networks,
Competitive intelligence,
Communication system software,
Software systems,
Computer science,
Information systems,
Informatics,
Quality of service"
Data-driven optimization for underactuated robotic hands,"Passively adaptive and underactuated robotic hands have shown the potential to achieve reliable grasping in unstructured environments without expensive mechanisms or sensors. Instead of complex run-time algorithms, such hands use design-time analysis to improve performance for a wide range of tasks. Along these directions, we present an optimization framework for underactuated compliant hands. Our approach uses a pre-defined set of grasps in a quasistatic equilibrium formulation to compute the actuation mechanism design parameters that provide optimal performance. We apply our method to a class of tendon-actuated hands; for the simplified design of a two-fingered gripper, we show how a global optimum for the design optimization problem can be computed. We have implemented the results of this analysis in the construction of a gripper prototype, capable of a wide range of grasping tasks over a variety of objects.",
Theoretical Bounds and System Design for Multipinhole SPECT,"The pinhole camera in single photon emission computed tomography (SPECT) has an inherent trade-off between resolution and sensitivity. Recent systems overcome this to some extent by utilizing multiple pinholes distributed around the imaging object. The present work is a theoretical study on how to optimally construct such systems. We use an analytic model to analyze the multipinhole SPECT geometry and identify the underlying trade-offs. One of the results is the derivation of the upper bound for the sensitivity, given the geometric resolution and field-of-view (FOV). Reaching this bound requires an infinitely large detector. However, a sensitivity very close to the upper bound can be achieved by a system with realistic proportions. We show that it is usually possible to get a sensitivity that is 95%-99% of the upper bound. Further analysis reveals a trade-off between sensitivity, magnification, and the number of pinholes. Based on this new theory, we develop a strategy for multipinhole SPECT design, from which a number of example systems are computed. Penetration in the pinhole knife edge is accounted for by using the resolution and sensitivity equivalent apertures.","Upper bound,
Detectors,
High-resolution imaging,
Single photon emission computed tomography,
Positron emission tomography,
Apertures,
Image resolution,
Physics,
Cameras,
Solid modeling"
Tool for Experimenting With Concepts of Mobile Robotics as Applied to Children's Education,"This paper describes the design and implementation of a tool for experimenting with mobile robotics concepts, primarily for use by children and teenagers, or by the general public, without previous experience in robotics. This tool helps children learn about science in an approachable and interactive way, using scientific research principles in captivating activities that help the child develop problem-solving skills within his group. This initiative seeks to spark interest in scientific and engineering careers as a response to diminished enrollment in such courses by young students. The application of this tool was tested on groups of people ranging from schoolchildren to college students with diverse backgrounds and varying levels of robotics experience and knowledge. The following performance parameters were measured: time to build the robotic platform, time to finalize challenges, and the percentage of challenges successfully accomplished.",
Hardware accelerators for biocomputing: A survey,"Computing research has become a vital cog in the machinery required to drive biological discovery. Computing has made possible significant achievements over the last decade, especially in the genomics sector. An emerging area is the investigation of hardware accelerators for speeding up the massive scale of computation needed in large-scale biocomputing applications. Various hardware platforms, such as FPGA, Graphics Processing Unit (GPU), the Cell Broadband Engine (CBE) and multi-core processors are being explored. In this paper, we present a survey of hardware accelerators for biocomputing by choosing a representative set of each.","Hardware,
Biology computing,
Machinery,
Drives,
Genomics,
Bioinformatics,
Large-scale systems,
Field programmable gate arrays,
Graphics,
Engines"
Design of Compact Quadruple Inverted-F Antenna With Circular Polarization for GPS Receiver,"A compact quadruple inverted-F antenna (QIFA) with right-hand circular polarization for global positioning system (GPS) receiver is presented. The proposed QIFA consists of four spiral-shaped inverted-F antennas fed by a compact multilayered feed network. In order to improve the radiation efficiency of four-port feed antenna like QIFA, we analyze an optimum matching method considering both reflection coefficient at each port and the mutual coupling between ports simultaneously. Experimental results show that QIFA of size 10 x 10 x 12 mm3 has a 3-dB beamwidth of more than 130°, the peak gain of -1 dBic and the axial ratio under 2 dB.","Receiving antennas,
Polarization,
Global Positioning System,
Antenna feeds,
Helical antennas,
Reflector antennas,
Mutual coupling,
Antennas and propagation,
Geometry,
Impedance"
LOC8: A Location Model and Extensible Framework for Programming with Location,"Location is a core concept in most pervasive systems-and one that's surprisingly hard to deal with flexibly. Using a location model supporting a range of expressive representations for spaces, spatial relationships, and positioning systems, the authors constructed LOC8, a programming framework for exploring location data's multifaceted representations and uses. With LOC8, developers can construct complex queries by combining basic queries and additional contextual information.","Space technology,
Computer science,
Pervasive computing,
Solid modeling,
Informatics,
Educational institutions,
Abstracts,
Uncertainty,
Process design,
Global Positioning System"
Shape and refractive index recovery from single-view polarisation images,"In this paper, we propose an approach to the problem of simultaneous shape and refractive index recovery from multispectral polarisation imagery captured from a single viewpoint. The focus of this paper is on dielectric surfaces which diffusely polarise light transmitted from the dielectric body into the air. The diffuse polarisation of the reflection process is modelled using a Transmitted Radiance Sinusoid curve and the Fresnel transmission theory. We provide a method of estimating the azimuth angle of surface normals from the spectral variation of the phase of polarisation. Moreover, to render the problem of simultaneous estimation of surface orientation and index of refraction well-posed, we enforce a generative model on the material dispersion equations for the index of refraction. This generative model, together with the Fresnel transmission ratio, permit the recovery of the index of refraction and the zenith angle simultaneously. We show results on shape recovery and rendering for real world and synthetic imagery.","Shape,
Refractive index,
Optical polarization,
Dielectrics,
Focusing,
Optical reflection,
Fresnel reflection,
Phase estimation,
Azimuth,
Equations"
An Evaluation of Video-to-Video Face Verification,"Person recognition using facial features, e.g., mug-shot images, has long been used in identity documents. However, due to the widespread use of web-cams and mobile devices embedded with a camera, it is now possible to realize facial video recognition, rather than resorting to just still images. In fact, facial video recognition offers many advantages over still image recognition; these include the potential of boosting the system accuracy and deterring spoof attacks. This paper presents an evaluation of person identity verification using facial video data, organized in conjunction with the International Conference on Biometrics (ICB 2009). It involves 18 systems submitted by seven academic institutes. These systems provide for a diverse set of assumptions, including feature representation and preprocessing variations, allowing us to assess the effect of adverse conditions, usage of quality information, query selection, and template construction for video-to-video face authentication.","Face recognition,
Computational modeling,
Three dimensional displays,
Solid modeling,
Hidden Markov models,
Biometrics"
Multivoltage Floorplan Design,"Energy efficiency has become a very important issue to be addressed in today's system-on-a-chip (SoC) designs. One way to lower power consumption is to reduce the supply voltage. Multisupply voltage (MSV) is thus introduced to provide flexibility in controlling the power and performance tradeoff. In region-based MSV, circuits are partitioned into ¿voltage islands¿ where each island occupies a contiguous physical space and operates at one voltage level. These tasks of island partitioning and voltage level assignment should be done simultaneously in the floorplanning process in order to take those important physical information into consideration. In this paper, we consider this core-based voltage island driven floorplanning problem including islands with power down mode, and propose a method to solve it. Given a candidate floorplan solution represented by a normalized Polish expression, we are able to obtain optimal voltage assignment and island partitioning (including islands with power down mode) simultaneously to minimize the total power consumption. Simulated annealing is used as the basic searching engine. By using this approach, we can achieve significant power saving (up to 50%) for all datasets, without any significant increase in area and wire length. We compared our approach with the most updated previous work on the same problem, and results show that our approach is much more efficient and is able to save more power in most cases. We have also studied two other approaches to solve the same problem, a simple dynamic programming approach and a lowest possible power consumption approach. Experimental results show that ours can perform the best among these three approaches. Our floorplanner can also be extended to minimize the number of level shifters, to address a minVdd version of the problem and to simplify the power routing step by placing islands close to their corresponding power pins.",
Design Optimization of FinFET Domino Logic Considering the Width Quantization Property,"Design optimization of FinFET domino logic is particularly challenging due to the unique width quantization property of FinFET devices. Since the keeper device in domino logic is sized based on the leakage current of the pull-down network (PDN) (to meet the noise margin constraint), a reliable statistical framework is required to accurately estimate the domino gate leakage current. Considering the width quantization property, this paper presents such a statistical framework, which provides a reliable design window for keeper sizing to meet the noise margin constraint (for the practical range of threshold voltage variation in sub-32-nm technology nodes). On the other hand, the width quantization property restricts the design optimization (including power/performance characteristics) typically achieved via continuous keeper sizing in planar-CMOS domino logic designs. To cope with this restriction, this paper also introduces a novel methodology for FinFET-based keeper design, which exploits the exclusive property of FinFET devices (capacitive coupling between the front gate and the back gate in a four-terminal FinFET) to simultaneously achieve higher performance and lower power consumption. Using this new methodology, the keeper device is made weaker at the beginning of the evaluation phase to reduce its contention with the PDN, but gradually becomes stronger to provide a higher noise margin.","FinFETs,
Threshold voltage,
Leakage current,
Performance evaluation,
Quantization,
Partial discharges"
Improvement on LEACH by combining Adaptive Cluster Head Election and Two-hop transmission,"LEACH is a popular hierarchical routing protocol which efficiently maintains the energy storage of nodes in Wireless Sensor Network (WSN). The nodes using LEACH are divided into clusters. The randomized rotation of cluster head in each cluster can save the energy consumption of nodes. However, the random election of cluster heads without considering nodes' residual energy may reduce and oscillate the lifespan of network. In this paper, we have proposed the Adaptive Cluster Head Election and Two-hop LEACH protocol (ACHTH-LEACH) to prolong the lifespan of network. It improves LEACH by using an adaptive algorithm of cluster head election and allowing multi-top transmission among cluster heads and Base Station (BS). Nodes are tagged as near nodes or far nodes according to the distances to the BS. The near nodes belong to one cluster while the far nodes are divided into different clusters by the Greedy K-means algorithm. The cluster head is shifted and the node with the maximal residual energy in each cluster is elected. During the data transmission phase, the far cluster heads may select the cluster head in the near area as the next hop or communicate directly to the BS. The simulation results have shown that ACHTH-LEACH outperforms several existing protocols in terms of network's lifespan. Especially, ACHTH-LEACH can achieve more than 2 times longer lifespan than LEACH and build a more stable routing environment.","Wireless sensor networks,
Routing protocols"
Two perceptually motivated strategies for shape classification,"In this paper, we propose two new, perceptually motivated strategies to better measure the similarity of 2D shape instances that are in the form of closed contours. The first strategy handles shapes that can be decomposed into a base structure and a set of inward or outward pointing “strand” structures, where a strand structure represents a very thin, elongated shape part attached to the base structure. The similarity of two such shape contours can be better described by measuring the similarity of their base structures and strand structures in different ways. The second strategy handles shapes that exhibit good bilateral symmetry. In many cases, such shapes are invariant to a certain level of scaling transformation along their symmetry axis. In our experiments, we show that these two strategies can be integrated into available shape matching methods to improve the performance of shape classification on several widely-used shape data sets.","Shape measurement,
Shape control,
Deformable models,
Humans,
Computer science,
Automation,
Automatic control,
Energy measurement,
Mathematical model,
Optimization methods"
Translation Validation of High-Level Synthesis,"The growing complexity of systems and their implementation into silicon encourages designers to look for ways to model designs at higher levels of abstraction and then incrementally build portions of these designs - automatically or manually - from these high-level specifications. Unfortunately, this translation process itself can be buggy, which can create a mismatch between what a designer intends and what is actually implemented in the circuit. Therefore, checking if the implementation is a refinement or equivalent to its initial specification is of tremendous value. In this paper, we present an approach to automatically validate the implementation against its initial high-level specification using insights from translation validation, automated theorem proving, and relational approaches to reasoning about programs. In our experiments, we first focus on concurrent systems modeled as communicating sequential processes and show that their refinements can be validated using our approach. Next, we have applied our validation approach to a realistic scenario - a parallelizing high-level synthesis framework called Spark. We present the details of our algorithm and experimental results.",
Evolving a CUDA kernel from an nVidia template,Rather than attempting to evolve a complete program from scratch we demonstrate genetic interface programming (GIP) by automatically generating a parallel CUDA kernel with identical functionality to existing highly optimised ancient sequential C code (gzip). Generic GPGPU nVidia kernel C++ code is converted into a BNF grammar. Strongly typed genetic programming uses the BNF to generate compilable and executable graphics card kernels. Their fitness is given by running the population on a GPU with randomised subsets of training data itself derived from gzip's SIR test suite. Back-to-back validation uses the original code as a test oracle.,"Grammar,
Kernel,
Humans,
Training data,
Graphics processing unit,
Training,
Testing"
Personalized Web search with location preferences,"As the amount of Web information grows rapidly, search engines must be able to retrieve information according to the user's preference. In this paper, we propose a new web search personalization approach that captures the user's interests and preferences in the form of concepts by mining search results and their clickthroughs. Due to the important role location information plays in mobile search, we separate concepts into content concepts and location concepts, and organize them into ontologies to create an ontology-based, multi-facet (OMF) profile to precisely capture the user's content and location interests and hence improve the search accuracy. Moreover, recognizing the fact that different users and queries may have different emphases on content and location information, we introduce the notion of content and location entropies to measure the amount of content and location information associated with a query, and click content and location entropies to measure how much the user is interested in the content and location information in the results. Accordingly, we propose to define personalization effectiveness based on the entropies and use it to balance the weights between the content and location facets. Finally, based on the derived ontologies and personalization effectiveness, we train an SVM to adapt a personalized ranking function for re-ranking of future search. We conduct extensive experiments to compare the precision produced by our OMF profiles and that of a baseline method. Experimental results show that OMF improves the precision significantly compared to the baseline.","Web search,
Data privacy,
Protection,
Educational institutions,
Testing,
Data models,
Sufficient conditions,
Publishing"
On Computing Compression Trees for Data Collection in Wireless Sensor Networks,"We address the problem of efficiently gathering correlated data from a wireless sensor network, with the aim of designing algorithms with provable optimality guarantees, and understanding how close we can get to the known theoretical lower bounds. Our proposed approach is based on finding an optimal or a near-optimal {\em compression tree} for a given sensor network: a compression tree is a directed tree over the sensor network nodes such that the value of a node is compressed using the value of its parent. We focus on {\em broadcast communication} model in this paper, but our results are more generally applicable to a unicast communication model as well. We draw connections between the data collection problem and a previously studied graph concept called {\em weakly connected dominating sets}, and we use this to develop novel approximation algorithms for the problem. We present comparative results on several synthetic and real-world datasets showing that our algorithms construct near-optimal compression trees that yield a significant reduction in the data collection cost.","Computer networks,
Wireless sensor networks,
Entropy,
Protocols,
Base stations,
Costs,
Monitoring,
Communications Society,
Computer science,
Educational institutions"
A cache scheme for femtocell reselection,"In a cellular network, femto base stations may be deployed to improve indoor coverage that cannot be accommodated by the macro base stations. However, to switch from the macro-tier to the femto-tier, a user equipment may be required to scan the whole femto radio spectrum, which is an expensive operation. We propose a cache scheme that may significantly speed up the macro-tier to femto-tier switching.",
Stochastic Differential Dynamic Programming,"Although there has been a significant amount of work in the area of stochastic optimal control theory towards the development of new algorithms, the problem of how to control a stochastic nonlinear system remains an open research topic. Recent iterative linear quadratic optimal control methods iLQG handle control and state multiplicative noise while they are derived based on first order approximation of dynamics. On the other hand, methods such as Differential Dynamic Programming expand the dynamics up to the second order but so far they can handle nonlinear systems with additive noise. In this work we present a generalization of the classic Differential Dynamic Programming algorithm. We assume the existence of state and control multiplicative process noise, and proceed to derive the second-order expansion of the cost-to-go. We find the correction terms that arise from the stochastic assumption. Despite having quartic and cubic terms in the initial expression, we show that these vanish, leaving us with the same quadratic structure as standard DDP.",
Maximum Likelihood Failure Diagnosis in Finite State Machines Under Unreliable Observations,"In this paper, we develop a probabilistic methodology for failure diagnosis in finite state machines based on a sequence of unreliable observations. Given prior knowledge of the input probability distribution but without actual knowledge of the applied input sequence, the core problem we consider is to choose from a pool of known, deterministic finite state machines (FSMs) the one that most likely matches the given sequence of observations. The problem becomes challenging because of sensor failures which may corrupt the observed sequence by inserting, deleting, and transposing symbols with certain probabilities (that are assumed known). We propose an efficient recursive algorithm for obtaining the most likely underlying FSM, given the possibly erroneous observed sequence. The proposed algorithm essentially allows us to perform online maximum likelihood failure diagnosis and is applicable to more general settings where one is required to choose the most likely underlying hidden Markov model (HMM) based on a sequence of observations that may get corrupted with known probabilities. The algorithm generalizes existing recursive algorithms for likelihood calculation in HMMs by allowing loops in the associated trellis diagram. We illustrate the proposed methodology using an example of diagnosis in the context of communication protocols.",
A Distributed Topological Camera Network Representation for Tracking Applications,"Sensor networks have been widely used for surveillance, monitoring, and tracking. Camera networks, in particular, provide a large amount of information that has traditionally been processed in a centralized manner employing a priori knowledge of camera location and of the physical layout of the environment. Unfortunately, these conventional requirements are far too demanding for ad-hoc distributed networks. In this article, we present a simplicial representation of a camera network called the camera network complex (CN-complex), that accurately captures topological information about the visual coverage of the network. This representation provides a coordinate-free calibration of the sensor network and demands no localization of the cameras or objects in the environment. A distributed, robust algorithm, validated via two experimental setups, is presented for the construction of the representation using only binary detection information. We demonstrate the utility of this representation in capturing holes in the coverage, performing tracking of agents, and identifying homotopic paths.","Cameras,
Permission,
Surveillance,
Monitoring,
Calibration,
Robustness,
Costs,
Ad hoc networks,
Distributed algorithms,
Computer networks"
An Intelligent Secure and Privacy-Preserving Parking Scheme Through Vehicular Communications,"There are always frustrations for drivers in finding parking spaces and being protected from auto theft. In this paper, to minimize the drivers' hassle and inconvenience, we propose a new intelligent secure privacy-preserving parking scheme through vehicular communications. The proposed scheme is characterized by employing parking lot RSUs to surveil and manage the whole parking lot and is enabled by communication between vehicles and the RSUs. Once vehicles that are equipped with wireless communication devices, which are also known as onboard units, enter the parking lot, the RSUs communicate with them and provide the drivers with real-time parking navigation service, secure intelligent antitheft protection, and friendly parking information dissemination. In addition, the drivers' privacy is not violated. Performance analysis through extensive simulations demonstrates the efficiency and practicality of the proposed scheme.","Intelligent vehicles,
Navigation,
Protection,
Space technology,
Wireless communication,
Privacy,
Ad hoc networks,
Vehicle driving,
Performance analysis,
Analytical models"
Flexible Split-Ring Electrode for Insect Flight Biasing Using Multisite Neural Stimulation,"We describe a flexible multisite microelectrode for insect flight biasing using neural stimulation. The electrode is made of two layers of polyimide (PI) with gold sandwiched in between in a split-ring geometry. The split-ring design in conjunction with the flexibility of the PI allows for a simple insertion process and provides good attachment between the electrode and ventral nerve cord of the insect. Stimulation sites are located at the ends of protruding tips that are circularly distributed inside the split-ring structure. These protruding tips penetrate into the connective tissue surrounding the nerve cord. We have been able to insert the electrode into pupae of the giant sphinx moth Manduca sexta as early as seven days before the adult moth emerges, and we are able to use the multisite electrode to deliver electrical stimuli that evoke multidirectional, graded abdominal motions in both pupae and adult moths. Finally, in loosely tethered flight, we have used stimulation through the flexible microelectrodes to alter the abdominal angle, thus causing the flying moth to deviate to the left or right of its intended path.","Electrodes,
Insects,
Telemetry,
Electrical stimulation,
Microelectrodes,
Abdomen,
Microelectromechanical systems,
Nervous system,
Optical pulse generation,
Muscles"
Social networking of the Smart Home,"Social networking on the Web has become an integral part of our lives. Merging of computing with physical things enabled the conversion of everyday objects into information appliances. This merging allows Smart Homes to offer new automation possibilities to their residents. We propose utilizing existing social networking infrastructures and their Web-based APIs in order to integrate Smart Homes to the Web, offering social status to physical devices. We exploit the functionality and the Web 2.0 technologies provided by Facebook to transform the interaction with the Smart Home into a shared, social experience. A preliminary technical evaluation indicates that our approach is feasible and it offers acceptable performance.",
Efficient Volume Sampling for Row/Column Subset Selection,"We give efficient algorithms for volume sampling, i.e., for picking k-subsets of the rows of any given matrix with probabilities proportional to the squared volumes of the simplices defined by them and the origin (or the squared volumes of the parallelepipeds defined by these subsets of rows). %In other words, we can efficiently sample k-subsets of [m] with probabilities proportional to the corresponding k by k principal minors of any given m by m positive semi definite matrix. This solves an open problem from the monograph on spectral algorithms by Kannan and Vempala (see Section 7.4 of \cite{KV}, also implicit in \cite{BDM, DRVW}). Our first algorithm for volume sampling k-subsets of rows from an m-by-n matrix runs in O(kmn^\omega \log n) arithmetic operations (where \omega is the exponent of matrix multiplication) and a second variant of it for (1+\eps)-approximate volume sampling runs in O(mn \log m \cdot k^{2}/\eps^{2} + m \log^{\omega} m \cdot k^{2\omega+1}/\eps^{2\omega} \cdot \log(k \eps^{-1} \log m)) arithmetic operations, which is almost linear in the size of the input (i.e., the number of entries) for small k. Our efficient volume sampling algorithms imply the following results for low-rank matrix approximation: (1) Given A \in \reals^{m \times n}, in O(kmn^{\omega} \log n) arithmetic operations we can find k of its rows such that projecting onto their span gives a \sqrt{k+1}-approximation to the matrix of rank k closest to A under the Frobenius norm. This improves the O(k \sqrt{\log k})-approximation of Boutsidis, Drineas and Mahoney \cite{BDM} and matches the lower bound shown in \cite{DRVW}. The method of conditional expectations gives a \emph{deterministic} algorithm with the same complexity. The running time can be improved to O(mn \log m \cdot k^{2}/\eps^{2} + m \log^{\omega} m \cdot k^{2\omega+1}/\eps^{2\omega} \cdot \log(k \eps^{-1} \log m)) at the cost of losing an extra (1+\eps) in the approximation factor. (2) The same rows and projection as in the previous point give a \sqrt{(k+1)(n-k)}-approximation to the matrix of rank k closest to A under the spectral norm. In this paper, we show an almost matching lower bound of \sqrt{n}, even for k=1.","Polynomials,
Approximation methods,
Matrix decomposition,
Algorithm design and analysis,
Vectors,
Approximation algorithms,
Principal component analysis"
Tight Bounds on the Capacity of Binary Input Random CDMA Systems,"In this paper, we consider code-division multiple-access (CDMA) communication over a binary input additive white Gaussian noise (AWGN) channel using random spreading. For a general class of symmetric distributions for spreading sequences, in the limit of a large number of users, we prove an upper bound to the capacity. The bound matches the formula obtained by Tanaka using the replica method. We also show concentration of various relevant quantities including mutual information and free energy. The mathematical methods are quite general and allow us to discuss extensions to other multiuser scenarios.",
Efficient and Robust Detection of Duplicate Videos in a Large Database,"We present an efficient and accurate method for duplicate video detection in a large database using video fingerprints. We have empirically chosen the color layout descriptor, a compact and robust frame-based descriptor, to create fingerprints which are further encoded by vector quantization (VQ). We propose a new nonmetric distance measure to find the similarity between the query and a database video fingerprint and experimentally show its superior performance over other distance measures for accurate duplicate detection. Efficient search cannot be performed for high-dimensional data using a nonmetric distance measure with existing indexing techniques. Therefore, we develop novel search algorithms based on precomputed distances and new dataset pruning techniques yielding practical retrieval times. We perform experiments with a database of 38 000 videos, worth 1600 h of content. For individual queries with an average duration of 60 s (about 50% of the average database video length), the duplicate video is retrieved in 0.032 s, on Intel Xeon with CPU 2.33 GHz, with a very high accuracy of 97.5%.","Videos,
Databases,
Fingerprint recognition,
Watermarking,
Vector quantization,
Information retrieval,
Noise robustness,
Performance evaluation,
Indexing,
Cross layer design"
Object detection using Non-Redundant Local Binary Patterns,"Local Binary Pattern (LBP) as a descriptor, has been successfully used in various object recognition tasks because of its discriminative property and computational simplicity. In this paper a variant of the LBP referred to as Non-Redundant Local Binary Pattern (NRLBP) is introduced and its application for object detection is demonstrated. Compared with the original LBP descriptor, the NRLBP has advantage of providing a more compact description of object's appearance. Furthermore, the NRLBP is more discriminative since it reflects the relative contrast between the background and foreground. The proposed descriptor is employed to encode human's appearance in a human detection task. Experimental results show that the NRLBP is robust and adaptive with changes of the background and foreground and also outperforms the original LBP in detection task.",
FRATS: Functional Regression Analysis of DTI Tract Statistics,"Diffusion tensor imaging (DTI) provides important information on the structure of white matter fiber bundles as well as detailed tissue properties along these fiber bundles in vivo. This paper presents a functional regression framework, called FRATS, for the analysis of multiple diffusion properties along fiber bundle as functions in an infinite dimensional space and their association with a set of covariates of interest, such as age, diagnostic status and gender, in real applications. The functional regression framework consists of four integrated components: the local polynomial kernel method for smoothing multiple diffusion properties along individual fiber bundles, a functional linear model for characterizing the association between fiber bundle diffusion properties and a set of covariates, a global test statistic for testing hypotheses of interest, and a resampling method for approximating the p-value of the global test statistic. The proposed methodology is applied to characterizing the development of five diffusion properties including fractional anisotropy, mean diffusivity, and the three eigenvalues of diffusion tensor along the splenium of the corpus callosum tract and the right internal capsule tract in a clinical study of neurodevelopment. Significant age and gestational age effects on the five diffusion properties were found in both tracts. The resulting analysis pipeline can be used for understanding normal brain development, the neural bases of neuropsychiatric disorders, and the joint effects of environmental and genetic factors on white matter fiber bundles.","Regression analysis,
Diffusion tensor imaging,
Statistical analysis,
Optical fiber testing,
In vivo,
Polynomials,
Kernel,
Smoothing methods,
Anisotropic magnetoresistance,
Eigenvalues and eigenfunctions"
Wound Bleeding Control by Low Temperature Air Plasma,"A portable low temperature air plasma torch was used to control bleeding from wounds. As animal models, two pigs were used in the tests: one for the plasma treatment, and the other as the untreated control. Plasma effects on the bleeding times of three types of wounds (straight cut and cross cut in the ham area, and a hole in the saphenous vein of an ear) were examined. The results were that this plasma torch shortened the bleeding time for these three types of wounds from about 3 min to 18 s, about 4 min to 13 s, and 88 s to 15 s, respectively. Emission spectroscopy of the torch was performed to explore the reactive species carried by the plasma effluent of the torch. The results show that this torch carries abundant reactive atomic oxygen (RAO), which is the dominant reactive species in the plasma effluent. RAO can activate erythrocyte-platelet interactions to enhance blood coagulation for plug formation. The present tests indicate that RAO can also penetrate through the skin surrounding the wound to block capillary blood flow to the wound.","Plasma temperature,
Wounds,
Hemorrhaging,
Temperature control,
Testing,
Effluents,
Animals,
Veins,
Ear,
Spectroscopy"
Maximizing Lifetime in Relay Cooperation Through Energy-Aware Power Allocation,"We study the problem of optimal power allocation among relays for lifetime maximization in a dual-hop cooperative network operated by amplify-and-forward relays with battery limitation. We first formulate the optimization problem for global noncausal power allocation and present a solution based on dual decomposition. In the special case of static channels, we provide a closed-form solution for lifetime maximization, which simply requires equally distributing energy over time for each participating relay. Based on this, we then develop a perceived lifetime (PLT) power allocation strategy, which can be viewed as a causal implementation of the noncausal solution by considering only the current channel state information. We also present a minimum weighted total power (MWTP) strategy that does not depend on the prediction of future channel state. PLT and MWTP are compared through analysis and simulation, and it is demonstrated that both result in lifetime performance close to that of the noncausal optimal solution, and that they significantly outperform the conventional strategy of minimizing the total power per transmission, especially when the link conditions are asymmetric or initial energy levels nonuniform among relays. We further extend the proposed power allocation strategies to relay cooperation with multiple sources and discuss how different network configurations affect relay power sharing among the sources.","Relays,
Batteries,
Power system relaying,
Closed-form solution,
Channel state information,
Performance analysis,
Analytical models,
Energy states,
Research and development,
Throughput"
Unitary Linear Dispersion Code Design and Optimization for MIMO Communication Systems,"Linear Dispersion Codes (LDCs) have recently attracted numerous research interests. Thanks to their efficient spreading of data across both the time and spatial domains, LDCs are capable of achieving a desired Diversity-Multiplexing Trade-off (DMT) in Multiple Input Multiple Output (MIMO) broadband wireless access systems. This paper proposes a novel LDC design method, which relies on the unitary matrix theory combined with a Genetic Algorithm (GA) aided optimization procedure. The proposed design provides a flexible framework, where new LDCs attaining higher data rates and better error resilience than a number of classic MIMO schemes can be generated.","Design optimization,
MIMO,
Maximum likelihood decoding,
OFDM modulation,
Genetic algorithms,
Algorithm design and analysis,
Optimization methods,
Communication systems,
Design methodology,
Resilience"
Securing Cluster-Based Ad Hoc Networks with Distributed Authorities,"In this paper, we address key management in cluster-based mobile ad hoc networks (MANETs). Ensuring secure communication in an ad hoc network is extremely challenging because of the dynamic nature of the network and the lack of centralized management. For this reason, key management is particularly difficult to implement in such networks. We present a fully-distributed ID-based multiple secrets key management scheme (IMKM). This scheme is implemented via a combination of ID-based multiple secrets and threshold cryptography. It eliminates the need for certificate-based authenticated public-key distribution and provides an efficient mechanism for key update and key revocation schemes, which leads to more suitable, economic, adaptable, scalable, and autonomous key management for mobile ad hoc networks.",
An ensemble of differential evolution algorithms for constrained function optimization,"This paper presents an ensemble of differential evolution algorithms employing the variable parameter search and two distinct mutation strategies in the ensemble to solve real-parameter constrained optimization problems. It is well known that the performance of DE is sensitive to the choice of mutation strategies and associated control parameters. For these reasons, the ensemble is achieved in such a way that each individual is assigned to one of the two distinct mutation strategies or a variable parameter search (VPS). The algorithm was tested using benchmark instances in Congress on Evolutionary Computation 2010. For these benchmark problems, the problem definition file, codes and evaluation criteria are available in http://www.ntu.edu.sg/home/EPNSugan. Since the optimal or best known solutions are not available in the literature, the detailed computational results required in line with the special session format are provided for the competition.",
Joint Learning of Labels and Distance Metric,"Machine learning algorithms frequently suffer from the insufficiency of training data and the usage of inappropriate distance metric. In this paper, we propose a joint learning of labels and distance metric (JLLDM) approach, which is able to simultaneously address the two difficulties. In comparison with the existing semi-supervised learning and distance metric learning methods that focus only on label prediction or distance metric construction, the JLLDM algorithm optimizes the labels of unlabeled samples and a Mahalanobis distance metric in a unified scheme. The advantage of JLLDM is multifold: 1) the problem of training data insufficiency can be tackled; 2) a good distance metric can be constructed with only very few training samples; and 3) no radius parameter is needed since the algorithm automatically determines the scale of the metric. Extensive experiments are conducted to compare the JLLDM approach with different semi-supervised learning and distance metric learning methods, and empirical results demonstrate its effectiveness.","Semisupervised learning,
Training data,
Learning systems,
Machine learning algorithms,
Optimization methods,
Employment,
Prediction algorithms,
Euclidean distance,
Asia,
Degradation"
"A Scalable, Accurate Hybrid Recommender System","Recommender systems apply machine learning techniques for filtering unseen information and can predict whether a user would like a given resource. There are three main types of recommender systems: collaborative filtering, content-based filtering, and demographic recommender systems. Collaborative filtering recommender systems recommend items by taking into account the taste (in terms of preferences of items) of users, under the assumption that users will be interested in items that users similar to them have rated highly. Content-based filtering recommender systems recommend items based on the textual information of an item, under the assumption that users will like similar items to the ones they liked before. Demographic recommender systems categorize users or items based on their personal attribute and make recommendation based on demographic categorizations. These systems suffer from scalability, data sparsity, and cold-start problems resulting in poor quality recommendations and reduced coverage. In this paper, we propose a unique cascading hybrid recommendation approach by combining the rating, feature, and demographic information about items. We empirically show that our approach outperforms the state of the art recommender system algorithms, and eliminates recorded problems with recommender systems.",
Differential Evolution Approach for Regularized Bioluminescence Tomography,"Bioluminescence tomography (BLT) is an inverse source problem that localizes and quantifies bioluminescent probe distribution in 3-D. The generic BLT model is ill-posed, leading to nonunique solutions and aberrant reconstruction in the presence of measurement noise and optical parameter mismatches. In this paper, we introduce the knowledge of the number of bioluminescence sources to stabilize the BLT problem. Based on this regularized BLT model, we develop a differential evolution-based reconstruction algorithm to determine the source locations and strengths accurately and reliably. Then, we evaluate this novel approach in numerical, phantom, and mouse studies.",
"Parallel, real-time visual SLAM","In this paper we present a novel system for real-time, six degree of freedom visual simultaneous localization and mapping using a stereo camera as the only sensor. The system makes extensive use of parallelism both on the graphics processor and through multiple CPU threads. Working together these threads achieve real-time feature tracking, visual odometry, loop detection and global map correction using bundle adjustment. The resulting corrections are fed back into to the visual odometry system to limit its drift over long sequences. We demonstrate our system on a series videos from challenging indoor environments with moving occluders, visually homogenous regions with few features, scene parts with large changes in lighting and fast camera motion. The total system performs its task of global map building in real time including loop detection and bundle adjustment on typical office building scale scenes.","Cameras,
Visualization,
Three dimensional displays,
Real time systems,
Feature extraction,
Tracking,
Simultaneous localization and mapping"
Model-Based Estimation of Forest Canopy Height in Red and Austrian Pine Stands Using Shuttle Radar Topography Mission and Ancillary Data: A Proof-of-Concept Study,"In this paper, accurate tree stand height retrieval is demonstrated using C-band Shuttle Radar Topography Mission (SRTM) height and ancillary data. The tree height retrieval algorithm is based on modeling uniform tree stands with a single layer of randomly oriented vegetation particles. For such scattering media, the scattering phase center height, as measured by SRTM, is a function of tree height, incidence angle, and the extinction coefficient of the medium. The extinction coefficient for uniform tree stands is calculated as a function of tree height and density using allometric equations and a fractal tree model. The accuracy of the proposed algorithm is demonstrated using SRTM and TOPSAR data for 15 red pine and Austrian pine stands (TOPSAR is an airborne interferometric synthetic aperture radar). The algorithm yields root-mean-square (rms) errors of 2.5-3.6 m, which is a substantial improvement over the 6.8-8.3-m rms errors from the raw SRTM minus National Elevation Dataset Heights.","Surfaces,
Radar scattering,
Particle scattering,
Extinction coefficients,
Information retrieval,
Vegetation,
Phase measurement,
Equations,
Fractals,
Synthetic aperture radar interferometry"
Learning a Hierarchical Deformable Template for Rapid Deformable Object Parsing,"In this paper, we address the tasks of detecting, segmenting, parsing, and matching deformable objects. We use a novel probabilistic object model that we call a hierarchical deformable template (HDT). The HDT represents the object by state variables defined over a hierarchy (with typically five levels). The hierarchy is built recursively by composing elementary structures to form more complex structures. A probability distribution-a parameterized exponential model-is defined over the hierarchy to quantify the variability in shape and appearance of the object at multiple scales. To perform inference-to estimate the most probable states of the hierarchy for an input image-we use a bottom-up algorithm called compositional inference. This algorithm is an approximate version of dynamic programming where approximations are made (e.g., pruning) to ensure that the algorithm is fast while maintaining high performance. We adapt the structure-perceptron algorithm to estimate the parameters of the HDT in a discriminative manner (simultaneously estimating the appearance and shape parameters). More precisely, we specify an exponential distribution for the HDT using a dictionary of potentials, which capture the appearance and shape cues. This dictionary can be large and so does not require handcrafting the potentials. Instead, structure-perceptron assigns weights to the potentials so that less important potentials receive small weights (this is like a ?soft? form of feature selection). Finally, we provide experimental evaluation of HDTs on different visual tasks, including detection, segmentation, matching (alignment), and parsing. We show that HDTs achieve state-of-the-art performance for these different tasks when evaluated on data sets with groundtruth (and when compared to alternative algorithms, which are typically specialized to each task).","Inference algorithms,
Shape,
Object detection,
Deformable models,
Dictionaries,
Image segmentation,
Computer vision,
Face detection,
State estimation,
Dynamic programming"
Control over WirelessHART network,"It has been observed that the history of industrial process control development is also a history of reducing the number of wires necessary for effecting the control. Control over wireless is the end of this evolution. Wireless control faces a lot of challenges such as security, reliability, feedback latency, battery longevity, etc. In this paper we report some experience with implementing control over wireless. The platform we use is the WirelessHART mesh network, the first international industrial wireless control standard. We describe a full implementation of the standard and study the issues and solutions in its application. Our data suggest that WirelessHART technology is up to the challenge of wireless control.","Wireless communication,
Logic gates,
Communication system security,
Wireless sensor networks,
Sensors,
Actuators,
Reliability"
Learning grasp stability based on tactile data and HMMs,"In this paper, the problem of learning grasp stability in robotic object grasping based on tactile measurements is studied. Although grasp stability modeling and estimation has been studied for a long time, there are few robots today able of demonstrating extensive grasping skills. The main contribution of the work presented here is an investigation of probabilistic modeling for inferring grasp stability based on learning from examples. The main objective is classification of a grasp as stable or unstable before applying further actions on it, e.g. lifting. The problem cannot be solved by visual sensing which is typically used to execute an initial robot hand positioning with respect to the object. The output of the classification system can trigger a regrasping step if an unstable grasp is identified. An off-line learning process is implemented and used for reasoning about grasp stability for a three-fingered robotic hand using Hidden Markov models. To evaluate the proposed method, experiments are performed both in simulation and on a real robot system.","Hidden Markov models,
Stability analysis,
Shape,
Grasping,
Tactile sensors"
Measures and setbacks for controlling electricity theft,"Most of the utility companies in developing countries incur huge losses because of the non-technical losses (NTL). It is very difficult to detect and control potential causes of NTL in developing countries due to their poor infrastructure. Electricity theft and billing irregularities form a major chunk of NTL. These losses affect quality of supply, electrical load on the generating station and tariff imposed on electricity consumed by genuine customers. This paper discusses various factors those influence the consumer to make an attempt to steal electricity In addition, some handy cases where electricity theft are detected will be illustrated. In view of these ill effects, some methods for detection and estimation of the theft will be discussed. This paper also illustrates several methods to quantify and control theft. In essence, setbacks for implementation of these measures and techniques will be illustrated in detail. Motivation of this work is to conserve the interest of utility companies in providing quality electricity to genuine customers at affordable tariff.","Electricity,
Companies,
Wires,
Economics,
Transmission line measurements,
Inspection,
Communities"
Adaptive Filter Design Using Recurrent Cerebellar Model Articulation Controller,"A novel adaptive filter is proposed using a recurrent cerebellar-model-articulation-controller (CMAC). The proposed locally recurrent globally feedforward recurrent CMAC (RCMAC) has favorable properties of small size, good generalization, rapid learning, and dynamic response, thus it is more suitable for high-speed signal processing. To provide fast training, an efficient parameter learning algorithm based on the normalized gradient descent method is presented, in which the learning rates are on-line adapted. Then the Lyapunov function is utilized to derive the conditions of the adaptive learning rates, so the stability of the filtering error can be guaranteed. To demonstrate the performance of the proposed adaptive RCMAC filter, it is applied to a nonlinear channel equalization system and an adaptive noise cancelation system. The advantages of the proposed filter over other adaptive filters are verified through simulations.","Adaptive filters,
Nonlinear filters,
Neural networks,
Noise cancellation,
Adaptive signal processing,
Signal processing algorithms,
Adaptive equalizers,
Digital filters,
Information filtering,
Information filters"
Growing semantically meaningful models for visual SLAM,"Though modern Visual Simultaneous Localisation and Mapping (vSLAM) systems are capable of localising robustly and efficiently even in the case of a monocular camera, the maps produced are typically sparse point-clouds that are difficult to interpret and of little use for higher-level reasoning tasks such as scene understanding or human- machine interaction. In this paper we begin to address this deficiency, presenting progress on expanding the competency of visual SLAM systems to build richer maps. Specifically, we concentrate on modelling indoor scenes using semantically meaningful surfaces and accompanying labels, such as “floor”, “wall”, and “ceiling” - an important step towards a representation that can support higher-level reasoning and planning. We leverage the Manhattan world assumption and show how to extract vanishing directions jointly across a video stream. We then propose a guided line detector that utilises known vanishing points to extract extremely subtle axis- aligned edges. We utilise recent advances in single view structure recovery to building geometric scene models and demonstrate our system operating on-line.","Simultaneous localization and mapping,
Layout,
Cameras,
Image edge detection,
Floors,
Clouds,
Image reconstruction,
Photometry,
Buildings,
Surface reconstruction"
Development of dual PZT transducers for reference-free crack detection in thin plate structures,"A new Lamb-wave-based nondestructive testing (NDT) technique, which does not rely on previously stored baseline data, is developed for crack monitoring in plate structures. Commonly, the presence of damage is identified by comparing ""current data"" measured from a potentially damaged stage of a structure with ""baseline data"" previously obtained at the intact condition of the structure. In practice, structural defects typically take place long after collection of the baseline data, and the baseline data can be also affected by external loading, temperature variations, and changing boundary conditions. To eliminate the dependence on the baseline data comparison, the authors previously developed a reference-free NDT technique using 2 pairs of collocated lead zirconate titanate (PZT) transducers placed on both sides of a plate. This reference-free technique is further advanced in the present study by the necessity of attaching transducers only on a single surface of a structure for certain applications such as aircraft. To achieve this goal, a new design of PZT transducers called dual PZT transducers is proposed. Crack formation creates Lamb wave mode conversion due to a sudden thickness change of the structure. This crack appearance is instantly detected from the measured Lamb wave signals using the dual PZT transducers. This study also suggests a reference-free statistical approach that enables damage classification using only the currently measured data set. Numerical simulations and experiments were conducted using an aluminum plate with uniform thickness and fundamental Lamb waves modes to demonstrate the applicability of the proposed technique to reference-free crack detection.","Transducers,
Current measurement,
Nondestructive testing,
Temperature,
Boundary conditions,
Titanium compounds,
Joining processes,
Surface cracks,
Aircraft,
Numerical simulation"
Tunable Infrared Emission From Printed Colloidal Quantum Dot/Polymer Composite Films on Flexible Substrates,"A simple and robust device structure for a flexible, multicolor infrared (IR) display is described. The display operates by optical downconversion of AC-driven blue phosphor electroluminescence using different-sized, IR-emitting colloidal quantum dots. Deposition of the IR emissive layer via inkjet printing facilitates side-by-side multicolor pixel definition with low material losses.","Polymer films,
Quantum dots,
Optical films,
Displays,
Robustness,
Stimulated emission,
Optical polymers,
Phosphors,
Electroluminescent devices,
Printing"
QR factorization of tall and skinny matrices in a grid computing environment,"Previous studies have reported that common dense linear algebra operations do not achieve speed up by using multiple geographical sites of a computational grid. Because such operations are the building blocks of most scientific applications, conventional supercomputers are still strongly predominant in high-performance computing and the use of grids for speeding up large-scale scientific problems is limited to applications exhibiting parallelism at a higher level. We have identified two performance bottlenecks in the distributed memory algorithms implemented in ScaLAPACK, a state-of-the-art dense linear algebra library. First, because ScaLA-PACK assumes a homogeneous communication network, the implementations of ScaLAPACK algorithms lack locality in their communication pattern. Second, the number of messages sent in the ScaLAPACK algorithms is significantly greater than other algorithms that trade flops for communication. In this paper, we present a new approach for computing a QR factorization - one of the main dense linear algebra kernels - of tall and skinny matrices in a grid computing environment that overcomes these two bottlenecks. Our contribution is to articulate a recently proposed algorithm (Communication Avoiding QR) with a topology-aware middleware (QCG-OMPI) in order to confine intensive communications (ScaLAPACK calls) within the different geographical sites. An experimental study conducted on the Grid'5000 platform shows that the resulting performance increases linearly with the number of geographical sites on large-scale problems (and is in particular consistently higher than ScaLAPACK's).","Grid computing,
Linear algebra,
Large-scale systems,
Supercomputers,
Concurrent computing,
Parallel processing,
Libraries,
Communication networks,
Kernel,
Middleware"
A Semantic Feature Model in Concurrent Engineering,"Concurrent engineering (CE) is a methodology applied to product lifecycle development so that high quality, well designed products can be provided at lower prices and in less time. Many research works have been proposed for efficiently modeling of different domains in CE. However, an integration of these works with consistent data flow is absent and still in great demand in industry. In this paper, we present a generic integration framework with a semantic feature model for knowledge representation and reasoning across domains in CE. An implementation of the proposed semantic feature model is presented to demonstrate its advantage in knowledge representation by feature transformation across domains in CE.","Concurrent engineering,
Knowledge representation,
Manufacturing industries,
Process planning,
Product development,
Product design,
Inspection,
Design automation,
Computer aided manufacturing,
Computer integrated manufacturing"
User's favorite scent design using paired comparison-based Interactive Differential Evolution,"This study proposes a method that creates a scent suited with a user's favor using paired comparison-based Interactive Differential Evolution. In the proposed method, the user smells two scents and selects the preferred one by simple comparison. Based on the repetitive comparisons, Differential Evolution (DE) optimizes the scent suited with the user. Each scent is composed of several source scents, and strength of each source scent is described as values in DE's vector. To investigate the efficacy of the proposed method fundamentally, smelling experiments composed of comparing experiment and evaluating experiment are performed. In the comparing experiment, the subjects compare presented pair scents and select the preferred one through ten generations, and DE evolves scent to user's favor based on the comparisons. In the evaluating experiment, the subjects evaluate four representative scents picked from 0-, 3-, 6-, 9-th generations, respectively. The results of the experiments showed a tendency of the increase of fitness value in accordance with evolution.","IEC,
Optimization,
Evolutionary computation,
IEC standards,
Concrete,
Evolution (biology),
Fatigue"
Parallel Recording of Single Ion Channels: A Heterogeneous System Approach,"The convergence of integrated electronic devices with nanotechnology structures on heterogeneous systems presents promising opportunities for the development of new classes of rapid, sensitive, and reliable sensors. The main advantage of embedding microelectronic readout structures with sensing elements is twofold. On the one hand, the SNR is increased as a result of scaling. On the other, readout miniaturization allows organization of sensors into arrays. The latter point will improve sensing accuracy by using statistical methods. However, accurate interface design is required to establish efficient communication between ionic-based and electronic-based signals. This paper shows a first example of a concurrent readout system with single-ion channel resolution, using a compact and scalable architecture. An array of biological nanosensors is organized on different layers stacked together in a mixed structure: fluidics, printed circuit board, and microelectronic readout. More specifically, an array of microholes machined into a polyoxymethylene homopolymer (POMH or Delrin) device coupled with ultralow noise sigma-delta converters current amplifiers, is used to form bilayer membranes within which ion channels are embedded. It is shown how formation of multiple artificial bilayer lipid membranes (BLMs) is automatically monitored by the interface. The system is used to detect current signals in the pA range, from noncovalent binding between single, BLM-embedded ¿-hemolysin pores and ß-cyclodextrin molecules. The current signals are concurrently processed by the readout structure.","Sensor arrays,
Microelectronics,
Biomembranes,
Convergence,
Nanotechnology,
Sensor systems,
Statistical analysis,
Signal design,
Signal resolution,
Nanobioscience"
Impact of Body Doping and Thickness on the Performance of Germanium-Source TFETs,The impact of body doping and thickness on the performance of a germanium-source tunnel field-effect transistor in which band-to-band tunneling occurs entirely within the source region is investigated via 2-D device simulations calibrated to experimental data. It is found that the dominant leakage mechanism varies depending on the body design parameter values. A moderately doped (1018 cm-3) body that is not fully depleted provides for the best transistor performance.,"Tunneling,
Doping,
Transistors,
Logic gates,
Silicon,
Junctions,
Semiconductor process modeling"
Analyzing and adjusting user runtime estimates to improve job scheduling on the Blue Gene/P,"Backfilling and short-job-first are widely acknowledged enhancements to the simple but popular first-come, first-served job scheduling policy. However, both enhancements depend on user-provided estimates of job runtime, which research has repeatedly shown to be inaccurate. We have investigated the effects of this inaccuracy on backfilling and different queue prioritization policies, determining which part of the scheduling policy is most sensitive. Using these results, we have designed and implemented several estimation-adjusting schemes based on historical data. We have evaluated these schemes using workload traces from the Blue Gene/P system at Argonne National Laboratory. Our experimental results demonstrate that dynamically adjusting job runtime estimates can improve job scheduling performance by up to 20%.","Runtime,
Processor scheduling,
Computer science,
Laboratories,
System performance,
Delay,
Mathematics,
Dynamic scheduling,
Large-scale systems,
Out of order"
Sensor Placement for Triangulation-Based Localization,"Robots operating in a workspace can localize themselves by querying nodes of a sensor-network deployed in the same workspace. This paper addresses the problem of computing the minimum number and placement of sensors so that the localization uncertainty at every point in the workspace is less than a given threshold. We focus on triangulation-based state estimation, where measurements from two sensors must be combined for an estimate. This problem is NP-hard in its most general from. For the general version, we present a solution framework based on integer linear programming and demonstrate its application in a fire-tower placement task. Next, we study the special case of bearing-only localization and present an approximation algorithm with a constant factor performance guarantee.","Robot sensing systems,
State estimation,
Robustness,
Fires,
Robot vision systems,
Cameras,
Robotics and automation,
Integer linear programming,
Approximation algorithms,
Mobile robots"
MIMO Radar Waveform Design via Alternating Projection,"Waveform design is essential to unleash the performance advantages promised by multiple-input multiple-output (MIMO) radar, and this topic has attracted a lot of attention in the recent years. Revisiting an earlier examined MIMO radar waveform design problem that optimizes both minimum mean-square error estimation (MMSE) and mutual information (MI), in this correspondence we formulate a new waveform design problem and provide some further results, which complement the previous study. More specifically, we present an iterative optimization algorithm based on the alternating projection method to determine waveform solutions that can simultaneously satisfy a structure constraint and optimize the design criteria. Numerical examples are provided, which illustrate the effectiveness of the proposed approach. In particular, we find that the waveform solutions obtained through our proposed algorithm can achieve very close and virtually indistinguishable performance from that predicted in the previous study.","MIMO,
Radar,
Design optimization,
Mutual information,
Constraint optimization,
Iterative algorithms,
Covariance matrix,
Estimation error,
Iterative methods"
Semisupervised Kernel Matrix Learning by Kernel Propagation,"The goal of semisupervised kernel matrix learning (SS-KML) is to learn a kernel matrix on all the given samples on which just a little supervised information, such as class label or pairwise constraint, is provided. Despite extensive research, the performance of SS-KML still leaves some space for improvement in terms of effectiveness and efficiency. For example, a recent pairwise constraints propagation (PCP) algorithm has formulated SS-KML into a semidefinite programming (SDP) problem, but its computation is very expensive, which undoubtedly restricts PCPs scalability in practice. In this paper, a novel algorithm, called kernel propagation (KP), is proposed to improve the comprehensive performance in SS-KML. The main idea of KP is first to learn a small-sized sub-kernel matrix (named seed-kernel matrix) and then propagate it into a larger-sized full-kernel matrix. Specifically, the implementation of KP consists of three stages: 1) separate the supervised sample (sub)set from the full sample set ; 2) learn a seed-kernel matrix on through solving a small-scale SDP problem; and 3) propagate the learnt seed-kernel matrix into a full-kernel matrix on . Furthermore, following the idea in KP, we naturally develop two conveniently realizable out-of-sample extensions for KML: one is batch-style extension, and the other is online-style extension. The experiments demonstrate that KP is encouraging in both effectiveness and efficiency compared with three state-of-the-art algorithms and its related out-of-sample extensions are promising too.","Kernel,
Laplace equations,
Accuracy,
Propagation,
Supervised learning,
Programming,
Machine learning"
Prospective Infectious Disease Outbreak Detection Using Markov Switching Models,"Accurate and timely detection of infectious disease outbreaks provides valuable information which can enable public health officials to respond to major public health threats in a timely fashion. However, disease outbreaks are often not directly observable. For surveillance systems used to detect outbreaks, noises caused by routine behavioral patterns and by special events can further complicate the detection task. Most existing detection methods combine a time series filtering procedure followed by a statistical surveillance method. The performance of this ""two-step¿ detection method is hampered by the unrealistic assumption that the training data are outbreak-free. Moreover, existing approaches are sensitive to extreme values, which are common in real-world data sets. We considered the problem of identifying outbreak patterns in a syndrome count time series using Markov switching models. The disease outbreak states are modeled as hidden state variables which control the observed time series. A jump component is introduced to absorb sporadic extreme values that may otherwise weaken the ability to detect slow-moving disease outbreaks. Our approach outperformed several state-of-the-art detection methods in terms of detection sensitivity using both simulated and real-world data.",
"Silicon-on-insulator-based high-voltage, high-temperature integrated circuit gate driver for silicon carbide-based power field effect transistors","Silicon carbide (SiC)-based field effect transistors (FETs) are gaining popularity as switching elements in power electronic circuits designed for high-temperature environments like hybrid electric vehicle, aircraft, well logging, geothermal power generation etc. Like any other power switches, SiC-based power devices also need gate driver circuits to interface them with the logic units. The placement of the gate driver circuit next to the power switch is optimal for minimising system complexity. Successful operation of the gate driver circuit in a harsh environment, especially with minimal or no heat sink and without liquid cooling, can increase the power-to-volume ratio as well as the power-to-weight ratio for power conversion modules such as a DC-DC converter, inverter etc. A silicon-on-insulator (SOI)-based high-voltage, high-temperature integrated circuit (IC) gate driver for SiC power FETs has been designed and fabricated using a commercially available 0.8--m, 2-poly and 3-metal bipolar-complementary metal oxide semiconductor (CMOS)-double diffused metal oxide semiconductor (DMOS) process. The prototype circuit-s maximum gate drive supply can be 40-V with peak 2.3-A sourcing/sinking current driving capability. Owing to the wide driving range, this gate driver IC can be used to drive a wide variety of SiC FET switches (both normally OFF metal oxide semiconductor field effect transistor (MOSFET) and normally ON junction field effect transistor (JFET)). The switching frequency is 20-kHz and the duty cycle can be varied from 0 to 100-. The circuit has been successfully tested with SiC power MOSFETs and JFETs without any heat sink and cooling mechanism. During these tests, SiC switches were kept at room temperature and ambient temperature of the driver circuit was increased to 200-C. The circuit underwent numerous temperature cycles with negligible performance degradation.","silicon-on-insulator,
CMOS integrated circuits,
field effect transistors,
MOSFET,
power integrated circuits,
power transistors,
silicon compounds"
Hybrid ARQ for FSO Communications Through Turbulent Atmosphere,"Hybrid automatic-repeat request (HARQ) technique is investigated for binary pulse-position modulation (BPPM), free-space optical (FSO) communications through turbulent optical channels. It is assume that the received optical signal is detected using a direct-detection (DD) mechanism and that shot-noise, background noise, and thermal noise are present at the receiver. Performance of the HARQ-FSO system is assessed in terms of packet error rate, and is compared with that of a conventional ARQ-FSO system to draw conclusions about the effectiveness of HARQ mechanism in circumventing the impact of turbulence.",
MAD2: A scalable high-throughput exact deduplication approach for network backup services,"Deduplication has been widely used in disk-based secondary storage systems to improve space efficiency. However, there are two challenges facing scalable high-throughput deduplication storage. The first is the duplicate-lookup disk bottleneck due to the large size of data index that usually exceeds the available RAM space, which limits the deduplication throughput. The second is the storage node island effect resulting from duplicate data among multiple storage nodes that are difficult to eliminate. Existing approaches fail to completely eliminate the duplicates while simultaneously addressing the challenges. This paper proposes MAD2, a scalable high-throughput exact deduplication approach for network backup services. MAD2 eliminates duplicate data both at the file level and at the chunk level by employing four techniques to accelerate the deduplication process and evenly distribute data. First, MAD2 organizes fingerprints into a Hash Bucket Matrix (HBM), whose rows can be used to preserve the data locality in backups. Second, MAD2 uses Bloom Filter Array (BFA) as a quick index to quickly identify non-duplicate incoming data objects or indicate where to find a possible duplicate. Third, Dual Cache is integrated in MAD2 to effectively capture and exploit data locality. Finally, MAD2 employs a DHT-based Load-Balance technique to evenly distribute data objects among multiple storage nodes in their backup sequences to further enhance performance with a well-balanced load. We evaluate our MAD2 approach on the backend storage of B-Cloud, a research-oriented distributed system that provides network backup services. Experimental results show that MAD2 significantly outperforms the state-of-the-art approximate deduplication approaches in terms of deduplication efficiency, supporting a deduplication throughput of at least 100MB/s for each storage component.","Space technology,
Peer to peer computing,
Throughput,
Acceleration,
Fingerprint recognition,
Costs,
Scalability,
Network servers,
Computer networks,
Laboratories"
CompactDFA: Generic State Machine Compression for Scalable Pattern Matching,"Pattern matching algorithms lie at the core of all contemporary Intrusion Detection Systems (IDS), making it intrinsic to reduce their speed and memory requirements. This paper focuses on the most popular class of pattern-matching algorithms, the Aho-Corasick--like algorithms, which are based on constructing and traversing a Deterministic Finite Automaton (DFA), representing the patterns. While this approach ensures deterministic time guarantees, modern IDSs need to deal with hundreds of patterns, thus requiring to store very large DFAs which usually do not fit in fast memory. This results in a major bottleneck on the throughput of the IDS, as well as its power consumption and cost. We propose a novel method to compress DFAs by observing that the name of the states is meaningless. While regular DFAs store separately each transition between two states, we use this degree of freedom and encode states in such a way that all transitions to a specific state can be represented by a single prefix that defines a set of current states. Our technique applies to a large class of automata, which can be categorized by simple properties. Then, the problem of pattern matching is reduced to the well-studied problem of Longest Prefix Matching (LPM) that can be solved either in TCAM, in commercially available IP-lookup chips, or in software. Specifically, we show that with a TCAM our scheme can reach a throughput of 10 Gbps with low power consumption.","Pattern matching,
Doped fiber amplifiers,
Intrusion detection,
Automata,
Throughput,
Energy consumption,
Computer science,
Hardware,
Communications Society,
USA Councils"
Error-Resilient Scheme for Wavelet Video Codec Using Automatic ROI Detection and Wyner-Ziv Coding Over Packet Erasure Channel,"The error-resilient for video transmission over the Internet in which regarded as the packet erasure channel is always a tough task and has gained lots of attentions. The main contradictory problem lies between error-resilient and bandwidth usage. Additional redundant data has to be added to achieve robust transmission which leads to huge bandwidth usage. In this paper, an error-resilient scheme called Wyner-Ziv Error-Resilient (WZER) based on a receiver driven layered Wyner-Ziv (WZ) coding framework is proposed. The WZER purposely emphasizes on the protection of the Region of Interest (ROI) area in the frame thus to achieve the better tradeoff between the bandwidth usage and error-resilience. WZER is designed to work for the scenario of wavelet based video coding over packet erasure channel, where several techniques including automatic ROI detection, ROI mask generation, Rate distortion optimization (RDO) quantization, WZ coding with layer design, and packet level Low Density Parity Check (LDPC) code are used. The performances of the proposed WZER are simulated based on average PSNR of luminance, perceptual reconstruction and bandwidth usage and compared with normal Forward Error Correction (FEC) full protection scheme and no protection scheme. The results show the advantages of the proposed WZER over traditional FEC protection, especially in the aspects of the recovery of the subject area and bandwidth efficiency.","Wavelet packets,
Video codecs,
Bandwidth,
Protection,
Forward error correction,
Parity check codes,
Internet,
Robustness,
Video coding,
Rate-distortion"
Reinterpreting the Application of Gabor Filters as a Manipulation of the Margin in Linear Support Vector Machines,"Linear filters are ubiquitously used as a preprocessing step for many classification tasks in computer vision. In particular, applying Gabor filters followed by a classification stage, such as a support vector machine (SVM), is now common practice in computer vision applications like face identity and expression recognition. A fundamental problem occurs, however, with respect to the high dimensionality of the concatenated Gabor filter responses in terms of memory requirements and computational efficiency during training and testing. In this paper, we demonstrate how the preprocessing step of applying a bank of linear filters can be reinterpreted as manipulating the type of margin being maximized within the linear SVM. This new interpretation leads to sizable memory and computational advantages with respect to existing approaches. The reinterpreted formulation turns out to be independent of the number of filters, thereby allowing the examination of the feature spaces derived from arbitrarily large number of linear filters, a hitherto untestable prospect. Further, this new interpretation of filter banks gives new insights, other than the often cited biological motivations, into why the preprocessing of images with filter banks, like Gabor filters, improves classification performance.",
Optimal node repositioning for tolerating node failure in wireless sensor actor network,"Wireless sensor and actor networks (WSANs) usually operate in harsh environment and thus become susceptible to breakage in connectivity due to the failure of one or multiple actor nodes. The positions of some of these actors are critical to the sustainability of inter-node communications. Specifically, some node failures may cause the network to partition into disjoint segments. Given that WSANS are deployed in remote areas, restoring connectivity through self reconfiguring the network topology becomes the most preferred solution. This paper investigates the optimal actor repositioning for restoring connectivity after one or multiple node fail. In particular, the problem is formulated as an integer linear program such that every node can reach every other node in the network while maximizing network coverage and minimizing the distance that an actor ought to travel.","Wireless sensor networks,
Fires,
Network topology,
Petroleum,
Minerals,
Thermal sensors,
Intelligent networks,
Computer networks,
Reconnaissance,
Surveillance"
Snakules: A Model-Based Active Contour Algorithm for the Annotation of Spicules on Mammography,"We have developed a novel, model-based active contour algorithm, termed “snakules”, for the annotation of spicules on mammography. At each suspect spiculated mass location that has been identified by either a radiologist or a computer-aided detection (CADe) algorithm, we deploy snakules that are converging open-ended active contours also known as snakes. The set of convergent snakules have the ability to deform, grow and adapt to the true spicules in the image, by an attractive process of curve evolution and motion that optimizes the local matching energy. Starting from a natural set of automatically detected candidate points, snakules are deployed in the region around a suspect spiculated mass location. Statistics of prior physical measurements of spiculated masses on mammography are used in the process of detecting the set of candidate points. Observer studies with experienced radiologists to evaluate the performance of snakules demonstrate the potential of the algorithm as an image analysis technique to improve the specificity of CADe algorithms and as a CADe prompting tool.","Active contours,
Mammography,
Lesions,
Image converters,
Breast cancer,
Permission,
Statistics,
Biomedical measurements,
Image motion analysis,
Engineering profession"
Modeling TSV open defects in 3D-stacked DRAM,"Three-dimensional (3D) stacking using through silicon vias (TSVs) is a promising solution to provide low-latency and high-bandwidth DRAM access from microprocessors. The large number of TSVs implemented in 3D DRAM circuits, however, are prone to open defects and coupling noises, leading to new test challenges. Through extensive simulation studies, this paper models the faulty behavior of TSV open defects occurred on the wordlines and the bitlines of 3D DRAM circuits, which serves as the first step for efficient and effective test and diagnosis solutions for such defects.","Through-silicon vias,
Couplings,
Random access memory,
Integrated circuit modeling,
Capacitance,
Three dimensional displays,
Circuit faults"
Game-Theoretic Approach for Improving Cooperation in Wireless Multihop Networks,"Traditional networks are built on the assumption that network entities cooperate based on a mandatory network communication semantic to achieve desirable qualities such as efficiency and scalability. Over the years, this assumption has been eroded by the emergence of users that alter network behavior in a way to benefit themselves at the expense of others. At one extreme, a malicious user/node may eavesdrop on sensitive data or deliberately inject packets into the network to disrupt network operations. The solution to this generally lies in encryption and authentication. In contrast, a rational node acts only to achieve an outcome that he desires most. In such a case, cooperation is still achievable if the outcome is to the best interest of the node. The node misbehavior problem would be more pronounced in multihop wireless networks like mobile ad hoc and sensor networks, which are typically made up of wireless battery-powered devices that must cooperate to forward packets for one another. However, cooperation may be hard to maintain as it consumes scarce resources such as bandwidth, computational power, and battery power. This paper applies game theory to achieve collusive networking behavior in such network environments. In this paper, pricing, promiscuous listening, and mass punishments are avoided altogether. Our model builds on recent work in the field of Economics on the theory of imperfect private monitoring for the dynamic Bertrand oligopoly, and adapts it to the wireless multihop network. The model derives conditions for collusive packet forwarding, truthful routing broadcasts, and packet acknowledgments under a lossy wireless multihop environment, thus capturing many important characteristics of the network layer and link layer in one integrated analysis that has not been achieved previously. We also provide a proof of the viability of the model under a theoretical wireless environment. Finally, we show how the model can be applied to design a generic protocol which we call the Selfishness Resilient Resource Reservation protocol, and validate the effectiveness of this protocol in ensuring cooperation using simulations.","Spread spectrum communication,
Wireless sensor networks,
Protocols,
Integrated circuit modeling,
Scalability,
Cryptography,
Authentication,
Bandwidth,
Batteries,
Game theory"
Minimizing Execution Costs when Using Globally Distributed Cloud Services,"Cloud computing is an emerging technology that allows users to utilize on-demand computation, storage, data and services from around the world. However, Cloud service providers charge users for these services. Specifically, to access data from their globally distributed storage edge servers, providers charge users depending on the user’s location and the amount of data transferred. When deploying data-intensive applications in a Cloud computing environment, optimizing the cost of transferring data to and from these edge servers is a priority, as data play the dominant role in the application’s execution. In this paper, we formulate a non-linear programming model to minimize the data retrieval and execution cost of data-intensive workflows in Clouds. Our model retrieves data from Cloud storage resources such that the amount of data transferred is inversely proportional to the communication cost. We take an example of an ‘intrusion detection’ application workflow, where the data logs are made available from globally distributed Cloud storage servers. We construct the application as a workflow and experiment with Cloud based storage and compute resources. We compare the cost of multiple executions of the workflow given by a solution of our non-linear program against that given by Amazon CloudFront’s ‘nearest’ single data source selection. Our results show a savings of three-quarters of total cost using our model.","Costs,
Cloud computing,
Distributed computing,
Intrusion detection,
Data mining,
Application software,
Information retrieval,
Laboratories,
Computer science,
Software engineering"
Secure data access in cloud computing,"Data security and access control is one of the most challenging ongoing research work in cloud computing, because of users outsourcing their sensitive data to cloud providers. Existing solutions that use pure cryptographic techniques to mitigate these security and access control problems suffer from heavy computational overhead on the data owner as well as the cloud service provider for key distribution and management. This paper addresses this challenging open problem using capability based access control technique that ensures only valid users will access the outsourced data. This work also proposes a modified Diffie-Hellman key exchange protocol between cloud service provider and the user for secretly sharing a symmetric key for secure data access that alleviates the problem of key distribution and management at cloud service provider. The simulation run and analysis shows that the proposed approach is highly efficient and secure under existing security models.","Access control,
Encryption,
Public key,
Cloud computing,
Servers"
Exploratory programming in the virtual laboratory,"GridSpace 2 is a novel virtual laboratory framework enabling researchers to conduct virtual experiments on Grid-based resources and other HPC infrastructures. GridSpace 2 facilitates exploratory development of experiments by means of scripts which can be written in a number of popular languages, including Ruby, Python and Perl. The framework supplies a repository of gems enabling scripts to interface low-level resources such as PBS queues, EGEE computing elements, scientific applications and other types of Grid resources. Moreover, GridSpace 2 provides a Web 2.0-based Experiment Workbench supporting development and execution of virtual experiments by groups of collaborating scientists. We present an overview of the most important features of the Experiment Workbench, which is the main user interface of the Virtual laboratory, and discuss a sample experiment from the computational chemistry domain.","Laboratories,
Programming,
Software,
Portals,
Libraries,
Middleware,
Browsers"
Automatic Segmentation of Rotational X-Ray Images for Anatomic Intra-Procedural Surface Generation in Atrial Fibrillation Ablation Procedures,"Since the introduction of 3-D rotational X-ray imaging, protocols for 3-D rotational coronary artery imaging have become widely available in routine clinical practice. Intra-procedural cardiac imaging in a computed tomography (CT)-like fashion has been particularly compelling due to the reduction of clinical overhead and ability to characterize anatomy at the time of intervention. We previously introduced a clinically feasible approach for imaging the left atrium and pulmonary veins (LAPVs) with short contrast bolus injections and scan times of ~ 4-10 s. The resulting data have sufficient image quality for intra-procedural use during electro-anatomic mapping (EAM) and interventional guidance in atrial fibrillation (AF) ablation procedures. In this paper, we present a novel technique to intra-procedural surface generation which integrates fully-automated segmentation of the LAPVs for guidance in AF ablation interventions. Contrast-enhanced rotational X-ray angiography (3-D RA) acquisitions in combination with filtered-back-projection-based reconstruction allows for volumetric interrogation of LAPV anatomy in near-real-time. An automatic model-based segmentation algorithm allows for fast and accurate LAPV mesh generation despite the challenges posed by image quality; relative to pre-procedural cardiac CT/MR, 3-D RA images suffer from more artifacts and reduced signal-to-noise. We validate our integrated method by comparing (1) automatic and manual segmentations of intra-procedural 3-D RA data, (2) automatic segmentations of intra-procedural 3-D RA and pre-procedural CT/MR data, and (3) intra-procedural EAM point cloud data with automatic segmentations of 3-D RA and CT/MR data. Our validation results for automatically segmented intra-procedural 3-D RA data show average segmentation errors of (1) ~ 1.3 mm compared with manual 3-D RA segmentations (2) ~ 2.3 mm compared with automatic segmentation of pre-procedural CT/MR data and (3) ~ 2.1 mm compared with registered intra-procedural EAM point clouds. The overall experiments indicate that LAPV surfaces can be automatically segmented intra-procedurally from 3-D RA data with comparable quality relative to meshes derived from pre-procedural CT/MR.","Image segmentation,
X-ray imaging,
Atrial fibrillation,
Computed tomography,
Optical imaging,
Anatomy,
Image quality,
Clouds,
Protocols,
Arteries"
Estimation of Diffusion Properties in Crossing Fiber Bundles,"There is an ongoing debate on how to model diffusivity in fiber crossings. We propose an optimization framework for the selection of a dual tensor model and the set of diffusion weighting parameters b, such that both the diffusion shape and orientation parameters can be precisely as well as accurately estimated. For that, we have adopted the Cramér-Rao lower bound (CRLB) on the variance of the model parameters, and performed Monte Carlo simulations. We have found that the axial diffusion λ|| needs to be constrained, while an isotropic fraction can be modeled by a single parameter fiso. Under these circumstances, the Fractional Anisotropy (FA) of both tensors can theoretically be independently estimated with a precision of 9% (at SNR=25 ). Levenberg-Marquardt optimization of the Maximum Likelihood function with a Rician noise model approached this precision while the bias was insignificant. A two-element b-vector b = [ 1.0 amp; 3.5 ] · 103 mm-2 s was found to be sufficient for estimating parameters of heterogeneous tissue with low error. This has allowed us to estimate consistent FA-profiles along crossing tracts. This work defines fundamental limits for comparative studies to correctly analyze crossing white matter structures.","Tensile stress,
Shape,
Anisotropic magnetoresistance,
Biomedical imaging,
Parameter estimation,
Magnetic analysis,
Magnetic resonance imaging,
Radiology,
Monte Carlo methods,
Estimation theory"
General object tracking with a component-based target descriptor,"In this paper, we present a component-based visual object tracker for mobile platforms. The core of the technique is a component-based descriptor that captures the structure and appearance of a target in a flexible way. This descriptor can be learned quickly from a single training image and is easily adaptable to different objects. The descriptor is integrated into the observation model of a visual tracker based on the well known Condensation algorithm. We show that the approach is applicable to a large variety of objects and in different environments with cluttered backgrounds and a moving camera. The method is robust to illumination and viewpoint changes and applicable to indoor as well as outdoor scenes.","Target tracking,
Cameras,
Robustness,
Mobile robots,
Robot vision systems,
Lighting,
Humans,
Histograms,
Particle tracking,
Robotics and automation"
A Relay Assisted Cooperative Transmission Protocol for Wireless Multiple Access Systems,"In this paper, we propose a spectrally efficient cooperative transmission protocol for multiple access scenarios. The key feature is to utilize multi-user diversity and fully exploit the dynamic nature of radio propagation. In particular, by carefully scheduling the multiple sources and relays' transmissions, a source with a poor connection to the destination can have higher priority to obtain help from a relay with better channel condition. As a result, the full diversity gain is achievable even though only a fraction of relays is scheduled to help each user. We developed an achievable diversity-multiplexing tradeoff for the proposed transmission protocol to assist performance evaluation. When the number of relays is large, the diversity-multiplexing tradeoff achieved by the proposed scheme can approximate the optimal multiple-input single-output upper bound. Both analytical and numerical results show that the proposed protocol outperform other comparable schemes in most conditions.","Wireless application protocol,
Access protocols,
Diversity methods,
Wireless sensor networks,
Robustness,
Cultural differences,
Digital relays,
Radio propagation,
Upper bound,
Fading"
Opportunistic Routing in Multi-Radio Multi-Channel Multi-Hop Wireless Networks,"Two major factors that limit the throughput in multi-hop wireless networks are the co-channel interference and unreliability of wireless transmissions. Multi-radio multi-channel technology and opportunistic routing (OR) have shown their promise to significantly improve the network capacity by combating these two limits. It raises an interesting problem on the tradeoff between multiplexing and spatial diversity when integrating these two techniques for throughput optimization. It is unknown what the capacity of the network could be when nodes have multiple radios and OR capability. In this paper, we present our study on optimizing an end-to-end throughput of the multi-radio multi-channel network when OR is available. First, we formulate the end-to-end throughput bound as a linear programming (LP) problem which jointly solves the radio-channel assignment, transmission scheduling, and forwarding candidate selection. Second, we propose an LP approach and a heuristic algorithm to find a feasible scheduling of opportunistic forwarding priorities to achieve the capacity. Simulations show that the heuristic algorithm achieves desirable performance under various number of forwarding candidates. Leveraging our analytical model, we find that 1) OR can achieve better performance than traditional routing (TR) under different radio/channel configurations, however, in particular scenario (e.g. bottleneck links exist between the sender and relays), TR is preferable; 2) OR can achieve comparable or better performance than TR by using less radio resource.","Throughput,
Radio transmitters,
Routing,
Wireless networks,
Spread spectrum communication,
Scheduling"
A real time hand gesture recognition system using motion history image,"Hand gesture recognition based man-machine interface is being developed vigorously in recent years. Due to the effect of lighting and complex background, most visual hand gesture recognition systems work only under restricted environment. An adaptive skin color model based on face detection is utilized to detect skin color regions like hands. To classify the dynamic hand gestures, we developed a simple and fast motion history image based method. Four groups of haar-like directional patterns were trained for the up, down, left, and right hand gestures classifiers. Together with fist hand and waving hand gestures, there were totally six hand gestures defined. In general, it is suitable to control most home appliances. Five persons doing 250 hand gestures at near, medium, and far distances in front of the web camera were tested. Experimental results show that the accuracy is 94.1% in average and the processing time is 3.81 ms per frame. These demonstrated the feasibility of the proposed system.",
"An integrated network of roadside sensors and vehicles for driving safety: Concept, design and experiments","One major goal of the vehicular ad hoc network (VANET) is to improve driving safety. However, the VANET may not guarantee timely detection of dangerous road conditions or maintain communication connectivity when the network density is low (e.g., in rural highways), which may pose as a big threat to driving safety. Towards addressing the problem, we propose to integrate the VANET with the inexpensive wireless sensor network (WSN). That is, sensor nodes are deployed along the roadside to sense road conditions, and to buffer and deliver information about dangerous conditions to vehicles regardless of the density or connectivity of the VANET. Along with the concept of VANET-WSN integration, new challenges arise and should be addressed. In this paper, we investigate these challenges and propose schemes for effective and efficient vehicle-sensor and sensor-sensor interactions. Prototype of the designed system has been implemented and tested in the field. Extensive simulations have also been conducted to evaluate the designed schemes. The results demonstrate various design tradeoffs, and indicate that satisfactory safety and energy efficiency can be achieved simultaneously when system parameters are appropriately chosen.",
Understanding and Improving Ratio Incentives in Private Communities,"Incentive mechanisms play a critical role in P2P systems. Private BitTorrent sites use a novel incentive paradigm, where the sites record upload and download amounts of users and require each user to maintain its upload-to-download ratio above a specified threshold. This paper explores in-depth incentives in private P2P file-sharing systems. Our contributions are threefold. We first conduct a measurement study on a representative private BitTorrent site, examining how incentives influence user behavior. Our measurement study shows that, as compared with public torrents, a private BitTorrent site provides more incentive for users to contribute and seed. Second, we develop a game theoretic model and analytically show that the ratio mechanism indeed provides effective incentives. But existing ratio incentives in private BitTorrent sites are vulnerable to collusions. Third, to prevent collusion, we propose an upload entropy scheme, and show through analysis and experiment that the entropy scheme successfully limits colluding, while rarely affecting normal users who do not collude.","Entropy,
Computer science,
Game theory,
Bandwidth,
Distributed computing,
Chaos,
Maintenance engineering,
Sun,
Aggregates,
Robustness"
Path Planning for Improved Visibility Using a Probabilistic Road Map,"This paper focuses on the challenges of vision-based motion planning for industrial manipulators. Our approach is aimed at planning paths that are within the sensing and actuation limits of industrial hardware and software. Building on recent advances in path planning, our planner augments probabilistic road maps with vision-based constraints. The resulting planner finds collision-free paths that simultaneously avoid occlusions of an image target and keep the target within the field of view of the camera. The planner can be applied to eye-in-hand visual-target-tracking tasks for manipulators that use point-to-point commands with interpolated joint motion.","Path planning,
Visual servoing,
Control systems,
Assembly systems,
Roads,
Cameras,
Communication system control,
Motion control,
Computer industry,
Hardware"
Construction of constrained multi-bit flip-flops for clock power reduction,"Based on the elimination feature of redundant inverters in merging 1-bit flip-flops into multi-bit flip-flops, given the congested constraint of unallocated bins and the length constraints of the input and output signals of all the 1-bit flip-flops, an efficient two-phase approach is proposed to obtain the final multi-bit flip-flops. Compared with the original design in the numbers of inverters for two tested examples, the experimental results show that our proposed approach eliminates 68% of inverters to maintain the synchronous designs and saves 19.75% of the clock power on the average for two tested examples in reasonable CPU time.","Flip-flops,
Clocks,
Inverters,
Routing,
Testing,
Merging,
Delay,
Power engineering and energy,
Signal design,
Law"
Hierarchical Prosody Conversion Using Regression-Based Clustering for Emotional Speech Synthesis,"This paper presents an approach to hierarchical prosody conversion for emotional speech synthesis. The pitch contour of the source speech is decomposed into a hierarchical prosodic structure consisting of sentence, prosodic word, and subsyllable levels. The pitch contour in the higher level is encoded by the discrete Legendre polynomial coefficients. The residual, the difference between the source pitch contour and the pitch contour decoded from the discrete Legendre polynomial coefficients, is then used for pitch modeling at the lower level. For prosody conversion, Gaussian mixture models (GMMs) are used for sentence- and prosodic word-level conversion. At subsyllable level, the pitch feature vectors are clustered via a proposed regression-based clustering method to generate the prosody conversion functions for selection. Linguistic and symbolic prosody features of the source speech are adopted to select the most suitable function using the classification and regression tree for prosody conversion. Three small-sized emotional parallel speech databases with happy, angry, and sad emotions, respectively, were designed and collected for training and evaluation. Objective and subjective evaluations were conducted and the comparison results to the GMM-based method for prosody conversion achieved an improved performance using the hierarchical prosodic structure and the proposed regression-based clustering method.","Speech synthesis,
Clustering methods,
Polynomials,
Spatial databases,
Decoding,
Classification tree analysis,
Regression tree analysis,
Speech analysis,
Councils,
Computer science"
DEBAR: A scalable high-performance de-duplication storage system for backup and archiving,"Driven by the increasing demand for large-scale and high-performance data protection, disk-based de-duplication storage has become a new research focus of the storage industry and research community where several new schemes have emerged recently. So far these systems are mainly inline de-duplication approaches, which are centralized and do not lend themselves easily to be extended to handle global de-duplication in a distributed environment. We present DEBAR, a de-duplication storage system designed to improve capacity, performance and scalability for de-duplication backup/archiving. DEBAR performs post-processing de-duplication, where backup streams are de-duplicated and cached on server-disks through an in-memory preliminary filter in phase I, and then completely de-duplicated in-batch in phase II. By decentralizing fingerprint lookup and update, DEBAR supports a cluster of servers to perform de-duplication backup in parallel, and is shown to scale linearly in both write throughput and physical capacity, achieving an aggregate throughput of 1.7GB/s and supporting a physical capacity of 2PB with 16 backup servers.",
A Survey of PCN-Based Admission Control and Flow Termination,"Pre-congestion notification (PCN) provides feedback about load conditions in a network to its boundary nodes. The PCN working group of the IETF discusses the use of PCN to implement admission control (AC) and flow termination (FT) for prioritized realtime traffic in a DiffServ domain. Admission control (AC) is a well-known flow control function that blocks admission requests of new flows when they need to be carried over a link whose admitted PCN rate already exceeds an admissible rate. Flow termination (FT) is a new flow control function that terminates some already admitted flows when they are carried over a link whose admitted PCN rate exceeds a supportable rate. The latter condition can occur in spite of AC, e.g., when traffic is rerouted due to network failures. This survey gives an introduction to PCN and is a primer for this new technology. It presents and discusses the multitude of architectural design options in an early stage of the standardization process in a comprehensive and streamlined way before only a subset of them is standardized by the IETF. It brings PCN from the IETF to the research community and serves as historical record.","Admission control,
Personal communication networks,
Diffserv networks,
Telecommunication traffic,
Communication system traffic control,
Quality of service,
Feedback,
Standardization,
Communication system control,
Communication networks"
Centrality-based Access-Points deployment for vehicular networks,"Vehicular Ad hoc Networks appeared as a natural result of the evolution of the communication technology, which becomes able to satisfy the need of users to be connected anytime and anywhere. Providing comfort services such as Internet access or even vehicle traffic monitoring requires the use of road-side units (RSU) as gateways to the requested resources. Today, most of Intelligent Transport Systems (ITS) architectures rely on the integration and use of such gateways. Nevertheless, none of them tried to study the way these should be deployed neither the way they should be organized to achieve best performances. We think that such a study is primordial, in an environment that cannot be fully covered due to the high costs of infrastructure deployment. In this paper we provide a deep analysis of the deployment problem. We show in a first part the benefits of using RSU as support for V2V communications. We then investigate in a second part different approaches and strategies for AccessPoints deployment. An objectives-based analysis reveals the role of centrality and equidistant-based deployment in optimizing the end-to-end delay and ensuring a regular and stable service access. Our simulation results confirm that the performances in a cooperative environment (V2I and V2V) get greatly improved. It shows that the use of RSU becomes essential in low density situations and especially in case of long-distance communications. In the context of RSU deployment, simulation results proved that centrality and equidistance are key factors for optimizing end-to-end delays and ensuring stable performances.","Delay,
Ad hoc networks,
Communications technology,
Web and internet services,
Road vehicles,
Telecommunication traffic,
Monitoring,
Intelligent systems,
Costs,
Context"
All-Digital Circuits for Measurement of Spatial Variation in Digital Circuits,"Increased variation in CMOS processes due to scaling results in greater reliance on accurate variation models in developing circuit methods to mitigate variation. This paper investigates spatial variation in digital circuit performance: we describe a test-chip in 90 nm CMOS containing all-digital measurement circuits capable of extracting accurate variation data. Specifically, we use replicated 64-bit Kogge-Stone adders, ring oscillators (ROs) of varying gate type and stage length and an all-digital, sub-picosecond resolution delay measurement circuit to provide this data. Measurement data from the test-chips indicate that 1) relative variation is significantly larger in low-voltage domains, 2) within-die variation is spatially uncorrelated, and 3) die-to-die (or global) variation is strongly correlated, but degrades toward uncorrelated as the power-supply voltage is lowered. Lastly, extended analysis of the data reveals that systematic effects such as layout pattern dependencies or circuit structure can be misinterpreted as random but spatially-correlated variation. This suggests that circuit designers will reap more benefit from design tools capable of modeling systematic, position-dependent variation rather than spatially correlated, distance-dependent variation.","Digital circuits,
Circuit testing,
CMOS process,
Semiconductor device modeling,
CMOS digital integrated circuits,
Data mining,
Adders,
Ring oscillators,
Spatial resolution,
Delay"
Multiperiodicity of Periodically Oscillated Discrete-Time Neural Networks With Transient Excitatory Self-Connections and Sigmoidal Nonlinearities,"The existing approaches to the multistability and multiperiodicity of neural networks rely on the strictly excitatory self-interactions of neurons or require constant interconnection weights. For periodically oscillated discrete-time neural networks (DTNNs), it is difficult to discuss multistable dynamics when the connection weights are periodically oscillated around zero. By using transient excitatory self-interactions of neurons and sigmoidal nonlinearities, we develop an approach to investigate multiperiodicity and attractivity of periodically oscillated DTNNs with time-varying and distributed delays. It shows that, under some new criteria, there exist multiplicity results of periodic solutions which are locally or globally exponentially stable. Computer numerical simulations are performed to illustrate the new theories.","Artificial neural networks,
Neurons,
Transient analysis,
Delay,
Associative memory,
Stability criteria"
Human vs. robotic tactile sensing: Detecting lumps in soft tissue,"Humans can localize lumps in soft tissue using the distributed tactile feedback and processing afforded by the fingers and brain. This task becomes extremely difficult when the fingers are not in direct contact with the tissue, such as in laparoscopic or robot-assisted procedures. Tactile sensors have been proposed to characterize and detect lumps in robot-assisted palpation. In this work, we compare the performance of a capacitive tactile sensor with that of the human finger. We evaluate the response of the sensor as it pertains to robot-assisted palpation and compare the sensor performance to that of human subjects performing an equivalent task on the same set of artificial tissue models. Furthermore, we investigate the effects of various tissue parameters (lump size, lump depth, and surrounding tissue stiffness) on the performance of both the human finger and the tactile sensor. Using signal detection theory for determining tactile sensor lump detection thresholds, the tactile sensor outperforms the human finger in a palpation task.","Humans,
Robot sensing systems,
Biological tissues,
Fingers,
Tactile sensors,
Sensor phenomena and characterization,
Feedback,
Laparoscopes,
Performance evaluation,
Signal detection"
A software-based self-test and hardware reconfiguration solution for VLIW processors,"Technology scaling inevitably leads to fabrication processes, which are more susceptible to production faults. At the same time, devices become more vulnerable to wear-out effects, which reduce the long term system reliability. The upcoming challenge of future designs is the development of integrated test and repair techniques dealing with both types of fault mechanisms. Our paper presents a built-in self-test (BIST) and repair solution for regular data path structures of VLIW processors by software-based self-test (SBST). After fault detection and localization by software a hardware reconfiguration, by using redundant components, takes place. Our software test and repair solution can be used to improve yield as well as reliability.","Built-in self-test,
Hardware,
VLIW,
Production,
Redundancy,
Reliability,
Aging,
Automatic test pattern generation,
Software testing,
Fault tolerance"
Studying Bio-Inspired Coalition Formation of Robots for Detecting Intrusions Using Game Theory,"In this paper, inspired by the society of animals, we study the coalition formation of robots for detecting intrusions using game theory. We consider coalition formation in a group of three robots that detect and capture intrusions in a closed curve loop. In our analytical model, individuals seek alliances if they think that their detect regions are too short to gain an intrusion capturing probability larger than their own. We assume that coalition seeking has an investment cost and that the formation of a coalition determines the outcomes of parities, with the detect length of a coalition simply being the sum of those of separate coalition members. We derive that, for any cost, always detecting alone is an evolutionarily stable strategy (ESS), and that, if the cost is below a threshold, always trying to form a coalition is an ESS (thus a three-way coalition arises).","Game theory,
Animals,
Costs,
Robot sensing systems,
Collaboration,
Societies,
Investments,
Electronic switching systems,
Intrusion detection,
Mobile robots"
Improving histogram-based reversible data hiding by interleaving predictions,"Data hiding is an important way of realising copyright protection for multimedia. In this study, a new predictive method is proposed to enhance the histogram-based reversible data hiding approach on grey images. In those developed histogram-based reversible data hiding approaches, their drawbacks are the number of predictive values less to the number of pixels in an image. In these interleaving prediction methods, the predictive values are as many as the pixel values. All predictive error values are transformed into histogram to create higher peak values and to improve the embedding capacity. Moreover, for each pixel, its difference value between the original image and the stego-image remains within ±1. This guarantees that the peak signal-to-noise ratio (PSNR) of the stego-image is above 48±dB. Experimental results show that the histogram-based reversible data hiding approach can raise a larger capacity and still remain a good image quality, compared to other histogram-based approaches.","image colour analysis,
data encapsulation,
image coding"
Cross-Lingual Document Representation and Semantic Similarity Measure: A Fuzzy Set and Rough Set Based Approach,"As cross-lingual information retrieval is attracting increasing attention, tools that measure cross-lingual semantic similarity between documents are becoming desirable. In this paper, two aspects of cross-lingual semantic document similarity measures are investigated: One is document representation, and the other is the formulation of similarity measures. Fuzzy set and rough set theories are applied to capture the inherently fuzzy relationships among concepts expressed by natural languages. Our approach first develops a language-independent sense-level document representation based on the fuzzy set model to reduce the barrier between different languages and further explores the fuzzy-rough hybrid approach to obtain a more robust macrosense-level document representation through the partitioning of the integrated sense association network of the document collection into macrosenses. Then, Tversky's notion of similarity and the F1 measure on information retrieval are adopted to formulate, respectively, two document similarity measures with fuzzy set operations on the two proposed document representations. The effectiveness of our approach is demonstrated by its success rate in identifying the English translations to their corresponding Chinese documents in a collection of Chinese-English parallel documents. Moreover, the proposed approach can be easily extended to process documents in other languages. It is believed that the proposed representations, along with the similarity measures, will enable more effective text mining processes.","Fuzzy sets,
Information retrieval,
Natural languages,
Set theory,
Robustness,
Text mining,
Internet,
Web pages,
Search engines,
Intelligent systems"
Multirobot Forest Coverage for Weighted and Unweighted Terrain,"One of the main applications of mobile robots is coverage: visiting each location in known terrain. Coverage is crucial for lawn mowing, cleaning, harvesting, search-and-rescue, intrusion detection, and mine clearing. Naturally, coverage can be sped up with multiple robots. However, we show that solving several versions of multirobot coverage problems with minimal cover times is NP-hard, which provides motivation for designing polynomial-time constant-factor approximation algorithms. We then describe multirobot forest coverage (MFC), a new polynomial-time multirobot coverage algorithm based on an algorithm by Even et al. [Min-max tree covers of graphs. Oper. Res. Lett., vol. 32, pp. 309-315, 2004] for finding a tree cover with trees of balanced weights. Our theoretical results show that the cover times of MFC in weighted and unweighted terrain are at most about a factor of 16 larger than minimal. Our simulation results show that the cover times of MFC are close to minimal in all tested scenarios and smaller than the cover times of an alternative multirobot coverage algorithm.","Polynomials,
Robot sensing systems,
Approximation algorithms,
Algorithm design and analysis,
Approximation methods,
Terrain factors"
On Gaussian MIMO compound wiretap channels,"We study the two-user one-eavesdropper discrete memoryless compound wiretap channel, where the transmitter sends a common confidential message to both users, which needs to be kept perfectly secret from the eavesdropper. We provide a new achievable secrecy rate which is shown to be potentially better than the best known lower bound for the secrecy capacity of this compound wiretap channel. We next consider the two-user one-eavesdropper Gaussian multiple-input multiple-output (MIMO) compound wiretap channel. We obtain an achievable secrecy rate for the Gaussian MIMO compound wiretap channel by using dirty-paper coding (DPC) in the achievable scheme we provided for the discrete memoryless case. We show that the corresponding achievable secrecy rate achieves at least half of the secrecy capacity of the two-user one-eavesdropper Gaussian MIMO wiretap channel. We also obtain the secrecy capacity of the two-user one-eavesdropper Gaussian MIMO compound wiretap channel when the eavesdropper is degraded with respect to one of the two users.","MIMO,
Transmitters,
Degradation,
Decoding,
Entropy,
Educational institutions,
Probability distribution,
Fading,
Upper bound,
Broadcasting"
Sparsity-Promoting Tomographic Fluorescence Imaging With Simplified Spherical Harmonics Approximation,"Fluorescence molecular tomography has become a promising technique for in vivo small animal imaging and has many potential applications. Due to the ill-posed and the ill-conditioned nature of the problem, Tikhonov regularization is generally adopted to stabilize the solution. However, the result is usually over-smoothed. In this letter, the third-order simplified spherical harmonics approximation to radiative transfer equation is utilized to model the photon propagation within biological tissues. Considering the sparsity of the fluorescent sources, we replace Tikhonov method with an iteratively reweighted scheme. By dynamically updating the weight matrix, L1-norm regularization can be approximated, which can promote the sparsity of the solution. Simulation study shows that this method can preserve the sparsity of the fluorescent sources within heterogeneous medium, even with very limited measurement data.","Tomography,
Fluorescence,
Optical imaging,
Biomedical measurements,
Biological system modeling,
Equations,
Image reconstruction,
In vivo,
Animals,
Biological tissues"
Energy efficiency in data centers and cloud-based multimedia services: An overview and future directions,"The expanding scale and density of data centers has made their power consumption an imperative issue. Data center energy management has become of unprecedented importance not only from an economic perspective but also for environment conservation. The recent surge in the popularity of cloud computing for providing rich multimedia services has further necessitated the need to consider energy consumption. Moreover, a recent phenomenon has been the astounding increase in multimedia data traffic over the Internet, which in turn is exerting a new burden on the energy resources. This paper provides a comprehensive overview of the techniques and approaches in the fields of energy efficiency for data centers and large-scale multimedia services. The paper also highlights important challenges in designing and maintaining green data centers and identifies some of the opportunities in offering green streaming service in cloud computing frameworks.",
Design of Embedded Controllers Based on Anytime Computing,"In this paper, we present a methodology for designing embedded controllers based on the so-called anytime control paradigm. A control law is split into a sequence of subroutine calls, each one fulfilling a control goal and refining the result produced by the previous one. We propose a design methodology to define a feedback controller structured in accordance with this paradigm and show how a switching policy of selecting the controller subroutines can be designed that provides stability guarantees for the closed-loop system. The cornerstone of this construction is a stochastic model describing the probability of executing, in each activation of the controller, the different subroutines. We show how this model can be constructed for realistic real-time task sets and provide an experimental validation of the approach.","Embedded computing,
Control systems,
Design methodology,
Algorithms,
Availability,
Fluctuations,
Sparks,
Ignition,
Engines,
Prototypes"
SURF applied in panorama image stitching,"SURF (Speeded Up Robust Features) is one of the famous feature-detection algorithms. This paper proposes a panorama image stitching system which combines an image matching algorithm; modified SURF and an image blending algorithm; multi-band blending. The process is divided in the following steps: first, get feature descriptor of the image using modified SURF; secondly, find matching pairs, check the neighbors by K-NN (K-nearest neighbor), and remove the mismatch couples by RANSAC(Random Sample Consensus); then, adjust the images by bundle adjustment and estimate the accurate homography matrix; lastly, blend images by multi-band blending. Also, comparison of SIFT (Scale Invariant Feature Transform) and modified SURF are also shown as a base of selection of image matching algorithm. According to the experiments, the present system can make the stitching seam invisible and get a perfect panorama for large image data and it is faster than previous method.","Feature extraction,
Lighting,
Robustness,
Mathematical model,
Equations,
Image matching,
Computer vision"
Bayesian Nonparametric Methods for Learning Markov Switching Processes,"In this article, we explored a Bayesian nonparametric approach to learning Markov switching processes. This framework requires one to make fewer assumptions about the underlying dynamics, and thereby allows the data to drive the complexity of the inferred model. We began by examining a Bayesian nonparametric HMM, the sticky HDPHMM, that uses a hierarchical DP prior to regularize an unbounded mode space. We then considered extensions to Markov switching processes with richer, conditionally linear dynamics, including the HDP-AR-HMM and HDP-SLDS. We concluded by considering methods for transferring knowledge among multiple related time series. We argued that a featural representation is more appropriate than a rigid global clustering, as it encourages sharing of behaviors among objects while still allowing sequence-specific variability. In this context, the beta process provides an appealing alternative to the DP.","Hidden Markov models,
Markov processes,
Switches,
Time series analysis,
Weight measurement,
Data models,
Bayesian methods"
Statistical Sinogram Smoothing for Low-Dose CT With Segmentation-Based Adaptive Filtering,"As is known, noises in calibrated and log-transformed projection data of low-mA (or low-dose) CT protocol follow approximately a non-stationary Gaussian distribution. In this study, we further demonstrate that some isolated noise points would not satisfy the above observation. Hence, we propose a noise reduction scheme which includes isolated data removal and segmentation-based filtering. In this scheme, an isolated data removal algorithm is first adopted to remove isolated data such that the remaining sinogram data approximately follows a Gaussian distribution. Secondly, image segmentation technique is employed for segmenting sinogram image into different segments in which pixels with similar intensities are grouped, and the segmentation-based adaptive statistical sinogram smoothing technique is proposed with different smoothness parameters applied to different segments for adaptively filtering. The effectiveness of the proposed method is validated by both computer simulations and experimental studies. The gain of the proposed approach over other methods is quantified by noise-resolution tradeoff curves.",
Game Bot Detection via Avatar Trajectory Analysis,"The objective of this work is to automatically detect the use of game bots in online games based on the trajectories of account users. Online gaming has become one of the most popular Internet activities in recent years, but cheating activity, such as the use of game bots, has increased as a consequence. Generally, the gaming community disapproves of the use of bots, as users may obtain unreasonable rewards without making corresponding efforts. However, game bots are hard to detect because they are designed to simulate human game playing behavior and they follow game rules exactly. Existing methods cannot solve the problem as the differences between bot and human trajectories are generally hard to describe. In this paper, we propose a method for detecting game bots based on some dissimilarity measurements between the trajectories of either bots or human users. The measurements are combined with manifold learning and classification techniques for detection; and the approach is generalizable to any game in which avatars' movements are controlled by the players directly. Through real-life data traces, we observe that the trajectories of bots and humans are very different. Since certain human behavior patterns are difficult to mimic, the characteristic can be used as a signature for bot detection. To evaluate the proposed scheme's performance, we conduct a case study of a popular online game called Quake 2. The results show that the scheme can achieve a high detection rate or classification accuracy on a short trace of several hundred seconds.","Games,
Trajectory,
Avatars,
Humans,
Manifolds,
Accuracy,
Markov processes"
Exploiting Transitivity of Correlation for Fast Template Matching,"Elimination Algorithms are often used in template matching to provide a significant speed-up by skipping portions of the computation while guaranteeing the same best-match location as exhaustive search. In this work, we develop elimination algorithms for correlation-based match measures by exploiting the transitivity of correlation. We show that transitive bounds can result in a high computational speed-up if strong autocorrelation is present in the dataset. Generally strong intrareference local autocorrelation is found in natural images, strong inter-reference autocorrelation is found if objects are to be tracked across consecutive video frames and strong intertemplate autocorrelation is found if consecutive video frames are to be matched with a reference image. For each of these cases, the transitive bounds can be adapted to result in an efficient elimination algorithm. The proposed elimination algorithms are exact, that is, they guarantee to yield the same peak location as exhaustive search over the entire solution space. While the speed-up obtained is data dependent, we show empirical results of up to an order of magnitude faster computation as compared to the currently used efficient algorithms on a variety of datasets.","Autocorrelation,
Computational efficiency,
Current measurement,
Testing,
Information technology,
Computer science,
Engineering management,
Computational complexity,
Brightness,
Robustness"
TrafRoute: A different approach to routing in vehicular networks,"In the near future vehicular networks based on wireless technology will be part of our lives. Efficient and robust routing algorithms will play a key role in the success of such technology. In this paper we present TrafRoute, an efficient and robust routing scheme for vehicular networks, suitable for both Vehicle-to-Vehicle and Vehicle-to-Infrastructure communications. TrafRoute introduces a novel approach to routing that involves landmark-based routes and forwarder self-election, exploiting the knowledge of the underlying road network. We demonstrate TrafRoute's efficiency and robustness through simulation studies performed with accurate mobility and propagation models.",
A Class of Spectrum-Sensing Schemes for Cognitive Radio Under Impulsive Noise Circumstances: Structure and Performance in Nonfading and Fading Environments,"In this paper, we propose a class of spectrum-sensing schemes for cognitive radio with receive diversity. By employing the generalized likelihood ratio test (GLRT) in the detectors on the antenna branches and exploiting a nonlinear diversity-combining strategy, the proposed scheme exhibits better performance than conventional schemes in various fading and noise environments. Exact expressions of the detection and false-alarm probabilities of the proposed scheme are derived in nonfading and Nakagami fading channels with Gaussian noise. Through computer simulations, it is confirmed that the proposed scheme provides a significant performance gain over conventional schemes in impulsive noise environments.",
RSSI-based indoor positioning using diversity and Inertial Navigation,"A substantial criterion with the use of wireless communication is the missing location information of the mobile participants. The RSSI (Received Signal Strength Indicator)-based localization technique is an easy and well known method to predict the position of an unknown node in indoor environments whereas additional measures are required for a sufficient accuracy. The distance-pending path loss is affected by strong variations, especially appearing as frequency specific signal dropouts. A diversity concept with redundant data transmission in different frequency bands can reduce the dropout probability. Not only the availability of the communication and the positioning, but also the accuracy of the localization can be increased by the diversity concept. Another improvement can be reached by a sensor fusion of the RSSI-based position data with an Inertial Navigation System. First experimental results with miniaturized transceiver prototypes show that a good performance for precision and availability can also be reached with low infrastructural costs.","Diversity reception,
Acceleration,
Propagation losses,
Fading,
Navigation,
Accuracy,
Estimation"
Coping with Node Misbehaviors in Ad Hoc Networks: A Multi-dimensional Trust Management Approach,"Nodes in Mobile Ad hoc Networks (MANETs) are required to relay data packets to enable communication between other nodes that are not in radio range with each other. However, whether for selfish or malicious reasons, a node may fail to cooperate during the network operations or even attempt to disturb them, both of which have been recognized as misbehaviors. Various trust management schemes have been studied to assess the behaviors of nodes so as to detect and mitigate node misbehaviors inMANETs. Most of existing schemes model a node's trustworthiness along a single dimension, combining all of the available evidence to calculate a single, scalar trust metric. A single measure, however, may not be expressive enough to adequately describe a node's trustworthiness in many scenarios. In this paper, we describe a multi-dimensional framework to evaluate the trustworthiness of MANET node from multiple perspectives. Our scheme evaluates trustworthiness from three perspectives: collaboration trust, behavioral trust, and reference trust. Different types of observations are used to independently derive values for these three trust dimensions. We present simulation results that illustrate the effectiveness of the proposed scheme in several scenarios.","Ad hoc networks,
Mobile ad hoc networks,
Batteries,
Mobile computing,
Computer network management,
Conference management,
Radio spectrum management,
Engineering management,
Relays,
Computer science"
LabelMe: Online Image Annotation and Applications,"Central to the development of computer vision systems is the collection and use of annotated images spanning our visual world. Annotations may include information about the identity, spatial extent, and viewpoint of the objects present in a depicted scene. Such a database is useful for the training and evaluation of computer vision systems. Motivated by the availability of images on the Internet, we introduced a web-based annotation tool that allows online users to label objects and their spatial extent in images. To date, we have collected over 400 000 annotations that span a variety of different scene and object classes. In this paper, we show the contents of the database, its growth over time, and statistics of its usage. In addition, we explore and survey applications of the database in the areas of computer vision and computer graphics. Particularly, we show how to extract the real-world 3-D coordinates of images in a variety of scenes using only the user-provided object annotations. The output 3-D information is comparable to the quality produced by a laser range scanner. We also characterize the space of the images in the database by analyzing 1) statistics of the co-occurrence of large objects in the images and 2) the spatial layout of the labeled images.","Image databases,
Computer vision,
Layout,
Spatial databases,
Application software,
Visual databases,
Internet,
Statistics,
Computer graphics,
Data mining"
Automatic 3-D Breath-Hold Related Motion Correction of Dynamic Multislice MRI,"Magnetic resonance (MR) cine images are often used to clinically assess left ventricular cardiac function. In a typical study, multiple 2-D long axis (LA) and short axis (SA) cine images are acquired, each in a different breath-hold. Differences in lung volume during breath-hold and overall patient motion distort spatial alignment of the images thus complicating spatial integration of all image data in three dimensions. We present a fully automatic postprocessing approach to correct these slice misalignments. The approach is based on the constrained optimization of the intensity similarity of intersecting image lines after the automatic definition of a region of interest. It uses all views and all time frames simultaneously. Our method models both in-plane and out-of-plane translations and full 3-D rotations, can be applied retrospectively and does not require a cardiac wall segmentation. The method was validated on both healthy volunteer and patient data with simulated misalignments, as well as on clinical multibreath-hold patient data. For the simulated data, subpixel accuracy could be obtained using translational correction. The possibilities and limitations of rotational correction were investigated and discussed. For the clinical multibreath-hold patient data sets, the median discrepancy between manual SA and LA contours was reduced from 2.83 to 1.33 mm using the proposed correction method. We have also shown the usefulness of the correction method for functional analysis on clinical image data. The same clinical multibreath-hold data sets were resegmented after positional correction, taking newly available complementary information of intersecting slices into account, further reducing the median discrepancy to 0.43 mm. This is due to the integration of the 2-D slice information into 3-D space.",
Transfer Equivalence and Realization of Nonlinear Input-Output Delta-Differential Equations on Homogeneous Time Scales,"Nonlinear control systems on homogeneous time scales are studied. First the concepts of reduction and irreducibility are extended to higher order delta-differential input-output equations. Subsequently, a definition of system equivalence is introduced which generalizes the notion of transfer equivalence in the linear case. Finally, the necessary and sufficient conditions are given for the existence of a state-space realization of a nonlinear input-output delta-differential equation.","Nonlinear equations,
Control systems,
Sufficient conditions,
Sampling methods,
Nonlinear control systems,
Roundoff errors,
Parameter estimation,
Numerical models,
Cybernetics,
Computer science"
Global Gaussian approach for scene categorization using information geometry,"Local features provide powerful cues for generic image recognition. An image is represented by a “bag” of local features, which form a probabilistic distribution in the feature space. The problem is how to exploit the distributions efficiently. One of the most successful approaches is the bag-of-keypoints scheme, which can be interpreted as sparse sampling of high-level statistics, in the sense that it describes a complex structure of a local feature distribution using a relatively small number of parameters. In this paper, we propose the opposite approach, dense sampling of low-level statistics. A distribution is represented by a Gaussian in the entire feature space. We define some similarity measures of the distributions based on an information geometry framework and show how this conceptually simple approach can provide a satisfactory performance, comparable to the bag-of-keypoints for scene classification tasks. Furthermore, because our method and bag-of-keypoints illustrate different statistical points, we can further improve classification performance by using both of them in kernels.",
Sensor Selection for Structural Observability in Discrete Event Systems Modeled by Petri Nets,"This paper studies optimal sensor selection in discrete event systems modeled by partially observed Petri nets. The goal is to place a minimum number of sensors while maintaining structural observability, i.e., the ability to uniquely determine the system state at any given time step based on sensor information up to that time step, knowledge of the system model, and an arbitrary but known initial state. The problem is important because the majority of existing control schemes for Petri nets rely on complete knowledge of the system state at any given time step. To simplify the problem, we consider two subproblems: the optimal place sensor selection (OPSS) problem and the optimal transition sensor selection (OTSS) problem. The OPSS problem is shown to be computationally hard by establishing that the corresponding decision problem is NP -complete. For this reason, we first reduce the problem to the linear integer programming problem, which can be solved optimally using existing linear integer programming solvers (at least for small problem instances), and then propose two heuristic algorithms to approximate its solution with polynomial complexity. Simulations suggest that the two proposed heuristics run faster and can find reasonably good solutions when compared to optimal methods that are based on linear integer programming solvers. Unlike the OPSS problem, the OTSS problem is solvable with polynomial complexity.",
Total Bregman divergence and its applications to shape retrieval,"Shape database search is ubiquitous in the world of bio-metric systems, CAD systems etc. Shape data in these domains is experiencing an explosive growth and usually requires search of whole shape databases to retrieve the best matches with accuracy and efficiency for a variety of tasks. In this paper, we present a novel divergence measure between any two given points in Rn or two distribution functions. This divergence measures the orthogonal distance between the tangent to the convex function (used in the definition of the divergence) at one of its input arguments and its second argument. This is in contrast to the ordinate distance taken in the usual definition of the Bregman class of divergences [4]. We use this orthogonal distance to redefine the Bregman class of divergences and develop a new theory for estimating the center of a set of vectors as well as probability distribution functions. The new class of divergences are dubbed the total Bregman divergence (TBD). We present the l\-norm based TBD center that is dubbed the t-center which is then used as a cluster center of a class of shapes The t-center is weighted mean and this weight is small for noise and outliers. We present a shape retrieval scheme using TBD and the t-center for representing the classes of shapes from the MPEG-7 database and compare the results with other state-of-the-art methods in literature.","Shape,
Information retrieval,
Databases,
Application software,
Computer science,
Biometrics,
Explosives,
Distribution functions,
Estimation theory,
Probability distribution"
Continuous Biometric User Authentication in Online Examinations,"Online examinations pose a unique problem for distance-based education, in that it can be very difficult to provide true user authentication. Due to the inherent anonymity of being online, compared to taking an examination in a classroom environment, students may attempt to artificially boost their scores in online examinations by having another individual take the exam for them, which a typical user/password authentication scheme cannot detect. This paper discusses and presents a method for providing continuous biometric user authentication in online examinations via keystroke dynamics.","Biometrics,
Authentication,
Security,
Fingerprint recognition,
Rhythm,
Information technology,
Computer science,
Computer science education,
Continuing education,
Testing"
A Saturated Doherty Power Amplifier Based On Saturated Amplifier,"A saturated Doherty power amplifier (PA) based on the saturated PA tuned by the self-generated harmonic currents is presented. When driven with mobile WiMAX 1FA signal, this Doherty PA demonstrates high efficiency performance (average 57%) over the WiMAX band from 2.5 GHz to 2.7 GHz. Simulated and experimental results allow the evaluation for the load modulation behavior of the saturated PA and bandwidth correlation between the Doherty and saturated unit PAs. The linearity requirement of the WiMAX signal is met using the digital feedback predistortion linearization technique.","Power amplifiers,
WiMAX,
Bandwidth,
Circuits,
Impedance,
Linearity,
Voltage,
Moon,
Predistortion,
Microwave amplifiers"
An Enhanced Multi-Channel MAC for the IEEE 1609.4 Based Vehicular Ad Hoc Networks,"This paper proposes a multi-channel MAC scheme for Vehicular Ad Hoc Networks (VANETs), which dynamically adjusts the intervals of Control Channel (CCH) and Service Channels (SCHs). Markov modeling is conducted to optimize the intervals based on the traffic condition. The scheme also introduces a multi-channel coordination mechanism to provide the contention-free access in SCHs. Theoretical analysis and simulation results show that the proposed scheme is able to help IEEE 1690.4 MAC improve the saturation throughput of SCHs significantly, while maintaining the prioritized transmission of critical safety information on the CCH.","Ad hoc networks,
Throughput,
Bandwidth,
Laboratories,
Peer to peer computing,
Broadcasting,
Vehicle safety,
Communications Society,
Computer science,
USA Councils"
Automatic identification of class stereotypes,"An approach is presented to automatically determine a class's stereotype. The stereotype is based on the frequency and distribution of method stereotypes in the class. Method stereotypes are automatically determined using a defined taxonomy given in previous work. The stereotypes, boundary, control and entity are used as a basis but refined based on an empirical investigation of 21 systems. A number of heuristics, derived from empirical evidence, are used to determine a class's stereotype. For example, the prominence of certain types of methods can indicate a class's main role. The approach is applied to five open source systems and evaluated. The results show that 95% of the classes are stereotyped by the approach. Additionally, developers (via manual inspection) agreed with the approach's results.","Taxonomy,
Production facilities,
Measurement,
Libraries,
Computer science,
Software systems,
Data models"
Characterizing Mechanical Properties of Biological Cells by Microinjection,"Microinjection has been demonstrated to be an effective technique to introduce foreign materials into biological cells. Despite the advance, whether cell injection can be used to characterize the mechanical properties of cells remains elusive. In this paper, extending the previously developed mechanical model, various constitutive materials are adopted to present the membrane characteristics of cells. To demonstrate the modeling approach and identify the most appropriate constitutive material for a specific biomembrane, finite element analysis (FEA) and experimental tests are carried out. It is shown that the modeling results agree well with those from both FEA and experiments, which demonstrates the validity of the developed approach. Moreover, Yeoh and Cheng materials are found to be the best constitutive materials in representing the deformation behaviors of zebrafish embryos and mouse embryos (or oocytes), respectively. Also, the mechanical properties of zebrafish embryos at different developmental stages and mouse embryos (or oocytes) are characterized.","Mechanical factors,
Biological cells,
Microinjection,
Biological materials,
Embryo,
Biological system modeling,
Biomembranes,
Mice,
Finite element methods,
Materials testing"
Block-Based Image Compression With Parameter-Assistant Inpainting,"This correspondence presents an image compression approach that integrates our proposed parameter-assistant inpainting (PAI) to exploit visual redundancy in color images. In this scheme, we study different distributions of image regions and represent them with a model class. Based on that, an input image at the encoder side is divided into featured and non-featured regions at block level. The featured blocks fitting the predefined model class are coded by a few parameters, whereas the non-featured blocks are coded traditionally. At the decoder side, the featured regions are restored through PAI relying on both delivered parameters and surrounding information. Experimental results show that our method outperforms JPEG in featured regions by an average bit-rate saving of 76% at similar perceptual quality levels.","Image coding,
Image restoration,
Decoding,
Asia,
Sun,
Transform coding,
Color,
Video compression,
MPEG 4 Standard,
Automatic voltage control"
HPDA: A hybrid parity-based disk array for enhanced performance and reliability,"A single flash-based Solid State Drive (SSD) can not satisfy the capacity, performance and reliability requirements of a modern storage system supporting increasingly demanding data-intensive computing applications. Applying RAID schemes to SSDs to meet these requirements, while a logical and viable solution, faces many challenges. In this paper, we propose a Hybrid Parity-based Disk Array architecture, HPDA, which combines a group of SSDs and two hard disk drives (HDDs) to improve the performance and reliability of SSD-based storage systems. In HPDA, the SSDs (data disks) and part of one HDD (parity disk) compose a RAID4 disk array. Meanwhile, a second HDD and the free space of the parity disk are mirrored to form a RAID1-style write buffer that temporarily absorbs the small write requests and acts as a surrogate set during recovery when a disk fails. The write data is reclaimed back to the data disks during the lightly loaded or idle periods of the system. Reliability analysis shows that the reliability of HPDA, in terms of MTTDL (Mean Time To Data Loss), is better than that of either pure HDD-based or SSD-based disk array. Our prototype implementation of HPDA and performance evaluations show that HPDA significantly outperforms either HDD-based or SSD-based disk array.",
Improved Channel Estimation for TDS-OFDM Based on Flexible Frequency-Binary Padding,"By adopting the pseudo-random noise (PN) sequences as the guard interval (GI) as well as the training sequence, time domain synchronous orthogonal frequency division multiplexing (TDS-OFDM) outperforms the conventional OFDM using the cyclic prefix (CP) in the spectral efficiency at the cost of the iterative padding subtraction (IPS) in channel estimation (CE). To avoid the high computational complexity of the IPS, an improved frequency domain CE scheme based on a newly designed frame structure is proposed. To further improve the CE accuracy, the time domain training sequences, which are frequency binary (FB) after the fast Fourier transform (FFT), are flexibly padded as the frame header instead of the PN sequences. Theoretical analyses and computer simulations show that the proposed scheme can improve the system performance under the time frequency doubly selective channels, even in the presence of large channel delays in the single frequency networks.","Channel estimation,
Frequency estimation,
OFDM,
Costs,
Computational complexity,
Frequency domain analysis,
Fast Fourier transforms,
Performance analysis,
Computer simulation,
System performance"
Optimization of Wireless Multicast Systems Employing Hybrid-ARQ with Chase Combining,"The throughput of conventional wireless multicast systems is limited by the multicast user with the lowest channel quality, which leads to a low throughput, particularly if the number of multicast users is large. In this paper, we show that hybrid-automatic repeat request with Chase combining (HARQ-CC) is a promising technique to overcome this problem and optimize the corresponding transmission rate. We analyze the throughput of wireless multicast systems with HARQ-CC under various channel conditions and derive a closed-form approximation for the optimal rate. The numerical evaluation of our analytical expressions reveals that HARQ-aided multicast outperforms conventional multicast in most channel environments. To further improve performance, we propose a dynamic rate-allocation scheme that combines the advantages of conventional multicast and HARQ-aided multicast.",
Performance Analysis of Scheduling Schemes for Rate-Adaptive MIMO OSFBC-OFDM Systems,"Dynamic channel-aware user-selection and resource-allocation schemes are attractive for providing high system performance for multiple-input-multiple-output orthogonal frequency-division multiplexing (MIMO-OFDM) systems. In this paper, we investigate the combination of different techniques, resulting in user scheduling schemes for multiuser MIMO-OFDM systems employing orthogonal space-frequency block coding (OSFBC) over multipath frequency-selective fading channels. Our contribution is a performance analysis framework that evaluates the advantages of employing user scheduling in MIMO-OFDM systems employing OSFBC in conjunction with adaptive modulation schemes. We derive analytical expressions for the average spectral efficiency (ASE), the average bit error rate (BER), the outage probability, and the average channel capacity for different scheduling and adaptive modulation schemes. Discrete-rate and continuous-rate adaptive modulation schemes are employed to increase the spectral efficiency of the system. We assume a signal-to-noise-ratio (SNR)-based user-selection scheme and the well-known proportional fair scheduling (PFS) scheme. Both full- and limited-feedback channel information scenarios are considered. Using the results obtained from both mathematical expressions and numerical simulations, we compare the presented schemes and show their significant advantages. Finally, the impact of spatial correlation on the performance of the system under study is analyzed and evaluated.","Performance analysis,
MIMO,
Bit error rate,
System performance,
Frequency division multiplexing,
Block codes,
Frequency-selective fading channels,
Channel capacity,
Adaptive scheduling,
Signal to noise ratio"
IGFS: A New MAC Protocol Exploiting Heterogeneous Propagation Delays in the Dynamic Bandwidth Allocation on WDM-EPON,"One of the most challenging issues of the Ethernet passive optical networks' (EPONs) architecture is the bandwidth allocation problem. Various dynamic allocation schemes have been proposed to schedule the subscribers' demands. However, the performance of all these schemes is significantly degraded when the round-trip times (RTTs) of the optical network units (ONUs) are dissimilar, due to the large number of gaps in the transmission schedule. Unfortunately, in real networks, RTTs are usually dissimilar. In this paper a new medium access control (MAC) protocol for multichannel EPONs, namely the Intelligent Gap Filling Strategy (IGFS) is proposed. The IGFS employs two algorithms: the DissimilarityExploitation algorithm, which exploits the RTTs' dissimilarities, and the MinimumLatencyScheduling algorithm, which rearranges the ONUs' service order in order to favor the requests that cause the minimum scheduling latency.","Media Access Protocol,
Propagation delay,
Channel allocation,
Optical network units,
Bandwidth,
Access protocols,
Scheduling algorithm,
Optical fiber networks,
Wavelength division multiplexing,
Filling"
Forwards: A Map-Free Intersection Collision-Warning System for All Road Patterns,"Collision warning is one of the most important functions of a vehicle safety system. The emergence and expansion of the applications of positioning techniques and dedicated short-range communication (DSRC) have promoted the collision warning system evolution from a simple ranging-sensor-based system to a cooperative system. Differing from prior work that relied heavily on the e-Map, high-accuracy differential Global Positioning System (DGPS), or advanced car features like the controller area network (CAN) bus, this paper proposes Forwards, i.e., a map-free intersection collision-warning system for all road patterns with lower requirement and lower cost accessories. Forwards employs a triple Kalman filter (tri-KF)-based estimator that integrates GPS and external inertial sensor measurement to provide calibrated motion state information (MSI) such as position, velocity, and acceleration of the vehicle. Each vehicle then adaptively broadcasts its own MSI via the DSRC-based protocol. Using the steady-state maneuvering model, short-term trajectories of local and neighboring vehicles are further predicted, based on their current MSI. Collision-detection algorithms are then designed based on the model of finding the minimum distance of vehicles' future trajectories, and hierarchical warnings are given upon different criteria. Simulation results show that our approach outperforms the referenced approach in successful warning ratio and requires far fewer accessories and external conditions than the other referenced approaches.",
MapReduce-based Backpropagation Neural Network over large scale mobile data,"Large scale mobile data are generated continuously by multiple mobile devices in daily communications. Classification on such data possesses high significance for analyzing the behaviors of mobile customers. However, the natural properties of mobile data presents three non-trivial challenges: large data scale leads it difficult to keep both efficiency and accuracy; similar data increases the system load; and noise in the data set is also an important influence factor of the processing result. To resolve the above problems, this paper integrates conventional backpropagation neural network in the cloud computing environment. A MapReduce-based method called MBNN (i.e. MapReduce-based Backpropagation Neural Network) is proposed to process classifications on large-scale mobile data. It utilizes a diversity-based algorithm to decrease the computational loads. Moreover, the Adaboosting mechanism is introduced to further ameliorate the performance of classifications. Extensive experiments on gigabyte of realistic mobile data are performed on a cloud computing platform. And the results show that MBNN is characterized by superior efficiency, good scalability and anti-noise.",
Formal modelling of a robust Wireless Sensor Network routing protocol,"Because of their low cost, small size, low resources and self-organizing nature a Wireless Sensor Network (WSN) is a potential solution in hostile environments including military applications. However, the broadcasting nature of radio transmission; their limited computing, power and communication resources; unattended and potentially hostile nature of the environment they operate in make WSNs prone to Denial of Service (DoS) attacks. Although many schemes have been proposed to address DoS attacks their effectiveness is yet to be proven. The traditional methods used (i.e. visual inspection, computer simulations and hardware implementations) can only detect errors but cannot verify that the whole system is error free. Therefore, new techniques to automatically determine the worst cases and hidden errors in WSNs are much desired. After an initial investigation using a formal verification which clearly shows that Arrive routing protocol is vulnerable to different DoS attacks, this paper proposes a method for its security. The finding contradicts the claim of the developers of Arrive that it is immune to black hole attacks. Several other DoS attacks were also found to be successful in Arrive routing protocol. The formal model generates the trace to confirm how an attack is possible in the protocol. However, it was found that INA attacks are addressed by Arrive protocol. To our best knowledge the results discussed in this paper have not been presented, proved or published before.",
Watermarking of Free-view Video,"With the advances in image based rendering (IBR) in recent years, generation of a realistic arbitrary view of a scene from a number of original views has become cheaper and faster. One of the main applications of this progress has emerged as free-view TV(FTV), where TV-viewers select freely the viewing position and angle via IBR on the transmitted multiview video. Noting that the TV-viewer might record a personal video for this arbitrarily selected view and misuse this content, it is apparent that copyright and copy protection problems also exist and should be solved for FTV. In this paper, we focus on this newly emerged problem by proposing a watermarking method for free-view video. The watermark is embedded into every frame of multiple views by exploiting the spatial masking properties of the human visual system. Assuming that the position and rotation of the virtual camera is known, the proposed method extracts the watermark successfully from an arbitrarily generated virtual image. In order to extend the method for the case of an unknown virtual camera position and rotation, the transformations on the watermark pattern due to image based rendering operations are analyzed. Based upon this analysis, camera position and homography estimation methods are proposed for the virtual camera. The encouraging simulation results promise not only a novel method, but also a new direction for watermarking research.","Watermarking,
Cameras,
Rendering (computer graphics),
Layout,
TV,
Protection,
Humans,
Visual system,
Image generation,
Image analysis"
Harvesting large-scale weakly-tagged image databases from the web,"To leverage large-scale weakly-tagged images for computer vision tasks (such as object detection and scene recognition), a novel cross-modal tag cleansing and junk image filtering algorithm is developed for cleansing the weakly-tagged images and their social tags (i.e., removing irrelevant images and finding the most relevant tags for each image) by integrating both the visual similarity contexts between the images and the semantic similarity contexts between their tags. Our algorithm can address the issues of spams, polysemes and synonyms more effectively and determine the relevance between the images and their social tags more precisely, thus it can allow us to create large amounts of training images with more reliable labels by harvesting from large-scale weakly-tagged images, which can further be used to achieve more effective classifier training for many computer vision tasks.","Large-scale systems,
Image databases,
Computer vision,
Collaboration,
Layout,
Tagging,
Object detection,
Image recognition,
Internet,
Large scale integration"
Standards-enabled Smart Grid for the future Energy Web,"An intelligent control architecture for the Smart Grid is proposed which combines two recently developed industrial standards. The utility network is modelled as IEC 61850-compliant logical nodes, embedded in an IEC 61499 distributed automation framework. We make the case that an incremental approach is required for the transition to the future EnergyWeb by bringing intelligence down to the level of substation automation devices to enrich the applications that can be created using interoperable Smart Grid devices. Using Matlab-based simulation environment we demonstrate that the collaborative environment achieves self-healing through simple fault location and power restoration.",
Convex Optimizations for Distance Metric Learning and Pattern Classification [Applications Corner],"The goal of machine learning is to build automated systems that can classify and recognize complex patterns in data. The representation of the data plays an important role in determining what types of patterns can be automatically discovered. Many algorithms for machine learning assume that the data are represented as elements in a metric space. The performance of these algorithms can depend sensitively on the manner in which distances are measured. When data are represented as points in a multidimensional vector space, simple Euclidean distances are often used to measure the dissimilarity between different examples. However, such distances often do not yield reliable judgments; in addition, they cannot highlight the distinctive features that play a role in certain types of classification, but not others. Naturally, for different types of clustering, different ways of measuring dissimilarity were needed. In particular, different metrics for computing distances between feature vectors. This paper describes two algorithms for learning such distance metrics based on recent developments in convex optimization.",
Cross-Layer Optimized MAC to Support Multihop QoS Routing for Wireless Sensor Networks,"This paper presents an efficient hybrid medium- access control (HMAC) protocol with an embedded cross-layer optimization solution to provide routing-layer coarse-grained end-to-end quality-of-service (QoS) support for latency-sensitive traffic flows. A novel channel-reservation technique is proposed to significantly reduce the end-to-end delay for delay-sensitive traffic flows by allowing packets to go through multiple hops within a single medium-access control (MAC) frame and by also giving them higher priority channel access to reduce possible queuing delay. Our proposed protocol (HMAC) combines energy-efficient features of the existing contention-based and time-division multiple-access (TDMA)-based MAC protocols and adopts a short frame structure to expedite packet delivery. Simulation results in ns-2 show that HMAC achieves significant performance improvements in energy consumption, latency, and throughput over existing MAC protocols.","Spread spectrum communication,
Routing,
Wireless sensor networks,
Delay,
Access protocols,
Communication system traffic control,
Traffic control,
Media Access Protocol,
Access control,
Quality of service"
Aging of distribution transformers due to harmonics,"Solid state electronics is used to increase the energy efficiency of electrical load devices. The harmonic distortion of current is increasing with the enhanced use of nonlinear loads i.e. solid state devices. Examples of nonlinear loads are personal computer, laptop, laser printer, fax machine, television set (TV), fluorescent tube with electronic ballast, compact fluorescent lamp, battery charger, adjustable speed drives, uninterrupted power supply (UPS) and any other equipment powered by switched-mode power supply (SMPS) unit. These nonlinear loads draw more current than the fundamental current and cause overloading of the components of the distribution system. Transformers are major components of the distribution system and are mainly affected by this overloading. This leads to higher losses, reduces the strength of insulation and consequently leads to reduction of useful life of the transformer. Aging of transformer increases due to overheating caused by overloading. This paper presents the results of a case study of aging of transformer caused by harmonics due to non linear loads. Here two transformers of 500 kVA and 100 kVA are considered which supply a technical institution and residential campus respectively. The harmonic currents produced by these loads are captured in the laboratory and their effect on transformers is studied. An attempt has been made to calculate the energy loss due to harmonic distortion caused by these nonlinear loads. The rise in operating temperature due to harmonic current and hence life expectancy of the transformers are calculated.",
Application-Driven Compression for Visualizing Large-Scale Time-Varying Data,"We advocate an application-driven approach to compressing and rendering large-scale time-varying scientific-simulation data. Scientists often have specific visualization tasks in mind based on certain domain knowledge. For example, in the context of time-varying, multivariate volume-data visualization, a scientist's domain knowledge might include the salient isosurface of interest for some variable. Given this knowledge, the scientist might want to observe spatiotemporal relationships among other variables in the neighborhood of that isosurface. We've tried to directly incorporate such knowledge and tasks into data reduction, compression, and rendering. Here, we present our solution andexperimental results for two largescale time-varying, multivariate scientific data sets.","Data visualization,
Large-scale systems,
Isosurfaces,
Spatiotemporal phenomena"
Efficient Power Management for Infrastructure IEEE 802.11 WLANs,"To achieve a long run-time for battery-operated portable electronic devices that incorporate wireless transceivers, efficient power management of the radio is a critical requirement. The power management function of IEEE 802.11 wireless local area networks (WLANs) allows stations (STAs) to operate in the doze mode so that their power consumption is significantly reduced. Hence, efficient algorithms to manage when and how often a STA enters and exits doze mode are crucial to battery-operated STAs. We address this problem by developing a novel model for stochastic analysis of timer-based power management in infrastructure IEEE 802.11 WLANs. Based on this model, the probabilities that a STA is active, idle, or dozing are derived, and the power consumption of the STA, number of frames buffered, and average delay per frame are obtained. These results enable an efficient power management algorithm that optimizes the idle timer and doze duration at the STA and the frame buffer at the access point. Moreover, similar statistics for the basic power management method in the IEEE 802.11 standard are derived as a special case of the proposed timer-based power management scheme. Numerical results are presented to demonstrate the effectiveness of the proposed algorithms.","Energy management,
Battery management systems,
Energy consumption,
Runtime,
Transceivers,
Radio spectrum management,
Wireless LAN,
Stochastic processes,
Delay,
Statistics"
"Modeling, Design, and Characterization of Multiturn Bondwire Inductors With Ferrite Epoxy Glob Cores for Power Supply System-on-Chip or System-in-Package Applications","The concept of coupled multiturn bondwire inductors with ferrite epoxy glob cores is investigated both experimentally and numerically to offer a cost-effective approach realizing power supply system-on-chip (PSoC) or system-in-package (PSiP). Improvement in total inductance and Q factor is demonstrated for the multiturn bondwire inductors due to the coupling effect. An empirical calculation method is developed to help determine the self and mutual inductance of the proposed bondwire inductors. The bondwire magnetic components can be easily integrated into IC packaging processes with minimal changes, and open possibilities for realizing cost-effective, high-current, and high-efficiency PSoCs or PSiPs.",
Component-Based Safety Analysis of FPGAs,"Component-based and modular software development techniques have become established in recent years. Without complementary verification and certification methods the benefits of these development techniques are reduced. As part of certification, it is necessary to show a system is acceptably safe which subsumes both the normal and abnormal (failure) cases. However, nonfunctional properties, such as safety and failures, are abstraction breakers, cutting across multiple components. Also, much of the work on component-based engineering has been applied to software-based systems rather than field programmable gate array (FPGA)-based systems whose use is becoming more popular in industry. In this paper, we show how a modular design embedded on a FPGA can be exhaustively analyzed (from a safety perspective) to derive the failure and safety properties to give the evidence needed for a safety case. The specific challenges faced are analyzing the fault characteristics of individual electronic components, combining the results across software modules, and then feeding this into a system safety case. A secondary benefit of taking this approach is that there is less uncertainty in the performance of the device, hence, it can be used for higher integrity systems. Finally, design improvements can be specifically targeted at areas of safety concern, leading to more optimal utilization of the FPGA device.",
Power-oscillator based high efficiency inductive power-link for transcutaneous power transmission,"Transcutaneous power transmission is a critical issue for long term reliable operation of implantable systems. This paper reports a power-oscillator based inductive power link to power up any implantable unit inside the human body. Instead of using power amplifier which requires high drive requirement, two power-oscillator based inductive powering schemes have been presented to achieve high link efficiency. The first scheme utilizes a class-E power oscillator whereas the second scheme uses a differential cross-coupled power oscillator to drive the inductive link. Resonant inductive link has been used to achieve better link efficiency. Simulation results indicate that for a coupling coefficient of 0.45, the class-E power-oscillator based scheme shows a link efficiency of 66% and the differential cross-coupled power-oscillator based scheme shows more than 90% link efficiency. The system has been designed using 0.5-µm standard CMOS process and both of the systems can handle more than 10 mW of power which is adequate for safe operation of biomedical implants.",
Dynamic Request Allocation and Scheduling for Context Aware Applications Subject to a Percentile Response Time SLA in a Distributed Cloud,"We consider geographically distributed data centers forming a collectively managed cloud computing system, hosting multiple Service Oriented Architecture (SOA) based context aware applications, each subject to Service Level Agreements (SLA). The Service Level Agreements for each context aware application require the response time of a certain percentile of the input requests to be less than a specified value for a profit to be charged by the cloud provider. We present a novel approach of data-oriented dynamic service-request allocation with gi-FIFO scheduling, in each of the geographically distributed data centers, to globally increase the profit charged by the cloud computing system. Our evaluation shows that our dynamic scheme far outperforms the commonly deployed static allocation with either First in First Out (FIFO) or Weighted Round Robin (WRR) scheduling.",
Observability and estimation uncertainty analysis for PMU placement alternatives,"The synchronized phasor measurement unit (PMU), developed in the 1980s, is considered to be one of the most important devices in the future of power systems. While PMU measurements currently cover fewer than 1% of the nodes in the U.S. power grid, the power industry has gained the momentum to advance the technology and install more units. However, with limited resources, the installation must be selective. Previous PMU placement research has focused primarily on the network topology, with the goal of finding configurations that achieve full network observability with a minimum number of PMUs. Here we present a new approach that also includes stochastic models for the signals and measurements, to characterize the observability and corresponding uncertainty of any given configuration of PMUs, whether that configuration achieves full observability or not. We hope that this approach can provide planning engineers with a new tool to help choose between PMU placement alternatives.","Phasor measurement units,
Current measurement,
Voltage measurement,
Observability,
Power measurement,
Power systems,
Transmission line measurements"
Fast Context-Adaptive Mode Decision Algorithm for Scalable Video Coding With Combined Coarse-Grain Quality Scalability (CGS) and Temporal Scalability,"To speed up the H.264/MPEG scalable video coding (SVC) encoder, we propose a layer-adaptive intra/inter mode decision algorithm and a motion search scheme for the hierarchical B-frames in SVC with combined coarse-grain quality scalability (CGS) and temporal scalability. To reduce computation but maintain the same level of coding efficiency, we examine the rate-distortion (R-D) performance contributed by different coding modes at the enhancement layers (EL) and the mode conditional probabilities at different temporal layers. For the intra prediction on inter frames, we can reduce the number of Intra4×4/Intra 8×8 prediction modes by 50% or more, based on the reference/base layer intra prediction directions. For the EL inter prediction, the look-up tables containing inter prediction candidate modes are designed to use the macroblock (MB) coding mode dependence and the reference/base layer quantization parameters (Qp). In addition, to avoid checking all motion estimation (ME) reference frames, the base layer (BL) reference frame index is selectively reused. And according to the EL MB partition, the BL motion vector can be used as the initial search point for the EL ME. Compared with Joint Scalable Video Model 9.11, our proposed algorithm provides a 20× speedup on encoding the EL and an 85% time saving on the entire encoding process with negligible loss in coding efficiency. Moreover, compared with other fast mode decision algorithms, our scheme can demonstrate a 7-41% complexity reduction on the overall encoding process.","Scalability,
Video coding,
Static VAr compensators,
Encoding,
Decoding,
Automatic voltage control,
Streaming media,
Central Processing Unit,
Quantization,
Motion estimation"
Reliable Adaptive Multipath Provisioning with Bandwidth and Differential Delay Constraints,"Robustness and reliability are critical issues in network management. To provide resiliency against network failures, a popular protection scheme against network failures is the simultaneous routing along multiple disjoint paths. Most previous protection and restoration schemes were designed for all-ornothing protection and thus, an overkill for data traffic. In this work, we study the Reliable Adaptive Multipath Provisioning (RAMP) problem with reliability and differential delay constraints. We aim to route the connections in a manner such that link failure does not shut down the entire stream but allows a continuing flow for a significant portion of the traffic along multiple (not necessary disjoint) paths, allowing the whole network to carry sufficient traffic even when link/node failure occurs. The flexibility enabled by a multipath scheme has the tradeoff of differential delay among the diversely routed paths. This requires increased memory in the destination node in order to buffer the traffic until the data arrives on all the paths. Increased buffer size will raise the network element cost and could cause buffer overflow and data corruption. Therefore, differential delay between the multiple paths should be bounded by containing the delay of a path in a range from dmin to dmax. We first prove that RAMP is a NP-hard problem. Then we present a pseudo-polynomial time solution to solve a special case of RAMP, representing edge delays as integers. Next, a (1 + \epsilon)-approximation is proposed to solve the optimization version of the RAMP problem. We also present numerical results confirming the advantage of our scheme over the current state of art.","Bandwidth,
Delay,
Telecommunication traffic,
Protection,
Routing,
Computer science,
Quality of service,
Application software,
Neodymium,
National electric code"
A survey on bee colony algorithms,"This paper presents a survey of current research activities inspired by bee life. This work is intended to provide a broad and comprehensive view of the various principles and applications of these bio-inspired systems. We propose to classify them into two major models. The first one is based on the foraging behavior in the bee quotidian life and the second is inspired by the marriage principle. Different original studies are described and classified along with their applications, comparisons against other approaches and results. We then summarize a review of their derived algorithms and research efforts.","Biological system modeling,
Insects,
Evolution (biology),
Ant colony optimization,
Radiofrequency interference,
Computer science,
Application software,
Testing,
Biology computing,
Computational biology"
Segmentation of Human Body Parts Using Deformable Triangulation,"This paper presents a novel segmentation algorithm to segment a body posture into different body parts using the technique of deformable triangulation. To analyze each posture more accurately, they are segmented into triangular meshes, where a spanning tree can be found from the meshes using a depth-first search scheme. Then, we can decompose the tree into different subsegments, where each subsegment can be considered as a limb. Then, two hybrid methods (i.e., the skeleton-based and model-driven methods) are proposed for segmenting the posture into different body parts according to its occlusion conditions. To analyze occlusion conditions, a novel clustering scheme is proposed to cluster the training samples into a set of key postures. Then, a model space can be used to classify and segment each posture. If the input posture belongs to the nonocclusion category, the skeleton-based method is used to divide it into different body parts that can be refined using a set of Gaussian mixture models (GMMs). For the occlusion case, we propose a model-driven technique to select a good reference model for guiding the process of body part segmentation. However, if two postures' contours are similar, there will be some ambiguity that can lead to failure during the model selection process. Thus, this paper proposes a tree structure that uses a tracking technique so that the best model can be selected not only from the current frame but also from its previous frame. Then, a suitable GMM-based segmentation scheme can be used to finely segment a body posture into the different body parts. The experimental results show that the proposed method for body part segmentation is robust, accurate, and powerful.","Humans,
Detectors,
Video surveillance,
Computer science,
Head,
Biological system modeling,
Tree data structures,
Robustness,
Event detection,
Power generation economics"
Permittivity characteristics of epoxy/alumina nanocomposite with high particle dispersibility by combining ultrasonic wave and centrifugal force,"This paper proposes a novel technique to fabricate epoxy/alumina nanocomposites with nanoparticle composite process by combination of ultrasonic wave and centrifugal force. The particle dispersion effect of the nanoparticle composite process and its influence on dielectric permittivity were discussed quantitatively. Experimental results clarified that the combination of ultrasonic wave and centrifugal force was effective to increase dispersed nanoparticles and as well as to separate residual agglomerates. We verified that the improvement of particle dispersibility in the nanoparticle composite process by combination of ultrasonic wave and centrifugal force could bring about lower permittivity of the nanocomposites, especially than that of unfilled epoxy material.","Permittivity,
Nanoparticles,
Dispersion,
Dielectric losses,
Polymers,
Composite materials,
Dielectric materials,
Surface treatment,
Conducting materials,
Inorganic materials"
A taxonomy of Botnet detection techniques,"Among the diverse forms of malware, Botnet is the most widespread and serious threat which occurs commonly in today's cyber attacks. Botnets are collections of compromised computers which are remotely controlled by its originator (BotMaster) under a common Commond-and-Control (C&C) infrastructure. They provide a distributed platform for several illegal activities such as launching distributed denial of service (DDOS) attacks against critical targets, malware distribution, phishing, and click fraud. Most of the existing Botnet detection approaches concentrate only on particular Botnet command and control (C&C) protocols (e.g., IRC, HTTP) and structures (e.g., centralized), and can become ineffective as Botnets change their structure and C&C techniques. The detection of Botnet has been a major research topic in recent years. Different techniques and approaches have been proposed for detection and tracking of Botnet. This survey classifies Botnet detection techniques into two approaches. One approach is based on setting up honeynets and another approach is based on Intrusion Detection System( IDS) which has been categorized into signature-based and anomaly-based detection techniques.","Monitoring,
Computational modeling,
Computers,
Cryptography"
New results on turbulence modeling for free-space optical systems,"In this paper, we propose a statistical channel model, named as Double-Weibull, to describe the irradiance fluctuations in moderate and strong turbulence for free-space optical (FSO) systems. The proposed stochastic model is based on the scintillation theory and derived via the product of two Weibull random variables. Closed-form expressions of probability and cumulative density functions are provided in terms of Meijer's G-function. We also compare the new model with the classical gamma-gamma model and assess their accuracy via a set of simulations when both plane and spherical waves are considered. We finally evaluate the performance of an FSO system over the Double-Weibull turbulence channel and derive closed-form expressions for the bit-error rate, assuming intensity-modulation/direct detection with On-Off keying, and the outage probability.","Atmospheric modeling,
Fluctuations,
Optical signal processing,
Biomedical optical imaging,
Optical refraction,
Optical variables control,
Closed-form solution,
Optical saturation,
Bit error rate,
Large-scale systems"
"Gate-First Integration of Tunable Work Function Metal Gates of Different Thicknesses Into High-
k
/Metal Gates CMOS FinFETs for Multi-
V
Th
Engineering","Gate-first integration of tunable work function metal gates of different thicknesses (3-20 nm) into high-k/metal gates CMOS FinFETs was demonstrated to achieve multiple threshold voltages (VTh) for 32-nm technology and beyond logic, memory, input/output, and system-on-a-chip applications. The fabricated devices showed excellent short-channel effect immunity (drain-induced barrier lowering ~40 mV/V), nearly symmetric VTh, low Tinv (~1.4 nm), and high Ion (~780 ¿A/¿m) for N/PMOS without any intentional strain enhancement.","Logic gates,
FinFETs,
High K dielectric materials,
Tin,
CMOS integrated circuits"
Evolving diverse Ms. Pac-Man playing agents using genetic programming,"This paper uses genetic programming (GP) to evolve a variety of reactive agents for a simulated version of the classic arcade game Ms. Pac-Man. A diverse set of behaviours were evolved using the same GP setup in three different versions of the game. The results show that GP is able to evolve controllers that are well-matched to the game used for evolution and, in some cases, also generalise well to previously unseen mazes. For comparison purposes, we also designed a controller manually using the same function set as GP. GP was able to significantly outperform this hand-designed controller. The best evolved controllers are competitive with the best reactive controllers reported for this problem.",
Nonlinear Stabilization via Control Lyapunov Measure,"This paper is concerned with computational methods for Lyapunov-based stabilization of an attractor set of a nonlinear dynamical system. Based upon a stochastic representation of deterministic dynamics, a Lyapunov measure is used for these purposes. The paper poses and solves the co-design problem of jointly obtaining a control Lyapunov measure and a state feedback controller. The computational framework employs set-oriented numerical techniques. Using these techniques, the resulting co-design problem is shown to lead to a finite number of linear inequalities. These inequalities determine the feasible set of the solutions to the co-design problem. A particular solution can be efficiently obtained using methods of linear programming.","Stability,
Nonlinear control systems,
Nonlinear dynamical systems,
Stochastic processes,
Nonlinear systems,
Control systems,
State feedback,
Linear programming,
Control system synthesis,
Lyapunov method"
Dynamic Cloud provisioning for scientific Grid workflows,"Scientific computing requires an ever-increasing number of resources to deliver results for growing problem sizes in a reasonable timeframe. In the last decade, while the largest research projects were able to afford expensive supercomputers, others were forced to opt for cheaper resources such as commodity clusters or computational Grids. Today, Cloud computing proposes an alternative by which resources are no longer hosted by the scientists' computational facilities, but leased from specialized data centers only when and for how long they are needed. In this paper, we analyze the problem of dynamic provisioning of Cloud resources to scientific workflows that do not have sufficient Grid resources available, as required by their computational demands. We propose and study four provisioning aspects that deal with the general leasing model encountered in today's commercial Cloud environments based on resource bulks, fuzzy descriptions, and hourly payment intervals: Cloud start, instance type, Grid rescheduling, and Cloud stop. We study the impact of our techniques to the overall execution time, overall cost, and cost per unit of saved time with respect to various instance types offered by the Amazon EC2.",
To GPU synchronize or not GPU synchronize?,"The graphics processing unit (GPU) has evolved from being a fixed-function processor with programmable stages into a programmable processor with many fixed-function components that deliver massive parallelism. By modifying the GPU's stream processor to support “general-purpose computation” on the GPU (GPGPU), applications that perform massive vector operations can realize many orders-of-magnitude improvement in performance over a traditional processor, i.e., CPU. However, the breadth of general-purpose computation that can be efficiently supported on a GPU has largely been limited to highly dataparallel or task-parallel applications due to the lack of explicit support for communication between streaming multiprocessors (SMs) on the GPU. Such communication can occur via the global memory of a GPU, but it then requires a barrier synchronization across the SMs of the GPU in order to complete the communication between SMs. Although our previous work demonstrated that implementing barrier synchronization on the GPU itself can significantly improve performance and deliver correct results in critical bioinformatics applications, guaranteeing the correctness of inter-SM communication is only possible if a memory consistency model is assumed. To address this problem, NVIDIA recently introduced the threadfence() function in CUDA 2.2, a function that can guarantee the correctness of GPU-based inter-SM communication. However, this function currently introduces so much overhead that when using it in (direct) GPU synchronization, GPU synchronization actually performs worse than indirect synchronization via the CPU, thus raising the question of whether “to GPU synchronize or not GPU synchronize?”",
Parallel tempering is efficient for learning restricted Boltzmann machines,"A new interest towards restricted Boltzmann machines (RBMs) has risen due to their usefulness in greedy learning of deep neural networks. While contrastive divergence learning has been considered an efficient way to learn an RBM, it has a drawback due to a biased approximation in the learning gradient. We propose to use an advanced Monte Carlo method called parallel tempering instead, and show experimentally that it works efficiently.","Neurons,
Temperature distribution,
Probability distribution,
Training data,
Machine learning,
Training,
Monte Carlo methods"
Enhanced Extraction Efficiency of InGaN-Based Light-Emitting Diodes Using 100-kHz Femtosecond-Laser-Scribing Technology,"A femtosecond laser was focused inside a thinned sapphire substrate to scribe the substrate and separate nitride-based light-emitting diodes (LEDs). The LED scribed by using the femtosecond laser exhibits an 11% enhancement in the output power at 20 mA, compared to that scribed by using the nanosecond laser, which is attributed to the reduction in both debris and thermal damage of the sapphire substrate. Femtosecond-laser scribing also has an advantage of high-speed processing because the extremely short pulsewidth enables it to easily reach very high peak laser intensity.",
3D Face recognition using distinctiveness enhanced facial representations and local feature hybrid matching,"This paper presents a simple yet effective approach for 3D face recognition. A novel 3D facial surface representation, namely Multi-Scale Local Binary Pattern (MS-LBP) Depth Map, is proposed, which is used along with the Shape Index (SI) Map to increase the distinctiveness of smooth range faces. Scale Invariant Feature Transform (SIFT) is introduced to extract local features to enhance the robustness to pose variations. Moreover, a hybrid matching is designed for a further improved accuracy. The matching scheme combines local and holistic analysis. The former is achieved by comparing the SIFT-based features extracted from both 3D facial surface representations; while the latter performs a global constraint using facial component and configuration. Compared with the state-of-the-art, the proposed method does not require time-consuming accurate registration or any additional data in a bootstrap for training special thresholds. The rank-one recognition rate achieved on the complete FRGC v2.0 database is 96.1%. As a result of using local facial features, the approach proves to be competent for dealing with partially occluded face probes as highlighted by supplementary experiments using face masks.","Face,
Three dimensional displays,
Silicon,
Feature extraction,
Shape,
Probes,
Pixel"
Balancing broadcast reliability and transmission range in VANETs,"In this paper, a novel transmit power control protocol for vehicular ad-hoc networks (VANETs) is proposed that aims to improve the reliability of safety-critical broadcasts while also maximizing the transmission range. Large transmission ranges are often desirable in order to ensure that safety-critical messages reach as many vehicles as possible, particularly in highvelocity situations. However, larger transmit powers also lead to increased channel contention and packet collisions. Further, vehicles in close proximity of the sender are likely to benefit the most from successfully receiving safety-critical information, requiring protocols that maximize the reliability of broadcasts over short distances. As a consequence, this work proposes an adaptive transmit power control approach that balances these two conflicting goals, i.e., maximizing the number of packets that are successfully received by nearby vehicles, while keeping the transmit power as large as possible to reach vehicles at larger distances. This proposed protocol incurs minimum additional overhead (since it is primarily based on simple overhearing) and works well in both highway and urban traffic scenarios.","Vehicles,
Power control,
Road transportation,
Reliability,
Ad hoc networks,
Safety,
Interference"
Optimal loop unrolling for GPGPU programs,"Graphics Processing Units (GPUs) are massively parallel, many-core processors with tremendous computational power and very high memory bandwidth. With the advent of general purpose programming models such as NVIDIA's CUDA and the new standard OpenCL, general purpose programming using GPUs (GPGPU) has become very popular. However, the GPU architecture and programming model have brought along with it many new challenges and opportunities for compiler optimizations. One such classical optimization is loop unrolling. Current GPU compilers perform limited loop unrolling. In this paper, we attempt to understand the impact of loop unrolling on GPGPU programs. We develop a semi-automatic, compile-time approach for identifying optimal unroll factors for suitable loops in GPGPU programs. In addition, we propose techniques for reducing the number of unroll factors evaluated, based on the characteristics of the program being compiled and the device being compiled to. We use these techniques to evaluate the effect of loop unrolling on a range of GPGPU programs and show that we correctly identify the optimal unroll factors. The optimized versions run up to 70% faster than the unoptimized versions.",
Optimizing communication in air-ground robot networks using decentralized control,"We develop a distributed controller to position a team of aerial vehicles in a configuration that optimizes communication-link quality, to support a team of ground vehicles performing a collaborative task. We propose a gradient-based control approach where agents' positions locally minimize a physically motivated cost function. The contributions of this paper are threefold. We formulate of a cost function that incorporates a continuous, physical model of signal quality, SIR. We develop a non-smooth gradient-based controller that positions aerial vehicles to acheive optimized signal quality amongst all vehicles in the system. This controller is provably convergent while allowing for non-differentiability due to agents moving in or out of communication with one another. Lastly, we guarantee that given certain initial conditions or certain values of the control parameters, aerial vehicles will never disconnect the connectivity graph. We demonstrate our controller on hardware experiments using AscTec Hummingbird quadrotors and provide aggregate results over 10 trials. We also provide hardware-in-the-loop and MATALB simulation results, which demonstrate positioning of the aerial vehicles to minimize the cost function H and improve signal-quality amongst all communication links in the ground/air robot team.",
A collaborative trust model of firewall-through based on Cloud Computing,"In this paper, the existing trust models and firewall technology are studied. Then we develop an approach based on Cloud Computing to estimate dynamic context and present the definition of risk signal. A collaborative trust model of firewall-through based on Cloud Environment is proposed. The model has three advantages: Firstly, there are different security policies for different domains. Secondly, the model considers the transaction context, the historical data of entity influences and the measurement of trust value dynamically. Thirdly, the trust model is compatible with the firewall and does not break the firewall's local control policies. To verify the reliability and effectiveness of the coordinated trust model, a simulation is carried out. The simulation result shows that this trust model is robust and out-performances traditional trust models based on domains because it successfully blocks malicious access under Cloud Computing environment.","Cloud computing,
Security,
Internet,
Application software,
Collaborative work,
International collaboration,
Context modeling,
Computational modeling,
Large-scale systems,
Scalability"
QoS scheduling for NoCs: Strict Priority Queueing versus Weighted Round Robin,"Strict Priority Queueing (SPQ) andWeighted Round Robin (WRR) are two common scheduling techniques to achieve Quality-of-Service (QoS) while using shared resources. Based on network calculus, we build analytical models for traffic flows under SPQ and WRR scheduling in on-chip wormhole networks. With these models, we can derive per-flow end-to-end delay bound. We compare the service behavior and show that WRR is not only more fair but also more flexible for QoS provision. To exhibit the potential and flexibility enabled by WRR, we develop a weight allocation algorithm to automatically assign proper weights for individual flows to satisfy their delay constraints. In particular, the weights are assigned in a way not more than necessary, in other words, to approach flows' delay constraints in order to leave room for other flows. Our experimental results validate our analysis technique and algorithms.","Delay,
Switches,
Nickel,
Resource management,
Quality of service,
Calculus,
Analytical models"
Transfer of GaN-Based Light-Emitting Diodes From Silicon Growth Substrate to Copper,"III-nitride light-emitting diodes (LEDs) grown on Si (111) substrates have the potential of low-cost manufacturing for solid-state lighting and display, by taking advantage of the well-developed IC technologies of silicon. In this letter, LEDs grown on silicon substrates were transferred onto copper substrates, to maximize light extraction and heat dissipation. On Si substrates, 300 × 300 ¿m2 multiple quantum well InGaN LEDs were first grown and processed. The top surface of the fabricated devices was then temporarily bonded to a sapphire wafer and the Si substrate was chemically etched. Ti/Al/Ti/Au layers were deposited on the backside of LEDs. An 80-¿m-thick copper layer was electroplated and the temporary bonding was removed, resulting in LEDs on copper substrate. The optical output power of LEDs on copper increased by ~ 70% as compared to that of the LEDs on silicon. The improved performance was attributed to the removal of the light-absorbing Si substrate and the good thermal conductivity of copper.",
Enhancing low light images using near infrared flash images,"In low light environment, photographs taken with a high ISO setting suffer from significant noise. In this paper, we propose to use a near infrared (NIR) flash image, instead of a normal visible flash image, to enhance its corresponding noisy visible image. We build a hybrid camera system to take an visible image and its NIR counterpart simultaneously. We introduce a new method to denoise an visible image and enhance its details using its corresponding NIR flash image. Experimental results show the superiority of our method compared with previous image denoising and detail enhancement methods.","Ash,
Image color analysis,
Cameras,
Smoothing methods,
Image edge detection,
Photography,
Noise"
Integrated Planar Monopole Antenna With Microstrip Resonators Having Band-Notched Characteristics,"Novel integrated planar monopole antennas with various microstrip resonators are presented. The proposed integrated antennas consist of wideband planar monopole antennas and electromagnetically coupled microstrip resonators producing band-notched characteristics. Various types of microstrip resonators such as open-circuited line resonator, short-circuited line resonator, closed-loop resonator and open-loop resonator are described. The proposed designs are suitable for wideband antennas with narrowband interferer rejection characteristic or multi-band antennas.",
Pulse Width Allocation and Clock Skew Scheduling: Optimizing Sequential Circuits Based on Pulsed Latches,"Pulsed latches, latches driven by a brief clock pulse, offer the same convenience of timing verification and optimization as flip-flop-based circuits, while retaining the advantages of latches over flip-flops. But a pulsed latch that uses a single pulse width has a lower bound on its clock period, limiting its capacity to deal with higher frequencies or operate at lower Vdd. The limitation still exists even when clock skew scheduling is employed, since the amount of skew that can be assigned and realized is practically limited due to process variation. For the first time, we formulate the problem of allocating pulse widths, out of a small discrete number of predefined widths, and scheduling clock skews, within a predefined upper bound on skew, for optimizing pulsed latch-based sequential circuits. We then present an algorithm called PWCS_Optimize (pulse width allocation and clock skew scheduling, PWCS) to solve the problem. The allocated skews are realized through synthesis of local clock trees between pulse generators and latches, and a global clock tree between a clock source and pulse generators. Experiments with 65-nm technology demonstrate that combining a small number of different pulse widths with clock skews of up to 10% of the clock period yield the minimum achievable clock period for many benchmark circuits. The results have an average figure of merit of 0.86, where 1.0 indicates a minimum clock period, and the average reduction in area by 11%. The design flow including PWCS_Optimize, placement and routing, and synthesis of local and global clock trees is presented and assessed with example circuits.",
Coordinated power management of periodic real-time tasks on chip multiprocessors,"In this paper, we undertake the problem of minimizing system-level energy on chip-multicore processors (CMPs) executing a periodic real-time workload. Our framework has two components: i.) a static phase that selects a subset of cores upon which the workload can be executed without dissipating excessive static power and performs task-to-core allocation, ii.) a dynamic phase that involves managing the selected cores at run-time through coordinated power management framework that exploits Dynamic Voltage and Frequency Scaling (DVFS) as well as multiple idle states offered by modern CMP architectures, to reduce the dynamic power. We explicitly consider the unique traits of the currently available CMP architectures that distinguish them from multiprocessors, including the unique voltage level shared by the cores and its implications for DVFS. We identify the global energy-efficient frequency which indicates the minimum frequency level at which concurrent execution on multiple cores should take place to preserve the efficiency of DVFS. Then we propose two algorithms CVFS and CVFS* to minimize the dynamic energy consumption through concerted use of DVFS and idle states. Our experimental evaluation indicates that our framework can provide significant gains in system energy.","Time frequency analysis,
Power demand,
Multicore processing,
Energy consumption,
Sleep,
Real time systems,
Resource management"
Product Sequencing With Respect to Quality in Flexible Manufacturing Systems With Batch Operations,"In many flexible manufacturing systems, batch production is often adopted to improve product quality. For example, in automotive paint shops, vehicles with same colors are typically grouped into small batches to reduce quality degradation and purge cost due to color change. In this paper, we present an analytical method to evaluate the quality performance of flexible manufacturing systems with batch operations. In addition, we investigate the impact of product sequencing and batch policies on product quality and present some insights to achieve better quality using these policies.",
Adaptive power loading for OFDM-based power line communications impaired by impulsive noise,"Adaptive modulation can improve the performance of OFDM systems significantly. In Power Line Communication systems, impulsive noise has to be considered due to its severe effect in the system performance. This paper deals with the effect of impulsive noise in adaptive power loading in OFDM-based PLC systems. We present a simple power loading algorithm with uniform bit allocation and nonuniform BER distribution and test it by means of computer simulations in a widely-accepted power line channel model impaired with impulsive noise. Closed form expressions for BER and power allocation in the presence of impulsive noise are presented. Simulation results show that the proposed algorithm can achieve a considerable improvement over conventional OFDM with uniform power allocation.","Power line communications,
Bit error rate,
OFDM modulation,
System performance,
Programmable control,
Bit rate,
Testing,
Computer simulation,
Power system modeling,
Computational modeling"
Near-Capacity Cooperative Space-Time Coding Employing Irregular Design and Successive Relaying,"In this paper, we develop a capacity-approaching Cooperative Space-Time Coding CSTC scheme employing irregular design for a twin-relay aided network as an extension of our previous work cast in the context of a half-duplex single-relay-aided network. For the sake of recovering the multiplexing loss imposed by a half-duplex three-terminal network, we employ a successive relaying protocol in this paper, where an additional relay node is activated. Hence, in order to design a near-capacity coding system, first the capacity and the achievable information-rate of a specific space-time coding aided scheme are quantified for the successive relaying aided channel. More specifically, the cooperative space-time codes employed at the source and the relays are jointly designed with the aid of EXtrinsic Information Transfer EXIT charts for the sake of high-integrity operation at Signal-to-Noise Ratios SNRs close to the corresponding successive relaying channel's capacity. Furthermore, unlike in the half-duplex single-relay based system, the destination node performs frame-by-frame Successive Interference Cancellation SIC aided iterative detection, in order to mitigate the efforts of multiple-access interference. Finally, our numerical results demonstrate that our proposed Irregular Cooperative Space-Time Coding Ir-CSTC scheme is capable of near-capacity operation in the successive relaying aided network, which is an explicit benefit of our joint source-and-relay transceiver design.",
Channel reordering and prefetching schemes for efficient IPTV channel navigation,"As Internet Protocol Television (IPTV) has become one of the major Internet applications, IPTV users increase rapidly and hundreds of channels emerge to satisfy users' demands. However, the increased number of channels makes users difficult to find their desired channels. Along with this problem, the channel zapping time of IPTV incurs serious user-perceived delay. To alleviate these problems, this paper presents hybrid schemes that combine channel prefetching and reordering schemes. Specifically, adjacency and popularity based prefetching schemes are combined with popular channel reordering schemes and their performances are simulated under various conditions. Experimental results show that the proposed schemes reduce the channel seek time by up to 44.7% when up-down channel selection interfaces are used.","Prefetching,
IPTV,
Navigation,
TV,
Internet,
Delay effects,
IP networks,
Modems,
Satellite broadcasting,
DSL"
Polynomial Learning of Distribution Families,"The question of polynomial learn ability of probability distributions, particularly Gaussian mixture distributions, has recently received significant attention in theoretical computer science and machine learning. However, despite major progress, the general question of polynomial learn ability of Gaussian mixture distributions still remained open. The current work resolves the question of polynomial learn ability for Gaussian mixtures in high dimension with an arbitrary fixed number of components. Specifically, we show that parameters of a Gaussian mixture distribution with fixed number of components can be learned using a sample whose size is polynomial in dimension and all other parameters. The result on learning Gaussian mixtures relies on an analysis of distributions belonging to what we call “polynomial families” in low dimension. These families are characterized by their moments being polynomial in parameters and include almost all common probability distributions as well as their mixtures and products. Using tools from real algebraic geometry, we show that parameters of any distribution belonging to such a family can be learned in polynomial time and using a polynomial number of sample points. The result on learning polynomial families is quite general and is of independent interest. To estimate parameters of a Gaussian mixture distribution in high dimensions, we provide a deterministic algorithm for dimensionality reduction. This allows us to reduce learning a high-dimensional mixture to a polynomial number of parameter estimations in low dimension. Combining this reduction with the results on polynomial families yields our result on learning arbitrary Gaussian mixtures in high dimensions.",
Unsupervised Object Segmentation with a Hybrid Graph Model (HGM),"In this work, we address the problem of performing class-specific unsupervised object segmentation, i.e., automatic segmentation without annotated training images. Object segmentation can be regarded as a special data clustering problem where both class-specific information and local texture/color similarities have to be considered. To this end, we propose a hybrid graph model (HGM) that can make effective use of both symmetric and asymmetric relationship among samples. The vertices of a hybrid graph represent the samples and are connected by directed edges and/or undirected ones, which represent the asymmetric and/or symmetric relationship between them, respectively. When applied to object segmentation, vertices are superpixels, the asymmetric relationship is the conditional dependence of occurrence, and the symmetric relationship is the color/texture similarity. By combining the Markov chain formed by the directed subgraph and the minimal cut of the undirected subgraph, the object boundaries can be determined for each image. Using the HGM, we can conveniently achieve simultaneous segmentation and recognition by integrating both top-down and bottom-up information into a unified process. Experiments on 42 object classes (9,415 images in total) show promising results.","Object segmentation,
Image segmentation,
Shape,
Computer vision,
Humans,
Object recognition,
Computer science"
Visual-Context Boosting for Eye Detection,"Eye detection plays an important role in many practical applications. This paper presents a novel two-step scheme for eye detection. The first step models an eye by a newly defined visual-context pattern (VCP), and the second step applies semisupervised boosting for precise detection. VCP describes both the space and appearance relations between an eye region (region of eye) and a reference region (region of reference). The context feature of a VCP is extracted by using the integral image. Aiming to reduce the human labeling efforts, we apply semisupervised boosting, which integrates the context feature and the Haar-like features for precise eye detection. Experimental results on several standard face data sets demonstrate that the proposed approach is effective, robust, and efficient. We finally show that this approach is ready for practical applications.","Boosting,
Face detection,
Computer vision,
Sun,
Humans,
Robustness,
Application software,
Object detection,
Eyes,
Research and development"
Enhanced Visual Analysis for Cluster Tendency Assessment and Data Partitioning,"Visual methods have been widely studied and used in data cluster analysis. Given a pairwise dissimilarity matrix D of a set of n objects, visual methods such as the VAT algorithm generally represent D as an n × n image I(D̃) where the objects are reordered to reveal hidden cluster structure as dark blocks along the diagonal of the image. A major limitation of such methods is their inability to highlight cluster structure when D contains highly complex clusters. This paper addresses this limitation by proposing a Spectral VAT algorithm, where D is mapped to D' in a graph embedding space and then reordered to D̃' using the VAT algorithm. A strategy for automatic determination of the number of clusters in I(D̃') is then proposed, as well as a visual method for cluster formation from I(D̃') based on the difference between diagonal blocks and off-diagonal blocks. A sampling-based extended scheme is also proposed to enable visual cluster analysis for large data sets. Extensive experimental results on several synthetic and real-world data sets validate our algorithms.","Clustering algorithms,
Data analysis,
Partitioning algorithms,
Computer science,
Data mining,
Taxonomy,
Marine animals,
Software measurement,
Software engineering,
Data structures"
Performance evaluation of a multi-branch tree algorithm in RFID,"Reading efficiency is one of the key factors to evaluate Radio Frequency Identification (RFID) systems. For the system using multi-branch protocols, the performance would be better if the tags are properly divided into multiple groups. This paper firstly gives the closed-form of system efficiency for binary tree algorithm. Based on the theoretical analysis, the optimal branches number is derived. An efficient multi-branch tree (EMBT) algorithm is proposed subsequently, along with a tag number estimation algorithm and performance evaluation. Both theoretical analysis and simulation results indicate that multi-branch tree algorithm has better performance than the conventional binary tree algorithm. System identification efficiency of the proposed method can achieve above 45%, while that of the binary tree algorithm is only 34.8%.",
Evaluating caching and storage options on the Amazon Web Services Cloud,"With the promise on-demand compute/storage resources, many users are deploying data-intensive scientific applications onto Clouds. To accelerate these applications, the prospect of caching intermediate data using the elastic compute and storage framework has proved promising. To this end, we believe that an in-depth study of cache placement decisions over various Cloud storage options would be highly beneficial to a large class of users. While tangential analyses have been proposed, ours in contrast focuses on cost-performance tradeoffs of maintaining a data cache with various parameters of any Cloud application. We have compared several Amazon Web Service (AWS Cloud) resources as possible cache placements and found that application dependent attributes like unit-data size, total cache size, and persistence, have far reaching implications on the cost of cache sustenance. Moreover, while instance-based caches expectedly yield higher cost, the performance that they afford may outweigh lower cost options.","Cloud computing,
Throughput,
Resource management,
Cache storage,
Bandwidth,
Computational modeling"
Investigation of Random Telegraph Noise in Gate-Induced Drain Leakage and Gate Edge Direct Tunneling Currents of High-k MOSFETs,"Random telegraph noise (RTN) in gate-induced drain leakage (GIDL) and gate edge direct tunneling (EDT) leakage currents under GIDL bias conditions were characterized in MOSFETs with a high-k gate dielectric for the first time. The RTNs were analyzed through systematic measurement and calculation. The results indicate that a high-current state in a GIDL current can be attributed to electron capture due to thermal emission. However, electron emission from a trap was mainly affected by gate bias. Both capture and emission times in the RTN of the EDT current had gate bias dependence. Moreover, multilevel RTN waveforms were detected in a device, and our analysis indicated that the multilevel RTN is the result of the combination of the RTNs of the GIDL and EDT currents. The analysis also indicated that two independent traps in the high- k gate dielectric can produce a four-level RTN in the GIDL current. This paper provides the fundamental physics required to understand such leakages in nanoscale MOSFETs and devices that utilize band-to-band tunneling.","Logic gates,
Electron traps,
Dielectrics,
Current measurement,
High K dielectric materials,
MOSFETs,
Noise"
Gesture recognition based on arm tracking for human-robot interaction,"In this paper we present a novel approach for hand gesture recognition. The proposed system utilizes upper body part tracking in a 9-dimensional configuration space and two Multi-Layer Perceptron/Radial Basis Function (MLP/RBF) neural network classifiers, one for each arm. Classification is achieved by buffering the trajectory of each arm and feeding it to the MLP Neural Network which is trained to recognize between five gesturing states. The RBF neural network is trained as a predictor for the future gesturing state of the system. By feeding the output of the RBF back to the MLP classifier, we achieve temporal consistency and robustness to the classification results. The proposed approach has been assessed using several video sequences and the results obtained are presented in this paper.","Hidden Markov models,
Artificial neural networks,
Gesture recognition,
Training,
Trajectory,
Robustness,
Humans"
Indoor scene recognition through object detection,"Scene recognition is a highly valuable perceptual ability for an indoor mobile robot, however, current approaches for scene recognition present a significant drop in performance for the case of indoor scenes. We believe that this can be explained by the high appearance variability of indoor environments. This stresses the need to include high-level semantic information in the recognition process. In this work we propose a new approach for indoor scene recognition based on a generative probabilistic hierarchical model that uses common objects as an intermediate semantic representation. Under this model, we use object classifiers to associate low-level visual features to objects, and at the same time, we use contextual relations to associate objects to scenes. As a further contribution, we improve the performance of current state-of-the-art category-level object classifiers by including geometrical information obtained from a 3D range sensor that facilitates the implementation of a focus of attention mechanism within a Monte Carlo sampling scheme. We test our approach using real data, showing significant advantages with respect to previous state-of-the-art methods.",
Student Behavior and Interaction Patterns With an LMS as Motivation Predictors in E-Learning Settings,Student motivation is an important factor for the successful completion of an e-learning course. Detecting motivational problems for particular students at an early stage of a course opens the door for instructors to be able to provide additional motivating activities for these students. This paper analyzes how the behavior patterns in the interaction of each particular student with the contents and services in a learning management system (LMS) can be used to predict student motivation and if this student motivation can be used to predict the successful completion of an e-learning course. The interactions of 180 students of six different universities taking a course in three consecutive years are analyzed.,"Electronic learning,
Indexes,
Correlation,
Least squares approximation,
Data mining,
Multimedia communication,
Analysis of variance"
Detection and classification of painted road objects for intersection assistance applications,"For a Driving Assistance System dedicated to intersection safety, knowledge about the structure and position of the intersection is essential, and detecting the painted road signs can greatly improve this knowledge. This paper describes a method for detection, measurement and classification of painted road objects that are typically found in European intersections. The features of the painted objects are first extracted using dark light dark transition detection on horizontal line regions, and then are refined using gray level segmentation based on Gaussian mixtures. The 3D bounding box of the objects is reconstructed using perspective geometry. The objects are classified based on a restricted set of features, using a decision tree and size constraints.","Roads,
Three dimensional displays,
Feature extraction,
Classification algorithms,
Histograms,
Pixel,
Image segmentation"
StakeSource: harnessing the power of crowdsourcing and social networks in stakeholder analysis,"Projects often fail because they overlook stakeholders. Unfortunately, existing stakeholder analysis tools only capture stakeholders' information, relying on experts to manually identify them. StakeSource is a web-based tool that automates stakeholder analysis. It ""crowdsources"" the stakeholders themselves for recommendations about other stakeholders and aggregates their answers using social network analysis.","Social network services,
Educational institutions,
Libraries,
Electronic mail,
Software,
User interfaces,
Computer science"
Fast Computation of Frequency Warping Transforms,"In this paper, we introduce an analytical approach for the frequency warping transform. Criteria for the design of operators based on arbitrary warping maps are provided and an algorithm carrying out a fast computation is defined. Such operators can be used to shape the tiling of time-frequency (TF) plane in a flexible way. Moreover, they are designed to be inverted by the application of their adjoint operator. According to the proposed model, the frequency warping transform is computed by considering two additive operators: the first one represents its nonuniform Fourier transform approximation and the second one suppresses aliasing. The first operator is fast computable by various interpolation approaches. A factorization of the second operator is found for arbitrary shaped nonsmooth warping maps. By properly truncating the operators involved in the factorization, the computation turns out to be fast without compromising accuracy.","Fourier transforms,
Time frequency analysis,
Algorithm design and analysis,
Signal processing algorithms,
Interpolation,
Signal processing,
Noise reduction,
Feature extraction,
Wavelet transforms,
Filter bank"
Evaluation of loss of load probability for power systems using intelligent search based state space pruning,One methodology that has been previously developed to improve the computational efficiency and convergence of Monte Carlo Simulation (MCS) when computing the reliability indices of power systems is a technique known as state space pruning. This technique works by pruning the state space in such a way that the MCS samples a state space that has a higher density of failure states than the original state space. This paper presents a new approach to limiting the state space sampled when calculating reliability indices by pruning the state space through the use of Population-based Intelligent Search (PIS). The preliminary results indicate that this technique is promising to improve the convergence performance of MCS when calculating reliability indices. This is tested using an IEEE Reliability Test System at different levels.,
Wireless sensor networks for monitoring the environmental activities,"The area of sensor network has a long history and many kind of sensor devices are used in various real life applications. Here, we introduce Wireless sensor network which when combine with other areas then plays an important role in analyzing the data of forest temperature, bioinformatics, water contamination, traffic control, telecommunication etc. Due to the advancement in the area of wireless sensor network and their ability to generate large amount of spatial/temporal data, always attract researchers for applying data mining techniques and getting interesting results. Wireless sensor networks in monitoring the environmental activities grows and this attract greater interest and challenge for finding out the patterns from large amount of spatial/temporal datasets. These datasets are generated by sensor nodes which are deployed in some tropical regions or from some wearable sensor nodes which are attached with wild animals in wild life centuries. Sensor networks generate continuous stream of data over time. So, Data mining techniques always plays a vital role for extracting the knowledge form large wireless sensor network data. In this paper, we present the detection of sensor data irregularities, Sensor data clustering, Pattern matching and their interesting results and with these results we can analyze the sensor node data in different ways.","Data mining,
Wireless sensor networks,
Temperature measurement,
Temperature distribution,
Monitoring,
Temperature sensors,
Pattern matching"
Congestion control and fairness in wireless sensor networks,"In this paper we propose a distributed congestion control algorithm for tree based communications in wireless sensor networks, that seeks to adaptively assign a fair and efficient transmission rate to each node. In our algorithm, each node monitors its aggregate output and input traffic rates. Based on the difference of the two, a node then decides either to increase or decrease the bandwidth allocable to a flow originating from itself and to those being routed through it. Since the application requirements in sensor network follows no common trait, our design abstracts the notion of fairness, allowing for the development of a generic utility controlling module. Such separation of the utility and fairness controlling modules enables each one to use a separate control law, thereby portraying a more flexible design. The working of our congestion control is independent of the underlying routing algorithm and is designed to adapt to changes in the underlying routing topology. We evaluate the performance of the algorithm via extensive simulations using an event-driven packet level simulator. The results suggest that the proposed protocol acquires a significantly high goodput of around 95% of the actual transmission rate, converges quickly to the optimal rate, and attains the desired fairness.","Wireless sensor networks,
Communication system control,
Routing,
Discrete event simulation,
Distributed control,
Aggregates,
Communication system traffic control,
Bandwidth,
Abstracts,
Algorithm design and analysis"
Equilibrium of Heterogeneous Congestion Control: Optimality and Stability,"When heterogeneous congestion control protocols that react to different pricing signals share the same network, the current theory based on utility maximization fails to predict the network behavior. The pricing signals can be different types of signals such as packet loss, queueing delay, etc, or different values of the same type of signal such as different ECN marking values based on the same actual link congestion level. Unlike in a homogeneous network, the bandwidth allocation now depends on router parameters and flow arrival patterns. It can be non-unique, suboptimal and unstable. In Tang et al. (“Equilibrium of heterogeneous congestion control: Existence and uniqueness,” IEEE/ACM Trans. Netw., vol. 15, no. 4, pp. 824-837, Aug. 2007), existence and uniqueness of equilibrium of heterogeneous protocols are investigated. This paper extends the study with two objectives: analyzing the optimality and stability of such networks and designing control schemes to improve those properties. First, we demonstrate the intricate behavior of a heterogeneous network through simulations and present a framework to help understand its equilibrium properties. Second, we propose a simple source-based algorithm to decouple bandwidth allocation from router parameters and flow arrival patterns by only updating a linear parameter in the sources' algorithms on a slow timescale. It steers a network to the unique optimal equilibrium. The scheme can be deployed incrementally as the existing protocol needs no change and only new protocols need to adopt the slow timescale adaptation.","Optimal control,
Protocols,
Delay,
Proposals,
Pricing,
Channel allocation,
Feedback,
Stability analysis,
Explosives,
Internet"
On counteracting Byzantine attacks in network coded peer-to-peer networks,"Random linear network coding can be used in peer-to- peer networks to increase the efficiency of content distribution and distributed storage. However, these systems are particularly susceptible to Byzantine attacks. We quantify the impact of Byzantine attacks on the coded system by evaluating the probability that a receiver node fails to correctly recover a file. We show that even for a small probability of attack, the system fails with overwhelming probability. We then propose a novel signature scheme that allows packet-level Byzantine detection. This scheme allows one-hop containment of the contamination, and saves bandwidth by allowing nodes to detect and drop the contaminated packets. We compare the net cost of our signature scheme with various other Byzantine schemes, and show that when the probability of Byzantine attacks is high, our scheme is the most bandwidth efficient.","Peer to peer computing,
Network coding,
Bandwidth,
Laboratories,
Telecommunications,
Contamination,
Costs,
Secure storage,
Throughput,
Robustness"
An A*-Based Algorithm for Constructing Reversible Variable Length Codes with Minimum Average Codeword Length,"Variable length codes (VLCs) are widely adopted in many compression standards due to their good coding efficiency on average codeword length. However, an inherent problem with a VLC is that an error of even one bit can cause serious error propagation and thus loss of synchronization at the receiver, which would lead to a series of non-correctly decoded symbols. Reversible variable length codes (RVLCs) were introduced to significantly mitigate this phenomenon. In this work, a method to find an optimal RVLC in terms of the minimum average codeword length is first formulated as a tree-searching problem, and then, instead of performing an exhaustive search, an A*-based construction algorithm is proposed to find an optimal RVLC. The proposed algorithm has been applied to several benchmarks for sources and has found respective optimal symmetric and asymmetric RVLCs.","Encoding,
Binary trees,
Construction industry,
Search problems,
Upper bound,
Transform coding,
Standards"
Code Design for Radar STAP via Optimization Theory,"In this paper, we deal with the problem of constrained code optimization for radar space-time adaptive processing (STAP) in the presence of colored Gaussian disturbance. At the design stage, we devise a code design algorithm complying with the following optimality criterion: maximization of the detection performance under a control on the regions of achievable values for the temporal and spatial Doppler estimation accuracy, and on the degree of similarity with a pre-fixed radar code. The resulting quadratic optimization problem is solved resorting to a convex relaxation that belongs to the semidefinite program (SDP) class. An optimal solution of the initial problem is then constructed through a suitable rank-one decomposition of an optimal solution of the relaxed one. At the analysis stage, we assess the performance of the new algorithm both on simulated data and on the standard challenging the Knowledge-Aided Sensor Signal Processing and Expert Reasoning (KASSPER) datacube.","Radar theory,
Design optimization,
Algorithm design and analysis,
Signal processing algorithms,
Doppler radar,
Constraint optimization,
Spaceborne radar,
Radar detection,
Optimal control,
Signal analysis"
Iterative Estimation of Sinusoidal Signal Parameters,"While the problem of estimating the amplitudes of sinusoidal components in signals, given an estimation of their frequencies, is linear and tractable, it is biased due to the unavoidable, in practice, errors in the estimation of frequencies. These errors are of great concern for processing signals with many sinusoidal like components as is the case of speech and audio. In this letter, we suggest using a time-varying sinusoidal representation which is able to iteratively correct frequency estimation errors. Then the corresponding amplitudes are computed through Least Squares. Experiments conducted on synthetic and speech signals show the suggested model's effectiveness in correcting frequency estimation errors and robustness in additive noise conditions.","Frequency estimation,
Amplitude estimation,
Error correction,
Estimation error,
Signal processing,
Speech processing,
Least squares methods,
Speech enhancement,
Noise robustness,
Additive noise"
Design of bandwidth-efficient unequal error protection LDPC codes,"This paper presents a strategy for the design of bandwidth-efficient LDPC codes with unequal error protection. Bandwidth efficiency is obtained by appropriately designing the codes for higher order constellations, assuming an AWGN channel. The irregularities of the LDPC code are designed, using the Gaussian approximation of the density evolution, to enhance the unequal error protection property of the code as well as account for the different bit error probabilities given by the higher order constellation. The proposed code design algorithm is flexible in terms of the number and proportions of protection classes. It also allows arbitrary modulation schemes. Our method combines the design of unequal error protection LDPC codes for the binary input AWGN channel with the code design for higher order constellations by dividing the variable node degree distribution into sub-degree distributions for each protection class and each level of protection from the modulation. The results show that appropriate code design for higher order constellations reduces the overall bit-error rate significantly. Furthermore, the unequal error protection capability of the code is increased, especially for high SNR.","Error correction codes,
Parity check codes,
AWGN channels,
Bandwidth,
Gaussian approximation,
Error probability,
Algorithm design and analysis,
Protection,
Design methodology,
Modulation coding"
No fair!! An interaction with a cheating robot,"Using a humanoid robot and a simple children's game, we examine the degree to which variations in behavior result in attributions of mental state and intentionality. Participants play the well-known children's game “rock-paper-scissors” against a robot that either plays fairly, or that cheats in one of two ways. In the “verbal cheat” condition, the robot announces the wrong outcome on several rounds which it loses, declaring itself the winner. In the “action cheat” condition, the robot changes its gesture after seeing its opponent's play. We find that participants display a greater level of social engagement and make greater attributions of mental state when playing against the robot in the conditions in which it cheats.",
An Energy Aware Routing Protocol with Sleep Scheduling for Wireless Sensor Networks,"Wireless Sensor Networks (WSNs) consist of a large number of small and low cost sensor nodes powered by small batteries and equipped with various sensing devices. Usually, for many applications, once a WSN is deployed, probably in an inhospitable terrain, it is expected to gather the required data for quite some time, say for years. Since each sensor node has limited energy, these nodes are usually put to sleep to conserve energy, and this helps to prolong the network lifetime. There are two major approaches to sleep scheduling of sensor nodes, viz. (i) random (ii) synchronized. Any sleep scheduling scheme has to ensure that data can always be routed from source to sink. In this paper, we propose a novel approach for sleep scheduling of sensor nodes using a tree and an energy aware routing protocol which is integrated with the proposed sleep scheduling scheme. The tree is rooted at the sink node. The internal nodes of the tree remain awake and the leaf nodes are made to sleep. This provides an assured path from any node to the sink node. The tree is periodically reconstructed considering the remaining energy of each node with a view to balance energy consumption of nodes, and remove any failed nodes from the tree. The proposed approach also considerably reduces average energy consumption rate of each node as we are able to put more number of nodes to sleep in comparison to other approaches. Additional fault-tolerance is provided by keeping two paths from each node towards the sink. Extensive simulation studies of the proposed routing protocol has been carried out using Castalia simulator, and its performance has been compared with that of a routing protocol, called GSP, which incorporates sleep scheduling using random approach. The simulation results show that the proposed approach has longer network lifetime in comparison to that provided by GSP, and the energy consumption of nodes is also balanced.","Routing protocols,
Sleep,
Wireless sensor networks,
Processor scheduling,
Energy consumption,
Transceivers,
Application software,
Batteries,
Fault tolerance,
Computer science"
Scientific Foundations: A Case for Technology- Mediated Social- Participation Theory,"Technology-mediated social-participation systems, such as Wikipedia and TopCoder, allow a vast user base to collaborate to solve difficult problems. TMSP could be applied to many current social issues, but doing so requires new theory and infrastructure for social design.","Communities,
Psychology,
Humans,
Economics,
Biological system modeling,
Computational modeling,
Organizations"
Spectral Feature Probabilistic Coding for Hyperspectral Signatures,"Spectral signature coding (SSC) is generally performed by encoding spectral values of a signature across its spectral coverage followed by the Hamming distance to measure signature similarity. The effectiveness of such an SSC largely relies on how well the Hamming distance can capture spectral variations that characterize a signature. Unfortunately, in most cases, this Hamming-distance-based SSC does not provide sufficient discriminatory information for signature analysis because the Hamming distance does not take into account the band-to-band variation, in which case the Hamming distance can be considered as a memoryless distance. This paper extends the Hamming-distance-based SSC to an approach, referred to as spectral feature probabilistic coding (SFPC), which introduces a new concept into SSC that uses a criterion with memory to measure spectral similarity. It implements the well-known arithmetic coding (AC) in two ways to encode a signature in a probabilistic manner, called circular SFPC and split SFPC. The values resulting from the AC is then used to measure the distance between two spectral signatures. In order to demonstrate advantages of using AC-based SSC in signature analysis, a comparative analysis is also conducted against spectral binary coding.",
Automatic Face Annotation in Personal Photo Collections Using Context-Based Unsupervised Clustering and Face Information Fusion,"In this paper, a novel face annotation framework is proposed that systematically leverages context information such as situation awareness information with current face recognition (FR) solutions. In particular, unsupervised situation and subject clustering techniques have been developed that are aided by context information. Situation clustering groups together photos that are similar in terms of capture time and visual content, allowing for the reliable use of visual context information during subject clustering. The aim of subject clustering is to merge multiple face images that belong to the same individual. To take advantage of the availability of multiple face images for a particular individual, we propose effective FR methods that are based on face information fusion strategies. The performance of the proposed annotation method has been evaluated using a variety of photo sets. The photo sets were constructed using 1385 photos from the MPEG-7 Visual Core Experiment 3 (VCE-3) data set and approximately 20000 photos collected from well-known photo-sharing websites. The reported experimental results show that the proposed face annotation method significantly outperforms traditional face annotation solutions at no additional computational cost, with accuracy gains of up to 25% for particular cases.",
Application-specific resource provisioning for wide-area distributed computing,"Some modern distributed applications require cooperation among multiple geographically separated computing facilities to perform intensive computing at the end sites and large-scale data transfers in the wide area network. It has been widely recognized that WDM networks are cost-effective means to support data transfers in this type of data-intensive applications. However, neither the traditional approaches to establishing lightpaths between given source destination pairs nor the existing application-level approaches that only consider computing resources but take the underlying connectivity for granted are sufficient. In this article we identify key limitations and issues in existing systems, and focus on joint resource allocation of both computing resources and network resources in federated computing and network systems. A variety of resource allocation schemes that provide modern distributed computing applications with performance and reliability guarantees are presented.","Distributed computing,
Computer networks,
Resource management,
Processor scheduling,
Laboratories,
WDM networks,
Network topology,
Telecommunication network reliability,
Optical fiber networks,
Cloud computing"
"Subcubic Equivalences between Path, Matrix and Triangle Problems","We say an algorithm on n by n matrices with entries in [-M, M] (or n-node graphs with edge weights from [-M, M]) is truly sub cubic if it runs in O(n^{3-\delta} \poly(\log M)) time for some \delta > 0. We define a notion of sub cubic reducibility, and show that many important problems on graphs and matrices solvable in O(n^3) time are equivalent under sub cubic reductions. Namely, the following weighted problems either all have truly sub cubic algorithms, or none of them do: - The all-pairs shortest paths problem (APSP). - Detecting if a weighted graph has a triangle of negative total edge weight. - Listing up to n^{2.99} negative triangles in an edge-weighted graph. - Finding a minimum weight cycle in a graph of non-negative edge weights. - The replacement paths problem in an edge-weighted digraph. - Finding the second shortest simple path between two nodes in an edge-weighted digraph. - Checking whether a given matrix defines a metric. - Verifying the correctness of a matrix product over the (\min, +)-semiring. Therefore, if APSP cannot be solved in n^{3-\eps} time for any \eps > 0, then many other problems also need essentially cubic time. In fact we show generic equivalences between matrix products over a large class of algebraic structures used in optimization, verifying a matrix product over the same structure, and corresponding triangle detection problems over the structure. These equivalences simplify prior work on sub cubic algorithms for all-pairs path problems, since it now suffices to give appropriate sub cubic triangle detection algorithms. Other consequences of our work are new combinatorial approaches to Boolean matrix multiplication over the (OR, AND)-semiring (abbreviated as BMM). We show that practical advances in triangle detection would imply practical BMM algorithms, among other results. Building on our techniques, we give two new BMM algorithms: a derandomization of the recent combinatorial BMM algorithm of Bansal and Williams (FOCS'09), and an improved quantum algorithm for BMM.",
On the security of an enhanced novel access control protocol for wireless sensor networks,"New node deployment is inevitable in a wireless sensor network because nodes in the network may be lost, exhausted, or destroyed. To secure the new node deployment process, Kim and Lee (2009) proposed an enhanced novel access control protocol (ENACP) using the elliptic curve cryptography and the hash chain. We identified an inherent flaw in their design and demonstrated that ENACP is vulnerable to a new node masquerading attack and a legal node masquerading attack, in violation of their security claims. We hope that by identifying this design flaw, similar structural mistakes can be avoided in future designs.","Access control,
Wireless application protocol,
Access protocols,
Wireless sensor networks,
Cryptographic protocols,
Authentication,
Elliptic curve cryptography,
Base stations,
Sun,
Law"
Receiver Multiuser Diversity Aided Multi-Stage Minimum Mean-Square Error Detection for Heavily Loaded DS-CDMA and SDMA Systems,"By investigating the conditions required for successive interference cancellation multiuser detectors (SIC-MUD) to achieve near-optimum BER performance, we propose and investigate a so-called receiver multiuser diversity aided multi-stage minimum mean-square error MUD (RMD/MS-MMSE MUD), which is operated in the SIC principles. The BER performance of the RMD/MS-MMSE MUD is investigated in association with both the direct-sequence code-division multiple-access (DS-CDMA) over either Gaussian or Rayleigh fading channels, and the space-division multiple-access (SDMA) over Rayleigh fading channels. Furthermore, we consider both full-load and overload scenarios in comparison with the spreading factor N of DS-CDMA and the number of receive antennas N in SDMA. Our studies show that the RMD/MS-MMSE MUD is highly efficient for both full-load and overload systems. Specifically, the RMD/MS-MMSE MUD for the full-load systems of moderate size is capable of attaining the BER performance similar to that of the optimum maximum likelihood MUD (ML-MUD). For the overload systems, it can allow a DS-CDMA or SDMA system to support K=2N users and still achieve much better BER performance than a corresponding DS-CDMA or SDMA system using conventional MMSE-MUD to support K=N users.","Multiaccess communication,
Multiuser detection,
Reliability,
Bit error rate,
Fading,
Signal to noise ratio,
Receivers"
Prototype design and realization of an innovative energy efficient transfemoral prosthesis,"In this paper, we present the prototype realization of the conceptual design of a fully-passive transfemoral prosthesis. The working principle has been inspired by the power flow in human gait so to achieve an energy efficient device. The main goal of this paper is to validate the concept by implementing in a real prototype. The prototype, in scale 1 ∶ 2 with respect to the average dimensions of an adult human, is based on two storage elements, which are responsible for the energetic coupling between the knee and ankle joints during the swing phase and for the energy storage during the stance phase. The design parameters of the prototype are determined according to the human body and the energetic characteristics of the gait. The construction of the prototype is explained in details together with a test setup that has been built to evaluate the prototype.","Joints,
Prototypes,
Knee,
Springs,
Foot,
Humans,
Prosthetics"
Abrupt motion tracking via adaptive stochastic approximation Monte Carlo sampling,"Robust tracking of abrupt motion is a challenging task in computer vision due to the large motion uncertainty. In this paper, we propose a stochastic approximation Monte Carlo (SAMC) based tracking scheme for abrupt motion problem in Bayesian filtering framework. In our tracking scheme, the particle weight is dynamically estimated by learning the density of states in simulations, and thus the local-trap problem suffered by the conventional MCMC sampling-based methods could be essentially avoided. In addition, we design an adaptive SAMC sampling method to further speed up the sampling process for tracking of abrupt motion. It combines the SAMC sampling and a density grid based statistical predictive model, to give a data-mining mode embedded global sampling scheme. It is computationally efficient and effective in dealing with abrupt motion difficulties. We compare it with alternative tracking methods. Extensive experimental results showed the effectiveness and efficiency of the proposed algorithm in dealing with various types of abrupt motions.",
Intrusion-Resilience in Mobile Unattended WSNs,"Wireless Sensor Networks (WSNs) are susceptible to a wide range of attacks due to their distributed nature, limited sensor resources and lack of tamper-resistance. Once a sensor is corrupted, the adversary learns all secrets and (even if the sensor is later released) it is very difficult for the sensor to regain security, i.e., to obtain intrusion-resilience. Existing solutions rely on the presence of an on-line trusted third party, such as a sink, or on the availability of secure hardware on sensors. Neither assumption is realistic in large-scale Unattended WSNs (UWSNs), characterized by long periods of disconnected operation and periodic visits by the sink. In such settings, a mobile adversary can gradually corrupt the entire network during the intervals between sink visits. As shown in some recent work, intrusionresilience in UWSNs can be attained (to a degree) via cooperative self-healing techniques. In this paper, we focus on intrusion-resilience in Mobile Unattended Wireless Sensor Networks (μUWSNs) where sensors move according to some mobility model. We argue that sensor mobility motivates a specific type of adversary and defending against it requires new security techniques. Concretely, we propose a cooperative protocol that - by leveraging sensor mobility - allows compromised sensors to recover secure state after compromise. This is obtained with very low overhead and in a fully distributed fashion. We provide a thorough analysis of the proposed protocol and support it by extensive simulation results.","Wireless sensor networks,
Security,
Cryptographic protocols,
Sensor phenomena and characterization,
Hardware,
Tin,
Communications Society,
Mobile computing,
Computer science,
USA Councils"
Performance Evaluation of AODV and DYMO Routing Protocols in MANET,"Routing protocols for mobile ad hoc networks (MANETs) have been explored extensively in recent years. Among these routing protocols, ad hoc on-demand distance vector (AODV) and dynamic MANET on-demand (DYMO) routing protocols have been standardized by the IETF MANET WG and are the most popular reactive routing protocols for MANETs. Therefore, in this paper, we present the results of the comparison of two reactive routing protocols, namely AODV and DYMO, based on packet-level simulations using an ns-2 simulator. Simulations are run to estimate the total throughput, routing overhead, and average packet size of the routing control packets.","Routing protocols,
Mobile ad hoc networks,
Ad hoc networks,
Peer to peer computing,
Force feedback,
Communications Society,
Computer science,
Mobile communication,
Research and development,
Throughput"
Cloud Computing Architectures for the Underserved: Public Health Cyberinfrastructures through a Network of HealthATMs,"This paper examines the impact of cyberinfrastructure architecture on healthcare services. More specifically, this research details the architectural design for a personal health record system called ""HealthATM"" that utilizes and integrates services from Google's cloud computing environment. These services are integrated into an unobtrusive and easy to use ATM-style interface for health consumers and care providers to manage and track their health. The impact for such an application, particularly for the underserved, is an important step toward better health management across this population with the end-goal of better health outcomes in the future.","Cloud computing,
Computer architecture,
Public healthcare,
Medical services,
Financial management,
Information technology,
Information management,
Biomedical informatics,
Data systems,
Technology management"
Womersley Number-Based Estimates of Blood Flow Rate in Doppler Analysis: In Vivo Validation by Means of Phase-Contrast MRI,"A common clinical practice during single-point Doppler analysis is to measure the centerline maximum velocity and to recover the time-averaged flow rate by exploiting an assumption on the shape of velocity profile (a priori formula), either a parabolic or a flat one. In a previous study, we proposed a new formula valid for the peak instant linking the maximum velocity and the flow rate by including a well-established dimensionless fluid-dynamics parameter (the Womersley number), in order to account for the hemodynamics conditions (Womersley number-based formula). Several in silico tests confirmed the reliability of the new formula. Nevertheless, an in vivo confirmation is missing limiting the clinical applicability of the formula. An experimental in vivo protocol using cine phase-contrast MRI (2-D PCMRI) technique has been designed and applied to ten healthy young volunteers in three different arterial districts: the abdominal aorta, the common carotid artery, and the brachial artery. Each PCMRI dataset has been used twice: 1) to compute the value of the blood flow rate used as a gold standard and 2) to estimate the flow rate by measuring directly the maximum velocity and the diameter (i.e., emulating the intravascular Doppler data acquisition) and by applying to these data the a priori and the Womersley number-based formulae. All the in vivo results have confirmed that the Womersley number-based formula provides better estimates of the flow rate at the peak instant with respect to the a priori formula. More precisely, mean performances of the Womersley number-based formula are about three times better than the a priori results in the abdominal aorta, five times better in the common carotid artery, and two times better in the brachial artery.","Blood flow,
In vivo,
Fluid flow measurement,
Velocity measurement,
Shape measurement,
Abdomen,
Carotid arteries,
Brachytherapy,
Joining processes,
Hemodynamics"
Recent developments in sparse hyperspectral unmixing,"This paper explores the applicability of new sparse algorithms to perform spectral unmixing of hyperspectral images using available spectral libraries instead of resorting to well-known endmember extraction techniques widely available in the literature. Our main assumption is that it is unlikely to find pure pixels in real hyperspectral images due to available spatial resolution and mixing phenomena happening at different scales. The algorithms analyzed in our study rely on different principles, and their performance is quantitatively assessed using both simulated and real hyperspectral data sets. The experimental validation of sparse techniques conducted in this work indicates promising results of this new approach to attack the spectral unmixing problem in remotely sensed hyperspectral images.","Hyperspectral imaging,
Libraries,
Pixel,
Signal to noise ratio,
Materials"
Orchestrator: An active resource orchestration framework for mobile context monitoring in sensor-rich mobile environments,"In this paper, we present Orchestrator, an active resource orchestration framework for mobile context monitoring. Emerging pervasive environments will introduce a PAN-scale sensor-rich mobile platform consisting of a mobile device and many wearable and space-embedded sensors. In such environments, it is challenging to enable multiple context-aware applications requiring continuous context monitoring to simultaneously run and share highly scarce and dynamic resources. Orchestrator enables multiple applications to effectively share the resources while exploiting the full capacity of overall system resources and providing high-quality service to users. For effective orchestration, we propose an active resource use orchestration approach that actively finds appropriate resource uses for applications and flexibly utilizes them depending on dynamic system conditions. Orchestrator is built upon a prototype platform that consists of off-the-shelf mobile devices and sensor motes. We present the detailed design, implementation, and evaluation of Orchestrator. The evaluation results show that Orchestrator enables applications in a resource-efficient way.","Wearable sensors,
Availability,
Mobile computing,
Context awareness,
Intelligent sensors,
Computerized monitoring,
Biomedical monitoring,
Watches,
Computer science,
Prototypes"
Dual-Band Bandpass Filter Using Parallel Short-Ended Feed Scheme,"In this letter, a compact dual-band (DB) bandpass filter based on parallel short-ended feed scheme is presented. Two sets of quarter-wavelength resonators operating at diverse frequencies are adopted to generate DB responses. A special feed scheme is proposed, which consists of two parallel short-ended strip branches. Each of them acts as a feed line of the respective resonator at one passband and a loading element at the other one. This scheme provides two independent transmission paths for RF signals. It is convenient to control the center frequencies of one passband, while the other's remains unchanged. Source-load coupling is also employed to create four transmission zeros close to the passband edges, resulting in high skirt-selectivity. To verify the proposed idea, a topology is demonstrated. The measured results exhibit good agreement with the full-wave simulation results.","Dual band,
Band pass filters,
Feeds,
Passband,
Resonator filters,
Couplings,
Strips,
Filtering theory,
Resonant frequency,
Circuits"
Modeling Spatial Structure of Wireless Communication Networks,"While modeling and analysis of network topology has been an active area of research in fixed networks, much less work has been done towards realistic modeling of wireless networks. The graph- based approach that has served as solid foundation for network science in the fixed domain is not natural for wireless communication networks, since their performance inherently depends on the spatial relationships between nodes. In this paper we apply techniques from spatial statistics literature to develop models of the spatial structure of the network for a variety of wireless network types. In particular, we construct models of television and radio transmitter distributions that have applications in, for example, cognitive wireless network applications. We use a stochastic approach based on fitting parametric location models to empirical data. Our results indicate that the so-called Geyer saturation model can accurately reproduce the spatial structure of a large variety of wireless network types, arising from both planned or chaotic deployments. The resulting models can be used in simulations or as basis of analytical calculations of different network properties, and we believe that the presented methodology can serve as a solid foundation for the emerging network science of wireless communication networks.",
Investigating the impact of NBTI on different power saving cache strategies,The occupancy of caches has tended to be dominated by the logic bit value ‘0’ approximately 75% of the time. Periodic bit flipping can reduce this to 50%. Combining cache power saving strategies with bit flipping can lower the effective logic bit value ‘0’ occupancy ratios even further. We investigate how Negative Bias Temperature Instability (NBTI) affects different power saving cache strategies employing symmetric and asymmetric 6- transistor (6T) and 8T Static Random Access Memory (SRAM) cells. We notice that greater than 38% to 66% of the recovery in stability parameters (SNM and WNM) under different power saving cache strategies have been achieved for different SRAM cells based caches. We also study the process variations effect along with NBTI for 32nm and 45nm technology node. It is observed that the rate of recovery in asymmetric SRAM cells based caches is slightly higher than the symmetric and 8T SRAM cells based caches.,
Group Level Activity Recognition in Crowded Environments across Multiple Cameras,"Environments such as schools, public parks and prisonsand others that contain a large number of people are typi-cally characterized by frequent and complex social interac-tions. In order to identify activities and behaviors in suchenvironments, it is necessary to understand the interactionsthat take place at a group level. To this end, this paper ad-dresses the problem of detecting and predicting suspiciousand in particular aggressive behaviors between groups ofindividuals such as gangs in prison yards. The work buildson a mature multi-camera multi-target person tracking sys-tem that operates in real-time and has the ability to han-dle crowded conditions. We consider two approaches forgrouping individuals: (i) agglomerative clustering favoredby the computer vision community, as well as (ii) decisiveclustering based on the concept of modularity, which is fa-vored by the social network analysis community. We showthe utility of such grouping analysis towards the detectionof group activities of interest. The presented algorithm isintegrated with a system operating in real-time to success-fully detect highly realistic aggressive behaviors enacted bycorrectional officers in a simulated prison environment. Wepresent results from these enactments that demonstrate theefficacy of our approach.","Cameras,
Target tracking,
Clustering algorithms,
Feature extraction,
Surveillance,
Real time systems"
Magnet Segmentation for Commutation Torque Ripple Reduction in a Brushless DC Motor Drive,"We present a new brushless DC motor (BDCM) design based on a model elaborated from a finite-element method associated to controller circuit equations represented in a Matlab-Simulink environment. The simulation model takes into account the commutation period effect and is based on the true system design implementation. The simulation results show that there is an effect between this commutation (a major source of torque ripple) and appropriate permanent-magnet segmentation design, particularly when the angle of advance between the back-electromotive force (EMF) and the current is adequately set. Current control strategies are found limited and may require complex implementation. Concentration on back-EMF and ultimately on permanent-magnet design are interesting aspects of torque ripple as well as rotor losses over wide speed range. After validation of the simulation model using an experimental kit set for the purpose, we perform an optimization procedure based on an indirect coupled field circuit approach that has led to an optimal design for which the torque ripple is minimal (less than 6%). An analytical design provided support for the study. The new design shows a lower cogging torque. Overall, the new design helps to provide a low-cost BDCM system for many applications using a simple square wave circuit controller.","Commutation,
Torque,
Brushless DC motors,
Mathematical model,
Circuit simulation,
Finite element methods,
Equations,
Computer languages,
Current control,
Design optimization"
Si Memristive devices applied to memory and neuromorphic circuits,"We report studies on nanoscale Si-based memristive devices for memory and neuromorphic applications. The devices are based on ion motion inside an insulating a-Si matrix. Digital devices show excellent performance metrics including scalability, speed, ON/OFF ratio, endurance and retention. High density non-volatile memory arrays based on a crossbar structure have been fabricated and tested. Devices inside a 1kb array can be individually addressed with excellent reproducibility and reliability. By adjusting the device and material structures, nanoscale analog memristor devices have also been demonstrated. The analog memristor devices exhibit incremental conductance changes that are controlled by the charge flown through the device. The performances of the digital and analog devices are thought to be determined by the formation of a dominant conducting filament and the continuous motion of a uniform conduction front, respectively.","Neuromorphics,
Circuits,
Nanoscale devices,
Memristors,
Insulation,
Measurement,
Scalability,
Nonvolatile memory,
Testing,
Reproducibility of results"
3-D in vitro estimation of temperature using the change in backscattered ultrasonic energy,"Temperature imaging with a non-invasive modality to monitor the heating of tumors during hyperthermia treatment is an attractive alternative to sparse invasive measurement. Previously, we predicted monotonic changes in backscattered energy (CBE) of ultrasound with temperature for certain sub-wavelength scatterers. We also measured CBE values similar to our predictions in bovine liver, turkey breast muscle, and pork rib muscle in 2-D in vitro studies and in nude mice during 2-D in vivo studies. To extend these studies to three dimensions, we compensated for motion and measured CBE in turkey breast muscle. 3-D data sets were assembled from images formed by a phased-array imager with a 7.5-MHz linear probe moved in 0.6-mm steps in elevation during uniform heating from 37 to 45°C in 0.5°C increments. We used cross-correlation as a similarity measure in RF signals to automatically track feature displacement as a function of temperature. Feature displacement was non-rigid. Envelopes of image regions, compensated for non-rigid motion, were found with the Hilbert transform then smoothed with a 3 × 3 running average filter before forming the backscattered energy at each pixel. CBE in 3-D motion-compensated images was nearly linear with an average sensitivity of 0.30 dB/°C. 3-D estimation of temperature in separate tissue regions had errors with a maximum standard deviation of about 0.5°C over 1-cm3 volumes. Success of CBE temperature estimation based on 3-D non-rigid tracking and compensation for real and apparent motion of image features could serve as the foundation for the eventual generation of 3-D temperature maps in soft tissue in a non-invasive, convenient, and low-cost way in clinical hyperthermia.","In vitro,
Muscles,
Temperature sensors,
Ultrasonic imaging,
Hyperthermia,
Ultrasonic variables measurement,
Breast,
Motion estimation,
Monitoring,
Heat treatment"
Packet Scheduling and Fairness for Multiuser MIMO Systems,"This paper investigates the network resource allocation in multiuser downlink wireless systems where the base station and the mobile stations are equipped with multiple antennas to provide fair and efficient transmission services to the mobile users. We focus on packet scheduling, given that it has a significant impact on the overall performance of a multiple-input-multiple-output (MIMO) system. Most previous schedulers designed at the packet level do not take into account the traffic characteristics (different packet lengths and the arrival process parameters); consequently, they fall short of simultaneously providing fairness and a low average packet transmission delay. We are making use of a flexible packet transmission algorithm at the medium access control (MAC) layer to develop and propose a novel scheduler, which is referred to as MIMO packet-based proportional fairness (MP-PF). The new scheduler is designed with the goal of providing high performance in terms of a low average packet transmission delay and time and service fairness among the users based on the concept of proportional fairness. The scheduler also conserves work and takes into consideration the packet length, the user queue length, the user transmission rate (related to its channel quality), and the service guarantees for heterogeneous users. The well-known ideal service fair scheduler called max-min can also significantly be improved using our framework by taking into consideration the traffic characteristics. We also provide an analysis for the fairness of the new scheduler in terms of time and service allocation, which is the key contribution of this paper. Simulations that consider the traffic characteristics and the mobility of users show the relatively low average packet transmission delay and demonstrate the time and service fairness capabilities of MP-PF, compared with other well-known MIMO schedulers.",
Infomax Control of Eye Movements,"Recently, infomax methods of optimal control have begun to reshape how we think about active information gathering. We show how such methods can be used to formulate the problem of choosing where to look. We show how an optimal eye movement controller can be learned from subjective experiences of information gathering, and we explore in simulation properties of the optimal controller. This controller outperforms other eye movement strategies proposed in the literature. The learned eye movement strategies are tailored to the specific visual system of the learner-we show that agents with different kinds of eyes should follow different eye movement strategies. Then we use these insights to build an autonomous computer program that follows this approach and learns to search for faces in images faster than current state-of-the-art techniques. The context of these results is search in static scenes, but the approach extends easily, and gives further efficiency gains, to dynamic tracking tasks. A limitation of infomax methods is that they require probabilistic models of uncertainty of the sensory system, the motor system, and the external world. In the final section of this paper, we propose future avenues of research by which autonomous physical agents may use developmental experience to subjectively characterize the uncertainties they face.",
A hibernating multi-swarm optimization algorithm for dynamic environments,"Many problems in the real world are dynamic in which the environment changes. However, the nature itself provides solutions for adaptation to these changes in order to gain the maximum benefit, i.e. finding the global optimum, at any moment. One of these solutions is hibernation of animals when food is scarce and an animal may use more energy in searching for food than it would receive from consuming the food. In this paper, we applied the idea of hibernation in a multi-swarm optimization algorithm, in which a parent swarm explores the search space and child swarms exploit promising areas found by the parent swarm. In the proposed model, whenever the search efforts of a child swarm for exploiting an area becomes unproductive, the child swarm hibernates. Similar to the nature, which the change of the season awakens hibernating animals, in the proposed model hibernating swarms are awakened upon the detection of a change in the environment. Experimental results on various dynamic environments modeled by the moving peaks benchmark show that the proposed algorithm outperforms other PSO algorithms, including similar particle swarm algorithms for dynamic environments like mQSO, adaptive mQSO, and FMSO.",
Personal learning environments in a global higher engineering education Web 2.0 realm,"This paper presents investigations on formal and informal requirements for personal learning environments taking into account students' personal and social learning practices. The potential of global Web 2.0 educational service bundles and informal learning communities, as well as their recommendation by educators are addressed. A scenario showing how these new paradigms can be integrated in engineering education as a way to bring together personal and social learning practices is drawn.",
Compact projection: Simple and efficient near neighbor search with practical memory requirements,"Image similarity search is a fundamental problem in computer vision. Efficient similarity search across large image databases depends critically on the availability of compact image representations and good data structures for indexing them. Numerous approaches to the problem of generating and indexing image codes have been presented in the literature, but existing schemes generally lack explicit estimates of the number of bits needed to effectively index a given large image database. We present a very simple algorithm for generating compact binary representations of imagery data, based on random projections. Our analysis gives the first explicit bound on the number of bits needed to effectively solve the indexing problem. When applied to real image search tasks, these theoretical improvements translate into practical performance gains: experimental results show that the new method, while using significantly less memory, is several times faster than existing alternatives.","Image databases,
Indexing,
Nearest neighbor searches,
Image retrieval,
Information retrieval,
Computer science,
Computer vision,
Image representation,
Asia,
Data structures"
Overrun Methods and Resource Holding Times for Hierarchical Scheduling of Semi-Independent Real-Time Systems,"The hierarchical scheduling framework (HSF) has been introduced as a design-time framework to enable compositional schedulability analysis of embedded software systems with real-time properties. In this paper, a software system consists of a number of semi-independent components called subsystems. Subsystems are developed independently and later integrated to form a system. To support this design process, in the paper, the proposed methods allow non-intrusive configuration and tuning of subsystem timing-behavior via subsystem interfaces for selecting scheduling parameters. This paper considers three methods to handle overruns due to resource sharing between subsystems in the HSF. For each one of these three overrun methods corresponding scheduling algorithms and associated schedulability analysis are presented together with analysis that shows under what circumstances one or the other is preferred. The analysis is generalized to allow for both fixed priority scheduling (FPS) and earliest deadline first (EDF) scheduling. Also, a further contribution of the paper is the technique of calculating resource-holding times within the framework under different scheduling algorithms; the resource holding times being an important parameter in the global schedulability analysis.","Real time systems,
Job shop scheduling,
Resource management,
Algorithm design and analysis,
Scheduling algorithm,
Independent component analysis,
Embedded software,
Software systems,
Process design,
Operating systems"
Biometric Authentication System on Mobile Personal Devices,"We propose a secure, robust, and low-cost biometric authentication system on the mobile personal device for the personal network. The system consists of the following five key modules: 1) face detection; 2) face registration; 3) illumination normalization; 4) face verification; and 5) information fusion. For the complicated face authentication task on the devices with limited resources, the emphasis is largely on the reliability and applicability of the system. Both theoretical and practical considerations are taken. The final system is able to achieve an equal error rate of 2% under challenging testing protocols. The low hardware and software cost makes the system well adaptable to a large range of security applications.",
A Stochastic Framework for Multiprocessor Soft Real-Time Scheduling,"Prior work has shown that the global earliest-deadline-first (GEDF) scheduling algorithm ensures bounded deadline tardiness on multiprocessors with no utilization loss; therefore, GEDF may be a good candidate scheduling algorithm for soft real-time workloads. However, such workloads are often implemented assuming an average-case provisioning, and in prior tardiness-bound derivations for GEDF, worst-case execution costs are assumed. As worst-case costs can be orders of magnitude higher than average-case costs, using a worst-case provisioning may result in significant wasted processing capacity. In this paper, prior tardiness-bound derivations for GEDF are generalized so that execution times are probabilistic, and a bound on expected (mean) tardiness is derived. It is shown that, as long as the total expected utilization is strictly less than the number of available processors, the expected tardiness of every task is bounded under GEDF. The result also implies that any quantile of the tardiness distribution is also bounded.",
Co-clustering of image segments using convex optimization applied to EM neuronal reconstruction,"This paper addresses the problem of jointly clustering two segmentations of closely correlated images. We focus in particular on the application of reconstructing neuronal structures in over-segmented electron microscopy images. We formulate the problem of co-clustering as a quadratic semi-assignment problem and investigate convex relaxations using semidefinite and linear programming. We further introduce a linear programming method with manageable number of constraints and present an approach for learning the cost function. Our method increases computational efficiency by orders of magnitude while maintaining accuracy, automatically finds the optimal number of clusters, and empirically tends to produce binary assignment solutions. We illustrate our approach in simulations and in experiments with real EM data.","Image segmentation,
Image reconstruction,
Linear programming,
Electron microscopy,
Cost function,
Biomedical imaging,
Computer science,
Application software,
Computational efficiency,
Computational modeling"
A Rigorous Analysis of a Phase-Locked Oscillator Under Injection,"This study presents injection-pulling effects on a local oscillator (LO) for wireless applications. A discrete-time analysis is provided to predict output spectra of the LO pulled by a sinusoidal and angle-modulated injection signal. A phase-locked loop synthesizer with an injection signal is analyzed in frequency domain to account for the inherent bandpass filtering on the injection signal. In addition, a phase noise model is developed by using the proposed frequency-domain approach to characterize the overall phase noise of a phase-locked oscillator under injection. Comparison between theoretical predictions and experimental results shows excellent agreement.","Voltage-controlled oscillators,
Local oscillators,
Phase locked loops,
Frequency domain analysis,
Frequency conversion,
Signal analysis,
Phase noise,
Phase frequency detector,
Feedback loop,
Interference"
A synergy of econometrics and computational methods (GARCH-RNFS) for volatility forecasting,"This paper presents the application of a rough-set based neuro-fuzzy system (RNFS) in volatility forecasting by synergizing the information extraction of popular generalized auto-regressive conditional heteroscedasticity (GARCH) models with the human like interpretable RNFS. Additional intraday volatility indicators such as realized power variation (RPV) are proposed to further boost volatility forecasts in the hybrid model. Experiments are performed on real-life data (Citigroup and J.P Morgan price series) to compare the volatility forecast and interpretability of the hybrid model against the commonly used GARCH, Exponential GARCH (EGARCH) and Glosten-Jagannathan-Runkle GARCH (GJR-GARCH) models and other soft computing methods. The results show that the accuracy of the proposed hybrid system can match or outperform the GARCH models and other soft computing methods. It also yields improved interpretability in terms of number of if-then fuzzy rules compared against other soft computing methods.","Predictive models,
Forecasting,
Biological system modeling,
Computational modeling,
Indexes,
Mathematical model,
Artificial neural networks"
Magnetic Eye Tracking: A New Approach Employing a Planar Transmitter,"A new scleral search coil (SSC) tracking approach employing a planar transmitter has been developed theoretically and tested experimentally. A thin and flat transmitter is much more convenient in installation, operation, and maintenance than the conventional large cubic one. A planar transmitter also increases the mobility of SSC systems, simplifies their accommodation in a limited clinical space, enables bedside testing, and causes no visual distractions and no discomfort to the users. Moreover, it allows tracking not only the SSC orientation, but also its location, which is very important for many medical and scientific applications. The suggested approach provides the speed and precision that are required in SSC applications. The experimental results show that it can be used for the diagnosis of vestibular disorders. The tracking precision is in good agreement with its theoretical estimation.","Transmitters,
Coils,
Medical diagnostic imaging,
Humans,
Magnetic field measurement,
Voltage,
Magnetic fields,
System testing,
Estimation theory,
Psychology"
A Genetic Programming Approach for Software Reliability Modeling,"Genetic programming (GP) models adapt better to the reliability curve when compared with other traditional, and non-parametric models. In a previous work, we conducted experiments with models based on time, and on coverage. We introduced an approach, named genetic programming and Boosting (GPB), that uses boosting techniques to improve the performance of GP. This approach presented better results than classical GP, but required ten times the number of executions. Therefore, we introduce in this paper a new GP based approach, named (¿ + ¿) GP. To evaluate this new approach, we repeated the same experiments conducted before. The results obtained show that the (¿ + ¿) GP approach presents the same cost of classical GP, and that there is no significant difference in the performance when compared with the GPB approach. Hence, it is an excellent, less expensive technique to model software reliability.","Genetic programming,
Software reliability,
Artificial neural networks,
Boosting,
Testing,
Solid modeling,
Machine learning,
Costs,
Predictive models,
Root mean square"
Fault Diagnosis of MEMS Lateral Comb Resonators Using Multiple-Model Adaptive Estimators,"In this brief a fault diagnostic unit is developed for microelectromechanical systems (MEMS) by means of multiple model adaptive estimation technique. Fault modeling tools such as contamination and reliability analysis of microelectromechanical layout enabled interpretation of microsystems behavior by evaluating their structural variations and modeling them in form of electric circuits. This technique cannot directly diagnose the faults during operation of microsystems. However, these fault-representing models can be used in multiple model adaptive estimation technique to form fault diagnosis units. Here, fault-representing systems are modeled by Kalman filters in real-time applications and are used to evaluate the fault in microsystems. MEMS lateral comb resonators are fabricated to experimentally demonstrate the fault diagnosis performance in multiple model adaptive estimation technique.",
Schottky-Ohmic Drain AlGaN/GaN Normally Off HEMT With Reverse Drain Blocking Capability,"In this letter, we propose an AlGaN/GaN normally off high-electron mobility transistor (HEMT) with reverse drain blocking capability. The device features a Schottky-ohmic drain electrode in which a Schottky-controlled normally off channel is inserted between the gate and the conventional ohmic drain contact. Under negative reverse drain bias, the normally off channel provides an energy barrier that effectively blocks the reverse current conduction while contributing only 0.55 V onset voltage in the forward-biased on state. In a device with a gate-drain distance of 9 m, a reverse blocking voltage of -321 V was obtained at VGS = 0 V, comparable with the forward blocking voltage of 351 V; at VGS = 3 V, the reverse blocking voltage was -276 V. The new HEMT also exhibits no degradation in drain saturation current and does not need extra photomask or process steps to fabricate. When forward biased at VGS = 3 V , the proposed device achieved a specific on resistance of 1.97 mΩ · m2.",
Oblivious algorithms for multicores and network of processors,"We address the design of algorithms for multicores that are oblivious to machine parameters. We propose HM, a multicore model consisting of a parallel shared-memory machine with hierarchical multi-level caching, and we introduce a multicore-oblivious (MO) approach to algorithms and schedulers for HM. An MO algorithm is specified with no mention of any machine parameters, such as the number of cores, number of cache levels, cache sizes and block lengths. However, it is equipped with a small set of instructions that can be used to provide hints to the run-time scheduler on how to schedule parallel tasks. We present efficient MO algorithms for several fundamental problems including matrix transposition, FFT, sorting, the Gaussian Elimination Paradigm, list ranking, and connected components. The notion of an MO algorithm is complementary to that of a network-oblivious (NO) algorithm, recently introduced by Bilardi et al. for parallel distributed-memory machines where processors communicate point-to-point. We show that several of our MO algorithms translate into efficient NO algorithms, adding to the body of known efficient NO algorithms.","Multicore processing,
Scheduling algorithm,
Algorithm design and analysis,
Computer networks,
Design engineering,
Runtime,
Sorting,
Microprocessors,
Network topology,
Parallel processing"
SPAMMS: A sensor-based pipeline autonomous monitoring and maintenance system,"Pipeline-based applications have become the indispensable part of life. Active monitoring and frequent inspections are critical to maintaining pipeline health. However, these tasks are highly expensive using the traditional maintenance systems, knowing that the pipeline systems can be largely deployed in an inaccessible and hazardous environment. In this paper, we propose a novel cost effective, scalable, customizable, and autonomous sensor-based system, called SPAMMS. It combines robot agent based technologies with sensing technologies for efficiently locating health related events and allows active and corrective monitoring and maintenance of the pipelines. SPAMMS integrates RFID systems with mobile sensors and autonomous robots. While the mobile sensor motion is based on the fluid transported by the pipeline, the fixed sensors provide event and mobile sensor location information and contribute efficiently to the study of health history of the pipeline. In addition, it permits a good tracking of the mobile sensors. Using the output of event analysis, a robot agent gets command from the controlling system, travels inside the pipelines for detailed inspection and repairing of the reported incidents (e.g., damage, leakage, or corrosion). The key innovations of SPAMMS are 3-fold: (a) the system can apply to a large variety of pipeline systems; (b) the solution provided is cost effective since it uses low cost powerless fixed sensors that can be setup while the pipeline system is operating; (c) the robot is autonomous and the localization technique allows controllable errors. The simulation experiments described in this paper along with prototyping activities demonstrate the feasibility of SPAMMS.","Pipelines,
Monitoring,
Robot sensing systems,
Costs,
Inspection,
Sensor systems,
Control systems,
Radiofrequency identification,
Mobile robots,
History"
A Multimedia Quality-Driven Network Resource Management Architecture for Wireless Sensor Networks With Stream Authentication,"Media integrity, transmission quality, and energy efficiency are critical for secure wireless image streaming in a wireless multimedia sensor network (WMSN). However, conventional data authentication and resource allocation schemes cannot be applied directly to WMSN due to the constraints on limited energy and computing resources. In this paper, we propose a quality-driven scheme to optimize stream authentication and unequal error protection (UEP) jointly. This scheme can provide digital image authentication, image transmission quality optimization, and high energy efficiency for WMSN. The contribution of this research is two-fold as summarized below. First, a new resource allocation-aware greedy stream authentication approach is proposed to simplify the authentication process. Second, an authentication-aware wireless network resource allocation scheme is developed to reduce image distortion and energy consumption in transmission. The scheme is studied by unequally protected image packets with the consideration of coding and authentication dependency. Simulation results demonstrate that the proposed scheme achieves a performance gain of 3 ~ 5&nbsp;dB in terms of authenticated image distortion.","Streaming media,
Resource management,
Wireless sensor networks,
Authentication,
Energy efficiency,
Communication system security,
Image sensors,
Error correction codes,
Digital images,
Image communication"
Conduction and Low-Frequency Noise Analysis in \hbox{Al}/\alpha\hbox{-TiO}_{X}/\hbox{Al} Bipolar Switching Resistance Random Access Memory Devices,"We investigated the low-frequency noise (LFN) properties of the bipolar switching resistance random access memories (RRAMs) for the first time with amorphous TiOx -based RRAM devices. The LFNs are proportional to 1/f for both high-resistance (HRS) and low-resistance states (LRS). The normalized noise in HRS is around an order of magnitude higher than that in LRS. The random telegraph noise (RTN) is observed only in HRS, which represents that the dominant trap causing the RTN becomes electrically inactive by being filled with electrons in LRS. The voltage dependence Si/I2 of shows that the noise can be used to elucidate the operation mechanism of RRAM devices.","Low-frequency noise,
Image analysis,
Electrodes,
Random access memory,
Noise measurement,
Amorphous materials,
Telegraphy,
Voltage,
Fluctuations,
Materials science and technology"
A 16-site neural probe integrated with a waveguide for optical stimulation,"In this paper, we report a neural probe which can selectively stimulate target neurons optically from an integrated optical waveguide and also monitor extracellular neural signals in electrical recording sites. The waveguide is composed of SU-8 core and oxide cladding layer to guide a light from optical source. A U-groove has been formed at the end of the waveguide for easy alignment with an optical fiber. The coupling loss between the optical fiber and waveguide has been measured below −3.7 dB with a waveguide loss of −0.22 dB/mm. We have successfully transmitted a light of 470nm in wavelength through the integrated polymer waveguide on the neural probe.","Optical waveguides,
Probes,
Integrated optics,
Stimulated emission,
Optical recording,
Optical fibers,
Optical fiber losses,
Neurons,
Monitoring,
Extracellular"
Design of a Low-Frequency Microphone for Mobile Phones and Its Application to Ubiquitous Medical and Healthcare Monitoring,"This paper describes a novel strategy for providing ubiquitous medical and healthcare monitoring through the use of a mobile phone equipped with a low-frequency microphone sensitive to pressure waves in the frequency range of 0.1 Hz to 10 kHz. The mobile phone is placed in a sealed air cushion under the pillow or mattress of the subject's bed. The low-frequency microphone in the mobile phone picks up the signals from the subject's heartbeat, respiration, body movement and snoring and transmits them to a healthcare center where an auto-diagnosing system or specialist monitors the subject's health condition.","Microphones,
Mobile handsets,
Medical services,
Biomedical monitoring,
Heart beat,
Sensor phenomena and characterization,
Frequency estimation,
Sleep apnea,
Acoustic sensors"
Dual Frame Motion Compensation With Optimal Long-Term Reference Frame Selection and Bit Allocation,"In dual frame motion compensation (DFMC), one short-term reference frame and one long-term reference frame (LTR) are utilized for motion compensation. The performance of DFMC is heavily influenced by the jump updating parameter and bit allocation for the reference frames. In this paper, first the rate-distortion performance analysis of motion compensated prediction in DFMC is presented. Based on this analysis, an adaptive jump updating DFMC (JU-DFMC) with optimal LTR selection and bit allocation is proposed. Subsequently, an error resilient JU-DFMC is further presented based on the error propagation analysis of the proposed adaptive JU-DFMC. The experimental results show that the proposed adaptive JU-DFMC achieves better performance over the existing JU-DFMC schemes and the normal DFMC scheme, in which the temporally most recently decoded two frames are used as the references. The performance of the adaptive JU-DFMC is significantly improved for video transmission over noisy channels when the specified error resilience functionality is introduced.","Motion compensation,
Bit rate,
Computer science,
Decoding,
Resilience,
Laboratories,
Buffer storage,
Encoding,
Rate-distortion,
Performance analysis"
An Efficient and Robust Algorithm for Shape Indexing and Retrieval,"Many shape matching methods are either fast but too simplistic to give the desired performance or promising as far as performance is concerned but computationally demanding. In this paper, we present a very simple and efficient approach that not only performs almost as good as many state-of-the-art techniques but also scales up to large databases. In the proposed approach, each shape is indexed based on a variety of simple and easily computable features which are invariant to articulations, rigid transformations, etc. The features characterize pairwise geometric relationships between interest points on the shape. The fact that each shape is represented using a number of distributed features instead of a single global feature that captures the shape in its entirety provides robustness to the approach. Shapes in the database are ordered according to their similarity with the query shape and similar shapes are retrieved using an efficient scheme which does not involve costly operations like shape-wise alignment or establishing correspondences. Depending on the application, the approach can be used directly for matching or as a first step for obtaining a short list of candidate shapes for more rigorous matching. We show that the features proposed to perform shape indexing can be used to perform the rigorous matching as well, to further improve the retrieval performance.","Robustness,
Shape,
Indexing,
Application software,
Automation,
Computer science,
Spatial databases,
Humans,
Object recognition,
Trademarks"
Relevance-Zone-Oriented Proof Search for Connect6,"Wu and Huang (Advances in Computer Games, pp. 180-194, 2006) presented a new family of k-in-a-row games, among which Connect6 (a kind of six-in-a-row) attracted much attention. For Connect6 as well as the family of k -in-a-row games, this paper proposes a new threat-based proof search method, named relevance-zone-oriented proof (RZOP) search, developed from the lambda search proposed by Thomsen (Int. Comput. Games Assoc. J., vol. 23, no. 4, pp. 203-217, 2000). The proposed RZOP search is a novel, general, and elegant method of constructing and promoting relevance zones. Using this method together with a proof number search, this paper solved effectively and successfully many new Connect6 game positions, including several Connect6 openings, especially the Mickey Mouse opening, which used to be one of the popular openings before we solved it.","Search methods,
Computer science,
Councils,
Permission,
Humans"
Novel Dynamic Representation and Control of Power Systems With FACTS Devices,"FACTS devices have been shown to be useful in damping power system oscillations. However, in large power systems, the FACTS control design is complex due to the combination of differential and algebraic equations required to model the power system. In this paper, a new method to generate a nonlinear dynamic representation of the power network is introduced to enable more sophisticated control design. Once the new representation is obtained, a back stepping methodology for the UPFC is utilized to mitigate the generator oscillations. Finally, the neural network approximation property is utilized to relax the need for knowledge of the power system topology and to approximate the nonlinear uncertainties. The net result is a power system representation that can be used for the design of an enhanced FACTS control scheme. Simulation results are given to validate the theoretical conjectures.","Power system dynamics,
Power system control,
Control systems,
Power systems,
Power system modeling,
Power system simulation,
Control design,
Damping,
Differential algebraic equations,
Nonlinear equations"
An Automatic and Robust Algorithm of Reestablishment of Digital Dental Occlusion,"In the field of craniomaxillofacial (CMF) surgery, surgical planning can be performed on composite 3-D models that are generated by merging a computerized tomography scan with digital dental models. Digital dental models can be generated by scanning the surfaces of plaster dental models or dental impressions with a high-resolution laser scanner. During the planning process, one of the essential steps is to reestablish the dental occlusion. Unfortunately, this task is time-consuming and often inaccurate. This paper presents a new approach to automatically and efficiently reestablish dental occlusion. It includes two steps. The first step is to initially position the models based on dental curves and a point matching technique. The second step is to reposition the models to the final desired occlusion based on iterative surface-based minimum distance mapping with collision constraints. With linearization of rotation matrix, the alignment is modeled by solving quadratic programming. The simulation was completed on 12 sets of digital dental models. Two sets of dental models were partially edentulous, and another two sets have first premolar extractions for orthodontic treatment. Two validation methods were applied to the articulated models. The results show that using our method, the dental models can be successfully articulated with a small degree of deviations from the occlusion achieved with the gold-standard method.","Robustness,
Dentistry,
Laser surgery,
Merging,
Computed tomography,
Surface emitting lasers,
Laser modes,
Process planning,
Surface treatment,
Quadratic programming"
Privacy-Aware Traffic Monitoring,"Traffic-monitoring systems (TMSs) are vital for safety and traffic optimization. However, these systems may compromise the privacy of drivers once they track the position of each driver with a high degree of temporal precision. In this paper, we argue that aggregated data can protect location privacy while providing accurate information for traffic monitoring. We identify a range of aggregate query types. Our proposed privacy-aware monitoring system (PAMS) works as an aggregate query processor that protects the location privacy of drivers as it anonymizes the IDs of cars. Our experiments show that PAMS answers queries with high accuracy and efficiency.","Monitoring,
Aggregates,
Privacy,
Protection,
Intrusion detection,
Road vehicles,
Data structures,
Telecommunication traffic,
Histograms,
Safety"
Interactive Visual Analysis of Multiple Simulation Runs Using the Simulation Model View: Understanding and Tuning of an Electronic Unit Injector,"Multiple simulation runs using the same simulation model with different values of control parameters generate a large data set that captures the behavior of the modeled phenomenon. However, there is a conceptual and visual gap between the simulation model behavior and the data set that makes data analysis more difficult. We propose a simulation model view that helps to bridge that gap by visually combining the simulation model description and the generated data. The simulation model view provides a visual outline of the simulation process and the corresponding simulation model. The view is integrated in a Coordinated Multiple Views; (CMV) system. As the simulation model view provides a limited display space, we use three levels of details. We explored the use of the simulation model view, in close collaboration with a domain expert, to understand and tune an electronic unit injector (EUI). We also developed analysis procedures based on the view. The EUI is mostly used in heavy duty Diesel engines. We were mainly interested in understanding the model and how to tune it for three different operation modes: low emission, low consumption, and high power. Very positive feedback from the domain expert shows that the use of the simulation model view and the corresponding ;analysis procedures within a CMV system represents an effective technique for interactive visual analysis of multiple simulation runs.","Computational modeling,
Data models,
Analytical models,
Fuels,
Visualization,
Engines,
Needles"
CrossRouter: A droplet router for cross-referencing digital microfluidic biochips,"Digital Microfluidic Biochip (DMFB) has drawn lots of attention today. It offers a promising platform for various kinds of biochemical experiments. DMFB that uses cross-referencing technology to drive droplets movements scales down the control pin number on chip, which not only brings down manufacturing cost but also allows large-scale chip design. However, the cross-referencing scheme that imposes different voltage on rows and columns to activate the cells, might cause severe electrode interference, and hence greatly decreases the degree of parallelism of droplet routing. Most of the previous papers get a direct-addressing result first, and then convert to cross-referencing compatible result. This paper proposes a new method that solves the droplet routing problem on cross-referencing biochip directly. Experimental results on public benchmarks demonstrate the effectiveness and efficiency of our method in comparison with the latest work on this problem.","Microfluidics,
Routing,
Design automation,
Biomedical electrodes,
Very large scale integration,
Computer science,
Manufacturing,
Large-scale systems,
Laboratories,
Costs"
Psychophysical Model for Vibrotactile Rendering in Mobile Devices,"Vibrotactile rendering is one of the most popular means for improving the user interface of a mobile device, but the availability of related perceptual data that can aid vibrotactile effect design is not currently sufficient. The present paper reports data from a series of psychophysical studies designed to fill this gap. In Experiment I, we measured the absolute detection thresholds of sinusoidal vibrotactile stimuli transmitted to the hand through a mobile phone. Stimuli were generated by a mechanical shaker system that can produce vibrations over a broad frequency and amplitude range. The detection thresholds reported here are a new addition to the literature, and can serve as a baseline for vibrotactile stimulus design. In Experiment II, we estimated the perceived intensities of mobile device vibrations for various frequencies and amplitudes using the same shaker system. We also determined a form of parametric nonlinear function based on Stevens' power law and fit the function to the measured data. This psychophysical magnitude function, which maps vibration frequency and amplitude to a resulting perceived intensity, can be used to predict the perceived intensity of a mobile device vibration from its physical parameter values. In Experiment III, we measured another set of perceived intensities using two commercial miniature vibration actuators (vibration motor and voice-coil actuator) in place of the mechanical shaker. The purpose of this experiment was to evaluate the utility of the psychophysical magnitude function obtained in Experiment II, as vibrotactile stimuli produced by miniature actuators may have different physical characteristics, such as vibration direction and ground condition. Comparison of the results of Experiments II and III confirmed that the psychophysical magnitude function can reliably predict changing trends in the perceived intensity of mobile device vibration. We also discuss further research issues encountered during the investigation. The results presented in this paper may be instrumental in the design of effective vibrotactile actuators and perceptually-salient rendering algorithms for mobile devices.",
Monotone and Partially Monotone Neural Networks,"In many classification and prediction problems it is known that the response variable depends on certain explanatory variables. Monotone neural networks can be used as powerful tools to build monotone models with better accuracy and lower variance compared to ordinary nonmonotone models. Monotonicity is usually obtained by putting constraints on the parameters of the network. In this paper, we will clarify some of the theoretical results on monotone neural networks with positive weights, issues that are sometimes misunderstood in the neural network literature. Furthermore, we will generalize some of the results obtained by Sill for the so-called min-max networks to the case of partially monotone problems. The method is illustrated in practical case studies.","Neural networks,
Feedforward neural networks,
Cardiac disease,
Testing,
Bonding,
Humans,
Cancer,
Cardiovascular diseases,
Digital-analog conversion,
Application software"
Networked cloud orchestration: A GENI perspective,"This paper describes the experience of developing a system for creation of distributed linked configurations of heterogeneous resources (slices) in GENI. Our work leverages a number of unique architectural solutions (distributed architecture, declarative resource specifications, unique approach to slice instantiation) which is applicable to a wider set of problems related to autonomic co-scheduling and provisioning of heterogeneous networked resources. We discuss the architecture, the resource description mechanisms and some of the algorithms used to enable our system. We conclude with an analysis of a real experiment at allocating resources from multiple providers across a very wide geographic area (spanning Massachusetts, Illinois and North Carolina) to create a single private Layer 2 network connecting virtual machines on the campus of Duke University to a sensor testbed at University of Massachusetts, Amherst.","Substrates,
OWL,
Ontologies,
Resource description framework,
Computer architecture,
Resource management,
Joining processes"
On the Restricted Isometry of deterministically subsampled Fourier matrices,"Matrices satisfying the Restricted Isometry Property (RIP) are central to the emerging theory of compressive sensing (CS). Initial results in CS established that the recovery of sparse vectors x from a relatively small number of linear observations of the form y = Ax can be achieved, using a tractable convex optimization, whenever A is a matrix that satisfies the RIP; similar results also hold when x is nearly sparse or the observations are corrupted by noise. In contrast to random constructions prevalent in many prior works in CS, this paper establishes a collection of deterministic matrices, formed by deterministic selection of rows of Fourier matrices, which satisfy the RIP. Implications of this result for the recovery of signals having sparse spectral content over a large bandwidth are discussed.","Sparse matrices,
Vectors,
Discrete Fourier transforms,
Bandwidth,
Particle measurements,
Constraint optimization,
Polynomials,
Testing,
Random variables"
Proximate sensing: Inferring what-is-where from georeferenced photo collections,The primary and novel contribution of this work is the conjecture that large collections of georeferenced photo collections can be used to derive maps of what-is-where on the surface of the earth. We investigate the application of what we term “proximate sensing” to the problem of land cover classification for a large geographic region. We show that our approach is able to achieve almost 75% classification accuracy in a binary land cover labelling problem using images from a photo sharing site in a completely automated fashion. We also investigate 1) how existing geographic knowledge can be used to provide labelled training data in a weakly-supervised manner; 2) the effect of the photographer's intent when he or she captures the photograph; and 3) a method for filtering out non-informative images.,"Labeling,
Training data,
Earth,
Frequency,
Layout,
Wikipedia,
Computer science,
Geoscience,
Application software,
Filtering"
Data Mining of Gene Expression Data by Fuzzy and Hybrid Fuzzy Methods,"Microarray studies and gene expression analysis have received tremendous attention over the last few years and provide many promising avenues toward the understanding of fundamental questions in biology and medicine. Data mining of these vasts amount of data is crucial in gaining this understanding. In this paper, we present a fuzzy rule-based classification system that allows for effective analysis of gene expression data. The applied classifier consists of a set of fuzzy if-then rules that enable accurate nonlinear classification of input patterns. We further present a hybrid fuzzy classification scheme in which a small number of fuzzy if-then rules are selected through means of a genetic algorithm, leading to a compact classifier for gene expression analysis. Extensive experimental results on various well-known gene expression datasets confirm the efficacy of our approaches.","Data mining,
Gene expression,
Support vector machines,
Support vector machine classification,
Genetic algorithms,
Data analysis,
Computer science,
Nearest neighbor searches,
Classification tree analysis,
Neural networks"
Generalized Low-Rank Approximations of Matrices Revisited,"Compared to singular value decomposition (SVD), generalized low-rank approximations of matrices (GLRAM) can consume less computation time, obtain higher compression ratio, and yield competitive classification performance. GLRAM has been successfully applied to applications such as image compression and retrieval, and quite a few extensions have been successively proposed. However, in literature, some basic properties and crucial problems with regard to GLRAM have not been explored or solved yet. For this sake, we revisit GLRAM in this paper. First, we reveal such a close relationship between GLRAM and SVD that GLRAM's objective function is identical to SVD's objective function except the imposed constraints. Second, we derive a lower bound of GLRAM's objective function, and discuss when the lower bound can be touched. Moreover, from the viewpoint of minimizing the lower bound, we answer one open problem raised by Ye (Machine Learning, 2005), i.e., a theoretical justification of the experimental phenomenon that, under given number of reduced dimension, the lowest reconstruction error is obtained when the left and right transformations have equal number of columns. Third, we explore when and why GLRAM can perform well in terms of compression, which is a fundamental problem concerning the usability of GLRAM.","Image coding,
Matrix decomposition,
Image reconstruction,
Singular value decomposition,
Image retrieval,
Computer science,
Information retrieval,
High performance computing,
Machine learning,
Usability"
An MPEG-2 to H.264 Video Transcoder in the Baseline Profile,"Based on our previous efforts, we introduce in this letter a high-efficient MPEG-2 to H.264 transcoder for the baseline profile in the spatial domain. Machine learning tools are used to exploit the correlation between the macroblock (MB) decision of the H.264 video format and the distribution of the motion compensated residual in MPEG-2. Moreover, a dynamic motion estimation technique is also proposed to further speed-up the decision process. Finally, we go a step further on our previous research efforts by combining the two aforementioned speed-up approaches. Our simulation results over more than 40 sequences at common intermediate format and quarter common intermediate format resolutions show that our proposal outperforms the MB mode selection of the rate-distortion optimization option of the H.264 encoder process by reducing the computational requirements by up to 90%, while maintaining the same coding efficiency. Finally, we conduct a comparative study of our approach with the most relevant fast inter-prediction methods for MPEG-2 to H.264 transcoder recently reported in the literature.","Videoconference,
Motion estimation,
Transform coding,
Video compression,
Transcoding,
Motion compensation,
Machine learning,
Computational modeling,
Proposals,
DVD"
COCKTAIL: An RF-Based Hybrid Approach for Indoor Localization,"Traditional RF-based indoor positioning approaches use only Radio Signal Strength Indicator (RSSI) to locate the target object. But RSSI suffers significantly from the multi-path phenomenon and other environmental factors. Hence, the localization accuracy drops dramatically in a large tracking field. To solve this problem, this paper introduces one more resource, the dynamic of RSSI, which is the variance of signal strength caused by the target object and is more robust to environment changes. By combining these two resources, we are able to greatly improve the accuracy and scalability of current RF-based approaches. We call such hybrid approach COCKTAIL. It employs both the technologies of active RFID and Wireless Sensor Networks (WSNs). Sensors use the dynamic of RSSI to figure out a cluster of reference tags as candidates. The final target location is estimated by using the RSSI relationships between the target tag and candidate reference tags. Experiments show that COCKTAIL can reach a remarkable high degree of localization accuracy to 0:45m, which outperforms significantly to most of the pure RF-based localization approaches.","Wireless sensor networks,
RFID tags,
Target tracking,
Radiofrequency identification,
Environmental factors,
Robustness,
Active RFID tags,
Radio frequency,
Communications Society,
Computer science"
Registering a MultiSensor Ensemble of Images,"Many registration scenarios involve aligning more than just two images. These image sets-called ensembles-are conventionally registered by choosing one image as a template, and every other image is registered to it. This pairwise approach is problematic because results depend on which image is chosen as the template. The issue is particularly acute for multisensor ensembles because different sensors create images with different features. Also, pairwise methods use only a fraction of the available data at a time. In this paper, we propose a maximum-likelihood clustering method that registers all the images in a multisensor ensemble simultaneously. Experiments involving rigid-body and affine transformations show that the clustering method is more robust and accurate than competing pairwise registration methods. Moreover, the clustering results can be used to form a rudimentary segmentation of the image ensemble.","Image sensors,
Clustering methods,
Biomedical imaging,
Magnetic resonance imaging,
Computed tomography,
Positron emission tomography,
Sensor phenomena and characterization,
Robustness,
Image segmentation,
Mutual information"
The Accelerated Universe,"The advent of powerful cosmological surveys demands a new generation of high-precision, large-volume, and high dynamic range simulations of structure formation in the Universe. Key aims of these simulations are understanding why the expansion of the Universe is accelerating and what dark matter is made of. The availability of Roadrunner, the world's first petaflop platform, led us to develop a new hybrid cosmology simulation code making essential use of hardware acceleration. We describe the strategies underlying the code and aspects of its implementation.","Acceleration,
Gravity,
Computational modeling,
History,
Dark energy,
Physics,
Hydrodynamics,
Laboratories,
Aerospace engineering,
Aerospace simulation"
Why Modern CPUs Are Starving and What Can Be Done about It,CPUs spend most of their time waiting for data to arrive. Identifying low-level bottlenecks-and how to ameliorate them-can save hours of frustration over poor performance in apparently well-written programs.,"Clocks,
Read-write memory,
Delay,
Frequency,
Random access memory,
Multicore processing,
Bandwidth,
Costs,
Central Processing Unit,
Impedance"
Constructing Maximum-Lifetime Data Gathering Trees in Sensor Networks with Data Aggregation,"This paper studies the problem of constructing maximum-lifetime data gathering trees in sensor networks in which the power levels of sensors are heterogeneous and adjustable. In-network data aggregation is also employed to aggregate sensor data while they are being forwarded toward the base station. For sensor networks in which sensors have fixed and the same transmission power level, Wu et al. has derived an upper bound on the lifetime of the optimal data gathering tree and developed an approximation algorithm for constructing data gathering trees. The model considered in this paper is more general than that considered by Wu et al. in that the transmission power levels of sensors are heterogeneous and adjustable. For this more general model, this paper derives an upper bound on the lifetime of the optimal data gathering tree. Given an initial tree, an algorithm is developed to construct a data gathering tree by iteratively rearranging the current tree and improving the lifetime of the current tree. The worst-case computational complexity of the algorithm is shown to be polynomial.","Base stations,
Upper bound,
Iterative algorithms,
Protocols,
Approximation algorithms,
Batteries,
Energy consumption,
Communications Society,
Computer science,
Aggregates"
A High-Performance Heterogeneous Computing Platform for Biological Sequence Analysis,"Advances in bioinformatics research continue to add complexity to the analyses and interpretation of biological data. Certain sequence database searches may take weeks to complete due to complicated data dependencies by dynamic programming. A reconfigurable coprocessor can remove this computational bottleneck and accelerate the operation. This paper presents a heterogeneous computing platform through Message Passing Interface (MPI) enabled enterprise computing infrastructure for high-throughput biological sequence analysis. The computing platform integrates heterogeneous computer architectures including conventional processors with Streaming Single Instruction Multiple Data Extensions 2 (SSE2) instructions, reconfigurable coprocessors, and legacy processors together into one system, and allows each to perform the task to which it is best suited. With appropriate computation and communication scheduling, the integrated heterogeneous computing infrastructure is designed to accommodate various types of accelerators to provide a High-Performance Computing (HPC) framework to support the most widely used life science applications.","Biology computing,
Coprocessors,
Computer interfaces,
Bioinformatics,
Databases,
Dynamic programming,
Acceleration,
Message passing,
Computer aided instruction,
Computer architecture"
Vibrotactile Feedback for Information Delivery in the Vehicle,"As technology advances, more functions have been, and continue to be added to the vehicle, resulting in increased needs for improved user interfaces. In this paper, we investigate the feasibility of using vibrotactile feedback for in-vehicle information delivery. First, we measured the spectral characteristics of ambient vibrations in a vehicle, and designed clearly distinguishable sinusoidal vibrations. We further selected via dissimilarity rating the four sets of sinusoidal vibrations which had three to six vibrations. Second, we evaluated the learnability of the vibration sets when associated with common menu items of a Driver Information System (DIS). We also replaced the two most confused sinusoidal vibrations with patterned messages, and assessed the degree of learnability improvement. Finally, we evaluated the extent to which participants could select a desired function in a DIS via vibrotactile messages while simultaneously performing a driving-like primary task with higher priority. The results demonstrated high potential for vibrotactile messages to be effectively used for the communicative transfer of in-vehicle system information.","Feedback,
Vibration measurement,
Information systems,
Humans,
Control systems,
Vehicle driving,
Driver circuits,
Auditory displays,
User interfaces,
Performance evaluation"
A Method for Compact Image Representation Using Sparse Matrix and Tensor Projections Onto Exemplar Orthonormal Bases,"We present a new method for compact representation of large image datasets. Our method is based on treating small patches from a 2-D image as matrices as opposed to the conventional vectorial representation, and encoding these patches as sparse projections onto a set of exemplar orthonormal bases, which are learned a priori from a training set. The end result is a low-error, highly compact image/patch representation that has significant theoretical merits and compares favorably with existing techniques (including JPEG) on experiments involving the compression of ORL and Yale face databases, as well as a database of miscellaneous natural images. In the context of learning multiple orthonormal bases, we show the easy tunability of our method to efficiently represent patches of different complexities. Furthermore, we show that our method is extensible in a theoretically sound manner to higher-order matrices (¿tensors¿). We demonstrate applications of this theory to compression of well-known color image datasets such as the GaTech and CMU-PIE face databases and show performance competitive with JPEG. Lastly, we also analyze the effect of image noise on the performance of our compression schemes.","Image representation,
Sparse matrices,
Tensile stress,
Image coding,
Image databases,
Transform coding,
Color,
Image analysis,
Performance analysis,
Acoustic noise"
On agreement problems with gossip algorithms in absence of common reference frames,"In this paper a novel approach to the problem of decentralized agreement toward a common point in space in a multi-agent system is proposed. Our method allows the agents to agree on the relative location of the network centroid respect to themselves, on a common reference frame and therefore on a common heading. Using this information a global positioning system for the agents using only local measurements can be achieved. In the proposed scenario, an agent is able to sense the distance between itself and its neighbors and the direction in which it sees its neighbors with respect to its local reference frame. Furthermore only point-to-point asynchronous communications between neighboring agents are allowed thus achieving robustness against random communication failures. The proposed algorithms can be thought as general tools to locally retrieve global information usually not available to the agents.","Space technology,
Multiagent systems,
Position measurement,
Asynchronous communication,
Robustness,
Information retrieval,
Distance measurement,
Global Positioning System,
Robotics and automation,
USA Councils"
Integrated Voltage Reference Generator for GaN Smart Power Chip Technology,"GaN smart power chip technology has been realized using a GaN-on-Si HEMT platform, featuring monolithically integrated high-voltage power devices and low-voltage peripheral devices for mixed-signal functional blocks. In particular, this brief presents the imperative analog functional block-voltage reference generator for smart power applications with wide-temperature-range stability. The circuit is capable of proper functions within a wide temperature range from room temperature up to 250°C , illustrating the unique advantage of the wide-bandgap GaN in high-temperature operation. The voltage reference generator was designed with an AlGaN/GaN HEMT and Schottky diodes, and the devices were operated in the subthreshold regime to obtain low power consumption. The voltage reference generator achieved an average drift of less than 0.5 mV/°C and can be used as a reference voltage in various biasing and sensing circuits.","Gallium nitride,
HEMTs,
Temperature measurement,
Plasma temperature,
Generators,
Aluminum gallium nitride"
Localization in wireless networks via spatial sparsity,"This paper exploits recent developments in sparse approximation and compressive sensing to efficiently perform localization in wireless networks. Particularly, we re-formulate the localization problem as a sparse approximation problem using the compressive sensing theory that provides a new paradigm for recovering a sparse signal solving an ℓ1 minimization problem. The proposed received signal strength-based method does not require any time specific/propriatery hardware since the location estimation is performed at the Access Points (APs). The experimental results show that our proposed method, when compared with traditional localization schemes results in a better accuracy in terms of the mean localization error.","Runtime,
Mobile communication,
Bayesian methods,
Measurement uncertainty,
Signal to noise ratio,
Vectors,
Compressed sensing"
Stereo-Assist: Top-down stereo for driver assistance systems,"This paper presents a top-down approach to stereo for use in driver assistance systems. We introduce an asymmetric configuration where monocular object detection and range estimation is performed in the primary camera and then that image patch is aligned and matched in the secondary camera. The stereo distance measure from the matching assists in target verification and improved distance measurements. This approach, Stereo-Assist, shows significant advantages over the classical bottom-up stereo approach which relies on first computing a dense depth map and then using the depth map for object detection. The new approach can provide increased object detection range, reduced computational load, greater flexibility in camera configurations (we are no longer limited to side-by-side stereo configurations), greater robustness to obstructions in part of the image and mixed camera modalities FIR/VIS can be used. We show results with two novel configurations and illustrate how monocular object detection allows for simple online calibration of the stereo rig.","Cameras,
Object detection,
Layout,
Costs,
Vehicle detection,
Packaging,
Automotive engineering,
Intelligent vehicles,
USA Councils,
Distance measurement"
Distributive Stochastic Learning for Delay-Optimal OFDMA Power and Subband Allocation,"In this paper, we consider the distributive queue-aware power and subband allocation design for a delay-optimal OFDMA uplink system with one base station, K users and NF independent subbands. Each mobile has an uplink queue with heterogeneous packet arrivals and delay requirements. We model the problem as an infinite horizon average reward Markov decision problem (MDP) where the control actions are functions of the instantaneous channel state information (CSI) as well as the joint queue state information (QSI). To address the distributive requirement and the issue of exponential memory requirement and computational complexity, we approximate the subband allocation Q-factor by the sum of the per-user subband allocation Q-factor and derive a distributive online stochastic learning algorithm to estimate the per-user Q-factor and the Lagrange multipliers (LM) simultaneously and determine the control actions using an auction mechanism. We show that under the proposed auction mechanism, the distributive online learning converges almost surely (with probability 1). For illustration, we apply the proposed distributive stochastic learning framework to an application example with exponential packet size distribution. We show that the delay-optimal power control has the multilevel water-filling structure where the CSI determines the instantaneous power allocation and the QSI determines the water-level. The proposed algorithm has linear signaling overhead and computational complexity O(KNF), which is desirable from an implementation perspective.","Stochastic processes,
Physical layer,
Queueing analysis,
Constraint theory,
Delay systems,
Power system modeling,
Channel state information,
Computational complexity,
Base stations,
Infinite horizon"
On optimal network selection in a dynamic multi-RAT environment,"A significant challenge to enable multimedia service delivery in a dynamic multiple radio access technologies (multi-RAT) environment is the coordination of vertical handovers between different RATs. Cost function approach has been widely adopted to make vertical handover decision by ranking candidate networks. Although this mechanism can reflect accurately the change of network states and user requirements, it results in frequent, and often, unnecessary handovers which have detrimental impact on QoS, signaling load and system capacity. In this letter, we introduce a novel measurement-based network selection technique that provides a pragmatic way to acquire QoS information. In addition, it augments the handover decision of existing cost function approach, through handover initiation, to provide an optimal network selection outcome. OPNET simulations verify that the proposed technique can reduce unnecessary handovers considerably, improve overall QoS and system capacity.","Cost function,
Quality of service,
Rats,
Bayesian methods,
Delay,
Information filtering,
Information filters,
Wireless networks,
Telecommunication traffic"
Autonomous Underwater Vehicle trajectory design coupled with predictive ocean models: A case study,"Data collection using Autonomous Underwater Vehicles (AUVs) is increasing in importance within the oceanographic research community. Contrary to traditional moored or static platforms, mobile sensors require intelligent planning strategies to maneuver through the ocean. However, the ability to navigate to high-value locations and collect data with specific scientific merit is worth the planning efforts. In this study, we examine the use of ocean model predictions to determine the locations to be visited by an AUV, and aid in planning the trajectory that the vehicle executes during the sampling mission. The objectives are: a) to provide near-real time, in situ measurements to a large-scale ocean model to increase the skill of future predictions, and b) to utilize ocean model predictions as a component in an end-to-end autonomous prediction and tasking system for aquatic, mobile sensor networks. We present an algorithm designed to generate paths for AUVs to track a dynamically evolving ocean feature utilizing ocean model predictions. This builds on previous work in this area by incorporating the predicted current velocities into the path planning to assist in solving the 3-D motion planning problem of steering an AUV between two selected locations. We present simulation results for tracking a fresh water plume by use of our algorithm. Additionally, we present experimental results from field trials that test the skill of the model used as well as the incorporation of the model predictions into an AUV trajectory planner. These results indicate a modest, but measurable, improvement in surfacing error when the model predictions are incorporated into the planner.","Underwater vehicles,
Trajectory,
Oceans,
Predictive models,
Intelligent sensors,
Sea measurements,
Path planning,
Strategic planning,
Navigation,
Marine vehicles"
Design of Digital Circuits Using Inverse-Mode Cascode SiGe HBTs for Single Event Upset Mitigation,"We report on the design and measured results of a new SiGe HBT radiation hardening by design technique called the “inverse-mode cascode” (IMC). A third-generation SiGe HBT IMC device was tested in a time resolved ion beam induced charge collection (TRIBICC) system, and was found to have over a 75% reduction in peak current transients with the use of an n-Tiedown on the IMC sub-collector node. Digital shift registers in a 1st-generation SiGe HBT technology were designed and measured under a heavy-ion beam, and shown to increase the LET threshold over standard npn only shift registers. Using the CREME96 tool, the expected orbital bit-errors/day were simulated to be approximately 70% lower with the IMC shift register. These measured results help demonstrate the efficacy of using the IMC device as a low-cost means for improving the SEE radiation hardness of SiGe HBT technology without increasing area or power.",
Active Route-Guiding Protocols for Resisting Obstacles in Wireless Sensor Networks,"In wireless sensor networks, a geographic region without the functionality of sensing and communication can generally be treated as an obstacle, which significantly impacts the performance of existing location-based routing. An obstacle can dynamically be formed due to unbalanced deployment, sensor failure, or power exhaustion, animus interference, or physical obstacles such as mountains or buildings. This paper proposes novel algorithms that enable the existing location-based routing protocols that resist obstacles. Applying the proposed active route-guiding protocol for single obstacles (S-RGP), border nodes that surround the obstacles will actively establish a forbidden region for concave obstacles and make the obstacle information transparent. Then, packets will be guided to overcome the obstacle and move along the shorter path from the encountered border node to the sink node. In addition, the proposed active route-guiding protocol for multiple obstacles (M-RGP) takes multiple obstacles into consideration and integrates their information to help the packets overcome multiple obstacles. Simulation results show that the proposed S-RGP and M-RGP create low overhead and significantly reduce the average route length, and, therefore, improve the energy consumption and end-to-end delay for a wireless sensor network with obstacles.",
Posture Monitoring System for Context Awareness in Mobile Computing,"The posture of a user is one of the contextual information that can be used for mobile applications and the treatment of idiopathic scoliosis. This paper describes a method for monitoring the posture of a user during operation of a mobile device in three activities such as sitting, standing, and walking. The user posture monitoring system (UPMS) proposed in this paper is based on two major technologies. The first involves a tilt-angle measurement algorithm (TAMA) using an accelerometer. Unlike most previous studies, it is based on a relative computation using the dot product from the time-series acceleration data. Because TAMA does not require a physical calibration by a user, it is more robust and accurate compared to other methods that rely on absolute computations. The second technology is an effective signal-processing method that eliminates the motion acceleration component of the accelerometer signal using a second-order Butterworth low-pass filter (SLPF). Because the posture of a user is only related to the gravity acceleration component, the motion acceleration components should be removed. The TAMA and UPMS are implemented on a personal digital assistant (PDA). They are evaluated to verify the possibility of application to a mobile device. Additionally, a posture-based intelligent control interface in context-aware computing that reacts to the posture of a PDA user is implemented on the PDA to complement the poor user interface (UI) of the mobile device, and its results are presented.","Monitoring,
Context awareness,
Mobile computing,
Acceleration,
Personal digital assistants,
Accelerometers,
Legged locomotion,
Calibration,
Robustness,
Physics computing"
Interactive low-complexity codes for synchronization from deletions and insertions,"We study the problem of synchronization of two remotely located data sources, which are mis-synchronized due to deletions and insertions. This is an important problem since a small number of synchronization errors can induce a large Hamming distance between the two sources. The goal is to effect synchronization with the rate-efficient use of lossless bidirectional links between the two sources. In this work, we focus on the following model. A binary sequence X of length n is edited to generate the sequence at the remote end, say Y, where the editing involves random deletions and insertions, possibly in small bursts. The problem is to synchronize Y with X with minimal exchange of information (in terms of both the average communication rate and the average number of interactive rounds of communication). We focus here on the case where the number of edits is much smaller than n, and propose an interactive algorithm which is computationally simple and has near-optimal communication complexity. Our algorithm works by efficiently splitting the source sequence into pieces containing either just a single deletion/insertion or a single burst deletion/insertion. Each of these pieces is then synchronized using an optimal one-way synchronization code, based on the single-deletion correcting channel codes of Varshamov and Tenengolts (VT codes).","Synchronization,
Decoding,
Protocols,
Approximation algorithms,
Channel coding,
Source coding"
A survey on Terrain Based Navigation for AUVs,"Terrain Based Navigation (TBN) is a method rooted to the early cruise missile navigation systems, when GPS was not yet available. For decades, TBN has been applied as a complementary system to INS navigation for Unmanned Aerial Vehicles (UAV). In the field of Autonomous Underwater Vehicles (AUVs), it has the potential to bound the drift inherent to dead reckoning navigation, based on INS and/or Doppler Velocity Log (DVL) sensors, as well as to make the navigation beyond the areas of coverture of the acoustic transponder networks, a reality. This paper overviews the main concepts related to TBN and present an exhaustive survey of the works reported in the literature. As a main contribution, a table comparing the motion and the measurement models, as well as the probabilistic framework used for the estimation is reported. An effort has been put on unifying the diverse nomenclature used across the surveyed works. We aim this paper to become an starting point for the researchers interested in this technology, with pointers to the most interested works in the area.","Navigation,
Robot sensing systems,
Sea measurements,
Sonar measurements"
Strong and affordable location privacy in VANETs: Identity diffusion using time-slots and swapping,"Public acceptance, and thus the economical success of Vehicular Ad Hoc Networks (VANETs), is highly dependent on the quality of deployed privacy mechanisms. Neither users nor operators should be able to track a given individual. One approach to facilitate this is the usage of pseudonym pools, which allow vehicles to autonomously switch between different identities. We extend this scheme with that of a time-slotted pseudonym pool of static size, reducing the storage and computation needs of the envisioned Intelligent Transportation System (ITS) while further improving users' privacy. In addition, we allow the exchange of pseudonyms between nodes, eliminating the mapping between vehicles and pseudonyms even for operators of the VANET. Here, we support the exchange of both the currently used pseudonym and those of future time-slots, further enhancing users' privacy. We evaluate the feasibility of our approach and back up privacy claims by performing a simulative study of the system using the entropy of nodes' anonymity sets as the primary metric.","Vehicles,
Privacy,
Entropy,
Driver circuits,
Protocols,
Measurement,
Ad hoc networks"
Robotics-Centered Outreach Activities: An Integrated Approach,"Nowadays, universities are making extensive efforts to attract prospective students to the fields of electrical, electronic, and computer engineering. Thus, outreach is becoming increasingly important, and activities with schoolchildren are being extensively carried out as part of this effort. In this context, robotics is a very attractive and effective tool for fostering interest in science and technology among children and young people and for attracting them toward engineering. In this article, experience with different robotics-centered outreach activities in the Universidad de Chile (UCH), Santiago, Chile, will be shared. These activities include robotics courses for children, social robots as keynote speakers, mechatronics design courses, and participation in international robotics competitions, which contribute synergistically to the goal of attracting students to UCH's Electrical Engineering (EE) Department. Owing to its novelty, the use of social robots as keynote speakers for schoolchildren will be described in detail. Experimental results that demonstrate how sophisticated social robots can be used to foster the interest of young people in technology will be shown. Altogether, more than 3000 schoolchildren have participated directly in these outreach activities here in Chile, creating a sizeable impact in this country.","Educational institutions,
Pediatrics,
Laboratories,
Mechatronics,
Humans,
Educational robots"
Rate Control With Pairwise Intersession Network Coding,"In this paper, we develop a distributed rate-control algorithm for networks with multiple unicast sessions when network coding is allowed across different sessions. Building on recent flow-based characterization of pairwise intersession network coding, the corresponding optimal rate-control problem is formulated as a convex optimization problem. The formulation exploits pairwise coding possibilities between any pair of sessions, where any coded symbol is formed by coding over at most two original symbols. The objective function is the sum of the utilities based on the rates supported by each unicast session. Working on the Lagrangian of the formulated problem, a distributed algorithm is developed with little coordination among intermediate nodes. Each unicast session has the freedom to choose its own utility function. The only information exchange required by the source is the weighted sum of the queue length of each link, which can be piggybacked to the acknowledgment messages. In addition to the optimal rate-control algorithm, we propose a decentralized pairwise random coding scheme that decouples the decision of coding from that of rate control, which further enhances the distributiveness of the proposed scheme. The convergence of the rate-control algorithm is proven analytically and verified by extensive simulations. Simulation results also demonstrate the advantage of the proposed algorithm over the state-of-the-art in terms of both throughput and fairness.",
Nonnegative matrix partial co-factorization for drum source separation,"We address a problem of separating drums from polyphonic music containing various pitched instruments as well as drums. Nonnegative matrix factorization (NMF) was successfully applied to spectrograms of music to learn basis vectors, followed by support vector machine (SVM) to classify basis vectors into ones associated with drums (rhythmic source) only and pitched instruments (harmonic sources). Basis vectors associated with pitched instruments are used to reconstruct drum-eliminated music. However, it is cumbersome to construct a training set for pitched instruments since various instruments are involved. In this paper, we propose a method which only incorporates prior knowledge on drums, not requiring such training sets of pitched instruments. To this end, we present nonnegative matrix partial co-factorization (NMPCF) where the target matrix (spectrograms of music) and drum-only-matrix (collected from various drums a priori) are simultaneously decomposed, sharing some factor matrix partially, to force some portion of basis vectors to be associated with drums only. We develop a simple multiplicative algorithm for NMPCF and show its usefulness empirically, with numerical experiments on real-world music signals.","Source separation,
Matrix decomposition,
Instruments,
Multiple signal classification,
Support vector machines,
Support vector machine classification,
Spectrogram,
Signal processing,
Image reconstruction,
Collaboration"
Predictive Deconvolution and Hybrid Feature Selection for Computer-Aided Detection of Prostate Cancer,"Computer-aided detection (CAD) schemes are decision making support tools, useful to overcome limitations of problematic clinical procedures. Trans-rectal ultrasound image based CAD would be extremely important to support prostate cancer diagnosis. An effective approach to realize a CAD scheme for this purpose is described in this work, employing a multi-feature kernel classification model based on generalized discriminant analysis. The mutual information of feature value and tissue pathological state is used to select features essential for tissue characterization. System-dependent effects are reduced through predictive deconvolution of the acquired radio-frequency signals. A clinical study, performed on ground truth images from biopsy findings, provides a comparison of the classification model applied before and after deconvolution, showing in the latter case a significant gain in accuracy and area under the receiver operating characteristic curve.","Deconvolution,
Cancer detection,
Prostate cancer,
Decision making,
Ultrasonic imaging,
Kernel,
Mutual information,
Pathology,
Radio frequency,
Biopsy"
On deciding between conservative and optimistic approaches on massively parallel platforms,"Over 5000 publications on parallel discrete event simulation (PDES) have appeared in the literature to date. Nevertheless, few articles have focused on empirical studies of PDES performance on large supercomputer-based systems. This gap is bridged here, by undertaking a parameterized performance study on thousands of processor cores of a Blue Gene supercomputing system. In contrast to theoretical insights from analytical studies, our study is based on actual implementation in software, incurring the actual messaging and computational overheads for both conservative and optimistic synchronization approaches of PDES. Complex and counter-intuitive effects are uncovered and analyzed, with different event timestamp distributions and available levels of concurrency in the synthetic benchmark models. The results are intended to provide guidance to the PDES community in terms of how the synchronization protocols behave at high processor core counts using a state-of-the-art supercomputing systems.","Synchronization,
Computational modeling,
Supercomputers,
Protocols,
Hardware,
Benchmark testing,
Optimized production technology"
Loop Heat Pipes for Cooling Systems of Servers,"Loop heat pipes (LHPs) are exceptionally efficient heat-transfer devices that employ a closed loop evaporation-condensation cycle that can be used to cool densely packed electronic systems that reject large quantities of heat, including computers and their central processing units (CPUs). Tests were carried out on miniature ammonia LHPs with a CPU thermal simulator using different ways of condenser cooling. The possibility of maintaining the cooled object temperatures between 40°C and 70°C with heat load changing from 100 to 320 W was demonstrated. Subsequent tests of these devices in a 1U computer with dual core advanced micro devices Opteron CPUs, dissipating between 95 and 120 W, have confirmed the advantages and heat transfer efficiency of LHP-based cooling systems used to cool CPU in 1U chassis.","Thermal resistance,
Temperature,
Central Processing Unit,
Heat transfer,
Heat sinks,
Electronics cooling,
Resistance heating,
Thermal loading,
Thermal conductivity,
Heat pumps"
"DuraCap: A supercapacitor-based, power-bootstrapping, maximum power point tracking energy-harvesting system","DuraCap is a solar-powered energy harvesting system that stores harvested energy in supercapacitors and is voltage-compatible with lithium-ion batteries. The use of supercapacitors instead of batteries enables DuraCap to extend the operational life time from tens of months to tens of years. DuraCap addresses two additional problems with micro-solar systems: inefficient operation of superca-pacitors during cold booting, and maximum power point tracking (MPPT) over a variety of solar panels. Our approach is to dedicate a smaller supercapacitor to cold booting before handing over to the array of larger-value supercapacitors. For MPPT, we designed a bound-control circuit for PFM regulator switching and an I-V tracer to enable self-configuring over the panel's aging process and replacement. Experimental results show the DuraCap system to achieve high conversion efficiency and minimal downtime.","Supercapacitors,
Switches,
Regulators,
Arrays,
Switching circuits,
Booting,
MOSFETs"
Visual tracking via incremental self-tuning particle filtering on the affine group,"We propose an incremental self-tuning particle filtering (ISPF) framework for visual tracking on the affine group. SIFT (Scale Invariant Feature Transform) like descriptors are used as basic features, and IPCA (Incremental Principle Component Analysis) is utilized to learn an adaptive appearance subspace for similarity measurement. ISPF tries to find the optimal target position in a step-by-step way: particles are incrementally drawn and intelligently tuned to their best states by an online LWPR (Local Weighted Projection Regression) pose estimator; searching is terminated if the maximum similarity of all tuned particles satisfies a target similarity distribution (TSD) modeled online or the permitted maximum number of particles is reached. Experimental results demonstrate that our ISPF can achieve great robustness and very high accuracy with only a very small number of random particles.","Particle tracking,
Filtering,
Target tracking,
State estimation,
Robustness,
Stochastic processes,
Boosting,
Bayesian methods,
Cost function,
Laboratories"
Probabilistic Self-Organizing Maps for Continuous Data,"The original self-organizing feature map did not define any probability distribution on the input space. However, the advantages of introducing probabilistic methodologies into self-organizing map models were soon evident. This has led to a wide range of proposals which reflect the current emergence of probabilistic approaches to computational intelligence. The underlying estimation theories behind them derive from two main lines of thought: the expectation maximization methodology and stochastic approximation methods. Here, we present a comprehensive view of the state of the art, with a unifying perspective of the involved theoretical frameworks. In particular, we examine the most commonly used continuous probability distributions, self-organization mechanisms, and learning schemes. Special emphasis is given to the connections among them and their relative advantages depending on the characteristics of the problem at hand. Furthermore, we evaluate their performance in two typical applications of self-organizing maps: classification and visualization.","Probabilistic logic,
Computational modeling,
Training,
Stochastic processes,
Approximation methods,
Covariance matrix,
Proposals"
The Effect of High-Z Materials on Proton-Induced Charge Collection,Charge collection measurements reveal that the presence of high-Z materials increases proton-induced charge collection cross sections for high charge collection events. The mechanism for this effect is proton-induced fission events as shown through validated Monte Carlo simulations. These fission fragments are emitted isotropically in contrast to high-LET secondary particles from proton-silicon interactions which tend to be forward directed.,"Computer simulation,
Monte Carlo methods,
Proton radiation effects,
Single event upset"
Efficient reversible image watermarking by using dynamical prediction-error expansion,"Reversible watermarking is a special watermarking technique which allows one to extract both the hidden data and the exact original signal from the watermarked content. In this paper, a recently introduced reversible image watermarking method based on prediction-error expansion is further investigated and improved. Instead of taking the pixels with small prediction-error as embedding pixels (i.e., the pixels that carry watermark bits), we propose to select these pixels in a dynamical way. In fact, we can pre-calculate the embedding distortion for each possible choice of embedding pixels, and determine the one with minimal distortion. We see that, with this choice of embedding pixels, the distortion is reduced comparing with the original method, and thus, the proposed approach has a better performance. In addition, experimental results show that the novel method outperforms some state-of-the-art algorithms.","Pixel,
Watermarking,
Histograms,
Image coding,
Prediction algorithms,
Data mining,
PSNR"
REALM: A rule-based evolutionary computation agent that learns to play Mario,"REALM is a rule-based evolutionary computation agent for playing a modified version of Super Mario Bros. according to the rules stipulated in the Mario AI Competition held in the 2010 IEEE Symposium on Computational Intelligence and Games. Two alternate representations for the REALM rule sets are reported here, in both hand-coded and learned versions. Results indicate that the second version, with an abstracted action set, tends to perform better overall, but the first version shows a steeper learning curve. In both cases, learning quickly surpasses the hand-coded rule sets.","Games,
Artificial intelligence,
Presses,
Green products,
Vocabulary,
Evolutionary computation"
The benefits and challenges of collecting richer object annotations,"Several recent works have explored the benefits of providing more detailed annotations for object recognition. These annotations provide information beyond object names, and allow a detector to reason and describe individual instances in plain English. However, by demanding more specific details from annotators, new difficulties arise, such as stronger language dependencies and limited annotator attention. In this work, we present the challenges of constructing such a detailed dataset, and discuss why the benefits of using this data outweigh the difficulties of collecting it.","Object recognition,
Computer science,
Object detection,
Detectors,
Natural languages,
Robots"
Source-level timing annotation for fast and accurate TLM computation model generation,"This paper proposes a source-level timing annotation method for generation of accurate transaction level models for software computation modules. While Transaction Level Modeling (TLM) approach is widely adopted now for system modeling and simulation speed improvement, timing estimation accuracy often is compromised. To have reliable and accurate estimation results at system level, we propose a timing annotation method for accurate TLM computation model generation considering processor architecture with pipeline and cache structures, which are challenging but critical to accurate timing estimation. The experiments show that our results are within 2% of cycle accurate results and the approach is three orders faster than conventional ISS approaches.",
Real Time Coincidence Detection Engine for High Count Rate Timestamp Based PET,"Coincidence engines follow two main implementation flows: timestamp based systems and AND-gate based systems. The latter have been more widespread in recent years because of its lower cost and high efficiency. However, they are highly dependent on the selected electronic components, they have limited flexibility once assembled and they are customized to fit a specific scanner's geometry. Timestamp based systems are gathering more attention lately, especially with high channel count fully digital systems. These new systems must however cope with important singles count rates. One option is to record every detected event and postpone coincidence detection offline. For daily use systems, a real time engine is preferable because it dramatically reduces data volume and hence image preprocessing time and raw data management. This paper presents the timestamp based coincidence engine for the LabPET¿, a small animal PET scanner with up to 4608 individual readout avalanche photodiode channels. The engine can handle up to 100 million single events per second and has extensive flexibility because it resides in programmable logic devices. It can be adapted for any detector geometry or channel count, can be ported to newer, faster programmable devices and can have extra modules added to take advantage of scanner-specific features. Finally, the user can select between full processing mode for imaging protocols and minimum processing mode to study different approaches for coincidence detection with offline software.",
Trusted sensors and remote sensing,"Remote trusted operation is essential for many types of sensors in an even greater number of applications. It is often crucial to secure guarantees that a particular sensor sample is taken by a specific sensor at a particular time and stated location. We present the first generic system architecture and security protocol that provides low cost, low power, and low latency trusted remote sensing. The approach employs already known randomized challenges and public physically unclonable function with a new concept of interleaved operational and security circuitry.","Wireless sensor networks,
Sensor systems,
Ad hoc networks,
Cryptography,
Global Positioning System"
Leaf shape identification based plant biometrics,"This paper presents a simple and computationally efficient method for plant species recognition using leaf image. This method works only for the plants with broad flat leaves which are more or less two dimensional in nature. The method consists of five major parts. First, images of leaf are acquired with digital camera or scanners. Then the user selects the base point of the leaf and a few reference points on the leaf blades. Based on these points the leaf shape is extracted from the background and a binary image is produced. After that the leaf is aligned horizontally with its base point on the left of the image. Then several morphological features, such as eccentricity, area, perimeter, major axis, minor axis, equivalent diameter, convex area and extent, are extracted. A unique set of features are extracted from the leaves by slicing across the major axis and parallel to the minor axis. Then the feature pointes are normalized by taking the ratio of the slice lengths and leaf lengths (major axis). These features are used as inputs to the probabilistic neural network. The network was trained with 1200 simple leaves from 30 different plant species. The proposed method has been tested using ten-fold cross-validation technique and the system shows 91.41% average recognition accuracy.","Feature extraction,
Pixel,
Shape,
Accuracy,
Training,
Artificial neural networks,
Probabilistic logic"
Modeling a Student's Behavior in a Tutorial-Like System Using Learning Automata,"This paper presents a new philosophy to model the behavior of a student in a tutorial- like system using learning automata (LAs). The model of the student in our system is inferred using a higher level LA, referred to as a meta-LA , which attempts to characterize the learning model of the students (or student simulators), while the latter use the tutorial-like system. The meta-LA , in turn, uses LAs as a learning mechanism to try to determine if the student in question is a fast, normal, or slow learner. The ultimate long-term goal of the exercise is the following: if the tutorial- like system can understand how the student perceives and processes knowledge, it will be able to customize the way by which it communicates the knowledge to the student to attain an optimal teaching strategy. The proposed meta-LA scheme has been tested for numerous environments, including the established benchmarks, and the results obtained are remarkable. Indeed, to the best of our knowledge, this is the first published result that infers the learning model of an LA when it is externally treated as a black box, whose outputs are the only observable quantities. Additionally, our paper represents a new class of multiautomata systems, where the meta-LA synchronously communicates with the students, also modeled using LAs. The meta-LA's environment ¿observes¿ the progress of the student LA, and the response of the latter to the meta-LA actions is based on these observations. This paper also discusses the learning system implications of such a meta-LA.","Tutorial,
Learning automata,
Adaptive systems,
Learning systems,
Stochastic systems,
Education,
Benchmark testing,
Councils,
Application software,
Artificial intelligence"
Automatic Best Reference Slice Selection for Smooth Volume Reconstruction of a Mouse Brain From Histological Images,"In this paper, we present a novel and effective method for registering histological slices of a mouse brain to reconstruct a 3-D volume. First, intensity variations in images are corrected through an intensity standardization process so that intensity values remain constant across slices. Second, the image space is transformed to a feature space where continuous variables are taken as high fidelity image features for accurate registration. Third, in order to improve the quality of the reconstructed volume, an automatic best reference slice selection algorithm is developed based on iterative assessment of image entropy and mean square error of the registration process. Fourth, a novel metric for evaluating the quality of the reconstructed volume is developed. Finally, the effect of optimal reference slice selection on the quality of registration and subsequent reconstruction is demonstrated.","Image reconstruction,
Mice,
Standardization,
Permission,
Iterative algorithms,
Entropy,
Mean square error methods,
Spatial resolution,
Diseases,
Pathology"
Multi-path transmission control scheme combining bandwidth aggregation and packet scheduling for real-time streaming in multi-path environment,"These days, a wide variety of wireless interfaces are available to connect to Internet. When coverage area of these different technologies overlap, receiver equipped with multiple interfaces can use them simultaneously to improve the performance of its applications in terms of bandwidth rely on bandwidth aggregation. However, specific conditions such as bottleneck bandwidth and end-to-end delay need to be accounted for before using such techniques. If this problem of end-to-end delay and bottleneck bandwidth are not properly addressed, there may be many packets along multiple paths which can arrive late and can lead to a large number of out-of-order packets at the receiver, which can eventually cause serious degradation of video quality at the receiver. For this reason, in this study, the authors propose a multi-path transmission control scheme (MTCS) combining bandwidth aggregation and packet scheduling for real-time streaming in a multi-path environment. In a bandwidth aggregation scheme, the authors propose a mathematical model to find the transmission rate over each path in order to obtain the optimal total throughput. However, the end-to-end delay of each path is not the same. The out-of-order packets problem will become serious in a multi-path environment. Therefore the authors propose a packet scheduling scheme to arrange the transmission sequence in order to effectively minimise the impact of packet reordering at the receiver. Our proposed control scheme not only aggregates the available bandwidth of multiple paths, but also reduces the time of packet reordering at the receiver. Experimental results show with our proposed scheme, the authors not only obtain the optimal transmission throughput but also reduce packet reordering delays under varying drop and delay conditions caused by the underlying network.",
Keyframe detection for appearance-based visual SLAM,"This paper is concerned with the problem of keyframe detection in appearance-based visual SLAM. Appearance SLAM models a robot's environment topologically by a graph whose nodes represent strategically interesting places that have been visited by the robot and whose arcs represent spatial connectivity between these places. Specifically, we discuss and compare various methods for identifying the next location that is sufficiently different visually from the previously visited location or node in the map graph in order to decide whether a new node should be created. We survey existing techniques of keyframe detection in image retrieval and video analysis. Using experimental results obtained from visual SLAM datasets, we conclude that the feature matching method offers the best performance among five representative methods in terms of accurately measuring the amount of appearance change between robot's views and thus can serve as a simple and effective metric for detecting keyframes. This study fills an important but missing step in the current appearance SLAM research.","Visualization,
Feature extraction,
Simultaneous localization and mapping,
Histograms,
Laboratories,
Pixel"
Speaker identification by combining MFCC and phase information in noisy environments,"In conventional speaker recognition methods based on MFCC, the phase information has been ignored. Recently, we proposed a method that integrated MFCC with the phase information on a speaker recognition method. Using the phase information, the speaker identification error rate was reduced by 78% for clean speech. In this paper, we describe the effectiveness of phase information for noisy environments on speaker identification. Integrationg MFCC with phase information, the speaker error identification rates were reduced by 20%∼70% in comparison with using only MFCC in noisy environments.","Mel frequency cepstral coefficient,
Working environment noise,
Phase noise,
Speaker recognition,
Speech analysis,
Cepstral analysis,
Data mining,
Linear predictive coding,
Humans,
Speech recognition"
Design of a comparator tree based on reversible logic,"The existing design of reversible n-bit binary comparator that compares two n-bit numbers is a serial design [1] having the latency of O(n). In this work, we present a new reversible n-bit binary comparator based on binary tree structure that has the latency of O(log2(n)). The reversible designs are based on a new reversible gate called the TR gate, the improved quantum cost of which is also derived in this work. In the proposed reversible binary tree comparator each node consists of a 2-bit reversible binary comparator that can compare two 2-bit numbers x(xi, xi−1) and y(yi, yi−1), to generate two 1-bit outputs Y and Z. Y will be 1 if x(xi, xi−1)> y(yi, yi−1), and Z will be 1 if x(xi, xi−1)&#60;y(yi, yi−1). After careful analysis, we modified the logic equations of Y = x1 ȳ1 ⨁ kx0ȳ0 and Z =x̄1y1 ⨁ kx̄0y0 to Y = x1ȳ1 ⨁ kx0ȳ0 and Z = x̄1y1 ⨁ kx̄0y0, respectively. The replacement of + operator with ⨁ operator without affecting the functionality of the design helped us in reversible mapping of the equations of Y and Z on the third output of the TR gate which is R=AB̄ ⨁ C. Further, TR gate can also efficiently generate functions such as x0ȳ0 and x̄0y0. In the proposed reversible binary comparator, the leaf nodes will consist of 2-bit reversible binary comparators. Each internal node (2-bit reversible binary comparator) of the binary tree receives the partial comparison results from the left and the right children and propagates the 2-bit output of the comparison to its parent. Finally, the root node which is also a 2-bit reversible binary comparator generates the 2-bit result of the comparison of the n-bit numbers x and y to evaluate whether x>y or x&#60;y. The 2-bit result of the root node are passed to the reversible output circuit designed from a Toffoli gate and 4 NOT gates to generate three signals O0(x&#60;y), O1(x>y) and O2(x=y).","Logic gates,
Delay,
Binary trees,
Equations,
Propagation delay,
Quantum computing,
Boolean functions"
A CMOS Outphasing Power Amplifier With Integrated Single-Ended Chireix Combiner,This brief proposes an on-chip outphasing power amplifier that uses a single-ended Chireix combiner for a linear amplification with a nonlinear component amplifier. The proposed combiner structure consists of a lumped inductor and a lumped capacitor that can achieve the simple single-ended configuration of a Chireix combiner. It is also suitable for on-chip implementation with minimum efficiency deterioration. An inductance-capacitance balun using the lumped model of λ/4 and 3λ/4 transmission lines was effectively merged into a simple Chireix combiner for two outphased input signals. The relation between the output resistance and the outphasing angle of the input signals was derived to determine the maximum efficiency. A voltage-mode class-D power amplifier was used with the combiner to illustrate the combiner's effectiveness. The prototype fabricated in a 0.13-μm complementary metal-oxide-semiconductor process shows a maximum 52% power-added efficiency (continuous wave) and a -47-dBc adjacent channel power ratio performance at a 10-MHz offset with a 1.92-GHz wideband code-division multiple-access signal.,"Power amplifiers,
Inductors,
Capacitors,
Impedance matching,
Power transmission lines,
Voltage,
Broadband amplifiers,
Prototypes,
Wideband,
Multiaccess communication"
Reliable histogram features for detecting LSB matching,"This paper proposes a novel steganalyzer for detecting one of the most popular steganography, LSB matching (also known as “±1 embedding”). The histogram of difference image (the differences of adjacent pixels), which is usually a generalized Gaussian distribution centered at 0, is exploited for deriving statistical features. We have proved theoretically that the peak-value of the histogram would decrease after LSB matching embedding, while the renormalized histogram (the ratio of the histogram to the peak-value) would increase. Then we take the peak-value and the renormalized histogram as features for classification. Extensive experimental results show that the proposed steganalytic method outperforms some previous ones.",
"Connectivity in Selfish, Cooperative Networks","This paper studies the connectivity of large cooperative ad hoc networks. Unlike existing work where all nodes are assumed to transmit cooperatively, the cooperative network we consider is realistic as we assume that not all nodes are willing to collaborate when relaying other nodes' traffic. For such selfish, cooperative network, we use stochastic geometry and percolation theory to analyze the connectivity and provide an upper bound of critical node density when the network percolates.",
NTHU-Route 2.0: A Robust Global Router for Modern Designs,"This paper presents a robust global router called NTHU-Route 2.0 that improves the solution quality and runtime of NTHU-Route by the following enhancements: 1) a new history based cost function; 2) new ordering methods for congested region identification and rip-up and reroute; and 3) two implementation techniques. We report convincing experimental results to show the effectiveness of each individual enhancement. With all these enhancements together, NTHU-Route 2.0 solves all ISPD98 benchmarks with very good quality. Moreover, NTHU-Route 2.0 routes 7 of 8 ISPD07 benchmarks and 12 of 16 ISPD08 benchmarks without any overflow. Compared with other state-of-the-art global routers, NTHU-Route 2.0 is able to produce better solution quality and/or run more efficiently.",
Homogenization of Form-Wound Windings in Frequency and Time Domain Finite-Element Modeling of Electrical Machines,"In this paper, the authors deal with the finite-element (FE) modeling of eddy-current effects in form-wound windings of electrical machines using a previously proposed general frequency- and time-domain homogenization method. By way of demonstration and validation, a real-life 1250-kW induction machine with double-layer stator winding is considered. The skin and proximity effects in one stator conductor (copper bar) are first quantified by means of a simple low-cost FE model, leading to complex and frequency-dependent coefficients for the homogenized winding (reluctivity for proximity effect and conductivity or resistance for skin effect). These complex coefficients are subsequently translated into real-valued and constant coefficients that allow for time-domain homogenization when introducing a limited number of additional degrees of freedom in the FE model. All results obtained with the homogenized model (considering one conductor or a complete slot) agree well with those produced by a brute-force approach (modeling and finely discretizing each conductor).","Machine windings,
Finite element methods,
Iron,
Conductors,
Frequency,
Time domain analysis,
Stator windings,
Proximity effect,
Induction machines,
Skin"
Selective flyback balancing circuit with improved balancing speed for series connected Lithium-ion batteries,"In this paper, a cell balancing circuit for the Lithium-ion battery string based on the Flyback topology is proposed. The proposed circuit draws the charge out of the high voltage cell and recovers it to the overall battery pack. With the selectivity of the target cell, the proposed circuit uses the minimized power path to simplify the circuit and optimize the balancing efficiency. The circuit also employs the peak current mode control scheme to accelerate the balancing speed and reduce the balancing time. Experimental results with the laboratory prototype hardware for multi-cell battery string verify the feasibility of the proposed scheme.","Circuits,
Batteries,
Switches,
Voltage,
Pulse width modulation,
Ice,
Silicon compounds,
Diodes,
Equalizers,
DC-DC power converters"
An Energy-Efficient Error Correction Scheme for IEEE 802.15.4 Wireless Sensor Networks,"In this paper, we validate a novel augmentation to the physical layer (PHY) of the IEEE 802.15.4 standard for wireless sensor networks. This augmentation implements interleaving and forward error correction (FEC) encoding within sensor node transmitters, facilitating a significant reduction in their transmission energy. We detail the design, parameterization, and implementation of this FEC encoder and show that it has insignificant energy consumption compared with the transmission energy reduction that it affords. Our analysis shows that net energy savings of 24.8%-31.4% can be achieved by the augmented PHY.","Energy efficiency,
Error correction,
Wireless sensor networks,
Physical layer,
Forward error correction,
Energy consumption,
Transmitters,
Payloads,
Interleaved codes,
Sensor systems"
Traffic grooming and regenerator placement in impairment-aware optical WDM networks,"In this paper, we address the problem of traffic grooming and regenerator placement in a WDM optical network in which lightpaths are hop-constrained by physical impairments. The efficient placement of regenerators and electronic grooming equipment at ROADM nodes for a given network topology is required such that all traffic demands can be supported with minimum cost. We present a detailed ROADM node architecture together with an associated cost model, and we propose an auxiliary-graph-based heuristic for jointly placing regenerators and electronic grooming equipment in the network. The numerical results show that combining the grooming problem with the placement of regenerators reduces the network cost significantly compared to the cases in which traffic grooming and regenerator placement are handled separately.",
Four-Terminal-Relay Body-Biasing Schemes for Complementary Logic Circuits,"Four-terminal-relay inverter circuit characteristics are investigated. To achieve maximum noise margin and zero crowbar current while allowing for relay-to-relay variations, the optimal biasing scheme provides for switching that is symmetric about VDD/2 with minimum hysteresis and no possibility of both the pull-down and pull-up devices being on simultaneously.",
The Effect of Local Scattering on the Gain and Beamwidth of a Collaborative Beampattern for Wireless Sensor Networks,"Collaborative beamforming is an approach where sensor nodes in a wireless sensor network, deployed randomly in an area of interest, transmit a common message by forming a beampattern towards a destination. Previous statistical analysis of the averaged power beampattern considered multipath-free conditions. Herein, we express the averaged power beampattern when the signal is observed at the destination in the presence of local scattering. Assuming the spreading angles are uniformly distributed around the destination direction, we derive closed-form expressions for the maximum gain and numerically examine the beamwidth as a function of the number of nodes, the cluster size, and the scattering parameters, for node positions with a uniform distribution or a Gaussian distribution.","Collaboration,
Wireless sensor networks,
Array signal processing,
Sensor arrays,
Gaussian distribution,
Temperature sensors,
Statistical analysis,
Scattering parameters,
Remote monitoring,
Land surface temperature"
A Motion-Aligned Auto-Regressive Model for Frame Rate Up Conversion,"In this paper, a motion-aligned auto-regressive (MAAR) model is proposed for frame rate up conversion, where each pixel is interpolated as the average of the results generated by one forward MAAR (Fw-MAAR) model and one backward MAAR (Bw-MAAR) model. In the Fw-MAAR model, each pixel in the to-be-interpolated frame is generated as a linear weighted summation of the pixels within a motion-aligned square neighborhood in the previous frame. To derive more accurate interpolation weights, the aligned actual pixels in the following frame are also estimated as a linear weighted summation of the newly interpolated pixels in the to-be-interpolated frame by the same weights. Consequently, the backward-aligned actual pixels in the following frame can be estimated as a weighted summation of the corresponding pixels within an enlarged square neighborhood in the previous frame. The Bw-MAAR is performed likewise except that it is operated in the reverse direction. A damping Newton algorithm is then proposed to compute the adaptive interpolation weights for the Fw-MAAR and Bw-MAAR models. Extensive experiments demonstrate that the proposed MAAR model is able to achieve superior performance than the traditional frame interpolation methods such as MCI, OBMC, and AOBMC, and it is even better than STAR model for the most test sequences with moderate or large motions.","Interpolation,
Motion compensation,
Telecommunications,
Computer science,
Damping,
Testing,
Image reconstruction,
Research and development,
Video coding,
Decoding"
A Simple Approach to Multiview Face Hallucination,Most face hallucination methods are usually limited to frontal face with small pose variations. This letter presents a simple and efficient multiview face hallucination (MFH) method to generate high-resolution (HR) multiview faces from a single given low-resolution (LR) one. The problem is addressed in two steps. A simple face transformation method is proposed by defining a constrained least square problem for LR multiview face transformation and a position-patch based face hallucination method is extended to incorporate HR multiview face details. Experimental results show that our approach has some advantages over existing MFH methods.,"Tensile stress,
Strontium,
Image sequences,
Principal component analysis,
Face recognition,
Active appearance model,
Least squares methods,
Image generation,
Cameras,
Computer science"
Reconciling 3-D Mixed-Mode Simulations and Measured Single-Event Transients in SiGe HBTs,"Comprehensive 3-D mixed-mode simulations, including accurate modeling of parasitic elements present in the experimental setup, resulted in close agreement between simulated and experimentally-measured heavy-ion-induced transients in first-generation SiGe HBTs. We have identified the key factors affecting previous simulations and observed experimental differences. The approach employed is also applicable to other submicron, high-speed technologies. Furthermore, we present a plausible answer to the previously unexplained issue of higher collector currents in single-transistor SiGe HBT single-event transients under positive collector bias. The new observations and conclusions facilitate improved understanding and potential mitigation options.","Semiconductor device modeling,
Radiation effects,
Radiation hardening,
Silicon germanium,
Single event transient,
Heterojunction bipolar transistors"
FAMPER: A fully autonomous mobile robot for pipeline exploration,"Pipeline-based applications have become an integral part of life. However, knowing that the pipeline systems can be largely deployed in an inaccessible and hazardous environment, active monitoring and frequent inspection of the pipeline systems are highly expensive using the traditional maintenance systems. Robot agents have been considered as an attractive alternative. Although many different types of pipeline exploration robots have been proposed, they were suffered from various limitations. In this paper, we present the design and implementation of a single-moduled fully autonomous mobile pipeline exploration robot, called FAMPER, that can be used for the inspection of 150mm pipelines. This robot consists of four wall-press caterpillars operated by two DC motors each. The speed of each caterpillar is controlled independently to provide steering capability to go through 45 degree elbows, 90 degree elbows, T-branches, and Y-branches. The uniqueness of this paper is to show the opportunity of using 4 caterpillar configuration for superior performance in all types of complex networks of pipelines. The robot system has been developed and experimented in different pipeline layouts.","Mobile robots,
Pipelines,
Inspection,
Elbow,
Wheels,
DC motors,
Prototypes,
Orbital robotics,
Computer science,
Application software"
An Abuse-Free Fair Contract-Signing Protocol Based on the RSA Signature,"A fair contract-signing protocol allows two potentially mistrusted parities to exchange their commitments (i.e., digital signatures) to an agreed contract over the Internet in a fair way, so that either each of them obtains the other's signature, or neither party does. Based on the RSA signature scheme, a new digital contract-signing protocol is proposed in this paper. Like the existing RSA-based solutions for the same problem, our protocol is not only fair, but also optimistic, since the trusted third party is involved only in the situations where one party is cheating or the communication channel is interrupted. Furthermore, the proposed protocol satisfies a new property- abuse-freeness. That is, if the protocol is executed unsuccessfully, none of the two parties can show the validity of intermediate results to others. Technical details are provided to analyze the security and performance of the proposed protocol. In summary, we present the first abuse-free fair contract-signing protocol based on the RSA signature, and show that it is both secure and efficient.","Contracts,
Cryptographic protocols,
Computer networks,
Digital signatures,
Internet,
Communication channels,
Security,
Electronic commerce,
Performance analysis,
Law"
InterMR: Inter-MANET routing in heterogeneous MANETs,"The advancements of diverse radio technologies and emerging applications have spawned increasing heterogeneity in mobile ad hoc networks (MANETs). But the collaborative nature of communications and operations often requires that these heterogeneous MANETs to be interoperable. Nonetheless, the existing interconnection protocols designed for the Internet (namely inter-domain routing protocol such as BGP) are not adequate for handling the unique challenges in MANETs. In this paper, we present a novel Inter-MANET Routing protocol called InterMR that can handle the heterogeneity and dynamics of MANETs. Our first contribution is an Inter-MANET address scheme based on a variety of node attributes (e.g., symbolic name, property, etc.); this allows dynamic merging/split of network topologies without a separate Name Server. Our second contribution is to provide a seamless routing mechanism across heterogeneous MANETs without modifying the internal routing mechanisms in each MANET. The proposed scheme can transparently adapt to topological changes due to node mobility in MANETs by dynamically assigning the gateway functionalities. We show, by packet-level simulation, that the performance of InterMR can be improved by up to 112% by adaptive gateway assignment functionalities. We also show that InterMR is scalable with only modest overhead by analysis.","Ad hoc networks,
Mobile computing,
Logic gates,
Routing,
Routing protocols,
Topology"
Estimation of Whole-Body Average SAR in Human Models Due to Plane-Wave Exposure at Resonance Frequency,"This study proposes an equation for estimating whole-body average specific absorption rate (WBSAR) in human body models for plane-wave exposure at whole-body resonance frequency. This study is important because the WBSAR takes maximal at this frequency and approaches the basic restrictions in the international guidelines/standards for human protection. Therefore, the variability of the WBSAR at this frequency has attracted a great deal of attention. First, the dominant factors influencing the resonance frequency of the human body models are investigated for plane-wave exposures. An equation for estimating the WBSAR at the resonance frequency is then proposed based on an analogy to an antenna. This equation can estimate the WBSAR with the body mass index of the human body only for a given incident power density. The uncertainty of the WBSAR estimated with the proposed equation is approximately 10%, which is mainly attributed to the electrical constants of tissue, including the inhomogeneity of the human body model. The variability of the WBSAR due to the body shape was found to be 30% for humans of the same age.","Resonant frequency,
Humans,
Mathematical model,
Pediatrics,
Biological system modeling,
Nonhomogeneous media,
Equations"
"Cinematic Visual Discourse: Representation, Generation, and Evaluation","In this paper, we present the design, implementation, and evaluation of an end-to-end camera planning system called Darshak. Darshak automatically constructs cinematic narrative discourse of a given story in a 3-D virtual environment. It utilizes a hierarchical partial-order causal link (POCL) planning algorithm to generate narrative plans that contain story events and camera directives for filming them. Dramatic situation patterns, commonly used by writers of fictional narratives, are formalized as communicative plan operators that provide a basis for structuring the cinematic content of the story's visualization. The dramatic patterns are realized through abstract communicative operators that represent operations on a viewer's beliefs about the story and its telling. Camera shot compositions and transitions are defined in this plan-based framework as execution primitives. Darshak's performance is evaluated through a novel user study based on techniques used to evaluate existing cognitive models of narrative comprehension. Initial study reveals significant effect of the choice of visualization strategies on measured viewer comprehension. It further shows significant effect of Darshak's choice of visualization strategy on comprehension.","Visualization,
Smart cameras,
Computational modeling,
Artificial intelligence,
Computational intelligence,
Virtual environment,
Natural languages,
Engineering profession,
Lifting equipment,
Computer science"
People tracking using integrated sensors for human robot interaction,"In human-human interaction, position and orientation of participants' bodies and faces play an important role. Thus, robots need to be able to detect and track human bodies and faces, and obtain human positions and orientations to achieve effective human-robot interaction. It is difficult, however, to robustly obtain such information from video cameras alone in complex environments. Hence, we propose to use integrated sensors that are composed of a laser range sensor and an omni-directional camera. A Rao-Blackwellized particle filter framework is employed to track the position and orientation of both bodies and heads of people based on the distance data and panorama images captured from the laser range sensor and the omni-directional camera. In addition to the tracking techniques, we present two applications of our integrated sensor system. One is a robotic wheelchair moving with a caregiver; the sensor system detects and tracks the caregiver and the wheelchair moves with the caregiver based on the tracking results. The other is a museum guide robot that explains exhibits to multiple visitors; the position and orientation data of visitors' bodies and faces enable the robot to distribute its gaze to each of multiple visitors to keep their attention while talking.","Human robot interaction,
Face detection,
Robot sensing systems,
Cameras,
Mobile robots,
Robot vision systems,
Sensor systems,
Wheelchairs,
Robustness,
Particle filters"
on-State Hot Carrier Degradation in Drain-Extended NMOS Transistors,"A close analysis of the universality of OFF-state hot carrier degradation (HCI) in drain-extended transistors suggests that on-state HCI degradation should likewise be universal. In this paper, we confirm this hypothesis through an extensive set of experiments on drain-extended n-channel metal-oxide-semiconductor (DeNMOS) transistors and demonstrate that the underlying mechanism for both OFF- and ON-state degradation are essentially identical (even though the drain current differs by several orders of magnitude for the respective stress bias conditions). We show how this universality of ON- and OFF-state hot carrier degradations allows the use of short-term measurements to predict device lifetime under arbitrary operating conditions.","Degradation,
Stress,
Hot carriers,
Logic gates,
Transistors,
Charge pumps,
Current measurement"
WARPWING: A complete open source control platform for miniature robots,"The electronics packages for many robot control systems have very similar requirements, yet are often redesigned for each custom application. To reduce wasted time and effort, the project presented in this paper (the Wireless Autonomous Robot Platform with Inertial Navigation and Guidance, WARP-WING) is intended to create a complete and easily customizable general purpose control system for miniature robotic systems, in particular micro air vehicles. In its default configuration, hardware designs, firmware, and software are all available to deliver an out-of-the-box robot control solution comprising 6 degree-of-freedom inertial sensors, a microprocessor, and wireless communication, along with general purpose input/output pins, serial ports, and control outputs for interfacing to additional sensors and actuators. The entire project is open source and a process is in place to enable modification of any component, allowing for easy adaptation to any need. WARPWING is already in use in a number of labs, with each research group contributing its expertise to enhance the platform and make such modifications available to others as well.",
Multicast Recipient Maximization in IEEE 802.16j WiMAX Relay Networks,"In this paper, we propose a resource-allocation scheme for multicast service in downlink transmission for IEEE 802.16j WiMax relay networks. Most existing algorithms try to minimize the total energy of a multicast tree. In contrast, we address the multicast recipient maximization (MRM) problem, which maximizes the total number of recipients with the given budget by adjusting the distribution of the allocated resource between the base station and the relay nodes. We prove that MRM is NP-complete and propose a polynomial-time scheme called dynamic station selection (DSS) to solve the problem based on the proposed auxiliary graph. Based on the provided lemmas, which serve as important guidelines for solving similar problems, we show that our heuristic algorithm has polynomial-time complexity and prove that its performance is bound to the optimum. The results of simulations demonstrate that, given different amounts of resource and variable channel conditions, the performance of DSS is always close to the optimum. Moreover, DSS more efficiently utilizes resources as the node density increases, resulting in more efficient resource allocation.","WiMAX,
Relays,
Decision support systems,
Resource management,
Polynomials,
Downlink,
Multicast algorithms,
Base stations,
Guidelines,
Heuristic algorithms"
Novel and Simple High-Frequency Single-Port Vector Network Analyzer,"Portable, accurate, and relatively inexpensive high-frequency vector network analyzers (VNAs) have great utility for a wide range of applications, encompassing microwave circuit characterization, reflectometry, imaging, material characterization, and nondestructive testing to name a few. To meet the rising demand for VNAs possessing the aforementioned attributes, we present a novel and simple VNA design based on a standing-wave probing device and an electronically controllable phase shifter. The phase shifter is inserted between a device under test (DUT) and a standing-wave probing device. The complex reflection coefficient of the DUT is then obtained from multiple standing-wave voltage measurements taken for several different values of the phase shift. The proposed VNA design eliminates the need for expensive heterodyne detection schemes required for tuned-receiver-based VNA designs. Compared with previously developed VNAs that operate based on performing multiple power measurements, the proposed VNA utilizes a single power detector without the need for multiport hybrid couplers. In this paper, the efficacy of the proposed VNA is demonstrated via numerical simulations and experimental measurements. For this purpose, measurements of various DUTs obtained using an X-band (8.2-12.4 GHz) prototype VNA are presented and compared with results obtained using an Agilent HP8510C VNA. The results show that the proposed VNA provides highly accurate vector measurements with typical errors on the order of 0.02 and 1° for magnitude and phase, respectively.","Phase shifters,
Image analysis,
Microwave devices,
Microwave circuits,
Reflectometry,
Microwave imaging,
Nondestructive testing,
Reflection,
Voltage measurement,
Performance evaluation"
Improving the visual analysis of high-dimensional datasets using quality measures,"Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task.",
Throughput analysis for a contention-based dynamic spectrum sharing model,"In this paper we present throughput analysis for a contention-based dynamic spectrum sharing model. We consider two scenarios of allocating channels to primary users, fixed allocation and random allocation. In fixed allocation, the number of primary users allocated to a channel is fixed all the time, but the number of users in different channels may be different. In random allocation, each primary user dynamically and randomly selects a channel in each time slot. We assume that the spectrum band of primary users is divided into multiple channels and the time is slotted. Primary users allocated to a specific channel compete to access this channel in each time slot. Secondary users are able to dynamically detect the idle channels in each time slot, and compete to access these channels. We develop analytical models for the throughput of primary users and secondary users in both scenarios and examine the impact of the number of secondary users on the throughput of the system. For a given number of primary users, channels and traffic generation probability, we aim to find the number of secondary users to maximize the total throughput of both primary users and secondary users. Our solutions match closely with the numerical results.","Throughput,
Cognitive radio,
Radio spectrum management,
Computer science,
Analytical models,
Telecommunication traffic,
Traffic control,
Radio frequency,
Engineering profession"
Analysis of the Role of Lead Resistivity in Specific Absorption Rate for Deep Brain Stimulator Leads at 3T MRI,"Magnetic resonance imaging (MRI) on patients with implanted deep brain stimulators (DBSs) can be hazardous because of the antenna-effect of leads exposed to the incident radio-frequency field. This study evaluated electromagnetic field and specific absorption rate (SAR) changes as a function of lead resistivity on an anatomically precise head model in a 3T system. The anatomical accuracy of our head model allowed for detailed modeling of the path of DBS leads between epidermis and the outer table. Our electromagnetic finite difference time domain (FDTD) analysis showed significant changes of 1 g and 10 g averaged SAR for the range of lead resistivity modeled, including highly conductive leads up to highly resistive leads. Antenna performance and whole-head SAR were sensitive to the presence of the DBS leads only within 10%, while changes of over one order of magnitude were observed for the peak 10 g averaged SAR, suggesting that local SAR values should be considered in DBS guidelines. With ¿lead = ¿copper , and the MRI coil driven to produce a whole-head SAR without leads of 3.2 W/kg, the 1 g averaged SAR was 1080 W/kg and the 10 g averaged SAR 120 W/kg at the tip of the DBS lead. Conversely, in the control case without leads, the 1 g and 10 g averaged SAR were 0.5 W/kg and 0.6 W/kg, respectively, in the same location. The SAR at the tip of lead was similar with electrically homogeneous and electrically heterogeneous models. Our results show that computational models can support the development of novel lead technology, properly balancing the requirements of SAR deposition at the tip of the lead and power dissipation of the system battery.","Conductivity,
Specific absorption rate,
Magnetic resonance imaging,
Satellite broadcasting,
Magnetic heads,
Electromagnetic modeling,
Finite difference methods,
Time domain analysis,
Power system modeling,
Magnetic analysis"
Location Privacy against Traffic Analysis Attacks in Wireless Sensor Networks,"Traffic analysis attacks are passive attacks that try to deduce the traffic pattern based on the eavesdropped information. Through analyzing the packet traffic, it can deduce the location of strategic nodes, and then launch an active attack to those locations, such as DoS attack. Therefore, defending against a traffic analysis attack is to prevent the adversary from tracing the location of critical sensor nodes. Due to the open wireless communication media exposing the context information to adversaries, we cannot use traditional encryption and authentication to prevent the adversaries from eavesdropping on the wireless communication. In this paper, we propose three schemes to defend against the traffic analysis attacks. Firstly, a random routing scheme (RRS) is proposed to provide path diversity. Secondly, we combine RRS with a dummy packet injection scheme (DPIS) to confuse the adversary by tracing or tracing back the forwarded packet to reach the receiver or source. Finally, an anonymous communication scheme (ACS) is proposed to hide the identities of all nodes that participate in packets transmission. Through security analysis and simulation, we can see that our proposed schemes can efficiently defend against traffic analysis attacks, take less delivery time and achieve uniform energy consumption.","Privacy,
Telecommunication traffic,
Wireless sensor networks,
Wireless communication,
Information analysis,
Pattern analysis,
Computer crime,
Context,
Cryptography,
Authentication"
Sensor-Mission Assignment in Constrained Environments,"When a sensor network is deployed in the field it is typically required to support multiple simultaneous missions, which may start and finish at different times. Schemes that match sensor resources to mission demands thus become necessary. In this paper, we consider new sensor-assignment problems motivated by frugality, i.e., the conservation of resources, for both static and dynamic settings. In the most general setting, the problems we study are NP-hard even to approximate, and so we focus on heuristic algorithms that perform well in practice. In the static setting, we propose a greedy centralized solution and a more sophisticated solution that uses the Generalized Assignment Problem model and can be implemented in a distributed fashion. In what we call the dynamic setting, missions arrive over time and have different durations. For this setting, we give heuristic algorithms in which available sensors propose to nearby missions as they arrive. We find that the overall performance can be significantly improved if available sensors sometimes refuse to offer utility to missions they could help, making this decision based on the value of the mission, the sensor's remaining energy, and (if known) the remaining target lifetime of the network. Finally, we evaluate our solutions through simulations.","Computer science,
Heuristic algorithms,
Resource management,
Batteries,
Waste materials,
Monitoring,
Cameras,
Information geometry,
Costs"
An Integrated EMI Choke for Differential-Mode and Common-Mode Noise Suppression,"This letter presents a novel integration approach for the electromagnetic interference choke. A low-permeability differential-mode (DM) choke is placed within the open window of the common-mode (CM) choke. Both chokes share the same winding structure. With the proposed approach, the footprint of inductors is greatly reduced, and high-DM inductance can be achieved. First, small-signal measurement is carried out to demonstrate the design concept and the symmetry of the proposed structure. Then large-signal experimental results verify the attenuation characteristics, as well as the thermal performance.",
Security management under uncertainty: From day-ahead planning to intraday operation,"In this paper, we propose to analyse the practical task of dealing with uncertainty for security management by Transmission System Operators in the context of day-ahead planning and intraday operation. We propose a general but very abstract formalization of this task in the form of a three-stage decision making problem under uncertainties in the min-max framework, where the three stages of decision making correspond respectively to operation planning, preventive control in operation, and post-contingency emergency control. We then consider algorithmic solutions for addressing this problem in the practical context of large scale power systems by proposing a bi-level linear programming formulation adapted to the case where security is constrained by power flow limits. This formulation is illustrated on two case studies corresponding respectively to a synthetic 7-bus system and the IEEE 30-bus system.","Uncertainty,
Security,
Mathematical model,
Planning,
Optimization,
Decision making,
Equations"
Anonymous User Communication for Privacy Protection in Wireless Metropolitan Mesh Networks,"As a combination of ad hoc networks and wireless local area network (WLAN), the wireless mesh network (WMN) provides a low-cost convenient solution to the last-mile network-connectivity problem. As such, existing route protocols designed to provide security and privacy protection for ad hoc networks are no longer applicable in WMNs. On the other hand, little research has focused on privacy-preserving routing for WMNs. In this paper, we propose two solutions for security and privacy protection in WMNs. The first scheme relies on group signatures, together with user credentials, to deliver security and privacy protection. By enforcing access control using user credentials, the user's identity has to be disclosed to mesh routers. To avoid this, our second scheme employs pairwise secrets between any two users to achieve stronger privacy protection. In the second scheme, the user is kept anonymous to mesh routers. Finally, we analyze these two schemes in terms of security, privacy, and performance.",
Learning Object Categories From Internet Image Searches,"In this paper, we describe a simple approach to learning models of visual object categories from images gathered from Internet image search engines. The images for a given keyword are typically highly variable, with a large fraction being unrelated to the query term, and thus pose a challenging environment from which to learn. By training our models directly from Internet images, we remove the need to laboriously compile training data sets, required by most other recognition approaches-this opens up the possibility of learning object category models “on-the-fly.” We describe two simple approaches, derived from the probabilistic latent semantic analysis (pLSA) technique for text document analysis, that can be used to automatically learn object models from these data. We show two applications of the learned model: first, to rerank the images returned by the search engine, thus improving the quality of the search engine; and second, to recognize objects in other image data sets.","Internet,
Search engines,
Image recognition,
Image analysis,
Councils,
Computer science,
Object recognition,
Training data,
Text recognition,
Text analysis"
Multiple relative pose graphs for robust cooperative mapping,"This paper describes a new algorithm for cooperative and persistent simultaneous localization and mapping (SLAM) using multiple robots. Recent pose graph representations have proven very successful for single robot mapping and localization. Among these methods, incremental smoothing and mapping (iSAM) gives an exact incremental solution to the SLAM problem by solving a full nonlinear optimization problem in real-time. In this paper, we present a novel extension to iSAM to facilitate online multi-robot mapping based on multiple pose graphs. Our main contribution is a relative formulation of the relationship between multiple pose graphs that avoids the initialization problem and leads to an efficient solution when compared to a completely global formulation. The relative pose graphs are optimized together to provide a globally consistent multi-robot solution. Efficient access to covariances at any time for relative parameters is provided through iSAM, facilitating data association and loop closing. The performance of the technique is illustrated on various data sets including a publicly available multi-robot data set. Further evaluation is performed in a collaborative helicopter and ground robot experiment.","Robustness,
Simultaneous localization and mapping,
Orbital robotics,
Robot sensing systems,
Smoothing methods,
Computational efficiency,
Space technology,
Robotics and automation,
USA Councils,
Optimization methods"
Minimizing write activities to non-volatile memory via scheduling and recomputation,"Non-volatile memories, such as flash memory, Phase Change Memory (PCM), and Magnetic Random Access Memory (MRAM), have many desirable characteristics for embedded DSP systems to employ them as main memory. These characteristics include low-cost, shock-resistivity, non-volatility, power-economy and high density. However, there are two common challenges we need to answer before we can apply non-volatile memory as main memory practically. First, non-volatile memory has limited write/erase cycles compared to DRAM. Second, a write operation is slower than a read operation on non-volatile memory. These two challenges can be answered by reducing the number of write activities on non-volatile main memory. In this paper, we propose two optimization techniques, write-aware scheduling and recomputation, to minimize write activities on non-volatile memory. With the proposed techniques, we can both speed up the completion time of programs and extend non-volatile memory's lifetime. The experimental results show that the proposed techniques can reduce the number of write activities on non-volatile memory by 55.71% on average. Thus, the lifetime of non-volatile memory is extend to 2.5 times as long as before on average. The completion time of programs can be reduced by 55.32% on systems with NOR flash memory and by 40.69% on systems with NAND flash memory on average.","Nonvolatile memory,
Random access memory,
Digital signal processing,
Phase change materials,
Read-write memory,
Flash memory,
Embedded system,
Scanning probe microscopy,
Computer science,
Phase change memory"
VDBench: A Benchmarking Toolkit for Thin-Client Based Virtual Desktop Environments,"The recent advances in thin client devices and the push to transition users' desktop delivery to cloud environments will eventually transform how desktop computers are used today. The ability to measure and adapt the performance of virtual desktop environments is a major challenge for ''virtual desktop cloud'' service providers. In this paper, we present the ''VD Bench'' toolkit that uses a novel methodology and related metrics to benchmark thin-client based virtual desktop environments in terms of scalability and reliability. We also describe how we used a VD Bench instance to benchmark the performance of: (a) popular user applications (Spreadsheet Calculator, Internet Browser, Media Player, Interactive Visualization), (b) TCP/UDP based thin client protocols (RDP, RGS, PCoIP), and (c) remote user experience (interactive response times, perceived video quality), under a variety of system load and network health conditions. Our results can help service providers to mitigate over-provisioning in sizing virtual desktop resources, and guesswork in thin client protocol configurations, and thus obtain significant cost savings while simultaneously fostering satisfied customers.","Benchmark testing,
Protocols,
Memory management,
Servers,
Time factors,
Measurement,
Driver circuits"
CFO Estimation and Compensation in SC-IFDMA Systems,"Single carrier interleaved frequency division multiple access (SC-IFDMA) has been recently receiving much attention for uplink multiuser access in the next generation mobile systems because of its lower peak-to-average transmit power ratio (PAPR). In this paper, we investigate the effect of carrier frequency offset (CFO) on SC-IFDMA and propose a new low-complexity time domain linear CFO compensation (TD-LCC) scheme. The TD-LCC scheme can be combined with successive interference cancellation (SIC) to further improve the system performance. The combined method will be referred to as TD-CC-SIC. We shall study the use of user equipment (UE) ordering algorithms in our TD-CC-SIC scheme and propose both optimal and suboptimal ordering algorithms in the MMSE sense. We also analyze both the output SINR and the BER performance of the proposed TD-LCC and TD-CC-SIC schemes. Simulation results along with theoretical SINR and BER results will show that the proposed TD-LCC and TD-CC-SIC schemes greatly reduce the CFO effect on SC-IFDMA. We also propose a new blind CFO estimation scheme for SC-IFDMA systems when the numbers of subcarrier sets allocated to different UEs are not the same due to their traffic requirements. Compared to the conventional blind CFO estimation schemes, it is shown that by using a virtual UE concept, the proposed scheme does not have the CFO ambiguity problem, and in some cases can improve the throughput efficiency since it does not need to increase the length of cyclic prefix (CP).","Interference,
Estimation,
Time domain analysis,
Frequency domain analysis,
Signal to noise ratio,
Sparse matrices,
Decorrelation"
YETI on the Cloud,"The York Extensible Testing Infrastructure (YETI) is an automated random testing tool that allows to test programs written in various programming languages. While YETI is one of the fastest random testing tools with over a million method calls per minute on fast code, testing large programs or slow code -- such as libraries using intensively the memory -- might benefit from parallel executions of testing sessions. This paper presents the cloud-enabled version of YETI. It relies on the Hadoop package and its map/reduce implementation to distribute tasks over potentially many computers. This would allow to distribute the cloud version of YETI over Amazon's Elastic Compute Cloud (EC2).","Clouds,
Java,
Software testing,
Automatic testing,
Libraries,
System testing,
Computer science,
Distributed computing,
Prototypes,
Computer languages"
Efficient Smith-Waterman on Multi-core with FastFlow,"Shared memory multiprocessors have returned to popularity thanks to rapid spreading of commodity multi-core architectures. However, little attention has been paid to supporting effective streaming applications on these architectures. We describe FastFlow, a low-level programming framework based on lock-free queues explicitly designed to support high-level languages for streaming applications. We compare FastFlow with state-of-the-art programming frameworks such as Cilk, OpenMP, and Intel TBB. We experimentally demonstrate that FastFlow is always more efficient than them on a given real world application: the speedup of FastFlow over other solutions may be substantial for fine grain tasks, for example +35\% over OpenMP, +226\% over Cilk, +96\% over TBB for the alignment of protein P01111 against UniProt DB using the Smith-Waterman algorithm.",
A non-replication multicasting scheme in delay tolerant networks,"Delay tolerant networks (DTNs) are a special type of wireless mobile networks which may lack continuous network connectivity. Multicast is an important routing function that supports the distribution of data to a group of users, a service needed for many potential DTNs applications. While multicasting in the Internet and mobile ad hoc networks has been studied extensively, efficient multicasting in DTNs is a considerably different and challenging problem due to the probabilistic nature of contact among nodes. This paper aims to provide a non-replication multicasting scheme in DTNs while keeping the number of forwardings low. The address of each destination is not replicated, but is assigned to a particular node based on its contact probability level and node active level. Our scheme is based on a dynamic multicast tree where each leaf node corresponds to a destination. Each tree branch is generated at a contact based on the compare-split rule proposed in this paper. The compare part determines when a new search branch is needed, and the split part decides how the destination set should be partitioned. When only one destination is left in the destination set, we use either wait (no further relay) or focus (with further relay) to reach the final destination. The effectiveness of our approach is verified through extensive simulation.","Routing protocols,
Relays,
Routing,
Probability,
Delay,
Mobile ad hoc networks"
"Human Brain Connectomics: Networks, Techniques, and Applications [Life Sciences]","The human brain is organized into a collection of interacting networks with specialized functions to support various cognitive functions. The word ""connectome"" first burst on the scene with the work of Sporns et al., who urged brain researchers to advance a comprehensive structural description of the elements and connections forming the human brain. An increasing body of evidence indicates that schizophrenia, multiple sclerosis, and autism exhibit abnormal brain connections. Changes in connectivity also appear to occur as a consequence of neuron degeneration, either from natural aging or diseases such as Alzheimer's disease. A connectome is hence fundamentally important for understanding brain growth, aging, and abnormality. At the micro level, the brain elements consist of single neurons, the amount of which often treads the realm of hundreds of billions, and possible connections between them numbering in the order of 1015. At a more macro (and more manageable) level, the brain is parcellated into a number of regions, where each region accounts for the activity and coactivity of a population of neurons. The colossal task of constructing a connectome calls for powerful tools for handling the vast amount of information given by advanced imaging techniques. In this article, we provide an overview of the fundamental concepts involved, the necessary techniques, and applications to date.",
Restricted Boltzmann machine based algorithm for multi-objective optimization,"Restricted Boltzmann machine is an energy-based stochastic neural network with unsupervised learning. This network consists of a layer of hidden unit and visible unit in an undirected generative network. In this paper, restricted Boltzmann machine is modeled as estimation of distribution algorithm in the context of multi-objective optimization. The probabilities of the joint configuration over the visible and hidden units in the network are trained until the distribution over the global state reach a certain degree of thermal equilibrium. Subsequently, the probabilistic model is constructed using the energy function of the network. Moreover, the proposed algorithm incorporates clustering in phenotype space and other canonical operators. The effects on the stability of the trained network and clustering in optimization are rigorously examined. Experimental investigations are conducted to analyze the performance of the algorithm in scalable problems with high numbers of objective functions and decision variables.",
A voice-commandable robotic forklift working alongside humans in minimally-prepared outdoor environments,"One long-standing challenge in robotics is the realization of mobile autonomous robots able to operate safely in existing human workplaces in a way that their presence is accepted by the human occupants. We describe the development of a multi-ton robotic forklift intended to operate alongside human personnel, handling palletized materials within existing, busy, semi-structured outdoor storage facilities. The system has three principal novel characteristics. The first is a multimodal tablet that enables human supervisors to use speech and pen-based gestures to assign tasks to the forklift, including manipulation, transport, and placement of palletized cargo. Second, the robot operates in minimally-prepared, semi-structured environments, in which the forklift handles variable palletized cargo using only local sensing (and no reliance on GPS), and transports it while interacting with other moving vehicles. Third, the robot operates in close proximity to people, including its human supervisor, other pedestrians who may cross or block its path, and forklift operators who may climb inside the robot and operate it manually. This is made possible by novel interaction mechanisms that facilitate safe, effective operation around people. We describe the architecture and implementation of the system, indicating how real-world operational requirements motivated the development of the key subsystems, and provide qualitative and quantitative descriptions of the robot operating in real settings.",
Design of an automotive traffic sign recognition system targeting a multi-core SoC implementation,"This paper describes the design of an automotive traffic sign recognition application. All stages of the design process, starting on system-level with an abstract, pure functional model down to final hardware/software implementations on an FPGA, are shown. The proposed design flow tackles existing bottlenecks of today's system-level design processes, following an early model-based performance evaluation and analysis strategy, which takes into account hardware, software and real-time operating system aspects. The experiments with the traffic sign recognition application show, that the developed mechanisms are able to identify appropriate system configurations and to provide a seamless link into the underlying implementation flows.","Automotive engineering,
Target recognition,
Traffic control,
Application software,
Hardware,
Process design,
Field programmable gate arrays,
System-level design,
Performance analysis,
Software performance"
The Study for the Extension of Bluetooth Ring Network,"Bluetooth is a short distance and low-power wireless transmission technology. Although the application of Bluetooth technology, models, mainly in a piconet (Piconet) within the means of communication, but I believe in the near future after the more popular Bluetooth chips, decentralized network (Scatternet) the application of model will continue to emerge. For example, in a meeting among the many people involved with each other via Bluetooth scatter-net formation, mutual transmission of documents and files. However, to achieve Scatternet related applications is obviously necessary to first solve the network data transmission problems between devices that are to provide multi-point to generation packet forwarding mechanism, known as routing protocol (Routing protocol). NS2 software used in this paper to simulate in a Bluetooth piconet, the Bluetooth packet transmission by analysis of transmission over the packet transmission path, packet transmission delays or lost, to find solutions related to the corresponding methods to increase the efficiency of data transfer, so that Bluetooth network to improve the stability of the overall transmission.","Bluetooth,
Personal area networks,
Network topology,
Bridges,
Scattering,
Master-slave,
Computer science,
Cities and towns,
Application software,
Data communication"
A public transportation ontology to support user travel planning,"Choose the best way to move from one place to another can involve different information: offers of different transport modes, their combination in the same journey and other information about services (such as restaurants, libraries, etc) that can be available in the route and useful for the passenger. Different approaches have been proposed to support the passenger's planning considering some part of this information. In this paper we present a public transportation domain ontology that considers different concepts related to the best and more relevant planning for the passenger. This ontology is formalized with OWL in Protégè tool. Using real instances and inferences, we show the ontology application, its relevance and consistency.","Ontologies,
Computer science,
Libraries,
OWL,
Diseases,
Scheduling,
Vehicles,
Urban areas,
Road transportation"
Policy Based Security Analysis in Enterprise Networks: A Formal Approach,"In a typical enterprise network, there are several sub-networks or network zones corresponding to different departments or sections of the organization. These zones are interconnected through set of Layer-3 network devices (or routers). The service accesses within the zones and also with the external network (e.g., Internet) are usually governed by a enterprise-wide security policy. This policy is implemented through appropriate set of access control lists (ACL rules) distributed across various network interfaces of the enterprise network. Such networks faces two major security challenges, (i) conflict free representation of the security policy, and (ii) correct implementation of the policy through distributed ACL rules. This work presents a formal verification framework to analyze the security implementations in an enterprise network with respect to the organizational security policy. It generates conflict-free policy model from the enterprise-wide security policy and then formally verifies the distributed ACL implementations with respect to the conflict-free policy model. The complexity in the verification process arises from extensive use of temporal service access rules and presence of hidden service access paths in the networks. The proposed framework incorporates formal modeling of conflict-free policy specification and distributed ACL implementation in the network and finally deploys Boolean satisfiability (SAT) based verification procedure to check the conformation between the policy and implementation models.",
Genetic Programming for Reward Function Search,"Reward functions in reinforcement learning have largely been assumed given as part of the problem being solved by the agent. However, the psychological notion of intrinsic motivation has recently inspired inquiry into whether there exist alternate reward functions that enable an agent to learn a task more easily than the natural task-based reward function allows. This paper presents a genetic programming algorithm to search for alternate reward functions that improve agent learning performance. We present experiments that show the superiority of these reward functions, demonstrate the possible scalability of our method, and define three classes of problems where reward function search might be particularly useful: distributions of environments, nonstationary environments, and problems with short agent lifetimes.","Genetic programming,
Psychology,
Scalability,
System performance,
Distributed computing,
Learning systems,
Search methods,
State-space methods"
Exploring the Dynamic Nature of Mobile Nodes for Predicting Route Lifetime in Mobile Ad Hoc Networks,"In mobile ad hoc networks, a host may exhaust its power or move away without giving any notice to its cooperative nodes, causing changes in network topology, and thus, these changes may significantly degrade the performance of a routing protocol. Several routing protocol studies based on node lifetime and link lifetime have been done to address this problem. We propose a new algorithm to evaluate the node lifetime and the link lifetime utilizing the dynamic nature, such as the energy drain rate and the relative mobility estimation rate of nodes. Integrating these two performance metrics by using the proposed route lifetime-prediction algorithm, we select the least dynamic route with the longest lifetime for persistent data forwarding. Finally, we implement our proposed route lifetime-prediction algorithm in an exploring dynamic nature routing (EDNR) protocol environment based on dynamic source routing (DSR) and compare the performance through simulations. The EDNR protocol outperforms the conventional DSR protocols that are implemented with lifetime-prediction routing (LPR) and signal-stability-based adaptive (SSA) routing mechanisms.","Mobile ad hoc networks,
Routing protocols,
Batteries,
Network topology,
Life estimation,
Lifetime estimation,
Degradation,
Measurement,
Ad hoc networks,
Mobile communication"
Memristor lookup table (MLUT)-based asynchronous nanowire crossbar architecture,"In this work, a novel memristor lookup table (MLUT)-based asynchronous nanowire reconfigurable crossbar architecture (ANRCA) is proposed. Unlike the existing nanowire crossbar architectures that mostly use crosspoints as pro-grammable diodes and/or field-effect transistors, the proposed architecture utilizes crosspoints as configurable memristors to realize nanoscale lookup tables (LUTs) and relies on a delay-insensitive logic paradigm known as Null Convention Logic (NCL) for the proposed clock-free operation. The primitive logic block of the proposed MLUT ANRCA is referred to as the Programmable Gate Macro Block (PGMB) and can be programmed to realize any given NCL gate function by directly implementing the truth table of the given NCL gate function using the proposed MLUT and also providing hysteresis (i.e., state-holding behavior) that is required to achieve the proposed delay-insensitivity via a feedback interconnect. Potential technical merits of the proposed MLUT ANRCA includes: 1) better manufacturability due to structural simplicity and regularity; 2) improved robustness over PVT (Process-Voltage-Temperature) variations; 3) event-driven low-power/noise asynchronous operation; and 4) encoding-level logic inversion.",
"Integrating Mobile, Web and Sensory Technologies to Support Inquiry-Based Science Learning","Recent advances in mobile, wireless, and sensor technologies provide new possibilities for supporting learning activities that can be spatially distributed and incorporate different physical and environmental sensory data. In this paper, we present our technical efforts in relation to the design and implementation of mobile and web applications that integrate sensory data used to support inquiry-based science learning. In order to test the validity of our solution and its functionality and novelty, we conducted a prototype experiment with high school students in the field of environmental sciences. The initial outcomes presented in this paper point towards the potential benefits of using sensor and mobile technologies with real-time geo-positioned data and visualizations, which may increase students’ engagement, enabling them to conduct scientific inquiries and analyses in new ways.",
Junior 3: A test platform for Advanced Driver Assistance Systems,"Advanced Driver Assistance Systems (ADAS) are becoming more common in today's vehicles with more complex functions being implemented in production vehicles. On the research side, significant technology development in hardware and software has been spurred in recent years by the DARPA Grand Challenge and Urban Challenge in 2005 and 2007 respectively. This paper describes ‘Junior 3’, a vehicle built at Volkswagen Group of America's Electronics Research Lab, based on the knowledge gained from the DARPA Challenges and applied to ADAS functionalities. Specifically we focussed on object detection and vehicle positioning capabilities with close to production grade sensors and describe an ‘Autonomous Valet Parking’ and ‘Object Tracking’ application with this system.","System testing,
Vehicle driving,
Production systems,
Remotely operated vehicles,
Hardware,
Object detection,
Vehicle detection,
Mobile robots,
Sensor phenomena and characterization,
Sensor systems and applications"
Rethinking Flash in the Data Center,Deployment of flash memory depends on making the most of its unique properties instead of treating it as a drop-in replacement for existing technologies.,
Protection of Memories Suffering MCUs Through the Selection of the Optimal Interleaving Distance,"Interleaving, together with single error correction codes (SEC), are common techniques to protect memories against multiple cell upsets (MCUs). This kind of errors is increasingly important as technology scales, becoming a prominent effect, and therefore greatly affecting the reliability of memories. Ideally, the interleaving distance (ID) should be chosen as the maximum expected MCU size. In this way, all errors in an MCU would occur in different logical words, thus being correctable by the SEC codes. However, the use of large interleaving distances usually results in an area increase and a more complex design of memories. In this paper, the selection of the optimal interleaving distance is explored, keeping the area overhead and complexity as low as possible, without compromising memory reliability.",
Optimal Testing of Reed-Muller Codes,"We consider the problem of testing if a given function f : \F_2^n \right arrow \F_2
is close to any degree d
polynomial in n
variables, also known as the Reed-Muller testing problem. %The Gowers norm is based on a natural 2^{d+1}
-query test for this property. Alon et al.~\cite{AKKLR} proposed and analyzed a natural 2^{d+1}
-query test for this problem. This test turned out to be intimately related to the Gowers norm. Alon et. al. showed that this test accepts every degree d
polynomial with probability 1
, while it rejects functions that are \Omega(1)
-far with probability \Omega(1/(d 2^{d}))
. We give an asymptotically optimal analysis of this test, and show that it rejects functions that are (even only) \Omega(2^{-d})
-far with \Omega(1)
-probability (so the rejection probability is a universal constant independent of d
and n
). This implies a tight relationship between the (d+1)^{\rm{st}}
-Gowers norm of a function and its maximal correlation with degree d
polynomials, when the correlation is close to 1. Our proof works by induction on n
and yields a new analysis of even the classical Blum-Luby-Rubinfeld~\cite{BLR} linearity test, for the setting of functions mapping \F_2^n
to \F_2
. The optimality follows from a tighter analysis of counterexamples to the ``inverse conjecture for the Gowers norm'' constructed by \cite{GT07, LMS}. Our result has several implications. First, it shows that the Gowers norm test is tolerant, in that it also accepts close code words. Second, it improves the parameters of an XOR lemma for polynomials given by Viola and Wigderson~\cite{VW}. Third, it implies a ``query hierarchy'' result for property testing of affine-invariant properties. That is, for every function q(n)
, it gives an affine-invariant property that is testable with O(q(n))
-queries, but not with o(q(n))
-queries, complementing an analogous result of \cite{GKNR08} for graph properties.","Polynomials,
Testing,
Complexity theory,
Correlation,
Computer science,
Electronic mail,
Linearity"
Adaptive Appearance Model and Condensation Algorithm for Robust Face Tracking,"We present an adaptive framework for condensation algorithms in the context of human-face tracking. We attack the face tracking problem by making factored sampling more efficient and appearance update more effective. An adaptive affine cascade factored sampling strategy is introduced to sample the parameter space such that coarse face locations are located first, followed by a fine factored sampling with a small number of particles. In addition, the local linearity of an appearance manifold is used in conjunction with a new criterion to select a tangent plane for updating an appearance in face tracking. Our proposed method seeks the best linear variety from the selected tangent plane to form a reference image. We demonstrate the effectiveness and efficiency of the proposed method on a number of challenging videos. These test video sequences show that our method is robust to illumination, appearance, and pose changes, as well as temporary occlusions. Quantitatively, our method achieves the average root-mean-square error at 4.98 on the well-known dudek video sequence while maintaining a proficient speed at 8.74 fps. Finally, while our algorithm is adaptive during execution, no training is required.",
Detecting atomic-set serializability violations in multithreaded programs through active randomized testing,"Concurrency bugs are notoriously difficult to detect because there can be vast combinations of interleavings among concurrent threads, yet only a small fraction can reveal them. Atomic-set serializability characterizes a wide range of concurrency bugs, including data races and atomicity violations. In this paper, we propose a two-phase testing technique that can effectively detect atomic-set serializability violations. In Phase I, our technique infers potential violations that do not appear in a concrete execution and prunes those interleavings that are violation-free. In Phase II, our technique actively controls a thread scheduler to enumerate these potential scenarios identified in Phase I to look for real violations. We have implemented our technique as a prototype system AssetFuzzer and applied it to a number of subject programs for evaluating concurrency defect analysis techniques. The experimental results show that AssetFuzzer can identify more concurrency bugs than two recent testing tools RaceFuzzer and AtomFuzzer.","Testing,
Computer bugs,
Concurrent computing,
Instruction sets,
Concrete,
Synchronization,
Monitoring"
Steward: Scaling Byzantine Fault-Tolerant Replication to Wide Area Networks,"This paper presents the first hierarchical byzantine fault-tolerant replication architecture suitable to systems that span multiple wide-area sites. The architecture confines the effects of any malicious replica to its local site, reduces message complexity of wide-area communication, and allows read-only queries to be performed locally within a site for the price of additional standard hardware. We present proofs that our algorithm provides safety and liveness properties. A prototype implementation is evaluated over several network topologies and is compared with a flat byzantine fault-tolerant approach. The experimental results show considerable improvement over flat byzantine replication algorithms, bringing the performance of byzantine replication closer to existing benign fault-tolerant replication techniques over wide area networks.","Fault tolerance,
Wide area networks,
Protocols,
Fault tolerant systems,
Public key,
Delay,
Computer science,
Communication standards,
Hardware,
Safety"
Parallel de novo assembly of large genomes from high-throughput short reads,"The advent of high-throughput short read technology is revolutionizing life sciences by providing an inexpensive way to sequence genomes at high coverage. Exploiting this technology requires the development of a de novo short read assembler, which is an important open problem that is garnering significant research effort. Current methods are largely limited to microbial organisms, whose genomes are two to three orders of magnitude smaller than complex mammalian and plant genomes. In this paper, we present the design and development of a parallel de novo short read assembler that can scale to large genomes with high coverage. Our approach is based on the string graph formulation. Input reads are mapped to short paths, and the genome is reconstructed as a superpath anchored by distance constraints inferred from read pairs. Our method can handle a mixture of multiple read sizes and multiple paired read distances. We present parallel algorithms for string graph construction, string graph compaction, graph based error detection and removal, and computing aggregate summarization of paired read links across graph edges. Using this, we navigate the final graph structure to reproduce large contiguous sequences from the underlying genome. We present a validation of our framework on experimental and simulated data from multiple known genomes and present scaling results on IBM Blue Gene/L.",
Survey of fall detection and daily activity monitoring techniques,"The risk of sustaining heavy injuries through accidental falls creates a major medical problem for elderly people. This paper conducts a survey of the various automatic techniques and methods proposed to detect falls and anomalies in movements of the elderly, through monitoring of their daily life activities. These methods can be broadly divided into three main categories: 1) Video Analysis Based; 2) Acoustic and Ambience Sensor Based; and 3) Kinematic Sensor Based. This paper critically analyzes the various proposed methodologies, comparing their strengths and weaknesses. We further propose our own technique for fall detection and monitoring of common daily life activities (walking, running, sitting, standing, and lying down), through a novel approach that provides a low cost solution and ensures the safety and security of the elderly without restricting them to confined surroundings.",
Regenerative morphing,"We present a new image morphing approach in which the output sequence is regenerated from small pieces of the two source (input) images. The approach does not require manual correspondence, and generates compelling results even when the images are of very different objects (e.g., a cloud and a face). We pose the morphing task as an optimization with the objective of achieving bidirectional similarity of each frame to its neighbors, and also to the source images. The advantages of this approach are 1) it can operate fully automatically, producing effective results for many sequences (but also supports manual correspondences, when available), 2) ghosting artifacts are minimized, and 3) different parts of the scene move at different rates, yielding more interesting (and less robotic) transitions.","Clouds,
Interpolation,
Layout,
Service robots,
Robotics and automation,
Visual effects,
Motion pictures,
Facial features,
Eyes,
Mouth"
Overcoming the Hole in the Bucket: Public-Key Cryptography Resilient to Continual Memory Leakage,"In recent years, there has been a major effort to design cryptographic schemes that remain secure even when arbitrary information about the secret key is leaked (e.g., via side-channel attacks). We explore the possibility of achieving security under \emph{continual} leakage from the \emph{entire} secret key by designing schemes in which the secret key is updated over time. In this model, we construct public-key encryption schemes, digital signatures, and identity-based encryption schemes that remain secure even if an attacker can leak a constant fraction of the secret memory (including the secret key) in each time period between key updates. We also consider attackers who may probe the secret memory during the updates themselves. We stress that we allow unrestricted leakage, without the assumption that ``only computation leaks information''. Prior to this work, constructions of public-key encryption schemes secure under continual leakage were not known even under this assumption.","Encryption,
Computational modeling,
Resilience,
Identity-based encryption"
Hand gesture recognition using neural networks,"Visual Interpretation of gestures can be useful in accomplishing natural Human Computer Interactions (HCI). In this paper we proposed a method for recognizing hand gestures. We have designed a system which can identify specific hand gestures and use them to convey information. At any time, a user can exhibit his/her hand doing a specific gesture in front of a web camera linked to a computer. Firstly, we captured the hand gesture of a user and stored it on disk. Then we read those videos captured one by one, converted them to binary images and created 3D Euclidian Space of binary values. We have used supervised feed-forward neural net based training and back propagation algorithm for classifying hand gestures into ten categories: hand pointing up, pointing down, pointing left, pointing right and pointing front and number of fingers user was showing. We could achieve up to 89% correct results on a typical test set.","Neural networks,
Human computer interaction,
Computer vision,
Image segmentation,
Computer applications,
Fingers,
Computer displays,
Real time systems,
Skin,
Cameras"
A Low Power Broadband Differential Low Noise Amplifier Employing Noise and IM3 Distortion Cancellation for Mobile Broadcast Receivers,"A CMOS broadband differential low noise amplifier (LNA) employing noise and third order intermodulation (IM3) distortion cancellation has been designed using a 0.13 μm CMOS process for mobile TV tuners. By combining a common gate amplifier with a common source amplifier through a current mirror, a high gain due to the additional current amplification and a low noise figure (NF) due to the thermal noise cancellation can be achieved with low power consumption without degrading the input matching. To improve the linearity with low power consumption, a multiple gated transistor technique for canceling the IM3 distortion is adopted. The proposed LNA has a maximum gain of 14.5 dB, an averaged NF of 3.6 dB, an IIP3 of 3 dBm, an IIP2 of 38 dBm, and an |Sn11| lower than -9 dB in a frequency range from 72 to 850 MHz. The power consumption is 9.6 mW at a 1.2 V supply voltage and the chip area is 0.08 mm2.","Noise measurement,
Power demand,
Transistors,
Gain,
Noise cancellation,
Broadband communication"
Improvements to LISP Mobile Node,"The Locator/Identifier Separation Protocol (LISP) is a new routing architecture for the Internet that separates local and global routing. It offers more flexibility to edge networks and has the potential to reduce the growths of the BGP routing tables. Recently, a concept for mobility in LISP (LISP Mobile Node, LISP-MN) was presented. We analyze LISP-MN and show that it needs double mapping lookups in all LISP gateways, leads to triangle routing under some conditions, and requires double encapsulation. We propose gradual improvements to LISP-MN that avoid these drawbacks under many conditions.","Manganese,
Internet,
Routing,
Tin,
Encapsulation,
Logic gates,
Mobile communication"
Tracking people interacting with objects,"While the problem of tracking 3D human motion has been widely studied, most approaches have assumed that the person is isolated and not interacting with the environment. Environmental constraints, however, can greatly constrain and simplify the tracking problem. The most studied constraints involve gravity and contact with the ground plane. We go further to consider interaction with objects in the environment. In many cases, tracking rigid environmental objects is simpler than tracking high-dimensional human motion. When a human is in contact with objects in the world, their poses constrain the pose of body, essentially removing degrees of freedom. Thus what would appear to be a harder problem, combining object and human tracking, is actually simpler. We use a standard formulation of the body tracking problem but add an explicit model of contact with objects. We find that constraints from the world make it possible to track complex articulated human motion in 3D from a monocular camera.","Humans,
Tracking,
Layout,
Kinematics,
Biological system modeling,
Object detection,
State-space methods,
Content addressable storage,
Computer science,
Gravity"
Exploiting OFDM systems for covert communication,"Both Long Term Evolution (LTE) and WiMAX (802.16) 4th generation wireless systems (4G) utilize orthogonal frequency division multiplexing (OFDM) on the down-link. The advantages of OFDM over other wireless communication techniques are well known. These technologies will become more ubiquitous as time goes on. Here a study is presented of the potential for covert communication within an OFDM waveform. Most OFDM standards call for unused sub-channels for channel spacing, synchronization of transmitter and receiver and to mitigate poor channel response. Here we study the effects of inserting a narrow band signal that will be used for covert communication in one of the unused sub-carrier locations of the OFDM signal and analyze its influence on the target OFDM signal as well as determining the communications capabilities of the covert link. The covert signal inserted in an unused subcarrier locations or frequency ""slot"", is no longer orthogonal to the target OFDM waveform. Thus, there is potential for the covert signal to impact the target link. Here we examine the effect of the covert signal on the target OFDM system as a function of the location of the covert signal, its power, and bit rate. The communications capability of the covert link is also studied. The amount of information that can be transmitted covertly with minimal impact on the target OFDM user (i.e., relatively low probability of detection) is also presented.","OFDM,
Bit error rate,
Receivers,
Transmitters,
Bit rate,
Resource management,
Noise"
SyReC: A programming language for synthesis of reversible circuits,"Reversible logic serves as a basis for emerging technologies like quantum computing and additionally has applications in low-power design. In particular, since traditional technologies like CMOS are going to reach their limits in the near future, reversible logic has been established as a promising alternative. Thus, in the last years this area started to become intensely studied by researchers. In particular, how to efficiently synthesize complex reversible circuits is an important question. So far, only synthesis approaches are available that rely on Boolean function representations, like e.g. truth tables or decision diagrams. In this paper, we propose the programming language SyReC that allows to specify and afterwards to automatically synthesize reversible circuits. Using an existing programming language for reversible software design as basis, we introduce new concepts, operations, and restrictions allowing the specification of reversible hardware. Furthermore, a hierarchical approach is presented that automatically transforms the respective statements and operations of the new programming language into a reversible circuit. Experiments show that with the proposed method, complex circuits can be easily specified and synthesized while with previous approaches this often is not possible due to the limits caused by truth tables or decision diagrams.","programming languages,
binary decision diagrams,
Boolean functions,
digital circuits,
logic design,
low-power electronics,
network synthesis"
Routing protocols in Delay Tolerant Networks - a survey,"Delay Tolerant Networks (DTN) are a class of networks that lack continuous connectivity between nodes due to limited wireless radio coverage, widely scattered mobile nodes, constrained energy resources, high levels of interference or due to some other similar channel impairment. Examples of such networks are those operating in mobile networks or extreme terrestrial environments, or simply as planned networks in space. The term disruption-tolerant network is also occasionally used in place of DTN. Routing in DTN is challenging because of frequent and long duration periods of non-connectivity. Several routing protocols have been proposed with strategies ranging from flooding to opportunistic approaches. Due to the diversity of available strategies, there is a need to properly classify and evaluate their performance with various angles. In this paper, we study state of the art routing protocols and give a comparison between them with respect to the characteristic features and methodology involved. The pros and cons of each, their performance and open research issues are also discussed.","Routing,
Routing protocols,
Encoding,
Relays,
Delay"
Extending LMS with Collaborative Remote Lab Features,"In university education, classroom activities are more and more combined with on-line teaching materials, webinars, electronic forums, wikis, web calendar and so on. This “blended approach” is often based on the adoption of Learning Management Systems (LMS), which are customized in many aspects to match both the teaching style of the university and the needs of teachers and students. More recently, also laboratory experiments, that are integral parts of science and technology classes, have come online. The first generation of Remote Web Laboratories (RWL) has demonstrated the feasibility and the effectiveness of on line experiments, with two major drawbacks: the lack of integration between LMS and RWL and the lack of synchronous interaction among the participants (teacher and students) to the experiment. In this scenario, the paper discusses the principal aspects and the main results about an integration project between the Moodle LMS and the MicroNet RWL at University of Salento, in Italy.",
Unsupervised classification of digital images using enhanced sensor pattern noise,"We present in this work an unsupervised image classifier, which is capable of clustering images taken by an unknown number of unknown digital cameras into a number of classes, each corresponding to one camera. The classification system first extracts and enhances a sensor pattern noise (SPN) from each image, which serves as the fingerprint of the camera that has taken the image. Secondly, it applies an unsupervised classifier trainer to a small training set of randomly selected SPNs to cluster the SPNs into classes and uses the centroids of those identified classes as the trained classifier. The classifier trainer treats each SPN as a random variable and uses Markov random field (MRF) approach to iteratively assigns a class label to each SPN (i.e., random variable) based on the class labels assigned to the members of a small set of SPNs, called membership committee, and the similarity values between it and the members of the membership committee until a stop criteria is met. The classifier trainer requires no a priori knowledge about the dataset from the user. Finally the image not included in the small training set are classified using the trained classifier depending on the similarity between their SPNs and the centroids of the trained classifier.","Digital images,
Image sensors,
Fingerprint recognition,
Digital cameras,
Membership Committee,
Random variables,
Forensics,
Image analysis,
Digital filters,
Computer science"
Highly scalable parallel sorting,"Sorting is a commonly used process with a wide breadth of applications in the high performance computing field. Early research in parallel processing has provided us with comprehensive analysis and theory for parallel sorting algorithms. However, modern supercomputers have advanced rapidly in size and changed significantly in architecture, forcing new adaptations to these algorithms. To fully utilize the potential of highly parallel machines, tens of thousands of processors are used. Efficiently scaling parallel sorting on machines of this magnitude is inhibited by the communication-intensive problem of migrating large amounts of data between processors. The challenge is to design a highly scalable sorting algorithm that uses minimal communication, maximizes overlap between computation and communication, and uses memory efficiently. This paper presents a scalable extension of the Histogram Sorting method, making fundamental modifications to the original algorithm in order to minimize message contention and exploit overlap. We implement Histogram Sort, Sample Sort, and Radix Sort in Charm++ and compare their performance. The choice of algorithm as well as the importance of the optimizations is validated by performance tests on two predominant modern supercomputer architectures: XT4 at ORNL (Jaguar) and Blue Gene/P at ANL (Intrepid).","Sorting,
Supercomputers,
Histograms,
Algorithm design and analysis,
Testing,
Computer science,
Application software,
Merging,
High performance computing,
Parallel processing"
Characterizing the lifetime reliability of manycore processors with core-level redundancy,"With aggressive technology scaling, integrated circuits suffer from ever-increasing wearout effects and their lifetime reliability has become a serious concern for the industry. For manycore processors that integrate a large number of processor cores on a single silicon die, introducing core-level redundancy is an effective way to alleviate this problem. There are, however, many strategies to make use of the redundant cores, which have different implications on the aging effects of embedded processors. How to characterize the lifetime reliability of manycore processors with different usages is therefore an important and relevant problem. In this paper, we propose a novel analytical method to tackle the above problem, which captures the impact of workloads and the associated temperature variations. We then use the proposed model to analyze the lifetime reliability for manycore processors with various redundancy configurations. Finally, the effectiveness of the proposed method is demonstrated with extensive experiments.",
Wideband Built-In Antenna With New Crossed C-Shaped Coupling Feed for Future Mobile Phone Application,"A wideband built-in antenna with a new crossed C-shaped coupling feed structure for wireless terminals is presented. With the proposed design scheme, a 10-band built-in antenna that covers LTE700/GSM850/GSM900/DCS1800/PCS1900/WCDMA/WiBro2350/Bluetooth/WiMAX2500/LTE2600 is experimentally tested. The antenna could be available for future 4G service and for current 2G/3G services. This novel 10-band built-in handset antenna is developed within the limits of a 50 × 14 × 6 mm3 volume for recent smart phones or personal digital assistant (PDA) applications, thereby achieving good agreement between measurement and simulation.","Broadband antennas,
Mobile antennas,
Antenna feeds,
Mobile handsets,
Personal digital assistants,
Multiaccess communication,
Bluetooth,
WiMAX,
Testing,
Telephone sets"
Generating UAV communication networks for monitoring and surveillance,"An important use of unmanned aerial vehicles is surveillance of distant targets, where sensor information must quickly be transmitted back to a base station. In many cases, high uninterrupted bandwidth requires line-of-sight between sender and transmitter to minimize quality degradation. Communication range is typically limited, especially when smaller UAVs are used. Both problems can be solved by creating relay chains for surveillance of a single target, and relay trees for simultaneous surveillance of multiple targets. In this paper, we show how such chains and trees can be calculated. For relay chains we create a set of chains offering different trade-offs between the number of UAVs in the chain and the chain's cost. We also show new results on how relay trees can be quickly calculated and then incrementally improved if necessary. Encouraging empirical results for improvement of relay trees are presented.","Relays,
Surveillance,
Unmanned aerial vehicles,
Base stations,
Optimization,
Robot sensing systems,
Steiner trees"
A roadmap for distribution energy management via multiobjective optimization,Multiobjective optimization has been applied to the problem of optimal energy management in power distribution systems. Future distribution systems with increased deployment of distributed energy storage devices and distributed energy resources are being designed under the aegis of a number of sectors of the power engineering community. This includes the National Science Foundation supported Future Renewable Electric Energy Distribution Management (FREEDM) center. A technical roadmap for the FREEDM center distribution system is proposed that is based on multiobjective optimization. Diverse objectives in the optimal control of the distribution energy management system are handled through a Pareto optimal approach. The normal boundary intersection method is used to develop a Pareto optimal front and solving the multiobjective optimization subroutine has been approached through separable programming techniques. Uncertainty in load demand and distributed resource power output are incorporated in the test cases studied to formulate a robust algorithm for distribution energy management. The paper also makes brief reference to the Smart Grid and its objectives - and how the proposed distribution energy management fits into this initiative.,"Optimization,
Energy management,
Energy storage,
Converters,
Programming,
Minimization,
Density estimation robust algorithm"
Optimal Linear Network Coding Design for Secure Unicast with Multiple Streams,"Linear network coding is a promising technology that can maximize the throughput capacity of communication network. Despite this salient feature, there are still many challenges to be addressed, and security is clearly one of the most important challenges. In this paper, we will address the design of secure linear network coding. Specifically, we will investigate the network coding design that can both satisfy the weakly secure requirements and maximize the transmission data rate of multiple unicast streams between the same source and destination pair, which has not been addressed in the literature. In our study, we first prove that the secure unicast routing problem is equivalent to a constrained link-disjoint path problem. We then develop efficient algorithm that can find the optimal unicast topology in a polynomial amount of time. Based on the topology, we design deterministic linear network code that is weakly secure and can be constructed at the source node. And finally, we investigate the potential of random linear code for weakly secure unicast and prove the low bound of the probability that a random linear code is weakly secure.","Network coding,
Unicast,
Network topology,
Data security,
Throughput,
Computer science,
Communication networks,
Routing,
Linear code,
Communications Society"
A DC-to-Three-Phase-AC High-Frequency Link Converter With Compensation for Nonlinear Distortion,"This paper focuses on a new high-frequency (HF) link dc-to-three-phase-ac power converter. The least number of switching devices among other HF link dc-to-three-phase-ac converters, improved power density due to the absence of devices of bidirectional voltage-blocking capability, simple commutation requirements, and isolation between input and output are the integral features of this topology. The commutation process of the converter requires zero portions in the link voltage. This causes a nonlinear distortion in the output three-phase voltages. The mathematical analysis is carried out to investigate the problem, and suitable compensation in modulating signal is proposed for different types of carrier. Along with the modified modulator structure, a synchronously rotating reference-frame-based control scheme is adopted for the three-phase ac side in order to achieve high dynamic performance. The effectiveness of the proposed scheme has been investigated and verified through computer simulations and experimental results with 1-kVA prototype.","Voltage,
Frequency conversion,
Analog-digital conversion,
Switching converters,
Topology,
Nonlinear distortion,
Phase distortion,
Mathematical analysis,
Phase modulation,
Computer simulation"
High-Resolution Multiple Wideband and Nonstationary Source Localization With Unknown Number of Sources,"In this paper, a new algorithm for high-resolution multiple wideband and nonstationary source localization using a sensor array is proposed. The received signals of the sensor array are first converted into the time-frequency domain via short-time Fourier transform (STFT) and we find that a set of short-time power spectrum matrices at different time instants have the joint diagonalization structure in each frequency bin. Based on such joint diagonalization structure, a novel cost function is designed and a new spatial spectrum for direction-of-arrival (DOA) estimation at hand is derived. Compared to the maximum-likelihood (ML) method with high computational complexity, the proposed algorithm obtains the DOA estimates via one-dimensional (1-D) search instead of multidimensional search. Therefore its computational complexity is much lower than the ML method. Unlike the subspace-based high-resolution DOA estimation techniques, it is not necessary to determine the number of sources in advance for the proposed algorithm. Moreover, the proposed method is robust to the effects of reverberation caused by multipath reflections. Hence it is suitable for multiple acoustic source localization in a reverberant room. The results of numerical simulations and experiments in a real room with a moderate reverberation are provided to demonstrate the good performance of the proposed approach.","Wideband,
Sensor arrays,
Direction of arrival estimation,
Maximum likelihood estimation,
Computational complexity,
Reverberation,
Time frequency analysis,
Fourier transforms,
Matrix converters,
Frequency conversion"
Minimizing the Maximum Firewall Rule Set in a Network with Multiple Firewalls,"A firewall's complexity is known to increase with the size of its rule set. Empirical studies show that as the rule set grows larger, the number of configuration errors on a firewall increases sharply, while the performance of the firewall degrades. When designing a security-sensitive network, it is critical to construct the network topology and its routing structure carefully in order to reduce the firewall rule sets, which helps lower the chance of security loopholes and prevent performance bottleneck. This paper studies the problems of how to place the firewalls in a topology during network design and how to construct the routing tables during operation such that the maximum firewall rule set can be minimized. These problems have not been studied adequately despite their importance. We have two major contributions. First, we prove that the problems are NP-complete. Second, we propose a heuristic solution and demonstrate the effectiveness of the algorithm by simulations. The results show that the proposed algorithm reduces the maximum firewall rule set by 2-5 times when comparing with other algorithms.","Routing,
Network topology,
Topology,
Access control,
Fires,
Logic gates"
Insulator condition analysis for overhead distribution lines using combined wavelet support vector machine (SVM),"Condition analysis of overhead power distribution system insulators using combined support vector machine (SVM) and wavelet multi-resolution analysis (MRA) seems to be promising for distribution system monitoring (DSM) automation to cope with the increasing system complexity. Though system well-being analysis for engineering applications has been used mostly for electric power system reliability studies, the same principle has been extended for assessing the condition of insulators in a distribution system based on the extent of their damage. Video surveillance with fixed cameras provide the required images of power lines along with insulators at regular intervals and same is sent to a control room using remote terminal units (RTUs) for analysis. Not only the health of the insulators, but also the sagging of the lines, breakage of both insulators and lines can be captured with such cameras. This paper mainly focuses on application of wavelet-transform based feature extraction for digital image processing and SVM for subsequent condition analysis of insulators. The most significant contribution of the paper is to compute the condition indices for overhead power distribution line insulators to overcome difficulties related to vehicular applications in video surveillance. The results contained in this paper validate the efficacy of the proposed methodology for wide-scale applications in overhead power distribution system monitoring (DSM) automation.",
Data deduplication techniques,"With the information and network technology, rapid development, rapid increase in the size of the data center, energy consumption in the proportion of IT spending rising. In the great green environment many companies are eyeing the green store, hoping thereby to reduce the energy storage system. Data de-duplication technology to optimize the storage system can greatly reduce the amount of data, thereby reducing energy consumption and reduce heat emission. Data compression can reduce the number of disks used in the operation to reduce disk energy consumption costs. By studying the data de-duplication strategy, processes, and implementations for the following further lay the foundation of the work.","Indexes,
Arrays,
Accuracy"
Multi-object filtering from image sequence without detection,Almost every single-view visual multi-target tracking method presented in the literature includes a detection routine that maps the image data to point measurements relevant to the target states. These measurements are commonly further processed by a filter to estimate the number of targets and their states. This paper presents a novel visual tracking technique based on a multi-object filtering algorithm that operates directly on the image observations without the need for any detection. Experimental results on tracking sport players show that our proposed method can automatically track numerous interacting targets and quickly finds players entering or leaving the scene.,"Filtering,
Image sequences,
Target tracking,
State estimation,
Bayesian methods,
Biological system modeling,
Data engineering,
Filters,
Video sequences,
Computer science"
Complex Oscillation-Based Test and Its Application to Analog Filters,"Testing is a critical factor for modern large-scale mixed-mode circuits. Strategies for mitigating test cost and duration include moving significant parts of the test hardware on-chip. This paper presents a novel low-overhead approach for design for test and built-in self-test of analog and mixed-mode blocks, derived from the oscillation-based test framework. The latter is enhanced by the use of complex oscillation regimes, improving fault coverage and enabling forms of parametric or specification-based testing. This technique, initially proposed targeting large subsystems such as A/D converters, is here illustrated at a much finer granularity, considering its application to analog-filter stages, and also proving its suitability to backfit existing designs. The simple case of a switched-capacitor second-order bandpass stage is used for illustration discussing how deviations from nominal gain, central frequency, and quality factor can be detected from measurements not requiring A/D stages. A sample design is validated by simulations run at the layout level, including Monte Carlo analysis and simulations based on random fault injections.","Circuit testing,
Automatic testing,
Circuit faults,
Analytical models,
Filters,
Large-scale systems,
Costs,
Hardware,
Built-in self-test,
Frequency"
Key Technical Challenges for the Electric Power Industry and Climate Change,"This paper, prepared by the Climate Change Technology Subcommittee, a subcommittee of the Power and Energy Society Energy Development and Power Generation Committee, identifies key technical issues facing the electric power industry, related to global climate change. The technical challenges arise from: 1) impacts on system operating strategies, configuration, and expansion plans of emission-reducing technologies; 2) power infrastructure response to extreme weather events; 3) effects of government policies including an expanded use of renewable and alternative energy technologies; and 4) impacts of market rules on power system operation. Possible lessons from other industries' responses to climate change are explored.","Power systems,
Power & Energy Society,
Life members,
Power generation,
Government,
Power engineering and energy,
Systems engineering and theory,
Power industry,
Paper technology,
Computer science"
Tactile interaction with a humanoid robot for children with autism: A case study analysis involving user requirements and results of an initial implementation,"The work presented in this paper is part of our investigation in the ROBOSKIN project. The project aims to develop and demonstrate a range of new robot capabilities based on the tactile feedback provided by a robotic skin. One of the project's objectives is to improve human-robot interaction capabilities in the application domain of robot-assisted play. This paper presents design challenges in augmenting a humanoid robot with tactile sensors specifically for interaction with children with autism. It reports on a preliminary study that includes requirements analysis based on a case study evaluation of interactions of children with autism with the child-sized, minimally expressive robot KASPAR. This is followed by the implementation of initial sensory capabilities on the robot that were then used in experimental investigations of tactile interaction with children with autism.","Autism,
Face,
Tactile sensors,
Fingers"
MediAlly: A provenance-aware remote health monitoring middleware,"This paper presents MediAlly, a middleware for supporting energy-efficient, long-term remote health monitoring. Data is collected using physiological sensors and transported back to the middleware using a smart phone. The key to MediAlly's energy efficient operations lies in the adoption of an Activity Triggered Deep Monitoring (ATDM) paradigm, where data collection episodes are triggered only when the subject is determined to possess a specified context. MediAlly supports the on-demand collection of contextual provenance using a novel low-overhead provenance collection sub-system. The behaviour of this sub-system is configured using an application-defined context composition graph. The resulting provenance stream provides valuable insight while interpreting the ‘episodic’ sensor data streams. The paper also describes our prototype implementation of MediAlly using commercially available devices.","Remote monitoring,
Middleware,
Biomedical monitoring,
Context-aware services,
Paper technology,
Energy efficiency,
Sensor phenomena and characterization,
Handheld computers,
Functional programming,
Context modeling"
Evaluation of Optimal Network Reliability Under Components-Assignments Subject to a Transmission Budget,"Network reliability evaluation for flow networks is an important issue in quality management. Many real-life systems can be modeled as stochastic-flow networks, in which each branch is multistate due to complete failure, partial failure, maintenance, etc. That is, each branch has several capacities with a probability distribution, and may fail. Hence, network reliability is the probability that a specified flow can be transmitted through the network successfully. Although there are many researches related to the evaluation of network reliability for a stochastic-flow network, how to assign a set of multistate components to the network so that the network reliability is maximal is never discussed. Therefore, this paper devotes to evaluating the optimal network reliability under components-assignments subject to a transmission budget, in which the transmission cost depends on each component's capacity. The network reliability under a components-assignment can be computed in terms of minimal paths, and state-space decomposition. Subsequently, we propose an optimization method based on a genetic algorithm. The experimental results show that the proposed method can be executed efficiently in a reasonable time.","Maintenance,
Capacity planning,
Probability distribution,
Computer networks,
Genetic algorithms,
Genetic mutations,
Biological cells,
Quality management,
Cost function,
Optimization methods"
Towards an ontological foundation of discrete event simulation,"This paper is an attempt to transfer some results in the meta-theory of conceptual modeling of software systems to discrete event simulation modeling. We present DESO, a foundational ontology for discrete event system modeling derived from the foundational ontology UFO. The main purpose of DESO is to provide a basis for evaluating discrete event simulation languages.","Unified modeling language,
Ontologies,
OWL,
Computational modeling,
Materials,
Image color analysis,
Semantics"
High-precision indoor UWB localization: Technical challenges and method,"We describe a centimeter-accuracy, three-dimensional ultra-wideband localization system for applications in a dense-multipath environment. From experimental results, we provide an in-depth analysis of the technical challenges toward realizing a robust, high-precision system: angle-dependent received waveform distortion and path-overlap. Specifically, for a realistic configuration (receiver placement, distance between transmit and receive antennas, and channel condition), we quantify the timing errors caused by the angle-dependent waveform distortion with First Peak detection, Leading-edge (LE) detection, and Matched Filter approaches at different relative angles between the boresights of the transmit and receive antennas. We then develop a new LE detection algorithm that virtually eliminates the timing errors caused by path-overlap.",
Efficient Multilevel Eigensolvers with Applications to Data Analysis Tasks,"Multigrid solvers proved very efficient for solving massive systems of equations in various fields. These solvers are based on iterative relaxation schemes together with the approximation of the “smooth” error function on a coarser level (grid). We present two efficient multilevel eigensolvers for solving massive eigenvalue problems that emerge in data analysis tasks. The first solver, a version of classical algebraic multigrid (AMG), is applied to eigenproblems arising in clustering, image segmentation, and dimensionality reduction, demonstrating an order of magnitude speedup compared to the popular Lanczos algorithm. The second solver is based on a new, much more accurate interpolation scheme. It enables calculating a large number of eigenvectors very inexpensively.","Data analysis,
Sparse matrices,
Eigenvalues and eigenfunctions,
Image segmentation,
Interpolation,
Matrix decomposition,
Sampling methods,
Equations,
Clustering algorithms,
Computational complexity"
Brain-Computer Interfacing [In the Spotlight],"Recently, CNN reported on the future of brain-computer interfaces (BCIs). BCIs are devices that process a user's brain signals to allow direct communication and interaction with the environment. BCIs bypass the normal neuromuscular output pathways and rely on digital signal processing and machine learning to translate brain signals to action (Figure 1). Historically, BCIs were developed with biomedical applications in mind, such as restoring communication in completely paralyzed individuals and replacing lost motor function. More recent applications have targeted nondisabled individuals by exploring the use of BCIs as a novel input device for entertainment and gaming. The task of the BCI is to identify and predict behaviorally induced changes or ""cognitive states"" in a user's brain signals. Brain signals are recorded either noninvasively from electrodes placed on the scalp [electroencephalogram (EEG)] or invasively from electrodes placed on the surface of or inside the brain. BCIs based on these recording techniques have allowed healthy and disabled individuals to control a variety of devices. In this article, we will describe different challenges and proposed solutions for noninvasive brain-computer interfacing.",
Information theoretic model validation for clustering,"Model selection in clustering requires (i) to specify a suitable clustering principle and (ii) to control the model order complexity by choosing an appropriate number of clusters depending on the noise level in the data. We advocate an information theoretic perspective where the uncertainty in the measurements quantizes the set of data partitionings and, thereby, induces uncertainty in the solution space of clusterings. A clustering model, which can tolerate a higher level of fluctuations in the measurements than alternative models, is considered to be superior provided that the clustering solution is equally informative. This tradeoff between informativeness and robustness is used as a model selection criterion. The requirement that data partitionings should generalize from one data set to an equally probable second data set gives rise to a new notion of structure induced information.","Clustering algorithms,
Couplings,
Stability,
Data analysis,
Partitioning algorithms,
Clustering methods,
Noise robustness,
Computer science,
Appropriate technology,
Noise level"
Routing protocol for Delay Tolerant Network: A survey and comparison,"Delay Tolerant Network (DTN) is evolved from Mobile Adhoc Network, MaNet. It is sparse and intermittently connected mobile adhoc network where reliable communication and end-to-end connectivity is not available for message transmission. The end to end connectivity is not ensured in Delay Tolerant Network. Only high latency applications are used in DTN. Latency may be in hours or days. The store and forward approach helps to increase message delivery probability in DTN irrespective of time taken to delivered message over normal MaNet. In DTN, the two or more nodes can exchange message when they move in transmission range of each other. Routing issue is very important due to limited resources for message storage and forwarding. This Routing issue is considered by many researchers which results in many routing protocol based on Flooding and Forwarding Approach. In this paper we try to summarize the routing protocols till date which are available in literature. We also try to compare the entire routing protocol. This paper gives right direction to researchers to proceed for designing a new routing protocol for Delay Tolerant Network.","Routing protocols,
Routing,
Strontium,
Thyristors,
Delay,
Relays"
A Doppler Robust Max-Min Approach to Radar Code Design,"This correspondence considers the problem of robust waveform design in the presence of colored Gaussian disturbance under a similarity and an energy constraint. We resort to a max-min approach, where the worst case detection performance (over the possible Doppler shifts) is optimized with respect to the radar waveform under the previously mentioned constraints. The resulting optimization problem is a non-convex Quadratically Constrained Quadratic Program (QCQP) with an infinite number of constraints, which is NP-hard in general and typically difficult to solve. Hence, we propose an algorithm with a polynomial computational complexity to generate a good sub-optimal solution for the aforementioned QCQP. The analysis, conducted in comparison with some known radar waveforms, shows that the sub-optimal solutions by the algorithm lead to high-quality radar signals.",
Modeling of Stress-Retarded Thermal Oxidation of Nonplanar Silicon Structures for Realization of Nanoscale Devices,"Accurate modeling of stress-retarded orientation-dependent 2-D oxidation is carried out by matching the experimental and simulated oxide thicknesses of silicon FIN nanostructures over a wide range of temperatures and times in dry oxygen. Experimentally observed initial oxidation rate enhancement, orientation-dependent stress retardation, and self-limiting phenomena are modeled, and a new universal stress retardation parameter set is obtained for the first time. The new parameter set has been validated against oxidation experiments presented here and those reported in the literature. Furthermore, the new model is used to explore silicon nanowire shape engineering.","Thermal stresses,
Oxidation,
Silicon,
Nanoscale devices,
Nanostructures,
Semiconductor device modeling,
Shape,
Microelectronics,
Temperature distribution,
Predictive models"
META: A Mobility Model of MEtropolitan TAxis Extracted from GPS Traces,"In this paper, we present our study of extracting a mobility model for vehicular ad hoc networks (VANETs) from a large amount of real taxi GPS trace data. In order to capture characteristics of the urban vehicle network from microscopic to macroscopic aspects, we design three parameters and extract their values from the GPS trace data. Using this mobility model, we can generate the synthetic trace to simulate the movement of taxis in the urban area of a metropolis. The validation is carried through extensive comparisons between the synthetic trace and the real trace. Validation results show that our mobility model has a good approximation to the real scenario.","Global Positioning System,
Data mining,
Urban areas,
Telecommunication traffic,
Traffic control,
Roads,
Computer science,
Data engineering,
Ad hoc networks,
Vehicles"
Independent Measurement of SET Pulse Widths From N-Hits and P-Hits in 65-nm CMOS,"A novel circuit design for separating single-event transients due to N-hits and P-hits is described. Measurement results obtained from a 65 nm technology using heavy-ions show different dominant mechanisms for charge collection for P-hits and N-hits. The data collected represent the first such separation of SET pulse widths for 65 nm bulk CMOS technology. For low LET particles, N-hit transients are longer, but for high LET particles, P-hit transients are longer. N-well depth and the parasitic bipolar effect are shown to be the most important parameters affecting transient pulse widths.",
Cost Efficient Erasure Coding Based Routing in Delay Tolerant Networks,"Routing in delay tolerant networks (DTNs) in which most of the nodes are mobile and intermittently connected is a challenging problem because of unpredictable node movements and lack of knowledge of future node connections. To ensure reliability against failures and increase the success rate of delivery, erasure coding technique is used to route messages in DTNs. In this paper, we study how the cost of erasure coding based routing protocols can be reduced. Specifically, we analyze the effects of different spraying algorithms, right parameter selection and splitting spraying phase on the cost of message delivery. We also perform simulations to evaluate the proposed approaches and demonstrate that the cost of erasure coding based routing can be reduced considerably with the proposed strategies while maintaining the delivery rate and delay objectives.","Costs,
Routing,
Disruption tolerant networking,
Peer to peer computing,
Tornadoes,
Spraying,
Delay,
US Government,
Communications Society,
Computer science"
A Compiler-Microarchitecture Hybrid Approach to Soft Error Reduction for Register Files,"For embedded systems, where neither energy nor reliability can be easily sacrificed, this paper presents an energy efficient soft error protection scheme for register files (RFs). Unlike previous approaches, the proposed method explicitly optimizes for energy efficiency and can exploit the fundamental tradeoff between reliability and energy. While even simple compiler-managed RF protection scheme can be more energy efficient than hardware schemes, this paper formulates and solves further compiler optimization problems to significantly enhance the energy efficiency of RF protection schemes by an additional 30% on average, as demonstrated in our experiments on a number of embedded application benchmarks.","Protection,
Error correction codes,
Energy efficiency,
Registers,
Radio frequency,
Hardware,
Error analysis,
Embedded system,
Threshold voltage,
Delay"
RELICS: In-network realization of incentives to combat selfishness in DTNs,"In this paper, we develop a cooperative mechanism, RELICS, to combat selfishness in DTNs. In DTNs, nodes belong to self-interested individuals. A node may be selfish in expending resources, such as energy, on forwarding messages from others, unless offered incentives. We devise a rewarding scheme that provides incentives to nodes in a physically realizable way in that the rewards are reflected into network operation. We call it in-network realization of incentives. We introduce explicit ranking of nodes depending on their transit behavior, and translate those ranks into message priority. Selfishness drives each node to set its energy depletion rate as low as possible while maintaining its own delivery ratio above some threshold. We show that our cooperative mechanism compels nodes to cooperate and also achieves higher energy-economy compared to other previous results.",
RC-MAC: A receiver-centric medium access control protocol for wireless sensor networks,"Wireless sensor networks usually operate under light traffic loads. However, when an event is detected, a large volume of data may be generated and delivered to the sink. The demand for simultaneous data transmission may cause severe channel collision and thus decrease communication throughput in contention-based medium access control (MAC) protocols. In this paper, we introduce a novel receiver-centric data transmission paradigm, which takes advantage of the tree structure that is naturally formed in data collection of a sensor network to assist scheduling of channel access. On the tree structure, a receiver is able to coordinate its multiple senders' channel access so as to reduce channel contention and consequently improve communication throughput. The protocol seamlessly integrates scheduling with contention-based medium access control. In addition, to ensure reliable data transmission, we propose a sequence-based lost packet recovery scheme in a hop-by-hop recovery pattern, which could further improve communication throughput by reducing control overhead. We present the performance of our receiver-centric MAC protocol through measurements of an implementation in TinyOS on TelosB motes and extend the evaluation through ns-2 simulations. Compared with B-MAC and RI-MAC, we show the benefits of improving throughput and fairness through receiver-centric scheduling under heavy traffic loads.","Media Access Protocol,
Wireless application protocol,
Access protocols,
Wireless sensor networks,
Throughput,
Data communication,
Telecommunication traffic,
Tree data structures,
Event detection,
Road accidents"
Rotor-Design Strategy of IPMSM for 42 V Integrated Starter Generator,"In this paper, we proposed an optimal design strategy of interior permanent magnet synchronous machine (IPMSM) considering various design constraints in the 42 V integrated starter generator (ISG). Since conventional optimal process needs much calculating time to check many constraints such as high starting torque, the high generating power at the maximum speed, we adopted AT-MGPSO as an optimization algorithm due to its special advantage that it can efficiently search superior peaks in the multimodal problem with short time. In addition, in order to deal with mechanical stress in the rotor by centrifugal force at maximum speed we combined mechanical stress analysis with the optimal design process. The validity of our proposed methods was verified by comparing simulation results with experimental data.","Rotors,
Stress,
Torque,
Permanent magnet machines,
Power generation,
Process design,
Synchronous generators,
Constraint optimization,
Alternators,
Low voltage"
Capacities for Long-Distance Free-Space Optical Links Under Beam Wander Effects,"The performance of the long-distance horizontal free-space optical (FSO) communication link under beam wander effects is studied from the perspective of information theory. Based on the newly proposed beam wander model and strong fluctuation theory, the influence of beam wander is directly included in the scintillation and then the statistical model for intensity fading is presented. The impact of beam wander on the average and outage capacities of the FSO link is investigated, showing that an optimum transmitter beam radius can be selected to make the system achieve maximum average capacity and minimum probability of capacity outage.","Optical fiber communication,
Optical beams,
Optical transmitters,
Additive white noise,
Optical noise,
Fluctuations,
Capacity planning,
Optical receivers,
Gaussian noise,
Background noise"
Motion planning with hybrid dynamics and temporal goals,"In this paper, we consider the problem of motion planning for mobile robots with nonlinear hybrid dynamics, and high-level temporal goals. We use a multi-layered synergistic framework that has been proposed recently for solving planning problems involving hybrid systems and high-level temporal goals. In that framework, a high-level planner employs a user-defined discrete abstraction of the hybrid system as well as exploration information to suggest high-level plans. A low-level sampling-based planner uses the dynamics of the hybrid system and the suggested high-level plans to explore the state-space for feasible solutions. In previous work, we have proposed a geometry-based approach for the construction of the discrete abstraction for the case when the robot is modeled as a continuous system. Here, we extend the approach for the construction of the discrete abstraction to the case when the robot is modeled as nonlinear hybrid system. To use the resulting abstraction more efficiently, we also propose a lazy-search approach for high-level planning that reduces the size of the search space by reusing previously constructed high-level plans for initializing the search. Our proposed techniques result in computational speedups of close to 10 times over other possible approaches for second-order nonlinear hybrid robot models in challenging workspace environments with obstacles and for a variety of temporal logic specifications.","Trajectory,
Geometry,
Planning,
Automata,
Heuristic algorithms,
Computational modeling"
Capacity of Data Collection in Arbitrary Wireless Sensor Networks,"How to efficiently collect sensing data from all sensor nodes is critical to the performance of wireless sensor networks. In this paper, we aim to understand the theoretical limitations of data collection in terms of possible and achievable maximum capacity. Previously, the study of data collection capacity has only concentrated on large-scale random networks. However, in most of practical sensor applications, the sensor network is not deployed uniformly and the number of sensors may not be as huge as in theory. Therefore, it is necessary to study the capacity of data collection in an arbitrary network. In this paper, we derive the upper and constructive lower bounds for data collection capacity in arbitrary networks. The proposed data collection method can lead to order-optimal performance for any arbitrary sensor networks. We also examine the design of data collection under a general graph model and discuss performance implications.","Wireless sensor networks,
Interference,
Capacitive sensors,
Protocols,
Computer science,
USA Councils,
Sensor phenomena and characterization,
Physical layer,
Communications Society,
Peer to peer computing"
Optimal strategies for countering dual-threat jamming/eavesdropping-capable adversaries in MIMO channels,"This paper investigates transmission strategies in a MIMO wiretap channel with a transmitter, receiver and wiretapper, each equipped with multiple antennas. In a departure from existing work, the wiretapper is able to act either as a passive eavesdropper or as an active jammer per channel use, under a half-duplex constraint. The transmitter therefore faces a choice between dynamically allocating all of its power for data; or broadcasting artificial noise along with the information signal in order to selectively degrade the eavesdropper's channel. We model the network as a zero-sum game in strategic form with the MIMO secrecy rate as the payoff function. We first carry out a detailed analysis of the various rate outcomes that result from the possible actions of the agents. We then discuss the conditions for equilibrium outcomes in the strategic form of the game. Finally, numerical simulations are presented to corroborate the analytical results.","MIMO,
Games,
Jamming,
Niobium,
Interference,
Transmitters,
Receivers"
Optical Reconstruction of High-Speed Surface Dynamics in an Uncontrollable Environment,"The ability to communicate with our voice can be regarded as the concatenation of the two processes “phonation” and “modulation.” These take place in the larynx and palatal and oral region, respectively. During phonation the audible primary voice signal is created by mutual reaction of vocal folds with the exhaled air stream of the lungs. The underlying interactions of masses, fluids and acoustics have yet to be identified and understood. One part of the primary signal's acoustical source are vortex induced vibrations, as e.g., created by the Coandăeffect in the air stream. The development of these vorteces is determined by the shape and 3-D movements of the vocal folds in the larynx. Current clinical in vivo research methods for vocal folds do not deliver data of satisfactory quality for fundamental research, e.g., an endoscope is limited to 2-D image information. Based hereupon, a few improved methods have been presented, however delivering only selective 3-D information, either for a single point or a line. This stands in contrast to the 3-D motions of the entire vocal fold surface. More complex imaging methods, such as MRI, do not deliver information in real-time. Thus, it is necessary to develop an easily applicable, more improved examination method, which allows for 3-D data of the vocal folds surfaces to be obtained. We present a method to calibrate a 3-D reconstruction setup including a laser projection system and a high-speed camera. The setup is designed with miniaturization and an in vivo application in mind. The laser projection system generates a divergent grid of 196 laser dots by diffraction gratings. It is calibrated with a planar calibration target through planar homography. In general, the setup allows to reconstruct the topology of a surface at high frame rates (up to 4000 frames per second) and in uncontrollable environments, as e.g., given by the lighting situation (little to no ambient light) and varying texture (e.g., varying grade of reflection) in the human larynx. In particular, this system measures the 3-D vocal fold surface dynamics during phonation. Applied to synthetic data, the calibration is shown to be robust (error approximately 0.5 ) regarding noise and systematic errors. Experimental data gained with a linear -stage proved that the system reconstructs the 3-D coordinates of points with an error at approximately 15 . The method was applied exemplarily to reconstruct porcine and artificial vocal folds' surfaces during phonation. Local differences such as asymmetry between left and right fold dynamics, as well as global parameters, such as opening and closing speed and maximum displacements, were identified and quantified.",
API access control in cloud using the Role Based Access Control Model,"As cloud is an emerging paradigm of computing, it throws open various challenges and issues. The major issue hindering the growth of popularity of usage of cloud computing is Cloud security. There are numerous cloud security issues, of which this paper addresses the problem of insecure APIs. APIs act as the interface between cloud provider and the customer and the security of cloud computing depends largely on the security of these APIs. Hence a strong API access control mechanism is required. This paper proposes a two stage access control mechanism implemented at the API level using the Role Based Access Control Model (RBAC).","Access control,
Cloud computing,
Organizations,
Computational modeling,
Encyclopedias"
On the Robustness of Transmit Beamforming,"Beamforming is a simple transmit strategy that uses only one eigen-direction in multiple-input multiple-output channels. This simplicity makes beamforming a competitive strategy in practice, but at the same time poses a doubt on the sensitivity of beamforming to the imperfectness of the channel state information at the transmitter (CSIT). This paper studies beamforming from the perspective of worst-case robustness. We show that beamforming can achieve the maximum received signal-to-noise ratio (SNR) or guarantees a given received SNR with the minimum transmit power, in the worst channel within an elliptical uncertainty region defined by the weighted spectral norm. This result further implies that beamforming has the ability to combat against the imperfectness of CSIT, especially for small channel dimensions or small channel uncertainty.","Robustness,
Array signal processing,
Signal to noise ratio,
Transmitters,
Uncertainty,
Channel state information,
Stochastic processes,
Permission,
Postal services,
MIMO"
Image parallel processing based on GPU,"In order to solve the compute-intensive character of image processing, based on advantages of GPU parallel operation, parallel acceleration processing technique is proposed for image. First, efficient architecture of GPU is introduced that improves computational efficiency, comparing with CPU. Then, Sobel edge detector and homomorphic filtering, two representative image processing algorithms, are embedded into GPU to validate the technique. Finally, tested image data of different resolutions are used on CPU and GPU hardware platform to compare computational efficiency of GPU and CPU. Experimental results indicate that if data transfer time, between host memory and device memory, is taken into account, speed of the two algorithms implemented on GPU can be improved approximately 25 times and 49 times as fast as CPU, respectively, and GPU is practical for image processing.","Parallel processing,
Image processing,
Computational efficiency,
Image edge detection,
Concurrent computing,
Acceleration,
Computer architecture,
Detectors,
Filtering algorithms,
Testing"
Reliability of a System of k Nodes for High Performance Computing Applications,"Reliability estimation of High Performance Computing (HPC) systems enables resource allocation, and fault tolerance frameworks to minimize the performance loss due to unexpected failures. Recent studies have shown that compute nodes in HPC systems follow a time varying failure rate distribution such as Weibull, instead of the exponential distribution. In this paper, we propose a model for the Time to Failure (TTF) distribution of a system of k s-independent nodes when individual nodes exhibit time varying failure rates. We also present the system reliability, failure rates, Mean Time to Failure (MTTF), and derivations of the proposed system TTF model. The model is validated using observed data on time to failure.",
nGFSIM : A GPU-based fault simulator for 1-to-n detection and its applications,"We present nGFSIM, a GPU-based fault simulator for stuck-at faults which can report the fault coverage of one-to n-detection for any specified integer n using only a single run of fault simulation. nGFSIM, which explores the massive parallelism in the GPU architecture and optimizes the memory access and usage, enables accelerated fault simulation without the need of fault dropping. We show that nGFSIM offers a 25X speedup in comparison with a commercial tool and enables new applications in test selection.","Circuit faults,
Graphics processing unit,
Integrated circuit modeling,
Instruction sets,
Logic gates,
Computational modeling,
Kernel"
News Filtering and Summarization on the Web,"The news filtering and summarization (NFAS) system can automatically recognize Web news pages, retrieve each news page's title and news content, and extract key phrases. This extraction method substantially outperforms methods based on term frequency and lexical chains.","Information filtering,
Information filters,
Web pages,
Data mining,
Computer science,
Automation,
Educational institutions,
Electronic mail,
Uniform resource locators,
Frequency"
Auto-calibration of cylindrical multi-projector systems,"In this paper we present a novel technique to calibrate multiple casually aligned projectors on a fiducial-free cylindrical curved surface using a single camera. We impose two priors to the cylindrical display: (a) cylinder is a vertically extruded surface; and (b) the aspect ratio of the rectangle formed by the four corners of the screen is known. Using these priors, we can estimate the display's 3D surface geometry and camera extrinsic parameters using a single image without any explicit display to camera correspondences. Using the estimated camera and display properties, we design a novel deterministic algorithm to recover the intrinsic and extrinsic parameters of each projector using a single projected pattern seen by the camera which is then used to register the images on the display from any arbitrary viewpoint making it appropriate for virtual reality systems. Finally, our method can be extended easily to handle sharp corners — making it suitable for the common CAVE like VR setup. To the best of our knowledge, this is the first method that can achieve accurate geometric auto-calibration of multiple projectors on a cylindrical display without performing an extensive stereo reconstruction.",
Novel Capacitive Pressure Sensor,"A new microelectromechanical-systems capacitive pressure sensor with extremely high sensitivity (2.24 ¿F/kPa) is introduced. The sensor essentially consists of a small drop of mercury and a flat aluminum electrode that are separated by a 1 ¿m-thick layer of Barium Strontium Titanate (a high dielectric-constant ceramic). The assembly constitutes a parallel-plate capacitor where the surface area of the electrodes is variable to a high degree. The mercury drop is pressured by a small corrugated metal diaphragm. As the electrode area of the parallel-plate capacitor varies, a total change in capacitance of more than 6 ¿F is obtained.",
Low-cost accelerometers for robotic manipulator perception,"We present a series of experiments which explore the use of consumer-grade accelerometers as joint position sensors for robotic manipulators. We show that 6- and 7-dof joint angle estimation is possible by using one 3-d accelerometer for each pair of joints. We demonstrate two calibration approaches and experimental results using accelerometer-based control in both position-control and torque-control regimes. We present a manipulator design combining accelerometer-based sensing with low-cost actuation, and conclude by demonstrating the utility of consumer-grade accelerometers even on high-precision manipulators.","Manipulators,
Accelerometers,
Robot sensing systems,
Joints,
Calibration"
Parallel I/O performance: From events to ensembles,"Parallel I/O is fast becoming a bottleneck to the research agendas of many users of extreme scale parallel computers. The principle cause of this is the concurrency explosion of high-end computation, coupled with the complexity of providing parallel file systems that perform reliably at such scales. More than just being a bottleneck, parallel I/O performance at scale is notoriously variable, being influenced by numerous factors inside and outside the application, thus making it extremely difficult to isolate cause and effect for performance events. In this paper, we propose a statistical approach to understanding I/O performance that moves from the analysis of performance events to the exploration of performance ensembles. Using this methodology, we examine two I/O-intensive scientific computations from cosmology and climate science, and demonstrate that our approach can identify application and middleware performance deficiencies — resulting in more than 4× run time improvement for both examined applications.","Concurrent computing,
File systems,
Laboratories,
Performance analysis,
Middleware,
High performance computing,
Monitoring,
Large-scale systems,
Supercomputers,
Explosions"
Linear Programming Models For Multi-Channel P2P Streaming Systems,"Most of the commercial P2P video streaming deployments support hundreds of channels and are referred to as multichannel systems. Measurement studies show that bandwidth resources of different channels are highly unbalanced and thus recent research studies have proposed various protocols to improve the streaming qualities for all channels by enabling cross-channel cooperation among multiple channels. However, there is no general framework for comparing existing and potential designs for multi-channel P2P systems. The goal of this paper is to establish tractable models for answering the fundamental question in multi-channel system designs: Under what circumstances, should a particular design be used to achieve the desired streaming quality with the lowest implementation complexity? To achieve this goal, we first classify existing and potential designs into three categories, namely Naive Bandwidth allocation Approach (NBA), Passive Channel-aware bandwidth allocation Approach (PCA) and Active Channel-aware bandwidth allocation Approach (ACA). Then, we define the bandwidth satisfaction ratio as a performance metric to develop linear programming models for the three designs. The proposed models are independent of implementations and can be efficiently solved due to the linear property, which provides a way of numerically exploring the design space of multi-channel systems and developing closedform solutions for special systems.","Linear programming,
Bandwidth,
Streaming media,
Watches,
Channel allocation,
Space exploration,
Resource management,
Communications Society,
Computer science,
USA Councils"
MIMO Broadcast Channels with Spatial Heterogeneity,"We develop a realistic model for multiple-input multiple-output (MIMO) broadcast channels, where each randomly located user's average SNR depends on its distance from the transmitter. With perfect channel state information at the transmitter (CSIT), the average sum capacity is proven to scale for many users like αM/2 log K instead of M log log K, where α, M, and K denote the path loss exponent, the number of transmit antennas, and the number of users in a cell. With only partial CSIT, the sum capacity at high SNR eventually saturates due to interference, and the saturation value scales for large B like MB/M-1, where B denotes the quantization resolution for channel feedback.","MIMO,
Broadcasting,
Interference,
Transmitters,
Transmitting antennas,
Feedback,
Channel state information,
Quantization,
Array signal processing,
Rayleigh channels"
Robustness analysis and new hybrid algorithm of wideband source localization for acoustic sensor networks,"Wideband source localization using acoustic sensor networks has been drawing a lot of research interest recently in wireless communication applications, such as cellular handset localization, global positioning systems (GPS), and land navigation technologies, etc. The maximum-likelihood is the predominant objective which leads to a variety of source localization approaches. However, the appropriate optimization (search) algorithms are still being pursuit by researchers since different aspects about the effectiveness of such algorithms have to be addressed on different circumstances. In this paper, we focus on the two popular source localization methods for wideband acoustic signals, namely the alternating projection (AP) algorithm and the expectation maximization (EM) algorithm. We explore the respective limitations of these two methods and design a new hybrid approach thereupon. Through Monte Carlo simulations, we demonstrate that the trade-off can be achieved between the computational complexity and the localization accuracy using our newly proposed scheme. Moreover, we present the new robustness analysis for the source localization algorithms. We derive the Cramer-Rao lower bound (CRLB) involving the source spectral estimation error and thus prove that the new hybrid algorithm is more efficient than the EM algorithm. By employing the Gaussianity test, we also quantify the statistical mismatch between the actual statistics of the sensor signals and the underlying Gaussian model. We show that the Gaussianity measure can be a reliable robustness figure for source localization.","Robustness,
Algorithm design and analysis,
Wideband,
Acoustic sensors,
Pursuit algorithms,
Gaussian processes,
Wireless communication,
Cellular networks,
Telephone sets,
Global Positioning System"
Towards marine bloom trajectory prediction for AUV mission planning,"This paper presents an oceanographic toolchain that can be used to generate multi-vehicle robotic surveys for large-scale dynamic features in the coastal ocean. Our science application targets Harmful Algal Blooms (HABs) which have significant societal impact to coastal communities yet are poorly understood ecologically. Bloom patches can be large spatially (in kms) and unpredictable in their extent. To understand their ecology, we need to be able to bring back water samples from the ‘right’ places and times for lab analysis. In doing so, we target hotspots representative of intense biogeochemical activity for such sampling. Our approach uses remote sensing data to detect such hotspots using ocean color as a proxy, and advectively projects these patches spatio-temporally using surface current data from HF Radar stations. Experiments with satellite and Radar data sets are promising for large, coherent blooms. We show how these predictions can be used to select an appropriate sampling trajectory for an AUV.",
100-km Long Distance Fiber Bragg Grating Sensor System Based on Erbium-Doped Fiber and Raman Amplification,A simple 100-km long distance fiber Bragg grating sensor system was proposed and demonstrated. It can achieve 100-km measurement length with reflected Bragg wavelength spectrum of 30 dB signal noise ratio by using only one Raman pump laser source with 1 W power at 1395 nm and two segments of erbium-doped fiber at the locations of 50 and 75 km separately.,
2020 Vision,"Based on the wireless world research forum (WWRF) vision of seven trillion wireless devices serving seven billion people by 2020, we identified several key user requirements and a scenario to motivate research on many different technical areas. If addressed successfully by the research community and the industry, innovation in new air interfaces (for high bit rate and capacity and low latency); network architectures (like mobile cloud, mesh networks, or cognitive systems); solutions to privacy, security, and trust; and devices that do not need to be recharged for long periods would unleash an era of the wireless world where: each and every person will be empowered by wireless services. Wireless device(s) will become our interface to the digital world. We will live an ambient life style, such that: 1) our mobile device will become the key enabler to interact with smart environments and users; and 2) our mobile device will be a trusted personal assistant that will be indispensible. We will enjoy and benefit from an untethered-but-connected user experience and ubiquitous service delivery with a consistent user experience.","Mobile communication,
Wireless sensor networks,
Communication system security,
Research and development,
Technological innovation,
Meetings"
Using stereo for object recognition,"There has been significant progress recently in object recognition research, but many of the current approaches still fail for object classes with few distinctive features, and in settings with significant clutter and viewpoint variance. One such setting is visual search in mobile robotics, where tasks such as finding a mug or stapler require robust recognition. The focus of this paper is on integrating stereo vision with appearance based recognition to increase accuracy and efficiency. We propose a model that utilizes a chamfer-type silhouette classifier which is weighted by a prior on scale, which is robust to missing stereo depth information. Our approach is validated on a set of challenging indoor scenes containing mugs and shoes, where we find that priors remove a significant number of false positives, improving the average precision by 0.2 on each dataset. We additionally experiment with an additional classifer by Felzenszwalb et al.[1] to demonstrate the approach's robustness.",
Probabilistic surveillance with multiple active cameras,"In this work we present a consistent probabilistic approach to control multiple, but diverse pan-tilt-zoom cameras concertedly observing a scene. There are disparate goals to this control: the cameras are not only to react to objects moving about, arbitrating conflicting interests of target resolution and trajectory accuracy, they are also to anticipate the appearance of new targets.",
"A probabilistic approach to mixed open-loop and closed-loop control, with application to extreme autonomous driving","We consider the task of accurately controlling a complex system, such as autonomously sliding a car sideways into a parking spot. Although certain regions of this domain are extremely hard to model (i.e., the dynamics of the car while skidding), we observe that in practice such systems are often remarkably deterministic over short periods of time, even in difficult-to-model regions. Motivated by this intuition, we develop a probabilistic method for combining closed-loop control in the well-modeled regions and open-loop control in the difficult-to-model regions. In particular, we show that by combining 1) an inaccurate model of the system and 2) a demonstration of the desired behavior, our approach can accurately and robustly control highly challenging systems, without the need to explicitly model the dynamics in the most complex regions and without the need to hand-tune the switching control law. We apply our approach to the task of autonomous sideways sliding into a parking spot, and show that we can repeatedly and accurately control the system, placing the car within about 2 feet of the desired location; to the best of our knowledge, this represents the state of the art in terms of accurately controlling a vehicle in such a maneuver.","Open loop systems,
Control systems,
Sliding mode control,
Vehicle dynamics,
Automatic control,
Control system synthesis,
State feedback,
Robotics and automation,
USA Councils,
Robust control"
Effects of basis-mismatch in compressive sampling of continuous sinusoidal signals,"The theory of compressive sampling (or compressed sensing) is very attractive in that it is possible to reconstruct some signals with a sub-Nyquist sampling rate provided that they are sparse in some basis domain. But if there exists a mismatch between the signal basis and the pre-defined reconstruction basis, the reconstruction performance is significantly degraded even if the signal is sparse enough. In this paper, the degradation due to this basis mismatch is investigated and a way to minimize the effects of basis mismatch in compressive sampling of continuous sinusoidal signals is discussed.","Sampling methods,
Degradation,
Data acquisition,
Australia,
Compressed sensing,
Length measurement,
Wireless communication,
Doppler shift,
Frequency,
Transmitters"
High Capacity Colored Two Dimensional codes,"Barcodes enable automated work processes without human intervention, and are widely deployed because they are fast and accurate, eliminate many errors and often save time and money. In order to increase the data capacity of barcodes, two dimensional (2D) code were developed; the main challenges of 2D codes lie in their need to store more information and more character types without compromising their practical efficiency. This paper proposes the High Capacity Colored Two Dimensional (HCC2D) code, a new 2D code which aims at increasing the space available for data, while preserving the strong reliability and robustness properties of QR. The use of colored modules in HCC2D poses some new and non-trivial computer vision challenges. We developed a prototype of HCC2D, which realizes the entire Print&Scan process. The performance of HCC2D was evaluated considering different operating scenarios and data densities. HCC2D was compared to other barcodes, such as QR and Microsoft's HCCB; the experiment results showed that HCC2D codes obtain data densities close to HCCB and strong robustness similar to QR.","Image color analysis,
Error correction codes,
Layout,
Robustness,
Encoding,
Hardware,
Prototypes"
Motion Refinement Based Progressive Side-Information Estimation for Wyner-Ziv Video Coding,"During the past ten years, Wyner-Ziv video coding (WZVC) has gained a lot of research interests because of its unique characteristics of ""simple encoding, complex de coding."" However, the performance gap between WZVC and conventional video coding has never been closed to the point promised by the information theory. In this paper, we illustrate the chicken-and-egg dilemma encountered in WZVC: high efficiency WZVC requires good estimation of side information (SI); however, good SI estimation is not possible for the decoder without access to the decoded current frame. To resolve such a dilemma, we present and advocate a framework that explores an important concept of decoder-side progressive-learning. More specifically, a decoder-side multi-resolution motion refinement (MRMR) scheme is proposed, where the decoder is able to learn from the already-decoded lower-resolution data to refine the motion estimation (ME), which in turn greatly improves the SI quality as well as the coding efficiency for the higher resolution data. Theoretical analysis shows that at high rates, decoder-side MRMR outperforms motion extrapolation by as much as 5 dB, while falling behind conventional encoder-side inter-frame ME by only about 1.5 dB. In addition, since decoder-side ME does not suffer from the bit-rate overhead in transmitting the motion information, further performance gain can be achieved for decoder-side MRMR by incorporating fractional-pel motion search, block matching with smaller block sizes, and multiple hypothesis prediction. We also present a practical WZVC implementation with MRMR, which shows comparable coding performance as H.264 at very high bit rates.","Decoding,
Extrapolation,
Encoding,
Accuracy,
Video coding,
Noise"
Autonomous Evolution of Topographic Regularities in Artificial Neural Networks,"Looking to nature as inspiration, for at least the past 25 years, researchers in the field of neuroevolution (NE) have developed evolutionary algorithms designed specifically to evolve artificial neural networks (ANNs). Yet the ANNs evolved through NE algorithms lack the distinctive characteristics of biological brains, perhaps explaining why NE is not yet a mainstream subject of neural computation. Motivated by this gap, this letter shows that when geometry is introduced to evolved ANNs through the hypercube-based neuroevolution of augmenting topologies algorithm, they begin to acquire characteristics that indeed are reminiscent of biological brains. That is, if the neurons in evolved ANNs are situated at locations in space (i.e., if they are given coordinates), then, as experiments in evolving checkers-playing ANNs in this letter show, topographic maps with symmetries and regularities can evolve spontaneously. The ability to evolve such maps is shown in this letter to provide an important advantage in generalization. In fact, the evolved maps are sufficiently informative that their analysis yields the novel insight that the geometry of the connectivity patterns of more general players is significantly smoother and more contiguous than less general ones. Thus, the results reveal a correlation between generality and smoothness in connectivity patterns. They also hint at the intriguing possibility that as NE matures as a field, its algorithms can evolve ANNs of increasing relevance to those who study neural computation in general.",
Detecting and sketching the common,"Given very few images containing a common object of interest under severe variations in appearance, we detect the common object and provide a compact visual representation of that object, depicted by a binary sketch. Our algorithm is composed of two stages: (i) Detect a mutually common (yet non-trivial) ensemble of ‘self-similarity descriptors’ shared by all the input images. (ii) Having found such a mutually common ensemble, ‘invert’ it to generate a compact sketch which best represents this ensemble. This provides a simple and compact visual representation of the common object, while eliminating the background clutter of the query images. It can be obtained from very few query images. Such clean sketches may be useful for detection, retrieval, recognition, co-segmentation, and for artistic graphical purposes.","Object detection,
Shape,
Image retrieval,
Image segmentation,
Computer science,
Mathematics,
Heart,
Software libraries,
Information retrieval,
Image databases"
Sequential Organization of Speech in Reverberant Environments by Integrating Monaural Grouping and Binaural Localization,"Existing binaural approaches to speech segregation place an exclusive burden on cues related to the location of sound sources in space. These approaches can achieve excellent performance in anechoic conditions but degrade rapidly in realistic environments where room reverberation corrupts localization cues. In this paper, we propose to integrate monaural and binaural processing to achieve segregation and localization of voiced speech in reverberant environments. The proposed approach builds on monaural analysis for simultaneous organization, and combines it with a novel method for generation of location-based cues in a probabilistic framework that jointly achieves localization and sequential organization. We compare localization performance to two existing methods, sequential organization performance to a model-based system that uses only monaural cues, and segregation performance to an exclusively binaural system. Results suggest that the proposed framework allows for improved source localization and robust segregation of voiced speech in environments with considerable reverberation.","Reverberation,
Robustness,
Speech analysis,
Time frequency analysis,
Degradation,
Image analysis,
Computer science,
Filtering,
Array signal processing,
Speech processing"
Construction of turbo lattices,"In this work we introduce and establish the concept of turbo lattices. We employ a routine method for constructing lattices, called Construction D, to construct turbo lattices. This kind of construction needs a set of nested linear codes as its underlying structure. We benefit from turbo codes as our bases codes. Therefore, we first build a set of nested turbo codes based on nested interleavers and nested convolutional codes. Then by means of these codes, along with construction D, we construct turbo lattices. Several properties of Construction D lattices and specially many characteristics of turbo lattices including the minimum distance, coding gain, kissing number and the probability of error under a maximum likelihood decoder over AWGN channel are investigated.","Lattices,
Turbo codes,
Convolutional codes,
Generators,
Block codes,
AWGN channels"
On the Equivalence of Finite Element and Finite Integration Formulations,"The paper offers a comparative study of numerical methods of analysis of electromagnetic fields. The focus is on the finite element method (FEM) and finite integration technique (FIT), but with the cell and equivalent network approaches also considered. It is shown how the approximate integrals describing coefficients of the FEM need to be derived for a mesh with parallelepiped elements to achieve consistency with FIT equations. The equivalence of FEM and FIT formulations for a triangular mesh in 2D is highlighted. The TEAM Workshops Problem No. 7 is used as an example for numerical comparisons. Two formulations have been considered: 1) using the edge values of the magnetic vector potential A and the nodal values of the electric scalar potential V; and 2) expressed in terms of the edge values of both magnetic A and electric T-T0 vector potentials.",
Pure and Bayes-Nash Price of Anarchy for Generalized Second Price Auction,"The Generalized Second Price Auction has been the main mechanism used by search companies to auction positions for advertisements on search pages. In this paper we study the social welfare of the Nash equilibria of this game in various models. In the full information setting, socially optimal Nash equilibria are known to exist (i.e., the Price of Stability is 1). This paper is the first to prove bounds on the price of anarchy, and to give any bounds in the Bayesian setting. Our main result is to show that the price of anarchy is small assuming that all bidders play un-dominated strategies. In the full information setting we prove a bound of 1.618 for the price of anarchy for pure Nash equilibria, and a bound of 4 for mixed Nash equilibria. We also prove a bound of 8 for the price of anarchy in the Bayesian setting, when valuations are drawn independently, and the valuation is known only to the bidder and only the distributions used are common knowledge. Our proof exhibits a combinatorial structure of Nash equilibria and uses this structure to bound the price of anarchy. While establishing the structure is simple in the case of pure and mixed Nash equilibria, the extension to the Bayesian setting requires the use of novel combinatorial techniques that can be of independent interest.",
Recognition of Partially Occluded and Rotated Images With a Network of Spiking Neurons,"In this paper, we introduce a novel system for recognition of partially occluded and rotated images. The system is based on a hierarchical network of integrate-and-fire spiking neurons with random synaptic connections and a novel organization process. The network generates integrated output sequences that are used for image classification. The proposed network is shown to provide satisfactory predictive performance given that the number of the recognition neurons and synaptic connections are adjusted to the size of the input image. Comparison of synaptic plasticity activity rule (SAPR) and spike timing dependant plasticity rules, which are used to learn connections between the spiking neurons, indicates that the former gives better results and thus the SAPR rule is used. Test results show that the proposed network performs better than a recognition system based on support vector machines.",
A Generalized Linear Model for Single Event Transient Propagation in Phase-Locked Loops,"A first-order linear model is formulated in closed-form for the examination of transient propagation through charge pump phase-locked loops (PLL). As a result, a novel PLL design parameter-the PLL critical time constant-is discovered as the primary factor influencing extraneous transient generation and propagation through the PLL independent of technology node. Various simulations and experiments have been performed on PLL circuits designed in 130 nm and 90 nm technology nodes. Using the described simulation and laser two-photon absorption (TPA) techniques, the generalized model is shown to accurately predict the output phase displacements and critical time constant of the PLL following transient perturbations, validating the analytical results independent of technology and without the need for calibration parameters. Moreover, the characteristic critical time constant is shown to be valuable for identifying and evaluating the single-event vulnerabilities in charge pump PLL designs.","Phase locked loops,
Transient analysis,
Time frequency analysis,
Voltage-controlled oscillators,
Frequency conversion,
Mathematical model,
Charge pumps"
DiffProbe: Detecting ISP Service Discrimination,"We propose an active probing method, called Differential Probing or DiffProbe, to detect whether an access ISP is deploying forwarding mechanisms such as priority scheduling, variations of WFQ, or WRED to discriminate against some of its customer flows. DiffProbe aims to detect if the ISP is doing one or both of delay discrimination and loss discrimination. The basic idea in DiffProbe is to compare the delays and packet losses experienced by two flows: an Application flow A and a Probing flow P. The paper describes the statistical methods that DiffProbe uses, a novel method for distinguishing between Strict Priority and WFQ-variant packet scheduling, simulation and emulation experiments, and a few real-world tests at major access ISPs.","Traffic control,
Scheduling algorithm,
Statistical analysis,
Emulation,
Testing,
Tomography,
Delay estimation,
Communications Society,
Computer science,
Processor scheduling"
A Queuing Model for Evaluating the Transfer Latency of Peer-to-Peer Systems,"This paper presents a queuing model to evaluate the latency associated with file transfers or replications in peer-to-peer (P2P) computer systems. The main contribution of this paper is a modeling framework for the peers that accounts for the file size distribution, the search time, load distribution at peers, and number of concurrent downloads allowed by a peer. We propose a queuing model that models the nodes or peers in such systems as M/G/1/K processor sharing queues. The model is extended to account for peers which alternate between online and offline states. The proposed queuing model for the peers is combined with a single class open queuing network for the routers interconnecting the peers to obtain the overall file transfer latency. We also show that in scenarios with multipart downloads from different peers, a rate proportional allocation strategy minimizes the download times.","Delay,
Peer to peer computing,
Network servers,
Web server,
Computer applications,
Computer networks,
IP networks,
Telecommunication traffic,
Traffic control,
Performance analysis"
A numerical method for the optimal control of switched systems,"Switched dynamical systems have shown great utility in modeling a variety of systems. Unfortunately, the determination of a numerical solution for the optimal control of such systems has proven difficult, since it demands optimal mode scheduling. Recently, we constructed an optimization algorithm to calculate a numerical solution to the problem subject to a running and final cost. In this paper, we modify our original approach in three ways to make our algorithm's application more tenable. First, we transform our algorithm to allow it to begin at an infeasible point and still converge to a lower cost feasible point. Second, we incorporate multiple objectives into our cost function, which makes the development of an optimal control in the presence of multiple goals viable. Finally, we extend our approach to penalize the number of hybrid jumps. We also detail the utility of these extensions to our original approach by considering two examples.","Optimal control,
Trajectory,
Equations,
Algorithm design and analysis,
Cost function,
Aerospace electronics"
Reducing the number of lines in reversible circuits,"Reversible logic became a promising alternative to traditional circuits because of its applications e.g. in low-power design and quantum computation. As a result, design of reversible circuits attracted great attention in the last years. The number of circuit lines is thereby a major criterion since it e.g. affects the still limited resource of qubits. Nevertheless, all approaches introduced so far for synthesis of complex reversible circuits need a significant amount of additional circuit lines - sometimes orders of magnitude more than the primary inputs. In this paper, we propose a post-process optimization method that addresses this problem. The general idea is to merge garbage output lines with appropriate constant input lines. To this end, parts of the circuits are re-synthesized. Experimental results show that by applying the proposed approach, the number of circuit lines can be reduced by 17% on average - in the best case by more than 40%. At the same time, the increase in the number of gates and the quantum costs, respectively, can be kept small.",
Self-Disciplinary Worms and Countermeasures: Modeling and Analysis,"In this paper, we address issues related to the modeling, analysis, and countermeasures of worm attacks on the Internet. Most previous work assumed that a worm always propagates itself at the highest possible speed. Some newly developed worms (e.g., “Atak” worm) contradict this assumption by deliberately reducing the propagation speed in order to avoid detection. As such, we study a new class of worms, referred to as self-disciplinary worms. These worms adapt their propagation patterns in order to reduce the probability of detection, and eventually, to infect more computers. We demonstrate that existing worm detection schemes based on traffic volume and variance cannot effectively defend against these self-disciplinary worms. To develop proper countermeasures, we introduce a game-theoretic formulation to model the interaction between the worm propagator and the defender. We show that an effective integration of multiple countermeasure schemes (e.g., worm detection and forensics analysis) is critical for defending against self-disciplinary worms. We propose different integrated schemes for fighting different self-disciplinary worms, and evaluate their performance via real-world traffic data.","Computer worms,
Computer crime,
Traffic control,
Distributed computing,
Computer science,
Forensics,
Game theory,
Web and internet services,
Computer networks,
Computer security"
Trust-based Dynamic Web service Composition using Social Network Analysis,"With the increasing popularity of Web services and Service-Oriented Architecture, we need sophisticated infrastructure to discover and compose Web services. Dynamic Web service Composition will gain wider acceptance only when the users know that the solutions obtained are comprised of trust-worthy services. In this paper, we present a framework for a Trust-based Dynamic Web service Composition that not only uses functional and non-functional attributes provided by the Web service description document but also filters and ranks solutions based on their trust rating. With the increasing popularity of Web-based Social Networks like Linkedin, Facebook, Orkut, and Twitter, there is great potential in determining the trust rating of a particular service provider or service provider organization using Social Network Analysis. We present a technique to calculate a trust rating per service using Centrality measure of Social Networks. We use this rating to further filter composition results to produce solutions that are comprised of services provided by trusted providers.",
Capacity Bounds and Low Complexity Transceiver Design for Double-Scattering MIMO Multiple Access Channels,"We investigate the sum capacity and present low complexity transceiver designs for the multiple-input multiple-output (MIMO) multiple access channel (MAC) under a general class of fading, known as double-scattering. We assume that the receiver has perfect channel state information (CSI), while each transmitter only has access to its own statistical CSI. We show that the optimum transmit directions for each user coincide with the eigenvectors of the user's own transmit spatial correlation matrix. We also derive new closed-form upper bounds on the sum capacity of the MIMO MAC under double-scattering, which are subsequently employed to obtain low complexity power allocation policies which are easy to compute, and require each user to know only their own channel statistics. Then, we establish beamforming optimality conditions for all users. Finally, we consider the case as the number of users becomes large, in which case we demonstrate that beamforming is asymptotically optimal.","Transceivers,
MIMO,
Transmitters,
Array signal processing,
Scattering,
Channel state information,
Upper bound,
Receiving antennas,
Fading,
Statistics"
"Revisiting log-linear learning: Asynchrony, completeness and payoff-based implementation","The theory of learning in games has sought to understand how and why equilibria emerge in non-cooperative games. Traditionally, social science literature develops descriptive game theoretic models for players, analyzes the limiting behavior, and generalizes the results for larger classes of games. Recently, there has been a significant amount of research seeking to understand these behavioral models not from a descriptive point of view, but rather from a prescriptive point of view [1]–[4]. The goal is to use these behavioral models as a prescriptive control approach in distributed multi-agent systems where the guaranteed limiting behavior would represent a desirable operating condition.","Games,
Noise,
Multiagent systems,
Economics,
Nash equilibrium,
Joints,
Limiting"
Modeling of the Point Spread Function by Numerical Calculations in Single-Pinhole and Multipinhole SPECT Reconstruction,"In conventional reconstruction of single photon emission computed tomography (SPECT) data acquired with a single-pinhole or multipinhole system, the point spread function (PSF) may be either approximated by some analytical equations or substituted by the sensitivity function, which is the integral of the PSF. We have developed a method to numerically calculate the PSF for a pinhole system in order to improve image resolution over a sensitivity-function-based method. The method calculates the probability of photon penetration through the pinhole edges using a ray-tracing approach. To calculate the transmission by the collimator plate along each ray, we trace the ray through the collimator by analytical calculations. The PSF is calculated for only one detector angle, and a Gaussian rotator is used to rotate the image grid for other detector angles in the iterative reconstruction. To evaluate our method, we measured the sensitivities of four keel-edged single-pinhole plates and scanned an ultramicro Derenzo phantom on a single-pinhole system and a five-pinhole system and performed two mouse bone scans on the five-pinhole system using the 140 keV photons of Tc-99m. The numerical calculations of sensitivities for the single-pinhole plates agreed well with the measurements. Results for both types of data scans showed that modeling of the PSF improved image resolution. In conclusion, we found that modeling of the PSF by numerical calculations increases the resolution of reconstruction for single-pinhole and multipinhole SPECT imaging.","Image reconstruction,
Single photon emission computed tomography,
Image resolution,
Integral equations,
Collimators,
Detectors,
Probability,
Image edge detection,
Ray tracing,
Imaging phantoms"
Design and comparison of NML systolic architectures,"Nanomagnet Logic (NML) is a device architecture that utilizes the magnetization of nano-scale magnets to perform logical operations. NML has been experimentally demonstrated and operates at room temperature. Because the nanomagnets are non-volatile, as data flows through a circuit, it is inherently pipelined. This feature makes NML an excellent fit for systolic architectures, which could enable low-power, high-throughput systems that can address a variety of application-level tasks. When considering possible NML systolic systems, the underlying systolic clocking scheme affects both architectural design and performance. In this paper we explore these issues in the context of two NML designs for convolution. One design is based on a 3-phase clocking scheme and uni-directional dataflow, and another is based on a 2-phase clocking scheme and bi-directional dataflow. We compare the two NML systolic designs in terms of area, delay, and energy. We also compare the NML and CMOS implementations of the design in terms of energy and delay. Results are supported by physical level simulation.","Clocks,
Nanoscale devices,
Delay,
Logic devices,
Magnetization,
Magnets,
Temperature,
Circuits,
Convolution,
Bidirectional control"
Performance evaluation of IEEE 802.11p physical layer infrastructure-to-vehicle real-world measurements,"We evaluate the physical layer of infrastructure-to-vehicle communications from real-world measurements. For the measurements, a prototypical implementation of IEEE 802.11p was deployed in two roadside units (RSUs) along a highway in Austria. The required signal-to-noise ratio (SNR) for achieving a frame-error-ratio (FER) less than 0.1 is estimated from measurements for various configurations of data rate, packet length, and vehicle speed. Evaluations show that for a RSU with an antenna mounted at a low height (1.8m) the required SNR depends on the packet length. This is not the case for a RSU, where the antenna is mounted higher (7.1 m). Further the averaged required SNR over all different parameter settings for the low RSU is 4.6 dB larger compared to the required SNR for the high RSU.","Signal to noise ratio,
Vehicles,
Antennas,
Road transportation,
OFDM,
Conferences,
Antenna measurements"
Influence of Ion Bombardment on Electron Emission of MgO Surface in AC Plasma Display Panel,"The influence of ion bombardment during a sustain discharge on the electron emission of the MgO surface and related driving characteristics of an ac plasma display panel were examined using the cathodoluminescence technique and SIMS analysis. The experimental results showed that severe ion bombardment predominantly sputtered Mg species from the MgO surface, thereby lowering the intensity of the F+ center peak to 3.2 eV due to the elimination of the oxygen vacancy and finally increasing the formative address delay time (Tf) due to an aggravated electron emission capability. Meanwhile, severe ion bombardment also destroyed the shallow trap level, thereby lowering the intensity of the shallow peak to 1.85 eV and eventually increasing the statistical address delay time (Ts) due to a poor electron emission capability from the shallow level. Finally, the aggravated electron emission capability from the shallow level resulted in a reduced wall voltage variation during the address period.","Electron emission,
Plasma displays,
Surface discharges,
Added delay,
Delay effects,
Voltage,
Research and development,
Electron traps,
Surface resistance"
A real-time controller for sustaining thermally relevant acoustic cavitation during ultrasound therapy,"A novel method for sustaining inertial cavitation during high-intensity focused ultrasound (HIFU) exposure in an agar-based tissue-mimicking material is presented. Inertial cavitation occurs during HIFU therapy when the local rarefaction pressure exceeds the inertial cavitation threshold of the insonated medium, and is characterized by broadband acoustic emissions which can be easily detected non-invasively using a passive cavitation detector (PCD). Under the right conditions, inertial cavitation has been previously shown to greatly enhance the rate of heat deposition by redistributing part of the energy carried at the fundamental HIFU frequency to higher frequencies, which are more readily absorbed by visco-elastic media such as soft tissue. However, in the absence of any cavitation control, inertial cavitation activity at the focus decays rapidly over a few seconds of exposure because of the combined effects of cavitation nuclei depletion, bubble dissolution, bubble-bubble interactions, increased vapor pressure caused by heating, and focal shielding caused by pre-focal bubble activity. The present work describes the design, validation, and testing of a real-time adaptive controller, with integrated passive localization capabilities, for sustaining inertial cavitation within the focal region of a HIFU transducer by modulation of the HIFU amplitude. Use of the controller in agar gel, originally at room temperature, has enabled therapeutically relevant temperatures in excess of 55°C to be maintained continuously in the focal region for more than 20 s using significantly less acoustic energy than is required to achieve the same temperature rise in the absence of cavitation control.","Transducers,
Biomedical imaging,
Phantoms,
Real time systems,
Heating,
Acoustic emission"
Quantifying the performance of compressive sensing on scalp EEG signals,"Compressive sensing is a new data compression paradigm that has shown significant promise in fields such as MRI. However, the practical performance of the theory very much depends on the characteristics of the signal being sensed. As such the utility of the technique cannot be extrapolated from one application to another. Electroencephalography (EEG) is a fundamental tool for the investigation of many neurological disorders and is increasingly also used in many non-medical applications, such as Brain-Computer Interfaces. This paper characterises in detail the practical performance of different implementations of the compressive sensing theory when applied to scalp EEG signals for the first time. The results are of particular interest for wearable EEG communication systems requiring low power, real-time compression of the EEG data.",
Exact response-time analysis for fixed-priority preemption-threshold scheduling,"Fixed-priority preemption-threshold scheduling (FPTS) has been proposed as a generalization of fixed-priority preemptive scheduling (FPPS) and fixed-priority non-preemptive scheduling (FPNS) with the aim to improve schedulability and reduce run-time overheads. In this paper, we show that the existing worst-case response time (WCRT) analysis for FPTS is pessimistic and present an exact WCRT analysis. Moreover, we refine the task model for FPTS, making FPTS also a generalization of fixed-priority scheduling with deferred preemption (FPDS). Finally, we present exact analysis for FPTS for this refined task model and an example showing that FPTS can improve on FPPS and FPDS.","Bismuth,
Analytical models,
Time factors,
Processor scheduling,
Real time systems,
Timing,
Computational modeling"
Global Nonlinear Electromagnetic Simulations of Tokamak Turbulence,"The particle-in-cell code ORB5 is a global gyrokinetic turbulence simulation code in tokamak geometry. It has been developed at CRPP, Lausanne, Switzerland, with major contributions from IPP, Garching, Germany, and IPP, Greifswald, Germany, under a long-standing collaboration. The code ORB5 solves the gyrokinetic equations in the whole plasma core, including the magnetic axis. A field-aligned filtering procedure and sophisticated noise-control and heating operators allow for accurate simulations. Recently, the code ORB5 has been extended to include self-consistent perpendicular magnetic field perturbations. The inclusion of magnetic perturbations allows for a comprehensive study of finite β effects on microinstability. In this paper, we present the first linear and nonlinear code results concerning electromagnetic effects on tokamak microinstabilities.","Tokamaks,
Magnetic separation,
Solid modeling,
Geometry,
Collaboration,
Nonlinear equations,
Plasma simulation,
Magnetic cores,
Filtering,
Magnetic noise"
Constrained geocast to support Cooperative Adaptive Cruise Control (CACC) merging,"In this paper we introduce a new geocasting concept to target vehicles based on where they will be in the direct future, in stead of their current position. We refer to this concept as constrained geocast. This may be useful in situations where vehicles have interdependencies based on (future) maneuvers. We have developed a first version of such a protocol in the context of an automated merging application, and tested it using simulations. Results show that the protocol is able to meet the requirements of such applications. Compared to a common geo-broadcast protocol this protocol becomes more reliable as road traffic densities increase, but in other aspects the performance is so far lacking. Based on our experiences with implementing the protocol however we see plenty of room for further improvement.",
Accurate computation of the MGF of the lognormal distribution and its application to sum of lognormals,"Sums of lognormal random variables (RVs) are of wide interest in wireless communications and other areas of science and engineering. Since the distribution of lognormal sums is not log-normal and does not have a closed-form analytical expression, many approximations and bounds have been developed. This paper develops two computational methods for the moment generating function (MGF) or the characteristic function (CHF) of a single lognormal RV. The first method uses classical complex integration techniques based on steepest-descent integration. The saddle point of the integrand is explicitly expressed by the Lambert function. The steepest-descent (optimal) contour and two closely-related closed-form contours are derived. A simple integration rule (e.g., the midpoint rule) along any of these contours computes the MGF/CHF with high accuracy. The second approach uses a variation on the trapezoidal rule due to Ooura and Mori. Importantly, the cumulative distribution function of lognormal sums is derived as an alternating series and convergence acceleration via the Epsilon algorithm is used to reduce, in some cases, the computational load by a factor of 106! Overall, accuracy levels of 13 to 15 significant digits are readily achievable.",
Spectral measure of robustness for Internet topology,"The natural connectivity as a novel robustness measure of complex networks is proposed. The natural connectivity has a clear physical meaning and a simple mathematical formulation. It is shown that the natural connectivity can be derived mathematically from the graph spectrum as an average eigenvalue and that it changes strictly monotonically with the addition or deletion of edges. By comparing the natural connectivity with other typical robustness measures within a scenario of edge elimination, it is demonstrated that the natural connectivity has an acute discrimination which agrees with our intuition. The robustness of global Internet AS-level topology and Chinese Internet AS-level topology is studied using natural connectivity.","Robustness,
Logic gates"
Urban-X: Towards distributed channel assignment in cognitive multi-radio mesh networks,"Researches about multi-radio mesh networks have mostly focused on channel allocation under internal interference. However, the deployment of WMNs in unlicensed bands of dense urban areas imposes many challenges regarding co-existence with residential access points. In this paper, we propose Urban-X, which is a first attempt towards a new architecture for MultiRadio Cognitive Mesh Networks. We develop a novel channel assignment that reflects channel and residential traffic state of external users to maximize network throughput. We evaluate our approach using an enhancement of the ns-2 simulator. Urban-X demonstrate the feasibility of our approach and show robustness to variation of channel environment and external user traffic.",
Fast human detection with cascaded ensembles on the GPU,"We investigate a fast pedestrian localization framework that integrates the cascade-of-rejectors approach with the Histograms of Oriented Gradients (HoG) features on a data parallel architecture. The salient features of humans are captured by HoG blocks of variable sizes and locations which are chosen by the AdaBoost algorithm from a large set of possible blocks. We use the integral image representation for histogram computation and a rejection cascade in a sliding-windows manner, both of which can be implemented in a data parallel fashion. Utilizing the NVIDIA CUDA framework to realize this method on a Graphics Processing Unit (GPU), we report a speed up by a factor of 13 over our CPU implementation. For a 1280×960 image our parallel technique attains a processing speed of 2.5 to 8 frames per second depending on the image scanning density, which is similar to the recent GPU implementation of the original HoG algorithm in [3].","Humans,
Histograms,
Central Processing Unit,
Support vector machines,
Support vector machine classification,
Concurrent computing,
Graphics,
Detectors,
Intelligent vehicles,
USA Councils"
Learning Gaussian Tree Models: Analysis of Error Exponents and Extremal Structures,"The problem of learning tree-structured Gaussian graphical models from independent and identically distributed (i.i.d.) samples is considered. The influence of the tree structure and the parameters of the Gaussian distribution on the learning rate as the number of samples increases is discussed. Specifically, the error exponent corresponding to the event that the estimated tree structure differs from the actual unknown tree structure of the distribution is analyzed. Finding the error exponent reduces to a least-squares problem in the very noisy learning regime. In this regime, it is shown that the extremal tree structure that minimizes the error exponent is the star for any fixed set of correlation coefficients on the edges of the tree. If the magnitudes of all the correlation coefficients are less than 0.63, it is also shown that the tree structure that maximizes the error exponent is the Markov chain. In other words, the star and the chain graphs represent the hardest and the easiest structures to learn in the class of tree-structured Gaussian graphical models. This result can also be intuitively explained by correlation decay: pairs of nodes which are far apart, in terms of graph distance, are unlikely to be mistaken as edges by the maximum-likelihood estimator in the asymptotic regime.","Error analysis,
Tree data structures,
Tree graphs,
Error probability,
Graphical models,
Maximum likelihood estimation,
Gaussian distribution,
Signal processing algorithms,
Noise reduction,
Information theory"
Simulating the Electro-Mechanical Behavior of Skeletal Muscles,"Computational models of the human body must be accurate enough to use in hypothesis testing or biological function analysis. This is possible only when such models use physiological information from different scales-such as the cell, tissue, and organ levels. This model of excitation-contraction coupling in skeletal muscles links cell-level electro-physiological behavior with organ-level biomechanical behavior.","Muscles,
Biological system modeling,
Humans,
Musculoskeletal system,
Heart,
Computational modeling,
Biology computing,
Testing,
Joining processes,
Elasticity"
UV-diagram: A Voronoi diagram for uncertain data,"The Voronoi diagram is an important technique for answering nearest-neighbor queries for spatial databases. In this paper, we study how the Voronoi diagram can be used on uncertain data, which are inherent in scientific and business applications. In particular, we propose the Uncertain-Voronoi Diagram (or UV-diagram in short). Conceptually, the data space is divided into distinct “UV-partitions”, where each UV-partition P is associated with a set S of objects; any point q located in P has the set S as its nearest neighbor with non-zero probabilities. The UV-diagram facilitates queries that inquire objects for having non-zero chances of being the nearest neighbor of a given query point. It also allows analysis of nearest neighbor information, e.g., finding out how many objects are the nearest neighbors in a given area. However, a UV-diagram requires exponential construction and storage costs. To tackle these problems, we devise an alternative representation for UV-partitions, and develop an adaptive index for the UV-diagram. This index can be constructed in polynomial time. We examine how it can be extended to support other related queries. We also perform extensive experiments to validate the effectiveness of our approach.","Nearest neighbor searches,
Spatial databases,
Satellite broadcasting,
Lungs,
Sun,
Computer science,
Data engineering,
Knowledge engineering,
Information analysis,
Costs"
Design of A ternary barrel shifter using multiple-valued reversible logic,"Multiple-valued reversible logic is emerging as a promising computing paradigm as it helps in reducing the width of the reversible or quantum circuits. Further, a barrel shifter that can shift and rotate multiple bits in a single cycle forms the essence of many computing systems. In this paper, we propose an efficient architecture and design of a reversible ternary barrel shifter. The ternary barrel shifter is realized using the Modified Fredkin gates (MFG) and the ternary Feynman gates. The design is evaluated in terms of quantum cost, the number of garbage outputs and the number of ancilla bits. To our knowledge, the use of multiple valued reversible logic for the design of a barrel shifter is being attempted for the first time in the literature.","Logic gates,
Quantum computing,
Computer architecture,
Multiplexing,
Iron,
Quantum cascade lasers,
Heating"
Ultrasonic Energy Transmission and Conversion Using a 2-D MEMS Resonator,"This letter reports a novel ultrasonic-based method to power biosensors. Compared with commonly used radio-frequency radiation methods, ultrasonic power transmission is relatively safe for the human body and does not cause electronic interference. To extract ambient kinetic energy with arbitrary motion directions, a novel 2-D microelectromechanical systems energy converter is designed with resonance frequencies of 38520 and 38725 Hz. Working in the diagonal direction, the device has a bandwidth of 302 Hz, which is twice wider than that of a comparable 1-D resonator device. A storage capacitor is charged up to 0.95 V in 15 s, when the converter is driven by an ultrasonic transducer at a distance of 0.5 cm, indicating the energy-conversion capability of 21.4 nW.","Micromechanical devices,
Biosensors,
Radio frequency,
Power transmission,
Humans,
Radiofrequency interference,
Kinetic energy,
Microelectromechanical systems,
Resonance,
Frequency conversion"
Learning with Positive and Unlabeled Examples Using Topic-Sensitive PLSA,"It is often difficult and time-consuming to provide a large amount of positive and negative examples for training a classification system in many applications such as information retrieval. Instead, users often find it easier to indicate just a few positive examples of what he or she likes, and thus, these are the only labeled examples available for the learning system. A large amount of unlabeled data are easier to obtain. How to make use of the positive and unlabeled data for learning is a critical problem in machine learning and information retrieval. Several approaches for solving this problem have been proposed in the past, but most of these methods do not work well when only a small amount of labeled positive data are available. In this paper, we propose a novel algorithm called Topic-Sensitive pLSA to solve this problem. This algorithm extends the original probabilistic latent semantic analysis (pLSA), which is a purely unsupervised framework, by injecting a small amount of supervision information from the user. The supervision from users is in the form of indicating which documents fit the users' interests. The supervision is encoded into a set of constraints. By introducing the penalty terms for these constraints, we propose an objective function that trades off the likelihood of the observed data and the enforcement of the constraints. We develop an iterative algorithm that can obtain the local optimum of the objective function. Experimental evaluation on three data corpora shows that the proposed method can improve the performance especially only with a small amount of labeled positive data.",
Intelligent cross road traffic management system (ICRTMS),"The aim of this research is to provide a design of an integrated intelligent system for management and controlling traffic lights based on distributed long range Photoelectric Sensors in distances prior to and after the traffic lights. The appropriate distances for sensors are chosen by the traffic management department so that they can monitor cars that are moving towards a specific traffic and then transfer this data to the intelligent software that are installed in the traffic control cabinet, which can control the traffic lights according to the measures that the sensors have read, and applying a proposed algorithm based on the total calculated relative weight of each road. Accordingly, the system will open the traffic that are overcrowded and give it a longer time larger than the given time for other traffics that their measures proved that their traffic density is less. This system can be programmed with very important criteria that enable it to take decisions for intelligent automatic control of traffic lights. Also the proposed system is designed to accept information about any emergency case through an active RFID based technology. Emergency cases such as the passing of presidents, ministries and ambulances vehicles that require immediate opening for the traffic automatically. The system has the ability to open a complete path for such emergency cases from the next traffic until reaching the target destination. (end of the path). As a result the system will guarantee the fluency of traffic for such emergency cases or for the main vital streets and paths that require the fluent traffic all the time, without affecting the fluency of traffic generally at normal streets according to the time of the day and the traffic density. Also the proposed system can be tuned to run automatically without any human intervention or can be tuned to allow human intervention at certain circumstances.",
Precoding Design for Multi-Antenna Multicast Broadcast Services With Limited Feedback,"The provision for spectrally efficient multicast broadcast services (MBS) is one of the key functional requirements for next generation wireless communication systems. The challenge inherent to MBS is to ensure that all MBS users can be served, and one effective solution to this problem is to employ MIMO multicast transmit precoding. In previous works on MIMO multicast transmit precoding design, the authors either assumed (1) perfect transmitter-side channel state information (CSIT) or (2) special channel conditions that facilitate precoder design with imperfect CSIT. In this paper, we focus on transmit precoding design for MBS where the CSIT is obtained via limited feedback. In addition, we analyze the average minimum receive signal-noise-ratio (RxSNR) among the MBS users and study the order of growth with respect to the number of MBS users, the number of feedback bits, and the number of transmit antennas. Finally, we propose a threshold based feedback reduction scheme and study the tradeoff between feedback cost and performance loss.",
The Geometry of Visual Perception: Retinotopic and Nonretinotopic Representations in the Human Visual System,"Geometry is closely linked to visual perception; yet, very little is known about the geometry of visual processing beyond early retinotopic organization. We present a variety of perceptual phenomena showing that a retinotopic representation is neither sufficient nor necessary to support form perception. We discuss the popular ¿object files¿ concept as a candidate for nonretinotopic representations and, based on its shortcomings, suggest future directions for research using local manifold representations. We suggest that these manifolds are created by the emergence of dynamic reference-frames that result from motion segmentation. We also suggest that the metric of these manifolds is based on relative motion vectors.",
A study on threat model for federated identities in federated identity management system,"Federated Identity Management (FIM) based on standards allows and facilitates participating federated organizations to share users identity attributes, facilitate authentication and grant or deny service access requests. Using single sign-on facility users authenticates only once to home identity provider and logged into access successive service providing service providers within federation. User's identity theft, misused of user identity information via single sign-on facility in identity providers and service providers, and trustworthiness of subject, identity providers and service providers are active concerns in federated identity management systems. In addition, we had explored trusted computing technology, which covers Trusted Platform Module security features such as Trusted Platform Module Identity, Integrity Measurement and Key certification as well as Trusted Network Connect. In this paper, we presented conceptual threat model for inter-domain web single sign-on in federate identity management system. For this, we set identity theft, misused of identity information, and trust relationship scenarios and in the end, we discussed how trusted computing technology use can effectively resolve identity theft, misused of identity information, and trust relationship concerns in federated identity management system.",
A hierarchical approach to autonomic network management,"Recently, the autonomic communication networks paradigm has been introduced as a solution to the increasing management complexity of communication networks in the Future Internet. In order to encompass the large-scale nature of these networks, a general consensus has been reached that the supporting autonomic management architectures should be distributed for scalability reasons. However, several open issues related to the distribution of autonomic components remain to be solved. In this paper, we propose a novel approach to structuring distributed autonomic components in large-scale communication networks. The approach is generic and can be applied to many existing autonomic architectures and control loops. The autonomic components are structured in a hierarchy, which simplifies the interaction between components, and allows them to manage resources and govern child components in a more scalable manner. In addition to giving a detailed description of the hierarchical architecture, the advantages of the proposed approach are validated through analytical evaluation results.",
Robust Processing of Optical Flow of Fluids,"This paper proposes a new approach, coupling physical models and image estimation techniques, for modelling the movement of fluids. The fluid flow is characterized by turbulent movement and dynamically changing patterns which poses challenges to existing optical flow estimation methods. The proposed methodology, which relies on Navier-Stokes equations, is used for processing fluid optical flow by using a succession of stages such as advection, diffusion and mass conservation. A robust diffusion step jointly considering the local data geometry and its statistics is embedded in the proposed framework. The diffusion kernel is Gaussian with the covariance matrix defined by the local second derivatives. Such an anisotropic kernel is able to implicitly detect changes in the vector field orientation and to diffuse accordingly. A new approach is developed for detecting fluid flow structures such as vortices. The proposed methodology is applied on artificially generated vector fields as well as on various image sequences.",
Adaptive Real-Time Bioheat Transfer Models for Computer-Driven MR-Guided Laser Induced Thermal Therapy,"The treatment times of laser induced thermal therapies (LITT) guided by computational prediction are determined by the convergence behavior of partial differential equation (PDE)-constrained optimization problems. In this paper, we investigate the convergence behavior of a bioheat transfer constrained calibration problem to assess the feasibility of applying to real-time patient specific data. The calibration techniques utilize multiplanar thermal images obtained from the nondestructive in vivo heating of canine prostate. The calibration techniques attempt to adaptively recover the biothermal heterogeneities within the tissue on a patient-specific level and results in a formidable PDE constrained optimization problem to be solved in real time. A comprehensive calibration study is performed with both homogeneous and spatially heterogeneous biothermal model parameters with and without constitutive nonlinearities. Initial results presented here indicate that the calibration problems involving the inverse solution of thousands of model parameters can converge to a solution within three minutes and decrease the ||·||L 2 2 (0,T;L 2 (¿)) norm of the difference between computational prediction and the measured temperature values to a patient-specific regime.",
A Low-Voltage Energy-Sampling IR-UWB Digital Baseband Employing Quadratic Correlation,"This paper describes a digital baseband designed for use in a non-coherent IR-UWB system. Owing to the nonlinear statistics introduced by the energy-sampling RF front-end, the baseband employs a new quadratic correlation technique that achieves comparable performance to a matched filter classifier, with the added benefit of being robust to SNR estimation errors. Additionally, “alias-free codes” are introduced that allow for pulse-level synchronization accuracy without requiring any increase in front-end complexity. Fabricated in a 90 nm CMOS process, the digital baseband utilizes significant parallelism in addition to clock and data gating to achieve low-power operation, with supply voltages as low as 0.55 V. At a clock frequency of 32 MHz, the baseband requires 14-to-79 μs to process a preamble during which it consumes an average power of 1.6 mW, while payload demodulation requires 12 pJ/bit.","Baseband,
Clocks,
Error analysis,
Radio frequency,
Matched filters,
Robustness,
Estimation error,
Frequency synchronization,
CMOS process,
Low voltage"
A Multistate Multipath Provisioning Scheme for Differentiated Failures in Telecom Mesh Networks,"Telecommunication networks spanning large areas are subject to various failures, such as natural disasters, operation errors, and malicious attacks. Disaster failures (DFs) are those, which can lead to a large-area malfunction and degrade the performance of a backbone telecom mesh network. A survivable network provisioning scheme that can recognize and address multiple levels of network failures, including DFs, is desirable for the future Internet. We study the characteristics of multiple failures in telecom mesh networks, such as optical wavelength-division-multiplexed (WDM) networks. In particular, we devise a novel provisioning scheme for telecom mesh networks, which can efficiently exploit the network connectivity using multiple paths. Three provisioning states are defined, in response to single-link failure (SF), multiple-link failure (MF), and DF. We integrate the conventional primary-backup method with reprovisioning and degraded service (i.e., a reduced level of service versus no service at all) into a state-transition model to handle different levels of failures. A predefined level of service is guaranteed for premium customers even if the service cannot be fully recovered. Multinode failures within the same shared risk group (SRG) and failures on destination node are also considered in our study. Our results show that: 1) connection-dropping probability due to a node failure can be significantly reduced with a small extra cost in SF protection; 2) for single-node failure, our algorithm achieves better performance than the shortest vertex-disjoint algorithm; and 3) remote-site data replication is effective to protect against destination-node failures.","Telecommunications,
Mesh networks,
Degradation,
Protection,
Spine,
IP networks,
Optical fiber networks,
Wavelength division multiplexing,
WDM networks,
Costs"
Simple and high-efficiency photovoltaic system under non-uniform operating conditions,"The interest in improving the efficiency of photovoltaic (PV) system has emerged because of increasing the number of home-based or small-scale PV power system. However, the home-based PV system is vulnerable to the non-uniform operating conditions. Under such circumstances, multiple-local maximum power points (MPPs) occur on the power-voltage characteristics and an advanced control algorithm is required to track the global MPP. It is very difficult to provide a sophisticated control algorithm because of the non-linear characteristics of PV system. This study describes the potential to improve the efficiency of PV arrays under non-uniform operating conditions by using the conventional hill-climbing MPP tracking method in total cross tied (TCT) connected PV arrays, in which each group of series connected solar cells that belong to single bypass diode is interconnected. The various scenarios were tested and the results indicate that the efficiency of the proposed system is much higher than that of the same size of series-parallel (SP) PV array configuration.",
How Reliable Can Two-Path Protection Be?,"This paper investigates the subject of reliability via two link-disjoint paths in mesh networks. We address the issues of how reliable two-path protection can be and how to achieve the maximum reliability. This work differs from traditional studies, such as MIN-SUM, MIN-MAX, and MIN-MIN, in that the objective in this paper is to maximize the reliability of the two-path connection given the link reliability, or equivalently, to minimize the end-to-end failure probability. We refer to this problem as MAX-REL. Solving MAX-REL provides 100% protection against a single failure while maximizing the reliability regardless of how many link failures occur in the network. We prove that this problem is NP-complete and derive a corresponding upper bound, which is the theoretical maximum reliability for a source-destination pair, and a lower bound, which is the worst case of the proposed algorithm. The time efficiency of the algorithms is analyzed, and the performance of the algorithms is evaluated through simulation. We demonstrate that our heuristic algorithms not only achieve a low computing complexity, but also achieve nearly equivalent performance to the upper bound.",
A Study on Loss Characteristics of IPMSM for FCEV Considering the Rotating Field,"This paper presented the loss characteristics of interior permanent-magnet machines (IPMSM) for a fuel-cell electric vehicle. In order to study the loss characteristics of the machine, one prototype machine having 100 [kW] was designed. In the analysis, to consider the harmonic magnetic field and the rotational variation of flux vectors in the core of the machine effectively, we proposed a new harmonic iron-loss calculation method based on adaptive loss coefficients. To verify the performance of the proposed method, we calculated a no-load iron loss in an IPMSM with conventional methods. Then, the estimated iron losses were compared with the experimental data. It was clarified that the proposed method is more effective than conventional methods at high-speed operation. Based on this proposed method, we investigated the losses of the machine considering operating points according to its speed. From the results, it was shown that the main loss component and the location of iron-loss distribution change depending on operating condition.",
Asymptotic Critical Transmission Radius for k-Connectivity in Wireless Ad Hoc Networks,"A range assignment to the nodes in a wireless ad hoc network induces a topology in which there is an edge between two nodes if and only if both of them are within each other's transmission range. The critical transmission radius for k-connectivity is the smallest r such that if all nodes have the transmission radius r, the induced topology is k -connected. In this paper, we study the asymptotic critical transmission radius for k -connectivity in a wireless ad hoc network whose nodes are uniformly and independently distributed in a unit-area square or disk. We provide a precise asymptotic distribution of the critical transmission radius for k -connectivity. In addition, the critical neighbor number for k -connectivity is the smallest integer l such that if every node sets its transmission radius equal to the distance between itself and its l-th nearest neighbor, the induced (symmetric) topology is k-connected. Applying the critical transmission radius for k-connectivity, we can obtain an asymptotic almost sure upper bound on the critical neighbor number for k-connectivity.","Network topology,
Mobile ad hoc networks,
Nearest neighbor searches,
Computer science,
Upper bound,
Joining processes,
Mobile computing,
Computer networks,
Materials science and technology,
Cities and towns"
GPU implemention of fast Gabor filters,"With their parallel multi-core architecture, Programmable Graphics Processing Units (GPUs) are well suited for implementing biologically-inspired visual processing algorithms, such as Gabor filtering. We compare several GPU implementations of Gabor filtering. On the same graphics card (an NVIDIA GeForce 9800 GTX+) and for convolution kernel radii from 8 to 48 pixels, an algorithm that decomposes Gabor filtering into a number of simpler steps results in an algorithm that is 2.2 to 33 times faster than direct 2D convolution and 2.8 to 6.6 times faster than a FFT based approach. Surprisingly, in comparison with an optimized algorithm for Gabor filtering running on a PC (Core2 Duo 3.16GHz), it is only 4–10 times faster. The PC can efficiently implement a recursive 1D filter, which requires far fewer arithmetic operations than convolution. However, due to data dependencies, this recursive filter typically runs slower than 1D convolution on the GPU. This highlights the importance of simultaneously considering both arithmetic and memory operations in porting algorithms to GPUs.","Gabor filters,
Convolution,
Filtering algorithms,
Kernel,
Graphics,
Arithmetic,
Frequency,
Demodulation,
Computer architecture,
Neurons"
Approximate confidence computation in probabilistic databases,"This paper introduces a deterministic approximation algorithm with error guarantees for computing the probability of propositional formulas over discrete random variables. The algorithm is based on an incremental compilation of formulas into decision diagrams using three types of decompositions: Shannon expansion, independence partitioning, and product factorization. With each decomposition step, lower and upper bounds on the probability of the partially compiled formula can be quickly computed and checked against the allowed error.",
Predicting Protein Function by Frequent Functional Association Pattern Mining in Protein Interaction Networks,"Predicting protein function from protein interaction networks has been challenging because of the complexity of functional relationships among proteins. Most previous function prediction methods depend on the neighborhood of or the connected paths to known proteins. However, their accuracy has been limited due to the functional inconsistency of interacting proteins. In this paper, we propose a novel approach for function prediction by identifying frequent patterns of functional associations in a protein interaction network. A set of functions that a protein performs is assigned into the corresponding node as a label. A functional association pattern is then represented as a labeled subgraph. Our frequent labeled subgraph mining algorithm efficiently searches the functional association patterns that occur frequently in the network. It iteratively increases the size of frequent patterns by one node at a time by selective joining, and simplifies the network by a priori pruning. Using the yeast protein interaction network, our algorithm found more than 1400 frequent functional association patterns. The function prediction is performed by matching the subgraph, including the unknown protein, with the frequent patterns analogous to it. By leave-one-out cross validation, we show that our approach has better performance than previous link-based methods in terms of prediction accuracy. The frequent functional association patterns generated in this study might become the foundations of advanced analysis for functional behaviors of proteins in a system level.","Iterative algorithms,
Computer science,
Protein engineering,
Prediction methods,
Fungi,
Pattern matching,
Accuracy,
Pattern analysis,
Crosstalk,
Sampling methods"
Cooperative Bridges: Topology Control in Cooperative Wireless Ad Hoc Networks,"Cooperative Communication (CC) is a technology that allows multiple nodes to simultaneously transmit the same data. It can save power and extend transmission coverage. However, prior research work on topology control considers CC only in the aspect of energy saving, not that of coverage extension. We identify the challenges in the development of a centralized topology control scheme, named Cooperative Bridges, which reduces transmission power of nodes as well as increases network connectivity. We observe that CC can bridge (link) disconnected networks. We propose two algorithms that select the most energy efficient neighbor nodes, which assist a source to communicate with a destination node; an optimal method and a greedy heuristic. In addition we consider a distributed version of the proposed topology control scheme. Our findings are substantiated by an extensive simulation study, through which we show that the Cooperative Bridges scheme substantially increases the connectivity while consuming a similar amount of transmission power compared to other existing topology control schemes.","Bridges,
Network topology,
Mobile ad hoc networks,
Communication system control,
Peer to peer computing,
Computer science,
Centralized control,
Data engineering,
Communications Society,
Power engineering and energy"
Efficient Scheduling and Grant Sizing Methods for WDM PONs,"Bandwidth allocation and transmission grant scheduling are problems of particular interest to multichannel passive optical networks (PONs). While prior studies have addressed each of these subproblems separately, to the best of our knowledge, a study on the joint problem has been lacking. In this paper, we first revisit the sequential model and derive a more efficient Integer Linear Program (ILP) for the nonjoint problem that yields up to nearly 12% reduction in makespan and 11% increase in average channel utilization. Then, we investigate the joint problem of bandwidth allocation and transmission grant scheduling in multichannel optical access networks using a scheduling theoretic approach. We derive two ILP models and compare them with the sequential model. Results show that joint scheduling and sizing algorithm achieves significant improvement in terms of scheduling cycle length when compared to the nonjoint models. Since the models for the joint problem was shown to be very hard to solve, except for small-sized networks, we introduce a Tabu search heuristic that provides near-optimal solutions in significantly shorter times. We further perform a packet-level simulation to study the benefit of our new methods.","Wavelength division multiplexing,
Passive optical networks,
Optical network units,
Channel allocation,
Optical fiber networks,
Bandwidth,
EPON,
Computer science,
Access protocols,
Optical control"
Bio-Inspired Adaptive Hyperspectral Imaging for Real-Time Target Tracking,"In this paper, we present an efficient and novel approach to embed hyperspectral imaging (HSI) capability in an intelligent panoramic scanning system for real-time target tracking and signature acquisition. The sensor platform we propose consists of a dual-panoramic peripheral vision component and a narrow field-of-view (FOV) HSI component. The panoramic HSI design optimizes the tradeoff of a wide FOV, a high-spatial/spectral resolution in real-time imaging, and bandwidth limitations. The dual-panoramic scanners with a hyperspectral fovea sensor platform improves some existing designs in literature in three aspects: 1) a panoramic view is provided instead of just a normal wide-angle view; 2) a dual scanning system is designed to obtain moving targets in a very effective and efficient manner; and 3) active control of the hyperspectral sensor is added to facilitate signature acquisition of targets of various locations that is required in real time for target tracking.",
The Power of One Move: Hashing Schemes for Hardware,"In a standard multiple-choice hashing scheme, each item is stored in one of hash table buckets. The availability of choice in where items are stored improves space utilization. These schemes are often very amenable to a hardware implementation, such as in a router. Recently, researchers have discovered powerful variants where items already in the hash table may be moved during the insertion of a new item. Unfortunately, these schemes occasionally require a large number of items to be moved to perform an insertion, making them inappropriate for a hardware implementation. We show that it is possible to significantly increase the space utilization of multiple-choice hashing schemes by allowing at most one item to be moved during an insertion. Furthermore, our schemes can be effectively analyzed, optimized, and compared using numerical methods based on fluid limit arguments, without resorting to much slower simulations.",
Ideal AFROC and FROC Observers,"Detection of multiple lesions in images is a medically important task and free-response receiver operating characteristic (FROC) analyses and its variants, such as alternative FROC (AFROC) analyses, are commonly used to quantify performance in such tasks. However, ideal observers that optimize FROC or AFROC performance metrics have not yet been formulated in the general case. If available, such ideal observers may turn out to be valuable for imaging system optimization and in the design of computer aided diagnosis techniques for lesion detection in medical images. In this paper, we derive ideal AFROC and FROC observers. They are ideal in that they maximize, amongst all decision strategies, the area, or any partial area, under the associated AFROC or FROC curve. Calculation of observer performance for these ideal observers is computationally quite complex. We can reduce this complexity by considering forms of these observers that use false positive reports derived from signal-absent images only. We also consider a Bayes risk analysis for the multiple-signal detection task with an appropriate definition of costs. A general decision strategy that minimizes Bayes risk is derived. With particular cost constraints, this general decision strategy reduces to the decision strategy associated with the ideal AFROC or FROC observer.",
Emerging low energy Wearable Body Sensor Networks using patch sensors for continuous healthcare applications,"Three emerging Wearable Body Sensor Networks (WBSN) using patch type sensors are examined and compared. Unique WBSN environment issues and techniques to overcome those issues are presented for continuous healthcare applications. The first is the battery powered RF patch sensor WBSN (Type 1); it maximizes user-convenience and is suitable for short-term healthcare. The second is the wirelessly powered patch sensor WBSN (Type 2); the proposed patch adopts Planar Fashionable Circuit Board (P-FCB) for pervasiveness and safety, and a base station controls an array of inductors that automatically configure sensor positions around the body. The Type 2 WBSN fits for long-term healthcare. Finally, a snap fastener patch sensor WBSN (Type 3) is proposed. This is the most secure method among 3. Again, P-FCB increases pervasiveness. A snap fastener provides secure power and data channels between sensors and a base station.","Sensors,
Monitoring,
Batteries,
Medical services,
Base stations,
Biomedical monitoring,
Fasteners"
Contour people: A parameterized model of 2D articulated human shape,"We define a new “contour person” model of the human body that has the expressive power of a detailed 3D model and the computational benefits of a simple 2D part-based model. The contour person (CP) model is learned from a 3D SCAPE model of the human body that captures natural shape and pose variations; the projected contours of this model, along with their segmentation into parts forms the training set. The CP model factors deformations of the body into three components: shape variation, viewpoint change and part rotation. This latter model also incorporates a learned non-rigid deformation model. The result is a 2D articulated model that is compact to represent, simple to compute with and more expressive than previous models. We demonstrate the value of such a model in 2D pose estimation and segmentation. Given an initial pose from a standard pictorial-structures method, we refine the pose and shape using an objective function that segments the scene into foreground and background regions. The result is a parametric, human-specific, image segmentation.","Humans,
Shape,
Biological system modeling,
Deformable models,
Image segmentation,
Mathematical model,
Solid modeling,
Belief propagation,
Mathematics,
Computer science"
Improved single image dehazing using segmentation,"In the hazy weather, the image of outdoor scene is degraded by suspended particles. Scattering and absorption hinder scene radiance and bring in environment light into camera. In this work, a novel algorithm is introduced to restore the clear day image by the segmented hazy image. First, the existing visibility restoration model is analyzed and a conclusion is drawn that the model will violate the contrast enhancement constraint in some specific situations. Next, the graph-based image segmentation method is applied to segment the hazed image by choosing the optimal parameter. Then, the transmission maps prior are obtained according to the blackbody theory. After that, a bilateral filter is designed to amend the transmission map, which can make up the deficiency of restoration model and ensure the transmission map smooth under the contrast enhancement constraint. Last, the experimental results show that the method achieves rather good dehazing results.","Image restoration,
Image segmentation,
Mathematical model,
Computer vision,
Equations,
Meteorology,
Image color analysis"
Cross-Layer Hybrid FEC/ARQ Reliable Multicast With Adaptive Modulation and Coding in Broadband Wireless Networks,"In this paper, we define and address a new problem that arises when a base station in a broadband wireless network wishes to multicast information to a large group of nodes and to guarantee some level of reliability using Application-layer forward error correction (FEC) codes. Every data block to be multicast is translated into a sequence of packets, from which every receiver must receive at least in order to correctly decode the block. The new problem is to determine which PHY-layer modulation and coding scheme (MCS) the base station should use for each packet. We present several variants of this problem, which differ in the number of automatic repeat request (ARQ) rounds during which the delivery of a data block must be completed. Most of these variants are shown to be NP-hard. However, we present optimal solutions for practical instances, where the number of MCSs is small, and efficient approximations and heuristics for the general case of each variant.","Automatic repeat request,
Modulation coding,
Wireless networks,
Forward error correction,
Base stations,
Decoding,
Computer science,
Unicast,
Adaptive systems,
WiMAX"
Broadband Terahertz Pulses Generated by a Compact Femtosecond Photonic Crystal Fiber Amplifier,"We demonstrate a scalable, compact, high-power, and broadband terahertz (THz) source based on a cutting-edge large-mode-area photonic-crystal-fiber amplifier system. A 3-mm (110)-cut bulk GaP crystal was used as the THz emitter based on an optical rectification technique. Systematic optimization of the operation parameters allowed a THz output up to 150 μW to be achieved with an input laser power of 12 W in the GaP crystal.","Pulse amplifiers,
Pulse generation,
Photonic crystal fibers,
Broadband amplifiers,
Optical pulse generation,
Ultrafast optics,
Photonic crystals,
Optical fiber amplifiers,
Optical amplifiers,
High power amplifiers"
Parallel frequent patterns mining algorithm on GPU,"Extraction of frequent patterns from a transactional database is a fundamental task in data mining. Its applications include association rules, time series, etc. The Apriori approach is a commonly used generate-and-test approach to obtain frequent patterns from a database with a given threshold. Many parallel and distributed methods have been proposed for frequent pattern mining (FPM) to reduce computation time. However, most of them require a Cluster system or Grid system. In this study, a graphic processing unit (GPU) was used to perform FPM with a GPU-FPM to speed-up the process. Because of GPU hardware delimitations, a compact data structure was designed to store an entire database on GPU. In addition, MemPack and CLProgram template classes were also designed. Two datasets with different conditions were used to verify the performance of GPU-FPM. The experimental results showed that the speed-up ratio of GPU-FPM can achieve 14.857 with 16 times of threads.",
Cloud Computing: Applying Issues in Small Business,"Cloud computing has developed from being a gifted commerce idea to one of the top geared sector of the Information Technology. Now, declined organizations are progressively introducing themselves in this technology in order to achieve reliable services at minimal cost. But as small and medium size business are looking forward to adopt least economical computing resources for their business applications, there is a need to identify all the issues while deploying it. The paper highlights some of most critical issues along with some mitigating steps in order to achieve rewarding deployment. This also describes some future development work of under laying concept.","Cloud computing,
Grid computing,
Business,
Web and internet services,
Pervasive computing,
Application software,
Computer applications,
Signal processing,
Computer science,
Information technology"
Mitigation of Black-Hole Nodes in Mobile Ad Hoc Networks,"In this paper, IDS (Intrusion Detection System) nodes are deployed in MANETs in order to mitigate black hole attacks. The IDS nodes must be set in sniff mode in order to perform the so-called ABM (Anti-Blackhole Mechanism) function, which is mainly used to estimate a suspicious value of a node according to the abnormal difference between the routing messages transmitted from the node. When a suspicious value exceeds a threshold, an IDS nearby will broadcast a block message, informing all nodes on the network, asking them to cooperatively isolate the malicious node.",
A Two Terminal Network-Based Method for Discrimination Between Internal Faults and Inrush Currents,"A novel scheme based on two-terminal network to distinguish the inrush current from the internal fault current in the power transformer is proposed. By eliminating the mutual flux linkage in the transformer loop equation, a two-terminal network containing only the winding resistance and the leakage inductance is generated. According to the absolute difference of active power (ADOAP) flowing into and consumed by the two-terminal network, the criterion to identify the internal fault is developed. A total of 162 experimental cases have been tested and the proposed method is able to reliably and accurately discriminate internal faults from inrush currents with easy implementation.",
A Joint PHY-MAC Spectrum Sensing Algorithm Exploiting Sequential Detection,"Spectrum sensing is one of the key functionalities in cognitive radios which enables opportunistic spectrum access. In a cognitive radio system, secondary users need to detect the emergence of primary users as soon as possible to avoid harmful interference. In particular, sensing performance can be evaluated by detection delay and sensing overhead. Sequential detection techniques such as quickest detection can achieve minimum detection delay, while MAC layer sensing scheduling of periodic energy detection has demonstrated its high sensing efficiency. These motivate us to propose a joint PHY-MAC spectrum sensing algorithm in this letter, which employs sequential probability ratio test in the PHY layer and a probability-based sensing scheduling mechanism in the MAC layer. This algorithm can minimize detection delay with limited sensing overhead. Simulation results reveal that it has remarkable performance improvement compared with periodic energy detection.","Cognitive radio,
Interference,
Delay,
Sequential analysis,
Physical layer,
Scheduling algorithm,
Cross layer design,
Matched filters,
Computer vision"
Nonbinary sequences with perfect and nearly perfect autocorrelations,"The design of pseudorandom sequences with optimal correlation properties forms a crucial part of communications and radar engineering. Perfect autocorrelation sequences are however exceedingly rare. We discuss a technique that yields examples of such designs over enlarged PSK (PSK+) alphabets. We also design nearly perfect autocorrelation sequences over enlarged QAM (QAM+) alphabets, compatible with contemporary wireless transmission standards.","Autocorrelation,
Multiaccess communication,
Quadrature amplitude modulation,
Phase shift keying,
Galois fields,
Computer science,
Software engineering,
Random sequences,
Radar,
Design engineering"
Quality-aware bandwidth allocation for scalable on-demand streaming in wireless networks,"In this paper, we propose a scalable transport scheme for delivering on-demand video streams over broadband wireless networks in next-generation network/IP multimedia subsystem (NGN/IMS) architecture. The proposed transport scheme makes use of fine-granular-scalability (FGS) encoded videos to accommodate high bandwidth variation of wireless networks. We formulate the bandwidth allocation to FGS-encoded streams as a resource allocation problem and develop a quality-aware bandwidth allocation scheme, called QABA. With QABA, the proposed transport scheme can dynamically adjust the bit rate allocated to different streams to maximize the overall perceptual quality when available network bandwidth varies with time. QABA is theoretically proven to be able to find the optimal bandwidth allocation for all on-demand streams. To validate the effectiveness of QABA, extensive trace-based simulations are performed.","Channel allocation,
Wireless networks,
Streaming media,
Broadcasting,
Bandwidth,
Video on demand,
Next generation networking,
Multimedia communication,
Video sharing,
Protocols"
"Dual-Wavelength
Cr
3+
:
LiCaAlF
6
Solid-State Laser With Tunable THz Frequency Difference",We present a scheme for dual-wavelength operation of a diode-pumped Cr3+:LiCaAlF6 (Cr:LiCAF) laser with tunable frequency difference suitable for terahertz continuous-wave generation by heterodyne mixing in low-temperature-grown GaAs photomixers or intracavity nonlinear difference-frequency mixing. The laser is based on a double external optical feedback configuration to achieve spectral purity of the laser light through self-injection locking. The wavelength separation reported allows for a fully equalized dual-wavelength source between 0 and 9 THz in the 785-nm region.,
A tutorial on stochastic approximation algorithms for training Restricted Boltzmann Machines and Deep Belief Nets,"In this study, we provide a direct comparison of the Stochastic Maximum Likelihood algorithm and Contrastive Divergence for training Restricted Boltzmann Machines using the MNIST data set. We demonstrate that Stochastic Maximum Likelihood is superior when using the Restricted Boltzmann Machine as a classifier, and that the algorithm can be greatly improved using the technique of iterate averaging from the field of stochastic approximation. We further show that training with optimal parameters for classification does not necessarily lead to optimal results when Restricted Boltzmann Machines are stacked to form a Deep Belief Network. In our experiments we observe that fine tuning a Deep Belief Network significantly changes the distribution of the latent data, even though the parameter changes are negligible.","Tutorial,
Stochastic processes,
Approximation algorithms,
Backpropagation,
Guidelines,
Computer science,
Sampling methods,
Collaborative work,
Filtering,
Logic circuits"
Sancta simplicitas - on the efficiency and achievable results of SLAM using ICP-based incremental registration,"This paper presents an efficient combination of algorithms for SLAM in dynamic environments. The overall approach is based on range image registration using the ICP algorithm. Different extensions to this algorithm are used to incrementally construct point models of the robot's workspace. A simple heuristic allows for determining which points in a newly acquired range image are already contained in the point model and for adding only those points that provide new information. Furthermore, the means for dealing with environment dynamics are presented which allow for continuously conducting SLAM and updating the point model according to changes in a dynamic environment. The achievable results of the overall approach are compared to Rao-Blackwellized Particle Filters as a state-of-the-art solution to the SLAM problem and evaluated using a recently published benchmark by Burgard et al. (2009).","Simultaneous localization and mapping,
Robot sensing systems,
Iterative algorithms,
Image registration,
Iterative closest point algorithm,
Particle filters,
Service robots,
Navigation,
Robotics and automation,
USA Councils"
Quaternion Multiplier Inspired by the Lifting Implementation of Plane Rotations,"A lifting-based structure for quaternion multipliers with unit-magnitude constant coefficients is proposed, whose development was inspired by the well-known implementation of a plane rotation (complex multiplication with a unit-magnitude coefficient) using three shears each of which corresponds to one real multiplication and addition. Our solution is mainly aimed at implementing quaternion transforms as dedicated multiplierless digital circuits. Compared to alternative schemes obtained using the most known general-purpose lifting factorizations, it needs 1/3-1/5 less lifting steps. On general-purpose hardware, it allows for saving 14% operations at the price of representing the hypercomplex coefficient indirectly using six, instead of four, real numbers.","Quaternions,
Hardware,
Filter bank,
Signal processing algorithms,
Real time systems,
Computer science,
Digital circuits,
Algebra,
Digital signal processing,
Multidimensional signal processing"
k-Anonymity in the Presence of External Databases,"The concept of k-anonymity has received considerable attention due to the need of several organizations to release microdata without revealing the identity of individuals. Although all previous k-anonymity techniques assume the existence of a public database (PD) that can be used to breach privacy, none utilizes PD during the anonymization process. Specifically, existing generalization algorithms create anonymous tables using only the microdata table (MT) to be published, independently of the external knowledge available. This omission leads to high information loss. Motivated by this observation, we first introduce the concept of k-join-anonymity (KJA), which permits more effective generalization to reduce the information loss. Briefly, KJA anonymizes a superset of MT, which includes selected records from PD. We propose two methodologies for adapting k-anonymity algorithms to their KJA counterparts. The first generalizes the combination of MT and PD, under the constraint that each group should contain at least 1 tuple of MT (otherwise, the group is useless and discarded). The second anonymizes MT, and then, refines the resulting groups using PD. Finally, we evaluate the effectiveness of our contributions with an extensive experimental evaluation using real and synthetic data sets.",
English digits speech recognition system based on Hidden Markov Models,"This paper aims to design and implement English digits speech recognition system using Matlab (GUI). This work was based on the Hidden Markov Model (HMM), which provides a highly reliable way for recognizing speech. The system is able to recognize the speech waveform by translating the speech waveform into a set of feature vectors using Mel Frequency Cepstral Coefficients (MFCC) technique This paper focuses on all English digits from (Zero through Nine), which is based on isolated words structure. Two modules were developed, namely the isolated words speech recognition and the continuous speech recognition. Both modules were tested in both clean and noisy environments and showed a successful recognition rates. In clean environment and isolated words speech recognition module, the multi-speaker mode achieved 99.5% whereas the speaker-independent mode achieved 79.5%. In clean environment and continuous speech recognition module, the multi-speaker mode achieved 72.5% whereas the speaker-independent mode achieved 56.25%. However in noisy environment and isolated words speech recognition module, the multi-speaker mode achieved 88% whereas the speaker-independent mode achieved 67%. In noisy environment and continuous speech recognition module, the multi-speaker mode achieved 82.5% whereas the speaker-independent mode achieved 76.67%. These recognition rates are relatively successful if compared to similar systems.",
From Theory to Practice: Evaluating Static Channel Assignments on a Wireless Mesh Network,"Multi-radio nodes in wireless mesh networks introduce extra complexity in utilizing channel resources. Depending on the configuration of the radios, bad mappings between radio to wireless frequencies may result in sub-optimal network topologies. Static channel assignments in wireless mesh networks have been studied in theory and through simulation but very little work has been done through experiments. This paper focuses on evaluating static channel assignments on a live wireless mesh network. We chose three popular types of static channel assignment algorithms for implementation and comparison purposes. The three types are breadth-first search, priority-based selection and integer linear programming. We find that there is no single channel assignment algorithm that does well overall. BFS algorithm can create the shortest paths to the gateway and also generate balanced channel usage topologies. The PBS algorithm can use all the best links in the network but have poor performance from each radio to the gateway. Overall, we find the channel assignments given by the algorithms to be suboptimal when applied to a live mesh network because temporal variations in the link quality metrics are not taken into account. Looking at the interflow and intraflow performance of these channel assignment algorithms in a live mesh network, we can conclude that routing protocols must be modified to take advantage of the underlying channel assignment algorithms.","Wireless mesh networks,
Mesh networks,
Network topology,
Integer linear programming,
Routing protocols,
Communications Society,
Computer science,
Peer to peer computing,
Frequency,
Wires"
Statistical channel modeling of wireless shallow water acoustic communications from experiment data,"This paper analyzes statistical characteristics of underwater acoustic channels estimated by ocean experimental data. The baseband complex channel impulse responses (CIRs) are estimated by a time-domain least square method with sliding windows applied to long probing sequences. The probability density functions (PDF) of the real part, imaginary part, magnitude, and phase of the CIR are evaluated, and the two-sample Kolmogorov-Smirnov test is used to measure fitness of the magnitude PDF to the Gamma, Rayleigh, and compound-K distributions. The second-order statistics of the channel are also investigated in terms of autocorrelation function, channel coherence time, and scattering function. The experimental results demonstrate that underwater channels are often worse than Rayleigh fading channels.",
DAWN: Energy efficient data aggregation in WSN with mobile sinks,"The benefits of using mobile sink to prolong sensor network lifetime have been well recognized. However, few provably theoretical results remain are developed due to the complexity caused by time-dependent network topology. In this work, we investigate the optimum routing strategy for the static sensor network. We further propose a number of motion stratifies for the mobile sink(s) to gather real time data from static sensor network, with the objective to maximize the network lifetime. Specially, we consider a more realistic model where the moving speed and path for mobile sinks are constrained. Our extensive experiments show that our scheme can significantly prolong entire network lifetime and reduce delivery delay.",
Estimation of Inferential Uncertainty in Assessing Expert Segmentation Performance From STAPLE,"The evaluation of the quality of segmentations of an image, and the assessment of intra- and inter-expert variability in segmentation performance, has long been recognized as a difficult task. For a segmentation validation task, it may be effective to compare the results of an automatic segmentation algorithm to multiple expert segmentations. Recently an expectation-maximization (EM) algorithm for simultaneous truth and performance level estimation (STAPLE) was developed to this end to compute both an estimate of the reference standard segmentation and performance parameters from a set of segmentations of an image. The performance is characterized by the rate of detection of each segmentation label by each expert in comparison to the estimated reference standard. This previous work provides estimates of performance parameters, but does not provide any information regarding the uncertainty of the estimated values. An estimate of this inferential uncertainty, if available, would allow the estimation of confidence intervals for the values of the parameters. This would facilitate the interpretation of the performance of segmentation generators and help determine if sufficient data size and number of segmentations have been obtained to precisely characterize the performance parameters. We present a new algorithm to estimate the inferential uncertainty of the performance parameters for binary and multicategory segmentations. It is derived for the special case of the STAPLE algorithm based on established theory for general purpose covariance matrix estimation for EM algorithms. The bounds on the performance parameters are estimated by the computation of the observed information matrix. We use this algorithm to study the bounds on performance parameters estimates from simulated images with specified performance parameters, and from interactive segmentations of neonatal brain MRIs. We demonstrate that confidence intervals for expert segmentation performance parameters can be estimated with our algorithm. We investigate the influence of the number of experts and of the segmented data size on these bounds, showing that it is possible to determine the number of image segmentations and the size of images necessary to achieve a chosen level of accuracy in segmentation performance assessment.",
P2P Content Distribution to Mobile Bluetooth Users,"The use of handheld devices, such as smart phones for personal entertainment, has become commonplace in today's lifestyle. Virtually all of these devices are equipped with Bluetooth technology, which can be used to distribute entertainment content, such as music and movie clips. Mobile users can download content from opportunistically available infrastructure (e.g., digital billboards) and direct peer-to-peer (P2P) collaboration, which significantly increases content availability/coverage. P2P content distribution protocol design is heavily influenced by the characteristics of Bluetooth, which is a main departure from Internet-based content distribution. However, little has been done to understand the performance of overall Bluetooth operations, ranging from peer discovery to data downloading, in dynamic environments with mobility, interference, and different Bluetooth versions/chipsets. In this paper, we perform an extensive measurement study and find that Bluetooth-based content distribution suffers from time/energy-consuming resource discovery and limited bandwidth, even with the enhanced features of the latest Bluetooth version. Given this, we discuss strategies that can effectively improve the performance of the resource-discovery and downloading phases.","Bluetooth,
Handheld computers,
Smart phones,
Motion pictures,
Peer to peer computing,
Collaboration,
Availability,
Protocols,
Internet,
Interference"
Probabilistic Track Coverage in Cooperative Sensor Networks,"The quality of service of a network performing cooperative track detection is represented by the probability of obtaining multiple elementary detections over time along a target track. Recently, two different lines of research, namely, distributed-search theory and geometric transversals, have been used in the literature for deriving the probability of track detection as a function of random and deterministic sensors' positions, respectively. In this paper, we prove that these two approaches are equivalent under the same problem formulation. Also, we present a new performance function that is derived by extending the geometric-transversal approach to the case of random sensors' positions using Poisson flats. As a result, a unified approach for addressing track detection in both deterministic and probabilistic sensor networks is obtained. The new performance function is validated through numerical simulations and is shown to bring about considerable computational savings for both deterministic and probabilistic sensor networks.","Target tracking,
Object detection,
Wireless sensor networks,
Quality of service,
Numerical simulation,
Computer networks,
Sensor phenomena and characterization,
Surveillance,
Monitoring"
Bringing simulation to life: A mixed reality autonomous intersection,"Fully autonomous vehicles are technologically feasible with the current generation of hardware, as demonstrated by recent robot car competitions. Dresner and Stone proposed a new intersection control protocol called Autonomous Intersection Management (AIM) and showed that with autonomous vehicles it is possible to make intersection control much more efficient than the traditional control mechanisms such as traffic signals and stop signs. The protocol, however, has only been tested in simulation and has not been evaluated with real autonomous vehicles. To realistically test the protocol, we implemented a mixed reality platform on which an autonomous vehicle can interact with multiple virtual vehicles in a simulation at a real intersection in real time. From this platform we validated realistic parameters for our autonomous vehicle to safely traverse an intersection in AIM. We present several techniques to improve efficiency and show that the AIM protocol can still outperform traffic signals and stop signs even if the cars are not as precisely controllable as has been assumed in previous studies.","Vehicles,
Acceleration,
Mobile robots,
Throughput,
Delay,
Driver circuits,
Trajectory"
Window optimization of reversible and quantum circuits,"This paper considers the optimization of reversible and quantum circuits. Both represent the basis for emerging technologies e.g. in the area of quantum computation and low power design. An approach called window optimization is described that does not consider the circuit as a whole, but smaller sub-circuits of it (so called windows). Two schemes for extracting the windows and three approaches for their optimization are considered. Application scenarios show that applying the proposed optimizations leads to significant reductions of the circuit cost.",
Silver Microstructure Control for Fluxless Bonding Success Using Ag-In System,"A fluxless bonding process is successfully developed between silicon (Si) chips and copper (Cu) substrates using the silver-indium (Ag-In) binary system. This is a new design concept that utilizes thick Ag plated over the Cu substrate to deal with the large mismatch in coefficient of thermal expansion between semiconductors, such as Si (3 ppm/°C) and Cu (17 ppm/°C). The Ag layer actually becomes a part of the Ag-Cu substrate. Ag is chosen for the cladding because of its superior physical properties of ductility, high electrical conductivity, and high thermal conductivity. Following the thick Ag layer, 5 μm In and 0.1 μm Ag layers are plated. The thin outer Ag layer inhibits oxidation of inner In. After many bonding experiments, we realize that the success of producing a joint relates to the microstructure of the Ag layer. Ag with small grains results in rapid growth of solid Ag2In intermetallic compounds through grain boundary diffusion. Thus, a joint is not obtained because of lack of molten phase (L). To coarsen Ag grains, an annealing step is added to the Ag-plated Cu substrate. This step makes Ag grains 200 times coarser compared to the as-plated Ag. The coarsened microstructure slows down the Ag2In growth. Consequently, the (L) phase stays at the molten state with sufficient time to react with the Ag layer on the Si chip to produce a joint. Nearly perfect joints are produced on Ag-plated Cu substrates. The resulting joints consist of pure Ag, Ag-rich solid solution, Ag2In, and Ag3In. The melting temperature exceeds 650 °C. Using the present process, high temperature joints of high thermal conductivity are made between Si chips and Cu substrates at low bonding temperature (200°C). We foresee the Ag-In system as an important system to explore for various fluxless bonding applications in electronic packaging. This system provides the possibilities of producing joints of wide composition choices and wide melting temperature range. This paper provides preliminary but useful information on how the microstructure of Ag affects the bonding results.","Silver,
Microstructure,
Control systems,
Copper,
Substrates,
Thermal conductivity,
Temperature,
Solids,
Bonding processes,
Silicon"
Assessment of waist-worn tri-axial accelerometer based fall-detection algorithms using continuous unsupervised activities,"This study aims to evaluate a variety of existing and novel fall detection algorithms, for a waist mounted accelerometer based system. Algorithms were tested against a comprehensive data-set recorded from 10 young healthy subjects performing 240 falls and 120 activities of daily living and 10 elderly healthy subjects performing 240 scripted and 52.4 hours of continuous unscripted normal activities.","Accelerometers,
Senior citizens,
Detection algorithms,
Sensitivity,
Sensors,
Algorithm design and analysis,
Aging"
Vision-based pose estimation for autonomous indoor navigation of micro-scale Unmanned Aircraft Systems,"We present a navigation system for autonomous indoor flight of micro-scale Unmanned Aircraft Systems (UAS) which is based on a method for accurate monocular vision pose estimation. The method makes use of low cost artificial landmarks placed in the environment and allows for fully autonomous flight with all computation done on-board a UAS on COTS hardware. We provide a detailed description of all system components along with an accuracy evaluation and a time profiling result for the pose estimation method. Additionally, we show how the system is integrated with an existing micro-scale UAS and provide results of experimental autonomous flight tests. To our knowledge, this system is one of the first to allow for complete closed-loop control and goal-driven navigation of a micro-scale UAS in an indoor setting without requiring connection to any external entities.","Aircraft navigation,
Unmanned aerial vehicles,
Sensor fusion,
Costs,
System testing,
Wireless communication,
Aerospace control,
Robotics and automation,
USA Councils,
Hardware"
Hot spots and core-to-core thermal coupling in future multi-core architectures,"This paper studies hot spot and thermal coupling problems in future multicore architectures as CMOS technology scales from 65 nm feature size to 15 nm. We demonstrate that the thermal coupling between neighboring cores will dramatically increase as the technology scales to smaller feature sizes. The simulation studies were based on solving the heat equation using the analytical Green's function method. Our simulations indicate that the thermal coupling in the 15 nm feature size just after 100 ms of operation will increase from 20% to 42% and in the steady state might reach even 65%. This finding uncovers a major challenge for the design of future multi-core architectures as the technology keeps scaling down. This will require a holistic approach to the design of future multi-core architectures encompassing low power computing, thermal management technologies and workload distribution.",
Fast Source Reconstruction for Bioluminescence Tomography Based on Sparse Regularization,"Bioluminescence tomography (BLT) is an inherent ill-posed inverse problem to reconstruct the internal source in 3-D with limited measurements on the external surface. In most BLT studies so far, a relatively small permissible source region or multispectral approach is typically used to enhance the stability or quality of the solution. In this letter, considering the sparsity characteristic of the light source, BLT is reformulated as a least absolute shrinkage and selection operator (LASSO) problem with l1 regularization, and then, a fast reconstruction algorithm named as stagewise fast LASSO is proposed for solving this problem. Numerical simulations of a 3-D mouse atlas under different noise levels demonstrate that the proposed algorithm is robust against measurement noise, and it can achieve high computational efficiency and accurate localization of source even without any permissible region constraint.","Bioluminescence,
Tomography,
Noise level,
Inverse problems,
Surface reconstruction,
Stability,
Light sources,
Reconstruction algorithms,
Numerical simulation,
Mice"
Partial Least Squares: A Method to Estimate Efficient Channels for the Ideal Observers,"We advocate a task-based approach to the assessment of image quality using the Bayesian ideal observer. The Bayesian ideal observer provides an absolute upper bound for performance estimates. However, using the full images as inputs to the observer is often infeasible due to their high dimensionality. A practical alternative is to reduce the dimensionality of the images by applying channels, while approximating the ideal observer by an observer constrained to the channels. Laguerre-Gauss (LG) channels and those derived from the singular value decomposition (SVD) of the system operator have previously been used with the Bayesian ideal observer. However, the channelized observer with LG and SVD channels was only applicable in situations with a rotationally symmetric signal or known system operator, respectively. We investigate a method using partial least squares (PLS) to compute efficient channels directly from the images, without prior knowledge of the background, signal, or system operator. Results show that the channelized ideal observer with PLS channels approximates the nonchannelized observer, and does so with fewer channels than the observer with either LG or SVD channels. The images are reduced from 4096 pixel values to 20 channel outputs, yet preserve the salient information. Furthermore, PLS reveals that the background image statistics provide important information necessary in signal-detection tasks. Overall, PLS is shown to be a viable channel generation method and may be applicable to real-life situations.","Least squares approximation,
Image quality,
Bayesian methods,
Neoplasms,
Drugs,
Humans,
Upper bound,
Least squares methods,
Statistics,
Mathematics"
On the optimal solutions of the infinite-horizon linear sensor scheduling problem,"This paper studies the infinite-horizon sensor scheduling problem for linear Gaussian processes with linear measurement functions. Several important properties of the optimal infinite-horizon schedules are derived. In particular, it is proved that under some mild conditions, both the optimal infinite-horizon average-per-stage cost and the corresponding optimal sensor schedules are independent of the covariance matrix of the initial state. It is also proved that the optimal estimation cost can be approximated arbitrarily closely by a periodic schedule with a finite period, and moreover, the trajectory of the error covariance matrix under this periodic schedule converges exponentially to a unique limit cycle. These theoretical results provide valuable insights about the problem and can be used as general guidelines in the design and analysis of various infinite-horizon sensor scheduling algorithms.","Schedules,
Covariance matrix,
Trajectory,
Optimal scheduling,
Estimation,
Scheduling,
Processor scheduling"
Homogenized Green's Functions for an Aperiodic Line Source Over Planar Densely Periodic Artificial Impedance Surfaces,"The accurate electromagnetic analysis of artificial periodic surfaces formed as planar layers with complicated periodic metallization patterns, having a grid period much smaller than the effective wavelength (densely periodic), is important for the design and analysis of a variety of electromagnetic structures. However, full-wave modeling can be extremely time-consuming and computationally expensive, especially for aperiodic sources in close proximity to periodic surfaces. In this paper, we describe approximate homogenized models for a Green's function that treats planar patterned screens (grids) as quasi-dynamic homogenized impedance surfaces and dielectric layers in a fully dynamic manner. The resulting Green's functions are only slightly more complicated than those for dielectric layers without metallization and can be numerically computed using standard methods for layered media. We restrict attention to line sources and compare numerical results from this method with those from a full-wave array scanning method, which is more complex analytically and much more demanding to evaluate numerically. Very good agreement is found between the two methods except for source and/or field points extremely close to the metallization layer, confirming the accuracy of the homogenized representations of periodic surfaces for near-field sources.",
Dynamic Vehicle Routing for Translating Demands: Stability Analysis and Receding-Horizon Policies,"We introduce a problem in which demands arrive stochastically on a line segment, and upon arrival, move with a fixed velocity perpendicular to the segment. We design a receding horizon service policy for a vehicle with speed greater than that of the demands, based on the translational minimum Hamiltonian path (TMHP). We consider Poisson demand arrivals, uniformly distributed along the segment. For a fixed segment width and fixed vehicle speed, the problem is governed by two parameters; the demand speed and the arrival rate. We establish a necessary condition on the arrival rate in terms of the demand speed for the existence of any stabilizing policy. We derive a sufficient condition on the arrival rate in terms of the demand speed that ensures stability of the TMHP-based policy. When the demand speed tends to the vehicle speed, every stabilizing policy must service the demands in the first-come-first-served (FCFS) order; and the TMHP-based policy becomes equivalent to the FCFS policy which minimizes the expected time before a demand is serviced. When the demand speed tends to zero, the sufficient condition on the arrival rate for stability of the TMHP-based policy is within a constant factor of the necessary condition for stability of any policy. Finally, when the arrival rate tends to zero for a fixed demand speed, the TMHP-based policy becomes equivalent to the FCFS policy which minimizes the expected time before a demand is serviced. We numerically validate our analysis and empirically characterize the region in the parameter space for which the TMHP-based policy is stable.",
Cover song detection: From high scores to general classification,"Existing cover song detection systems require prior knowledge of the number of cover songs in a test set in order to identify cover(s) to a reference song. We describe a system that does not require such prior knowledge. The input to the system is a reference track and test track, and the output is a binary classification of whether the inputs are either a reference and a cover or a reference and a non-cover. The system differs from state-of-the-art detectors by calculating multiple input features, performing a novel type of test song normalization in order to combat against “impostor” tracks, and performing classification using either a support vector machine (SVM) or multi-layer perceptron (MLP). On the covers80 test set, the system achieves an equal error rate of 10%, compared to 21.3% achieved by the 2007 LabROSA cover song detection system.",
Enabling technologies for self-aware adaptive systems,"Self-aware computer systems will be capable of adapting their behavior and resources thousands of times a second to automatically find the best way to accomplish a given goal despite changing environmental conditions and demands. Such a capability benefits a broad spectrum of computer systems from embedded systems to supercomputers and is particularly useful for meeting power, performance, and resource-metering challenges in mobile computing, cloud computing, multicore computing, adaptive and dynamic compilation environments, and parallel operating systems. Some of the challenges in implementing self-aware systems are a) knowing within the system what the goals of applications are and if they are meeting them, b) deciding what actions to take to help applications meet their goals, and c) developing standard techniques that generalize and can be applied to a broad range of self-aware systems. This work presents our vision for self-aware adaptive systems and proposes enabling technologies to address these three challenges. We describe a framework called Application Heartbeats that provides a general, standardized way for applications to monitor their performance and make that information available to external observers. Then, through a study of a self-optimizing synchronization library called Smartlocks, we demonstrate a powerful technique that systems can use to determine which optimization actions to take. We show that Heartbeats can be applied naturally in the context of reinforcement learning optimization strategies as a reward signal and that, using such a strategy, Smartlocks are able to significantly improve performance of applications on an important emerging class of multicore systems called asymmetric multicores.","Adaptive systems,
Monitoring,
Multicore processing,
Benchmark testing,
Biomedical monitoring,
Computers"
Robust codebook-based video background subtraction,"Dynamic backgrounds and sudden illumination changes are two of the major problems associated with background subtraction techniques. In this paper, we present a novel approach to background subtraction that addresses both of these challenges. In particular, we present an improved codebook background modelling and subtraction technique. We utilise image segmentation on the background image and model the background with a codebook for each pixel along with a pseudo background layer. We perceive background motion as an occlusion of one background layer by a nearby background layer. In other words, sliding of one background layer over a neighbouring layer causes background motion and will hence result in false segmentation. We present our approach of codeword spreading across layer boundaries to handle background motion. Furthermore, we present a two-step update of the background codebook to handle both sudden and gradual illumination changes.","Robustness,
Lighting,
Hidden Markov models,
Image segmentation,
Computer science,
Subtraction techniques,
Pixel,
Computer vision,
Application software,
Gaussian distribution"
A new approach for defining a fuzzy color space,"In this paper we introduce formal definitions of the concepts of fuzzy color and fuzzy color space. We present an approach to the automatic design of customized fuzzy color spaces on the basis of a collection of crisp colors, each crisp color being fully representative of a certain color term. The approach works on any euclidean crisp space and is based on obtaining a Voronoi diagram having the aforementioned representative crisp colors as centroids. The proposal will be illustrated building fuzzy color spaces on RGB colors on the basis of the ISCC-NBS color naming system.","Image color analysis,
Color,
Silicon,
Pragmatics,
Humans,
Kernel,
Semantics"
Electrical characterization of RF TSV for 3D multi-core and heterogeneous ICs,"In this paper, radio frequency (RF) through-silicon via (TSV) designs and models are proposed to achieve high-frequency vertical connectivity for three dimensional (3D) multi-core and heterogeneous ICs. Specifically, coaxial dielectric and novel air-gap-based TSVs are designed and simulated to reduce signal degradation during RF operations. The simulation results demonstrate that these RF TSVs can provide decay-tolerance frequencies two orders of magnitude higher than simple Cu-plug TSVs. The data rate and energy per bit of the RF TSVs are summarized, providing an important guideline for future 3D high-frequency TSV designs.","Through-silicon vias,
Radio frequency,
Three dimensional displays,
Air gaps,
Integrated circuit modeling,
Atmospheric modeling,
Mathematical model"
Volunteer-instigated connectivity restoration algorithm for Wireless Sensor and Actor Networks,"Due to their applications, Wireless Sensor and Actor Networks (WSANs) have recently been getting significant attention from the research community. In these networks, maintaining inter-actor connectivity is of a paramount concern in order to plan an optimal coordinated response to a detected event. Failure of an actor may partition the inter-actor network into disjoint segments, and may thus hinder inter-actor coordination. This paper presents VCR, a novel distributed algorithm that opts to repair severed connectivity while imposing minimal overhead on the nodes. In VCR the neighbors of the failed actor volunteer to restore connectivity by exploiting their partially utilized transmission range and by repositioning closer to the failed actor. Furthermore, a diffusion force is applied among the relocating actors based on transmission range in order to reduce potential of interference, and improve connectivity. VCR is validated through simulation and is shown to outperform contemporary schemes found in the literature.",
Towards the Personal Equation of Interaction: The impact of personality factors on visual analytics interface interaction,"These current studies explored the impact of individual differences in personality factors on interface interaction and learning performance behaviors in both an interactive visualization and a menu-driven web table in two studies. Participants were administered 3 psychometric measures designed to assess Locus of Control, Extraversion, and Neuroticism. Participants were then asked to complete multiple procedural learning tasks in each interface. Results demonstrated that all three measures predicted completion times. Additionally, results analyses demonstrated personality factors also predicted the number of insights participants reported while completing the tasks in each interface. We discuss how these findings advance our ongoing research in the Personal Equation of Interaction.",
E-DEEC- Enhanced Distributed Energy Efficient Clustering scheme for heterogeneous WSN,"Many routing protocols on clustering structure have been proposed in recent years. In recent advances, achieving the energy efficiency, lifetime, deployment of nodes, fault tolerance, latency, in short high reliability and robustness have become the main research goals of wireless sensor network. Many routing protocols on clustering structure have been proposed in recent years based on heterogeneity. We propose EDEEC for three types of nodes in prolonging the lifetime and stability of the network. Hence, it increases the heterogeneity and energy level of the network. Simulation results show that EDEEC performs better than SEP with more stability and effective messages.",
Accurate time synchronization in PTP-based industrial networks with long linear paths,"Assuring very accurate time synchronization across wide area industrial networks is still an open issue, which even the second version of the Precision Time Protocol (PTPv2) has not been able to solve completely. This is due to the accumulation of many uncertainty contributions when PTP event messages are routed from the master clock to the slave one through multiple network nodes. Peer-to-peer transparent clocks may mitigate this problem. Nonetheless, poor or noisy relative clock rate estimates may drastically reduce the synchronization accuracy on the farthest nodes. In this paper Kalman filters are used to estimate and to compensate, drift rate differences, frequency skews and time offsets between pairs of adjacent transparent clocks. Although the idea of using a Kalman filter for synchronization purposes is not new per se, the proposed solution is specifically tailored to optimize the performance of networks with a long linear topology. Several simulation results confirm the validity of this approach.",
Defining Minimum Requirements of Inter-collaborated Nodes by Measuring the Weight of Node Interactions,"In this paper we are focusing on the minimum requirements to be addressed in order to demonstrate a inter-node communication within a Virtual Organisation (VO) using the method of Self-led Critical Friends (SCF). The method is able to decide paths that a node can choose in order to locate neighbouring nodes by aiming at realizing the overhead of each communication. The weight of each path will be measured by the analysis of prerequisites in order to achieve the interaction between nodes. We define requirements as the least fundamentals that a node needs to achieve in order to determine its accessibility factor. The information gathered from an interaction is then stored in a snapshot, a profile that is made available during the discovery stage.","Weight measurement,
Graph theory,
Computer science,
Resource management,
Complex networks,
Competitive intelligence,
Communication system software,
Software systems,
Software measurement,
Informatics"
Distributed Fair Scheduling for Wireless Mesh Networks Using IEEE 802.11,"In IEEE-802.11-based wireless mesh networks (WMNs), unfair bandwidth sharing may arise, because the carrier sense multiple access with collision avoidance protocol is designed to provide per-station fairness only in one hop. As the hop count from a mobile client to the gateway node increases, the throughput of the node drastically decreases. In this paper, we propose a fair bandwidth allocation scheme for multiradio multichannel WMNs. This scheme provides fair bandwidth sharing among the nodes in a WMN, regardless of their hop distance from the gateway node. To achieve fairness, we first estimate the number of active nodes attached to each router and calculate the effective weights of routers based on the estimation. Then, we differentiate their contention window using their weights. For this method, we derive a multihop packet collision model. The proposed scheme is fully distributed and does not require any global information. Through an extensive simulation study, we show that our scheme ensures per-node fairness without loss of the total aggregate throughput.","Bandwidth,
IEEE 802.11 Standards,
Estimation,
Spread spectrum communication,
Wireless mesh networks"
Controlling software applications via resource allocation within the heartbeats framework,"A formalism was recently introduced to instrument, monitor and control computer applications based on the rate of heartbeats they emit, thereby quantitatively signaling their progress toward goals. To date, the idea was however used essentially in an heuristic manner. This work first shows that a very simple dynamic heartbeat rate model can be devised, an that said model allows to address the corresponding control problems in a methodologically grounded way. A general solution is then devised, that can be realized through different actuation mechanisms, depending on which type of resource—CPU, memory, bandwidth, etc.—is constraining the application performance in the particular situation at hand. Experiments prove the efficacy of the proposed extension to the heartbeats framework, both with applications that fit the proposed model and with more complex test cases, for which said model is just a coarse approximation.","Computational modeling,
Heart rate,
Software,
Actuators,
Encoding,
Instruments"
Optimal Sensing Disruption for a Cognitive Radio Adversary,"Spectrum sensing vulnerabilities in cognitive radio (CR) networks are being actively investigated, where most research focuses on mechanisms that deal with possible attacks without examining optimal sensing disruption strategies. This paper addresses the optimal design and analysis of a power-limited intelligent adversary to a CR network. The adversary targets unused bands and puts energy into them so that the number of unused bands appears reduced to secondary users. This is called sensing disruption. The optimal disruption strategy is obtained by maximizing the average number of false detections under the adversary's power constraint. It is shown that, for a CR network where energy detection is utilized by secondary users, the optimal sensing disruption strategy for noise spoofing for a CR adversary is equal-power partial-band spoofing. Numerical results and analyses of the optimal sensing disruption are provided.",
Low-SNR Capacity of Multiple-Antenna Systems With Statistical Channel-State Information,"This paper investigates the capacity of double-scattering and Rician fading multiple-input-multiple-output (MIMO) channels in the low signal-to-noise ratio (SNR) regime. We first derive analytical expressions for the two key low-SNR parameters-the minimum required Eb/N0 for reliable communications and the wideband slope-assuming statistical channel state information (CSI) at the transmitter. Based on these results, we study the effects of transmit, scatter, and receive correlation, as well as the Rician K -factor. For double-scattering MIMO channels, we find that the minimum required Eb/N0 improves with increasing transmit-side correlation and is independent of the scatter and receive correlation, whereas the wideband slope degrades with increasing the scatter and receive correlation and is independent of the transmit-side correlation. For Rician MIMO channels, we show that increasing the Rician K-factor leads to an improvement in the minimum required Eb/N0 while degrading the wideband slope. We also analyze the low-SNR capacity for different levels of transmit CSI for special cases of both channels. Our results demonstrate that the additional beamforming gain due to more accurate CSI leads to a reduced minimum required Eb/N0 but does not yield improvements in the wideband slope.","MIMO,
Transmitters,
Rician channels,
Wideband,
Scattering,
Mobile communication,
Covariance matrix,
Degradation,
Receiving antennas,
Laboratories"
Comparing time-triggered Ethernet with FlexRay: An evaluation of competing approaches to real-time for in-vehicle networks,"FlexRay is considered the next generation state-of-the-art technology for in-car networks, while time-triggered Ethernet emerges with the promise to integrate real-time and best-effort traffic into one homogeneous backbone. This paper contributes a competitive analysis of FlexRay and time-triggered Ethernet. By showing that it is possible to transfer a fully utilized FlexRay system to a system based on time-triggered Ethernet, it is demonstrated that time-triggered Ethernet is a suitable replacement of current in-vehicle bus-systems. Further it is shown that a switched system has advantages in bandwidth utilization over a shared bus, when using group communication.","Ethernet networks,
Spine,
Bandwidth,
Automotive engineering,
Delay,
Protocols,
Telecommunication traffic,
Switched systems,
Vehicle safety,
Jitter"
Real-Time Detection of Stealthy DDoS Attacks Using Time-Series Decomposition,"Recently, many new types of distributed denial of service (DDoS) attacks have emerged, posing a great challenge to intrusion detection systems. In this paper, we introduce a new type of DDoS attacks called stealthy DDoS attacks, which can be launched by sophisticated attackers. Such attacks are different from traditional DDoS attacks in that they cannot be detected by previous detection methods effectively. In response to this type of DDoS attacks, we propose a detection approach based on time-series decomposition, which divides the original time series into trend and random components. It then applies a double autocorrelation technique and an improved cumulative sum technique to the trend and random components, respectively, to detect anomalies in both components. By separately examining each component and synthetically evaluating the overall results, the proposed approach can greatly reduce not only false positives and negatives but also detection latency. In addition, to make our method more generally applicable, we apply an adaptive sliding-window to our real-time algorithm. We evaluate the performance of the proposed approach using real Internet traces, demonstrating its effectiveness.",
Cross-Domain Learning from Multiple Sources: A Consensus Regularization Perspective,"Classification across different domains studies how to adapt a learning model from one domain to another domain which shares similar data characteristics. While there are a number of existing works along this line, many of them are only focused on learning from a single source domain to a target domain. In particular, a remaining challenge is how to apply the knowledge learned from multiple source domains to a target domain. Indeed, data from multiple source domains can be semantically related, but have different data distributions. It is not clear how to exploit the distribution differences among multiple source domains to boost the learning performance in a target domain. To that end, in this paper, we propose a consensus regularization framework for learning from multiple source domains to a target domain. In this framework, a local classifier is trained by considering both local data available in one source domain and the prediction consensus with the classifiers learned from other source domains. Moreover, we provide a theoretical analysis as well as an empirical study of the proposed consensus regularization framework. The experimental results on text categorization and image classification problems show the effectiveness of this consensus regularization learning method. Finally, to deal with the situation that the multiple source domains are geographically distributed, we also develop the distributed version of the proposed algorithm, which avoids the need to upload all the data to a centralized location and helps to mitigate privacy concerns.","Training data,
Text categorization,
Image classification,
Learning systems,
Data privacy,
Laboratories,
Information processing,
Computers,
Information management"
Centralized and decentralized cooperative spectrum sensing in cognitive radio networks: A novel approach,"In this paper, the cooperative spectrum sensing is probabilistically modeled as a mixture of two Gaussian distributions and EM algorithm is applied for learning the parameters and classifying these two classes. Also, in order to exploit the dependencies of the states of the primary user in time, a Hidden Markov Model is used to improve the performance of the centralized spectrum sensing. Furthermore, a new decentralized cooperative spectrum sensing algorithm is proposed. In this case, the local information of secondary users are appropriately combined to guarantee a reliable communication. Our simulation results indicate the remarkable performance of the proposed cooperative sensing algorithms even in very low signal to noise ratios.",
Study of compact antenna for UWB applications,"A novel miniature antenna design for ultra-wideband (UWB) applications is presented. The proposed compact antenna is achieved by exploiting a quasi-self-complementary structure along with a tapered radiating slot. The optimal design of this type of antenna can offer an ultra-wide 10 dB impedance bandwidth with reasonable radiation properties. It also exhibits very small dimensions, 19 × 16 mm in physical size, and 0.19 ¿ in electrical size. Good agreement is obtained between simulated and measured antenna characteristics.",
Fast Katsevich Algorithm Based on GPU for Helical Cone-Beam Computed Tomography,"Katsevich reconstruction algorithm represents a breakthrough for helical cone-beam computed tomography (CT) reconstruction, because it is the first exact cone-beam reconstruction algorithm of filtered backprojection (FBP) type with 1-D shift-invariant filtering. Although FBP-type reconstruction algorithm is effective, 3-D CT reconstruction is time-consuming, and the accelerations of Katsevich algorithm on CPU or cluster have been widely studied. In this paper, Katsevich algorithm is accelerated by using graphics processing unit, including flat-detector and curved-detector geometry in the case of helical orbit. An overscan formula is derived, which helps to avoid unnecessary overscan in practical CT scanning. Based on the overscan formula, a volume-blocking method in device memory is proposed. One advantage of the blocking method is that it can reconstruct large volume with high speed.",
An online approach: Learning-Semantic-Scene-by-Tracking and Tracking-by-Learning-Semantic-Scene,"Learning the knowledge of scene structure and tracking a large number of targets are both active topics of computer vision in recent years, which plays a crucial role in surveillance, activity analysis, object classification and etc. In this paper, we propose a novel system which simultaneously performs the Learning-Semantic-Scene and Tracking, and makes them supplement each other in one framework. The trajectories obtained by the tracking are utilized to continually learn and update the scene knowledge via an online un-supervised learning. On the other hand, the learned knowledge of scene in turn is utilized to supervise and improve the tracking results. Therefore, this “adaptive learning-tracking loop” can not only perform the robust tracking in high density crowd scene, dynamically update the knowledge of scene structure and output semantic words, but also ensures that the entire process is completely automatic and online. We successfully applied the proposed system into the JR subway station of Tokyo, which can dynamically obtain the semantic scene structure and robustly track more than 150 targets at the same time.","Layout,
Target tracking,
Robustness,
Computer vision,
Surveillance,
Trajectory,
Tracking loops"
Termite colony optimization: A novel approach for optimizing continuous problems,"In this paper, a novel approach, called Termite colony optimization (or TCO), for optimizing numerical functions is presented. TCO is a population based optimization technique which is inspired from intelligent behaviors of termites. The proposed approach provides a decision making model which is used by termites to adjust their movement trajectories. Termites move randomly in the search space, but their trajectories are biased towards regions with more pheromones. TCO is compared with existing population-based algorithms on a set of well known numerical test functions. The experimental results show that the TCO is effective and robust; produce good results, and outperform other algorithms investigated in this consideration.","Ant colony optimization,
Particle swarm optimization,
Space exploration,
Negative feedback,
Decision making,
Testing,
Optimization methods,
Genetic mutations,
Insects,
Information technology"
FS2You: Peer-Assisted Semipersistent Online Hosting at a Large Scale,"It has been widely acknowledged that online file hosting systems within the “cloud” of the Internet have provided valuable services to end users who wish to share files of any size. Such online hosting services are typically provided by dedicated servers, either in content distribution networks (CDNs) or large data centers. Server bandwidth costs, however, are prohibitive in these cases, especially when serving large volumes of files to a large number of users. Though it seems intuitive to take advantage of peer upload bandwidth to mitigate such server bandwidth costs in a complementary fashion, it is not trivial to design and fine-tune important aspects of such peer-assisted online hosting in a real-world large-scale deployment. This paper presents FS2You, a large-scale and real-world online file hosting system with peer assistance and semipersistent file availability. FS2You is designed to dramatically mitigate server bandwidth costs. In this paper, we show a number of key challenges involved in such a design objective, our architectural and protocol design in response to these challenges, as well as an extensive measurement study at a large scale to demonstrate the effectiveness of our design, using real-world traces that we have collected. To our knowledge, this paper represents the first attempt to design, implement, and evaluate a new peer-assisted semipersistent online file hosting system at a realistic scale. Since the launch of FS2You, it has quickly become one of the most popular online file hosting systems in mainland China, and a favorite in many online forums across the country.","Large-scale systems,
Bandwidth,
Costs,
File servers,
Network servers,
Peer to peer computing,
Web server,
Protocols,
Sun,
Web and internet services"
Computer Modelling and Analysis of Lightning Surges in HV Substations due to Shielding Failure,"This paper deals with modelling and analyzing specific transient states of voltages (i.e., of lightning surges in electric power systems of high voltages). The lightning surges arriving in a substation are impacted by more complicated wave effects. Those effects result from a complex spatial structure of each substation, and are determined by all equipment units mounted on it. A model of an electric power line and substation developed for computer software Electromagnetic Transients Program-Alternative Transients Program is presented in this paper. This model includes wave effects and nonlinear effects. It is based on a set of appropriately connected elements (i.e., distributed parameter elements and lumped parameter elements). Furthermore, the analysis results of lightning surges as well as the optimization results of a surge protection system installed in a 110-kV substation are presented in this paper.","Failure analysis,
Lightning,
Substations,
Surge protection,
Power system modeling,
Transient analysis,
Power system transients,
Voltage,
Power system analysis computing,
Electromagnetic modeling"
Unsupervised learning of invariant features using video,"We present an algorithm that learns invariant features from real data in an entirely unsupervised fashion. The principal benefit of our method is that it can be applied without human intervention to a particular application or data set, learning the specific invariances necessary for excellent feature performance on that data. Our algorithm relies on the ability to track image patches over time using optical flow. With the wide availability of high frame rate video (eg: on the web, from a robot), good tracking is straightforward to achieve. The algorithm then optimizes feature parameters such that patches corresponding to the same physical location have feature descriptors that are as similar as possible while simultaneously maximizing the distinctness of descriptors for different locations. Thus, our method captures data or application specific invariances yet does not require any manual supervision. We apply our algorithm to learn domain-optimized versions of SIFT and HOG. SIFT and HOG features are excellent and widely used. However, they are general and by definition not tailored to a specific domain. Our domain-optimized versions offer a substantial performance increase for classification and correspondence tasks we consider. Furthermore, we show that the features our method learns are near the optimal that would be achieved by directly optimizing the test set performance of a classifier. Finally, we demonstrate that the learning often allows fewer features to be used for some tasks, which has the potential to dramatically improve computational concerns for very large data sets.","Unsupervised learning,
Testing,
Surgery,
Image motion analysis,
Optimization methods,
Machine learning algorithms,
Streaming media,
Artificial intelligence,
Laboratories,
Computer science"
Multi-layer clustering routing algorithm for wireless vehicular sensor networks,"Recently, there is a strong interest in developing wireless sensor network (WSN) techniques and important applications for moving vehicles, to enable WSN communication between roadside and vehicles or between vehicles. Wireless vehicular sensor networks (VSNs) using all kinds of routing algorithms of low-energy efficiency has recently received considerable attention. Clustering algorithm has a significant impact on the operation of WSN. Effective clustering algorithm leads WSN to operate efficiently. Hierarchical clustering is a new clustering scheme in WSN. This study presents a novel vehicular clustering scheme integrating hierarchical clustering on the basis of classical routing algorithm. Simulation results show that the new scheme efficiently mitigates the hot spot problem in WSN and achieves much improvement in network lifetime and load balance compared to the old algorithm which is Direct, LEACH and DCHS.","wireless sensor networks,
automotive electronics,
pattern clustering"
Approximation of Generalized Processor Sharing With Interleaved Stratified Timer Wheels,"This paper presents Interleaved Stratified Timer Wheels as a novel priority queue data structure for traffic shaping and scheduling in packet-switched networks. The data structure is used to construct an efficient packet approximation of general processor sharing (GPS). This scheduler is the first of its kind by combining all desirable properties without any residual catch. In contrast to previous work, the scheduler presented here has constant and near-optimal delay and fairness properties, and can be implemented with O(1) algorithmic complexity, and has a low absolute execution overhead. The paper presents the priority queue data structure and the basic scheduling algorithm, along with several versions with different cost-performance trade-offs. A generalized analytical model for rate-controlled rounded timestamp schedulers is developed and used to assess the scheduling properties of the different scheduler versions.","Wheels,
Scheduling algorithm,
Processor scheduling,
Global Positioning System,
Data structures,
Traffic control,
Costs,
Approximation algorithms,
Telecommunication traffic,
Delay"
"Thinning, Entropy, and the Law of Thin Numbers","Rényi's thinning operation on a discrete random variable is a natural discrete analog of the scaling operation for continuous random variables. The properties of thinning are investigated in an information-theoretic context, especially in connection with information-theoretic inequalities related to Poisson approximation results. The classical Binomial-to-Poisson convergence (sometimes referred to as the “law of small numbers”) is seen to be a special case of a thinning limit theorem for convolutions of discrete distributions. A rate of convergence is provided for this limit, and nonasymptotic bounds are also established. This development parallels, in part, the development of Gaussian inequalities leading to the information-theoretic version of the central limit theorem. In particular, a “thinning Markov chain” is introduced, and it is shown to play a role analogous to that of the Ornstein-Uhlenbeck process in connection to the entropy power inequality.","Entropy,
Random variables,
Convergence,
Polynomials,
Councils,
Information theory,
Mathematics,
Informatics,
Source coding,
Convolutional codes"
Smart lighting using LED luminaries,"The target of a smart lighting system is to control light sources in an environment (e.g. home, office) adaptively according to user contexts and preferences. Literature work in this area focuses on traditional light sources such as incandescent and fluorescent lights, whereas this paper takes a step towards adopting LED luminaries. A novel illumination model for distributed LED luminary control is presented. A prototype system is designed and implemented using several LED luminaries and light sensors. Experiments carried out on the reading space use case show that the desired illumination can be achieved based on user preferences, irrespective of the existence of external light sources.","LED lamps,
Light emitting diodes,
Lighting control,
Light sources,
Intelligent sensors,
Fluorescence,
Fluorescent lamps,
Control systems,
Prototypes,
Sensor systems"
Understanding and Supporting Lightweight Communication in Hospital Work,"Informal communication is an essential resource in hospital work; it is used as a means to collaborate and coordinate the way in which work is performed, as well as to locate and gather the artifacts and human resources required for patient care. The need of physical proximity to establish and hold informal communications has motivated the development of tools that support remote informal interaction. However, this kind of technology has not been widely adopted in hospitals, where workers experience intense mobility. In this paper, we present the results of an observational study in a hospital aimed at understanding how local mobility changes the rules in the provision of support for informal communication, and how technology could improve this form of communication. We found that local mobility fosters opportunities for colocated communication; however, it faces some inconveniences related to the affordances of the physical environment. We address these issues through the design of SOLAR, a collaborative application that supports colocated interactions in hospital work through the implementation and integration of five services that form a ubicomp infrastructure. Additionally, we present a discussion about the perception of users related to the usefulness of this tool.","Hospitals,
Collaborative work,
Laboratories,
Computer science,
Humans,
Communications technology,
Pervasive computing,
Medical services,
Mobile communication,
Medical diagnostic imaging"
Controller for improving the quality of the tandem rolling of hot metal strip,"The tandem hot metal strip rolling process presents a difficult control challenge because of its highly complex and nonlinear nature. This challenge is heightened by the hostile hot metal rolling environment which precludes the location of certain sensors to measure variables that are important for control. Based on our previous work using a state-dependent Riccati equation technique for development of a controller for the tandem cold metal rolling process, it is considered that a similar basis could be expanded upon to realize an improved method for the control of this more complex application. In this paper we present a comprehensive model of this process plus the results of our first efforts in the development of a suitable controller, which for control of this application is different than previous methods. The results of simulations of the controller coupled to the model show a strong potential for improvement in the quality of the final product.","Strips,
Milling machines,
Finishing,
Riccati equations,
Slabs,
Furnaces,
USA Councils,
Electric motors,
Electric variables control,
Nonlinear equations"
Multiscale Model of Liver DCE-MRI Towards a Better Understanding of Tumor Complexity,"The use of quantitative imaging for the characterization of hepatic tumors in magnetic resonance imaging (MRI) can improve the diagnosis and therefore the treatment of these life-threatening tumors. However, image parameters remain difficult to interpret because they result from a mixture of complex processes related to pathophysiology and to acquisition. These processes occur at variable spatial and temporal scales. We propose a multiscale model of liver dynamic contrast-enhanced (DCE) MRI in order to better understand the tumor complexity in images. Our design couples a model of the organ (tissue and vasculature) with a model of the image acquisition. At the macroscopic scale, vascular trees take a prominent place. Regarding the formation of MRI images, we propose a distributed model of parenchymal biodistribution of extracellular contrast agents. Model parameters can be adapted to simulate the tumor development. The sensitivity of the multiscale model of liver DCE-MRI was studied through observations of the influence of two physiological parameters involved in carcinogenesis (arterial flow and capillary permeability) on its outputs (MRI images at arterial and portal phases). Finally, images were simulated for a set of parameters corresponding to the five stages of hepatocarcinogenesis (from regenerative nodules to poorly differentiated HepatoCellular Carcinoma).","Liver neoplasms,
Magnetic resonance imaging,
Computational modeling,
Image color analysis,
Lesions,
Medical treatment,
Extracellular,
Permeability,
Portals,
Analytical models"
Multi-focus image fusion using wavelet-domain statistics,"The aim of multi-focus image fusion is to combine multiple images with different focuses for enhancing the perception of a scene. The critical issue in the design of multi-focus image fusion algorithms is to evaluate the local content information of the input images. Motivated by the observation that the marginal distribution of the wavelet coefficients is different for images with different focus levels, an image fusion approach using wavelet-domain statistics is proposed in this paper. The proposed approach exploits the spreading of the wavelet coefficients distribution to measure the degree of the image's blur. Furthermore, the wavelet coefficients distribution is evaluated using a locally-adaptive Laplacian mixture model. Extensive experiments are conducted using three sets of test images under three objective metrics to demonstrate the superior performance of the proposed approach.","Image fusion,
Laplace equations,
Measurement,
Approximation methods,
Wavelet transforms,
Image edge detection"
Towards automated self-calibration of robot skin,"This paper deals with the problem of calibrating a large number of tactile elements (i.e., taxels) organized in a skin sensor system after fixing them to a robot body part. This problem has not received much attention in literature because of the lack of large-scale skin sensor systems. The proposed approach is based on a controlled compliance motion with respect to external objects whose pose is known, which allows a robot to determine the location of its own taxels. The major contribution of this work is the formulation of the skin calibration problem as a maximum-likelihood mapping problem in a 6D space, where both the position and the orientation of each taxel are recovered. An effective calibration process is envisaged that, given a compliance control law that assures prolonged contact maintainance between a given body part and an external object, returns a maximum-likelihood estimate of detected taxel poses. Simulations validate the approach.",
Visualization of Spatiotemporal Behavior of Discrete Maps via Generation of Recursive Median Elements,"Spatial interpolation is one of the demanding techniques in geographic information science (GISci) to generate interpolated maps in a continuous manner by using two discrete spatial and/or temporal data sets. Noise-free data (thematic layers) depicting a specific theme at varied spatial or temporal resolutions consist of connected components either in aggregated or in disaggregated forms. This short paper provides a simple framework: 1) to categorize the connected components of layered sets of two different time instants through their spatial relationships and the Hausdorff distances between the companion-connected components and 2) to generate sequential maps (interpolations) between the discrete thematic maps. Development of the median set, using Hausdorff erosion and dilation distances to interpolate between temporal frames, is demonstrated on lake geometries mapped at two different times and also on the bubonic plague epidemic spread data available for 11 consecutive years. We documented the significantly fair quality of the median sets generated for epidemic data between alternative years by visually comparing the interpolated maps with actual maps. They can be used to visualize (animate) the spatiotemporal behavior of a specific theme in a continuous sequence.","Spatiotemporal phenomena,
Interpolation,
Spatial resolution,
Information systems,
Information science,
Data visualization,
Geographic Information Systems,
Lakes,
Geometry,
Animation"
Continuous Subgraph Pattern Search over Certain and Uncertain Graph Streams,"Search over graph databases has attracted much attention recently due to its usefulness in many fields, such as the analysis of chemical compounds, intrusion detection in network traffic data, and pattern matching over users' visiting logs. However, most of the existing works focus on search over static graph databases, while in many real applications, graphs are changing over time. In this paper, we investigate a new problem on continuous subgraph pattern search under the situation where multiple target graphs are constantly changing in a stream style, namely, the subgraph pattern search over graph streams. Obviously, the proposed problem is a continuous join between query patterns and graph streams where the join predicate is the existence of subgraph isomorphism. Due to the NP-completeness of subgraph isomorphism checking, to achieve the real-time monitoring of the existence of certain subgraph patterns, we would like to avoid using subgraph isomorphism verification to find the exact query-stream subgraph isomorphic pairs but to offer an approximate answer that could report all probable pairs without missing any actual answer pairs. Therefore, we propose a lightweight yet effective feature structure called Node-Neighbor Tree to filter out false candidate query-stream pairs. To reduce the computational cost, we propose a novel idea, projecting the feature structures into a numerical vector space and conducting dominant relationship checking in the projected space. We design two methods to efficiently verify dominant relationships, and thus, answer the subgraph search over graph streams efficiently. In addition to answering queries over certain graph streams, we propose a novel problem, detecting the appearance of subgraph patterns over uncertain graph streams with high probability (i.e., larger than the probability threshold specified by users). To address this problem, we not only extend the proposed solutions for certain graphs streams, but also propose a new pruning technique by utilizing the probability threshold. We substantiate our methods with extensive experiments on both certain and uncertain graph streams.","Databases,
Chemical analysis,
Pattern analysis,
Chemical compounds,
Intrusion detection,
Telecommunication traffic,
Pattern matching,
Monitoring,
Filters,
Computational efficiency"
Local clock skew minimization using blockage-aware mixed tree-mesh clock network,"Clock network construction is one key problem in high performance VLSI design. Reducing the clock skew variation is one of the most important objectives during clock network synthesis. Local clock skew (LCS) is the clock skew between any two sinks with distance less than or equal to a given threshold. It is defined in the ISPD 2010 High Performance Clock Network Synthesis Contest [1], and it is a novel criterion that captures process variation effects on a clock network. In this paper, we propose a hybrid method that creates a mesh upon a tree topology. Total wire and buffer capacitance is minimized under the LCS and slew constraints. In our method, a clock mesh will be built first according to the positions and capacitance of the sinks. A top-level tree is then built to drive the mesh. A blockage-aware routing method is used during the tree construction. Experimental results show our efficiency and the solution generated by our approach can satisfy the LCS constraint of all the benchmarks in the contest [1], with a fair capacitance usage.","Clocks,
Capacitance,
Merging,
Wire,
Delay,
Routing,
Design automation"
Using correlated surprise to infer shared influence,"We propose a method for identifying the sources of problems in complex production systems where, due to the prohibitive costs of instrumentation, the data available for analysis may be noisy or incomplete. In particular, we may not have complete knowledge of all components and their interactions. We define influences as a class of component interactions that includes direct communication and resource contention. Our method infers the influences among components in a system by looking for pairs of components with time-correlated anomalous behavior. We summarize the strength and directionality of shared influences using a Structure-of-Influence Graph (SIG). This paper explains how to construct a SIG and use it to isolate system misbehavior, and presents both simulations and in-depth case studies with two autonomous vehicles and a 9024-node production supercomputer.","Production systems,
Instruments,
Computer science,
Costs,
Silicon carbide,
Data analysis,
Remotely operated vehicles,
Mobile robots,
Supercomputers,
Delay effects"
An improved Sobel edge detection,"This paper proposes a method which combines Sobel edge detection operator and soft-threshold wavelet de-noising to do edge detection on images which include White Gaussian noises. In recent years, a lot of edge detection methods are proposed. The commonly used methods which combine mean de-noising and Sobel operator or median filtering and Sobel operator can not remove salt and pepper noise very well. In this paper, we firstly use soft-threshold wavelet to remove noise, then use Sobel edge detection operator to do edge detection on the image. This method is mainly used on the images which includes White Gaussian noises. Through the pictures obtained by the experiment, we can see very clearly that, compared to the traditional edge detection methods, the method proposed in this paper has a more obvious effect on edge detection.","Image edge detection,
Noise reduction"
A Simple and Robust Dissemination protocol for VANETs,"Several promising applications for Vehicular Ad-hoc Networks (VANETs) exist. For most of these applications, the communication among vehicles is envisioned to be based on the broadcasting of messages. This is due to the inherent highly mobile environment and importance of these messages to vehicles nearby. To deal with broadcast communication, dissemination protocols must be defined in such a way as to (i) prevent the so-called broadcast storm problem in dense networks and (ii) deal with disconnected networks in sparse topologies. In this paper, we present a Simple and Robust Dissemination (SRD) protocol that deals with these requirements in both sparse and dense networks. Its novelty lies in its simplicity and robustness. Simplicity is achieved by considering only two states (cluster tail and non-tail) for a vehicle. Robustness is achieved by assigning message delivery responsibility to multiple vehicles in sparse networks. Our simulation results show that SRD achieves high delivery ratio and low end-to-end delay under diverse traffic conditions.",
Scalable segmentation-based malicious circuitry detection and diagnosis,"Hardware Trojans (HTs) pose a significant threat to the modern and pending integrated circuit (IC). Several approaches have been proposed to detect HTs, but they are either incapable of detecting HTs under the presence of process variation (PV) or unable to handle very large circuits in the modern IC industry. We develop a scalable HT detection and diagnosis scheme by using segmentation techniques and gate level characterization (GLC). In order to address the scalability issue, we propose a segmentation method which divides the large circuit into small sub-circuits by using input vector control. We propose a segment selection model in terms of properties of segments and their effects on GLC accuracy. The model parameters are calibrated by sampled data from the GLC process. Based on the selected segments we are able to detect and diagnose HTs correctly by tracing gate level leakage power. We evaluate our approach on several ISCAS85/ISCAS89/ITC99 benchmarks. The simulation results show that our approach is capable of detecting and diagnosing HTs accurately on large circuits.",
Applying the Possibilistic c-Means Algorithm in Kernel-Induced Spaces,"In this paper, we study a kernel extension of the classic possibilistic c-means. In the proposed extension, we implicitly map input patterns into a possibly high-dimensional space by means of positive semidefinite kernels. In this new space, we model the mapped data by means of the possibilistic clustering algorithm. We study in more detail the special case where we model the mapped data using a single cluster only, since it turns out to have many interesting properties. The modeled memberships in kernel-induced spaces yield a modeling of generic shapes in the input space. We analyze in detail the connections to one-class support vector machines and kernel density estimation, thus, suggesting that the proposed algorithm can be used in many scenarios of unsupervised learning. In the experimental part, we analyze the stability and the accuracy of the proposed algorithm on some synthetic and real datasets. The results show high stability and good performances in terms of accuracy.","Clustering algorithms,
Prototypes,
Kernel,
Shape,
Phase change materials,
Algorithm design and analysis,
Unsupervised learning,
Support vector machines,
Stability analysis,
Data analysis"
On the scaling of polar codes: II. The behavior of un-polarized channels,"We provide upper and lower bounds on the escape rate of the Bhattacharyya process corresponding to polar codes where transmission takes place over the the binary erasure channel. More precisely, we bound the exponent of the number of sub-channels whose Bhattacharyya constant falls in a fixed interval [a, b]. Mathematically this can be stated as bounding the limit limn→8 1overn ln ℙ(Zn ∈ [a, b]), where Zn is the Bhattacharyya process. The quantity ℙ(Zn ∈ [a, b]) represents the fraction of sub-channels that are still un-polarized at time n.","Zinc,
Polarization,
Random variables,
H infinity control"
On signal tracing in post-silicon validation,"It is increasingly difficult to guarantee the first silicon success for complex integrated circuit (IC) designs. Post-silicon validation has thus become an essential step in the IC design flow. Tracing internal signals during circuit's normal operation, being able to provide real-time visibility to the circuit under debug (CUD), is one of the most effective silicon debug techniques and has gained wide acceptance in industrial designs. Trace-based debug solution, however, involves non-trivial design for debug overhead. How to conduct signal tracing effectively for bug elimination is therefore a challenging task for IC designers. In this paper, we provide in-depth discussion for trace-based debug strategy and review recent advancements in this important area.","Silicon,
Signal design,
Computer bugs,
Circuit testing,
Design for disassembly,
Laboratories,
Computer science,
Reliability engineering,
Design engineering,
Integrated circuit modeling"
The FACE of autism,"People with autism are known to possess deficits in processing emotional states, both their own and of others. A humanoid robot, FACE (Facial Automation for Conveying Emotions), capable of expressing and conveying emotions and empathy has been constructed to enable autistic children and adults to better deal with emotional and expressive information. We describe the development of an adaptive therapeutic platform which integrates information deriving from wearable sensors carried by a patient or subject as well as sensors placed in the therapeutic ambient. Through custom developed control and data processing algorithms the expressions and movements of FACE are then tuned and modulated to harmonize with the feelings of the subject postulated by their physiological and behavioral correlates. Preliminary results demonstrating the potential of adaptive therapy are presented.","Face,
Medical treatment,
Autism,
Humanoid robots,
Robot sensing systems,
Variable speed drives,
Androids"
Nonclassical Channel Design in MOSFETs for Improving OTA Gain-Bandwidth Trade-Off,"In this paper, gain-bandwidth (GB) trade-off associated with analog device/circuit design due to conflicting requirements for enhancing gain and cutoff frequency is examined. It is demonstrated that the use of a nonclassical source/drain (S/D) profile (also known as underlap channel) can alleviate the GB trade-off associated with analog design. Operational transconductance amplifier (OTA) with 60 nm underlap S/D MOSFETs achieve 15 dB higher open loop voltage gain (AVO_OTA) along with three times higher cutoff frequency (fT_OTA) as compared to OTA with classical nonunderlap S/D regions. Underlap design provides a methodology for scaling analog devices into the sub-100 nm regime and is advantageous for high temperature applications with OTA, preserving functionality up to 540 K. Advantages of underlap architecture over graded channel (GC) or laterally asymmetric channel (LAC) design in terms of GB behavior are demonstrated. Impact of transistor structural parameters on the performance of OTA is also analyzed. Results show that underlap OTAs designed with spacer-to-straggle (s/ σ) ratio of 3.2 and operated below a bias current (IBIAS) of 80 μA demonstrate optimum performance. The present work provides new opportunities for realizing future ultra wide band OTA design with underlap DG MOSFETs in silicon-on-insulator (SOI) technology.",
A real-time service-oriented framework to support sustainable cyber-physical systems,"Sustainability is an important issue with a growing interest. Two ICT technologies provide useful support for the sustainability of industrial systems: service-oriented architecture (SOA) and cyber-physical systems (CPS). SOA has been adopted in a variety of industrial systems due to its integration flexibility and process composability. CPS is a new technology to bring computational intelligence to physical devices and to make them mission- and situation-aware. We study a real-time SOA architecture to enhance sustainability and predictability in CPS. The proposed real-time SOA middleware builds the support for service accountability and global resource management for real-time service processes. Given a service plan and known resource constraints, the middleware monitors the performance and reserves resources in advance for each service in the process to ensure its real-time feasibility. A prototype of RT-SOA ESB has been implemented and evaluated.",
A Brief Survey on the Security Model of Cloud Computing,"Being proposed in 2007, cloud computing has been a hot researching area of computer network technology. Some giant companies can offer the cloud services now. With the development of cloud computing, a set of security problem appears, such as accessing security and so on. This paper surveys the security problems of current cloud computing., then based on the architecture of cloud computing, a security model is proposed.","Security,
Cloud computing,
Clouds,
Computational modeling,
Computer architecture,
Software,
Servers"
Migrating Autonomic Self-Testing to the Cloud,"The cloud computing model continues to gain much attention from software industry practitioners. As such, leading companies are investing in the development, packaging and delivery of cloud services over the Internet. However, although much work is being done to model and build cloud applications and services, there is significantly less research devoted to testing them. In this paper, we describe our research-in-progress towards migrating autonomic self-testing (AST) to the cloud. Our approach combines the development of an automated test harness for a cloud service, with the delivery of test support as-a-service (TSaaS). Both AST and TSaaS are supported by a virtual test environment, which utilizes the power of the cloud to enhance the self-testing process.",
Retinal vessel cannulation with an image-guided handheld robot,"Cannulation of small retinal vessels is often prohibitively difficult for surgeons, since physiological tremor often exceeds the narrow diameter of the vessel (40–120 µm). Using an active handheld micromanipulator, we introduce an image-guided robotic system that reduces tremor and provides smooth, scaled motion during the procedure. The micromanipulator assists the surgeon during the approach, puncture, and injection stages of the procedure by tracking the pipette and anatomy viewed under the microscope. In experiments performed ex vivo by an experienced retinal surgeon on 40–60 µm vessels in porcine eyes, the success rate was 29% (2/7) without the aid of the system and 63% (5/8) with the aid of the system.",
Evaluating natural interaction techniques in video games,"Despite the gaming industry's recent trend for using “natural” interaction techniques, which mimic real world actions with a high level of fidelity, it is not clear how natural interaction techniques affect the player experience. In order to obtain a better understanding, we designed and conducted a study using Mario Kart Wii, a commercial racing game for the Nintendo Wii. We chose this platform due to its seemingly balanced design of both natural and non-natural interaction techniques. Our empirical study of these techniques found that the non-natural interaction techniques significantly outperform their more natural counterparts. We offer three hypotheses to explain our finding and suggest them as important interaction design considerations.",
Integrating Visualization and Interaction Research to Improve Scientific Workflows,"Scientific-visualization research is, nearly by necessity, interdisciplinary. In addition to their collaborators in application domains (for example, cell biology), researchers regularly build on close ties with disciplines related to visualization, such as graphics, human-computer interaction, and cognitive science. One of these ties is the connection between visualization and interaction research. This isn't a new direction for scientific visualization (see the ""Early Connections"" sidebar). However, momentum recently seems to be increasing toward integrating visualization research (for example, effective visual presentation of data) with interaction research (for example, innovative interactive techniques that facilitate manipulating and exploring data). We see evidence of this trend in several places, including the visualization literature and conferences.","Data visualization,
Collaborative work,
Biological cells,
Graphics,
Cognitive science"
Sensitivity Analysis for Biomedical Models,"This article discusses the application of sensitivity analysis (SA) in biomedical models. Sensitivity analysis is widely applied in physics, chemistry, economics, social sciences and other areas where models are developed. By assigning a prior probability distribution to each model variable, the SA framework appeals to the posterior probabilities of the model to evaluate the relative importance of these variables on the output distribution based on the principle of general variance decomposition. Within this framework, the SA paradigm serves as an objective platform to quantify the contributions of each model factor relative to their empirical range. We present statistical derivations of variance-based SA in this context and discuss its detailed properties through some practical examples. Our emphasis is on the application of SA in the biomedical field. As we show, it may provide a useful tool for model quality assessment, model reduction and factor prioritization, and improve our understanding of the model structure and underlying mechanisms. When usual approaches for calculating sensitivity index involve the employment of Monte Carlo analysis, which is computationally expensive in the large-sampling paradigm, we develop two effective numerical approximate methods for quick SA evaluations based on the unscented transformation (UT) that utilize a deterministic sampling approach in place of random sampling to calculate posterior statistics. We show that these methods achieve an excellent compromise between computational burden and calculation precision. In addition, a clear guideline is absent to evaluate the importance of variable for model reduction, we also present an objective statistical criterion to quantitatively decide whether or not a descriptive parameter is nominal and may be discarded in ensuing model-based analysis without significant loss of information on model behavior.",
Multi-user diversity for secrecy in wireless networks,"The ability to transmit a message securely in the presence of eavesdroppers in a dense wireless network is considered. As with a number of recent schemes, system nodes other than the transmitter and receiver are chosen to generate noise that confuses the eavesdropper. By exploiting the dynamics of the fading, significantly improved performance is achieved beyond that generated from the standard multi-user diversity gain expected from opportunistic relaying. In particular, the node with the best fading characteristics takes responsibility for message relaying, while those whose fading will significantly reduce their impact on the desired communication play the role of noise generators. For a source transmitting to a destination using a set of intermediate relays, we consider the number of eavesdroppers that can be present without the interception of packets, in both the case where the eavesdroppers operate independently and in the case where they collude. The latter case also encompasses the more likely scenario of a single eavesdropper with a sophisticated receiver.","Wireless networks,
Relays,
Transmitters,
Fading,
Noise generators,
Interference cancellation,
Protocols,
Noise cancellation,
Jamming,
Diversity methods"
Measurement of Dielectric Constants of Nematic Liquid Crystals at mm-Wave Frequencies Using Patch Resonator,"A new technique for the measurement of dielectric constants of nematic liquid-crystal (LC) materials at millimeter-wave frequencies is presented. The proposed method utilizes an electric field to align the LC molecules, therefore offering safety and enormous size reduction over the method using the magnetic field to achieve LC directors' orientation. The measurement device is planar and consists of a rectangular patch resonator with the LC cell directly beneath it. Two preconditioned surface preparations, corresponding to transverse and longitudinal rubbing of the patch surface and ground plane in contact with LC, are investigated. Using the same measurement device with the two preconditioned surfaces, the measurements of dielectric constants and dielectric constant anisotropy of a nematic LC commonly known as E7 are conducted, and the results are found to agree to within 1% while confirming earlier published data.","Dielectric measurements,
Liquid crystals,
Permittivity measurement,
Dielectric constant,
Resonant frequency,
Millimeter wave technology"
Towards IEEE 802.15.4e: A study of performance aspects,"We discuss the applicability of IEEE 802.15.4 for application in industrial automation. Based on the specific requirements in this field, especially w.r.t. real-time operation, we analyzed the weaknesses of the standard protocol and proposed a novel MAC protocol that keeps the original PHY definition in order to work using available IEEE 802.15.4 chipsets. In earlier work, we analytically derived the worst case latency for using the improved protocol version in typical industrial setups. We now also implemented this protocol version in a simulation environment in order to show the typical behavior in the network taking into account typical channel conditions. We performed extensive simulation experiments that show the limitations of the standard protocol and that demonstrate the capabilities of the new protocol in a selected automation scenario. Our protocol variant is going to become the forthcoming IEEE 802.15.4e standard.","Physical layer,
Analytical models,
Media Access Protocol,
Wireless application protocol,
Delay,
Wireless sensor networks,
Energy efficiency,
Computer industry,
Manufacturing automation,
Wireless LAN"
The Specific-Force Performance Parameter for Electromagnetic Launchers,"A new electromagnetic-launcher (EML) performance parameter called the specific force is presented and analyzed in this paper. The specific force is the second derivative of the EML's force equation with respect to current and represents the force generated by the EML per unit square ampere, i.e., the EML's current efficiency. The specific force is independent of operating current and is defined for EMLs utilizing linear and nonlinear magnetic materials. The second derivative is termed as the specific force, since it unifies the various EML geometries so that only one force equation is required. The specific force, together with the energy-conversion efficiency, can be used as criterion to evaluate and compare EML geometries for various applications. The specific force for conventional railguns, augmented railguns, conventional helical launchers, and high-efficiency helical launchers is derived in this paper. The experimental performance of conventional railguns, augmented railguns, and conventional helical launchers are also analyzed in terms of their specific-force parameters.","Electromagnetic launching,
Geometry,
Railguns,
Physics,
Laboratories,
Electromagnetic forces,
Performance analysis,
Nonlinear equations,
Magnetic materials,
Electromagnetic analysis"
Warp propagation for video resizing,"This paper presents a video resizing approach that provides both efficiency and temporal coherence. Prior approaches either sacrifice temporal coherence (resulting in jitter), or require expensive spatio-temporal optimization. By assessing the requirements for video resizing we observe a fundamental tradeoff between temporal coherence in the background and shape preservation for the moving objects. Understanding this tradeoff enables us to devise a novel approach that is efficient, because it warps each frame independently, yet can avoid introducing jitter. Like previous approaches, our method warps frames so that the background are distorted similarly to prior frames while avoiding distortion of the moving objects. However, our approach introduces a motion history map that propagates information about the moving objects between frames, allowing for graceful tradeoffs between temporal coherence in the background and shape preservation for the moving objects. The approach can handle scenes with significant camera and object motion and avoid jitter, yet warp each frame sequentially for efficiency. Experiments with a variety of videos demonstrate that our approach can efficiently produce high-quality video resizing results.",
Convex optimization in identification of stable non-linear state space models,"A new framework for nonlinear system identification is presented in terms of optimal fitting of stable nonlinear state space equations to input/output/state data, with a performance objective defined as a measure of robustness of the simulation error with respect to equation errors. Basic definitions and analytical results are presented. The utility of the method is illustrated on a simple simulation example as well as experimental recordings from a live neuron.","Mathematical model,
Upper bound,
Equations,
Stability analysis,
Robustness,
Data models,
Linear systems"
"Relative to direct haptic feedback, remote vibrotactile feedback improves but slows object manipulation","Most prosthetic hand users are limited to visual feedback of movement performance. To characterize the benefit of vibrotactile feedback for a task that lacks haptic feedback, a virtual environment was used to experimentally manipulate visual, task-relevant haptic, and remote vibrotactile feedback on simple object manipulation for unimpaired subjects. The combination of visual and remote vibrotactile feedback was compared to visual feedback alone, and to simultaneous visual and direct haptic feedback to represent ideal performance. Visual and vibrotactile feedback resulted in improvement of most performance variables including difficulty ratings relative to visual feedback alone. However addition of sensory cues to visual feedback increased trial times and the increase was steeper for vibrotactile than for haptic feedback. Specifically, during vibrotactile feedback the velocity did not change, but the duration of execution increased due to improved performance, resulting in increased trial times. This result suggests future exploration of performance improvement and execution speed for augmented sensory feedback.","Visualization,
Force,
Virtual environment,
Prosthetic hand,
Force feedback,
Fingers"
Printed passive UHF RFID tags as wearable strain sensors,Strain measurements could be utilized in monitoring human bodily functions and movements. Cost effective and low maintenance wearable sensors are needed in this field. The goal of this paper was to produce wearable strain sensors based on UHF RFID technology and the behavior of the materials which were utilized in prototypes. Two tag geometries were compared. Polymer thick film silver ink was used as the conductive medium. The tags were fabricated by screen printing the ink on stretchable PVC and on fabric substrates. Performance of the tags and the effect of mechanical straining on tag functioning was examined. The prototypes tolerated large strain levels. The results showed that the behavior of the UHF RFID tag strain sensor is dependent on the material behavior under strain as well as the tag antenna geometry. These offer various possibilities in strain measuring.,
Toward real-time grocery detection for the visually impaired,"We present a study on grocery detection using our object detection system, ShelfScanner, which seeks to allow a visually impaired user to shop at a grocery store without additional human assistance. ShelfScanner allows online detection of items on a shopping list, in video streams in which some or all items could appear simultaneously. To deal with the scale of the object detection task, the system leverages the approximate planarity of grocery store shelves to build a mosaic in real time using an optical flow algorithm. The system is then free to use any object detection algorithm without incurring a loss of data due to processing time. For purposes of speed we use a multiclass naive-Bayes classifier inspired by NIMBLE, which is trained on enhanced SURF descriptors extracted from images in the GroZi-120 dataset. It is then used to compute per-class probability distributions on video keypoints for final classification. Our results suggest ShelfScanner could be useful in cases where high-quality training data is available.",
Policy-aware sender anonymity in location based services,"Sender anonymity in location-based services (LBS) attempts to hide the identity of a mobile device user who sends requests to the LBS provider for services in her proximity (e.g. “find the nearest gas station” etc.). The goal is to keep the requester's interests private even from attackers who (via hacking or subpoenas) gain access to the request and to the locations of the mobile user and other nearby users at the time of the request. In an LBS context, the best-studied privacy guarantee is known as sender k-anonymity. We show that state-of-the art solutions for sender k-anonymity defend only against naive attackers who have no knowledge of the anonymization policy that is in use. We strengthen the privacy guarantee to defend against more realistic “policy-aware” attackers. We describe a polynomial algorithm to obtain an optimum anonymization policy. Our implementation and experiments show that the policy-aware sender k-anonymity has potential for practical impact, being efficiently enforceable, with limited reduction in utility when compared to policy-unaware guarantees.","Privacy,
Partitioning algorithms,
Computer crime,
Power system protection,
Databases,
Computer science,
Art,
Polynomials,
Hospitals,
Wireless networks"
Modern instruments for increasing the efficiency of the energy transfer in electric vehicles,"This paper describes the high efficiency drive unit for an EV, which is designed with accessible solutions for the efficiency increasing. Synchronous utilization of ultracapacitors and three-level inverter brings considerable power savings and enhancement longevity for a lithium battery pack. The total loss and EMI comparison between the two-level and three-level inverter and power measurements on the EV drive unit are presented at the conclusion part of this paper.","Supercapacitors,
Converters,
Inverters,
Batteries,
Fuel cells,
Insulated gate bipolar transistors,
Traction motors"
Evaluation and design exploration of solar harvested-energy prediction algorithm,"To respond to variations in solar energy, harvested-energy prediction is essential to harvested-energy management approaches. The effectiveness of such approaches is dependent on both the achievable accuracy and computation overhead of prediction algorithm implementation. This paper presents detailed evaluation of a recently reported solar energy prediction algorithm to determine empirical bounds on achievable accuracy and implementation overhead using an effective error evaluation technique. We evaluate the algorithm performance over varying prediction horizons and propose guidelines for algorithm parameter selection across different real solar energy profiles to simplify implementation. The prediction algorithm computation overhead is measured on actual hardware to demonstrate prediction accuracy-cost trade-off. Finally, we motivate the basis for dynamic prediction algorithm and show that more than 10% increase in prediction accuracy can be achieved compared to static algorithm.","Algorithm design and analysis,
Prediction algorithms,
Solar energy,
Energy management,
Accuracy,
Power measurement,
Embedded system,
Energy storage,
Costs,
Solar power generation"
An Empirical Evaluation of Puzzle-Based Learning as an Interest Approach for Teaching Introductory Computer Science,This correspondence describes an adaptation of puzzle-based learning to teaching an introductory computer programming course. Students from two offerings of the course-with and without the puzzle-based learning-were surveyed over a two-year period. Empirical results show that the synthesis of puzzle-based learning concepts with existing course content improves students' learning experience by increasing their interest and participation in the course and developing their critical thinking skills.,"Computer science education,
Problem-solving,
Laboratories,
Learning systems"
Selection Policy-Induced Reduction Mappings for Boolean Networks,"Developing computational models paves the way to understanding, predicting, and influencing the long-term behavior of genomic regulatory systems. However, several major challenges have to be addressed before such models are successfully applied in practice. Their inherent high complexity requires strategies for complexity reduction. Reducing the complexity of the model by removing genes and interpreting them as latent variables leads to the problem of selecting which states and their corresponding transitions best account for the presence of such latent variables. We use the Boolean network (BN) model to develop the general framework for selection and reduction of the model's complexity via designating some of the model's variables as latent ones. We also study the effects of the selection policies on the steady-state distribution and the controllability of the model.","Computer networks,
Genomics,
Bioinformatics,
Steady-state,
Biological system modeling,
Biology computing,
Optimal control,
Computational modeling,
Predictive models,
Controllability"
An Empirical Test of the Mobile Services Acceptance Model,"This paper presents a mobile services acceptance model, which includes aspects of trust, contextual fit, and personal initiatives and characteristics in addition to perceived usefulness and perceived ease of use from the technology acceptance model (TAM). The proposed research model was empirically tested using data collected from a survey of 25 users of a mobile service called Mobile Student Information Systems (MSIS). The results reveal that the fitness of the acceptance model is quite good. Our findings indicate that personal initiatives and characteristics, trust, and perceived ease of use are key determinants for the users to adopt the mobile service. Context via its influence on perceived usefulness and perceived ease of use has an indirect affect on intention to use. Furthermore, a striking finding is the negative influence of perceived usefulness on intention to use.",
Developing a Dark Web collection and infrastructure for computational and social sciences,"In recent years, there have been numerous studies from a variety of perspectives analyzing the Internet presence of hate and extremist groups. Yet the websites and forums of extremist and terrorist groups have long remained an underutilized resource for terrorism researchers due to their ephemeral nature and access and analysis problems. The purpose of the Dark Web archive is to provide a research infrastructure for use by social scientists, computer and information scientists, policy and security analysts, and others studying a wide range of social and organizational phenomena and computational problems. The Dark Web Forum Portal provides web enabled access to critical international jihadist and other extremist web forums. The focus of this paper is on the significant extensions to previous work including: increasing the scope of data collection, adding an incremental spidering component for regular data updates; enhancing the searching and browsing functions; enhancing multilingual machine-translation for Arabic, French, German and Russian; and advanced Social Network Analysis. A case study on identifying active participants is shown at the end.","Information analysis,
Internet,
Information security,
Uniform resource locators,
Terrorism,
Social network services,
Computer security,
Data visualization,
Natural languages,
National security"
Understanding the Effect of Bias in Fiducial Localization Error on Point-Based Rigid-Body Registration,"Image registration is a single point of failure in the image-guided computer-assisted surgery. Registration is primarily used to align and fuse the data sets taken from patient's anatomy before and during surgeries. Point-based rigid-body registration is usually performed by identifying corresponding fiducials (either natural landmarks or implanted ones) in the data sets. Since the localization of fiducials is imprecise and is generally perturbed by random noise, the performed registration is imperfect and has some error. Previous work has extensively analyzed the behavior of this error when the fiducial localization error has zero-mean over the entire set of fiducials. However, if noise has a nonzero-mean or a bias, no formulation yet exists to determine the effect of noise on the overall registration accuracy. In this work, we derive novel formulations that relate the bias in the localized fiducials to the accuracy of the performed registration. We analytically and numerically demonstrate that by eliminating the estimated bias from the measured fiducial locations, one can effectively increase the accuracy of the performed registration.","Computer errors,
Surgery,
Biomedical engineering,
Permission,
Image registration,
Fuses,
Anatomy,
Performance analysis,
Performance evaluation,
Anisotropic magnetoresistance"
ESOP-Based Toffoli Network Generation with Transformations,"In this paper a new Toffoli gate cascade synthesis method is presented. This method is based on previous work and generates a cascade of inverted-control-Toffoli gates from the ESOP representation of a multi-output function. The algorithm first generates a circuit with n + m lines, where n and m are the number of inputs and outputs, respectively. A set of gate transformations are applied to the circuits to remove some of the output lines. The improvements of this new algorithm are twofold: most NOT gates are eliminated and the number of lines is reduced. A significant reduction is the quantum cost of the resulting networks can be observed.","Circuit synthesis,
Logic,
Quantum computing,
Optical computing,
Data structures,
Boolean functions,
Computer science,
Niobium,
Network synthesis,
Costs"
Four-Phase AC Connections: An Alternative Possibility for the Expansion of Transmission Grids,"This paper investigates the economical feasibility of four-phase (4P) overhead transmission lines, considered as a possible alternative to the traditional three-phase (3P) connections. The paper performs an economical comparison between innovative 4P transmission lines and traditional 3P lines, with the goal of evaluating the contests where a 4P connection could become convenient, accounting for different reliability, land occupation, visual impact, energy losses and investment costs.",
Alternative hyper-heuristic strategies for multi-method global optimization,The purpose of this paper is to investigate the use of meta-heuristics as low-level heuristics in a hyper-heuristic framework. A novel multi-method hyper-heuristic algorithm which makes use of a number of common meta-heuristics is presented. Algorithm performance is evaluated on a diverse set of real parameter benchmark problems and meaningful conclusions are drawn with respect to the selection of alternative low-level heuristics and the acceptance of the obtained solutions within the proposed multi-method meta-heuristic approach.,"Optimization,
Heuristic algorithms,
Algorithm design and analysis,
Benchmark testing,
Evolutionary computation,
Equations,
Software algorithms"
A Spatio-Temporal Deconvolution Method to Improve Perfusion CT Quantification,"Perfusion imaging is a useful adjunct to anatomic imaging in numerous diagnostic and therapy-monitoring settings. One approach to perfusion imaging is to assume a convolution relationship between a local arterial input function and the tissue enhancement profile of the region of interest via a ¿residue function¿ and subsequently solve for this residue function. This ill-posed problem is generally solved using singular-value decomposition based approaches, and the hemodynamic parameters are solved for each voxel independently. In this paper, we present a formulation which incorporates both spatial and temporal correlations, and show through simulations that this new formulation yields higher accuracy and greater robustness with respect to image noise. We also show using rectal cancer tumor images that this new formulation results in better segregation of normal and cancerous voxels.",
Dual-Differential Rheological Actuator for High-Performance Physical Robotic Interaction,"Today's robotic systems are mostly rigid and position-controlled machines designed to operate in structured environments. To extend their application domains to partially unknown, dynamic, or anthropic environments, improved physical-interaction capabilities are required. In this new context, to blend the requirements for safety, robustness, and versatility is often a challenge, in part, because commonly available actuator technologies are inadequate. This paper presents our solution with the introduction of the dual-differential rheological actuator (DDRA) concept, which is based on the synergistic combination of an electromagnetic (EM) motor and two differentially coupled magnetorheological (MR) brakes. This paper describes the approach and the prototype design. It then discusses performances in force, motion, and interaction control.","Rheology,
Actuators,
Robots,
Electromagnetic coupling,
Safety,
Robustness,
Electromagnetic forces,
Prototypes,
Force control,
Motion control"
Asymmetric Multilevel Diversity Coding and Asymmetric Gaussian Multiple Descriptions,"We consider the asymmetric multilevel diversity (A-MLD) coding problem, where a set of 2K - 1 information sources, ordered in a decreasing level of importance, is encoded into K messages (or descriptions). There are 2K - 1 decoders, each of which has access to a nonempty subset of the encoded messages. Each decoder is required to reproduce the information sources up to a certain importance level depending on the combination of descriptions available to it. We obtain a single letter characterization of the achievable rate region for the 3-description problem. In contrast to symmetric multilevel diversity coding, source-separation coding is not sufficient in the asymmetric case, and ideas akin to network coding need to be used strategically. Based on the intuitions gained in treating the A-MLD problem, we derive inner and outer bounds for the rate region of the asymmetric Gaussian multiple description (MD) problem with three descriptions. Both the inner and outer bounds have a similar geometric structure to the rate region template of the A-MLD coding problem, and, moreover, we show that the gap between them is constant, which results in an approximate characterization of the asymmetric Gaussian three description rate region.",
Face recognition for newborns: A preliminary study,"Newborn swapping and abduction is a global problem and traditional approaches such as ID bracelets and footprinting do not provide the required level of security. This paper introduces the concept of using face recognition for identifying newborns and presents an automatic face recognition algorithm. The proposed multiresolution algorithm extracts Speeded up robust features and local binary patterns from different levels of Gaussian pyramid. The feature descriptors obtained at each Gaussian level are combined using weighted sum rule. On a newborn face database of 34 babies, the proposed algorithm yields rank-1 identification accuracy of 86.9%.","Pediatrics,
Face recognition,
Face,
Feature extraction,
Databases,
Pixel,
Accuracy"
An Interaction-Embedded HMM Framework for Human Behavior Understanding: With Nursing Environments as Examples,"This paper presents an interaction-embedded hidden Markov model (IE-HMM) framework for automatically detecting and classifying individual human behaviors and group interactions. The proposed framework comprises a switch control (SC) module, an individual duration HMM (IDHMM) module, and an interaction-coupled duration HMM (ICDHMM) module. By analyzing the relative distances between the various participants in each scene, and monitoring the duration for which these distances are maintained, the SC module assigns each participant to an individual behavior unit (comprising a single participant) or an interaction behavior unit (comprising two or more participants). The individual behavior units are passed to the IDHMM module, which classifies the corresponding human behavior in accordance with the pose, motion, and duration information using duration HMM (DHMM). Similarly, the interaction behavior units are dispatched to the ICDHMM module, where the corresponding interaction mode is classified using an integrated scheme comprising multiple coupled-duration HMM (CDHMM), in which each state has an embedded coupled HMM (CHMM). The validity of the IE-HMM framework is confirmed by analyzing the human actions and interactions observed in a nursing home environment. The results confirm that the atomic behavior unit concept embedded in the SC module enables the IE-HMM framework to recognize multiple concurrent actions and interactions within a single scene. Overall, it is shown that the proposed framework has a recognition performance of 100% when applied to the analysis of individual human actions and 95% when applied to that of group interactions.","Hidden Markov models,
Humans,
Medical services,
Bayesian methods,
Switches,
Layout,
Monitoring,
Performance analysis,
Surveillance"
On the Scatterers' Mobility and Second Order Statistics of Narrowband Fixed Outdoor Wireless Channels,"In this paper, we study the temporal behavior of narrowband fixed outdoor wireless channels by modeling the impact of scatterers' mobility on the second order statistics of such channels. We show that the Nakagami-m, gamma, Weibull and lognormal probability density functions (PDFs) can adequately approximate the scatterers' mobility at outdoor environments by comparing the theoretically derived autocorrelation functions (ACFs) with measured ACFs. These theoretical ACFs arise after considering several candidate PDFs for the impact of scatterers mobility. We select that PDF whose ACF provides the best fitting to measurements. The modeling of scatterers' mobility lead us to present analytical expressions for the level crossing rate (LCR) and average fade duration (AFD) together with an exact expression for the power spectral density (PSD).",
Repetition-based web page segmentation by detecting tag patterns for small-screen devices,"Web page segmentation into logical blocks is an important preprocessing step for recognizing informative content blocks in a page that leads to efficient information extraction and convenient display on the devices with small-sized screens. Previous methods for Web page segmentation are not flexible in a dynamic Web environment because they largely relied on heuristic rules generated by exploiting structural tags and visual information inherent in a page. To resolve this problem, this paper proposes a new method of Web page segmentation by recognizing repetitive tag patterns called key patterns in the DOM tree structure of a page. We report on the Repetition-based Page Segmentation (REPS) algorithm, which detects key patterns in a page and generates virtual nodes to correctly segment nested blocks. A series of experiments performed for real Web sites showed that REPS greatly contributes to improving the correctness of Web page segmentation.","Web pages,
Data mining,
Pattern recognition,
Tree data structures,
Computer science,
HTML,
Large screen displays,
Computer displays,
Mobile computing,
Mobile communication"
Opportunistic Cooperation in Low Duty Cycle Wireless Sensor Networks,"Energy efficient asynchronous duty cycle MAC protocols are crucial to the success of wireless sensor networks (WSNs). In asynchronous protocols, each node operates its active/sleep schedule independently and enjoys a very low duty cycle when there is no traffic. However, when a node has data to send, it has to keep active and wait until the receiver wakes up due to the lack of schedule knowledge of the receiver. In low duty cycle networks, where nodes wake up infrequently, a sender usually suffers a long period of waiting, which consumes more energy than transmitting data packet itself. In this paper, we propose a new asynchronous MAC protocol, called OCMAC, which decreases the waiting time of sender by exploring opportunistic cooperation among senders. In OC-MAC, neighboring active senders are permitted to exchange data with each other aggressively when waiting for receivers to wake up. After delegating data to another sender, a sender can go to sleep before its receiver wakes up. Though this cooperation works only when there are multiple neighboring active senders, itself almost incurs no additional overhead. Simulation results and measurements on a testbed have shown that OC-MAC helps decrease idle listening, collision and end-to-end delay further.","Wireless sensor networks,
Sleep,
Synchronization,
Media Access Protocol,
Energy consumption,
Paper technology,
Peer to peer computing,
Telecommunication traffic,
Computer science,
Delay"
Basic unit layer rate control for video security,"Video security is one of multi-view video applications. However the current multi-view video coding (MVC) software does not contain any rate control technique, this paper proposes a rate control algorithm for MVC based on the quadratic rate-distortion (R-D) model. The proposed algorithm adopts the fluid-flow traffic model, HRD (hypothetical reference decoder) and linear prediction model of MAD (the mean absolute difference). Compared to the multi-view video coding with fixed quantization parameter, the proposed scheme can efficiently control the bit rate with an average rate control error of 0.62% while keeping high coding efficiency.","Bit rate,
Video coding,
Streaming media,
Encoding,
Prediction algorithms,
Quantization,
Algorithm design and analysis"
Energy-awareness in dynamic traffic grooming,"We introduce an energy-efficient traffic grooming scheme for promoting greener optical networks. The scheme considers a modular node architecture, reuses already active components during request allocations, and conserves total energy consumption in the network.","Telecommunication traffic,
Energy consumption,
Optical fiber networks,
Routing,
Costs,
Energy management,
Wavelength division multiplexing,
Computer science,
Power engineering and energy,
Energy efficiency"
Customers' Role in Teaching Distributed Software Development,"This paper describes different aspects of teaching distributed software development, regarding the types of project customers: industry and academia. These approaches enable students to be more engaged in real-world situations, by having customers from the industry, local or distributed customers in universities, distributed customers in software engineering contests or being involved in an ongoing project, thus simulating the company merging. The methods we describe are used in a distributed project-oriented course, which is jointly carried out by two universities from Sweden and Croatia. The paper presents our experiences of such projects being done during the course, the differences in each approach, issues observed and ways to solve them, in order to create a more engaging education for better-prepared engineers of tomorrow.","Education,
Programming,
Software engineering,
Distributed computing,
Computer industry,
Merging,
Technological innovation,
Design engineering,
Industrial training,
Corporate acquisitions"
Green cooperative communication using threshold-based relay selection protocols,"This paper proposes new approach to relay selection using a threshold-based transmission protocol for a system with multiple amplify-and-forward relays and users. The novelty of this protocol includes (1) economical feedback that reduces signal processing complexity, as well as (2) adaptively interrupted transmission that can save significant RF power when the selection requirement is not met. Applied to the downlink, this protocol uses a threshold on the first-hop (base-station-to-relay) SNR for relay selection. One-bit feedback is sent from each relay to the base station, reporting the comparison result between the base station-relay link SNR and threshold. Transmission takes place for a relay satisfying the selection condition of having its received SNR greater than a threshold or is otherwise switched off. Numerical results show that for low average SNR scenarios (where relaying is required), the selection threshold can be appropriately chosen relative to the number of relays to dramatically reduce transmit power without sacrificing outage performance.","Relays,
Protocols,
Power system relaying,
Feedback,
Power system economics,
Power generation economics,
Environmental economics,
Signal processing,
Radio frequency,
Downlink"
The Cost of Complexity in System Identification: Frequency Function Estimation of Finite Impulse Response Systems,"In this paper, we consider full order modeling, i.e., when the true system belongs to the model set. We investigate the minimum amount of input energy required to estimate a given linear system with a full order model within a prescribed degree of accuracy γ, as a function of the model complexity. This quantity we define to be the “cost of complexity.” The degree of accuracy is measured by the inverse of the maximum variance of the discrete-time frequency function estimator over a given frequency range [-ωB,ωB]. It is commonly believed that the cost increases as the model complexity increases. However, the amount of information that is to be extracted from the system also influences the cost. The objective of this paper is to quantify these dependencies for systems described by finite-impulse response models. It is shown that, asymptotically in the model order n and sample size, the cost is well approximated by γσo2nωB/π where σo2 is the noise variance. This expression can be used as a simple rule of thumb for assessing trade-offs that have to be made in a system identification project where full order models are used. For example, for given experiment duration, excitation level and desired accuracy, one can assess how the achievable frequency range depends on the required model order. This type of consideration is useful when formally planning experiments. In addition, we establish several properties of the cost of complexity. We find, for example, that if ωB is very close (but not necessarily equal) to π, the optimal input satisfies the model quality constraint for all frequencies.",
Estimation of Optimal Fiducial Target Registration Error in the Presence of Heteroscedastic Noise,"We study the effect of point dependent (heteroscedastic) and identically distributed anisotropic fiducial localization noise on fiducial target registration error (TRE). We derive an analytic expression, based on the concept of mechanism spatial stiffness, for predicting TRE. The accuracy of the predicted TRE is compared to simulated values where the optimal registration transformation is computed using the heteroscedastic errors in variables algorithm. The predicted values are shown to be contained by the 95% confidence intervals of the root mean square TRE obtained from the simulations.","Pollution measurement,
Optical noise,
Anisotropic magnetoresistance,
Surgery,
Quaternions,
Gaussian noise,
Coordinate measuring machines,
Biomedical optical imaging,
Noise measurement,
Jitter"
Particle grid tracking system for stereovision based environment perception,"This paper presents an occupancy grid tracking solution based on particles. The particles will have a dual nature - they will denote hypotheses, as in the particle filtering algorithms, but they will also be the building blocks of our modeled world. The particles have position and speed, and they can migrate in the grid from cell to cell depending on their motion model and motion parameters, but they will also be created and destroyed using a weighting-resampling mechanism specific to particle filter algorithms. An obstacle grid derived from processing a stereovision-generated elevation map is used as measurement information, and the measurement model takes into account the uncertainties of the stereo reconstruction. The resulted system is a flexible, real-time tracking solution for dynamic unstructured driving environments.","Particle tracking,
Vehicle dynamics,
Roads,
Bayesian methods,
Filtering algorithms,
Computer science,
Intelligent vehicles,
USA Councils,
Particle filters,
Real time systems"
Discovering bits of place histories from people's activity traces,"Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Significant and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years.",
LDPC codes for rank modulation in flash memories,"An LDPC code is proposed for flash memories based on rank modulation. In contrast to previous approaches, this enables the use of long ECCs with fixed-length modulation codes. For ECC design, the rank modulation scheme is treated as part of an equivalent channel. A probabilistic model of the equivalent channel is derived and a simple high-SNR approximation is given. LDPC codes over integer rings and finite fields are designed for the approximate channel and a low-complexity symbol-flipping verification-based (SFVB) message-passing decoding algorithm is proposed to take advantage of the channel structure. Density evolution (DE) is used to calculate decoding thresholds and simulations are used to compare the low-complexity decoder with sum-product decoding.","Parity check codes,
Modulation coding,
Flash memory,
Decoding,
Error correction codes,
Nonvolatile memory,
Algorithm design and analysis,
Tunneling,
Computer science,
Galois fields"
Computational Transition at the Uniqueness Threshold,"The hardcore model is a model of lattice gas systems which has received much attention in statistical physics, probability theory and theoretical computer science. It is the probability distribution over independent sets I
of a graph weighted proportionally to \lambda^{|I|}
with fugacity parameter \lambda
. We prove that at the uniqueness threshold of the hardcore model on the d
-regular tree, approximating the partition function becomes computationally hard on graphs of maximum degree d
. Specifically, we show that unless NP=
RP there is no polynomial time approximation scheme for the partition function (the sum of such weighted independent sets) on graphs of maximum degree d
for fugacity \lambda_c(d) 0
. Weitz produced an FPTAS for approximating the partition function when $0","Approximation methods,
Computational modeling,
Physics,
Correlation,
Polynomials,
Phase measurement,
Markov processes"
GPU optimization of the SGM stereo algorithm,"GPU hardware architectures have evolved into a suitable platform for the hardware acceleration of complex computing tasks. Stereo vision is one such task where acceleration is desirable for robotic and automotive systems. Much research was invested in developing stereo vision algorithms with increased quality, but real-time implementations are still lacking. In this work we focus on creating a real-time dense stereo reconstruction system. We selected the Semi-global Matching method as the basis of our system due to its high quality and reduced computational complexity. The Census transform is selected as the matching metric because our results show that it can reduce the matching errors for traffic images compared to classical solutions. We also present two modifications to the original Semi-Global algorithm to improve the sub-pixel accuracy and the execution time. The system was implemented and evaluated on a current generation GPU with a running time of 19ms for image having the resolution 512×383.","Measurement,
Real time systems,
Optimization,
Transforms,
Pixel,
Parallel processing,
Pipelines"
A 3D SoC design for H.264 application with on-chip DRAM stacking,"Three-dimensional (3D) on-chip memory stacking has been proposed as a promising solution to the “memory wall” challenge with the benefits of low access latency, high data bandwidth, and low power consumption. The stacked memory tiers leverage through-silicon-vias (TSVs) to communicate with logic tiers, and thus dramatically reduce the access latency and improve the data bandwidth without the constraint of I/O pin count. To demonstrate the feasibility of 3D memory stacking, this paper introduces a 3D System-on-Chip (SoC) for H.264 applications that can make use of multiple memory channels offered by 3D integration. Two logic tiers are stacked together with each having an area of 2.5×5.0mm2, with a 3-layer 8-channel 3D DRAM stacked on the top. The design flow for this 3D SoC is also presented. The prototype chip has been fabricated with GlobalFoundries' 130nm low-power process and Tezzaron's 3D TSV technology. The 3D implementation shows that the 3D ICs can alleviate the pressure from I/O pin count and allow parallel memory accesses through multiple channels.",
Uncertain Range Queries for Necklaces,"We address the problem of efficient processing of spatio-temporal range queries for moving objects whose whereabouts in time are not known exactly. The fundamental question tackled by such queries is, given a spatial region and a temporal interval, retrieve the objects that were inside the region during the given interval. As earlier works have demonstrated, when the location, time information is uncertain, syntactic constructs are needed to capture the impact of the uncertainty, along with the corresponding processing algorithms. In this work, we focus on the uncertainty model that represents the whereabouts in-between two known locations as a bead and an uncertain trajectory is represented as a necklace -- a sequence of beads. For each syntactic variant of the range query, we present the respective processing algorithms and, in addition, we propose pruning strategies that speed up the generation of the queries' answers. We also present the experimental observations that quantify the benefits of our proposed methodologies.","Uncertainty,
Computer science,
Environmental management,
Global Positioning System,
Sensor systems,
Mobile computing,
Conference management,
Engineering management,
Information management,
Navigation"
Interactive modelling for AR applications,"We present a method for estimating the 3D shape of an object from a sequence of images captured by a hand-held device. The method is well suited to augmented reality applications in that minimal user interaction is required, and the models generated are of an appropriate form. The method proceeds by segmenting the object in every image as it is captured and using the calculated silhouette to update the current shape estimate. In contrast to previous silhouette-based modelling approaches, however, the segmentation process is informed by a 3D prior based on the previous shape estimate. A voting scheme is also introduced in order to compensate for the inevitable noise in the camera position estimates. The combination of the voting scheme with the closed-loop segmentation process provides a robust and flexible shape estimation method. We demonstrate the approach on a number of scenes where segmentation without a 3D prior would be challenging.","Image segmentation,
Three dimensional displays,
Cameras,
Solid modeling,
Shape,
Pixel,
Image color analysis"
Two novel Ant Colony Optimization approaches for Bayesian network structure learning,"Learning Bayesian networks from data is an NP-hard problem with important practical applications. Several researchers have designed algorithms to overcome the computational complexity of this task. Difficult challenges remain however in reducing computation time for structure learning in networks of medium to large size and in understanding problem-dependent aspects of performance. In this paper, we present two novel algorithms (ChainACO and K2ACO) that use Ant Colony Optimization (ACO). Both algorithms search through the space of orderings of data variables. The ChainACO approach uses chain structures to reduce computational complexity of evaluation but at the expense of ignoring the richer structure that is explored in the K2ACO approach. The novel algorithms presented here are ACO versions of previously published GA approaches. We are therefore able to compare ACO vs GA algorithms and Chain vs K2 evaluations. We present a series of experiments on three well-known benchmark problems. Our results show problem-specific trade-offs between solution quality and computational effort. However it seems that the ACO-based approaches might be favored for larger problems, achieving better fitnesses and success rate than their GA counterparts on the largest network studied in our experiments.","Measurement,
Algorithm design and analysis,
Asia,
Heuristic algorithms,
Bayesian methods,
Probabilistic logic,
Benchmark testing"
Spatio-temporal modeling of grasping actions,"Understanding the spatial dimensionality and temporal context of human hand actions can provide representations for programming grasping actions in robots and inspire design of new robotic and prosthetic hands. The natural representation of human hand motion has high dimensionality. For specific activities such as handling and grasping of objects, the commonly observed hand motions lie on a lower-dimensional non-linear manifold in hand posture space. Although full body human motion is well studied within Computer Vision and Biomechanics, there is very little work on the analysis of hand motion with nonlinear dimensionality reduction techniques. In this paper we use Gaussian Process Latent Variable Models (GPLVMs) to model the lower dimensional manifold of human hand motions during object grasping. We show how the technique can be used to embed high-dimensional grasping actions in a lower-dimensional space suitable for modeling, recognition and mapping.","Grasping,
Humans,
Principal component analysis,
Kernel,
Robots,
Trajectory,
Joints"
Iterative Soft Compensation for OFDM Systems with Clipping and Superposition Coded Modulation,"This paper deals with the clipping method used in orthogonal frequency-division multiplexing (OFDM) systems to reduce the peak-to-average power ratio (PAPR). An iterative soft compensation method is proposed to mitigate the clipping distortion, which can outperform conventional treatments. The impact of signaling schemes on the residual clipping noise power is studied via the symbol variance analysis. It is found that superposition coded modulation (SCM) can minimize the residual clipping noise power among all possible signaling schemes. This indicates that SCM-based OFDM systems are more robust to clipping effect than other alternatives when soft compensation is applied. It is also shown that a multi-code SCM scheme can further reduce the clipping effect and its overall performance can be quickly evaluated using a semi-analytical evolution method. Numerical examples are provided to verify the analysis.",
PEGASIS Protocol in Wireless Sensor Network Based on an Improved Ant Colony Algorithm,"This paper proposes a routing protocol for the applications of Wireless Sensor Network (WSN). It is a protocol based on the PEGASIS protocol but using an improved ant colony algorithm rather than the greedy algorithm to construct the chain. Compared with the original PEGASIS, this one, PEG-ant, can achieve a global optimization. It forms a chain that makes the path more even-distributed and the total square of transmission distance much less. Moreover, in the constructing process, the energy factor has been taken into account, which brings about a balance of energy consumption between nodes. In each round of transmission, according to the current energy of each node, a leader is selected to directly communicate with the base station (BS). Simulation results have show that the proposed protocol significantly prolongs the network lifetime.",
Maximum Amplitude Method for Estimating Compact Fractional Fourier Domain,"A maximum-amplitude-based coarse-to-fine algorithm is proposed with two novel ideas highlighted: adopting the maximum value of the fractional Fourier amplitude spectrum to measure the compactness of a signal, and using a coarse-to-fine strategy to speed up the searching process. The simulation results on synthetic and real signals show the validity of the proposed method.","Amplitude estimation,
Fourier transforms,
Signal processing,
Frequency,
Computer science,
Signal processing algorithms,
Velocity measurement,
Solids,
Bandwidth,
Genetic algorithms"
Stiffness modulation for Haptic Augmented Reality: Extension to 3D interaction,"Haptic Augmented Reality (AR) allows a user to touch a real environment augmented with synthetic haptic stimuli. For example, medical students can palpate a virtual tumor inside a real mannequin using a haptic AR system to practice cancer detection. To realize such functionality, we need to alter the haptic attributes of a real object by means of virtual haptic feedback. Previously, we presented a haptic AR system with stiffness as a goal modulation property, and demonstrated its competent physical and perceptual performances for 1D interaction. In this paper, we extend the system so that a user can interact with a real object in any 3D exploratory pattern while perceiving its augmented stiffness. A series of algorithms are developed for contact detection, deformation estimation, force rendering, and force control. Their performances are thoroughly evaluated with real samples. A particular focus has been on minimizing the amount of preprocessing such as geometry modeling. Our haptic AR system can provide convincing stiffness modulation for real objects of relatively homogeneous deformation properties. The limitations of our AR system are also discussed along with a plan for future work.","Haptic interfaces,
Augmented reality,
Neoplasms,
Virtual reality,
Performance evaluation,
Space technology,
Force control,
Industrial training,
Computer science,
Biomedical engineering"
Position-Dependent Threshold-Voltage Variation by Random Telegraph Noise in nand Flash Memory Strings,"The position dependence of threshold-voltage change (ΔVth) in floating-gate NAND Flash cell strings due to random telegraph noise was characterized. It was found that the cumulative distribution of ΔVth's measured from 100 cell devices at word line 31 (WL31) is broader than that at WL0 due to smaller transconductance (Gm). As the position of a read cell in the string is changed from WL0 to WL31, maximum Gm decreases by ~50% since the equivalent source resistance (Rs) of the read cell increases. Decreasing Gm makes the slope of the Iread - Vread curve low, which increases ΔVth at the same noise current fluctuation. It was also shown that the Gm (finally, ΔVth) of a read cell can be changed by controlling the pass bias since the pass bias changes the channel resistance (≈ Rs) of the pass cells.",
Real-time aerial image mosaicing,"This paper describes a scheme for seamlessly stitching together images captured from an aerial platform, in real-time, in order to provide an operator with a larger field-of-view. Both recent images, and images from earlier in a flight are used. To obtain real-time performance several of the latest computer vision techniques are applied: firstly the Bag-of-Words image representation allows overlapping images to be found efficiently, and provides cheap wide-baseline correspondences between them. Secondly the BaySAC robust estimation framework allows images to be registered efficiently from a prior motion model combined with large numbers of potential matches between cheap image patch descriptors. Thirdly an efficient seam-placement algorithm allows the rendering of a visually attractive mosaic. Results are presented on a sequence of high-resolution images captured from a microlight.","Real time systems,
Cameras,
Feature extraction,
Transforms,
Image edge detection,
Dictionaries,
Image representation"
Skip-links: A dynamically reconfiguring topology for energy-efficient NoCs,"We introduce the Skip-link architecture that dynamically reconfigures Network-on-Chip (NoC) topologies, in order to reduce the overall switching activity in many-core systems. The proposed architecture allows the creation of long-range Skip-links at runtime to reduce the logical distance between frequently communicating nodes. This offers a number of advantages over existing methods of creating optimised topologies already present in the literature such as the Reconfigurable NoC (ReNoC) architecture and static Long-Range Link (LRL) insertion. Our architecture monitors traffic behaviour and optimises the mesh topology without prior analysis of communications behaviour, and is thus applicable to all applications. Our technique does not utilise a master node, and each router acts independently. The architecture is thus scalable to future many-core networks. We evaluate the performance using a cycle-accurate simulation with synthetic traffic patterns and compare the results to a mesh architecture, demonstrating hop count and energy reductions of around 10%.","Topology,
Network topology,
Tornadoes,
Computer architecture,
Routing,
Energy consumption,
Switches"
Pixel readout ASIC with per pixel digitization and digital storage for the DSSC detector at XFEL,"The DSSC collaboration is developing an instrument for the detection of synchrotron X-rays (E > 0.5 keV) at XFEL. The hexagonal pixels of a DEPFET based sensor with integrated signal compression will be read out by bump-bonded pixel readout ASICs. Each ASIC will have 64 × 64 pixel channels of 236 × 204 μm2 area, each one containing a low-noise (< 50 e−) amplification of the DEPFET signal, an 8 bit single-slope ADC and a digital memory, as well as other blocks for test injection, gain switching and trimming. Data is acquired during the XFEL burst at a rate of up to 4.5 MHz. The signal is first processed by a trapezoidal shaping filter, digitized immediately and then stored to the in-pixel memory of > 512 events capacity. The accumulated digital data is transferred off chip during the 100 ms long burst gaps on a single serial link while the analogue sections are shut down to bring the average power dissipation to < 100 mW per ASIC. The chip architecture is described and results obtained from first test chips are presented.","Pixel,
Capacitors,
Random access memory,
Noise,
Decision support systems,
X-rays,
Application specific integrated circuits"
Collaborative spectrum sensing in the presence of Byzantine attacks in Cognitive Radio Networks,"Cognitive radio (CR) has emerged as a solution to the problem of spectrum scarcity as it exploits the transmission opportunities in the under-utilized spectrum bands of primary users. Collaborative (or distributed) spectrum sensing has been shown to have various advantages in terms of spectrum utilization and robustness. The data fusion scheme is a key component of collaborative spectrum sensing. In this paper, we analyze the performance limits of collaborative spectrum sensing under Byzantine Attacks where malicious users send false sensing data to the fusion center leading to increased probability of incorrect sensing results. We show that above a certain fraction of Byzantine attackers in the CR network, data fusion scheme becomes completely incapable and no reputation based fusion scheme can achieve any performance gain. We present optimal attacking strategies for given attacking resources and also analyze the possible counter measures at the fusion center (FC).","Collaboration,
Cognitive radio,
Wireless sensor networks,
Chromium,
Performance analysis,
Counting circuits,
Communication system security,
Frequency,
Availability,
Degradation"
"Analysis of Nonlinear Characteristics for a Three-Phase, Five-Limb Transformer Under DC Bias","Monopole HVDC systems create dc current flow in the earth, which can cause the grounding location potential to rise relative to infinite spot and alters the working point of the transformer core. Because of the nonlinearity of the transformer core, the exciting current produces the amount of harmonics under dc bias. Past research has focused almost on simulation and testing dc bias problems of single-phase transformers. However, due to the complicated magnetic circuit structure in a three-phase five-limb transformer, there are some difficulties in studying its dc bias problem. In this paper, a new model and algorithm are proposed to find the nonlinear characteristics for the three-phase five-limb transformer under dc bias. Maxwell's equations are used to replace the magnetic circuit model of the transformer. By combining an electrical circuit with the nonlinear characteristic curve of the core, dc bias problems for a three-phase five-limb transformer are studied. Results show that the waveform of the no-load current and magnetic field intensity of the transformer are distorted under dc current inrush, and low-order harmonics increase with increasing dc current. Finally the interior and exterior nonlinear curve characteristics under dc bias are discussed.","Transformer cores,
Magnetic circuits,
HVDC transmission,
Grounding,
Circuit simulation,
Circuit testing,
Phase transformers,
Maxwell equations,
Magnetic cores,
Magnetic fields"
Novel sequence design for low-PMEPR and high-code-rate OFDM systems,"In this paper, we propose a new family of 64-QAM based sequences for achieving the lowest PMEPR and the highest code rate compared to all other 64-QAM based schemes, which can be applied for OFDM systems. The construction of the proposed sequences is simple and the theoretical analysis is presented.","Upper bound,
Computer science,
Quadrature amplitude modulation,
Spectroscopy,
Acoustic measurements,
OFDM modulation,
Communications Society,
Systems engineering and theory,
Information technology"
Solving Sudoku with genetic operations that preserve building blocks,Genetic operations that consider effective building blocks are proposed for using genetic algorithms to solve Sudoku puzzles. A stronger local search function is also proposed. Evaluation of the proposed techniques using commercial Sudoku puzzle sets and three puzzles ranked as super difficult compared with previously reported examples show that the rate of optimum solutions can be greatly improved. It is demonstrated that even further improvement in accuracy is expected from a correction technique based on disparity hypothesis.,
Scaling Populations of a Genetic Algorithm for Job Shop Scheduling Problems Using MapReduce,"Inspired by Darwinian evolution, a genetic algorithm (GA) approach is one popular heuristic method for solving hard problems such as the Job Shop Scheduling Problem (JSSP), which is one of the hardest problems lacking efficient exact solutions today. It is intuitive that the population size of a GA may greatly affect the quality of the solution, but it is unclear what are the effects of having population sizes that are significantly greater than typical experiments. The emergence of MapReduce, a framework running on a cluster of computers that aims to provide large-scale data processing, offers great opportunities to investigate this issue. In this paper, a GA is implemented to scale the population using MapReduce. Experiments are conducted on a large cluster, and population sizes up to 10^7 are inspected. It is shown that larger population sizes not only tend to yield better solutions, but also require fewer generations. Therefore, it is clear that when dealing with a hard problem such as JSSP, an existing GA can be improved by massively scaling up populations with MapReduce, so that the solution can be parallelized and completed in reasonable time.","Gallium,
Biological cells,
Schedules,
Genetic algorithms,
Cloud computing,
Job shop scheduling,
Decoding"
Learning the elasticity parameters of deformable objects with a manipulation robot,"In this paper, we consider the problem of determining the elasticity properties of deformable objects with a mobile manipulator equipped with a force sensorb. We learn the parameters by establishing a relation between the applied forces and the corresponding surface deformations. To determine the parameters, we minimize the difference between the observed surface of an object that is deformed by a real manipulator and the deformed surface obtained with a deformation simulator based on finite element methods. To establish the correspondences between the surfaces, our approach applies a 3D registration technique based on point-clouds which is used as the basis for comparing the results of the simulation system with the observations of the real deformations. As we demonstrate in real-world experiments, our system is able to estimate appropriate parameters that can be used to predict future deformations. This information can directly be incorporated into motion planning approaches that are designed for robots operating with deformable objects.","Deformable models,
Computational modeling,
Force,
Force measurement,
Elasticity,
Robot sensing systems"
A Sensor Fusion Framework Using Multiple Particle Filters for Video-Based Navigation,"This paper presents a sensor-fusion framework for video-based navigation. Video-based navigation offers the advantages over existing approaches. With this type of navigation, road signs are directly superimposed onto the video of the road scene, as opposed to those superimposed onto a 2-D map, as is the case with conventional navigation systems. Drivers can then follow the virtual signs in the video to travel to the destination. The challenges of video-based navigation require the use of multiple sensors. The sensor-fusion framework that we propose has two major components: (1) a computer vision module for accurately detecting and tracking the road by using partition sampling and auxiliary variables and (2) a sensor-fusion module using multiple particle filters to integrate vision, Global Positioning Systems (GPSs), and Geographical Information Systems (GISs). GPS and GIS provide prior knowledge about the road for the vision module, and the vision module, in turn, corrects GPS errors.",
The comparison between cloud computing and grid computing,"It is a great idea to make many normal computers together to get a super computer, and this computer can do a lot of things. This is the concept of cloud computing. Cloud computing is an emerging model of business computing. And it is becoming a development trend. This article compares cloud computing and grid computing. Internet has connected all the computers in the world. Grid computing has been put forward under this background. Its core concept is to complete computing based on compute grid, in it every computer will devote power. In recent years a new concept cloud computing has been put forward, it can connect millions of computers to a super cloud. This article also introduces the application field the merit of cloud computing, such as, it do not need user's high level equipment, so it reduces the user's cost. It provides secure and dependable data storage center, so user needn't do the awful things such storing data and killing virus, this kind of task can be done by professionals. It can realize data share through different equipments. The users need not know how the cloud runs. In this paper I describe the concept of cloud computing and grid computing and compare them.","Cloud computing,
Grid computing,
Clouds,
Computers,
Software,
Servers"
Comparative Power Analysis of Modular Exponentiation Algorithms,"This paper proposes new chosen-message power-analysis attacks for public-key cryptosystems based on modular exponentiation, where specific input pairs are used to generate collisions between squaring operations at different locations in the two power traces. Unlike previous attacks of this kind, the new attack can be applied to all standard implementations of the exponentiation process, namely binary (left-to-right and right-to-left), m-ary, and sliding window methods. The proposed attack can also circumvent typical countermeasures, such as the Montgomery powering ladder and the double-add algorithm. The effectiveness of the attack is demonstrated in experiments with hardware and software implementations of RSA on an FPGA and a PowerPC processor, respectively. In addition to the new collision generation methods, a highly accurate waveform matching technique is introduced for detecting the collisions even when the recorded signals are noisy and there is a certain amount of clock jitter.","Estimation,
Computational efficiency,
Data mining,
Software algorithms,
Software,
Clocks,
Cathode ray tubes"
A dynamic voltage scaling algorithm for wireless sensor networks,"A wireless sensor node is often powered by battery which is not easily replaced, so researching how to use its limited energy effectively is the meaningful thing for wireless sensor networks (WSNs). Dynamic voltage scaling (DVS) has become a promising way for wireless sensor networks to exploit multiple voltage and frequency levels and prolong the sensor node's life. However, pure DVS for embedded systems did not perform well without considering the feature of wireless sensor networks' workloads. This paper proposed a task-driven feedback dynamic voltage scaling algorithm based on the multihop routing and topology changed easily could scale the working frequency and voltage levels dynamically according to the workloads of sensor node, fix the errors through feedback scheme and reduce the node's power consumption at the premise of real-time tasks. The results of simulation indicated that the improved algorithm could effectively reduce almost 30% more energy consumption than previous dynamic voltage scaling algorithm and prolong the life of wireless sensor networks significantly.",
Ferroelectric (Fe)-NAND Flash Memory With Batch Write Algorithm and Smart Data Store to the Nonvolatile Page Buffer for Data Center Application High-Speed and Highly Reliable Enterprise Solid-State Drives,"A ferroelectric (Fe)-NAND flash memory with a batch write algorithm and a smart data store to the nonvolatile page buffer is proposed. An enterprise solid-state drive (SSD) for a data center is a future promising market of NAND flash memories. The critical problem for such an enterprise SSD is a slow random write. The write unit in a NAND flash memory is a page, 4-8 KBytes. Because the minimum write unit of the operating system is a sector, 512 Bytes, a random write to write a smaller data than a page size frequently happens, which creates a garbage. As a garbage accumulates, a garbage collection is performed to increase a workable memory capacity. The garbage collection takes as much as 100 ms, which is 100 times longer than a page program time, 800 μs, and thus causes a serious performance degradation. In the proposed Fe-NAND flash memory, the data fragmentation in a random write is removed by introducing a batch write algorithm where a page buffer in the Fe-NAND flash memory temporarily stores a program data. The memory cell program starts after the program data as much as the page size accumulates in page buffers. As the data fragmentation is eliminated, the SSD performance can double. In addition, the nonvolatile page buffer realizes a power-outage-immune highly reliable operation. With a low program/erase voltage of 6 V and a high endurance of 100 million cycles, the proposed Fe-NAND flash memory is most suitable for a highly reliable highspeed low-power data-center-application enterprise SSD.","Ash,
Nonvolatile memory,
Latches,
Buffer storage,
Computer architecture,
Flash memory,
Registers"
